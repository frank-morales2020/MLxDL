{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Copy_of_news_RNN_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN-based language model\n",
        "\n",
        "## Utility functions and classes\n",
        "\n",
        "In the cell below, we import the dependencies and define the utility functions and the model class:"
      ],
      "metadata": {
        "id": "4k_iGNa_JVHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CS2WM3jQ9uI",
        "outputId": "f3a4f99f-99dd-4052-caaa-f1cf88d6e168"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 10 19:47:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yy0zjL_2ouOU"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os               # For file and path operations (check_file_exists, extract_dataset)\n",
        "import urllib.request   # For downloading dataset files from URLs\n",
        "import tarfile          # For extracting .tar.gz dataset archives\n",
        "import torch            # Main PyTorch library for tensor operations and deep learning\n",
        "import torch.nn as nn   # Neural network modules, layers, and utilities\n",
        "from torch.utils.data import DataLoader, IterableDataset  # For efficient data loading and streaming\n",
        "import random           # For setting random seeds in reproducibility\n",
        "from tqdm import tqdm   # For progress bars in training and evaluation\n",
        "import math             # For computing perplexity using exp()\n",
        "import re               # For preprocessing text (replacing numbers with placeholders)\n",
        "from transformers import AutoTokenizer # For loading a pre-trained tokenizer\n",
        "\n",
        "# ----------------------------\n",
        "# Utility Functions\n",
        "# ----------------------------\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Sets random seeds for reproducibility across different Python libraries.\n",
        "    This ensures that random operations give the same results across runs.\n",
        "\n",
        "    Args:\n",
        "        seed (int): Seed value for random number generation\n",
        "    \"\"\"\n",
        "    # Set seed for Python's built-in random module\n",
        "    random.seed(seed)\n",
        "    # Set seed for PyTorch's CPU random number generator\n",
        "    torch.manual_seed(seed)\n",
        "    # Set seed for PyTorch's GPU random number generator\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # Forces cuDNN to use deterministic algorithms for better reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # Disables cuDNN's auto-tuner which finds the best algorithm for your specific input size\n",
        "    # Ensures consistent behavior but might be slower as it doesn't optimize for input sizes\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class IterableTextDataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    An iterable dataset for processing text data in a memory-efficient way.\n",
        "    Instead of loading all data into memory, it streams data from disk.\n",
        "    Inherits from PyTorch's IterableDataset for streaming support.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the text file containing sentences\n",
        "        tokenizer: Tokenizer object for converting text to tokens\n",
        "        max_length (int): Maximum sequence length to process (default: 30)\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, tokenizer, max_length=30):\n",
        "        # Store file path for reading data\n",
        "        self.file_path = file_path\n",
        "        # Store tokenizer for text processing\n",
        "        self.tokenizer = tokenizer\n",
        "        # Set maximum sequence length to truncate long sequences\n",
        "        self.max_length = max_length\n",
        "        self._count_sentences()\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        Creates an iterator over the dataset.\n",
        "        This method is called when iterating over the dataset.\n",
        "\n",
        "        Yields:\n",
        "            tuple: (input_sequence, target_sequence) pairs for language modeling\n",
        "                  input_sequence is the sequence up to the last token\n",
        "                  target_sequence is the sequence shifted one position right\n",
        "        \"\"\"\n",
        "        # Open file in read mode with UTF-8 encoding\n",
        "        with open(self.file_path, 'r', encoding='utf-8') as f:\n",
        "            # Process each line (sentence) in the file\n",
        "            for line in f:\n",
        "                # Remove leading/trailing whitespace\n",
        "                sentence = line.strip()\n",
        "                # Replace all numbers with ### placeholder\n",
        "                # This reduces vocabulary size and helps model generalize\n",
        "                sentence = re.sub(r'\\d+', '###', sentence)\n",
        "\n",
        "                # Convert sentence to token IDs\n",
        "                encoded_sentence = self.tokenizer.encode(\n",
        "                    sentence,\n",
        "                    max_length=self.max_length,\n",
        "                    truncation=True\n",
        "                )\n",
        "\n",
        "                # Only use sequences with at least 2 tokens\n",
        "                # (need at least one input and one target token)\n",
        "                if len(encoded_sentence) >= 2:\n",
        "                    # Input is all tokens except last\n",
        "                    input_seq = encoded_sentence[:-1]\n",
        "                    # Target is all tokens except first\n",
        "                    target_seq = encoded_sentence[1:]\n",
        "                    # Convert to PyTorch tensors and yield\n",
        "                    yield torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return self._num_sentences\n",
        "\n",
        "    def _count_sentences(self):\n",
        "        print(f\"Counting sentences in {self.file_path}...\")\n",
        "        with open(self.file_path, 'r', encoding='utf-8') as f:\n",
        "            self._num_sentences = sum(1 for _ in f)\n",
        "        print(f\"Found {self._num_sentences} sentences in {self.file_path}.\")\n",
        "\n",
        "## ----------------------------\n",
        "## Download and prepare data\n",
        "## ----------------------------\n",
        "\n",
        "def create_collate_fn(tokenizer):\n",
        "    \"\"\"\n",
        "    Creates a collate function for batching sequences of different lengths.\n",
        "    This function pads shorter sequences to match the longest sequence in the batch.\n",
        "\n",
        "    Args:\n",
        "        tokenizer: Tokenizer object containing padding token information\n",
        "\n",
        "    Returns:\n",
        "        function: Collate function that handles padding in batches\n",
        "    \"\"\"\n",
        "    def collate_fn(batch):\n",
        "        # Separate inputs and targets from batch\n",
        "        input_seqs, target_seqs = zip(*batch)\n",
        "        # Get padding token ID from tokenizer\n",
        "        pad_index = tokenizer.pad_token_id\n",
        "        # Pad input sequences to same length\n",
        "        input_padded = nn.utils.rnn.pad_sequence(input_seqs, batch_first=True, padding_value=pad_index)\n",
        "        # Pad target sequences to same length\n",
        "        target_padded = nn.utils.rnn.pad_sequence(target_seqs, batch_first=True, padding_value=pad_index)\n",
        "        return input_padded, target_padded\n",
        "    return collate_fn\n",
        "\n",
        "def check_file_exists(filename):\n",
        "    \"\"\"\n",
        "    Checks if a file exists in the current directory.\n",
        "    Args:\n",
        "        filename (str): Name of the file to check\n",
        "    Returns:\n",
        "        bool: True if file exists, False otherwise\n",
        "    \"\"\"\n",
        "    return os.path.exists(filename)\n",
        "\n",
        "def download_file(url):\n",
        "    \"\"\"\n",
        "    Downloads a file from the given URL if it doesn't exist locally, handling redirects.\n",
        "    Forces the downloaded file to be saved as news.tar.gz regardless of URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of the file to download\n",
        "    Returns:\n",
        "        str: Name of the downloaded file\n",
        "    \"\"\"\n",
        "    # Always use news.tar.gz as the filename, regardless of URL\n",
        "    filename = \"news.tar.gz\"\n",
        "\n",
        "    if not check_file_exists(filename):\n",
        "        print(f\"Downloading dataset from {url}...\")\n",
        "        req = urllib.request.Request(\n",
        "            url,\n",
        "            headers={'User-Agent': 'Mozilla/5.0'}\n",
        "        )\n",
        "        with urllib.request.urlopen(req) as response:\n",
        "            with open(filename, 'wb') as out_file:\n",
        "                out_file.write(response.read())\n",
        "        print(\"Download completed.\")\n",
        "    else:\n",
        "        print(f\"{filename} already downloaded.\")\n",
        "    return filename\n",
        "\n",
        "def is_within_directory(directory, target):\n",
        "    \"\"\"\n",
        "    Checks if a target path is within a specified directory (prevents path traversal).\n",
        "    Args:\n",
        "        directory (str): Base directory path\n",
        "        target (str): Target path to check\n",
        "    Returns:\n",
        "        bool: True if target is within directory, False otherwise\n",
        "    \"\"\"\n",
        "    abs_directory = os.path.abspath(directory)\n",
        "    abs_target = os.path.abspath(target)\n",
        "    prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "    return prefix == abs_directory\n",
        "\n",
        "def extract_dataset(filename):\n",
        "    \"\"\"\n",
        "    Extracts train.txt and test.txt from the downloaded archive.\n",
        "    Includes debug information about archive contents.\n",
        "\n",
        "    Args:\n",
        "        filename (str): Name of the archive file\n",
        "    Returns:\n",
        "        tuple: Paths to extracted train and test files\n",
        "    \"\"\"\n",
        "    data_dir = os.path.join(os.path.dirname(filename), 'news')\n",
        "    train_path = os.path.join(data_dir, 'train.txt')\n",
        "    test_path = os.path.join(data_dir, 'test.txt')\n",
        "\n",
        "    if check_file_exists(train_path) and check_file_exists(test_path):\n",
        "        print(\"Data files already extracted.\")\n",
        "        return train_path, test_path\n",
        "\n",
        "    print(\"\\nListing archive contents:\")\n",
        "    with tarfile.open(filename, 'r:gz') as tar:\n",
        "        for member in tar.getmembers():\n",
        "            print(f\"Archive member: {member.name}\")\n",
        "\n",
        "        print(\"\\nExtracting files...\")\n",
        "        # Extract to current directory first\n",
        "        tar.extractall('.')\n",
        "\n",
        "    if not (check_file_exists(train_path) and check_file_exists(test_path)):\n",
        "        raise FileNotFoundError(f\"Required files not found in the archive. Please check the paths above.\")\n",
        "\n",
        "    print(\"Extraction completed.\")\n",
        "    return train_path, test_path\n",
        "\n",
        "def create_datasets(train_file, test_file, tokenizer):\n",
        "    \"\"\"\n",
        "    Creates IterableTextDataset objects for training and testing.\n",
        "    These datasets will stream data from disk instead of loading it all into memory.\n",
        "\n",
        "    Args:\n",
        "        train_file (str): Path to training data file\n",
        "        test_file (str): Path to test data file\n",
        "        tokenizer: Tokenizer object for text processing\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataset, test_dataset) - Dataset objects for training and testing\n",
        "    \"\"\"\n",
        "    # Create training dataset\n",
        "    train_dataset = IterableTextDataset(train_file, tokenizer)\n",
        "    # Create test dataset\n",
        "    test_dataset = IterableTextDataset(test_file, tokenizer)\n",
        "\n",
        "    # Print dataset sizes\n",
        "    print(f\"Training sentences: {len(train_dataset)}\")\n",
        "    print(f\"Test sentences: {len(test_dataset)}\")\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def create_dataloaders(train_dataset, test_dataset, batch_size, collate_fn):\n",
        "    \"\"\"\n",
        "    Creates DataLoader objects that handle batching and shuffling of data.\n",
        "    DataLoaders provide iterators over the datasets with automatic batching.\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Training dataset\n",
        "        test_dataset: Test dataset\n",
        "        batch_size (int): Number of sequences per batch\n",
        "        collate_fn: Function to handle padding when creating batches\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataloader, test_dataloader) - DataLoader objects\n",
        "    \"\"\"\n",
        "    # Create training data loader\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,    # Function to handle padding\n",
        "        num_workers=0             # Number of worker processes (0 = single process)\n",
        "    )\n",
        "    # Create test data loader\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0\n",
        "    )\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "def download_and_prepare_data(url, batch_size, tokenizer):\n",
        "    \"\"\"\n",
        "    Main function to handle the complete data preparation pipeline.\n",
        "    Downloads data, extracts it, and creates necessary dataset objects.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL where the dataset archive can be downloaded\n",
        "        batch_size (int): Batch size for data loading\n",
        "        tokenizer: Tokenizer object for text processing\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataloader, test_dataloader) - Ready-to-use data loaders\n",
        "    \"\"\"\n",
        "    # Step 1: Download dataset archive from URL\n",
        "    filename = download_file(url)\n",
        "\n",
        "    # Step 2: Extract training and test files from archive\n",
        "    train_file, test_file = extract_dataset(filename)\n",
        "\n",
        "    # Step 3: Create dataset objects for streaming data\n",
        "    train_dataset, test_dataset = create_datasets(train_file, test_file, tokenizer)\n",
        "\n",
        "    # Step 4: Create function to handle batch creation\n",
        "    collate_fn = create_collate_fn(tokenizer)\n",
        "\n",
        "    # Step 5: Create and return data loaders\n",
        "    return create_dataloaders(train_dataset, test_dataset, batch_size, collate_fn)\n",
        "\n",
        "# ----------------------------\n",
        "# Recurrent Language Model Class\n",
        "# ----------------------------\n",
        "\n",
        "def initialize_weights(model):\n",
        "    \"\"\"\n",
        "    Initializes model weights using Xavier uniform initialization for multi-dimensional\n",
        "    parameters and uniform initialization for biases and other 1D parameters.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): PyTorch model whose weights need to be initialized\n",
        "    \"\"\"\n",
        "    # Loop through all named parameters in the model\n",
        "    for name, param in model.named_parameters():\n",
        "        # Check if parameter has more than 1 dimension (e.g., weight matrices)\n",
        "        if param.dim() > 1:\n",
        "            # Use Xavier uniform initialization for weight matrices\n",
        "            # This helps prevent vanishing/exploding gradients by keeping the variance constant\n",
        "            nn.init.xavier_uniform_(param)\n",
        "        else:\n",
        "            # For 1D parameters (like biases), use simple uniform initialization\n",
        "            nn.init.uniform_(param)\n",
        "\n",
        "class ElmanRNNUnit(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of a single Elman RNN unit (a simple recurrent neural network cell).\n",
        "    This is the basic building block of our RNN that processes one time step of input.\n",
        "\n",
        "    Args:\n",
        "        emb_dim (int): Dimension of the embedding/hidden state vectors\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim):\n",
        "        super(ElmanRNNUnit, self).__init__()\n",
        "        # Hidden-to-hidden weight matrix: transforms previous hidden state\n",
        "        # Shape: (emb_dim, emb_dim)\n",
        "        self.Uh = nn.Parameter(torch.rand(emb_dim, emb_dim))\n",
        "\n",
        "        # Input-to-hidden weight matrix: transforms current input\n",
        "        # Shape: (emb_dim, emb_dim)\n",
        "        self.Wh = nn.Parameter(torch.rand(emb_dim, emb_dim))\n",
        "\n",
        "        # Bias term added to the sum of transformations\n",
        "        # Shape: (emb_dim,)\n",
        "        self.b = nn.Parameter(torch.rand(emb_dim))\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        \"\"\"\n",
        "        Computes one step of the RNN unit.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Current input tensor of shape (batch_size, emb_dim)\n",
        "            h (torch.Tensor): Previous hidden state of shape (batch_size, emb_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: New hidden state of shape (batch_size, emb_dim)\n",
        "\n",
        "        The formula implemented is: h_new = tanh(x @ Wh + h @ Uh + b)\n",
        "        where @ represents matrix multiplication\n",
        "        \"\"\"\n",
        "        # 1. Transform current input: x @ Wh\n",
        "        input_transform = x @ self.Wh\n",
        "\n",
        "        # 2. Transform previous hidden state: h @ Uh\n",
        "        hidden_transform = h @ self.Uh\n",
        "\n",
        "        # 3. Add both transformations and bias\n",
        "        # 4. Apply tanh activation function to get new hidden state\n",
        "        # tanh squashes values to range (-1, 1), helping prevent exploding gradients\n",
        "        return torch.tanh(input_transform + hidden_transform + self.b)\n",
        "\n",
        "class ElmanRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer Elman RNN implementation that processes entire sequences.\n",
        "    Stacks multiple RNN units to create a deeper network that can learn more complex patterns.\n",
        "\n",
        "    Args:\n",
        "        emb_dim (int): Dimension of embeddings and hidden states\n",
        "        num_layers (int): Number of stacked RNN layers\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Create a list of RNN units, one for each layer\n",
        "        # ModuleList is used so PyTorch tracks all parameters\n",
        "        self.rnn_units = nn.ModuleList(\n",
        "            [ElmanRNNUnit(emb_dim) for _ in range(num_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Processes input sequence through all RNN layers.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, emb_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, emb_dim)\n",
        "        \"\"\"\n",
        "        # Get dimensions from input tensor\n",
        "        batch_size, seq_len, emb_dim = x.size()\n",
        "\n",
        "        # Initialize hidden states for each layer with zeros\n",
        "        # Each hidden state has shape (batch_size, emb_dim)\n",
        "        h_prev = [\n",
        "            torch.zeros(batch_size, emb_dim, device=x.device)\n",
        "            for _ in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "        # Will store outputs for each time step\n",
        "        outputs = []\n",
        "\n",
        "        # Process each time step\n",
        "        for t in range(seq_len):\n",
        "            # Get input for current time step\n",
        "            input_t = x[:, t]\n",
        "\n",
        "            # Process through each layer\n",
        "            for l, rnn_unit in enumerate(self.rnn_units):\n",
        "                # Compute new hidden state for this layer\n",
        "                h_new = rnn_unit(input_t, h_prev[l])\n",
        "\n",
        "                # Update hidden state for this layer\n",
        "                h_prev[l] = h_new\n",
        "\n",
        "                # Output of this layer becomes input to next layer\n",
        "                input_t = h_new\n",
        "\n",
        "            # Add final layer's output to results\n",
        "            outputs.append(input_t)\n",
        "\n",
        "        # Stack all time steps' outputs into a single tensor\n",
        "        # Shape: (batch_size, seq_len, emb_dim)\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "class RecurrentLanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete language model implementation combining embedding layer,\n",
        "    multi-layer RNN, and output projection layer.\n",
        "\n",
        "    The model architecture is:\n",
        "    1. Input tokens -> Embedding Layer -> Embedded Vectors\n",
        "    2. Embedded Vectors -> RNN Layers -> Context Vectors\n",
        "    3. Context Vectors -> Linear Layer -> Vocabulary Predictions\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): Size of the vocabulary (number of unique tokens)\n",
        "        emb_dim (int): Dimension of embeddings and hidden states\n",
        "        num_layers (int): Number of RNN layers\n",
        "        pad_index (int): Index used for padding tokens\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, num_layers, pad_index):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save model parameters\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.pad_index = pad_index\n",
        "\n",
        "        # Embedding layer: converts token indices to dense vectors\n",
        "        # pad_index tokens will be mapped to zero vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, pad_index)\n",
        "\n",
        "        # RNN layers for processing sequences\n",
        "        self.rnn = ElmanRNN(\n",
        "            emb_dim=emb_dim,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Final linear layer to convert RNN outputs to vocabulary predictions\n",
        "        # Output size is vocab_size to get logits for each possible token\n",
        "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Processes input sequences through the entire model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of token indices\n",
        "                            Shape: (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits for next token prediction\n",
        "                         Shape: (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        Process:\n",
        "        1. Convert token indices to embeddings\n",
        "        2. Process embeddings through RNN layers\n",
        "        3. Project RNN outputs to vocabulary size\n",
        "        \"\"\"\n",
        "        # Convert token indices to embeddings\n",
        "        # Shape: (batch_size, seq_len) -> (batch_size, seq_len, emb_dim)\n",
        "        embeddings = self.embedding(x)\n",
        "\n",
        "        # Process through RNN layers\n",
        "        # Shape: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, emb_dim)\n",
        "        rnn_output = self.rnn(embeddings)\n",
        "\n",
        "        # Project to vocabulary size to get logits\n",
        "        # Shape: (batch_size, seq_len, emb_dim) -> (batch_size, seq_len, vocab_size)\n",
        "        logits = self.fc(rnn_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def compute_loss_and_perplexity(model, vocab_size, val_dataloader, criterion, device, max_sentences=1000):\n",
        "    \"\"\"\n",
        "    Evaluates model performance by computing loss and perplexity on validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The language model to evaluate\n",
        "        val_dataloader (DataLoader): Validation data loader\n",
        "        criterion: Loss function (usually CrossEntropyLoss)\n",
        "        device: Device to run computation on (cuda/cpu)\n",
        "        max_sentences (int): Maximum number of sentences to evaluate\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, perplexity, sentences_processed)\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode (disables dropout, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize counters for loss calculation\n",
        "    total_loss = 0.0          # Accumulator for total loss across all batches\n",
        "    total_tokens = 0          # Counter for total number of tokens processed\n",
        "    sentences_processed = 0    # Counter for number of sentences processed\n",
        "\n",
        "    # Disable gradient computation for efficiency\n",
        "    with torch.no_grad():\n",
        "        # Iterate through validation data with progress bar\n",
        "        for input_seq, target_seq in tqdm(val_dataloader, desc=\"Evaluating\", leave=False):\n",
        "            # Move input and target sequences to specified device\n",
        "            input_seq = input_seq.to(device)      # Shape: (batch_size, seq_len)\n",
        "            target_seq = target_seq.to(device)    # Shape: (batch_size, seq_len)\n",
        "\n",
        "            # Get current batch size (might be smaller for last batch)\n",
        "            batch_size_current = input_seq.size(0)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            output = model(input_seq)                     # Shape: (batch_size, seq_len, vocab_size)\n",
        "            # Reshape output and target for loss calculation\n",
        "            output = output.view(-1, vocab_size)          # Shape: (batch_size * seq_len, vocab_size)\n",
        "            target = target_seq.view(-1)                  # Shape: (batch_size * seq_len)\n",
        "\n",
        "            mask = target != tokenizer.pad_token_id\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # Update counters\n",
        "            # multiply loss by number of tokens to get total loss\n",
        "            loss_value = loss.item() * mask.sum().item()\n",
        "            total_loss += loss_value\n",
        "            # Add number of actual tokens (non-padding) processed\n",
        "            total_tokens += mask.sum().item()\n",
        "\n",
        "            # Update sentence counter and check if we've reached maximum\n",
        "            sentences_processed += batch_size_current\n",
        "            if sentences_processed >= max_sentences:\n",
        "                break\n",
        "\n",
        "    # Calculate final metrics\n",
        "    average_loss = total_loss / total_tokens           # Normalize loss by number of tokens\n",
        "    perplexity = math.exp(average_loss)               # Convert loss to perplexity (lower is better)\n",
        "    return average_loss, perplexity, sentences_processed\n",
        "\n",
        "def perform_model_evaluation(model, test_dataloader, criterion, tokenizer, device, contexts):\n",
        "    \"\"\"\n",
        "    Perform evaluation of the model including loss calculation, perplexity, and text generation.\n",
        "\n",
        "    Args:\n",
        "        model: The neural network model\n",
        "        test_dataloader: DataLoader containing test/validation data\n",
        "        criterion: Loss function\n",
        "        tokenizer: Tokenizer for text generation\n",
        "        device: Device to run computations on (cuda/cpu)\n",
        "        contexts: List of context strings for text generation\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, perplexity)\n",
        "    \"\"\"\n",
        "    # Switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Compute metrics\n",
        "    average_loss, perplexity, sentences_processed = compute_loss_and_perplexity(\n",
        "        model=model,\n",
        "        vocab_size=len(tokenizer),\n",
        "        val_dataloader=test_dataloader,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        max_sentences=1000\n",
        "    )\n",
        "\n",
        "    print(f\"Validation Average Loss: {average_loss:.4f}, Perplexity: {perplexity:.2f}\")\n",
        "    print(f\"Computed on {sentences_processed} sentences\")\n",
        "\n",
        "    # Generate text using the contexts\n",
        "    print(\"Generating text based on contexts using generate_text:\\n\")\n",
        "    for context in contexts:\n",
        "        generated_text = generate_text(\n",
        "            model=model,\n",
        "            start_string=context,\n",
        "            tokenizer=tokenizer,\n",
        "            device=device,\n",
        "            max_length=50\n",
        "        )\n",
        "        print(f\"\\nContext: {context}\")\n",
        "        print(f\"\\nGenerated text: {generated_text}\\n\")\n",
        "\n",
        "    return average_loss, perplexity\n",
        "\n",
        "def generate_text(model, start_string, tokenizer, device, max_length=50):\n",
        "    \"\"\"\n",
        "    Generates text continuation from a given start string using greedy decoding.\n",
        "    This method always chooses the most likely next token.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained language model\n",
        "        start_string (str): Initial text to continue from\n",
        "        tokenizer: Tokenizer for text processing\n",
        "        device: Device to run generation on (cuda/cpu)\n",
        "        max_length (int): Maximum length of generated sequence\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text continuation\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Convert start string to token ids and move to device\n",
        "    # return_tensors='pt' returns PyTorch tensor instead of list\n",
        "    tokens = tokenizer.encode(start_string, return_tensors='pt', max_length=max_length, truncation=True).to(device)\n",
        "\n",
        "    # Initialize generated sequence with input tokens\n",
        "    generated = tokens\n",
        "\n",
        "    # Generate new tokens one at a time\n",
        "    for _ in range(max_length):\n",
        "        # Get model's predictions\n",
        "        output = model(generated)                    # Shape: (1, seq_len, vocab_size)\n",
        "        # Get logits for the next token (last position)\n",
        "        next_token_logits = output[0, -1, :]        # Shape: (vocab_size)\n",
        "\n",
        "        # Choose token with highest probability (greedy decoding)\n",
        "        # unsqueeze twice to match expected shape (1, 1)\n",
        "        next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Add new token to generated sequence\n",
        "        generated = torch.cat((generated, next_token_id), dim=1)\n",
        "\n",
        "        # Stop if end of sequence token is generated\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Convert token ids back to text\n",
        "    generated_text = tokenizer.decode(generated.squeeze().tolist())\n",
        "    return generated_text\n",
        "\n",
        "def save_model(model, tokenizer, file_prefix):\n",
        "    model_state = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'vocab_size': model.vocab_size,\n",
        "        'emb_dim': model.emb_dim,\n",
        "        'num_layers': model.num_layers,\n",
        "        'pad_index': model.pad_index,\n",
        "        'training': model.training  # Save training state\n",
        "    }\n",
        "\n",
        "    torch.save(model_state, f'{file_prefix}_model.pth')\n",
        "    tokenizer.save_pretrained(f'{file_prefix}_tokenizer')\n",
        "\n",
        "def load_model(file_prefix):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load state dict to the correct device first\n",
        "    model_state = torch.load(f'{file_prefix}_model.pth', map_location=device)\n",
        "\n",
        "    # Create model and move it to device before loading state dict\n",
        "    model = RecurrentLanguageModel(\n",
        "        model_state['vocab_size'],\n",
        "        model_state['emb_dim'],\n",
        "        model_state['num_layers'],\n",
        "        model_state['pad_index']\n",
        "    ).to(device)\n",
        "\n",
        "    # Load state dict after model is on correct device\n",
        "    model.load_state_dict(model_state['state_dict'])\n",
        "\n",
        "    # Keep model on device\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(f'{file_prefix}_tokenizer')\n",
        "    return model, tokenizer\n",
        "\n",
        "def get_hyperparameters():\n",
        "    \"\"\"\n",
        "    Returns default hyperparameters for model training.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (emb_dim, num_layers, batch_size, learning_rate, num_epochs)\n",
        "    \"\"\"\n",
        "    emb_dim = 128         # Embedding dimension\n",
        "    num_layers = 2        # Number of RNN layers\n",
        "    batch_size = 128      # Training batch size\n",
        "    learning_rate = 0.001 # Learning rate for optimization\n",
        "    num_epochs = 1        # Number of training epochs\n",
        "    return emb_dim, num_layers, batch_size, learning_rate, num_epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the language model\n",
        "\n",
        "In the cell below, we load the data, train, and save the language model:"
      ],
      "metadata": {
        "id": "xcutQEMSJg77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s61ovCwawq3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "630d21fff5244e488c6811458be81afb",
            "4d8740c3cc1f483aa59db02bb410ab80",
            "e628a38b90874e52bc19263adb041b65",
            "3e96499b15d34ea48d1f8656d621daee",
            "2a5481d7e47a493fbea2b44e0735bdfa",
            "6d9cfb2d146c47628575853dbe7cfbcb",
            "61765eddb3594cdfbc4d4b1d6be7b9f4",
            "1d5632a18d2c4341b47244f805d10404",
            "78b44428d22e4746b3624d949f065801",
            "22d23345f58c4bde89519b339150cd77",
            "6b88f3b6c36e41d2abc713b83be3b2da",
            "cfdbd84d25c940db85f44d30eb1074f7",
            "a6520655c644421db53bd988981e2c58",
            "d416271ded974c3db000d4bcaefdac22",
            "019c3a225d484a38ab93cea610da6c09",
            "c017f138eae8465e8d7247b89560991b",
            "1cecf93f058b467fa642c0f84934dd53",
            "6282fa1ed8f7473c8b1f676fcfb884ef",
            "86081ecc5c1d4bea9b206da50d8550f7",
            "0722e57fbd8b4d93b548bfb7ac198673",
            "72c6acd8bc7d4045949b0a19fe5f484d",
            "4f81fad0ff334affb501f9e4dce85825",
            "40d225a820614d13ab892c197ea4ae4f",
            "e3b95d65f1e54391ad94cf6e8f125145",
            "763c64a5c89b464d858832f55460ca04",
            "d117b339ea8b401dbeacafcf1217cc71",
            "6a5cadc6074a4ed0addedf271d364bdc",
            "0a0f124575b145efb6c6f1836e8f3eeb",
            "2f27c63f44bd43e09259b2f12ed51a98",
            "4f282c4fb45e4658a4b3e827baa290ec",
            "06e95e397f2d454dbe08f4ffb47f3730",
            "62c69bda59524bf2b22265bba05dbbbf",
            "b80e85fc0df14838826c2a464bdc3b59",
            "533510d21cc342b9b671971f559a6086",
            "7d0057bd584744859e739e1a8e8c6f97",
            "d9f029930ded4c31b8d6adc0bcf42c5e",
            "af8c8e80b1b14b5f8474004b82853ead",
            "216feeb1b9204560b01661079bc75358",
            "bcc7a9f003e64909b82181f2b1ae72d0",
            "4ef41b8a338641fe85e0bcb426b5d725",
            "97e4c7c0c1b34e2abd33922df1dfd584",
            "0328953cff5540628eb9957255a3e8e2",
            "b8289f90b1a541419c826438a36cb836",
            "d3f0800e263b4d988cb225e9f00e87d6",
            "ee7030df20d04f40a070578268fc4323",
            "a1ee564261ce45fcb934ac92f1ba98ac",
            "fbcc333061b34c64b1486743dc52a2e4",
            "684d3b3ef03e4379be723b51ab842a54",
            "24fab24d4c524013a762dc08781b020f",
            "c085845e48e74870b14094c8e197ebec",
            "6810cc69749e4abea0a48728c2b61fce",
            "d936fb175d0640ceabcf6637939fc915",
            "f9c7996a10b14f4b83ca265de2e93737",
            "750b5d8559444b12b8d04578433cd4c0",
            "a5cfac77841245cb8d03f405fdfa5607"
          ]
        },
        "outputId": "0f21da3c-eb86-499f-c23a-dce65885b0a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "630d21fff5244e488c6811458be81afb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfdbd84d25c940db85f44d30eb1074f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d225a820614d13ab892c197ea4ae4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "533510d21cc342b9b671971f559a6086"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee7030df20d04f40a070578268fc4323"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from https://www.thelmbook.com/data/news...\n",
            "Download completed.\n",
            "\n",
            "Listing archive contents:\n",
            "Archive member: news\n",
            "Archive member: news/train.txt\n",
            "Archive member: news/test.txt\n",
            "\n",
            "Extracting files...\n",
            "Extraction completed.\n",
            "Counting sentences in news/train.txt...\n",
            "Found 22034911 sentences in news/train.txt.\n",
            "Counting sentences in news/test.txt...\n",
            "Found 449693 sentences in news/test.txt.\n",
            "Training sentences: 22034911\n",
            "Test sentences: 449693\n",
            "Total trainable parameters: 8292619\n",
            "\n",
            "Starting Epoch 1/1, Model in training mode: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   1%|          | 1561/172148 [01:11<2:11:35, 21.61it/s, loss=5.7836]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 6.3757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 33.76it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 5.5840, Perplexity: 266.13\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow , the ##-year-old , who was a lot of the world . '' he said . 's the first time . '' he said . 's the first time , the first time of the time , I 've been a lot of\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York , ## , was a lot of the world . '' he said . 's the first time . '' he said . 's the first time , the first time of the time , I 've been a lot of the world . '' he said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the first-year-old , who was a lot of the world . '' he said . 's the first time . '' he said . 's the first time , the first time of the time , I 've been a lot of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   1%|          | 1567/172148 [01:16<17:28:43,  2.71it/s, loss=5.6652]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was a lot of the world . '' he said . 's the first time . '' he said . 's the first time , 's the first time . '' he said . 's the first time . '' he said . 's the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   2%|▏         | 3123/172148 [02:29<2:17:25, 20.50it/s, loss=5.4569]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 5.4135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.92it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 5.2107, Perplexity: 183.23\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's mother , who was a `` to be able to be a good way . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time . '' he said . 's\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , who was a `` to be able to be a good way . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the ##-year-old was a `` to be able to be a good way . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time . '' he said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   2%|▏         | 3129/172148 [02:30<6:51:10,  6.85it/s, loss=5.2555]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President , ## , said : 'We are not a good way . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time . '' he said . 's the time . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   3%|▎         | 4688/172148 [03:43<2:07:05, 21.96it/s, loss=5.1191]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 5.1565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.94it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 5.0319, Perplexity: 153.22\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's mother , who was a key of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who was a second-time . 's a lot of people . 's a lot of people . '' he said . 's a lot of people . 's a lot of . '' . 's a time . '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was a free kick in the #### . ' I 'm not going to be a bit of the right . '' . 's a time . '' said the . 's the time . '' said the . 's the time . '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   3%|▎         | 4691/172148 [03:44<8:40:39,  5.36it/s, loss=5.0359]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the UK , the ##-year-old was a `` <rare> '' . 's the right . '' he said . 's a lot of people . 's a lot of . '' . 's a time . '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   4%|▎         | 6250/172148 [04:58<2:08:52, 21.46it/s, loss=4.9857]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 5.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.34it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.9154, Perplexity: 136.38\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's mother , who was a ##-year-old . ' I 'm not going to be a lot of people . '' said the . 's . '' said the ##-year-old was a `` <rare> ' , and\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York , the ##-year-old was a `` <rare> ' , and the family 's mother , who was a ##-year-old . ' I 'm not going to be a lot of people . '' said the . 's\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was a very good thing . ' '' he said . 's the time . 's the time . 's the time . 's the time . 's the time . 's the time . 's the time . 's the time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   4%|▎         | 6256/172148 [05:00<6:43:07,  6.86it/s, loss=5.0330]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President Barack Obama said the ##-year-old was a `` <rare> ' , '' said the former <rare> , said : ' I 'm not going to be a lot of people . '' said the . 's . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   5%|▍         | 7813/172148 [06:13<2:08:31, 21.31it/s, loss=4.8549]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.83it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.8310, Perplexity: 125.34\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-degree murder , was a `` <rare> '' . 's the end of the day . '' said . '' he said . 's the time . '' said . 's ) . '' he said . 's the\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , the former presidential candidate , who was a `` <rare> '' . 's the end of the day . '' said . '' he said . 's the time . '' said . 's ) . '' he said . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was a very good way to the . 's ] . '' he said . 's the time . '' said . 's ) . '' he said . 's the time . '' said . 's ) . '' he said . 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   5%|▍         | 7819/172148 [06:14<6:35:35,  6.92it/s, loss=4.7741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President Barack Obama has been a `` to be a good way to get a lot of people who are not going to be a good way . '' . 's . '' said the . 's ] . '' he said . 's the time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   5%|▌         | 9375/172148 [07:27<2:03:30, 21.97it/s, loss=4.8292]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.8369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.12it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.7661, Perplexity: 117.47\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-team-class-year-old was also charged with murdering a few months ago . 's a . ' '' he said . 's the time . 's ] . 's a . '' . 's ] .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was found in the first half of the first time . 's a . ' '' he said . 's the time . 's ] . 's a . '' . 's ] . 's\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the <rare> , the world 's most important thing you can be able to be able to be able to get out of the world . '' said . 's the right . 's ] . 's a . '' . 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   5%|▌         | 9381/172148 [07:29<6:28:31,  6.98it/s, loss=4.7916]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the National Assembly of the National Institute of Defence , which is also known as a result of the first time . 's a . ' '' he said . 's the time . 's ] . 's a . '' . 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   6%|▋         | 10938/172148 [08:42<2:10:36, 20.57it/s, loss=4.7031]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.7787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.54it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.7127, Perplexity: 111.36\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow is the first time in the first time in the ####s , which is the first time in the ####s , which is the first time in the ####s . 's the . '' . 's the . '' . 's the . ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was a `` serious condition '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very good way to get the . '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   6%|▋         | 10943/172148 [08:43<7:10:08,  6.25it/s, loss=4.6813]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President Barack Obama said the ##-year-old was a `` serious condition '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's the . '' . 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   7%|▋         | 12502/172148 [09:57<2:07:10, 20.92it/s, loss=4.8597]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.7274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.83it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.6745, Perplexity: 107.18\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official said the report is not the case . '' . 's ] . ' '' he said . '' said . 's the . '' . 's Office . '' said . 's the . '' . 's Office . '' said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was a `` unprecedented '' of the country 's most-elected . '' . 's ] . ' '' he said . '' said . 's the . '' . 's Office\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , which is the most popularity of the world 's most of the world . '' . 's ] . ' '' he said . '' said . 's the . '' . 's Office . '' said . 's the . '' .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   7%|▋         | 12508/172148 [09:58<6:26:32,  6.88it/s, loss=4.7940]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the city of the city of the city of the city of the city of the city of the city of the city of the city . '' . 's ] . ' '' he said . '' said . 's the . '' . 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   8%|▊         | 14066/172148 [11:11<2:00:49, 21.81it/s, loss=4.7040]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.6893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:46, 33.10it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.6457, Perplexity: 104.14\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's most important thing is the most important thing that is the most important thing . '' ' said the . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with murdering the death of the ##-year-old son , who was born in the ####s . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the <rare> , the U.S. military has been linked to the U.S. military . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   8%|▊         | 14069/172148 [11:13<8:19:29,  5.27it/s, loss=4.7456]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's death was not the first time to be a `` <rare> '' . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   9%|▉         | 15627/172148 [12:26<2:02:56, 21.22it/s, loss=4.5647]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.6595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.50it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.6143, Perplexity: 100.92\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's most popular director , who is the most popular in the world , and the other side of the world . '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was a `` unfortunate decision . '' ' said the company said . '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area of the city 's most popular in the world . '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   9%|▉         | 15633/172148 [12:27<6:15:44,  6.94it/s, loss=4.5966]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government has been accused of the death of the ##-year-old . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  10%|▉         | 17192/172148 [13:41<2:07:52, 20.20it/s, loss=4.6015]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.6339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.50it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5910, Perplexity: 98.59\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's largest city of the country , and the U.S. military spokesman said . 'S ] . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New Yorkers have been a very good way to get the way . '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a big-day location . '' . ' ] is a good job . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  10%|▉         | 17195/172148 [13:43<8:19:29,  5.17it/s, loss=4.5845]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's newborn was a `` unacceptable '' . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  11%|█         | 18755/172148 [14:55<1:58:46, 21.53it/s, loss=4.5637]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.6104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.05it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5709, Perplexity: 96.63\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-choice-born man was arrested in #### , was found in the ####s , and the city of the city of the city was in the middle of the country . '' . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the government was `` not to be a good thing . '' . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK , and the UK is the first time in the UK . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  11%|█         | 18758/172148 [14:57<8:00:22,  5.32it/s, loss=4.5959]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government was `` not to be a good thing . '' . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  12%|█▏        | 20317/172148 [16:10<1:57:11, 21.59it/s, loss=4.5015]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.35it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5529, Perplexity: 94.91\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's deaths were not immediately clear . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who is the most important thing that is the most important thing that is the most important thing . '' 's ] . '' 's ] . ' '' he said . ' '' he said . ' '' he said . ' '' he\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the most common sense of the most important thing . '' 's ] , '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  12%|█▏        | 20323/172148 [16:12<6:05:39,  6.92it/s, loss=4.5711]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's death was a `` significant problem '' . '' 's ] , ' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  13%|█▎        | 21880/172148 [17:25<1:59:05, 21.03it/s, loss=4.6180]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.59it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5302, Perplexity: 92.78\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's most popularity of the world 's largest , and the country 's most importantly , the country 's most important thing . '' ) . '' ) . '' . ' '' he said . '' ) . '' said . '' )\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the couple had been a `` <rare> '' . '' he said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' )\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK . '' the report said . '' ) . '' . ' '' he said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' ) .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  13%|█▎        | 21886/172148 [17:27<6:06:53,  6.83it/s, loss=4.5460]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been in the UK and the UK 's most important thing . '' ) . '' . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  14%|█▎        | 23443/172148 [18:41<1:55:11, 21.52it/s, loss=4.5115]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.69it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5235, Perplexity: 92.16\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has said the government 's decision to be `` a very serious '' . '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been a major role in the public that the government has been `` not to be able to do . '' . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area . 's the club . '' ) . '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  14%|█▎        | 23448/172148 [18:42<6:35:59,  6.26it/s, loss=4.4742]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government 's decision to be `` a very serious '' . '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  15%|█▍        | 25005/172148 [19:56<1:55:07, 21.30it/s, loss=4.5187]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.07it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5127, Perplexity: 91.16\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been criticised by the U.S. District Court in #### . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was arrested on the scene of the incident . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the city 's eastern town of the city of the city of the city of the city . '' ) said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  15%|█▍        | 25011/172148 [19:57<6:00:35,  6.80it/s, loss=4.5142]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was the first time of the attack . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  15%|█▌        | 26570/172148 [21:11<1:55:19, 21.04it/s, loss=4.6281]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:45, 33.27it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4918, Perplexity: 89.29\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major role in the first time in the ####s . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old man who was a ##-year-old girl who was a ##-year-old girl who was a member of the family . ' '' he said . ' '' he said . ' '' he said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the city 's body was found in the area . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  15%|█▌        | 26573/172148 [21:13<7:39:31,  5.28it/s, loss=4.5934]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government would be a `` unacceptable '' . '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  16%|█▋        | 28132/172148 [22:27<1:51:27, 21.53it/s, loss=4.4456]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.42it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4849, Perplexity: 88.67\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been in the country 's most popular destination for the United States , and the United States , the United States , said : ‘ The incident was a very good person . '' said . ' '' he said . ' '' he said . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who is the first time in the United States , said : ' I 'm not going to be a good player . '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the country is the most popular in the world , and the world 's largest . 'S . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  16%|█▋        | 28138/172148 [22:29<5:46:48,  6.92it/s, loss=4.3693]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government has been `` not to be a lot of people to do . '' . ' '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  17%|█▋        | 29694/172148 [23:42<1:47:42, 22.04it/s, loss=4.2938]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.5016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.94it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4723, Perplexity: 87.56\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's death , the report said . 'Donnell said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with the murder of the incident . ' '' said the .##m . 'F . ' '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the water and thefts . 'Fotland is the first time . '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  17%|█▋        | 29700/172148 [23:43<5:36:40,  7.05it/s, loss=4.5202]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been killed in the attack . ' '' said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' '' he said . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  18%|█▊        | 31257/172148 [24:56<1:51:02, 21.15it/s, loss=4.5722]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.84it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4633, Perplexity: 86.77\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been in the UK and the UK 's most recent ##-year-old is the first time in the Premier League . ' '' he said . ' '' he said . ' '' she said . ' '' she said . ' '' she said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old son was arrested in the attack , and the ##-year-old was a ##-year-old girl who was a ##-year-old girl who was a ##-year-old girl who was\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the ##-year-old was a ##-year-old girl who was a ##-year-old girl who was a ##-year-old girl who was a ##-year-old girl who was a ##-year-old\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  18%|█▊        | 31263/172148 [24:57<5:40:30,  6.90it/s, loss=4.4452]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been in the UK and the UK 's most recent ##-year-old has been in the UK . ' '' he said . ' '' he said . ' '' she said . ' '' she said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  19%|█▉        | 32820/172148 [26:10<1:48:03, 21.49it/s, loss=4.3727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.92it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4544, Perplexity: 86.01\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been criticized by the government to the U.S. Embassy in #### . ' '' said the .### . ' '' he said . ' '' said the .### . ' '' he said . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , ## , was found in the area . 's the .### . ' '' he said . ' '' said the .### . ' '' he said . ' '' said the .### . ' '' he said . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the most popular destination for the first time , and the most popular players have been in the world . '' 's first lady . ' '' he said . ' '' said the .### . ' '' he said . ' '' said the .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  19%|█▉        | 32826/172148 [26:12<5:38:56,  6.85it/s, loss=4.4859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's newborns , the U.S. Embassy in #### , and the U.S. Embassy in #### . 's the . ' '' he said . ' '' said the .### . ' '' he said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  20%|█▉        | 34384/172148 [27:25<1:45:38, 21.74it/s, loss=4.5607]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.90it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4410, Perplexity: 84.86\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and murdered the death of the death of the death of the .### . ' '' said the .##.# . ' '' said the .### . ' '' said the statement . ' '' said the .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old was shot in the attacking half . '## . ' '' said the .##m . ' '' said the statement . ' '' said the .### . ' '' said the statement . ' '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the ##-year-old was found in the area of the city of the city of the city . 's . '' ) said . ' '' said the .### . ' '' said the statement . ' '' said the .###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  20%|█▉        | 34390/172148 [27:27<5:23:44,  7.09it/s, loss=4.2880]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. Embassy in the UK , the U.S. Embassy in the UK , the U.S. Embassy in #### , the ##-year-old , who has been charged with murder and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  21%|██        | 35946/172148 [28:40<1:43:59, 21.83it/s, loss=4.4307]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.91it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4416, Perplexity: 84.91\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's office said the law is not the case . ' '' said the .### , '' said the company . ' '' said the company . ' '' said the company . ' '' said the company . ' '' said the company . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old woman was arrested in the attack , which was found dead in the city of the city . ' '' said the .### , '' said the U.S. . ' '' said the .### ,\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the ship 's body was found in the water . '## . '' 's not . ' '' said the .### , '' said the .### , '' said the company . ' '' said the company . ' '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  21%|██        | 35952/172148 [28:42<5:27:52,  6.92it/s, loss=4.4555]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's ##-year-old was a member of the U.S. Embassy in the city of the city . ' '' said the .### , '' said the U.S. . ' '' said the company . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  22%|██▏       | 37509/172148 [29:55<1:47:29, 20.88it/s, loss=4.3672]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.69it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4315, Perplexity: 84.06\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first lady , who was a ##-year-old daughter , said : ' I 'm not going to be a good friend . ' '' said the .### . ' '' said the .### . ' '' said the .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who is the first of the largest city of the city , and the UK is the largest of the largest . 'S . ' '' said the report . ' I 'm not going to be a good friend . ' '' said the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the disease is the only way to the . ' '' said the company . ' '' said the .### . ' '' said the . ' I 'm not going to be a good friend . ' '' said the .### . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  22%|██▏       | 37515/172148 [29:57<5:29:20,  6.81it/s, loss=4.5374]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's name was the first time that the government has been a `` significant '' of the `` <rare> '' of the <rare> . ' '' said the company said . ' I 'm not going to be a good job . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  23%|██▎       | 39074/172148 [31:11<1:42:32, 21.63it/s, loss=4.4933]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.74it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.5218, Perplexity: 92.00\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of the death\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York 's most recent interview with the U.S. military in the UK and the U.S. military in the United States , where the death of the death of the death of the death of the .### , and the victim of a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area , which was found in the area of the area . ' '' said the .### , '' he said . ' I 'm not going to be a very difficult time to do it . '' 's a very good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  23%|██▎       | 39077/172148 [31:13<6:55:37,  5.34it/s, loss=4.5660]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been released in the case of the case , but the police were not immediately returned to the hospital . ' ' I 'm not going to be a very difficult time to do it . '' 's a very good friend . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  24%|██▎       | 40635/172148 [32:27<1:42:47, 21.32it/s, loss=4.3749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.54it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4200, Perplexity: 83.10\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's office said the government would be `` a very difficult time '' . ' '' said the . ' I 'm not going to do . '' 's said . ' I 'm not going to do . ' '' said the .###\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old was arrested on suspicion of murdering a woman who was arrested on suspicion of murdering a woman who was arrested on suspicion of murdering a woman who was arrested on suspicion of murdering a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane in the UK are the largest city of the city . '' ' said the . 'S . ' '' said . ' I 'm not going to do . ' '' said the .### . ' '' said the statement . ' I 'm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  24%|██▎       | 40641/172148 [32:29<5:17:16,  6.91it/s, loss=4.2400]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was the first time of the attack . ' '' said the .### . ' '' said the statement . ' '' said the statement . ' I 'm not going to do . ' '' said the .### . ' '' said the statement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  25%|██▍       | 42198/172148 [33:42<1:44:43, 20.68it/s, loss=4.3259]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.85it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4173, Perplexity: 82.87\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a member of the House of Commons in #### . ' I 'm not going to do . '' ' said the .##am . ' '' said . ' I 'm not going to do . '' ' said the .##am .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York Times : ' I 'm not going to be a good job . '' 's a .### . ' '' said . ' I 'm not going to do . '' ' said the .##am . ' '' said . ' I '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the ##-year-old , who was arrested in #### , was arrested in #### . ' I 'm not going to do . ' '' said the .##am . ' '' said . ' I 'm not going to do . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  25%|██▍       | 42204/172148 [33:44<5:16:27,  6.84it/s, loss=4.5252]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's most recent cases are not the first time in the UK . ' I 'm not going to do . '' ' said the .##am . ' '' said . ' I 'm not going to do . '' ' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  25%|██▌       | 43761/172148 [34:58<1:41:08, 21.16it/s, loss=4.5171]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.43it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4110, Perplexity: 82.35\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a very good idea . '' 's said . ' I 'm not going to be a very good job . '' 's said . ' I 'm not going to be a very good job . '' 's said . ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who is a professor of the U.S. government to be able to provide a new deal with the government 's government to be able to make a new deal with the government . ' '' said the company . ' I 'm\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the disease is a very rare condition , and it 's not a problem . '' 's said . ' I 'm not going to be a very good job . '' 's said . ' I 'm not going to be a very\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  25%|██▌       | 43767/172148 [35:00<5:16:14,  6.77it/s, loss=4.3998]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's family have been charged with a child in the case . ' I 'm not going to be a very good job . '' 's said . ' I 'm not going to be a very good job . '' 's said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  26%|██▋       | 45325/172148 [36:13<1:37:56, 21.58it/s, loss=4.3642]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:46, 32.88it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3983, Perplexity: 81.31\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first minister , who has been in the United States , which is the first time in the United States . 's . '' 's a .### . 'D# . ' '' said the . ' I 'm not going to\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-round tie was a second goal in the second half . ' I 'm not going to be a good job . '' 's a good job . ' '' said the .### . ' I 'm not going to\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very small number of people who have been killed . 's the first time . '' 's a .### . 'Dowell said . ' I 'm not going to be a good thing . '' 's a .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  26%|██▋       | 45331/172148 [36:15<5:07:46,  6.87it/s, loss=4.5039]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's new lawyers have been in the case , which is the first time in the United States . 's the .### . 'S.# . ) . '' 's a . ' I think it 's a good thing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  27%|██▋       | 46887/172148 [37:28<1:37:41, 21.37it/s, loss=4.5328]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.50it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.4014, Perplexity: 81.56\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been a member of the state 's government , which is the most important thing to do with the . '' . ' '' said . ' I 'm not going to do . '' 's said . ' I 'm not\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been a member of the House of Commons in #### . ' '' said the .### . ' '' said the statement . ' '' said the .##am . ' '' said . ' I 'm not going to do\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a huge amount of time . '' 's a . ' '' said . ' I 'm not going to do . '' 's said . ' I 'm not going to do . '' 's said . ' I 'm not going\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  27%|██▋       | 46893/172148 [37:29<5:05:41,  6.83it/s, loss=4.4631]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government has been a `` unacceptable '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  28%|██▊       | 48450/172148 [38:42<1:34:24, 21.84it/s, loss=4.4368]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 3/3514 [00:00<02:00, 29.16it/s]\u001b[A\n",
            "Evaluating:   0%|          | 7/3514 [00:00<01:54, 30.75it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3907, Perplexity: 80.69\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow , who has been charged with the death of the U.S. military . ' '' said the .##m . ' '' said the .##am . ' '' said the .##am . ' '' said the .##am . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , who was a member of the National Institute of Technology , and the U.S. military . '' 's said . ' I 'm not going to be a very good job . ' '' said the .##am . ' '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the plane was found in the area . 's the .### . 'S. . ' '' said the .##m . ' '' said the .##m . ' '' said the .##am . ' '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  28%|██▊       | 48456/172148 [38:44<5:03:12,  6.80it/s, loss=4.3742]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government would be `` a very serious '' of the case . ' '' said the .##am . ' '' said the .##am . ' '' said the .##am . ' '' said the .##am . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  29%|██▉       | 50015/172148 [39:58<1:35:45, 21.26it/s, loss=4.3985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.05it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3863, Perplexity: 80.35\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been accused of the murder of the ##-year-old , who was arrested on suspicion of murder and was arrested on suspicion of murder . ' ' I 'm not going to do . ' '' said the .### . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been accused of the murder of the ##-year-old , who was arrested on suspicion of murder and was arrested on suspicion of murder . ' ' I 'm not going to do . ' '' said the .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is also known to be a popularity of the world 's most popular destination for the world . '' 's said . '' 's a great-grandmother . ' ) . '' 's a great man . ' '' said the .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  29%|██▉       | 50020/172148 [39:59<5:26:24,  6.24it/s, loss=4.3058]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been accused of being a member of the country 's most recent history . '' . 'Fort Office said . '' 's a very good thing . ' '' said . ' I 'm not going to do . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  30%|██▉       | 51576/172148 [41:14<1:33:37, 21.46it/s, loss=4.4827]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.51it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3941, Perplexity: 80.98\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a member of the country 's most recent years . '' 's said . ' '' said the . ' I 'm not going to do . '' 's said . ' I 'm not going to be a . ' I '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , the chief executive of the U.S. Army , said : 'The police are not going to be a very good guy . '' 's said . ' I 'm not going to be a . ' I 'm not\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the attack is the largest of the world , and the country is the most common . '' . ' '' said . ' I 'm not going to be a . '' . ' '' said . ' I 'm not going to be a .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  30%|██▉       | 51582/172148 [41:16<4:51:14,  6.90it/s, loss=4.5257]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with the murder of the . 'Fort Office said . ' I 'm not going to be a . '' . ' '' said . ' I 'm not going to be a . ' I 'm not going\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  31%|███       | 53139/172148 [42:29<1:35:26, 20.78it/s, loss=4.4079]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 33.81it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3859, Perplexity: 80.31\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a member of the country 's government . ' '' said the company . 'Fox . ' '' said the .### . 'Fort . '' 's said . ' I 'm not going to do . ' '' said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City manager , who has been charged with murder and attempted murder . ' ' I 'm not going to do . ' '' said the .### . 'Fort . '' 's said . ' I 'm not going to do . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is to be a great place in the world . '' 's said . ' '' said the .### . 'Fort . '' 's said . ' I 'm not going to do . ' '' said the .### . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  31%|███       | 53145/172148 [42:30<4:49:53,  6.84it/s, loss=4.3846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with murder . ' '' said the .### . 'Fort . '' 's said . ' I 'm not going to do . ' '' said the .### . 'Fort . '' 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  32%|███▏      | 54704/172148 [43:44<1:32:59, 21.05it/s, loss=4.4164]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.83it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3771, Perplexity: 79.61\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been accused of the death penalty . ' '' said the .### . ' '' said the company . 's . ' '' said the company . 's . ' '' said the company . 's . ' '' said the company . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with murdering a child , and the family said . ' I 'm not going to be able to get the best friend . '' 's a .### . ' '' said the company . 's .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area , which was found in the area , which was found in the area , which was found in the area , which was found in the area . 's the .### . ' '' said the company . 's .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  32%|███▏      | 54707/172148 [43:45<6:07:57,  5.32it/s, loss=4.5318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's decision to be a `` tough '' of the president 's decision to be a good job . '' 's not . ' '' said the .### . ' '' said the .### . ' '' said the company . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  33%|███▎      | 56265/172148 [44:59<1:30:36, 21.32it/s, loss=4.3546]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.89it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3719, Perplexity: 79.19\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and a ##-year-old man was shot dead . ' I was . ' I 'm not going to be a very good job . ' '' said the .### . 'S . ' '' said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old was arrested in connection with the death of the death of the .### . 'S. . ' '' said the company said . ' I 'm not going to be a very good job . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very difficult time for the future . '' 's official said . ' I 'm not going to be a very good job . ' '' said the .### . 'S . ' '' said . ' I 'm not going to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  33%|███▎      | 56271/172148 [45:00<4:41:57,  6.85it/s, loss=4.4099]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with murder and a ##-year-old man was shot dead . ' I was . ' I 'm not going to be a very good job . ' '' said the .### . 'S . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  34%|███▎      | 57829/172148 [46:14<1:30:58, 20.94it/s, loss=4.3800]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.38it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3674, Perplexity: 78.84\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major role in the attacking half . ' '' said the .### . '' #### #### . ) . '' said . '' 's a .### . '' said . '' 'Suchy said . '' 's a\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been in the UK , and the United States has been in the country . ' '' said the .### . '' #### #### . ) . '' said . '' 's a .### . '' said . '' '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a major problem , but the government has been in the country . '' 's a . '' said . '' said . '' 's a .### . '' said . '' 'Suchy said . '' 's a . '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  34%|███▎      | 57835/172148 [46:15<4:37:02,  6.88it/s, loss=4.3439]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's lawyers have been in the country 's largest city in the city of the city of the city . 'Fort . '' 's most . '' said the .### . '' #### #### . ) . '' said . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  35%|███▍      | 59392/172148 [47:28<1:26:57, 21.61it/s, loss=4.4734]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.4007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.36it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3672, Perplexity: 78.82\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's ##-year-old , who was a ##-year-old son of a ##-year-old girl , who was a ##-year-old son of a woman who was a ##-year-old son of a woman\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with murder and a police officer who was a `` tough '' of the `` unacceptable '' of the `` unacceptable '' of the `` unacceptable '' of the `` American '' . '' . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is expected to be a third-party agreement with the United States . '' 's said . 'Fort . '' said the company . 's . '' said the company . 's . '' said the company . 's . '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  35%|███▍      | 59398/172148 [47:30<4:25:20,  7.08it/s, loss=4.3757]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with a ##-year-old , who was a `` tougher '' to be a `` tough '' of the `` unacceptable '' of the `` American '' . '' . 'Fort . '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  35%|███▌      | 60955/172148 [48:42<1:27:15, 21.24it/s, loss=4.3208]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.24it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3711, Perplexity: 79.13\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow is not the first time in the UK . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .### . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old was arrested on suspicion of murder and was arrested . ' I was a very good friend . '' 's said . '' said the .##pm . ' '' said . '' said . '' said the .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the world . '' 's said . '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  35%|███▌      | 60961/172148 [48:43<4:23:54,  7.02it/s, loss=4.4582]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's lawyers are not the first time in the UK . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  36%|███▋      | 62518/172148 [49:56<1:23:07, 21.98it/s, loss=4.5049]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.53it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3683, Perplexity: 78.91\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` significant step '' for the first time in the case . ' '' said the .### . '' said . ' I 'm not going to do . '' 's home . ' '' said the .### . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-half-year-old was arrested in the attack , and the ##-year-old was arrested in the attack . ' I 'm not going to be a good job . '' 's home . ' '' said the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the largest , the largest city of the world . '' 's official said . '' said the .### . '' . 'S. . '' . 'S. . ' '' said . ' I 'm not going to do . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  36%|███▋      | 62524/172148 [49:58<4:21:02,  7.00it/s, loss=4.2597]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's lawyers said the government has been `` not the most important thing '' . ' '' said the .### . '' said . ' I 'm not going to do . '' 's home . ' '' said the .###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  37%|███▋      | 64081/172148 [51:10<1:24:17, 21.37it/s, loss=4.4122]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.85it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3658, Perplexity: 78.72\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` great example of the issue of the government , '' he said . 'We are not going to be a very good job . '' 's not . ' '' said the .### . 'S.D . 'S.\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-half-year-old was a ##-year-old man who was a ##-year-old man , who was a ##-year-old man , who was a ##-year-old man , who was\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a major problem in the UK , and the UK 's economy . '' '' said . 'Fort . '' said . 'Fort . '' said . 'Fort . '' said . 'Fort . '' said . 'Fort\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  37%|███▋      | 64087/172148 [51:11<4:23:11,  6.84it/s, loss=4.4445]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been in the case , and the government has been in the case . ' '' said the company . 'Fort . '' said . 'Fort . '' said . 'Fort . '' said . 'Fort . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  38%|███▊      | 65643/172148 [52:24<1:24:29, 21.01it/s, loss=4.3692]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.55it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3605, Perplexity: 78.30\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been in the country 's largest city in the UK . ' '' said the .### . '' ) said . '' said the .### . '' . 'S ) . '' said the .### . 'S. . ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been in the country , but the government has not been able to use the money to be able to use the money . ' '' said the .### . 'S. . '' . 'S ) . '' said the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is not the first time in the country . '' 's official said . '' said the .### . '' . 'S ) . '' said the .### . 'S. . '' . 'S ) . '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  38%|███▊      | 65649/172148 [52:25<4:11:59,  7.04it/s, loss=4.4611]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was also charged with murder and a police officer . 's said . '' said the .### . 'S. . '' . 'S ) . '' said the .### . 'S. . '' . 'S ) . '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  39%|███▉      | 67207/172148 [53:38<1:23:29, 20.95it/s, loss=4.3660]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.29it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3598, Perplexity: 78.24\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first minister , who has been accused of being charged with murder . ' ' I 'm not going to be able to get to the floor . ' '' said the .##pm . ' '' said . ' I 'm not going to\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been accused of being charged with murder . ' ' I 'm not going to be able to get to the floor . ' '' said the .##pm . ' '' said . ' I 'm not going to be able\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the area , and the ##-year-old was killed . ' '' said the .##pm . ' '' said the .##pm . ' '' said . ' I 'm not going to be able to get to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  39%|███▉      | 67213/172148 [53:39<4:10:32,  6.98it/s, loss=4.4699]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the country 's government has been accused of being a `` very serious issue '' . ' '' said the .##pm . ' '' said . ' I 'm not going to be able to get to the floor . ' '' said the .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  40%|███▉      | 68770/172148 [54:52<1:20:31, 21.40it/s, loss=4.5108]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 35.03it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3553, Perplexity: 77.89\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has said the government has not yet been released . ' '' said the .##pm . ' '' said . ' I 'm not going to do . ' '' said the .##pm . ' '' said . ' I 'm\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-half years ago , he said : ' I 'm not going to be a little bit . ' '' said the .##-caliber pistol . ' I 'm not going to be a little bit . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is to be a huge amount of time . ' '' said the .##-caliber gunfire . ' '' said the .##-caliber gunfire . ' '' said the .##-caliber gunfire . ' '' said the .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  40%|███▉      | 68776/172148 [54:53<4:11:43,  6.84it/s, loss=4.4126]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was a ##-year-old woman who was a ##-year-old woman , who was arrested in #### , was arrested in connection with the death of the ##-year-old woman who was arrested in the ##-year-old ,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  41%|████      | 70332/172148 [56:06<1:18:25, 21.64it/s, loss=4.3449]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.14it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3459, Perplexity: 77.16\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` significant '' of the country 's most recent incidents , including the <rare> , and the most important thing . '' said . '' said . ' I said . '' said . ' I said . ' I think it '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been accused of being a `` significant '' of the `` significant '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare>\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the area , and the ##-year-old was found in the area . 's said . ' I said . '' said . ' I said . ' I think it 's a very good thing . '' 's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  41%|████      | 70338/172148 [56:07<4:05:49,  6.90it/s, loss=4.3671]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was a `` significant '' of the `` significant '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  42%|████▏     | 71897/172148 [57:20<1:17:41, 21.51it/s, loss=4.3304]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.27it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3457, Perplexity: 77.14\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major role in the country 's largest city . '' 's official . '' said . '' said the .### .### .### .### . ) . '' 's a .### .### .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# draw with the goalkeeper , but the club is a good job . ' '' said the .### .### .### .### . ) . '' 's a .### .### .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time the world 's largest city of the country . '' 's a .### .### .### .### . ) . '' 's a .### .### .### .### .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  42%|████▏     | 71900/172148 [57:21<5:16:09,  5.28it/s, loss=4.3734]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is a `` good-class '' and `` unacceptable '' of the `` <rare> '' -- the .### . '' said . '' said the .### .### .### .### . ) .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  43%|████▎     | 73460/172148 [58:34<1:15:51, 21.68it/s, loss=4.3886]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.62it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3463, Perplexity: 77.19\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been accused of the attackers . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , the ##-year-old , was a former president of the United States . ' '' said the . 'Following of the . ' '' said the . 'Following of the . ' '' said the . 'Follow\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is expected to be a major role in the first time . '' 's a . 'Furbart , '' he said . ' '' said the . 'Following of the incident . ' '' said the . 'Following of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  43%|████▎     | 73463/172148 [58:35<5:05:42,  5.38it/s, loss=4.2916]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been accused of the attackers . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said the incident . ' '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  44%|████▎     | 75023/172148 [59:47<1:13:04, 22.15it/s, loss=4.3844]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.26it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3500, Perplexity: 77.48\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been criticised for the first time in the country 's government . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been criticised for the first time in the case . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a major threat to the country . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  44%|████▎     | 75026/172148 [59:49<4:58:23,  5.42it/s, loss=4.5674]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been criticised for the first time in the case . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' '' said the .### . '' ) said . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  44%|████▍     | 76585/172148 [1:01:01<1:14:03, 21.51it/s, loss=4.2767]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.39it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3427, Perplexity: 76.92\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major factor in the United States , and the United States , the United States , and the United States , and the United States , the United States , said the government has been in the UK . ' '' said . ' I 'm\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-ever-minute video shows the video of the video . ' I 'm not going to be a very good friend . ' '' said . ' I 'm not going to be a very good friend . ' '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the world , and the United States is the largest of the world 's largest cities . '' . ) . '' 's a .### .### .### .### .### . ) . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  44%|████▍     | 76591/172148 [1:01:03<3:47:09,  7.01it/s, loss=4.3731]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government is not the first time in the United States , and the United States , the United States , and the United States , and the United States , the United States , said the government has been in the UK . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  45%|████▌     | 78147/172148 [1:02:15<1:13:38, 21.27it/s, loss=4.3380]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.64it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3410, Perplexity: 76.79\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's office said the government 's decision to make a new deal of the new rules . ' '' said the company 's website . 'F . ) . ' I 'm not going to do . ' '' said the .### .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was arrested in #### , but he was arrested in #### . ' I was a very good man . ' '' said the .### . 'Fort . '' said . ' I think it 's\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK , which is the largest of the largest population of ## % of the population . '' 's official . 'F.C. , . 'Fort . '' said . 'Fort . '' said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  45%|████▌     | 78153/172148 [1:02:17<3:46:59,  6.90it/s, loss=4.4432]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been a `` very difficult time '' . ' '' said the .### . 'Fort . '' said . ) . ' I 'm not going to do . ' '' said the .### . 'Fort .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  46%|████▋     | 79712/172148 [1:03:30<1:09:59, 22.01it/s, loss=4.3885]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.89it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3445, Perplexity: 77.05\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been criticised for the first time in the ####s . ' '' he said . ' I 'm not going to be a little bit . ' '' said the .##pm . '' ) said . ' I 'm not\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been a major role in the United States . ' '' said the .### . ' '' said the .### . 'Fort . '' said the .### . 'Fort . '' said the .##\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is to be seen in the city of the city . ' '' said the .### . ' '' said the .### . 'Fort . '' said the .### . 'Fort . '' said the .### . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  46%|████▋     | 79715/172148 [1:03:31<4:44:38,  5.41it/s, loss=4.3442]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been criticised for the `` austerity '' of the `` <rare> '' . ' '' said the .### . ' '' said the .### . 'Fort . '' said the .### . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  47%|████▋     | 81275/172148 [1:04:45<1:09:42, 21.73it/s, loss=4.3220]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.75it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3365, Perplexity: 76.44\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been criticised for the first time in the ####s . '' said the .### . '' said . '' said the .##pm . '' said . '' said the .##pm . '' said . '' said the .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first lady , who was a ##-year-old girl who was a ##-year-old girl , who was arrested in #### , was arrested in connection with the death of the death of the .##am . '' said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the United States . 's the same time . '' said the .### . '' said . '' said the .##pm . '' said . '' said the .##pm . '' said . '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  47%|████▋     | 81278/172148 [1:04:46<4:38:19,  5.44it/s, loss=4.3253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government would not be allowed to pay for the money . ' '' said the .### . '' said . '' said the .##pm . '' said . '' said the .##pm . '' said . '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  48%|████▊     | 82838/172148 [1:05:59<1:08:59, 21.57it/s, loss=4.3338]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.57it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3440, Perplexity: 77.02\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` significant step in the country '' . ' '' said the .##-caliber gun . ' '' said the .##-caliber gun . ' '' said the .##-## . 'Fort . '' said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , ## , was arrested and charged with murder and a police officer . ' I was a very good person . ' '' said . ' I was a very good person . ' '' said . ' I 'm not sure . ' '' said the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is to be a major problem . '' 's a . 'Fort . '' said . 'Following . '' said the .##-caliber gun . ' '' said the .##-caliber gun . ' '' said the .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  48%|████▊     | 82841/172148 [1:06:00<4:37:11,  5.37it/s, loss=4.3178]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been a `` significant step in the country '' . ' '' said the .##-caliber gun . ' '' said the .##-caliber gun . ' '' said the .##-## . 'Fort . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  49%|████▉     | 84401/172148 [1:07:13<1:07:57, 21.52it/s, loss=4.4841]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.65it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3337, Perplexity: 76.22\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and a criminal investigation . ' '' said the .### .### ) . '' ) said . ' I 'm not going to do . ' '' said the .### .### ) . '' ) said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was arrested in the hospital , and the police were found in the area . ' '' said the .### . ' '' said the .### . 'F ) , '' he said . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the country , and the country 's most recent cases were reported . ' '' said the .### . '' ) said . ' I 'm not going to do . ' '' said the .### .###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  49%|████▉     | 84404/172148 [1:07:15<4:38:12,  5.26it/s, loss=4.3879]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been charged with murder and a criminal investigation . ' '' said the .### .### ) . '' ) said . ' I 'm not going to do . ' '' said the .### .### ) . '' ) said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  50%|████▉     | 85964/172148 [1:08:27<1:04:17, 22.34it/s, loss=4.3207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 36.00it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3315, Perplexity: 76.06\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been accused of the alleged attack on the death of the ##-year-old . 'Forta . '' said . 'Furbart , which is the first time , the first time , the president 's office said the\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old , who was a former presidential candidate , who has been accused of being a `` very serious '' of the `` terrorist '' of the Islamic State . '' . 'Forta said . ' I\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s , which is the first time of the ####s , which is the first time of the ####s , which is the first time in the ####s , which is the first time in the ####s , which\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  50%|████▉     | 85967/172148 [1:08:29<4:27:08,  5.38it/s, loss=4.3711]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been accused of the attack , which is the first of the most recent years , the president said . ' I 'm not going to be able to get the money . ' '' said the . 'Science\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  51%|█████     | 87527/172148 [1:09:40<1:04:18, 21.93it/s, loss=4.3941]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.37it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3288, Perplexity: 75.85\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been a `` very important thing '' . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said the .##\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the World Cup . 's win . '' 's the World Cup . ' '' said the .### . ' '' said the .### . ' '' said the .### . ' '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK , and the ##-year-old has been in the UK . '##s . '' 's the World Cup . ' '' said the .### . ' '' said the .### . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  51%|█████     | 87530/172148 [1:09:42<4:19:43,  5.43it/s, loss=4.4521]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. Embassy in the U.S. Embassy in the U.S. Embassy in the U.S. Embassy in the U.S. Embassy in the U.S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  52%|█████▏    | 89090/172148 [1:10:54<1:05:06, 21.26it/s, loss=4.3759]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.13it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3299, Perplexity: 75.94\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-half-year-old was a ##-year-old , who has been a ##-year-old , who has been a ##-year-old , who has been a ##-year-old , who has been\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old , who has been a ##-year-old , who has been a ##-year-old , who has been a ##-year-old , who has been a ##-year-old , who\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the U.S. military , and the U.S. military has been killed in the attack . '## . '' said . 'Bothers and the .### . '' ) said . ' I 'm not going to be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  52%|█████▏    | 89093/172148 [1:10:55<4:17:57,  5.37it/s, loss=4.3973]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been criticised for the first time in the UK . '## . '' said . 'Bothers and the .### . '' ) said . ' I 'm not going to be a good job . ' '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  53%|█████▎    | 90653/172148 [1:12:09<1:04:23, 21.09it/s, loss=4.3013]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:42, 34.16it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3224, Perplexity: 75.37\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-largest city of the country is the first time in the country . '' 's a .##-caliber and a .##-caliber and a bit of a good day . '' ' I said . '' ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-#-# win over the Champions League . '' ' I 'm not going to be a good player . '' 's a .##-caliber and a bit of a good day . '' ' I said . ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time the attack was a `` very serious '' and the case . ' '' said the incident . ' '' said the incident . ' I was a very good friend . '' 's a .##-caliber handgun . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  53%|█████▎    | 90656/172148 [1:12:10<4:15:11,  5.32it/s, loss=4.4102]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the country 's largest group of the country 's largest city of the country is the first time . '' 's a .##-caliber and a .##-caliber and a bit of a good day . '' ' I said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  54%|█████▎    | 92215/172148 [1:13:24<1:03:07, 21.11it/s, loss=4.3260]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.74it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3267, Perplexity: 75.70\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been a `` very difficult time '' . ' '' said the .### . '' ) said . '' 's a .##-caliber and right footed shot from the right side of the box is saved in the bottom\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-#-# win over the World Cup in #### . ' '' said the .### . '' ) . ' '' said the .### . '' ) . 'Fort . '' 's office said . '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the city of the city . '' 's office said . '' said . 'Fort . '' said . 'Fort . '' said . 'Fort . '' said . 'Fort . '' said . 'F\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  54%|█████▎    | 92221/172148 [1:13:25<3:10:57,  6.98it/s, loss=4.4005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is a `` very difficult time '' . ' '' said the .### . '' ) said . '' 's a .##-caliber and right footed shot from the right side of the box is saved in the bottom right\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  54%|█████▍    | 93778/172148 [1:14:38<1:00:27, 21.61it/s, loss=4.3673]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.68it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3332, Perplexity: 76.19\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been in the midst of a `` significant impact on the ground '' . ' '' said the .### . '' said . '' said . '' said . '' said . '' said . '' said . '' said . '' said .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been in the UK , and the US government has been given a number of people to pay for the UK . ' '' said the .### . '' said . '' said . '' said . '' said . '' said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the ####s . '' #### #### #### . '' #### #### #### . '' ) said . '' 's a source of the <rare> . '' said . '' said . '' said . '' said . '' said . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  54%|█████▍    | 93784/172148 [1:14:39<3:07:09,  6.98it/s, loss=4.3566]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is a `` significant '' of the `` <rare> '' -- a `` <rare> '' -- a `` <rare> '' -- a `` <rare> '' -- a `` <rare> '' -- a `` <rare> ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  55%|█████▌    | 95342/172148 [1:15:52<1:03:14, 20.24it/s, loss=4.2964]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.67it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3276, Perplexity: 75.76\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been in the UK to be a `` significant '' of the country 's most recent financial crisis . '' 's a .### , '' he said . ' I 'm sure it 's a good thing . '' '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , ## , #### , and the ##-year-old woman was found dead in the ##th minute , and the ##-year-old was found dead in the attack . ' I was in the middle of the day . ' '' said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the ##-year-old , who was killed in the attack , and the police said . ' I 'm not sure . ' '' said the .### . '' said . 'Farms said . ' '' said the .##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  55%|█████▌    | 95345/172148 [1:15:53<3:59:11,  5.35it/s, loss=4.2796]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government has been in the country 's most recent financial crisis . '' 's a .### , '' he said . ' I 'm sure it 's a good thing . '' 's a .###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  56%|█████▋    | 96903/172148 [1:17:06<57:05, 21.96it/s, loss=4.3469]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.34it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3213, Perplexity: 75.29\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and was not a member of the family . ' '' said the .### . '' said . 'Furbart , '' said the .### . '' said . ) . '' 's a .###\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was killed in the attack . '##s . '' 's a .### . '' said . ) . '' 's a .### . '' said . 'Furbart , ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK . '##s . '' said the .### . '' said . ) . '' 's a .### . '' said . 'Furbart , '' said the .### . '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  56%|█████▋    | 96909/172148 [1:17:07<2:55:49,  7.13it/s, loss=4.2564]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the UK 's most recent report , which is the first time in the UK , the UK government said . '### . '' said . 'Furbart , '' said the .### . '' said . ) . '' '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  57%|█████▋    | 98466/172148 [1:18:19<56:02, 21.91it/s, loss=4.2648]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.41it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3235, Perplexity: 75.45\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said : 'The ICC 's decision is not the first time . ' '' said the .### . '' said . 'Fort . '' 's official website . 'Five . 'Fort . '' said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City officials said the ##-year-old was arrested in connection with the death of the ##-year-old . ' I was a very good friend . ' '' said the .### . ' I 'm not going to do . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the country . ' '' said the .### . '' said . 'Fort . '' said . 'Five . ' '' said the .### . ' '' said the .### . ' '' said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  57%|█████▋    | 98472/172148 [1:18:21<2:53:36,  7.07it/s, loss=4.3644]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government 's `` unacceptable '' of the `` unacceptable '' of the case is not the first time . ' '' said the .### . '' said . 'Fort . '' 's official website .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  58%|█████▊    | 100029/172148 [1:19:34<54:08, 22.20it/s, loss=4.2603]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:47, 32.52it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3186, Perplexity: 75.08\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and murder , and the ##-year-old man was arrested in connection with the incident . ' I was a man . ' '' said the .### . '' said . ' I 'm not sure . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who have been charged with murder and murder , and the ##-year-old man was arrested in connection with the incident . ' I was a man . ' '' said the .### . '' said . ' I 'm not\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the UK , and the ##-year-old is the most expensive . '' #### .### ) # .### . '' ) said . '' ' I 'm not sure . ' '' he said . ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  58%|█████▊    | 100035/172148 [1:19:35<2:56:06,  6.82it/s, loss=4.3628]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been criticised for the first time in the UK . ' '' said the company 's `` <rare> '' -- a . '' said . ' I 'm not sure . ' '' said the .### . '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  59%|█████▉    | 101592/172148 [1:20:48<54:14, 21.68it/s, loss=4.3285]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 36.15it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3133, Perplexity: 74.69\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` significant step in the way '' . '' 's the news . ' ) . '' ' I 'm not going to be a good person . '' 's funny . ' ) . '' ' I 'm not going to\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been a `` good idea '' . ' '' he said . ' I 'm not going to be a bit of a bit of a bit of a bit of a bit of a bit of a bit of a bit of a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the city of the city of the city . 'Fifseyside . '' ) said . '' 's a source . ' ) . '' 's a very high school . '' ) . ' I 'm not\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  59%|█████▉    | 101598/172148 [1:20:49<2:45:34,  7.10it/s, loss=4.4346]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` significant step in the way '' . '' 's the news . ' ) . '' ' I 'm not going to be a good person . '' 's funny . ' ) . '' ' I 'm not going to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  60%|█████▉    | 103155/172148 [1:22:02<53:36, 21.45it/s, loss=4.3693]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 3/3514 [00:00<02:00, 29.17it/s]\u001b[A\n",
            "Evaluating:   0%|          | 7/3514 [00:00<01:48, 32.31it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3144, Perplexity: 74.77\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very important step '' . ' '' said the .### . '' ) . '' ) . ' I 'm not going to be able to get the best wishes . '' ' I 'm not going to be able to get\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been charged with the murder of the murder of the murder of the . ' I 'm not going to be able to get the chance to get a lot of people . '' 's naked . ' I 'm not going to\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s . '' #### . ) # .### ) # . '' ) . '' ) . '' ) . ' I 'm not going to be able to get the chance to get a lot of money . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  60%|█████▉    | 103160/172148 [1:22:03<3:04:07,  6.24it/s, loss=4.3363]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military , the U.S. military , the U.S. military , the U.S. military , and the U.S. military . '' ) said . '' 's a . '' ) said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  61%|██████    | 104719/172148 [1:23:16<52:09, 21.55it/s, loss=4.2933]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.15it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3180, Perplexity: 75.04\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been in the same way of the .### . '' ) said . '' 's a big part of the game . '' 's nudge . ' '' he said . ' I 'm not going to be a good friend .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York 's ##-year-old , who was a ##-year-old man , who was a ##-year-old man , who was arrested in the hospital , and the police were killed . ' I 'm not going to be a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the city of the city . 'Farms said . 's a lot of people . '' 's a very high school . '' ) . ' I 'm not going to be a big . '' ) . ' I '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  61%|██████    | 104725/172148 [1:23:18<2:42:44,  6.90it/s, loss=4.2774]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been criticised by the government 's office . ' '' said the company 's chief executive of the United States . 's the same time . '' 's not . ' '' said the .##-caliber pig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  62%|██████▏   | 106283/172148 [1:24:31<50:44, 21.63it/s, loss=4.2497]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.82it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3153, Perplexity: 74.84\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very serious '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's first-half-year-old was shot in the attacking half . ' I was a bit of a good friend . ' '' said the .### . ' '' said . ' I 'm not sure what I 'm\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the first time , the first time in the world 's top-flight match was a first-half-year-old 's first goal of the goal . ' I was going to be a bit of a good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  62%|██████▏   | 106286/172148 [1:24:33<3:22:07,  5.43it/s, loss=4.2938]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been accused of being a `` very serious '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of the `` terrorist '' of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  63%|██████▎   | 107846/172148 [1:25:46<51:37, 20.76it/s, loss=4.3404]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:45, 33.19it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3130, Perplexity: 74.66\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with conspiracy to commit suicide . ' . ' '' she said . ' I 'm not going to be a very good thing . '' ' I said . '' ' I 'm not sure . ' '' he said .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with conspiracy to commit suicide . ' . ' '' she said . ' I 'm not going to be a very good thing . '' ' I said . '' ' I 'm not sure . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time of the crash , the police said . ' I 'm not going to be a very good thing . '' ' I said . '' ' I 'm not sure . ' '' he said . ' I 'm not going to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  63%|██████▎   | 107849/172148 [1:25:48<3:20:11,  5.35it/s, loss=4.3235]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been charged with conspiracy to commit suicide . ' . ' '' said the company 's name . ' '' said the company 's name . ' '' said the company 's name . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  64%|██████▎   | 109407/172148 [1:27:01<50:12, 20.83it/s, loss=4.1687]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.76it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3025, Perplexity: 73.88\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been criticised for the first time in the ####s . ' '' said the .### . '' ) . '' ) . '' ' I said . '' ' I said . '' ' I was a very good friend . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who has been charged with murdering a ##-year-old , who was arrested in the hospital , where he was arrested in the hospital . ' I was a very good man . '' ' I said . '' ' I was a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very difficult time for the future . '' 's time . '' ' I said . '' ' I said . '' ' I was a very good friend . ' '' said the .### . '' ) . ' I 'm not going\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  64%|██████▎   | 109412/172148 [1:27:03<2:43:13,  6.41it/s, loss=4.3469]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the country 's largest cities are expected to be a major boost for the country . ' '' said the company 's website . ) . '' ) . '' ' I 'm not going to be a good thing . '' ' I said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  64%|██████▍   | 110970/172148 [1:28:16<47:22, 21.52it/s, loss=4.2438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.02it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3107, Perplexity: 74.49\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very serious issue '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , the ##-year-old , who was born in the village of the city , and the same . ' '' said the .### . '' ) . '' ' I 've got a lot of people . ' '' said the .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the same as the first time in the world . '' 's not . '' said . '' ' I think it 's a good thing . '' ' I 've got a lot of money . ' '' said the .### . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  64%|██████▍   | 110976/172148 [1:28:18<2:26:08,  6.98it/s, loss=4.1974]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been a `` very serious '' of the government 's government . '' 's not clear whether the government is not the first time . '' 's not clear whether the government is not the first time . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  65%|██████▌   | 112535/172148 [1:29:31<47:54, 20.74it/s, loss=4.3836]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.36it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3095, Perplexity: 74.40\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow , the U.S. military said the government would not be able to use the new rules . ' '' said the .##-caliber rifle . ' '' said the .##-caliber rifle . ' I was a man who\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was arrested in connection with the death of the ##-year-old man , who was arrested in connection with the death of the ##-year-old . ' I was a man who was a man\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the area , the U.S. military said . 's a lot of people . '' 's a time . ' '' said the .##pm . '' ) . ' I 'm a man who was a man\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  65%|██████▌   | 112538/172148 [1:29:32<3:05:11,  5.36it/s, loss=4.4693]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been arrested in connection with the deaths of the U.S. and the U.S. military . '' 's the court heard . ' I 'm not going to be a man . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  66%|██████▋   | 114097/172148 [1:30:46<45:27, 21.28it/s, loss=4.3274]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:46, 33.05it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3198, Perplexity: 75.17\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said : 'The other was a very good idea , '' he said . ' I 'm not going to be a very good friend . ' '' said the .##-caliber gun . ' '' he said . ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City : The ##-year-old was a ##-year-old girl who was a ##-year-old girl , who was a member of the family , who was a member of the family , who was a member of the family ,\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s , and the ##-year-old was shot dead . ' I was a very good man . ' '' said the .##-caliber gun . ' I 'm not going to be a very good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  66%|██████▋   | 114103/172148 [1:30:47<2:24:34,  6.69it/s, loss=4.2517]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` very serious '' of the country 's government to be a `` very good '' and a `` very good '' and a `` very good '' and a `` very good '' and a `` very good '' and a `` very good ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  67%|██████▋   | 115660/172148 [1:32:01<43:55, 21.43it/s, loss=4.3790]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.58it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3015, Perplexity: 73.81\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's presidential candidate , who is the first of the most popular presidential candidate . ' '' said the .### . '' ) . '' ' I 've got to be able to play . '' ' I 'm not going to be\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old , who was ## , and the ##-year-old was arrested on suspicion of murder . ' ' I 'm not going to be a very good . ' '' I was . ' '' she said\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s , and the ##-year-old was in the top ## . ' I 've been a good player . ' '' he said . ' I 'm not going to be able to play . '' '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  67%|██████▋   | 115666/172148 [1:32:03<2:16:44,  6.88it/s, loss=4.3209]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been charged with murder and a ##-year-old man . ' ' I 'm not going to be a very good . ' '' I 've been told . ' I 'm not going to be a very good player . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  68%|██████▊   | 117223/172148 [1:33:15<42:22, 21.61it/s, loss=4.3882]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.48it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3054, Perplexity: 74.10\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first ministerial candidate has been charged with the murder of the ####s . ' I said . '' said the .### . '' ) said . ' I 'm not going to be a very good thing . ' '' said the .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was a member of the country 's largest city in the country . '' 's not . '' said . '' said . ' I said . '' said . ' I was going to be a very good\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the city of the city of the city . ' '' said the .### ) . '' said . ' '' said the .### ) . '' said . ' I 've got to be a very good thing .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  68%|██████▊   | 117229/172148 [1:33:17<2:11:16,  6.97it/s, loss=4.4126]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military is a `` very difficult time '' to be a member of the country 's most recent . '' . ) # . '' ) said . ' I 'm not going to be a very good thing . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  69%|██████▉   | 118785/172148 [1:34:30<42:24, 20.98it/s, loss=4.3110]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 3/3514 [00:00<01:58, 29.73it/s]\u001b[A\n",
            "Evaluating:   0%|          | 7/3514 [00:00<01:50, 31.83it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3036, Perplexity: 73.96\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very serious '' of the government 's decision . '' 's not . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' said . '' ) . '' said . ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old was a ##-year-old man who was arrested in #### . ' I was a bit of a bit of a bit of a lot of time . '' ' I was a bit of a bit of a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane season was a ##-year-old man . ' I was a bit of a bit of a bit of a lot of the time . '' ' I 'm not going to be a good job . ' '' said the .### . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  69%|██████▉   | 118791/172148 [1:34:32<2:11:50,  6.74it/s, loss=4.3990]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been a `` very serious '' of the government 's decision . '' 's not . '' said . '' ) . '' said . '' ) . '' said . '' ) . '' said . '' said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  70%|██████▉   | 120348/172148 [1:35:45<41:57, 20.57it/s, loss=4.3366]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:42, 34.11it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3014, Perplexity: 73.80\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said . '' ) said . '' ' I 'm not sure . ' '' he said . ' I 'm not sure . ' '' he said . ' I 'm not sure . ' '' she said . ' I '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-#-# #-# win over the ##th minute , but the goal is to be able to get the ball to the bottom of the table . '' ' I 'm not sure . '' ' I think it '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the world , and the ##-year-old was a 'tremont ' . '' ) said . ' I 'm not going to be a very good thing . ' '' said . ' I 'm not sure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  70%|██████▉   | 120353/172148 [1:35:46<2:16:04,  6.34it/s, loss=4.3852]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the ##-year-old was a 'very untrue ' . ' '' said . ' I 'm not sure . ' '' he said . ' I 'm not sure . ' '' she said . ' I 'm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  71%|███████   | 121912/172148 [1:36:59<39:14, 21.33it/s, loss=4.2976]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.24it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2999, Perplexity: 73.69\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said . ' I 'm not going to be a very important thing . ' '' said . ' I 'm not going to be a very nice man . ' '' said . ' I 'm not going to be a very\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , which is the first time in the UK , which is the most common problem . ' '' said the company said . ' I 'm not going to be a very important thing . ' '' said . ' I 'm not going to\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the world , and the world 's largest <rare> , the company said . ' I 'm not going to be a very important thing . ' '' said . ' I 'm not going to be a very nice\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  71%|███████   | 121918/172148 [1:37:01<2:01:11,  6.91it/s, loss=4.3987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government is not the only way to make a new deal . '' 's not the same way . '' ' I 'm not going to be a good friend . ' '' said . ' I 'm not going to be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  72%|███████▏  | 123475/172148 [1:38:14<37:52, 21.42it/s, loss=4.2147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.43it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2978, Perplexity: 73.54\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very serious '' of the government 's decision to be a `` very serious '' of the government 's decision to be a `` very serious '' of the government 's decision to be a `` very serious '' of the government '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York , the ##-year-old , who was a member of the family , said the man was killed in the attack . ' '' said the .## . '' ) . '' ' I 've got a lot of people . '' 's a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the city , and the ##-year-old was found in the city of the city . ' '' said the .## '' . ' '' said . '' ' I 'm a friend of the family . '' ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  72%|███████▏  | 123481/172148 [1:38:15<1:56:32,  6.96it/s, loss=4.3273]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government is not the first time in the country . '' 's not . '' said the .## '' . '' ) . '' ' I 've got a lot of people . '' 's a very good friend .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  73%|███████▎  | 125037/172148 [1:39:28<36:42, 21.39it/s, loss=4.3047]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:36, 36.21it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3017, Perplexity: 73.83\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-half-year-old , who was a ##-year-old man who was a ##-year-old girl who was a ##-year-old girl , who was born in #### , was found guilty of murdering\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , who have been arrested in connection with the death of the death of the .## . '' ) . '' ' I said . '' ' I 'm not sure what I 'm going to be a good person . ' '' said .\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane , the ##-year-old , who was born in the ####s , and the ##-year-old was born in #### . ' I 'm not sure what I 'm going to be a good player . '' ' I think I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  73%|███████▎  | 125043/172148 [1:39:30<1:51:47,  7.02it/s, loss=4.3341]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is not the first time in the world . '' 's report . '' ) said . '' 's a lot of people who are going to be a good person . '' 's n't . ' '' said . ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  74%|███████▎  | 126600/172148 [1:40:43<36:05, 21.03it/s, loss=4.3640]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.32it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2953, Perplexity: 73.35\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-half-year-old was a ##-year-old man who was shot dead in the attack . ' I was a bit of a bad foul . ' '' he said . ' I 'm not going to be a\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said : 'The first time I was going to be a little bit of the way I 've got to be able to get the ball . '' ' I 'm not going to be a good player . ' '' he said . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time in the world , and the most important thing to do . '' 's not the first time . ' '' he said . ' I 'm not going to be a little bit . ' '' he said . ' I 'm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  74%|███████▎  | 126606/172148 [1:40:44<1:50:21,  6.88it/s, loss=4.4825]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government is not the first time in the United States . '' 's not the first time . '' 's `` The Situation Room '' . ' '' he said . ' I 'm not going to be a little\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  74%|███████▍  | 128163/172148 [1:41:58<35:56, 20.40it/s, loss=4.2922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.55it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3186, Perplexity: 75.09\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and was arrested on suspicion of murdering a ##-year-old girl . ' I was a very good man . ' '' said the .### . '' ) . ' I 'm not going to be a\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the `` <rare> '' is the first time , the company has been in the UK . '## . '' ' I 'm a fan of the world . '' ' I 'm a fan of the world . '' ' I\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane season , which is the first time in the ####s , and the ##-year-old is a member of the world 's largest in the world , and the most popular tourist group , which is the first time in the ####s ,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  74%|███████▍  | 128169/172148 [1:41:59<1:51:27,  6.58it/s, loss=4.2988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been charged with murder and was arrested on suspicion of murdering a ##-year-old girl . ' I was a very good man . ' '' said the .### . '' ) . ' I 'm not going to be a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  75%|███████▌  | 129726/172148 [1:43:13<32:55, 21.47it/s, loss=4.3756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.08it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2982, Perplexity: 73.57\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's chief executive of the United Nations said the ##-year-old was killed in the attack . ' '' said the .### . '' ) . '' ) . '' ) . '' ' I 've got a lot of people . ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City officials said the ##-year-old was a `` very good '' and he was a very good friend . ' '' said the .### . '' ) . '' ) . '' ) . '' ' I 've got a lot of people\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s , and the ##-year-old was found dead in the car . ' '' said the .### . '' ) . '' ) . '' ) . '' ' I 've got a lot of people\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  75%|███████▌  | 129732/172148 [1:43:14<1:41:02,  7.00it/s, loss=4.3863]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the country 's parliamentary committee will be able to provide a `` thorough investigation '' . '' 's report . '' ) . '' ' I told me . ' I 'm not sure what I 'm going to be a very good job\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  76%|███████▋  | 131291/172148 [1:44:29<32:09, 21.18it/s, loss=4.3057]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.88it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2960, Perplexity: 73.41\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's office , which is the first of the most popular , and the most popularity of the world 's most popular destinations are the most popular to the world . '' 's most of the world . '' 's most of the world\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been criticised for the first time in the ####s , and the ##-year-old was a `` very good idea '' . ' '' he said . '' ' I think I 'm not going to be a very good friend\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the ####s , and the ##-year-old was a ##-year-old girl , who was arrested in #### , and the ##-year-old was arrested in connection with the death of the ##-year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  76%|███████▋  | 131294/172148 [1:44:30<2:06:51,  5.37it/s, loss=4.4463]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been criticised for the first time in the ####s , and the ##-year-old was a `` very good idea '' . ' '' he said . '' ' I think I 'm not going to be a very good friend . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  77%|███████▋  | 132854/172148 [1:45:44<31:36, 20.72it/s, loss=4.2561]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 36.12it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2987, Perplexity: 73.60\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good place '' in the country . '' 's narcotics , '' he said . '' ' I 'm not sure what 's going to happen . '' ' I 'm not sure what 's going to\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York , the ##-year-old , who has been a great player , and he has been a good player . ' '' he said . ' I 'm not going to be a good player . ' '' he said . ' I 'm not\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very good idea . '' 's a great player . ' '' said the .### . '' ) . '' ' I 'm going to be a good player . ' '' said the .### . '' ) . '' ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  77%|███████▋  | 132857/172148 [1:45:45<2:02:41,  5.34it/s, loss=4.3477]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` very good idea '' to be a good idea . '' ' I 'm going to be a good player . ' '' said the .### . '' ) . '' ' I 'm going to be a good player . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  78%|███████▊  | 134415/172148 [1:46:58<29:21, 21.43it/s, loss=4.4530]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 35.02it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2989, Perplexity: 73.62\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and a ##-year-old boy who was a `` very dangerous person '' . ' '' said the .### . '' ) . '' ' I said . ' I 'm not going to be a little bit .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the World Cup . ' I 've got to get back to the ground . '' ' I 'm sure he 's a good player . '' ' I think it 's a good player . ' ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a very difficult time for the first time . '' 's a lot of people . '' ' I think it 's a good thing . '' ' I said . ' I 'm not going to be a little bit . ' '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  78%|███████▊  | 134421/172148 [1:47:00<1:32:03,  6.83it/s, loss=4.2934]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with the murder of the ##-year-old boy who was killed in the attack . ' I was a bit of a bad foul . ' '' said . ' I 'm not going to be a little bit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  79%|███████▉  | 135978/172148 [1:48:14<28:37, 21.06it/s, loss=4.3501]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 33.83it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2953, Perplexity: 73.36\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with murder and a ##-year-old man who was arrested on suspicion of murder and was arrested on suspicion of murder . ' ' I was a very nice man . ' '' said . ' I was a very nice man\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old , who has been in the world , and the ##-year-old was born in #### . ' I was a very nice man . ' '' said the .### . '' ) . '' ' I\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a long-term solution , and the .### , '' said the .## '' of the #### World War . ' '' said . ' I 've been in the world . '' ' I said . ' I 'm not going to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  79%|███████▉  | 135984/172148 [1:48:15<1:26:19,  6.98it/s, loss=4.3847]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the National Assembly , which is the most important thing for the country 's most recent . '' #### #### #### #### .### , #### . '' ) . '' said . ' I 've been in the world . '' ' I 'm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  80%|███████▉  | 137542/172148 [1:49:29<27:14, 21.17it/s, loss=4.2844]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.24it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2956, Perplexity: 73.38\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good '' of the country 's most recent .##-caliber rifle . ' '' said the .##pm . '' ) . '' said . ' I 've been able to get a good time . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was found guilty of murdering ##-year-old daughter , who was found guilty of murdering ##-year-old daughter , who was found guilty of murdering ##-year-old daughter ,\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is the first time the first time in the world is the most commonplace . ' '' said the .##-caliber rifle . ' '' said the .##pm . '' ) . '' said . ' I 've been able to get\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  80%|███████▉  | 137548/172148 [1:49:30<1:23:37,  6.90it/s, loss=4.3947]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is the first time in the United States , which is the first time in the United States . '' 's . '' said . '' ' I said . '' ' I said . ' I 've been able to get a good time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  81%|████████  | 139105/172148 [1:50:44<25:37, 21.50it/s, loss=4.4562]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 34.94it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2957, Perplexity: 73.38\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good '' of the president 's speech , '' he said . '' ' I 'm not sure . '' ' I think it was a very good thing . '' ' I think it was a great thing . '' ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old was arrested in the hospital after the attack was found in the area . ' ' I was a very good man . '' ' I was a bit of a little bit . ' '' said the .##-cal\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane of the crash occurred in the city of the city . '' 's . '' ) . '' ' I 'm not sure . '' ' I think it was a very good thing . '' ' I think it was a very good thing . '' '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  81%|████████  | 139111/172148 [1:50:45<1:18:58,  6.97it/s, loss=4.2655]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is a very good man , '' he said . '' ' I 'm not sure . '' ' I think it was a very good thing . '' ' I think it was a very good thing . '' ' I think it was a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  82%|████████▏ | 140667/172148 [1:51:59<24:25, 21.49it/s, loss=4.3837]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 33.90it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2875, Perplexity: 72.79\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with the murder of the ##-year-old , who was arrested in the hospital . ' ' I was in the house . ' '' said . ' I was a man who was a man who was a man who was a member\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was arrested in the hospital , where he was arrested in the hospital . ' . ' '' said the .## . '' ) . ' I was a very good friend . ' '' said . ' I was\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a huge increase in the number of people in the country . ' . '' ) . '' ' I think I 'm not going to be able to get the right to be able to get the best to the first time . ' '' he said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  82%|████████▏ | 140672/172148 [1:52:01<1:24:08,  6.23it/s, loss=4.2623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government is not the first time in the country . '' 's . ' '' said . ' I 'm not sure what I 'm not going to be a very good thing . ' '' said . ' I '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  83%|████████▎ | 142232/172148 [1:53:14<24:14, 20.56it/s, loss=4.3806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 35.08it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.3570, Perplexity: 78.03\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very dangerous '' and that he would be a very good idea . '' 's a very good player . '' ' I 'm not going to be a bit of a very good team . 's a very good player . ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the last ## . ' I 've got to be a good player . '' ' I 'm not going to be a bit of a bit of a bit of a bit of a bit of a bit of\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a long time , the government has been a `` very dangerous '' to the government . '' 's not the case . '' ' I 'm not going to be a very good idea . '' 's a very good player . '' ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  83%|████████▎ | 142235/172148 [1:53:16<1:37:30,  5.11it/s, loss=4.4508]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` very strong '' to the government . '' 's not the president , '' he said . '' ) . '' ' I said . '' ' I said . '' ' I do n't think I 'm going to be a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  84%|████████▎ | 143793/172148 [1:54:29<21:51, 21.63it/s, loss=4.3707]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.23it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2968, Perplexity: 73.47\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a 'happy ' of the 'deal ' by the . ' I was in the room . ' '' he said . ' I 'm not sure . ' '' he said . ' I was a very good friend . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the world , but the ##-year-old was a ##-year-old man who was a ##-year-old girl , who was a ##-year-old girl , who was found guilty\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a long time , but it is not a problem . ' '' said the .### ) . '' ' I 've got to be a very good thing . ' '' said . ' I was a very good friend . ' '' said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  84%|████████▎ | 143799/172148 [1:54:31<1:08:17,  6.92it/s, loss=4.3940]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a 'most important role in the first time , but the government has been in the case . '' 's not the case . ' '' he said . ' I 'm not sure . ' '' he said . ' I was a very\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  84%|████████▍ | 145356/172148 [1:55:44<20:07, 22.19it/s, loss=4.2614]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:40, 35.05it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2903, Perplexity: 72.99\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said : `` The U.S. '' of the U.S. military . '' 's `` <rare> '' . ' '' said the .### ) . '' ' I 'm not sure what I 'm\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been charged with murdering a ##-year-old girl , who was arrested in connection with the incident . ' ' I 'm not sure what I 'm not going to do . '' ' I said . ' I 'm\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane is a long-term solution to the .### . '' ) . '' ' I said . ' I 'm not sure how to do it . ' '' he said . ' I 'm not sure how to do it . ' '' she\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  84%|████████▍ | 145362/172148 [1:55:46<1:03:43,  7.01it/s, loss=4.4544]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been a `` very serious '' of the country 's most recent years . '' 's not the first time . ' '' he said . ' I 'm not sure how to do it . ' '' he\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  85%|████████▌ | 146919/172148 [1:56:59<20:08, 20.88it/s, loss=4.3030]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.30it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2991, Perplexity: 73.63\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good opportunity to get the best to the team . '' ' I think it 's a good thing . '' ' I think I 'm not sure what I 'm going to be a good player . ' '' he said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the ##-year-old was a ##-year-old boy who was a woman who was a woman who was a woman who was a woman who was a woman who was a woman who was a woman who was a woman who\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was a major problem in the region . '' 's a source . ) . '' said . '' ' I said . '' ' I told him . ' I 'm not sure what I was going to be a bit . ' '' said . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  85%|████████▌ | 146925/172148 [1:57:01<1:01:17,  6.86it/s, loss=4.2996]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office , which is the first time of the year , and the ##-year-old was in the midst of a ##-year-old man who was a ##-year-old boy who was shot dead by a police officer .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  86%|████████▋ | 148484/172148 [1:58:16<19:33, 20.16it/s, loss=4.2752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.53it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2960, Perplexity: 73.40\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very sadistic '' of the president 's speech . '' 's `` The <rare> '' . ' '' said the .### . '' ) . '' said . ' I 'm a friend who was a little girl\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the world . ' '' he said . ' I 'm not going to be a little bit . ' '' said the .### . ' '' said the .### . ' '' said . '' '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was discovered in the area . ' '' said the .### . '' ) . '' said . '' ' I said . ' I 'm not going to be a little bit . ' '' said the .## . '' ) . '' said .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  86%|████████▋ | 148487/172148 [1:58:17<1:15:15,  5.24it/s, loss=4.4657]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been a `` very sadistic '' of the president 's speech . '' 's `` The <rare> '' . ' '' said the .### . '' ) . '' said . ' I 'm a friend who was\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  87%|████████▋ | 150046/172148 [1:59:33<17:35, 20.94it/s, loss=4.4097]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:41, 34.48it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2945, Perplexity: 73.30\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been accused of the attacking the Islamic State . ' '' said the .##-caliber handgun . ' '' said the .##pm . ' ) . '' ' I 'm a friend of the . ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old , who was a ##-year-old , who was a ##-year-old , who was a ##-year-old , who was a ##-year-old , who was a ##-\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area , and the ##-year-old was killed . ' . ' '' said the .##pm . ' ) . '' ' I 'm a friend of the . ' I was a bit of a good job . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  87%|████████▋ | 150052/172148 [1:59:35<54:33,  6.75it/s, loss=4.2847]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is not the first time . '' 's `` The right '' . ' '' said the .##pm . ' ) . '' ' I 'm a friend of the . ' I was a bit of a good job . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  88%|████████▊ | 151610/172148 [2:00:51<16:22, 20.90it/s, loss=4.3501]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:47, 32.53it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2950, Perplexity: 73.33\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been accused of being a `` very good '' of the country 's most powerful . '' . '' said . '' ' I said . ' I was a very good friend . ' '' said . ' I was a very good friend . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's official website said : 'The whole thing is that I 've been doing . ' I was a very good friend . ' '' said . ' I was a very good friend . ' '' said . ' I was a very good friend\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the UK , and the ##-year-old was arrested in connection with the incident . ' I was a man . ' '' said . ' I was a very good friend . ' '' said . ' I was a very\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  88%|████████▊ | 151613/172148 [2:00:52<1:05:01,  5.26it/s, loss=4.2721]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government has been accused of the attacking the government 's government to be able to control the government 's government to be able to control the government 's government to be able to control the government 's government to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  89%|████████▉ | 153172/172148 [2:02:08<15:34, 20.30it/s, loss=4.2498]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:52, 31.21it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2971, Perplexity: 73.48\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's government has been accused of being a `` very dangerous '' of the country 's largest . '' '' said the .## '' . '' ) . '' said . '' ' I was a member of the school . ' '' said the .##\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , the ##-year-old , who has been in the world , and the most popular destination for the world 's biggest-ever-generation of the world 's biggest-ever-generation is the most popular destination for the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the area , the ##-year-old said . 's not a case of the case . '' ' I was a member of the school . ' '' said the .## p.m. , the .## .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  89%|████████▉ | 153177/172148 [2:02:09<51:54,  6.09it/s, loss=4.4326]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President was also accused of the `` serious threat '' to be a `` very dangerous '' of the country 's largest . '' '' said the .## '' . '' ) . '' said . '' ' I was a member of the school . ' '' said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  90%|████████▉ | 154734/172148 [2:03:26<14:17, 20.31it/s, loss=4.1536]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 33.90it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2869, Perplexity: 72.74\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major issue of the country 's most recent years . '' 's not . '' said . '' ' I said . ' I was a bit of a bit of a lot of people . ' '' said the .## . '' )\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council , which is the first time in the UK , which is expected to be a key part of the country 's most recent years . '' 's not . ' '' said the .### . '' ) . '' ' I was a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the crash , which was found in the area . ' '' said the police officer . ' I was a woman . ' '' said . ' I was a woman . ' '' said . ' I was a woman . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  90%|████████▉ | 154740/172148 [2:03:27<43:32,  6.66it/s, loss=4.3694]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been charged with the death of the two-year-old , who was killed in the crash , which was found in the village of the city of the city of the city of the city of the city of the city of the city of the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  91%|█████████ | 156299/172148 [2:04:44<13:11, 20.02it/s, loss=4.3814]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:47, 32.67it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2888, Perplexity: 72.88\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good opportunity to be a good player . '' ' I 'm not sure what I 'm going to be a little bit . ' '' said the .### ) . '' ' I told him . ' I was a\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's ##-year-old was arrested in #### after the deaths of the ##-year-old . ' I was a little bit . ' '' said . ' I 'm not sure what I 'm going to do . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the world , and the ##-year-old was in the first half . ' I was a bit of a good job . ' '' said the .### . ' I 'm not going to be a little bit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  91%|█████████ | 156302/172148 [2:04:45<52:01,  5.08it/s, loss=4.3695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the United States has been in the UK , which is expected to be a third of the most expensive . 's #.# million . '' ) . '' said . ' I 'm not sure what I 'm going to do . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  92%|█████████▏| 157860/172148 [2:06:03<11:47, 20.18it/s, loss=4.3152]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:50, 31.80it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2851, Perplexity: 72.61\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with the murder of the murder of the murder of the murder of the murder of the woman . ' ' I was a man . ' '' said . ' I 've got a lot of people . ' '' said the . ' I\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# draw with the United States is the first to be a great player in the Premier League . ' '' he said . ' I 've got a lot of the players . '' ' I 've got a lot of the\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area , and the ##-year-old was killed in the crash . ' ' I 've got a lot of people . ' '' said the . ' I 'm not sure . ' '' he said . ' I '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  92%|█████████▏| 157865/172148 [2:06:05<39:48,  5.98it/s, loss=4.2367]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office has been charged with the murder of the murder of the murder of the murder of the murder of the woman . ' ' I was a man . ' '' said . ' I 've got a lot of people . ' '' said the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  93%|█████████▎| 159423/172148 [2:07:24<10:56, 19.39it/s, loss=4.2477]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.70it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2908, Perplexity: 73.02\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very important '' of the country 's government . '' 's not the same . '' ) . '' said . ' I was a very good friend . ' '' said . ' I was a very good friend . ' '' said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , the ##-year-old , who is a member of the United States . 's the same . '' ) . '' ' I 'm not sure what happened . ' '' she said . ' I was a very good friend . '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the UK , the ##-year-old , who is the first of the most famous man . ' '' said the .##pm . '' ) . '' ' I 'm not sure what happened . ' '' she said\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  93%|█████████▎| 159429/172148 [2:07:25<35:04,  6.05it/s, loss=4.3521]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is a `` very important '' of the American government . '' 's not the same . '' ' I 'm not sure what happened . ' '' she said . ' I was a very good friend . ' '' said . ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  94%|█████████▎| 160987/172148 [2:08:42<08:42, 21.34it/s, loss=4.4473]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:38, 35.53it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2853, Perplexity: 72.63\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said . 'Given the . '' ) . '' said . ' I 'm not going to be a little bit . ' '' she said . ' I 'm not going to be a little bit . ' '' she said\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the World Cup . ' I 'm going to be a good player . '' ' I 'm going to be a good player . '' ' I 'm going to be a good player . '' ' I\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was discovered in the city of the city . ' '' I said . ' '' she said . ' I 'm not going to be a little bit . ' '' she said . ' I 'm not going to be a little bit . ' ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  94%|█████████▎| 160993/172148 [2:08:43<26:50,  6.93it/s, loss=4.2262]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` very good opportunity '' to the United States . '' 's a news conference . ' '' he said . ' I 'm not going to be a little bit . ' '' she said . ' I 'm not going to be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  94%|█████████▍| 162550/172148 [2:10:00<07:51, 20.37it/s, loss=4.3133]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:49, 32.18it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2890, Perplexity: 72.89\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a major factor in the attacking government . '' 's a statement . ) . '' ' I 'm sure . ' '' he said . ' I 'm not sure . ' '' he said . ' I 'm not sure .\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# draw with the ##-year-old , who was a ##-year-old , who was a ##-year-old , who was a ##-year-old , who was arrested in the hospital , and\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the water , and the ##-year-old was found in the area . ' '' I 'm a friend of the family and friends . ' '' said . ' I 'm a friend of the family and I was n'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  94%|█████████▍| 162556/172148 [2:10:02<23:57,  6.67it/s, loss=4.3957]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. government is not the only one of the most important people . '' 's a .### ) . '' ' I 'm sure . ' '' said the .### ) . '' ' I 'm a friend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  95%|█████████▌| 164113/172148 [2:11:19<06:38, 20.17it/s, loss=4.2926]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:43, 34.07it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2917, Perplexity: 73.09\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said : 'We are not going to be able to get the money to be able to do it . '' ' I told him . ' I 'm not sure what happened . ' '' she said . '' ' I told him\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council has been accused of being a `` very serious threat '' to be a . '' ) . '' ' I told the BBC . ' I 'm not sure what happened . ' '' she said . '' ' I told him . ' I '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  95%|█████████▌| 164119/172148 [2:11:21<20:03,  6.67it/s, loss=4.3839]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President of the U.S. military has been accused of being a `` very serious threat '' to be a `` very serious threat '' . '' ' I told him . ' I 'm not sure what happened . ' '' she said . '' ' I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  96%|█████████▌| 165676/172148 [2:12:38<05:29, 19.67it/s, loss=4.2406]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:44, 33.63it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2904, Perplexity: 72.99\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been a `` very good '' of the presidential election . '' . '' ) . '' said . '' ' I 'm a friend . '' . ) . '' ) . '' ' I 'm a friend . '' . ) . '' )\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City , the ##-year-old , who was a ##-year-old man who was a ##-year-old man who was a ##-year-old man who was shot dead by a police officer . ' ' I was a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area . ' '' said the .### ) . '' . ) # . '' ) . ' I 'm a friend . '' . ) . '' ) . '' ' I 'm a friend . '' . ) . ''\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  96%|█████████▌| 165681/172148 [2:12:40<19:14,  5.60it/s, loss=4.4089]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government has not been able to identify the suspects . ' '' said the .## . '' ) . '' said . '' ' I 'm a friend . '' . ) . '' ) . '' ' I 'm a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  97%|█████████▋| 167238/172148 [2:13:57<03:56, 20.74it/s, loss=4.2733]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:47, 32.71it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2897, Perplexity: 72.95\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's official statement said : 'We are not aware of the situation . '' ' I said . ' '' she said . ' I 'm not sure what happened . ' '' she said . ' I 'm not sure what happened . ' ''\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Council said the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the `` <rare> '' of the <rare> , which is the first time . ''\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the past year . ' '' he said . ' '' he said . ' I 'm not sure what happened . ' '' she said . ' I 'm not sure what happened . ' '' she said . ' I '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  97%|█████████▋| 167244/172148 [2:13:59<12:05,  6.76it/s, loss=4.2491]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President has been a `` very strong '' of the president 's decision to end the . '' ) of the first time . ' '' he said . ' I 'm not sure what happened . ' '' she said . ' I 'm not sure what\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  98%|█████████▊| 168803/172148 [2:15:14<02:33, 21.84it/s, loss=4.3676]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:49, 32.07it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2865, Perplexity: 72.71\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with the murder of a ##-year-old woman who was arrested in connection with the death of the death of the death of the death of the death of the death of the death of the death of the death of the death of\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-# #-\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time of the year , and the ##-year-old was in the UK . ' ' I 'm not sure what I 'm going to be a little bit . ' '' said . ' I 'm not sure what I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  98%|█████████▊| 168806/172148 [2:15:16<10:28,  5.32it/s, loss=4.2422]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office said the government has been `` very concerned '' by the government . '' 's . ' ) . '' ' I said . ' I was a very good friend . ' '' said . ' I was a friend of the couple . '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  99%|█████████▉| 170366/172148 [2:16:28<01:22, 21.63it/s, loss=4.3556]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:39, 35.33it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2846, Perplexity: 72.57\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow 's first-handed attacker was the first of the deadliest attack on the island of the city . '' ' I 'm a friend . '' ' I 'm a friend . ' '' said . '' ' I 'm a friend\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City 's #-# win over the World Cup . '' ' I 've got to be a bit more . '' ' I 've got to be a bit more . '' ' I 've got to be a bit more . '' '\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was found in the area , and the plane was found in the area . ' '' he said . ' '' she said . ' I 'm not sure what I 'm not going to be a bit of a good job . '' ' I '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:  99%|█████████▉| 170369/172148 [2:16:30<05:32,  5.36it/s, loss=4.2799]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's government has been in the country 's government and the government 's government to be a `` very dangerous '' . '' '' said . '' ) . '' ' I 'm not sure what I 'm going to be a very good thing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|█████████▉| 171929/172148 [2:17:43<00:10, 21.45it/s, loss=4.2463]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After 200064 examples, Average Loss: 4.3117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating:   0%|          | 0/3514 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   0%|          | 4/3514 [00:00<01:37, 35.86it/s]\u001b[A\n",
            "                                                            \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2843, Perplexity: 72.55\n",
            "Computed on 1024 sentences\n",
            "Generating text based on contexts using generate_text:\n",
            "\n",
            "\n",
            "Context: Moscow\n",
            "\n",
            "Generated text: Moscow has been charged with the murder of the death of the ##-year-old . ' I was a very good friend . ' '' said . ' I was a friend . ' '' said . ' I was a friend . ' '' said . '\n",
            "\n",
            "Context: New York\n",
            "\n",
            "Generated text: New York City Mayor Michael Bloomberg said the attack was `` very concerned '' by the president 's government . '' ' I said . '' ' I said . ' I was a little bit of the car . ' '' she said . ' I was a\n",
            "\n",
            "Context: The hurricane\n",
            "\n",
            "Generated text: The hurricane was the first time in the UK , and the ##-year-old is the first time in the UK . ' '' he said . ' I 'm not going to be a good time . ' '' she said . ' I was a friend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|█████████▉| 171932/172148 [2:17:44<00:40,  5.33it/s, loss=4.2707]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context: The President\n",
            "\n",
            "Generated text: The President 's office is not the first time to be able to take the lead . '' ' I 'm not sure what 's going to happen . '' ' I said . '' ' I was a friend . ' '' said . ' I was a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 172148/172148 [2:17:54<00:00, 20.80it/s, loss=4.3168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/1, Average Loss: 4.3072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Loss: 4.2824, Perplexity: 72.41\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# Main training loop for a Recurrent Neural Network Language Model\n",
        "# This script handles the entire training process including data loading,\n",
        "# model training, validation, and text generation\n",
        "# ----------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize random seeds to ensure reproducible results\n",
        "    set_seed(42)\n",
        "\n",
        "    # Check for CUDA-capable GPU and set the device accordingly\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Retrieve model architecture and training hyperparameters from configuration\n",
        "    # emb_dim: dimensionality of word embeddings and hidden states\n",
        "    # num_layers: number of recurrent layers in the model\n",
        "    # batch_size: mini-batch size\n",
        "    # learning_rate: step size for optimizer updates\n",
        "    # num_epochs: number of complete passes through the training dataset\n",
        "    emb_dim, num_layers, batch_size, learning_rate, num_epochs = get_hyperparameters()\n",
        "\n",
        "    # Initialize the tokenizer using Microsoft's Phi-3.5-mini model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
        "\n",
        "    # Get the size of the vocabulary that the model needs to handle\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Download the news dataset and create DataLoader objects for training and testing\n",
        "    # DataLoaders handle batching and shuffling\n",
        "    data_url = \"https://www.thelmbook.com/data/news\"\n",
        "    train_dataloader, test_dataloader = download_and_prepare_data(data_url, batch_size, tokenizer)\n",
        "\n",
        "    # Initialize the RNN language model with specified architecture parameters\n",
        "    # vocab_size: determines output layer dimensionality\n",
        "    # emb_dim: size of word embeddings and hidden states\n",
        "    # num_layers: number of RNN layers\n",
        "    # pad_token_id: special token ID used for padding shorter sequences\n",
        "    model = RecurrentLanguageModel(vocab_size, emb_dim, num_layers, tokenizer.pad_token_id)\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize model weights using custom initialization scheme\n",
        "    # This is important for stable training of deep neural networks\n",
        "    initialize_weights(model)\n",
        "\n",
        "    # Calculate and display the total number of trainable parameters in the model\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total trainable parameters: {total_params}\\n\")\n",
        "\n",
        "    # Initialize the loss function (Cross Entropy) for training\n",
        "    # ignore_index=pad_token_id ensures that padding tokens don't contribute to the loss\n",
        "    # This prevents the model from learning to predict padding tokens\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "    # Initialize the AdamW optimizer with specified learning rate\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Set evaluation interval (number of examples after which to perform validation)\n",
        "    # 100,000 examples provides a good balance between training time and monitoring frequency\n",
        "    eval_interval = 200_000\n",
        "    examples_processed = 0  # Counter for tracking progress toward next evaluation\n",
        "\n",
        "    # Define test contexts for generating sample text during evaluation\n",
        "    contexts = [\n",
        "        \"Moscow\",\n",
        "        \"New York\",\n",
        "        \"The hurricane\",\n",
        "        \"The President\"\n",
        "    ]\n",
        "\n",
        "    # Main training loop - iterate through specified number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Set model to training mode\n",
        "        model.train()\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}, Model in training mode: {model.training}\")\n",
        "\n",
        "        # Initialize tracking variables for this epoch\n",
        "        total_loss = 0.0      # Accumulator for loss across all batches\n",
        "        total_tokens = 0      # Counter for actual tokens processed (excluding padding)\n",
        "        # Create progress bar for monitoring training progress\n",
        "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Iterate through batches in the training data\n",
        "        for batch_idx, (input_seq, target_seq) in enumerate(progress_bar):\n",
        "            # Move input and target sequences to GPU if available\n",
        "            input_seq = input_seq.to(device)\n",
        "            target_seq = target_seq.to(device)\n",
        "            # Get current batch dimensions for reshaping operations\n",
        "            batch_size_current, seq_len = input_seq.shape\n",
        "\n",
        "            # Clear gradients from previous batch\n",
        "            # This is necessary as PyTorch accumulates gradients by default\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass: get model predictions for this batch\n",
        "            # output shape: (batch_size, seq_len, vocab_size)\n",
        "            output = model(input_seq)\n",
        "\n",
        "            # Reshape output and target tensors for loss computation\n",
        "            # - output: reshape to (batch_size * seq_len, vocab_size) for CrossEntropyLoss\n",
        "            # - target: reshape to (batch_size * seq_len) to match CrossEntropyLoss requirements\n",
        "            output = output.reshape(batch_size_current * seq_len, vocab_size)\n",
        "            target = target_seq.reshape(batch_size_current * seq_len)\n",
        "\n",
        "            # Count number of non-padding tokens in target\n",
        "            # This is needed because to calculate the average loss for multiple batches we need to divide the total loss\n",
        "            # by the number of tokens in these batches, but criterion(output, target) returns the average loss per token in a batch.\n",
        "            # So, we will multiply the loss per token by the number of tokens to get the loss per batch\n",
        "            non_padding_token_count = (target != tokenizer.pad_token_id).sum().item()\n",
        "\n",
        "            # Compute loss between model predictions and actual targets\n",
        "            loss = criterion(output, target)\n",
        "            # Backward pass: compute gradients of loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # Update model parameters using calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate actual loss value for this batch\n",
        "            # Multiply the loss per token by number of non-padding tokens to get total loss for the batch\n",
        "            loss_value = loss.item() * non_padding_token_count\n",
        "            # Accumulate total loss for epoch statistics\n",
        "            total_loss += loss_value\n",
        "            # Accumulate total number of actual tokens processed\n",
        "            total_tokens += non_padding_token_count\n",
        "            # Increment counter for examples processed\n",
        "            examples_processed += batch_size_current\n",
        "\n",
        "            # Update progress bar with current batch loss\n",
        "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "            # Periodic evaluation after processing specified number of examples\n",
        "            if examples_processed >= eval_interval:\n",
        "                # Calculate average loss over the last eval_interval examples\n",
        "                avg_loss = total_loss / total_tokens\n",
        "                print(f\"\\nAfter {examples_processed} examples, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "                # Switch to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Compute validation metrics\n",
        "                # average_loss: mean loss on validation set\n",
        "                # perplexity: exponential of average loss, lower is better\n",
        "                # sentences_processed: number of validation sequences evaluated\n",
        "                average_loss, perplexity, sentences_processed = compute_loss_and_perplexity(\n",
        "                    model=model,\n",
        "                    vocab_size=vocab_size,\n",
        "                    val_dataloader=test_dataloader,\n",
        "                    criterion=criterion,\n",
        "                    device=device,\n",
        "                    max_sentences=1000  # Limit validation to 1000 sentences for speed\n",
        "                )\n",
        "                print(f\"Validation Average Loss: {average_loss:.4f}, Perplexity: {perplexity:.2f}\")\n",
        "                print(f\"Computed on {sentences_processed} sentences\")\n",
        "\n",
        "                # Generate sample texts to qualitatively assess model performance\n",
        "                print(\"Generating text based on contexts using generate_text:\\n\")\n",
        "                for context in contexts:\n",
        "                    # Generate text continuation for each test context\n",
        "                    generated_text = generate_text(\n",
        "                        model=model,\n",
        "                        start_string=context,\n",
        "                        tokenizer=tokenizer,\n",
        "                        device=device,\n",
        "                        max_length=50  # Limit generation to 50 tokens for brevity\n",
        "                    )\n",
        "                    print(f\"\\nContext: {context}\")\n",
        "                    print(f\"\\nGenerated text: {generated_text}\")\n",
        "\n",
        "                # Switch back to training mode for continued training\n",
        "                model.train()\n",
        "                # Reset counters for next evaluation interval\n",
        "                examples_processed = 0\n",
        "                total_loss = 0.0\n",
        "                total_tokens = 0\n",
        "\n",
        "        # End-of-epoch reporting\n",
        "        if total_tokens > 0:\n",
        "            # Calculate and display average loss for the epoch\n",
        "            avg_loss = total_loss / total_tokens\n",
        "            print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "        else:\n",
        "            # Handle edge case where no tokens were processed\n",
        "            print(f\"\\nEpoch {epoch+1}/{num_epochs} completed.\")\n",
        "\n",
        "        # Perform end-of-epoch validation\n",
        "        model.eval()\n",
        "        average_loss, perplexity, sentences_processed = compute_loss_and_perplexity(\n",
        "            model=model,\n",
        "            vocab_size=vocab_size,\n",
        "            val_dataloader=test_dataloader,\n",
        "            criterion=criterion,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"Validation Average Loss: {average_loss:.4f}, Perplexity: {perplexity:.2f}\\n\")\n",
        "\n",
        "        # Reset to training mode for next epoch\n",
        "        model.train()\n",
        "\n",
        "    # Save the trained model and tokenizer for later use\n",
        "    # This includes model architecture, weights, and tokenizer configuration\n",
        "    model_name = \"RNN_LM\"\n",
        "    save_model(model, tokenizer, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "\n",
        "In the cell below, we load and test the language model:"
      ],
      "metadata": {
        "id": "JoSevu4VJ-Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Model tests\n",
        "# ----------------------------\n",
        "\n",
        "# Load the previously saved model and tokenizer from disk\n",
        "# This recreates the exact model state from after training\n",
        "model, tokenizer = load_model(model_name)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Print header for test section\n",
        "print(\"Testing the model:\\n\")\n",
        "\n",
        "# Define a list of test prompts to evaluate model performance\n",
        "contexts = [\n",
        "    \"Moscow\",\n",
        "    \"New York\",\n",
        "    \"A hurricane\",\n",
        "    \"The President\"\n",
        "]\n",
        "\n",
        "# Iterate through each test prompt and generate text\n",
        "for context in contexts:\n",
        "    # Generate text using greedy decoding (most likely tokens)\n",
        "    # Add a space after the context to separate it from generated text\n",
        "    generated_text = generate_text(\n",
        "        model=model,          # The loaded language model\n",
        "        start_string=context,  # Add space to avoid the generated text to be \"glued\" to the prompt\n",
        "        tokenizer=tokenizer,  # Tokenizer for text conversion\n",
        "        device=device,        # CPU or GPU device\n",
        "        max_length=50         # Maximum length of generated sequence\n",
        "    )\n",
        "\n",
        "    # Print the original prompt and model's response\n",
        "    print(f\"\\nPrompt: {context}\")\n",
        "    print(f\"\\nGenerated response: {generated_text}\")"
      ],
      "metadata": {
        "id": "7JmWY6HACeCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fa8c08-274c-49ba-d863-b90025862ebf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-05703a206286>:673: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_state = torch.load(f'{file_prefix}_model.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model:\n",
            "\n",
            "\n",
            "Prompt: Moscow\n",
            "\n",
            "Generated response: Moscow has been a `` very serious '' to the government 's decision . '' 's . '' ) . '' ) . '' ' I 'm not sure what 's wrong . ' '' ) . '' ) . ' '' she said . ' ''\n",
            "\n",
            "Prompt: New York\n",
            "\n",
            "Generated response: New York City 's #-#-# win over the world 's top ## . ' '' he said . ' '' he said . ' '' he said . ' '' I 'm not sure ] . ' '' she said . ' '' she said\n",
            "\n",
            "Prompt: A hurricane\n",
            "\n",
            "Generated response: A hurricane season , the ##-year-old was found dead in the car . ' '' . ' '' ) . '' ' I 'm not sure what 's ] . ' '' she said . ' '' she said . ' '' she said . '\n",
            "\n",
            "Prompt: The President\n",
            "\n",
            "Generated response: The President 's office has been criticised for the first time in the past . '' ' I 'm not sure what 's happening . '' ' I 'm not sure what I 'm not going to be a little bit . ' '' he said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "N3ypCXJmxubs"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "630d21fff5244e488c6811458be81afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d8740c3cc1f483aa59db02bb410ab80",
              "IPY_MODEL_e628a38b90874e52bc19263adb041b65",
              "IPY_MODEL_3e96499b15d34ea48d1f8656d621daee"
            ],
            "layout": "IPY_MODEL_2a5481d7e47a493fbea2b44e0735bdfa"
          }
        },
        "4d8740c3cc1f483aa59db02bb410ab80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9cfb2d146c47628575853dbe7cfbcb",
            "placeholder": "​",
            "style": "IPY_MODEL_61765eddb3594cdfbc4d4b1d6be7b9f4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e628a38b90874e52bc19263adb041b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5632a18d2c4341b47244f805d10404",
            "max": 3984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78b44428d22e4746b3624d949f065801",
            "value": 3984
          }
        },
        "3e96499b15d34ea48d1f8656d621daee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d23345f58c4bde89519b339150cd77",
            "placeholder": "​",
            "style": "IPY_MODEL_6b88f3b6c36e41d2abc713b83be3b2da",
            "value": " 3.98k/3.98k [00:00&lt;00:00, 317kB/s]"
          }
        },
        "2a5481d7e47a493fbea2b44e0735bdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9cfb2d146c47628575853dbe7cfbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61765eddb3594cdfbc4d4b1d6be7b9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5632a18d2c4341b47244f805d10404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b44428d22e4746b3624d949f065801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22d23345f58c4bde89519b339150cd77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b88f3b6c36e41d2abc713b83be3b2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfdbd84d25c940db85f44d30eb1074f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6520655c644421db53bd988981e2c58",
              "IPY_MODEL_d416271ded974c3db000d4bcaefdac22",
              "IPY_MODEL_019c3a225d484a38ab93cea610da6c09"
            ],
            "layout": "IPY_MODEL_c017f138eae8465e8d7247b89560991b"
          }
        },
        "a6520655c644421db53bd988981e2c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cecf93f058b467fa642c0f84934dd53",
            "placeholder": "​",
            "style": "IPY_MODEL_6282fa1ed8f7473c8b1f676fcfb884ef",
            "value": "tokenizer.model: 100%"
          }
        },
        "d416271ded974c3db000d4bcaefdac22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86081ecc5c1d4bea9b206da50d8550f7",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0722e57fbd8b4d93b548bfb7ac198673",
            "value": 499723
          }
        },
        "019c3a225d484a38ab93cea610da6c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72c6acd8bc7d4045949b0a19fe5f484d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f81fad0ff334affb501f9e4dce85825",
            "value": " 500k/500k [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "c017f138eae8465e8d7247b89560991b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cecf93f058b467fa642c0f84934dd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6282fa1ed8f7473c8b1f676fcfb884ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86081ecc5c1d4bea9b206da50d8550f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0722e57fbd8b4d93b548bfb7ac198673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72c6acd8bc7d4045949b0a19fe5f484d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f81fad0ff334affb501f9e4dce85825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40d225a820614d13ab892c197ea4ae4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3b95d65f1e54391ad94cf6e8f125145",
              "IPY_MODEL_763c64a5c89b464d858832f55460ca04",
              "IPY_MODEL_d117b339ea8b401dbeacafcf1217cc71"
            ],
            "layout": "IPY_MODEL_6a5cadc6074a4ed0addedf271d364bdc"
          }
        },
        "e3b95d65f1e54391ad94cf6e8f125145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a0f124575b145efb6c6f1836e8f3eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_2f27c63f44bd43e09259b2f12ed51a98",
            "value": "tokenizer.json: 100%"
          }
        },
        "763c64a5c89b464d858832f55460ca04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f282c4fb45e4658a4b3e827baa290ec",
            "max": 1844408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06e95e397f2d454dbe08f4ffb47f3730",
            "value": 1844408
          }
        },
        "d117b339ea8b401dbeacafcf1217cc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c69bda59524bf2b22265bba05dbbbf",
            "placeholder": "​",
            "style": "IPY_MODEL_b80e85fc0df14838826c2a464bdc3b59",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "6a5cadc6074a4ed0addedf271d364bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a0f124575b145efb6c6f1836e8f3eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f27c63f44bd43e09259b2f12ed51a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f282c4fb45e4658a4b3e827baa290ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e95e397f2d454dbe08f4ffb47f3730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62c69bda59524bf2b22265bba05dbbbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80e85fc0df14838826c2a464bdc3b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "533510d21cc342b9b671971f559a6086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d0057bd584744859e739e1a8e8c6f97",
              "IPY_MODEL_d9f029930ded4c31b8d6adc0bcf42c5e",
              "IPY_MODEL_af8c8e80b1b14b5f8474004b82853ead"
            ],
            "layout": "IPY_MODEL_216feeb1b9204560b01661079bc75358"
          }
        },
        "7d0057bd584744859e739e1a8e8c6f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc7a9f003e64909b82181f2b1ae72d0",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef41b8a338641fe85e0bcb426b5d725",
            "value": "added_tokens.json: 100%"
          }
        },
        "d9f029930ded4c31b8d6adc0bcf42c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e4c7c0c1b34e2abd33922df1dfd584",
            "max": 306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0328953cff5540628eb9957255a3e8e2",
            "value": 306
          }
        },
        "af8c8e80b1b14b5f8474004b82853ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8289f90b1a541419c826438a36cb836",
            "placeholder": "​",
            "style": "IPY_MODEL_d3f0800e263b4d988cb225e9f00e87d6",
            "value": " 306/306 [00:00&lt;00:00, 26.7kB/s]"
          }
        },
        "216feeb1b9204560b01661079bc75358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc7a9f003e64909b82181f2b1ae72d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef41b8a338641fe85e0bcb426b5d725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e4c7c0c1b34e2abd33922df1dfd584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0328953cff5540628eb9957255a3e8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8289f90b1a541419c826438a36cb836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3f0800e263b4d988cb225e9f00e87d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee7030df20d04f40a070578268fc4323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1ee564261ce45fcb934ac92f1ba98ac",
              "IPY_MODEL_fbcc333061b34c64b1486743dc52a2e4",
              "IPY_MODEL_684d3b3ef03e4379be723b51ab842a54"
            ],
            "layout": "IPY_MODEL_24fab24d4c524013a762dc08781b020f"
          }
        },
        "a1ee564261ce45fcb934ac92f1ba98ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c085845e48e74870b14094c8e197ebec",
            "placeholder": "​",
            "style": "IPY_MODEL_6810cc69749e4abea0a48728c2b61fce",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "fbcc333061b34c64b1486743dc52a2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d936fb175d0640ceabcf6637939fc915",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9c7996a10b14f4b83ca265de2e93737",
            "value": 665
          }
        },
        "684d3b3ef03e4379be723b51ab842a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750b5d8559444b12b8d04578433cd4c0",
            "placeholder": "​",
            "style": "IPY_MODEL_a5cfac77841245cb8d03f405fdfa5607",
            "value": " 665/665 [00:00&lt;00:00, 55.5kB/s]"
          }
        },
        "24fab24d4c524013a762dc08781b020f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c085845e48e74870b14094c8e197ebec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6810cc69749e4abea0a48728c2b61fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d936fb175d0640ceabcf6637939fc915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c7996a10b14f4b83ca265de2e93737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "750b5d8559444b12b8d04578433cd4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5cfac77841245cb8d03f405fdfa5607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}