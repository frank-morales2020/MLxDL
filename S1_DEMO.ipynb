{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN0SiKVtDLIHEHcf0hpbAkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/S1_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "EChP6rbDmrwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm -q\n",
        "!pip install huggingface_hub -q\n",
        "!pip install colab_env -q\n",
        "\n",
        "!pip uninstall -y pyzmq -q\n",
        "!pip install --no-cache-dir pyzmq -q\n",
        "!pip install --upgrade vllm -q\n",
        "\n",
        "!pip install --upgrade torch torchvision torchaudio -q\n",
        "!pip install --upgrade transformers -q\n",
        "!pip install accelerate -q\n",
        "!pip install -U flash-attn --no-build-isolation --quiet"
      ],
      "metadata": {
        "id": "McxboevW1tvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "GDWa-7n94ufc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import os\n",
        "\n",
        "# Pass the context to the LLM constructor\n",
        "llm = LLM(model=\"mistralai/Mistral-7B-Instruct-v0.2\", trust_remote_code=True, hf_token=access_token_write)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "h4yb3X545qHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"The capital of France is\",\n",
        "    \"Explain the theory of relativity in simple terms.\"\n",
        "]\n",
        "sampling_params = SamplingParams(max_tokens=50)\n",
        "\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "v_l_1HoK760z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n')\n",
        "for prompt, output in zip(prompts, outputs):\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Output: {output.outputs[0].text}\")\n",
        "    print(\"-\" * 20)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPquCYLGeFFu",
        "outputId": "7a52f17c-335f-46f7-9a25-4241f0442251"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--------------------\n",
            "Prompt: The capital of France is\n",
            "Output:  an exceptional city: Paris, the city of art and knowledge. Around 13 million tourists visit this part of Europe every year. Undoubtedly, Paris is the most popular city in the world, and it is not surprising, because it has everything\n",
            "--------------------\n",
            "\n",
            "\n",
            "--------------------\n",
            "Prompt: Explain the theory of relativity in simple terms.\n",
            "Output: \n",
            "\n",
            "The theory of relativity, proposed by Albert Einstein in the early 1900s, is a scientific explanation of how the physical world works at large scales and high speeds. It consists of two parts: the special theory of rel\n",
            "--------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irKJSBRh1l8v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from vllm import LLM, SamplingParams\n",
        "from transformers import AutoTokenizer\n",
        "device= device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Pass the context to the LLM constructor\n",
        "model = LLM(\n",
        "    \"simplescaling/s1.1-7B\",\n",
        "    tensor_parallel_size=1,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"simplescaling/s1-32B\")\n",
        "stop_token_ids = tok(\"<|im_end|>\")[\"input_ids\"]\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    max_tokens=32768,\n",
        "    min_tokens=0,\n",
        "    stop_token_ids=stop_token_ids,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Count all occurrences of the letter 'r' in the word \\\"raspberry.\\\"\"\n",
        "prompt = \"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant. Your task is to accurately count the number of times a specific letter appears in a given word.\\n<|im_end|>\\n<|im_start|>user\\n\" + prompt + \"<|im_end|>\\n<|im_start|>assistant\\n\"\n",
        "\n",
        "o = model.generate(prompt, sampling_params=sampling_params)"
      ],
      "metadata": {
        "id": "iQF_Sv7aCitb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(o[0].outputs[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073PNk--ml-g",
        "outputId": "341b8670-d2fb-4159-aaf0-6b6460515b64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "think\n",
            "Okay, so I need to count how many times the letter 'r' appears in the word \"raspberry.\" Let me try to think step by step. First, maybe I should write down the word and then go through each letter one by one, checking if it's an 'r'. The word is \"raspberry.\"\n",
            "\n",
            "Let me break it down:\n",
            "\n",
            "1. The first letter is 'r', so that's one 'r'.\n",
            "2. Next is 'a', no 'r'.\n",
            "3. 's' – nope.\n",
            "4. 'p' – not an 'r'.\n",
            "5. 'b' – also not.\n",
            "6. 'e' – nope.\n",
            "7. 'r' – another 'r'! That's two now.\n",
            "8. 'b' – no.\n",
            "9. 'e' – nothing.\n",
            "10. 'r' – there's a third 'r' at the end. So three 'r's?\n",
            "\n",
            "Wait, let me double-check. Let's list each letter again: r-a-s-p-b-e-r-r-y. Yes, so:\n",
            "\n",
            "First letter: r\n",
            "Third letter: r\n",
            "Last two letters: r and r\n",
            "\n",
            "So yeah, three 'r's. I think that’s correct. But maybe I should think of another way to ensure I didn't skip any. What if I count each occurrence? Or maybe use a different approach. Alternatively, perhaps use a systematic check.\n",
            "\n",
            "Breaking the word: \"raspberry\" into syllables or sounds: r-a-sp-berry. So in each part:\n",
            "\n",
            "r - a - sp - berry.\n",
            "\n",
            "So in the first syllable, \"r-a-sp,\" we have an 'r'. In the next, \"b-erry,\" there are two 'r's? Wait, no: second syllable is \"berry,\" which has two 'r's. So total: first syllable has one, then the second has two. So 1 + 2 = 3. Yes, that method gives me three 'r's.\n",
            "\n",
            "Alternatively, use fingers. No, maybe not. But mentally, I can try this: first 'r' is obvious. Then in the rest of the word, \"aspberry.\" Let's see: 'a' 's' 'p' 'b' 'e' 'r' 'r' 'y'. So in \"aspberry\", which is the remaining letters after the first 'r', we have another 'r' and then another. So that's two more. So yeah, seems like three. \n",
            "\n",
            "Alternatively, code. If I were programming, I could write a loop to iterate through each character and count the 'r's, but since I'm just doing it in my head, maybe that's overcomplicating. But the answer seems to be three. I should confirm.\n",
            "\n",
            "Wait, the word is \"raspberry.\" Let me try to spell it out again, counting each 'r':\n",
            "\n",
            "1. r\n",
            "2. a\n",
            "3. s\n",
            "4. p\n",
            "5. b\n",
            "6. e\n",
            "7. r\n",
            "8. b\n",
            "9. e\n",
            "10. r\n",
            "11. r\n",
            "12. y\n",
            "\n",
            "Yes, exactly. So indeed, the count is 3. Starting with 1 at the first letter, then adding when I see another 'r'. So total is 3.\n",
            "\n",
            "Just to check one last time, let me look for any other occurrences I might have missed. Another way: the word \"raspberry\" has three syllables. \"ras-p-by-erry.\" So in the breakdown \"ras-p-berry,\" 'ras' has an 'r', 'pby' has no 'r', 'berry' has two 'r's. So yes, total three. So it's confirmed.\n",
            "\n",
            "So the answer is 3. \n",
            "\n",
            "**Final Answer**\n",
            "The letter 'r' appears \\boxed{3} times in the word \"raspberry.\"\n",
            "answer\n",
            "Answer: To count the number of times the letter 'r' appears in the word \"raspberry,\" we can break down the word step by step:\n",
            "\n",
            "1. The first letter is 'r' (count: 1).\n",
            "2. Next letters are 'a', 's', 'p', 'b', 'e' (no additional 'r's).\n",
            "3. The following letters are 'r' (count: 2) and 'b' (no 'r').\n",
            "4. The final letters are 'e', 'r' (count: 3) and 'r' (count: 4), followed by 'y' (no 'r').\n",
            "\n",
            "Alternatively, breaking the word into syllables: \"ras-p-berry,\" we find:\n",
            "- \"ras\" has 1 'r'.\n",
            "- \"pberry\" has 2 'r's.\n",
            "\n",
            "Thus, the total number of 'r's is 3.\n",
            "\n",
            "\\boxed{3}\n"
          ]
        }
      ]
    }
  ]
}