{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOcAA8DeN/mu7mfqfPi4kOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/SEQ2SEQ_fptransformer_model_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "qmqWVXRvyxis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5t_DXaNbfVT",
        "outputId": "c4a7f85f-be97-41b9-a246-fdb59d5d36d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 16:29:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   77C    P0             36W /   72W |     905MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "import colab_env\n",
        "!pip install transformers datasets torch -q\n",
        "!pip install geopy -q"
      ],
      "metadata": {
        "id": "Qz47jn9NCcVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "-fTdYX3qGB7-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code covers the complete process of training, evaluation, and validation for a built-from-scratch Transformer model for waypoint coordinate prediction using a Sequence-to-Sequence (Seq2Seq) architecture.\n",
        "\n",
        "Here's a breakdown of how the code addresses each stage:\n",
        "\n",
        "1. Building the Model:\n",
        "\n",
        "* * It defines a custom Transformer model (Seq2SeqCoordsTransformer) with an encoder-decoder structure and attention mechanisms.\n",
        "\n",
        "* * It includes positional encoding to capture sequence order information.\n",
        "\n",
        "* * The output layer is designed to predict both waypoint coordinates and the waypoint count.\n",
        "\n",
        "2. Training:\n",
        "\n",
        "* * It uses a training loop to update the model's parameters using the training dataset.\n",
        "* * It employs an optimizer (AdamW) and a combined loss function (CombinedLossSeq2Seq) that considers both coordinate and count prediction errors.\n",
        "* * Data augmentation is applied during training to improve the model's robustness.\n",
        "\n",
        "3. Evaluation and Validation:\n",
        "\n",
        "* * The code splits the data into training, validation, and test sets.\n",
        "\n",
        "* * After each training epoch, the model is evaluated on the validation set to monitor its performance on unseen data.\n",
        "\n",
        "* * Early stopping is implemented to prevent overfitting and select the best-performing model.\n",
        "\n",
        "4. Inference and Testing:\n",
        "\n",
        "* * After training, the best model is loaded and used for inference on the test set.\n",
        "\n",
        "* * The code calculates various evaluation metrics, including average coordinate loss, count loss, and average absolute count difference, to assess the model's accuracy and generalization ability.\n",
        "\n",
        "In summary, the code provides a comprehensive implementation of a Seq2Seq Transformer model for flight plan waypoint prediction, including all the necessary steps for training, evaluation, validation, and testing. This suggests a well-structured and thorough approach to developing a model for this task."
      ],
      "metadata": {
        "id": "gCk0PHMDxn6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training - Seq2SeqCoordsTransformer"
      ],
      "metadata": {
        "id": "V059SaBgOyFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "# Ensure tqdm.notebook is used for interactive environments like Colab/Jupyter\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import traceback # For printing full tracebacks on error\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import torch.distributed as dist\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# ... (other configuration settings) ...\n",
        "world_size = torch.cuda.device_count()  # Get the number of available GPUs\n",
        "rank = int(os.environ.get('RANK', 0)) # Set RANK variable for environment like slurm\n",
        "print(f\"World size: {world_size}, Rank: {rank}\")\n",
        "if world_size > 1:\n",
        "    dist.init_process_group('nccl', rank=rank, world_size=world_size)\n",
        "    device = torch.device(f\"cuda:{rank}\")\n",
        "    print(f\"Process {rank} using device: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using single device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFCtzlgiyOOf",
        "outputId": "e884a23d-ed85-405f-d90a-c67e8f807691"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World size: 1, Rank: 0\n",
            "Using single device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL CODE (Seq2Seq Arch + Classification Count + Corrected count_loss_weight=100.0)\n",
        "# Includes: Seq2Seq, LR=1e-5, Coord Norm+Sigmoid, Learned SOS, isclose Mask,\n",
        "#           count_loss_weight=100.0, patience=10, Augmentation, CPU Debugging.\n",
        "# WARNING: hf_repo_id points to frankmorales2020/FlightPlan_Transformer_LLM.\n",
        "# Loading from this ID later will likely FAIL due to incompatible architecture.\n",
        "# ==============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "# Ensure tqdm.notebook is used for interactive environments like Colab/Jupyter\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import traceback # For printing full tracebacks on error\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import torch.distributed as dist\n",
        "\n",
        "# --- Hugging Face Hub Integration ---\n",
        "try:\n",
        "    from huggingface_hub import HfApi, HfFolder, login, create_repo, upload_file, notebook_login, hf_hub_download\n",
        "    access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "    # Suppressing login attempt messages\n",
        "except ImportError:\n",
        "    print(\"Warning: huggingface_hub not found. Deployment/loading features unavailable.\")\n",
        "    HfApi = None; hf_hub_download = None\n",
        "\n",
        "# --- Configuration ---\n",
        "hf_repo_id = \"frankmorales2020/FlightPlan_Transformer_LLM_1GPU_Colab\"  # Removed the ')'\n",
        "tokenizer_name = \"gpt2\"\n",
        "dataset_name = \"frankmorales2020/flight_plan_waypoints\"\n",
        "# Model Hyperparameters\n",
        "embedding_dimension = 256; nhead = 8; num_encoder_layers = 4; num_decoder_layers = 4\n",
        "dim_feedforward = 1024; transformer_dropout = 0.1\n",
        "# Training Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 1e-5 # Keeping reduced LR\n",
        "num_epochs = 20\n",
        "# >>> PARAMETER CORRECTION: Setting count weight to 100.0 <<<\n",
        "count_loss_weight = 0.5 # Increased significantly to improve count accuracy\n",
        "coordinate_pad_value = 0.0\n",
        "train_subset_size = None; eval_subset_size = None\n",
        "# Early Stopping Configuration\n",
        "early_stopping_patience = 10 # Keeping increased patience\n",
        "min_delta = 0.0001\n",
        "best_model_save_path = \"./best_seq2seq_model_clf_count.bin\"\n",
        "# Data Augmentation Config\n",
        "augment_training_data = True\n",
        "coord_noise_level = 0.01\n",
        "# Coordinate Scaling Params\n",
        "LAT_MIN, LAT_MAX = -90.0, 90.0; LON_MIN, LON_MAX = -180.0, 180.0\n",
        "COORD_EPSILON = 1e-6\n",
        "print(f\"Using Coord Scaling: Lat ({LAT_MIN}, {LAT_MAX}), Lon ({LON_MIN}, {LON_MAX})\")\n",
        "\n",
        "# --- Explicitly Setting max_waypoints ---\n",
        "max_waypoints = 10\n",
        "num_count_classes = max_waypoints + 1\n",
        "max_coord_seq_len = max_waypoints + 1\n",
        "max_text_seq_len = 128\n",
        "print(f\"Using max_waypoints: {max_waypoints} => Num Count Classes: {num_count_classes}\")\n",
        "print(f\"Max Decoder Seq Len: {max_coord_seq_len}\")\n",
        "\n",
        "\n",
        "# >>> FORCING CPU EXECUTION FOR DEBUGGING <<<\n",
        "#device = torch.device(\"cpu\")\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print(f\"*** RUNNING ON CPU FOR DEBUGGING ***\")\n",
        "#print('\\n\\n')\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# --- Tokenizer Setup ---\n",
        "print(f\"Loading tokenizer: {tokenizer_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "special_tokens_dict = {}\n",
        "if tokenizer.bos_token is None: special_tokens_dict['bos_token'] = '[SOS]'\n",
        "if tokenizer.eos_token is None: special_tokens_dict['eos_token'] = '[EOS]'\n",
        "if tokenizer.pad_token is None: special_tokens_dict['pad_token'] = '[PAD]'\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "if num_added_toks > 0: print(f\"Added {num_added_toks} special tokens: {special_tokens_dict}\")\n",
        "sos_token_id = tokenizer.bos_token_id; eos_token_id = tokenizer.eos_token_id; pad_token_id = tokenizer.pad_token_id\n",
        "vocab_size = len(tokenizer)\n",
        "print(f\"Tokenizer vocabulary size: {vocab_size}\")\n",
        "print(f\"SOS ID: {sos_token_id}, EOS ID: {eos_token_id}, PAD ID: {pad_token_id}\")\n",
        "print('\\n')\n",
        "\n",
        "# --- Load Dataset ---\n",
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "try: dataset = load_dataset(dataset_name); print(\"Dataset loaded.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR: Failed to load dataset '{dataset_name}'. Error: {e}\") from e\n",
        "\n",
        "\n",
        "# --- Coordinate Normalization / Denormalization ---\n",
        "PAD_COORD_NORM_LAT = max(0.0, min(1.0, (coordinate_pad_value - LAT_MIN) / (LAT_MAX - LAT_MIN + COORD_EPSILON)))\n",
        "PAD_COORD_NORM_LON = max(0.0, min(1.0, (coordinate_pad_value - LON_MIN) / (LON_MAX - LON_MIN + COORD_EPSILON)))\n",
        "PAD_COORD_NORM = [PAD_COORD_NORM_LAT, PAD_COORD_NORM_LON]\n",
        "print(f\"Using PAD_COORD_NORM: {PAD_COORD_NORM}\")\n",
        "print('\\n')\n",
        "\n",
        "def normalize_coords(coords_list):\n",
        "    normalized = []\n",
        "    for coords in coords_list:\n",
        "        lat, lon = coords[0], coords[1]\n",
        "        norm_lat = (lat - LAT_MIN) / (LAT_MAX - LAT_MIN + COORD_EPSILON)\n",
        "        norm_lon = (lon - LON_MIN) / (LON_MAX - LON_MIN + COORD_EPSILON)\n",
        "        norm_lat = max(0.0, min(1.0, norm_lat)); norm_lon = max(0.0, min(1.0, norm_lon))\n",
        "        normalized.append([norm_lat, norm_lon])\n",
        "    return normalized\n",
        "\n",
        "def denormalize_coords(norm_coords_list):\n",
        "    denormalized = []\n",
        "    for norm_coords in norm_coords_list:\n",
        "        norm_lat, norm_lon = norm_coords[0], norm_coords[1]\n",
        "        if abs(norm_lat - PAD_COORD_NORM[0]) < COORD_EPSILON and abs(norm_lon - PAD_COORD_NORM[1]) < COORD_EPSILON: lat, lon = coordinate_pad_value, coordinate_pad_value\n",
        "        else: lat = norm_lat * (LAT_MAX - LAT_MIN + COORD_EPSILON) + LAT_MIN; lon = norm_lon * (LON_MAX - LON_MIN + COORD_EPSILON) + LON_MIN\n",
        "        denormalized.append([lat, lon])\n",
        "    return denormalized\n",
        "\n",
        "# --- Data Preprocessing Function (Seq2Seq, Norm, Correct SOS/EOS Handling v2) ---\n",
        "print(\"Defining data preprocessing function...\")\n",
        "def preprocess_seq2seq_data(examples, is_training=False):\n",
        "    # Returns integer target_count\n",
        "    if \"input\" not in examples or \"waypoints\" not in examples or \"label\" not in examples: return {\"input_ids\": [], \"attention_mask\": [], \"decoder_input_coords_norm\": [], \"target_coords_output_norm\": [], \"target_count\": [], \"coord_mask\": []}\n",
        "    encoder_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=max_text_seq_len)\n",
        "    input_ids = encoder_inputs[\"input_ids\"]; attention_mask = encoder_inputs[\"attention_mask\"]\n",
        "    decoder_input_batch_norm, target_output_batch_norm, target_counts_batch, coord_masks_batch = [], [], [], []\n",
        "    waypoints_list = examples[\"waypoints\"] if isinstance(examples[\"waypoints\"], list) else []; labels_list = examples[\"label\"] if isinstance(examples[\"label\"], list) else []\n",
        "    min_len = min(len(waypoints_list), len(labels_list))\n",
        "\n",
        "    for i in range(min_len):\n",
        "        waypoints, label = waypoints_list[i], labels_list[i]\n",
        "        try:\n",
        "            if isinstance(waypoints, list) and all(isinstance(wp, (list, tuple)) and len(wp) == 2 for wp in waypoints): waypoints_float = [[float(lat), float(lon)] for lat, lon in waypoints]\n",
        "            else: raise TypeError(\"Waypoints format incorrect\")\n",
        "        except (ValueError, TypeError, IndexError): waypoints_float = []\n",
        "\n",
        "        if is_training and augment_training_data and waypoints_float:\n",
        "            augmented_waypoints = []\n",
        "            for lat, lon in waypoints_float: noise_lat=random.uniform(-coord_noise_level,coord_noise_level); noise_lon=random.uniform(-coord_noise_level,coord_noise_level); augmented_waypoints.append([lat+noise_lat,lon+noise_lon])\n",
        "            coords_processed = augmented_waypoints\n",
        "        else: coords_processed = waypoints_float\n",
        "\n",
        "        coords_truncated = coords_processed[:max_waypoints]; num_actual_waypoints = len(coords_truncated)\n",
        "        coords_normalized = normalize_coords(coords_truncated)\n",
        "        decoder_input_seq_norm = coords_normalized\n",
        "        target_output_seq_norm = coords_normalized + [PAD_COORD_NORM]\n",
        "        decoder_input_padding_len = max_waypoints - len(decoder_input_seq_norm); decoder_input_seq_norm.extend([PAD_COORD_NORM] * decoder_input_padding_len)\n",
        "        target_output_padding_len = max_coord_seq_len - len(target_output_seq_norm); target_output_seq_norm.extend([PAD_COORD_NORM] * target_output_padding_len)\n",
        "        coord_mask = [1.0] * (num_actual_waypoints + 1) + [0.0] * target_output_padding_len\n",
        "\n",
        "        decoder_input_batch_norm.append(decoder_input_seq_norm)\n",
        "        target_output_batch_norm.append(target_output_seq_norm)\n",
        "        coord_masks_batch.append(coord_mask)\n",
        "        try:\n",
        "            count_label = int(round(float(label))); count_label = max(0, min(max_waypoints, count_label))\n",
        "            target_counts_batch.append(count_label)\n",
        "        except (ValueError, TypeError): target_counts_batch.append(0)\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"decoder_input_coords_norm\": decoder_input_batch_norm, \"target_coords_output_norm\": target_output_batch_norm, \"target_count\": target_counts_batch, \"coord_mask\": coord_masks_batch}\n",
        "\n",
        "\n",
        "# --- Apply Preprocessing and Split ---\n",
        "print(\"Applying preprocessing (with augmentation for training set)...\")\n",
        "columns_to_remove_post_preprocess = [\"distance\", \"distance_category\", \"waypoint_names\"]\n",
        "columns_to_remove_train_val = ['input', 'waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "columns_to_remove_test = ['waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "print('\\n')\n",
        "try:\n",
        "    train_testvalid_original = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "    test_valid_original = train_testvalid_original['test'].train_test_split(test_size=0.5, seed=42)\n",
        "    processed_train = train_testvalid_original['train'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=True), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_validation = test_valid_original['test'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=False), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_test_for_loss = test_valid_original['train'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=False), batched=True, remove_columns=['input', 'waypoints', 'label'] + columns_to_remove_test)\n",
        "    original_test_set_for_comparison = test_valid_original['train']\n",
        "    processed_train.set_format(\"torch\"); processed_validation.set_format(\"torch\"); processed_test_for_loss.set_format(\"torch\")\n",
        "    print(\"Preprocessing complete.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR during preprocessing: {e}\") from e\n",
        "\n",
        "# Select data for training/evaluation/testing\n",
        "train_data = processed_train.shuffle(seed=42).select(range(min(train_subset_size, len(processed_train)))) if train_subset_size else processed_train\n",
        "eval_data = processed_validation.shuffle(seed=42).select(range(min(eval_subset_size, len(processed_validation)))) if eval_subset_size else processed_validation\n",
        "test_data_processed_for_loss = processed_test_for_loss\n",
        "print(f\"Using Train: {len(train_data)}, Validation: {len(eval_data)}, Test (for loss): {len(test_data_processed_for_loss)} samples.\")\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# --- Data Loaders ---\n",
        "print(\"Creating DataLoaders...\")\n",
        "try:\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    eval_dataloader = DataLoader(eval_data, batch_size=batch_size, drop_last=False)\n",
        "    test_dataloader_for_loss = DataLoader(test_data_processed_for_loss, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "    print(f\"Loaders created (Train/Eval/Test batches): {len(train_dataloader)} / {len(eval_dataloader)} / {len(test_dataloader_for_loss)}\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR creating DataLoaders: {e}\") from e\n",
        "\n",
        "# --- Positional Encoding ---\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__(); self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1); div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model); pe[:, 0::2] = torch.sin(position * div_term); pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x): x = x + self.pe[:x.size(1), :].unsqueeze(0); return self.dropout(x)\n",
        "\n",
        "# --- Model Definition (Encoder-Decoder Transformer with Classification Count Head) ---\n",
        "print(\"Defining the Seq2SeqCoordsTransformer model (Classification Count Head)...\")\n",
        "print('\\n')\n",
        "class Seq2SeqCoordsTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int, emb_size: int, nhead: int, src_vocab_size: int, num_count_classes: int, tgt_coord_dim: int = 2, dim_feedforward: int = 512, dropout: float = 0.1, max_text_len: int = 128, max_coord_len: int = 12):\n",
        "        super().__init__(); self.emb_size = emb_size; self.max_coord_len = max_coord_len\n",
        "        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size); self.pos_encoder_enc = PositionalEncoding(emb_size, dropout, max_len=max_text_len); self.pos_encoder_dec = PositionalEncoding(emb_size, dropout, max_len=max_coord_len)\n",
        "        self.coord_input_proj = nn.Linear(tgt_coord_dim, emb_size); self.coord_output_proj = nn.Linear(emb_size, tgt_coord_dim)\n",
        "        self.sos_embedding = nn.Parameter(torch.randn(1, 1, emb_size) * 0.02)\n",
        "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
        "        self.encoder_pooler = lambda x: x.mean(dim=1)\n",
        "        self.count_head = nn.Linear(emb_size, num_count_classes) # Classification head\n",
        "        self._reset_parameters()\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "    def forward(self, src_input_ids: torch.Tensor, tgt_input_coords_norm: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor, src_padding_mask: torch.Tensor, tgt_padding_mask: torch.Tensor, memory_key_padding_mask: torch.Tensor):\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_padding_mask); pooled_encoder_output = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_encoder_output) # Output logits\n",
        "        batch_size = tgt_input_coords_norm.size(0)\n",
        "        coord_vals_emb = self.coord_input_proj(tgt_input_coords_norm); sos_emb_batch = self.sos_embedding.repeat(batch_size, 1, 1)\n",
        "        tgt_emb = torch.cat([sos_emb_batch, coord_vals_emb], dim=1); tgt_emb = self.pos_encoder_dec(tgt_emb)\n",
        "        decoder_output = self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "        projected_coords = self.coord_output_proj(decoder_output); predicted_coords_normalized = torch.sigmoid(projected_coords)\n",
        "        return predicted_coords_normalized, predicted_count_logits # Return logits\n",
        "\n",
        "    def encode(self, src_input_ids: torch.Tensor, src_mask: torch.Tensor): # src_mask is padding mask\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_mask); pooled_memory = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_memory); return memory, predicted_count_logits # Return logits\n",
        "\n",
        "# --- Utility Functions for Seq2Seq ---\n",
        "def generate_square_subsequent_mask(sz, device): return torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n",
        "def create_mask(src_input_ids, target_output_norm, pad_idx, device): # Use target output shape for target mask dims\n",
        "    src_seq_len = src_input_ids.shape[1]; tgt_seq_len = target_output_norm.shape[1]\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "    src_padding_mask = (src_input_ids == pad_idx)\n",
        "    pad_tensor = torch.tensor(PAD_COORD_NORM, device=device).unsqueeze(0).unsqueeze(0)\n",
        "    tgt_padding_mask = torch.all(torch.isclose(target_output_norm, pad_tensor), dim=-1) # Check against normalized pad\n",
        "    memory_key_padding_mask = src_padding_mask\n",
        "    return tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask\n",
        "\n",
        "# --- Loss Function Definition (Classification Count Loss) ---\n",
        "print(\"Defining the CombinedLoss function (Classification Count Loss)...\")\n",
        "print('\\n')\n",
        "class CombinedLossSeq2Seq(nn.Module):\n",
        "    def __init__(self, count_loss_weight=100.0): # Using 100.0 now\n",
        "        super().__init__(); self.coord_loss_fn = nn.MSELoss(reduction='none')\n",
        "        self.count_loss_fn = nn.CrossEntropyLoss() # Using CrossEntropy\n",
        "        self.count_loss_weight = count_loss_weight\n",
        "    def forward(self, predicted_coords_norm, predicted_count_logits, target_coords_output_norm, target_count_labels, coord_mask):\n",
        "        # predicted_count_logits: (N, num_classes), target_count_labels: (N,) LongTensor\n",
        "        effective_coord_mask = coord_mask.unsqueeze(-1).expand_as(predicted_coords_norm)\n",
        "        coord_loss_elementwise = self.coord_loss_fn(predicted_coords_norm, target_coords_output_norm)\n",
        "        masked_coord_loss = coord_loss_elementwise * effective_coord_mask\n",
        "        num_actual_elements = effective_coord_mask.sum(); mean_coord_loss = masked_coord_loss.sum() / num_actual_elements if num_actual_elements > 0 else torch.tensor(0.0, device=predicted_coords_norm.device)\n",
        "        # Ensure labels are long and clamped\n",
        "        target_count_labels = target_count_labels.long().clamp(0, predicted_count_logits.size(1) - 1)\n",
        "        count_loss = self.count_loss_fn(predicted_count_logits, target_count_labels) # CrossEntropy loss calculation\n",
        "        total_loss = mean_coord_loss + self.count_loss_weight * count_loss\n",
        "        if not torch.isfinite(total_loss): total_loss = torch.tensor(0.0, requires_grad=True, device=predicted_coords_norm.device); mean_coord_loss = torch.tensor(0.0); count_loss = torch.tensor(0.0)\n",
        "        return total_loss, mean_coord_loss, count_loss # Return CE loss for count\n",
        "\n",
        "# --- Instantiate Model, Loss, Optimizer ---\n",
        "print(\"Instantiating Seq2Seq model (Classification Count), loss function, and optimizer...\")\n",
        "model = Seq2SeqCoordsTransformer(num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, emb_size=embedding_dimension, nhead=nhead, src_vocab_size=vocab_size, num_count_classes=num_count_classes, tgt_coord_dim=2, dim_feedforward=dim_feedforward, dropout=transformer_dropout, max_text_len=max_text_seq_len, max_coord_len=max_coord_seq_len)\n",
        "\n",
        "if world_size > 1:\n",
        "    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = CombinedLossSeq2Seq(count_loss_weight=count_loss_weight) # Passes 100.0\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model.to(device)\n",
        "model.src_tok_emb = nn.Embedding(vocab_size, embedding_dimension).to(device)\n",
        "print(f\"Model moved to: {device}. Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "print('\\n')\n",
        "\n",
        "# --- Training Loop with Early Stopping (Classification Count) ---\n",
        "print(f\"Starting training for up to {num_epochs} epochs with Early Stopping (patience={early_stopping_patience}) on CPU...\")\n",
        "training_stats = []\n",
        "best_eval_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "epoch_iterator = tqdm(range(num_epochs), desc=\"Overall Training Progress\")\n",
        "for epoch in epoch_iterator:\n",
        "    model.train()\n",
        "    batch_iterator_train = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "    for batch in batch_iterator_train:\n",
        "        try:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device)\n",
        "            target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "            target_cnt_labels = batch['target_count'].long().to(device) # Target is LONG type\n",
        "            output_coord_mask = batch['coord_mask'].float().to(device)\n",
        "            tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device) # Use target shape for mask\n",
        "            optimizer.zero_grad()\n",
        "            predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "            loss, coord_loss_norm, count_loss = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask) # Pass logits/labels\n",
        "            if torch.isfinite(loss) and loss > 0:\n",
        "                loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0); optimizer.step()\n",
        "                batch_iterator_train.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord_N': f\"{coord_loss_norm.item():.4f}\", 'count_CE': f\"{count_loss.item():.4f}\"}) # Use count_CE\n",
        "        except Exception as e: print(f\"\\nERROR training batch: {e}\\n{traceback.format_exc()}\"); continue\n",
        "\n",
        "    # --- Evaluation Phase ---\n",
        "    model.eval()\n",
        "    eval_losses, eval_coord_losses_norm, eval_count_losses = [], [], []\n",
        "    batch_iterator_eval = tqdm(eval_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Evaluation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in batch_iterator_eval:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device)\n",
        "                target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "                target_cnt_labels = batch['target_count'].long().to(device) # Target is LONG type\n",
        "                output_coord_mask = batch['coord_mask'].float().to(device)\n",
        "                tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device)\n",
        "                predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "                loss, coord_loss_norm, count_loss = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask) # Pass logits/labels\n",
        "                if torch.isfinite(loss): eval_losses.append(loss.item()); eval_coord_losses_norm.append(coord_loss_norm.item()); eval_count_losses.append(count_loss.item())\n",
        "                batch_iterator_eval.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord_N': f\"{coord_loss_norm.item():.4f}\", 'count_CE': f\"{count_loss.item():.4f}\"}) # Use count_CE\n",
        "            except Exception as e: print(f\"\\nERROR eval batch: {e}\\n{traceback.format_exc()}\"); continue\n",
        "\n",
        "    avg_eval_loss = np.mean(eval_losses) if eval_losses else float('inf')\n",
        "    avg_eval_coord_loss_norm = np.mean(eval_coord_losses_norm) if eval_coord_losses_norm else float('inf')\n",
        "    avg_eval_count_loss = np.mean(eval_count_losses) if eval_count_losses else float('inf') # Avg CrossEntropy loss\n",
        "    print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} Eval Summary ---\")\n",
        "    print(f\"  Avg Eval Loss: {avg_eval_loss:.4f} (CoordNorm: {avg_eval_coord_loss_norm:.4f}, CountCE: {avg_eval_count_loss:.4f})\") # Use CountCE\n",
        "    training_stats.append({'epoch': epoch + 1, 'eval_loss': avg_eval_loss, 'eval_coord_loss_norm': avg_eval_coord_loss_norm, 'eval_count_loss_ce': avg_eval_count_loss}) # Use count_CE\n",
        "    epoch_iterator.set_postfix({'Avg Eval Loss': f\"{avg_eval_loss:.4f}\", 'Avg CoordNorm Loss': f\"{avg_eval_coord_loss_norm:.4f}\", 'Avg CountCE Loss': f\"{avg_eval_count_loss:.4f}\"}) # Use CountCE\n",
        "\n",
        "    # --- Early Stopping Check ---\n",
        "    if avg_eval_loss < best_eval_loss - min_delta:\n",
        "        best_eval_loss = avg_eval_loss; epochs_no_improve = 0\n",
        "        try: torch.save(model.state_dict(), best_model_save_path); print(f\"  New best model saved (Eval Loss: {best_eval_loss:.4f})\")\n",
        "        except Exception as e: print(f\"  ERROR saving best model: {e}\")\n",
        "    else:\n",
        "        epochs_no_improve += 1; print(f\"  No improvement in eval loss for {epochs_no_improve} epoch(s).\")\n",
        "    if epochs_no_improve >= early_stopping_patience:\n",
        "        print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs ---\"); break\n",
        "\n",
        "print(\"\\n--- Training loop finished ---\")\n",
        "print(f\"Best validation loss achieved: {best_eval_loss:.4f}\")\n",
        "print('\\n')\n",
        "\n",
        "# --- Load the best model state before saving/deploying ---\n",
        "print(f\"\\nLoading best model state from {best_model_save_path} for final steps...\")\n",
        "try:\n",
        "    if os.path.exists(best_model_save_path): state_dict = torch.load(best_model_save_path, map_location=device); model.load_state_dict(state_dict); print(\"Loaded best model weights.\")\n",
        "    else: print(f\"Warning: Best model checkpoint not found. Using state from last epoch.\")\n",
        "except Exception as e: print(f\"ERROR loading best model state: {e}. Using state from last epoch.\")\n",
        "\n",
        "# --- Saving the model Locally ---\n",
        "print(\"\\nSaving best model locally...\")\n",
        "model_save_path = \"./flight_plan_seq2seq_clf_model_final\" # New path name\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "try:\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, \"pytorch_model.bin\"))\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    config_to_save = {\"vocab_size\": vocab_size, \"emb_size\": embedding_dimension, \"nhead\": nhead, \"num_encoder_layers\": num_encoder_layers, \"num_decoder_layers\": num_decoder_layers, \"dim_feedforward\": dim_feedforward, \"dropout\": transformer_dropout, \"max_text_len\": max_text_seq_len, \"max_coord_len\": max_coord_seq_len, \"max_waypoints\": max_waypoints,\n",
        "                      \"num_count_classes\": num_count_classes, # Save num classes info\n",
        "                      \"architecture\": model.__class__.__name__}\n",
        "    with open(os.path.join(model_save_path, \"config.json\"), \"w\") as f: json.dump(config_to_save, f, indent=4)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "except Exception as e: print(f\"ERROR saving model locally: {e}\")\n",
        "\n",
        "# --- Deployment to Hugging Face Hub ---\n",
        "print(f\"\\n--- Attempting Deployment of Best Model to Hugging Face Hub: {hf_repo_id} ---\")\n",
        "# WARNING: This will overwrite the target repo ID with the new Seq2Seq model!\n",
        "if HfApi and hf_hub_download:\n",
        "    try:\n",
        "        print(f\"Creating/accessing repository '{hf_repo_id}'...\")\n",
        "        create_repo(hf_repo_id, private=False, exist_ok=True)\n",
        "        api = HfApi()\n",
        "        # --- README Generation (Updated for Classification Count) ---\n",
        "        print(\"Generating README.md content...\")\n",
        "        readme_content = f\"\"\"---\n",
        "license: apache-2.0\n",
        "tags:\n",
        "  - flight-planning\n",
        "  - transformer\n",
        "  - coordinate-prediction\n",
        "  - sequence-to-sequence\n",
        "  - count-classification\n",
        "---\n",
        "# Flight Plan Coordinate Prediction Model ({model.__class__.__name__})\n",
        "Encoder-Decoder Transformer model trained for AI flight planning project. Predicts normalized coordinates directly and waypoint count via classification.\n",
        "## Model Description\n",
        "{model.__class__.__name__} architecture using `torch.nn.Transformer`. Predicts normalized lat/lon coordinates autoregressively and waypoint count (0-{max_waypoints}) via classification head on encoder output.\n",
        "* Embed Dim: {embedding_dimension}, Heads: {nhead}, Enc Layers: {num_encoder_layers}, Dec Layers: {num_decoder_layers}, Max Waypoints: {max_waypoints}\n",
        "## Intended Use\n",
        "Research prototype. **Not for real-world navigation.**\n",
        "## Limitations\n",
        "Accuracy depends on data/tuning. Fixed max waypoints ({max_waypoints}). Not certified. **Architecture differs significantly from previous versions in this repo.**\n",
        "## How to Use\n",
        "Requires loading the custom `{model.__class__.__name__}` class and weights. Generation requires autoregressive decoding and taking argmax of count logits.\n",
        "## Training Data\n",
        "Trained on `{dataset_name}` - https://huggingface.co/datasets/frankmorales2020/flight_plan_waypoints.\n",
        "## Contact\n",
        "Frank Morales, BEng, MEng, SMIEEE (Boeing ATF) - https://www.linkedin.com/in/frank-morales1964/\"\"\"\n",
        "        try:\n",
        "            with open(\"README.md\", \"w\", encoding=\"utf-8\") as f: f.write(readme_content)\n",
        "            print(\"Uploading README.md...\"); api.upload_file(path_or_fileobj=\"README.md\", path_in_repo=\"README.md\", repo_id=hf_repo_id, repo_type=\"model\", commit_message=\"Update README (Seq2Seq Clf Count)\"); os.remove(\"README.md\"); print(\"README.md uploaded.\")\n",
        "        except Exception as e: print(f\"ERROR creating/uploading README.md: {e}\")\n",
        "\n",
        "        print(f\"Uploading model files from {model_save_path}...\")\n",
        "        api.upload_folder(folder_path=model_save_path, repo_id=hf_repo_id, repo_type=\"model\", commit_message=f\"Upload trained {model.__class__.__name__} (Seq2Seq, Clf Count)\")\n",
        "        print(f\"Model files uploaded: https://huggingface.co/{hf_repo_id}\")\n",
        "    except Exception as e: print(f\"ERROR deploying to HF Hub: {e}\")\n",
        "else: print(\"Skipping deployment: huggingface_hub library/login unavailable.\")\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "iaNzLIDZdtIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Coord Scaling: Lat (-90.0, 90.0), Lon (-180.0, 180.0)\n",
        "Using max_waypoints: 10 => Num Count Classes: 11\n",
        "Max Decoder Seq Len: 11\n",
        "Loading tokenizer: gpt2\n",
        "Added 1 special tokens: {'pad_token': '[PAD]'}\n",
        "Tokenizer vocabulary size: 50258\n",
        "SOS ID: 50256, EOS ID: 50256, PAD ID: 50257\n",
        "\n",
        "\n",
        "Loading dataset: frankmorales2020/flight_plan_waypoints\n",
        "Dataset loaded.\n",
        "Using PAD_COORD_NORM: [0.49999999722222227, 0.4999999986111111]\n",
        "\n",
        "\n",
        "Defining data preprocessing function...\n",
        "Applying preprocessing (with augmentation for training set)...\n",
        "\n",
        "\n",
        "Map: 100%\n",
        " 200/200 [00:00<00:00, 4845.77 examples/s]\n",
        "Preprocessing complete.\n",
        "Using Train: 1600, Validation: 200, Test (for loss): 200 samples.\n",
        "\n",
        "\n",
        "Creating DataLoaders...\n",
        "Loaders created (Train/Eval/Test batches): 100 / 13 / 13\n",
        "Defining the Seq2SeqCoordsTransformer model (Classification Count Head)...\n",
        "\n",
        "\n",
        "Defining the CombinedLoss function (Classification Count Loss)...\n",
        "\n",
        "\n",
        "Instantiating Seq2Seq model (Classification Count), loss function, and optimizer...\n",
        "Model moved to: cuda. Parameters: 20,244,237\n",
        "\n",
        "\n",
        "Starting training for up to 20 epochs with Early Stopping (patience=10) on CPU...\n",
        "Overall Training Progress: 100%\n",
        " 20/20 [01:35<00:00,  4.75s/it, Avg Eval Loss=0.9785, Avg CoordNorm Loss=0.0170, Avg CountCE Loss=1.9230]\n",
        "\n",
        "--- Epoch 1/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.1007 (CoordNorm: 0.0222, CountCE: 2.1571)\n",
        "  New best model saved (Eval Loss: 1.1007)\n",
        "\n",
        "--- Epoch 2/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.1003 (CoordNorm: 0.0221, CountCE: 2.1564)\n",
        "  New best model saved (Eval Loss: 1.1003)\n",
        "\n",
        "--- Epoch 3/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0853 (CoordNorm: 0.0215, CountCE: 2.1276)\n",
        "  New best model saved (Eval Loss: 1.0853)\n",
        "\n",
        "--- Epoch 4/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0790 (CoordNorm: 0.0216, CountCE: 2.1147)\n",
        "  New best model saved (Eval Loss: 1.0790)\n",
        "\n",
        "--- Epoch 5/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0780 (CoordNorm: 0.0209, CountCE: 2.1141)\n",
        "  New best model saved (Eval Loss: 1.0780)\n",
        "\n",
        "--- Epoch 6/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0649 (CoordNorm: 0.0209, CountCE: 2.0880)\n",
        "  New best model saved (Eval Loss: 1.0649)\n",
        "\n",
        "--- Epoch 7/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0502 (CoordNorm: 0.0203, CountCE: 2.0598)\n",
        "  New best model saved (Eval Loss: 1.0502)\n",
        "\n",
        "--- Epoch 8/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0443 (CoordNorm: 0.0204, CountCE: 2.0480)\n",
        "  New best model saved (Eval Loss: 1.0443)\n",
        "\n",
        "--- Epoch 9/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0308 (CoordNorm: 0.0189, CountCE: 2.0239)\n",
        "  New best model saved (Eval Loss: 1.0308)\n",
        "\n",
        "--- Epoch 10/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0245 (CoordNorm: 0.0191, CountCE: 2.0107)\n",
        "  New best model saved (Eval Loss: 1.0245)\n",
        "\n",
        "--- Epoch 11/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0196 (CoordNorm: 0.0180, CountCE: 2.0032)\n",
        "  New best model saved (Eval Loss: 1.0196)\n",
        "\n",
        "--- Epoch 12/20 Eval Summary ---\n",
        "  Avg Eval Loss: 1.0165 (CoordNorm: 0.0196, CountCE: 1.9939)\n",
        "  New best model saved (Eval Loss: 1.0165)\n",
        "\n",
        "--- Epoch 13/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9984 (CoordNorm: 0.0180, CountCE: 1.9609)\n",
        "  New best model saved (Eval Loss: 0.9984)\n",
        "\n",
        "--- Epoch 14/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9899 (CoordNorm: 0.0181, CountCE: 1.9437)\n",
        "  New best model saved (Eval Loss: 0.9899)\n",
        "\n",
        "--- Epoch 15/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9968 (CoordNorm: 0.0175, CountCE: 1.9587)\n",
        "  No improvement in eval loss for 1 epoch(s).\n",
        "\n",
        "--- Epoch 16/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9980 (CoordNorm: 0.0192, CountCE: 1.9576)\n",
        "  No improvement in eval loss for 2 epoch(s).\n",
        "\n",
        "--- Epoch 17/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9875 (CoordNorm: 0.0165, CountCE: 1.9420)\n",
        "  New best model saved (Eval Loss: 0.9875)\n",
        "\n",
        "--- Epoch 18/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9863 (CoordNorm: 0.0162, CountCE: 1.9402)\n",
        "  New best model saved (Eval Loss: 0.9863)\n",
        "\n",
        "--- Epoch 19/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9842 (CoordNorm: 0.0168, CountCE: 1.9349)\n",
        "  New best model saved (Eval Loss: 0.9842)\n",
        "\n",
        "--- Epoch 20/20 Eval Summary ---\n",
        "  Avg Eval Loss: 0.9785 (CoordNorm: 0.0170, CountCE: 1.9230)\n",
        "  New best model saved (Eval Loss: 0.9785)\n",
        "\n",
        "--- Training loop finished ---\n",
        "Best validation loss achieved: 0.9785\n",
        "\n",
        "\n",
        "\n",
        "Loading best model state from ./best_seq2seq_model_clf_count.bin for final steps...\n",
        "Loaded best model weights.\n",
        "\n",
        "Saving best model locally...\n",
        "Model saved to ./flight_plan_seq2seq_clf_model_final\n",
        "\n",
        "--- Attempting Deployment of Best Model to Hugging Face Hub: frankmorales2020/FlightPlan_Transformer_LLM_1GPU_Colab ---\n",
        "Creating/accessing repository 'frankmorales2020/FlightPlan_Transformer_LLM_1GPU_Colab'...\n",
        "Generating README.md content...\n",
        "Uploading README.md...\n",
        "README.md uploaded.\n",
        "Uploading model files from ./flight_plan_seq2seq_clf_model_final...\n",
        "pytorch_model.bin: 100%\n",
        " 81.2M/81.2M [00:09<00:00, 7.33MB/s]\n",
        "Model files uploaded: https://huggingface.co/frankmorales2020/FlightPlan_Transformer_LLM_1GPU_Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ueje-ckZdsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation - Seq2SeqCoordsTransformer"
      ],
      "metadata": {
        "id": "ctH2mbLikx4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore')\n",
        "\n",
        "# --- Model Loading and Test Set Evaluation (Refactored for Seq2Seq Clf Count) ---\n",
        "print(\"\\n--- Loading Model and Evaluating on Test Set ---\")\n",
        "print('\\n')\n",
        "\n",
        "# --- Generation Function (Updated for Classification Count Head) ---\n",
        "def generate_flight_plan_seq2seq(trained_model, tokenizer_instance, query_text, device_instance, max_len=max_coord_seq_len):\n",
        "    trained_model.eval(); trained_model.to(device_instance)\n",
        "    try:\n",
        "        inputs = tokenizer_instance(query_text, return_tensors='pt', padding='longest', truncation=True, max_length=max_text_seq_len)\n",
        "        src_input_ids = inputs['input_ids'].to(device_instance); src_padding_mask = (src_input_ids == pad_token_id)\n",
        "        with torch.no_grad():\n",
        "            # >>> FIX: Encode now returns logits <<<\n",
        "            memory, predicted_count_logits = trained_model.encode(src_input_ids, src_padding_mask)\n",
        "            # >>> FIX: Get predicted count index from logits <<<\n",
        "            pred_count_index = torch.argmax(predicted_count_logits, dim=1).item() # This is the predicted count (0 to max_waypoints)\n",
        "\n",
        "        # Start decoding with SOS embedding\n",
        "        decoder_input_embeddings = trained_model.sos_embedding.repeat(1, 1, 1) # (N=1, 1, E)\n",
        "        generated_denorm_coords_list = []\n",
        "\n",
        "        for step in range(max_waypoints): # Generate up to max_waypoints coordinates\n",
        "            current_tgt_len = decoder_input_embeddings.size(1)\n",
        "            tgt_mask = generate_square_subsequent_mask(current_tgt_len, device_instance) # (T, T)\n",
        "            memory_key_padding_mask = src_padding_mask # (N, S)\n",
        "            tgt_padding_mask = torch.zeros(1, current_tgt_len, dtype=torch.bool, device=device_instance) # (N, T)\n",
        "\n",
        "            tgt_emb_with_pe = trained_model.pos_encoder_dec(decoder_input_embeddings) # (N, T, E)\n",
        "            decoder_output = trained_model.transformer.decoder(tgt_emb_with_pe, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "            predicted_norm_coord_next = torch.sigmoid(trained_model.coord_output_proj(decoder_output[:, -1:, :])) # (1, 1, 2) Normalized\n",
        "\n",
        "            # Denormalize prediction to store\n",
        "            #predicted_denorm_coord_next = denormalize_coords(predicted_norm_coord_next.squeeze(0).cpu().numpy().tolist())\n",
        "            predicted_denorm_coord_next = denormalize_coords(predicted_norm_coord_next.detach().squeeze(0).cpu().numpy().tolist())\n",
        "            new_denorm_coord_value = predicted_denorm_coord_next[0]\n",
        "            if isinstance(new_denorm_coord_value, list) and len(new_denorm_coord_value) == 2: generated_denorm_coords_list.append(new_denorm_coord_value)\n",
        "            else: print(f\"Warning: Invalid denorm coord predicted: {new_denorm_coord_value}\"); break\n",
        "\n",
        "            # Prepare next input embedding\n",
        "            next_input_emb = trained_model.coord_input_proj(predicted_norm_coord_next) # Project normalized prediction\n",
        "            decoder_input_embeddings = torch.cat([decoder_input_embeddings, next_input_emb], dim=1)\n",
        "\n",
        "            # Stop if we've generated the predicted number of points\n",
        "            if len(generated_denorm_coords_list) >= pred_count_index: break\n",
        "\n",
        "        final_waypoints = generated_denorm_coords_list\n",
        "        # Return the predicted count index (which is the count) and raw logits if needed\n",
        "        return final_waypoints, pred_count_index, predicted_count_logits.squeeze().cpu().numpy() # Return index and logits\n",
        "\n",
        "    except Exception as e: print(f\"ERROR generating for query '{query_text}': {e}\\n{traceback.format_exc()}\"); return [], 0, np.array([])\n",
        "\n",
        "\n",
        "# --- Load the model ---\n",
        "load_from_hf = False # Defaulting to False\n",
        "model_load_id = hf_repo_id if load_from_hf else model_save_path\n",
        "loaded_model = None; loaded_tokenizer = None\n",
        "print(f\"Attempting to load Seq2Seq model from: {model_load_id} (Using {'HF Hub' if load_from_hf else 'Local Path'})\")\n",
        "print('\\n')\n",
        "#print(device)\n",
        "\n",
        "\n",
        "if hf_hub_download:\n",
        "    try:\n",
        "        if load_from_hf:\n",
        "             if \"YOUR_USERNAME\" in model_load_id or model_load_id == \"frankmorales2020/FlightPlan_Transformer_LLM\": raise ValueError(f\"Refusing to load potentially incompatible model from '{model_load_id}'. Update hf_repo_id or set load_from_hf=False.\")\n",
        "             tokenizer_load_path = model_load_id; config_load_path = hf_hub_download(repo_id=model_load_id, filename=\"config.json\"); weights_load_path = hf_hub_download(repo_id=model_load_id, filename=\"pytorch_model.bin\")\n",
        "        else: # Loading from local\n",
        "             tokenizer_load_path = model_save_path; config_load_path = os.path.join(model_save_path, \"config.json\"); weights_load_path = best_model_save_path\n",
        "             if not os.path.exists(weights_load_path): print(f\"Warning: Best model file {weights_load_path} not found, trying final...\"); weights_load_path = os.path.join(model_save_path, \"pytorch_model.bin\")\n",
        "             if not all(os.path.exists(p) for p in [config_load_path, weights_load_path, os.path.join(tokenizer_load_path, 'tokenizer_config.json')]): raise FileNotFoundError(f\"Required model files not found locally.\")\n",
        "\n",
        "        loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_load_path)\n",
        "        with open(config_load_path, 'r') as f: config_dict = json.load(f)\n",
        "        expected_arch = \"Seq2SeqCoordsTransformer\"; loaded_arch = config_dict.get(\"architecture\")\n",
        "        if loaded_arch != expected_arch: print(f\"\\n>>> WARNING: Config architecture ('{loaded_arch}') != Expected ('{expected_arch}'). Ensure correct model type is loaded. <<<\\n\")\n",
        "\n",
        "        # Use loaded config values, providing defaults\n",
        "        loaded_model = Seq2SeqCoordsTransformer(\n",
        "            num_encoder_layers=config_dict.get('num_encoder_layers', num_encoder_layers),\n",
        "            num_decoder_layers=config_dict.get('num_decoder_layers', num_decoder_layers),\n",
        "            emb_size=config_dict.get('emb_size', embedding_dimension),\n",
        "            nhead=config_dict.get('nhead', nhead),\n",
        "            src_vocab_size=len(loaded_tokenizer),\n",
        "            # Get num_count_classes from config\n",
        "            num_count_classes=config_dict.get('num_count_classes', num_count_classes),\n",
        "            tgt_coord_dim=2,\n",
        "            dim_feedforward=config_dict.get('dim_feedforward', dim_feedforward),\n",
        "            dropout=config_dict.get('dropout', transformer_dropout),\n",
        "            max_text_len=config_dict.get('max_text_len', max_text_seq_len),\n",
        "            max_coord_len=config_dict.get('max_coord_len', max_coord_seq_len)\n",
        "        )\n",
        "        loaded_model.to(device)\n",
        "\n",
        "        state_dict = torch.load(weights_load_path, map_location=device)\n",
        "        # Handle embedding resize AFTER model instantiation and moving to device\n",
        "        current_tokenizer_vocab_size = len(loaded_tokenizer)\n",
        "        if state_dict.get('src_tok_emb.weight') is not None and state_dict['src_tok_emb.weight'].size(0) != current_tokenizer_vocab_size:\n",
        "            print(f\"Resizing embedding weights from {state_dict['src_tok_emb.weight'].size(0)} to {current_tokenizer_vocab_size}\")\n",
        "            loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "            new_emb = loaded_model.src_tok_emb.weight.data\n",
        "            common_size = min(state_dict['src_tok_emb.weight'].size(0), new_emb.size(0))\n",
        "            new_emb[:common_size, :] = state_dict['src_tok_emb.weight'][:common_size, :]\n",
        "            state_dict['src_tok_emb.weight'] = new_emb\n",
        "        elif 'src_tok_emb.weight' not in state_dict:\n",
        "             print(\"Warning: src_tok_emb.weight not found in state_dict. Initializing embedding layer.\")\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "        else: # Ensure model's embedding layer matches state dict if no resize needed\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "\n",
        "        # Load state dict - use strict=False due to potential architecture changes or saved optimizer states\n",
        "        load_result = loaded_model.load_state_dict(state_dict, strict=False)\n",
        "        print(f\"Model load result (strict=False): Missing keys: {load_result.missing_keys}, Unexpected keys: {load_result.unexpected_keys}\")\n",
        "        loaded_model.eval(); print(\"Model loading successful.\")\n",
        "\n",
        "    except Exception as e: print(f\"\\n>>> ERROR loading model from {model_load_id}: {e}\\n{traceback.format_exc()}\"); loaded_model = None\n",
        "else: print(\"Skipping model loading: huggingface_hub library not available.\")\n",
        "\n",
        "\n",
        "# --- Run Inference Loop and Calculate Loss on Test Set (Classification Count) ---\n",
        "if loaded_model and loaded_tokenizer:\n",
        "    print(\"\\nRunning inference and loss calculation on the test set using Seq2Seq model...\")\n",
        "    test_results = []\n",
        "    test_iterator_batches = tqdm(test_dataloader_for_loss, desc=\"Processing Test Set Batches for Loss\")\n",
        "    #test_iterator_batches = tqdm(train_dataloader, desc=\"Processing Train Set Batches for Loss\")\n",
        "\n",
        "\n",
        "    #train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    #eval_dataloader = DataLoader(eval_data, batch_size=batch_size, drop_last=False)\n",
        "    #test_dataloader_for_loss = DataLoader(test_data_processed_for_loss, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "    total_test_samples_loss = 0\n",
        "    test_coord_losses_norm = []\n",
        "    test_count_losses_ce = []\n",
        "\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator_batches:\n",
        "            try:\n",
        "\n",
        "                # Get predictions\n",
        "                tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device)\n",
        "                predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "                # Calculate loss using logits and labels\n",
        "                loss, coord_loss_norm, count_loss_ce = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask)\n",
        "\n",
        "                # Accumulate losses\n",
        "                if torch.isfinite(coord_loss_norm):\n",
        "                    test_coord_losses_norm.append(coord_loss_norm.item() * input_ids.size(0))\n",
        "                if torch.isfinite(count_loss_ce):\n",
        "                    test_count_losses_ce.append(count_loss_ce.item() * input_ids.size(0))\n",
        "                total_test_samples_loss += input_ids.size(0)\n",
        "\n",
        "                # Display progress\n",
        "                test_iterator_batches.set_postfix({'batch_coord_norm_loss': f\"{coord_loss_norm.item():.4f}\", 'batch_count_CE_loss': f\"{count_loss_ce.item():.4f}\"})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nERROR processing test batch for loss: {e}\")\n",
        "                continue\n",
        "\n",
        "    # --- Loop for Generation Metrics ---\n",
        "    print(\"\\nCalculating generation metrics on test samples...\")\n",
        "    original_test_set_for_gen = original_test_set_for_comparison\n",
        "    test_iterator_samples = tqdm(range(len(original_test_set_for_gen)), desc=\"Generating Test Samples\")\n",
        "    total_count_diff_gen = 0\n",
        "    total_test_samples_gen = len(original_test_set_for_gen)\n",
        "    count_correct = 0  # Track number of perfectly predicted counts\n",
        "\n",
        "    for i in test_iterator_samples:\n",
        "        try:\n",
        "            sample = original_test_set_for_gen[i]\n",
        "            query = sample.get('input', '')\n",
        "            actual_waypoints_raw = sample.get('waypoints', [])\n",
        "\n",
        "            # Handle waypoints (convert to list if necessary)\n",
        "            if isinstance(actual_waypoints_raw, np.ndarray):\n",
        "                actual_waypoints = actual_waypoints_raw.tolist()\n",
        "            elif isinstance(actual_waypoints_raw, list):\n",
        "                actual_waypoints = actual_waypoints_raw\n",
        "            else:\n",
        "                actual_waypoints = []\n",
        "\n",
        "            # Get actual count label (handle errors)\n",
        "            try:\n",
        "                actual_count_label = int(round(float(sample.get('label', 0))))\n",
        "                actual_count_label = max(0, min(max_waypoints, actual_count_label))\n",
        "            except (ValueError, TypeError):\n",
        "                actual_count_label = 0\n",
        "\n",
        "            # Skip empty queries\n",
        "            if not query:\n",
        "                total_test_samples_gen -= 1\n",
        "                continue\n",
        "\n",
        "            # Generate flight plan and calculate count difference\n",
        "            pred_waypoints, pred_count_index, pred_count_logits = generate_flight_plan_seq2seq(loaded_model, loaded_tokenizer, query, device)\n",
        "            count_diff = abs(pred_count_index - actual_count_label)\n",
        "            total_count_diff_gen += count_diff\n",
        "\n",
        "            #print(\"\\n--- Generated Flight Plan ---\")\n",
        "            #print(f\"Query: {query}\")\n",
        "            #print(f\"Predicted Waypoints: {pred_waypoints}\")\n",
        "            #print(f\"Actual Waypoints: {actual_waypoints}\")\n",
        "            #print(f\"Predicted Count: {pred_count_index}\")\n",
        "            #print(f\"Actual Count: {actual_count_label}\")\n",
        "            #print('\\n')\n",
        "\n",
        "            # Check count accuracy\n",
        "            if pred_count_index == actual_count_label:\n",
        "                count_correct += 1\n",
        "\n",
        "            # Store results\n",
        "            test_results.append({'query': query, 'predicted_waypoints': pred_waypoints, 'predicted_count': pred_count_index, 'actual_count': actual_count_label})\n",
        "\n",
        "            # Display progress\n",
        "            test_iterator_samples.set_postfix({'avg_count_diff': f\"{total_count_diff_gen / (i + 1):.2f}\"})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR generating for test sample {i}: {e}\")\n",
        "            total_test_samples_gen -= 1\n",
        "            continue\n",
        "\n",
        "    # --- Calculate and Print Overall Metrics ---\n",
        "    avg_test_coord_loss_norm = np.sum(test_coord_losses_norm) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_loss_ce = np.sum(test_count_losses_ce) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_difference = total_count_diff_gen / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "    test_count_accuracy = count_correct / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Final Test Set Evaluation Summary ---\")\n",
        "    print(f\"  Average Absolute Count Difference: {avg_test_count_difference:.4f}\")\n",
        "    print(f\"  Count Prediction Accuracy:         {test_count_accuracy:.4f}\")\n",
        "    print(f\"  Average Coordinate Loss (MSE, Normalized): {avg_test_coord_loss_norm:.4f}\")\n",
        "    print(f\"  Average Count Loss (CrossEntropy):       {avg_test_count_loss_ce:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping test set evaluation: model/tokenizer loading failed or unavailable.\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "7TM5Ossnk0if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "--- Loading Model and Evaluating on Test Set ---\n",
        "\n",
        "\n",
        "Attempting to load Seq2Seq model from: ./flight_plan_seq2seq_clf_model_final (Using Local Path)\n",
        "\n",
        "\n",
        "Model load result (strict=False): Missing keys: [], Unexpected keys: []\n",
        "Model loading successful.\n",
        "\n",
        "Running inference and loss calculation on the test set using Seq2Seq model...\n",
        "Processing Test Set Batches for Loss: 100%\n",
        " 13/13 [00:00<00:00, 51.48it/s, batch_coord_norm_loss=0.0169, batch_count_CE_loss=1.9580]\n",
        "\n",
        "Calculating generation metrics on test samples...\n",
        "Generating Test Samples: 100%\n",
        " 200/200 [00:08<00:00, 24.10it/s, avg_count_diff=1.35]\n",
        "\n",
        "--- Final Test Set Evaluation Summary ---\n",
        "  Average Absolute Count Difference: 1.3550\n",
        "  Count Prediction Accuracy:         0.1800\n",
        "  Average Coordinate Loss (MSE, Normalized): 0.0169\n",
        "  Average Count Loss (CrossEntropy):       1.9580\n",
        "\n",
        "--- Script Finished ---"
      ],
      "metadata": {
        "id": "u6rAcIaAZnfq"
      }
    }
  ]
}