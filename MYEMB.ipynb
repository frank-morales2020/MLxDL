{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/wEi1PN11IIdIhfiM1txk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MYEMB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST Digit Recognition"
      ],
      "metadata": {
        "id": "v55kGS8REZyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Load MNIST test dataset\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the ImageEBM with mixed activations\n",
        "class ImageEBM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEBM, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.fc1 = nn.Linear(8 * 28 * 28, 10)\n",
        "        self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn1(self.conv1(x)))  # ReLU after convolution\n",
        "        x = x.view(-1, 8 * 28 * 28)\n",
        "        x = torch.sigmoid(self.fc1(x))  # Sigmoid in fully connected layer\n",
        "        energy = self.fc2(x)\n",
        "        return energy\n",
        "\n",
        "# Initialize the EBM, optimizer, and learning rate scheduler\n",
        "model = ImageEBM()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Training loop with reduced energy regularization\n",
        "num_epochs = 5\n",
        "alpha = 0.1  # Reduced regularization strength\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        energy = model(data)\n",
        "\n",
        "        # Add energy regularization to the loss\n",
        "        loss = torch.mean(energy) + alpha * torch.mean(torch.relu(-energy))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    scheduler.step()  # Update learning rate\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            energy = model(data)\n",
        "            test_loss += torch.mean(energy).item()  # Sum up batch loss\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    #print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XiU23XyvOjY",
        "outputId": "4ee8a377-33ce-4eb8-bf7d-24a7be013062"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [1/938], Loss: 0.4417\n",
            "Epoch [1/5], Batch [101/938], Loss: -0.3597\n",
            "Epoch [1/5], Batch [201/938], Loss: -0.4088\n",
            "Epoch [1/5], Batch [301/938], Loss: -0.4551\n",
            "Epoch [1/5], Batch [401/938], Loss: -0.5005\n",
            "Epoch [1/5], Batch [501/938], Loss: -0.5460\n",
            "Epoch [1/5], Batch [601/938], Loss: -0.5912\n",
            "Epoch [1/5], Batch [701/938], Loss: -0.6365\n",
            "Epoch [1/5], Batch [801/938], Loss: -0.6816\n",
            "Epoch [1/5], Batch [901/938], Loss: -0.7267\n",
            "Epoch [2/5], Batch [1/938], Loss: -0.7439\n",
            "Epoch [2/5], Batch [101/938], Loss: -0.7890\n",
            "Epoch [2/5], Batch [201/938], Loss: -0.8341\n",
            "Epoch [2/5], Batch [301/938], Loss: -0.8791\n",
            "Epoch [2/5], Batch [401/938], Loss: -0.9242\n",
            "Epoch [2/5], Batch [501/938], Loss: -0.9692\n",
            "Epoch [2/5], Batch [601/938], Loss: -1.0143\n",
            "Epoch [2/5], Batch [701/938], Loss: -1.0593\n",
            "Epoch [2/5], Batch [801/938], Loss: -1.1044\n",
            "Epoch [2/5], Batch [901/938], Loss: -1.1494\n",
            "Epoch [3/5], Batch [1/938], Loss: -1.1665\n",
            "Epoch [3/5], Batch [101/938], Loss: -1.2115\n",
            "Epoch [3/5], Batch [201/938], Loss: -1.2566\n",
            "Epoch [3/5], Batch [301/938], Loss: -1.3016\n",
            "Epoch [3/5], Batch [401/938], Loss: -1.3466\n",
            "Epoch [3/5], Batch [501/938], Loss: -1.3916\n",
            "Epoch [3/5], Batch [601/938], Loss: -1.4366\n",
            "Epoch [3/5], Batch [701/938], Loss: -1.4816\n",
            "Epoch [3/5], Batch [801/938], Loss: -1.5267\n",
            "Epoch [3/5], Batch [901/938], Loss: -1.5717\n",
            "Epoch [4/5], Batch [1/938], Loss: -1.5888\n",
            "Epoch [4/5], Batch [101/938], Loss: -1.6338\n",
            "Epoch [4/5], Batch [201/938], Loss: -1.6788\n",
            "Epoch [4/5], Batch [301/938], Loss: -1.7238\n",
            "Epoch [4/5], Batch [401/938], Loss: -1.7688\n",
            "Epoch [4/5], Batch [501/938], Loss: -1.8138\n",
            "Epoch [4/5], Batch [601/938], Loss: -1.8588\n",
            "Epoch [4/5], Batch [701/938], Loss: -1.9038\n",
            "Epoch [4/5], Batch [801/938], Loss: -1.9488\n",
            "Epoch [4/5], Batch [901/938], Loss: -1.9938\n",
            "Epoch [5/5], Batch [1/938], Loss: -2.0109\n",
            "Epoch [5/5], Batch [101/938], Loss: -2.0559\n",
            "Epoch [5/5], Batch [201/938], Loss: -2.1009\n",
            "Epoch [5/5], Batch [301/938], Loss: -2.1459\n",
            "Epoch [5/5], Batch [401/938], Loss: -2.1909\n",
            "Epoch [5/5], Batch [501/938], Loss: -2.2359\n",
            "Epoch [5/5], Batch [601/938], Loss: -2.2810\n",
            "Epoch [5/5], Batch [701/938], Loss: -2.3260\n",
            "Epoch [5/5], Batch [801/938], Loss: -2.3710\n",
            "Epoch [5/5], Batch [901/938], Loss: -2.4160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST test dataset\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            energy = model(data)\n",
        "            test_loss += torch.mean(energy).item()  # Sum up batch loss\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Eval Loss: {test_loss:.4f}\")\n",
        "\n",
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrkfus8a35qD",
        "outputId": "4b228e37-9e6c-4324-a25d-732da0b8b4a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: -3.1242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR-10 Image Classification"
      ],
      "metadata": {
        "id": "-_VmeqWUEm5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the ImageEBM for CIFAR-10 (color images)\n",
        "class ImageEBM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEBM, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # Input channels = 3 for color\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)  # Adjust input size for CIFAR-10\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn1(self.conv1(x)))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = torch.relu(self.bn2(self.conv2(x)))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 32 * 8 * 8)  # Adjust size for CIFAR-10\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        energy = self.fc2(x)\n",
        "        return energy\n",
        "\n",
        "# Initialize the EBM, optimizer, and learning rate scheduler\n",
        "model = ImageEBM()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Training loop with energy regularization\n",
        "num_epochs = 5  # You might need more epochs for CIFAR-10\n",
        "alpha = 0.1\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        energy = model(data)\n",
        "\n",
        "        # Add energy regularization to the loss\n",
        "        loss = torch.mean(energy) + alpha * torch.mean(torch.relu(-energy))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    scheduler.step()  # Update learning rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaXsg-yI5MJU",
        "outputId": "9fa1f325-f57d-4403-d7ff-44c98d8b05d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/5], Batch [1/782], Loss: -0.3356\n",
            "Epoch [1/5], Batch [101/782], Loss: -3.6440\n",
            "Epoch [1/5], Batch [201/782], Loss: -4.3777\n",
            "Epoch [1/5], Batch [301/782], Loss: -5.0892\n",
            "Epoch [1/5], Batch [401/782], Loss: -5.8079\n",
            "Epoch [1/5], Batch [501/782], Loss: -6.5292\n",
            "Epoch [1/5], Batch [601/782], Loss: -7.2430\n",
            "Epoch [1/5], Batch [701/782], Loss: -7.9535\n",
            "Epoch [2/5], Batch [1/782], Loss: -8.5346\n",
            "Epoch [2/5], Batch [101/782], Loss: -9.2422\n",
            "Epoch [2/5], Batch [201/782], Loss: -9.9488\n",
            "Epoch [2/5], Batch [301/782], Loss: -10.6550\n",
            "Epoch [2/5], Batch [401/782], Loss: -11.3972\n",
            "Epoch [2/5], Batch [501/782], Loss: -12.1229\n",
            "Epoch [2/5], Batch [601/782], Loss: -12.8440\n",
            "Epoch [2/5], Batch [701/782], Loss: -13.5626\n",
            "Epoch [3/5], Batch [1/782], Loss: -14.1661\n",
            "Epoch [3/5], Batch [101/782], Loss: -14.9152\n",
            "Epoch [3/5], Batch [201/782], Loss: -15.6515\n",
            "Epoch [3/5], Batch [301/782], Loss: -16.4029\n",
            "Epoch [3/5], Batch [401/782], Loss: -17.1639\n",
            "Epoch [3/5], Batch [501/782], Loss: -17.9122\n",
            "Epoch [3/5], Batch [601/782], Loss: -18.6556\n",
            "Epoch [3/5], Batch [701/782], Loss: -19.3960\n",
            "Epoch [4/5], Batch [1/782], Loss: -20.0016\n",
            "Epoch [4/5], Batch [101/782], Loss: -20.7388\n",
            "Epoch [4/5], Batch [201/782], Loss: -21.4747\n",
            "Epoch [4/5], Batch [301/782], Loss: -22.2097\n",
            "Epoch [4/5], Batch [401/782], Loss: -22.9438\n",
            "Epoch [4/5], Batch [501/782], Loss: -23.6773\n",
            "Epoch [4/5], Batch [601/782], Loss: -24.4102\n",
            "Epoch [4/5], Batch [701/782], Loss: -25.1426\n",
            "Epoch [5/5], Batch [1/782], Loss: -25.7429\n",
            "Epoch [5/5], Batch [101/782], Loss: -26.4747\n",
            "Epoch [5/5], Batch [201/782], Loss: -27.2061\n",
            "Epoch [5/5], Batch [301/782], Loss: -27.9372\n",
            "Epoch [5/5], Batch [401/782], Loss: -28.6682\n",
            "Epoch [5/5], Batch [501/782], Loss: -29.3989\n",
            "Epoch [5/5], Batch [601/782], Loss: -30.1295\n",
            "Epoch [5/5], Batch [701/782], Loss: -30.8599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## eval for CIFAR-10"
      ],
      "metadata": {
        "id": "dkCpZcGV58B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            energy = model(data)\n",
        "            test_loss += torch.mean(energy).item()  # Sum up batch loss\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Eval Loss: {test_loss:.4f}\")\n",
        "\n",
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRWXRN7752QM",
        "outputId": "38b8c492-41cf-4038-eae8-dd2306437dea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Eval Loss: -34.9541\n"
          ]
        }
      ]
    }
  ]
}