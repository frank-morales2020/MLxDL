{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Copy_of_rag_fusion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a58112-8a18-49ad-9c8c-2088778613d0",
      "metadata": {
        "id": "41a58112-8a18-49ad-9c8c-2088778613d0"
      },
      "source": [
        "# RAG Fusion Query Pipeline\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/run-llama/llama-hub/blob/main/llama_hub/llama_packs/query/rag_fusion_pipeline/rag_fusion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook shows how to implement RAG Fusion using the LlamaIndex Query Pipeline syntax."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5bdbf5-d525-42e2-ab4a-19234c023491",
      "metadata": {
        "id": "8c5bdbf5-d525-42e2-ab4a-19234c023491"
      },
      "source": [
        "## Setup / Load Data\n",
        "\n",
        "We load in the pg_essay.txt data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b91e78-d733-44dd-b9a2-7c6eab3aee3d",
      "metadata": {
        "id": "20b91e78-d733-44dd-b9a2-7c6eab3aee3d"
      },
      "outputs": [],
      "source": [
        "#added by Frank Morales(FM) 11/01/2024\n",
        "%pip install openai  --root-user-action=ignore\n",
        "!pip install llama_index phoenix pyvis network\n",
        "!pip install llama_hub\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "\n",
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt' -O pg_essay.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1785ffb1-5fc2-4855-854a-238003ff848b",
      "metadata": {
        "id": "1785ffb1-5fc2-4855-854a-238003ff848b"
      },
      "outputs": [],
      "source": [
        "#%pip install openai --root-user-action=ignore\n",
        "\n",
        "import openai\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=[\"pg_essay.txt\"])\n",
        "docs = reader.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3bc7134-a34b-41de-b7e6-c85a6e356b56",
      "metadata": {
        "id": "e3bc7134-a34b-41de-b7e6-c85a6e356b56"
      },
      "source": [
        "### [Optional] Setup Tracing\n",
        "\n",
        "We also setup tracing through Arize Phoenix to look at our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d32462fb-07e0-4e5d-871c-98a782363330",
      "metadata": {
        "id": "d32462fb-07e0-4e5d-871c-98a782363330"
      },
      "outputs": [],
      "source": [
        "#import phoenix as px\n",
        "\n",
        "#px.launch_app()\n",
        "#import llama_index\n",
        "\n",
        "#llama_index.set_global_handler(\"arize_phoenix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c9299c-06d6-4710-afb0-3cc13761f358",
      "metadata": {
        "id": "a7c9299c-06d6-4710-afb0-3cc13761f358"
      },
      "source": [
        "## Setup Llama Pack\n",
        "\n",
        "Next we download the LlamaPack. All the code is in the downloaded directory - we encourage you to take a look to see the QueryPipeline syntax!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f5143a5f-7cd3-4aac-99e7-a357f3239f03",
      "metadata": {
        "id": "f5143a5f-7cd3-4aac-99e7-a357f3239f03"
      },
      "outputs": [],
      "source": [
        "# Option 1: Use `download_llama_pack`\n",
        "# from llama_index.llama_pack import download_llama_pack\n",
        "\n",
        "# RAGFusionPipelinePack = download_llama_pack(\n",
        "#     \"RAGFusionPipelinePack\",\n",
        "#     \"./rag_fusion_pipeline_pack\",\n",
        "#     # leave the below line commented out if using the notebook on main\n",
        "#     # llama_hub_url=\"https://raw.githubusercontent.com/run-llama/llama-hub/jerry/add_query_pipeline_pack/llama_hub\"\n",
        "# )\n",
        "\n",
        "# Option 2: Import from llama_hub package\n",
        "from llama_hub.llama_packs.query.rag_fusion_pipeline.base import RAGFusionPipelinePack\n",
        "\n",
        "\n",
        "from llama_index.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e4786b6-6add-4caf-9f9c-c2d8f455702a",
      "metadata": {
        "id": "1e4786b6-6add-4caf-9f9c-c2d8f455702a"
      },
      "outputs": [],
      "source": [
        "pack = RAGFusionPipelinePack(docs, llm=OpenAI(model=\"gpt-3.5-turbo\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a84473-0b2f-4649-be8e-7a603f526f02",
      "metadata": {
        "id": "b0a84473-0b2f-4649-be8e-7a603f526f02"
      },
      "source": [
        "## Inspecting the Code\n",
        "\n",
        "If we take a look at how it's setup (in your downloaded directory, you'll see the following code using our QueryPipeline syntax).\n",
        "\n",
        "`retrievers` is a dictionary mapping a chunk size to retrievers (chunk sizes: 128, 256, 512, 1024).\n",
        "\n",
        "```python\n",
        "# construct query pipeline\n",
        "p = QueryPipeline()\n",
        "module_dict = {\n",
        "    **self.retrievers,\n",
        "    \"input\": InputComponent(),\n",
        "    \"summarizer\": TreeSummarize(),\n",
        "    # NOTE: Join args\n",
        "    \"join\": ArgPackComponent(),\n",
        "    \"reranker\": rerank_component,\n",
        "}\n",
        "p.add_modules(module_dict)\n",
        "# add links from input to retriever (id'ed by chunk_size)\n",
        "for chunk_size in self.chunk_sizes:\n",
        "    p.add_link(\"input\", str(chunk_size))\n",
        "    p.add_link(str(chunk_size), \"join\", dest_key=str(chunk_size))\n",
        "p.add_link(\"join\", \"reranker\")\n",
        "p.add_link(\"input\", \"summarizer\", dest_key=\"query_str\")\n",
        "p.add_link(\"reranker\", \"summarizer\", dest_key=\"nodes\")\n",
        "```\n",
        "\n",
        "We visualize the DAG below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34143d87-163f-4246-8ee5-15940d17c629",
      "metadata": {
        "id": "34143d87-163f-4246-8ee5-15940d17c629",
        "outputId": "3ae924c9-4434-487b-db81-14d4b6360f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rag_dag.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e1be72c97b0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"rag_dag.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(pack.query_pipeline.dag)\n",
        "net.show(\"rag_dag.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "065ef0c4-0c9e-4611-8de4-98b2a7fe3094",
      "metadata": {
        "id": "065ef0c4-0c9e-4611-8de4-98b2a7fe3094",
        "outputId": "6a256f3a-f789-4a47-c072-732862f89756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What did the author do growing up?\n",
            "The author worked on writing and programming growing up. They wrote short stories and tried writing programs on an IBM 1401 computer.\n",
            "\n",
            "\n",
            "Who is the President of the USA?\n",
            "I'm sorry, but I cannot answer that question based on the given context information.\n",
            "\n",
            "\n",
            "Who won the baseball World Series in 2020? and Who Lost\n",
            "I'm sorry, but I cannot answer that query based on the given context information.\n",
            "\n",
            "\n",
            "Anything about LIPS\n",
            "Lisp is a programming language that was originally intended as a formal model of computation, an alternative to the Turing machine. It was invented by John McCarthy and later became a programming language in the ordinary sense. Lisp has a core that is defined by writing an interpreter in itself. McCarthy's original Lisp interpreter could only interpret Lisp expressions and lacked many features of a programming language. Over time, these features were added, but not using McCarthy's original axiomatic approach. Lisp has a power and elegance that other languages couldn't match, which attracted the author in college. The author worked on developing a new Lisp called Bel, which was written in Arc, a dialect of Lisp. It took the author four years to complete this project.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#modify By FM 11/01/2024\n",
        "\n",
        "#response = pack.run(query=\"What did the author do growing up?\")\n",
        "query0=\"What did the author do growing up?\"\n",
        "query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query1 = \"Who is the President of the USA?\"\n",
        "query2 = \"Who won the baseball World Series in 2020? and Who Lost\"\n",
        "query3 = 'Anything about FORTRAN'\n",
        "query4 = 'Anything about LIPS'\n",
        "query5 = 'Anything about Python'\n",
        "\n",
        "response0 = pack.run(query=query0)\n",
        "response1 = pack.run(query=query1)\n",
        "response2 = pack.run(query=query2)\n",
        "response4 = pack.run(query=query4)\n",
        "\n",
        "print()\n",
        "print(query0)\n",
        "print(str(response0))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query1)\n",
        "print(str(response1))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query2)\n",
        "print(str(response2))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query4)\n",
        "print(str(response4))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ea4ef382-fd11-4a82-8f5d-b2c53a21c665",
      "metadata": {
        "id": "ea4ef382-fd11-4a82-8f5d-b2c53a21c665"
      },
      "outputs": [],
      "source": [
        "#response.source_nodes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_hub",
      "language": "python",
      "name": "llama_hub"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}