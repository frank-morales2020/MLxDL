{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Copy_of_rag_fusion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a58112-8a18-49ad-9c8c-2088778613d0",
      "metadata": {
        "id": "41a58112-8a18-49ad-9c8c-2088778613d0"
      },
      "source": [
        "# RAG Fusion Query Pipeline\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/run-llama/llama-hub/blob/main/llama_hub/llama_packs/query/rag_fusion_pipeline/rag_fusion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook shows how to implement RAG Fusion using the LlamaIndex Query Pipeline syntax."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5bdbf5-d525-42e2-ab4a-19234c023491",
      "metadata": {
        "id": "8c5bdbf5-d525-42e2-ab4a-19234c023491"
      },
      "source": [
        "## Setup / Load Data\n",
        "\n",
        "We load in the pg_essay.txt data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "20b91e78-d733-44dd-b9a2-7c6eab3aee3d",
      "metadata": {
        "id": "20b91e78-d733-44dd-b9a2-7c6eab3aee3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593f5066-f4aa-4145-ed50-04d93af31132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.9.29)\n",
            "Requirement already satisfied: phoenix in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pyvis in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: network in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.26.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.8)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.2)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama_index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (3.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama_index) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index) (1.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Requirement already satisfied: llama_hub in /usr/local/lib/python3.10/dist-packages (0.0.69)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (from llama_hub) (2020.1.16)\n",
            "Requirement already satisfied: llama-index>=0.9.29 in /usr/local/lib/python3.10/dist-packages (from llama_hub) (0.9.29)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama_hub) (5.9.5)\n",
            "Requirement already satisfied: pyaml<24.0.0,>=23.9.7 in /usr/local/lib/python3.10/dist-packages (from llama_hub) (23.12.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from llama_hub) (1.3.4)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (0.26.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (1.5.8)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.29->llama_hub) (0.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml<24.0.0,>=23.9.7->llama_hub) (6.0.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->llama_hub) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.29->llama_hub) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index>=0.9.29->llama_hub) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index>=0.9.29->llama_hub) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.29->llama_hub) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.29->llama_hub) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.29->llama_hub) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.29->llama_hub) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.29->llama_hub) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index>=0.9.29->llama_hub) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.29->llama_hub) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.29->llama_hub) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index>=0.9.29->llama_hub) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index>=0.9.29->llama_hub) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index>=0.9.29->llama_hub) (3.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index>=0.9.29->llama_hub) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index>=0.9.29->llama_hub) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index>=0.9.29->llama_hub) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index>=0.9.29->llama_hub) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index>=0.9.29->llama_hub) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index>=0.9.29->llama_hub) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index>=0.9.29->llama_hub) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index>=0.9.29->llama_hub) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index>=0.9.29->llama_hub) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index>=0.9.29->llama_hub) (23.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "--2024-01-11 12:36:57--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75042 (73K) [text/plain]\n",
            "Saving to: ‘pg_essay.txt’\n",
            "\n",
            "pg_essay.txt        100%[===================>]  73.28K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-11 12:36:58 (38.5 MB/s) - ‘pg_essay.txt’ saved [75042/75042]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#added by Frank Morales(FM) 11/01/2024\n",
        "%pip install openai  --root-user-action=ignore\n",
        "!pip install llama_index phoenix pyvis network\n",
        "!pip install llama_hub\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "!pip install accelerate\n",
        "#!pip install typing_extensions\n",
        "\n",
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt' -O pg_essay.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1785ffb1-5fc2-4855-854a-238003ff848b",
      "metadata": {
        "id": "1785ffb1-5fc2-4855-854a-238003ff848b"
      },
      "outputs": [],
      "source": [
        "#%pip install openai --root-user-action=ignore\n",
        "\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=[\"pg_essay.txt\"])\n",
        "docs = reader.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pseZJ2Z2BlH",
        "outputId": "ae202dbe-7f82-4ec9-df5a-5455c0f2f09c"
      },
      "id": "9pseZJ2Z2BlH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "\n",
        "loader = TextLoader(\"/content/pg_essay.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs0 = text_splitter.split_documents(documents)\n",
        "\n",
        "collection_name0 = \"pg_essay\"\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs0)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyLRNSCwS91R",
        "outputId": "6f128424-c8a7-4f62-a036-278bd996f57d"
      },
      "id": "hyLRNSCwS91R",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1004, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1203, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1025, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Document Pages 1\n",
            "# of Document Chunks: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3bc7134-a34b-41de-b7e6-c85a6e356b56",
      "metadata": {
        "id": "e3bc7134-a34b-41de-b7e6-c85a6e356b56"
      },
      "source": [
        "### [Optional] Setup Tracing\n",
        "\n",
        "We also setup tracing through Arize Phoenix to look at our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d32462fb-07e0-4e5d-871c-98a782363330",
      "metadata": {
        "id": "d32462fb-07e0-4e5d-871c-98a782363330"
      },
      "outputs": [],
      "source": [
        "#import phoenix as px\n",
        "\n",
        "#px.launch_app()\n",
        "#import llama_index\n",
        "\n",
        "#llama_index.set_global_handler(\"arize_phoenix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c9299c-06d6-4710-afb0-3cc13761f358",
      "metadata": {
        "id": "a7c9299c-06d6-4710-afb0-3cc13761f358"
      },
      "source": [
        "## Setup Llama Pack\n",
        "\n",
        "Next we download the LlamaPack. All the code is in the downloaded directory - we encourage you to take a look to see the QueryPipeline syntax!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5143a5f-7cd3-4aac-99e7-a357f3239f03",
      "metadata": {
        "id": "f5143a5f-7cd3-4aac-99e7-a357f3239f03"
      },
      "outputs": [],
      "source": [
        "# Option 1: Use `download_llama_pack`\n",
        "# from llama_index.llama_pack import download_llama_pack\n",
        "\n",
        "# RAGFusionPipelinePack = download_llama_pack(\n",
        "#     \"RAGFusionPipelinePack\",\n",
        "#     \"./rag_fusion_pipeline_pack\",\n",
        "#     # leave the below line commented out if using the notebook on main\n",
        "#     # llama_hub_url=\"https://raw.githubusercontent.com/run-llama/llama-hub/jerry/add_query_pipeline_pack/llama_hub\"\n",
        "# )\n",
        "\n",
        "# Option 2: Import from llama_hub package\n",
        "from llama_hub.llama_packs.query.rag_fusion_pipeline.base import RAGFusionPipelinePack\n",
        "from llama_index.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral - MODEL"
      ],
      "metadata": {
        "id": "vB6EiQq-TKHt"
      },
      "id": "vB6EiQq-TKHt"
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "#!pip install accelerate\n",
        "\n",
        "import torch\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#from transformers import AutoTokenizer, MistralForCausalLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "51d2eefd5de5425da5c67dd5589dd10e",
            "91d1b100aaa242ee8b90bc64ea0c486d",
            "dbcf5f319c8e485ba4f1978942b5211d",
            "e184eac6197047e682b72ffffdcfde64",
            "0a9e1fb877e54d6f9598efccd74b5e42",
            "912401263dc8432ebeafa5bafd80c680",
            "425f63bca43941589fbecc52af830f89",
            "ff120051bca0412ab69ac995886150f3",
            "3d805244f94f462b9155a32ee95b9d2b",
            "c4738ae6a31f41fda3bb7d120e1f903f",
            "5256bb0677b64fc79a2b1cea39a50e5d"
          ]
        },
        "id": "6pObTXaM1W86",
        "outputId": "a5e43f01-8e13-4bf7-e76d-a8d248567c50"
      },
      "id": "6pObTXaM1W86",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51d2eefd5de5425da5c67dd5589dd10e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 1024\n",
        "generation_config.temperature = 0.8\n",
        "generation_config.top_p = 0.95\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "KxgTE53-PWtB"
      },
      "id": "KxgTE53-PWtB",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "MGGo2O7kPebC"
      },
      "id": "MGGo2O7kPebC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "query = \"How AWS has evolved?\"\n",
        "result = llm(query)\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J7hMlciRPj5y",
        "outputId": "7e7a416b-0789-4a30-d412-b3eb1e8ca728"
      },
      "id": "J7hMlciRPj5y",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>How AWS has evolved?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nAWS have been evolving rapidly. SaaS, IaaS and PaaS models are now common practice with AWS providing various services to customers in these areas. They also offer serverless computing which is becoming increasingly popular due to cost savings and scalability benefits. Their infrastructure management tools such as AWS CloudFormation, AWS CloudTrail and AWS Config provide more visibility into cloud operations for better control over the environment. Security features like AWS Key Management Service (KMS) and AWS Identity and Access Management (IAM) ensure that data remains protected within the cloud. Additionally, they offer various services related to big data analytics, IoT devices, machine learning, AI, and many other emerging technologies. Overall, AWS continues to innovate and expand its service offering to meet the needs of modern businesses looking to adopt a cloud-first approach.</p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POSTGRESQL"
      ],
      "metadata": {
        "id": "olzeIcZ3a8Jm"
      },
      "id": "olzeIcZ3a8Jm"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install locale\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "print()\n",
        "# PostGRES SQL Settings\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "print('START: PG embedding COMPILATION')\n",
        "%cd /content/\n",
        "!git clone https://github.com/neondatabase/pg_embedding.git\n",
        "%cd /content/pg_embedding\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG embedding COMPILATION')\n",
        "\n",
        "print()\n",
        "\n",
        "#!sudo -u postgres psql -c \"DROP EXTENSION embedding\"\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION embedding\"\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id integer PRIMARY KEY, embedding real[])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLp1-7HZOkTW",
        "outputId": "51e45626-3d11-4fc4-8bce-a9ad019324cf"
      },
      "id": "KLp1-7HZOkTW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement locale (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for locale\u001b[0m\u001b[31m\n",
            "\u001b[0m * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql-server-dev-all is already the newest version (238).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "\n",
            "/content\n",
            "ALTER ROLE\n",
            "START: PG embedding COMPILATION\n",
            "/content\n",
            "fatal: destination path 'pg_embedding' already exists and is not an empty directory.\n",
            "/content/pg_embedding\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o embedding.o embedding.c\n",
            "g++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -std=c++11 -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o hnswalg.o hnswalg.cpp\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o distfunc.o distfunc.c\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -shared -o embedding.so embedding.o hnswalg.o distfunc.o -lstdc++ -L/usr/lib/x86_64-linux-gnu -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now -L/usr/lib/llvm-14/lib  -Wl,--as-needed  \n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o embedding.bc embedding.c\n",
            "/usr/bin/clang-14 -xc++ -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o hnswalg.bc hnswalg.cpp\n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o distfunc.bc distfunc.c\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  embedding.so '/usr/lib/postgresql/14/lib/embedding.so'\n",
            "/usr/bin/install -c -m 644 .//embedding.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//embedding--0.3.5--0.3.6.sql .//embedding--0.3.5.sql .//embedding--0.3.6.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/embedding'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/embedding/\n",
            "/usr/bin/install -c -m 644 embedding.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 hnswalg.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 distfunc.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o embedding.index.bc embedding/embedding.bc embedding/hnswalg.bc embedding/distfunc.bc\n",
            "END: PG embedding COMPILATION\n",
            "\n",
            "CREATE EXTENSION\n",
            "DROP TABLE\n",
            "CREATE TABLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PG EMBEDDING"
      ],
      "metadata": {
        "id": "Xgo5C7hzbWCY"
      },
      "id": "Xgo5C7hzbWCY"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "\n",
        "# https://supabase.com/blog/fewer-dimensions-are-better-pgvector\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "collection_name='pg_essay'\n",
        "connection_string = os.getenv(\"DATABASE_URL\")\n",
        "\n",
        "db = PGEmbedding.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs0,\n",
        "    collection_name=collection_name,\n",
        "    connection_string=connection_string,\n",
        ")"
      ],
      "metadata": {
        "id": "SHrXuMUXGAMW"
      },
      "id": "SHrXuMUXGAMW",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='What did the author do growing up?'\n",
        "docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)\n",
        "\n",
        "print(query)\n",
        "print()\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4RiRP1jOGVs",
        "outputId": "886f482a-2ed0-417e-956b-e2e8a135d10d"
      },
      "id": "A4RiRP1jOGVs",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What did the author do growing up?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.5970912\n",
            "What I Worked On\n",
            "\n",
            "February 2021\n",
            "\n",
            "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
            "\n",
            "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.59990704\n",
            "Working on Bel was hard but satisfying. I worked on it so intensively that at any given time I had a decent chunk of the code in my head and could write more there. I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\n",
            "\n",
            "In the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.60247165\n",
            "Over the next several years I wrote lots of essays about all kinds of different topics. O'Reilly reprinted a collection of them as a book, called Hackers & Painters after one of the essays in it. I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\n",
            "\n",
            "One night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.61382335\n",
            "In the print era, the channel for publishing essays had been vanishingly small. Except for a few officially anointed thinkers who went to the right parties in New York, the only people allowed to publish essays were specialists writing about their specialties. There were so many essays that had never been written, because there had been no way to publish them. Now they could be, and I was going to write them. [12]\n",
            "\n",
            "I've worked on several different things, but to the extent there was a turning point where I figured out what to work on, it was when I started publishing essays online. From then on I knew that whatever else I did, I'd always write essays too.\n",
            "\n",
            "I knew that online essays would be a marginal medium at first. Socially they'd seem more like rants posted by nutjobs on their GeoCities sites than the genteel and beautifully typeset compositions published in The New Yorker. But by this point I knew enough to find that encouraging instead of discouraging.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a84473-0b2f-4649-be8e-7a603f526f02",
      "metadata": {
        "id": "b0a84473-0b2f-4649-be8e-7a603f526f02"
      },
      "source": [
        "# Inspecting the Code\n",
        "\n",
        "If we take a look at how it's setup (in your downloaded directory, you'll see the following code using our QueryPipeline syntax).\n",
        "\n",
        "`retrievers` is a dictionary mapping a chunk size to retrievers (chunk sizes: 128, 256, 512, 1024).\n",
        "\n",
        "```python\n",
        "# construct query pipeline\n",
        "p = QueryPipeline()\n",
        "module_dict = {\n",
        "    **self.retrievers,\n",
        "    \"input\": InputComponent(),\n",
        "    \"summarizer\": TreeSummarize(),\n",
        "    # NOTE: Join args\n",
        "    \"join\": ArgPackComponent(),\n",
        "    \"reranker\": rerank_component,\n",
        "}\n",
        "p.add_modules(module_dict)\n",
        "# add links from input to retriever (id'ed by chunk_size)\n",
        "for chunk_size in self.chunk_sizes:\n",
        "    p.add_link(\"input\", str(chunk_size))\n",
        "    p.add_link(str(chunk_size), \"join\", dest_key=str(chunk_size))\n",
        "p.add_link(\"join\", \"reranker\")\n",
        "p.add_link(\"input\", \"summarizer\", dest_key=\"query_str\")\n",
        "p.add_link(\"reranker\", \"summarizer\", dest_key=\"nodes\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG FUSION PIPELINE"
      ],
      "metadata": {
        "id": "bzeoJMRNbzXg"
      },
      "id": "bzeoJMRNbzXg"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1e4786b6-6add-4caf-9f9c-c2d8f455702a",
      "metadata": {
        "id": "1e4786b6-6add-4caf-9f9c-c2d8f455702a"
      },
      "outputs": [],
      "source": [
        "#ValueError: Unknown model 'Mistral-7B-Instruct-v0.1'.\n",
        "\n",
        "#del pack\n",
        "#Please provide a valid OpenAI model name in: gpt-4, gpt-4-32k, gpt-4-1106-preview,\n",
        "#gpt-4-vision-preview, gpt-4-0613, gpt-4-32k-0613, gpt-4-0314, gpt-4-32k-0314,\n",
        "#gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-1106, gpt-3.5-turbo-0613,\n",
        "#gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301, text-davinci-003, text-davinci-002,\n",
        "#gpt-3.5-turbo-instruct, text-ada-001, text-babbage-001, text-curie-001,\n",
        "#ada, babbage, curie, davinci, gpt-35-turbo-16k, gpt-35-turbo, gpt-35-turbo-1106,\n",
        "#gpt-35-turbo-0613, gpt-35-turbo-16k-0613\n",
        "\n",
        "#### OPENAI MODELS ########\n",
        "#pack = RAGFusionPipelinePack(docs, llm=OpenAI(model=\"gpt-3.5-turbo\"))\n",
        "#pack = RAGFusionPipelinePack(docs, llm=OpenAI(model=\"gpt-4\"))\n",
        "#pack = RAGFusionPipelinePack(docs, llm=OpenAI(model=\"gpt-4-1106-preview\"))\n",
        "#pack = RAGFusionPipelinePack(docs, llm=OpenAI(model=\"gpt-4-vision-preview\"))\n",
        "\n",
        "### MISTRAL\n",
        "pack = RAGFusionPipelinePack(docs, llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the DAG below."
      ],
      "metadata": {
        "id": "G0Kk6TF8jEh7"
      },
      "id": "G0Kk6TF8jEh7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34143d87-163f-4246-8ee5-15940d17c629",
      "metadata": {
        "id": "34143d87-163f-4246-8ee5-15940d17c629"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(pack.query_pipeline.dag)\n",
        "net.show(\"rag_dag.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "065ef0c4-0c9e-4611-8de4-98b2a7fe3094",
      "metadata": {
        "id": "065ef0c4-0c9e-4611-8de4-98b2a7fe3094",
        "outputId": "e1b1e117-2bac-4584-ae2f-ec073bd47b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What did the author do growing up?\n",
            "The author wrote short stories and tried writing programs on an IBM 1401 computer during their school days. They also mentioned that they painted still lives in their bedroom at night.\n",
            "\n",
            "\n",
            "Who is the President of the USA?\n",
            "I'm sorry, but the provided context does not contain any information about the current President of the United States.\n",
            "\n",
            "\n",
            "Who won the baseball World Series in 2020? and Who Lost\n",
            "I'm sorry, but I cannot answer that question based on the given context information.\n",
            "\n",
            "\n",
            "Anything about LIPS\n",
            "Lisp is a programming language that was originally intended as a formal model of computation, an alternative to the Turing machine. It was invented by John McCarthy and later became a programming language in the ordinary sense. Lisp has a core that is defined by writing an interpreter in itself. McCarthy's original Lisp interpreter could only interpret Lisp expressions and lacked many features of a programming language. Over time, these features were added, but not using McCarthy's original axiomatic approach. Lisp has a power and elegance that other languages couldn't match, which attracted the attention of many programmers.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#modify By FM 11/01/2024\n",
        "\n",
        "#response = pack.run(query=\"What did the author do growing up?\")\n",
        "query0=\"What did the author do growing up?\"\n",
        "query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query1 = \"Who is the President of the USA?\"\n",
        "query2 = \"Who won the baseball World Series in 2020? and Who Lost\"\n",
        "query3 = 'Anything about FORTRAN'\n",
        "query4 = 'Anything about LIPS'\n",
        "query5 = 'Anything about Python'\n",
        "\n",
        "response0 = pack.run(query=query0)\n",
        "response1 = pack.run(query=query1)\n",
        "response2 = pack.run(query=query2)\n",
        "response4 = pack.run(query=query4)\n",
        "\n",
        "print()\n",
        "print(query0)\n",
        "print(str(response0))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query1)\n",
        "print(str(response1))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query2)\n",
        "print(str(response2))\n",
        "print()\n",
        "\n",
        "print()\n",
        "print(query4)\n",
        "print(str(response4))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4ef382-fd11-4a82-8f5d-b2c53a21c665",
      "metadata": {
        "id": "ea4ef382-fd11-4a82-8f5d-b2c53a21c665"
      },
      "outputs": [],
      "source": [
        "#response.source_nodes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_hub",
      "language": "python",
      "name": "llama_hub"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e3bc7134-a34b-41de-b7e6-c85a6e356b56",
        "a7c9299c-06d6-4710-afb0-3cc13761f358",
        "vB6EiQq-TKHt",
        "olzeIcZ3a8Jm",
        "Xgo5C7hzbWCY"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51d2eefd5de5425da5c67dd5589dd10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91d1b100aaa242ee8b90bc64ea0c486d",
              "IPY_MODEL_dbcf5f319c8e485ba4f1978942b5211d",
              "IPY_MODEL_e184eac6197047e682b72ffffdcfde64"
            ],
            "layout": "IPY_MODEL_0a9e1fb877e54d6f9598efccd74b5e42"
          }
        },
        "91d1b100aaa242ee8b90bc64ea0c486d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912401263dc8432ebeafa5bafd80c680",
            "placeholder": "​",
            "style": "IPY_MODEL_425f63bca43941589fbecc52af830f89",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dbcf5f319c8e485ba4f1978942b5211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff120051bca0412ab69ac995886150f3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d805244f94f462b9155a32ee95b9d2b",
            "value": 2
          }
        },
        "e184eac6197047e682b72ffffdcfde64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4738ae6a31f41fda3bb7d120e1f903f",
            "placeholder": "​",
            "style": "IPY_MODEL_5256bb0677b64fc79a2b1cea39a50e5d",
            "value": " 2/2 [00:09&lt;00:00,  4.50s/it]"
          }
        },
        "0a9e1fb877e54d6f9598efccd74b5e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912401263dc8432ebeafa5bafd80c680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425f63bca43941589fbecc52af830f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff120051bca0412ab69ac995886150f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d805244f94f462b9155a32ee95b9d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4738ae6a31f41fda3bb7d120e1f903f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5256bb0677b64fc79a2b1cea39a50e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}