{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqO7IvdrlE4Xpqmg3iX42H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AAI_CHROMA_GEMINI_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai crewai_tools langchain-google-genai chromadb pydantic -q\n",
        "!pip install google-generativeai -q\n",
        "!pip install langchain_community -q\n",
        "!pip install crewai['tools'] -q\n",
        "!pip install langchain-chroma -q"
      ],
      "metadata": {
        "id": "NLYufKL0j7Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"Not running in Google Colab or 'GEMINI' secret not found. Attempting to get 'GEMINI' environment variable.\")\n",
        "    GOOGLE_API_KEY = os.getenv('GEMINI')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8D_4egoskp",
        "outputId": "211c3ceb-d601-46f0-d95c-106a91db512c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "import colab_env\n",
        "!rm -rf /content/chroma_data"
      ],
      "metadata": {
        "id": "_5k0rLC2peAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "prompt=\"What is the capital of France?\"\n",
        "\n",
        "resp = completion(\n",
        "    model=\"gemini/gemini-2.5-flash\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    api_key=os.getenv('GEMINI'),\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cU60nUTyXXo",
        "outputId": "a56543f2-8ec4-4afb-f57f-8bada01f84c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "cHOfKYlLj3JS",
        "outputId": "4e42438c-9c37-4a16-db7f-79842fd28743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "Gemini API configured with model: gemini-2.5-flash\n",
            "ChromaDB initialized successfully.\n",
            "\n",
            ">>> Detected Flight Search Request. Initiating CrewAI Search Task...\n",
            "\n",
            "--- TOOL EXECUTION: Searching flights from Montreal to Toronto on July 20, 2025 ---\n",
            "I found two flight options from Montreal to Toronto on July 20, 2025:\n",
            "*   AirCanada AC101 departing at 9:00 AM and arriving at 10:15 AM for $150.\n",
            "*   WestJet WS205 departing at 11:00 AM and arriving at 12:15 PM for $130.\n",
            "\n",
            "Would you like to proceed with booking one of these flights, or would you like to explore other options?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            ">>> Detected General Query. Using LLM with combined memory (Direct Google Generative AI)..\n",
            "Okay, I've noted that you always prefer morning flights with window seats. I'll keep that in mind for future searches!\n",
            "\n",
            "Regarding the flights for July 20, 2025, both AC101 (9:00 AM) and WS205 (11:00 AM) are morning flights. Which one would you like to book, or would you like me to look for other options with your preferences in mind?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            ">>> Detected General Query. Using LLM with combined memory (Direct Google Generative AI)..\n",
            "You prefer window seats.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            ">>> Detected General Query. Using LLM with combined memory (Direct Google Generative AI)..\n",
            "The best time to visit Toronto really depends on what you're looking for!\n",
            "\n",
            "*   **Summer (June to August)** is very popular, with warm weather, festivals, and lots of outdoor activities. It can be quite busy and a bit humid sometimes.\n",
            "*   **Spring (April to May)** and **Fall (September to October)** are often considered ideal. The weather is milder, there are fewer crowds than in summer, and you can enjoy beautiful foliage in the fall.\n",
            "*   **Winter (November to March)** can be cold and snowy, but it's a great time for indoor attractions, museums, and enjoying the festive atmosphere around the holidays.\n",
            "\n",
            "Do you have any specific activities or types of weather in mind for your visit?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            ">>> Detected Flight Search Request. Initiating CrewAI Search Task...\n",
            "\n",
            "--- TOOL EXECUTION: Searching flights from Paris to London on July 20, 2024 ---\n",
            "I looked for flights from Paris to London for tomorrow, July 20, 2024, but I couldn't find any direct flights for that date. Would you like me to check for alternative dates or explore options from nearby airports?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "--- End of Agent Interaction ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.tools import BaseTool\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Type\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import datetime\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "# --- 1. Configuration for Agent ---\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "    CREWAI_LLM_MODEL_NAME: str = \"gemini/gemini-2.5-flash\"\n",
        "\n",
        "\n",
        "# --- 2. Google Colab / Gemini API Imports and Configuration ---\n",
        "GOOGLE_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"Not running in Google Colab or 'GEMINI' secret not found. Attempting to get 'GEMINI' environment variable.\")\n",
        "    GOOGLE_API_KEY = os.getenv('GEMINI')\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    print(f\"Gemini API configured with model: {AgentConfig.LLM_MODEL_NAME}\")\n",
        "else:\n",
        "    print(\"Warning: GOOGLE_API_KEY not found. LLM calls will not work.\")\n",
        "    print(\"Please set your 'GEMINI' environment variable or Colab secret.\")\n",
        "\n",
        "# --- 3. LLM Integration (CrewAI LLM for Gemini) ---\n",
        "llm_for_crewai_agents = LLM(\n",
        "    model=AgentConfig.CREWAI_LLM_MODEL_NAME,\n",
        "    temperature=0.7,\n",
        "    api_key=GOOGLE_API_KEY,\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Vector DB Integration (ChromaDB for Memory) ---\n",
        "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "vector_db = None\n",
        "\n",
        "conversational_memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# --- 5. Tools (Using BaseTool for Custom Tools) ---\n",
        "\n",
        "class FlightSearchInput(BaseModel):\n",
        "    origin: str = Field(description=\"The city or airport code of the departure location.\")\n",
        "    destination: str = Field(description=\"The city or airport code of the arrival location.\")\n",
        "    date: str = Field(description=\"The date of the flight in a clear format (e.g., 'July 20, 2025').\")\n",
        "\n",
        "class FlightSearchTool(BaseTool):\n",
        "    name: str = \"Flight Search Tool\"\n",
        "    description: str = \"Useful for finding flight information between two cities on a specific date.\"\n",
        "    args_schema: Type[BaseModel] = FlightSearchInput\n",
        "\n",
        "    def _run(self, origin: str, destination: str, date: str) -> str:\n",
        "        print(f\"\\n--- TOOL EXECUTION: Searching flights from {origin} to {destination} on {date} ---\")\n",
        "        if origin.lower() == \"montreal\" and destination.lower() == \"toronto\" and \"july 20\" in date.lower():\n",
        "            return \"Simulated Flight Results: AirCanada AC101 (9:00 AM - 10:15 AM) $150; WestJet WS205 (11:00 AM - 12:15 PM) $130. Please confirm to book.\"\n",
        "        elif \"paris\" in origin.lower() and \"london\" in destination.lower():\n",
        "            today_simulated = datetime.date(2025, 7, 2)\n",
        "            tomorrow_simulated = today_simulated + datetime.timedelta(days=1)\n",
        "            tomorrow_str = tomorrow_simulated.strftime(\"%B %d, %Y\").lower()\n",
        "\n",
        "            if \"tomorrow\" in date.lower() or tomorrow_str in date.lower():\n",
        "                return \"Simulated Flight Results: British Airways BA245 (10:30 AM - 11:30 AM) $220. Prices may vary.\"\n",
        "            else:\n",
        "                return \"Simulated Flight Results: No direct flights found for your specified criteria. Consider alternative dates or nearby airports.\"\n",
        "        else:\n",
        "            return \"Simulated Flight Results: No direct flights found for your specified criteria. Consider alternative dates or nearby airports.\"\n",
        "\n",
        "    def _arun(self, origin: str, destination: str, date: str) -> str:\n",
        "        raise NotImplementedError(\"Asynchronous _arun not implemented for FlightSearchTool.\")\n",
        "\n",
        "flight_tool_instance = FlightSearchTool()\n",
        "\n",
        "\n",
        "# --- 6. CrewAI Agents ---\n",
        "flight_planner = Agent(\n",
        "    role='Expert Flight Planner',\n",
        "    goal='Plan optimal flight itineraries based on user requests, considering preferences and real-time availability.',\n",
        "    backstory=(\n",
        "        \"You are a highly efficient and knowledgeable AI flight planning assistant. \"\n",
        "        \"You leverage powerful search tools and access to vast flight data to provide \"\n",
        "        \"the best possible flight options. You also integrate memory for personalized service.\"\n",
        "    ),\n",
        "    verbose=False,\n",
        "    allow_delegation=False,\n",
        "    llm=llm_for_crewai_agents,\n",
        "    tools=[flight_tool_instance]\n",
        ")\n",
        "\n",
        "memory_manager = Agent(\n",
        "    role='Memory and Preference Manager',\n",
        "    goal='Store and retrieve user preferences and past interactions for personalized flight planning.',\n",
        "    backstory=(\n",
        "        \"You are the diligent keeper of user history and preferences. \"\n",
        "        \"You seamlessly interact with the vector database to ensure that the flight planner \"\n",
        "        \"always has access to relevant past information, making experiences personalized and efficient.\"\n",
        "    ),\n",
        "    verbose=False,\n",
        "    allow_delegation=False,\n",
        "    llm=llm_for_crewai_agents\n",
        ")\n",
        "\n",
        "# --- 7. CrewAI Tasks ---\n",
        "search_flight_task = Task(\n",
        "    description=(\n",
        "        \"Identify the origin, destination, and date from the user's request. \"\n",
        "        \"Then, use the 'Flight Search Tool' to find available flights. \"\n",
        "        \"Summarize the results clearly and ask the user for confirmation or further details.\"\n",
        "        \"Current user query: {query}\"\n",
        "    ),\n",
        "    expected_output=\"A clear summary of flight options found (or not found) and a polite follow-up question.\",\n",
        "    agent=flight_planner,\n",
        ")\n",
        "\n",
        "store_preference_task = Task(\n",
        "    description=(\n",
        "        \"Extract the user's preference from the provided 'preference_content'. \"\n",
        "        \"Store this preference as a plain text string in the ChromaDB vector store \"\n",
        "        \"using `vector_db.add_texts([preference_content])`. \"\n",
        "        \"Confirm to the user that the preference has been stored.\"\n",
        "        \"Preference to store: {preference_content}\"\n",
        "    ),\n",
        "    expected_output=\"A confirmation message that the user's preference has been successfully stored.\",\n",
        "    agent=memory_manager,\n",
        "    human_input=False\n",
        ")\n",
        "\n",
        "retrieve_preference_task = Task(\n",
        "    description=(\n",
        "        \"Based on the 'retrieve_query', search the ChromaDB vector store for relevant user preferences \"\n",
        "        \"using `vector_db.similarity_search(retrieve_query, k=3)`. \"\n",
        "        \"Summarize the retrieved preferences concisely for the user. If nothing is found, state that.\"\n",
        "        \"Query for retrieval: {retrieve_query}\"\n",
        "    ),\n",
        "    expected_output=\"A summary of retrieved preferences or a statement indicating no relevant preferences were found.\",\n",
        "    agent=memory_manager,\n",
        "    human_input=False\n",
        ")\n",
        "\n",
        "# --- Dynamic Interaction Loop (integrating conversational memory and vector DB) ---\n",
        "\n",
        "def run_gemini_flight_agent(user_input: str) -> str:\n",
        "    conversational_memory.chat_memory.add_user_message(user_input)\n",
        "\n",
        "    chat_history_for_llm = \"\\n\".join([f\"{msg.type.capitalize()}: {msg.content}\" for msg in conversational_memory.buffer_as_messages])\n",
        "\n",
        "    if vector_db:\n",
        "        vector_db.add_texts([f\"User input: {user_input}\"])\n",
        "    else:\n",
        "        print(\"Warning: vector_db is not initialized. Cannot add to long-term memory.\")\n",
        "\n",
        "    final_response = \"\"\n",
        "\n",
        "    if \"flight from\" in user_input.lower() and \"to\" in user_input.lower():\n",
        "        print(\"\\n>>> Detected Flight Search Request. Initiating CrewAI Search Task...\")\n",
        "        inputs = {\"query\": user_input}\n",
        "        flight_planning_crew = Crew(\n",
        "            agents=[flight_planner],\n",
        "            tasks=[search_flight_task],\n",
        "            process=Process.sequential,\n",
        "            verbose=False,\n",
        "        )\n",
        "        try:\n",
        "            # Add a small delay before kickoff to mitigate rapid API calls\n",
        "            time.sleep(1)\n",
        "            crew_result = flight_planning_crew.kickoff(inputs=inputs)\n",
        "            final_response = crew_result.raw\n",
        "        except Exception as e:\n",
        "            final_response = f\"An error occurred during flight search: {type(e).__name__}: {e}. Please try again in a moment.\"\n",
        "            print(f\"Error during CrewAI kickoff: {e}\")\n",
        "\n",
        "    elif \"remember that i prefer\" in user_input.lower() or \"store my preference\" in user_input.lower():\n",
        "        print(\"\\n>>> Detected Preference Storage Request. Initiating CrewAI Store Preference Task...\")\n",
        "        preference_content = user_input.replace(\"remember that i prefer \", \"\").replace(\"store my preference \", \"\").strip()\n",
        "        inputs = {\"preference_content\": preference_content}\n",
        "        flight_planning_crew = Crew(\n",
        "            agents=[memory_manager],\n",
        "            tasks=[store_preference_task],\n",
        "            process=Process.sequential,\n",
        "            verbose=False,\n",
        "        )\n",
        "        try:\n",
        "            time.sleep(1) # Small delay\n",
        "            crew_result = flight_planning_crew.kickoff(inputs=inputs)\n",
        "            final_response = crew_result.raw\n",
        "        except Exception as e:\n",
        "            final_response = f\"An error occurred during preference storage: {type(e).__name__}: {e}. Please try again in a moment.\"\n",
        "            print(f\"Error during CrewAI kickoff: {e}\")\n",
        "\n",
        "    elif \"what was my preference\" in user_input.lower() or \"retrieve my preference\" in user_input.lower():\n",
        "        print(\"\\n>>> Detected Preference Retrieval Request. Initiating CrewAI Retrieve Preference Task...\")\n",
        "        inputs = {\"retrieve_query\": user_input}\n",
        "        flight_planning_crew = Crew(\n",
        "            agents=[memory_manager],\n",
        "            tasks=[retrieve_preference_task],\n",
        "            process=Process.sequential,\n",
        "            verbose=False,\n",
        "        )\n",
        "        try:\n",
        "            time.sleep(1) # Small delay\n",
        "            crew_result = flight_planning_crew.kickoff(inputs=inputs)\n",
        "            final_response = crew_result.raw\n",
        "        except Exception as e:\n",
        "            final_response = f\"An error occurred during preference retrieval: {type(e).__name__}: {e}. Please try again in a moment.\"\n",
        "            print(f\"Error during CrewAI kickoff: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n>>> Detected General Query. Using LLM with combined memory (Direct Google Generative AI)..\")\n",
        "        relevant_docs = []\n",
        "        if vector_db:\n",
        "            relevant_docs = vector_db.similarity_search(user_input, k=3)\n",
        "        else:\n",
        "             print(\"Warning: vector_db is not initialized. Cannot retrieve from long-term memory.\")\n",
        "\n",
        "        context_from_db = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "        full_llm_prompt = (\n",
        "            f\"You are a helpful AI flight planning assistant. Engage in a natural conversation.\\n\"\n",
        "            f\"Here's the recent chat history:\\n{chat_history_for_llm}\\n\\n\"\n",
        "            f\"Here's relevant information from your long-term memory:\\n{context_from_db}\\n\\n\"\n",
        "            f\"User: {user_input}\\n\"\n",
        "            f\"Agent's Response:\"\n",
        "        )\n",
        "        try:\n",
        "            # Use google.generativeai.GenerativeModel directly for general queries\n",
        "            model_direct = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "            time.sleep(1) # Small delay\n",
        "            response_direct = model_direct.generate_content(full_llm_prompt)\n",
        "            final_response = response_direct.text\n",
        "        except Exception as e:\n",
        "            final_response = f\"An error occurred with the general LLM query (Direct GenAI): {type(e).__name__}: {e}. Please try again in a moment.\"\n",
        "            print(f\"Error during general LLM query (Direct GenAI): {e}\")\n",
        "\n",
        "    conversational_memory.chat_memory.add_ai_message(final_response)\n",
        "\n",
        "    return final_response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chroma_dir = \"/content/chroma_data\"\n",
        "    if os.path.exists(chroma_dir):\n",
        "        try:\n",
        "            shutil.rmtree(chroma_dir)\n",
        "            print(f\"Cleared existing ChromaDB data directory: {chroma_dir}\")\n",
        "            time.sleep(1)\n",
        "        except OSError as e:\n",
        "            print(f\"Error clearing chroma_data directory {chroma_dir}: {e}\")\n",
        "\n",
        "    try:\n",
        "        vector_db = Chroma(\n",
        "            collection_name=\"flight_planning_memory\",\n",
        "            embedding_function=embeddings_model,\n",
        "            persist_directory=chroma_dir\n",
        "        )\n",
        "        print(\"ChromaDB initialized successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing ChromaDB: {e}\")\n",
        "        vector_db = None\n",
        "\n",
        "    print(run_gemini_flight_agent(\"I need a flight from Montreal to Toronto on July 20, 2025.\"))\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(run_gemini_flight_agent(\"Remember that I always prefer morning flights with window seats.\"))\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(run_gemini_flight_agent(\"What was my seating preference?\"))\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(run_gemini_flight_agent(\"Tell me about the best time to visit Toronto.\"))\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(run_gemini_flight_agent(\"I also need a flight from Paris to London tomorrow.\"))\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    print(\"--- End of Agent Interaction ---\")"
      ]
    }
  ]
}