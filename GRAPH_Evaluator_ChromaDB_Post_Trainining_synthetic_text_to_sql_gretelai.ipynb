{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "53VITjInrs-6",
        "b_dQycoVu1yF"
      ],
      "authorship_tag": "ABX9TyPJSJmn54gqaIjCbORvglJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55ac4e0315644c3588841ed0e3c19623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b5577246a51469096dc364dfe29104e",
              "IPY_MODEL_8e3f41792f1142a6a6544039a30fea52",
              "IPY_MODEL_88154fb425434be98fff7589b586a392"
            ],
            "layout": "IPY_MODEL_dce88e8e9805494eae2f172a43b151bb"
          }
        },
        "8b5577246a51469096dc364dfe29104e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fda987cb129493389b5329e7be1e219",
            "placeholder": "​",
            "style": "IPY_MODEL_9cfefb7b83d449f69e21829e08f3093a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8e3f41792f1142a6a6544039a30fea52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fc723c0c064470b203d93428948fa9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e72452e30fe484d96552f1d43fa5818",
            "value": 2
          }
        },
        "88154fb425434be98fff7589b586a392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2d42c6c4034e80acd0510398d8711f",
            "placeholder": "​",
            "style": "IPY_MODEL_279b954044df4035964e81f5e212f295",
            "value": " 2/2 [00:45&lt;00:00, 21.42s/it]"
          }
        },
        "dce88e8e9805494eae2f172a43b151bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fda987cb129493389b5329e7be1e219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfefb7b83d449f69e21829e08f3093a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14fc723c0c064470b203d93428948fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e72452e30fe484d96552f1d43fa5818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b2d42c6c4034e80acd0510398d8711f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279b954044df4035964e81f5e212f295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f862ace03b406e9abec67e14f2b15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d636663b01274b7991058fa56afb5194",
              "IPY_MODEL_27e95d31bd57433ca85379bd155e8db9",
              "IPY_MODEL_1730c431584548459eefc407742820c1"
            ],
            "layout": "IPY_MODEL_b8b81bb9dd0447bca6d4cd3c4df7a3cf"
          }
        },
        "d636663b01274b7991058fa56afb5194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c774c3ee3342e78f9df9c791df0c96",
            "placeholder": "​",
            "style": "IPY_MODEL_b4214e42e3e548c488a10edd1016f9e4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "27e95d31bd57433ca85379bd155e8db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19d31cb8a3441fcb0870f207e774f0f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d40df9553af451ba13d21e3639658e6",
            "value": 3
          }
        },
        "1730c431584548459eefc407742820c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d88ec92f6f46fd9ea14c20829bea2a",
            "placeholder": "​",
            "style": "IPY_MODEL_ab9f978831a14ae898f241e018880eff",
            "value": " 3/3 [00:47&lt;00:00, 15.74s/it]"
          }
        },
        "b8b81bb9dd0447bca6d4cd3c4df7a3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c774c3ee3342e78f9df9c791df0c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4214e42e3e548c488a10edd1016f9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d19d31cb8a3441fcb0870f207e774f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d40df9553af451ba13d21e3639658e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76d88ec92f6f46fd9ea14c20829bea2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9f978831a14ae898f241e018880eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "620196c95c0d453da209bbfb36abd30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_380d0a8375244e9f8f73f654e379f672",
              "IPY_MODEL_8ee4187742984561baeea9cce1652272",
              "IPY_MODEL_63d0bebe69284aff84e0e6d02c2c08ea"
            ],
            "layout": "IPY_MODEL_7db71e8d11744c1d94335ce574dca8f6"
          }
        },
        "380d0a8375244e9f8f73f654e379f672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1434271aa4b43f8a7c3e701aa9886ed",
            "placeholder": "​",
            "style": "IPY_MODEL_c67c67126ed24de6bc41ef76cb960228",
            "value": "100%"
          }
        },
        "8ee4187742984561baeea9cce1652272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ce29c13f7b4f608db2e83c813c9181",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab24af899e4c43d991731343c75d404e",
            "value": 5
          }
        },
        "63d0bebe69284aff84e0e6d02c2c08ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df66a51148654ad99badafd0183f6338",
            "placeholder": "​",
            "style": "IPY_MODEL_29cf11cae538450c9c21421acf43c3ed",
            "value": " 5/5 [03:53&lt;00:00, 31.61s/it]"
          }
        },
        "7db71e8d11744c1d94335ce574dca8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1434271aa4b43f8a7c3e701aa9886ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67c67126ed24de6bc41ef76cb960228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ce29c13f7b4f608db2e83c813c9181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab24af899e4c43d991731343c75d404e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df66a51148654ad99badafd0183f6338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cf11cae538450c9c21421acf43c3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/GRAPH_Evaluator_ChromaDB_Post_Trainining_synthetic_text_to_sql_gretelai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRARIES"
      ],
      "metadata": {
        "id": "53VITjInrs-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q chromadb\n",
        "!pip install -q faiss-gpu\n",
        "!pip install peft  -q\n",
        "\n",
        "!pip install bitsandbytes -q\n",
        "!pip pip install accelerate -q\n",
        "\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install mistral_inference -q\n",
        "\n",
        "!pip install -q evaluate sentence_transformers"
      ],
      "metadata": {
        "id": "zR4yytDbPyOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0011f5-3eae-4e1e-f36f-9929969addc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hERROR: unknown command \"pip\"\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cJWzOH4B81",
        "outputId": "3adf17b4-57a8-47df-efde-23179f3d0671"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 12 06:30:12 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   49C    P8              16W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import colab_env\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "metadata": {
        "id": "zAOOi0pfRZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2c4ae1-5f72-4899-fcb5-6fa66b1ad174"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Settings"
      ],
      "metadata": {
        "id": "zi9nbbcSvbWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ckGGJclusZ",
        "outputId": "9deee467-6766-4bd9-dbc1-71f780c33672"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading Mistral Tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=True)\n",
        "\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "print('\\n')\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading Mistral Model...\")\n",
        "# Load model and tokenizer\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    token=True\n",
        ")\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "55ac4e0315644c3588841ed0e3c19623",
            "8b5577246a51469096dc364dfe29104e",
            "8e3f41792f1142a6a6544039a30fea52",
            "88154fb425434be98fff7589b586a392",
            "dce88e8e9805494eae2f172a43b151bb",
            "2fda987cb129493389b5329e7be1e219",
            "9cfefb7b83d449f69e21829e08f3093a",
            "14fc723c0c064470b203d93428948fa9",
            "4e72452e30fe484d96552f1d43fa5818",
            "9b2d42c6c4034e80acd0510398d8711f",
            "279b954044df4035964e81f5e212f295"
          ]
        },
        "id": "4f5pWT8nlz0x",
        "outputId": "d5bf2ddf-903d-4cc0-a6e2-dc2d82a9a38d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loading Mistral Tokenizer...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Loading Mistral Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55ac4e0315644c3588841ed0e3c19623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Models and Tokenizer AND ChromaDB Setup"
      ],
      "metadata": {
        "id": "F8UCjMvgdl8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[{'content': 'You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE Has_allergy (allergy VARCHAR); CREATE TABLE Allergy_type (allergy VARCHAR, allergytype VARCHAR)',\n",
        "  'role': 'system'},\n",
        " {'content': 'How many students have a food allergy?', 'role': 'user'},\n",
        " {'content': 'SELECT COUNT(*) FROM Has_allergy AS T1 JOIN Allergy_type AS T2 ON T1.allergy = T2.allergy WHERE T2.allergytype = \"food\"',\n",
        "  'role': 'assistant'}]"
      ],
      "metadata": {
        "id": "jUbq2WUgvNnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import os\n",
        "\n",
        "from peft import PeftModel # PeftModel is now correctly imported from peft\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "# Logging Setup\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# 1. Configurable Parameters\n",
        "\n",
        "#gretelai/synthetic_text_to_sql\n",
        "\n",
        "#DATASET_FILE = \"/content/gdrive/MyDrive/datasets/test_dataset.json\"\n",
        "\n",
        "DATASET_FILE = \"/content/gdrive/MyDrive/datasets/gretelai_test_dataset.json\"\n",
        "\n",
        "NUM_SAMPLES_TO_PROCESS = int(os.getenv(\"NUM_SAMPLES\", 5))\n",
        "GENERATION_PARAMS = {\n",
        "    \"max_new_tokens\": 256, \"do_sample\": True, \"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95\n",
        "}\n",
        "SIMILARITY_THRESHOLD = 0.85\n",
        "\n",
        "\n",
        "# 2. Load Evaluation Dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=DATASET_FILE, split=\"train\")\n",
        "if NUM_SAMPLES_TO_PROCESS > 0:\n",
        "    eval_dataset = eval_dataset.select(range(NUM_SAMPLES_TO_PROCESS))\n",
        "logging.info(f\"Processing {len(eval_dataset)} samples from the dataset.\")\n",
        "\n",
        "\n",
        "# 3. Load Models and Tokenizer\n",
        "\n",
        "PEFT_MODEL_ID = \"frankmorales2020/Mistral-7B-text-to-sql-flash-attention-2-dataeval\"\n",
        "#model = AutoPeftModelForCausalLM.from_pretrained(PEFT_MODEL_ID)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading Mistral-T2SQL Model...\")\n",
        "mistral_model = AutoPeftModelForCausalLM.from_pretrained(PEFT_MODEL_ID)\n",
        "print('\\n')\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading Mistral Tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(PEFT_MODEL_ID)\n",
        "print('\\n')\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading GNNT2SQL Model...\")\n",
        "model_id ='/content/gdrive/MyDrive/model/GNNT2SQL/checkpoint-1950/'\n",
        "logging.info(f\"Loading fine-tuned PEFT model from: {model_id}\")\n",
        "\n",
        "# Use PeftModel to load the model, pass the model object and model_id as arguments\n",
        "model = PeftModel.from_pretrained(mistral_model, model_id)\n",
        "print('\\n')\n",
        "\n",
        "### ONLY WITH HF MODEL ######\n",
        "#print('\\n')\n",
        "#print(\"Loading Mistral-T2SQL Model...\")\n",
        "#PEFT_MODEL_ID = \"frankmorales2020/Mistral-7B-text-to-sql-flash-attention-2-dataeval\"\n",
        "#model = AutoPeftModelForCausalLM.from_pretrained(PEFT_MODEL_ID)\n",
        "#tokenizer = AutoTokenizer.from_pretrained(PEFT_MODEL_ID)\n",
        "#print('\\n')\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, **GENERATION_PARAMS)\n",
        "logging.info(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "# 4. ChromaDB Setup\n",
        "client = chromadb.PersistentClient(path='db')  # Store embeddings on disk\n",
        "collection = client.get_or_create_collection(name=\"sql_queries_and_embeddings\")\n",
        "\n",
        "print('\\n')\n",
        "print(\"Loading ChromaDB queries...\")\n",
        "# Add Original SQL Queries to ChromaDB\n",
        "# original_answer = sample[\"messages\"][2][\"content\"]\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "original_sql_queries = [\n",
        "    item['messages'][2]['content']\n",
        "    for item in eval_dataset if len(item['messages']) > 2 and item['messages'][2].get('content')\n",
        "]\n",
        "\n",
        "sql_embeddings = embedding_model.encode(original_sql_queries).tolist()\n",
        "collection.add(\n",
        "    embeddings=sql_embeddings,\n",
        "    metadatas=[{\"original_sql\": query} for query in original_sql_queries],\n",
        "    ids=[f\"original_{i}\" for i in range(len(original_sql_queries))]  # Unique IDs\n",
        ")\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "tOrvw1OpPw_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676,
          "referenced_widgets": [
            "b6f862ace03b406e9abec67e14f2b15d",
            "d636663b01274b7991058fa56afb5194",
            "27e95d31bd57433ca85379bd155e8db9",
            "1730c431584548459eefc407742820c1",
            "b8b81bb9dd0447bca6d4cd3c4df7a3cf",
            "87c774c3ee3342e78f9df9c791df0c96",
            "b4214e42e3e548c488a10edd1016f9e4",
            "d19d31cb8a3441fcb0870f207e774f0f",
            "5d40df9553af451ba13d21e3639658e6",
            "76d88ec92f6f46fd9ea14c20829bea2a",
            "ab9f978831a14ae898f241e018880eff"
          ]
        },
        "outputId": "b29951cd-ab4a-452e-db81-7443cb0018c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loading Mistral-T2SQL Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6f862ace03b406e9abec67e14f2b15d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Loading Mistral Tokenizer...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Loading GNNT2SQL Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Loading ChromaDB queries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PeftModel to load the model, pass the model object and model_id as arguments\n",
        "#model = PeftModel.from_pretrained(mistral_model, model_id)\n",
        "#pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, **GENERATION_PARAMS)\n",
        "#logging.info(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "#print()\n",
        "#output = pipe(\"What is the percentage of successful open data initiatives in the education sector?\")\n",
        "#print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "mzi-BodP0bo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postgresql Setup"
      ],
      "metadata": {
        "id": "b_dQycoVu1yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ADDED By FM 01/06/2024\n",
        "!apt-get update -y\n",
        "!apt-get install postgresql-14 -y\n",
        "\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all"
      ],
      "metadata": {
        "id": "fz3g0Q77QTBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3d39ce-25ef-4e3b-92b9-b36739b2ea43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [999 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Ign:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,224 kB]\n",
            "Hit:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,438 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,298 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,499 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,149 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,571 kB]\n",
            "Fetched 19.5 MB in 5s (4,274 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl logrotate netbase\n",
            "  postgresql-client-14 postgresql-client-common postgresql-common ssl-cert sysstat\n",
            "Suggested packages:\n",
            "  bsd-mailx | mailx postgresql-doc-14 isag\n",
            "The following NEW packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl logrotate netbase\n",
            "  postgresql-14 postgresql-client-14 postgresql-client-common postgresql-common ssl-cert sysstat\n",
            "0 upgraded, 12 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 18.4 MB of archives.\n",
            "After this operation, 51.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 logrotate amd64 3.19.0-1ubuntu1.1 [54.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcommon-sense-perl amd64 3.75-2build1 [21.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-perl all 4.04000-1 [81.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtypes-serialiser-perl all 1.01-1 [11.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-xs-perl amd64 4.030-1build3 [87.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-client-common all 238 [29.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-client-14 amd64 14.13-0ubuntu0.22.04.1 [1,225 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 ssl-cert all 1.1.2 [17.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-common all 238 [169 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-14 amd64 14.13-0ubuntu0.22.04.1 [16.2 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]\n",
            "Fetched 18.4 MB in 3s (6,129 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package logrotate.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../00-logrotate_3.19.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libcommon-sense-perl:amd64.\n",
            "Preparing to unpack .../02-libcommon-sense-perl_3.75-2build1_amd64.deb ...\n",
            "Unpacking libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Selecting previously unselected package libjson-perl.\n",
            "Preparing to unpack .../03-libjson-perl_4.04000-1_all.deb ...\n",
            "Unpacking libjson-perl (4.04000-1) ...\n",
            "Selecting previously unselected package libtypes-serialiser-perl.\n",
            "Preparing to unpack .../04-libtypes-serialiser-perl_1.01-1_all.deb ...\n",
            "Unpacking libtypes-serialiser-perl (1.01-1) ...\n",
            "Selecting previously unselected package libjson-xs-perl.\n",
            "Preparing to unpack .../05-libjson-xs-perl_4.030-1build3_amd64.deb ...\n",
            "Unpacking libjson-xs-perl (4.030-1build3) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../06-postgresql-client-common_238_all.deb ...\n",
            "Unpacking postgresql-client-common (238) ...\n",
            "Selecting previously unselected package postgresql-client-14.\n",
            "Preparing to unpack .../07-postgresql-client-14_14.13-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-client-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../08-ssl-cert_1.1.2_all.deb ...\n",
            "Unpacking ssl-cert (1.1.2) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../09-postgresql-common_238_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (238) ...\n",
            "Selecting previously unselected package postgresql-14.\n",
            "Preparing to unpack .../10-postgresql-14_14.13-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../11-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking sysstat (12.5.2-2ubuntu0.2) ...\n",
            "Setting up logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Created symlink /etc/systemd/system/timers.target.wants/logrotate.timer → /lib/systemd/system/logrotate.timer.\n",
            "Setting up libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Setting up ssl-cert (1.1.2) ...\n",
            "Setting up libtypes-serialiser-perl (1.01-1) ...\n",
            "Setting up libjson-perl (4.04000-1) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up sysstat (12.5.2-2ubuntu0.2) ...\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
            "Setting up postgresql-client-common (238) ...\n",
            "Setting up libjson-xs-perl (4.030-1build3) ...\n",
            "Setting up postgresql-client-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up postgresql-common (238) ...\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /lib/systemd/system/postgresql.service.\n",
            "Setting up postgresql-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "Creating new PostgreSQL cluster 14/main ...\n",
            "/usr/lib/postgresql/14/bin/initdb -D /var/lib/postgresql/14/main --auth-local peer --auth-host scram-sha-256 --no-instructions\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/14/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default time zone ... Etc/UTC\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/postmaster.1.gz to provide /usr/share/man/man1/postmaster.1.gz (postmaster.1.gz) in auto mode\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14 python3-pygments\n",
            "  python3-yaml\n",
            "Suggested packages:\n",
            "  llvm-14-doc python-pygments-doc ttf-bitstream-vera\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14\n",
            "  postgresql-server-dev-all python3-pygments python3-yaml\n",
            "0 upgraded, 13 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 59.8 MB of archives.\n",
            "After this operation, 361 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 binfmt-support amd64 2.2.1-2 [55.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-runtime amd64 1:14.0.0-1ubuntu1.1 [484 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpfm4 amd64 4.11.1+git32-gd0b85fb-1ubuntu0.1 [345 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14 amd64 1:14.0.0-1ubuntu1.1 [12.7 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-pygments all 2.11.2+dfsg-2 [750 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-tools amd64 1:14.0.0-1ubuntu1.1 [404 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-4 amd64 4.8.12-1 [5,766 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-dev amd64 4.8.12-1 [72.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-dev amd64 1:14.0.0-1ubuntu1.1 [37.8 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 postgresql-server-dev-14 amd64 14.13-0ubuntu0.22.04.1 [1,177 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 postgresql-server-dev-all amd64 238 [14.0 kB]\n",
            "Fetched 59.8 MB in 5s (11.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 13.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 125555 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Selecting previously unselected package binfmt-support.\n",
            "Preparing to unpack .../01-binfmt-support_2.2.1-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.2.1-2) ...\n",
            "Selecting previously unselected package llvm-14-runtime.\n",
            "Preparing to unpack .../02-llvm-14-runtime_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libpfm4:amd64.\n",
            "Preparing to unpack .../03-libpfm4_4.11.1+git32-gd0b85fb-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Selecting previously unselected package llvm-14.\n",
            "Preparing to unpack .../04-llvm-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../05-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../06-python3-pygments_2.11.2+dfsg-2_all.deb ...\n",
            "Unpacking python3-pygments (2.11.2+dfsg-2) ...\n",
            "Selecting previously unselected package llvm-14-tools.\n",
            "Preparing to unpack .../07-llvm-14-tools_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libz3-4:amd64.\n",
            "Preparing to unpack .../08-libz3-4_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-4:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package libz3-dev:amd64.\n",
            "Preparing to unpack .../09-libz3-dev_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-dev:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package llvm-14-dev.\n",
            "Preparing to unpack .../10-llvm-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-14.\n",
            "Preparing to unpack .../11-postgresql-server-dev-14_14.13-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-all:amd64.\n",
            "Preparing to unpack .../12-postgresql-server-dev-all_238_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-all:amd64 (238) ...\n",
            "Setting up python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up python3-pygments (2.11.2+dfsg-2) ...\n",
            "Setting up libz3-4:amd64 (4.8.12-1) ...\n",
            "Setting up libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Setting up llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up binfmt-support (2.2.1-2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "Setting up llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libz3-dev:amd64 (4.8.12-1) ...\n",
            "Setting up llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up postgresql-server-dev-14 (14.13-0ubuntu0.22.04.1) ...\n",
            "Setting up postgresql-server-dev-all:amd64 (238) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PostGRES SQL Settings\n",
        "!sudo -u postgres psql -c \"CREATE USER postgres WITH SUPERUSER\"\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFbxBi-HQZT-",
        "outputId": "52d7c9e8-af58-4229-e700-86307d1b6472"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR:  role \"postgres\" already exists\n",
            "ALTER ROLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_create='CREATE TABLE table_name_24 (score VARCHAR, date VARCHAR)'"
      ],
      "metadata": {
        "id": "l5ATm5VvQiAg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_select='SELECT 2009 FROM table_name_50 WHERE 2011 = \"a\"'"
      ],
      "metadata": {
        "id": "iJjf15-aQqco"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def table_creator(query):\n",
        "    import os\n",
        "    import psycopg2 as ps\n",
        "    import pandas as pd\n",
        "\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "                  user=DB_USER,\n",
        "                  password=DB_PASS,\n",
        "                  host=DB_HOST,\n",
        "                  port=DB_PORT)\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Wrap the execute command in a try-except block to handle potential errors\n",
        "    try:\n",
        "        cur.execute(\"\"\"\n",
        "                            %s\n",
        "                            \"\"\"%query)\n",
        "        conn.commit()\n",
        "        print(\"Table Created successfully\")\n",
        "    except Exception as e:\n",
        "        conn.rollback() # Rollback the transaction in case of an error\n",
        "        print(\"Error creating table:\", e)\n",
        "\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "Q5qUFuunQvHU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2 as ps\n",
        "import pandas as pd\n",
        "\n",
        "DB_NAME = \"postgres\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_PASS = \"postgres\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5432\""
      ],
      "metadata": {
        "id": "BqlIz9IYQ3UT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2 as ps\n",
        "import pandas as pd\n",
        "\n",
        "def table_select(query):\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "                      user=DB_USER,\n",
        "                      password=DB_PASS,\n",
        "                      host=DB_HOST,\n",
        "                      port=DB_PORT)\n",
        "    print(\"Database connected successfully\")\n",
        "\n",
        "    #query = query.replace('\"', \"'\") # Replace double quotes with single quotes for potential date values\n",
        "\n",
        "    try:\n",
        "\n",
        "        #df = pd.read_sql_query(\"%s\"%query, con=conn)\n",
        "        #print('rec: %'%df) # Print the resulting DataFrame\n",
        "\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(query)\n",
        "        rows = cur.fetchall()\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print('\\n')\n",
        "        print('Record(s): %s \\n'%len(rows))\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "\n",
        "\n",
        "        eqc=1\n",
        "\n",
        "    except Exception as e:\n",
        "        eqc=0\n",
        "        #conn.rollback() # Rollback the transaction in case of an error\n",
        "        print(\"Error executing query:\", e)\n",
        "        #print('TABLE IS EMPTY')\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    return eqc"
      ],
      "metadata": {
        "id": "ptNXNomUQ0Fy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_creator(QUERY_create)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsMREUeGQ9QQ",
        "outputId": "78a90afd-bbd3-4e39-f865-5dae61280c20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table Created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluator"
      ],
      "metadata": {
        "id": "VszcBUuCvLAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluation Function (Exact Match Only)\n",
        "def evaluate(sample):\n",
        "    eqc=0\n",
        "    prompt = pipe.tokenizer.apply_chat_template(sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
        "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
        "    predicted_answer = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "    #predicted_answer = outputs[0]['generated_text']\n",
        "\n",
        "    #print(\"\\n\\n\")\n",
        "    question = sample[\"messages\"][1][\"content\"]\n",
        "    original_answer = sample[\"messages\"][2][\"content\"]\n",
        "\n",
        "\n",
        "    schema=sample[\"messages\"][0]['content']\n",
        "    schema_query=schema[153:len(schema)]\n",
        "\n",
        "    print(f'Question: {question}')\n",
        "    print(f'SCHEMA: {schema_query}')\n",
        "    print(f'Original Answer: {original_answer}')\n",
        "    print(f'Generated Answer: {predicted_answer}')\n",
        "\n",
        "    if predicted_answer == original_answer:\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print('MATCH')\n",
        "        print(\"\\n\")\n",
        "\n",
        "        print(f'Question: {question}')\n",
        "        #print(f'SCHEMA: {schema_query}')\n",
        "        print(f'Original Answer: {original_answer}')\n",
        "        #print(f'Generated Answer: {predicted_answer}')\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'SCHEMA QUERY: {schema_query}')\n",
        "        table_creator(schema_query)\n",
        "        print(\"\\n\")\n",
        "        print(f'Generated Answer: {predicted_answer}')\n",
        "        eqc=table_select(predicted_answer)\n",
        "        print(eqc)\n",
        "        print(\"\\n\")\n",
        "        if int(eqc)==1:\n",
        "           print('Good Query execution')\n",
        "        else:\n",
        "           print('Bad Query execution')\n",
        "\n",
        "        #print(\"\\n\")\n",
        "        #print('MATCH')\n",
        "        return 1, eqc\n",
        "\n",
        "    # If not an exact match, check semantic similarity using ChromaDB:\n",
        "    predicted_embedding = embedding_model.encode([predicted_answer]).tolist()[0]\n",
        "    results = collection.query(\n",
        "        query_embeddings=[predicted_embedding],\n",
        "        n_results=1,\n",
        "        include=[\"distances\", \"metadatas\"]\n",
        "    )\n",
        "    closest_distance = results['distances'][0][0]\n",
        "    most_similar_query = results['metadatas'][0][0]['original_sql']\n",
        "    print(\"\\n\")\n",
        "    print(f'Closest Distance by ChromaDB: {closest_distance}')\n",
        "\n",
        "    similarity_threshold = SIMILARITY_THRESHOLD\n",
        "\n",
        "    #if closest_distance < similarity_threshold:\n",
        "    if most_similar_query == original_answer:\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print('MATCH (Semantically Similar by ChromaDB)')\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'Question: {question}')\n",
        "        print(f'SCHEMA: {schema_query}')\n",
        "        print(f'Original Answer: {original_answer}')\n",
        "        print(\"\\n\\n\")\n",
        "        print(f'Generated Answer: {predicted_answer}')\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'SCHEMA QUERY: {schema_query}')\n",
        "        table_creator(schema_query)\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "        print('Similar Query:', most_similar_query)\n",
        "        eqc=table_select(most_similar_query)\n",
        "        print(\"\\n\")\n",
        "        if int(eqc)==1:\n",
        "           print('Good Query execution')\n",
        "        else:\n",
        "           print('Bad Query execution')\n",
        "        print(\"\\n\")\n",
        "        return 1, eqc\n",
        "\n",
        "    else:\n",
        "        print('NO MATCH')\n",
        "        return 0, eqc\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "# 7. Main Evaluation Loop\n",
        "success_rate = []\n",
        "success_rate_query = []\n",
        "\n",
        "for i, s in enumerate(tqdm(eval_dataset)):\n",
        "    print()\n",
        "    print(f\"EVALUATING SAMPLE: {i}\")\n",
        "    try:\n",
        "        success_rate.append(evaluate(s))\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error evaluating sample {i}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# 8. Compute and Print Accuracy\n",
        "if len(success_rate) > 0:\n",
        "    # Extract the first element (match success indicator) from each tuple\n",
        "    match_successes = [result[0] for result in success_rate]\n",
        "    accuracy = sum(match_successes) / len(success_rate)\n",
        "    print(f\"\\nMatch Accuracy: {accuracy:.2%}\\n\")\n",
        "\n",
        "    query_successes = [result[1] for result in success_rate]\n",
        "    accuracy = sum(query_successes) / len(query_successes)\n",
        "    print(f\"\\nQuery Successes: {accuracy:.2%}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo samples were successfully evaluated. Check the dataset and evaluation logic.\\n\")\n",
        "\n",
        "\n",
        "# 8. Compute and Print Accuracy\n",
        "#if len(success_rate) > 0:\n",
        "#    accuracy = sum(success_rate) / len(success_rate)\n",
        "#    print(f\"\\nMatch Accuracy: {accuracy:.2%}\\n\")\n",
        "#else:\n",
        "#    print(\"\\nNo samples were successfully evaluated. Check the dataset and evaluation logic.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "620196c95c0d453da209bbfb36abd30f",
            "380d0a8375244e9f8f73f654e379f672",
            "8ee4187742984561baeea9cce1652272",
            "63d0bebe69284aff84e0e6d02c2c08ea",
            "7db71e8d11744c1d94335ce574dca8f6",
            "c1434271aa4b43f8a7c3e701aa9886ed",
            "c67c67126ed24de6bc41ef76cb960228",
            "c6ce29c13f7b4f608db2e83c813c9181",
            "ab24af899e4c43d991731343c75d404e",
            "df66a51148654ad99badafd0183f6338",
            "29cf11cae538450c9c21421acf43c3ed"
          ]
        },
        "id": "pkl430CeQb8Z",
        "outputId": "4ff802aa-402b-4d4b-8be5-5848e579805f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "620196c95c0d453da209bbfb36abd30f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EVALUATING SAMPLE: 0\n",
            "Question: What is the percentage of successful open data initiatives in the education sector?\n",
            "SCHEMA: CREATE TABLE open_data_initiatives (id INT, sector VARCHAR(20), status VARCHAR(10)); INSERT INTO open_data_initiatives (id, sector, status) VALUES (1, 'justice', 'open'), (2, 'transportation', 'open'), (3, 'education', 'closed'), (4, 'education', 'open');\n",
            "Original Answer: SELECT 100.0 * COUNT(CASE WHEN status = 'open' THEN 1 END) / COUNT(*) FROM open_data_initiatives WHERE sector = 'education';\n",
            "Generated Answer: SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' AS OPEN_INITIATIVES FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' UNION SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'closed' AS CLOSED_INITIATIVES FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' UNION SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'closed' FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' OR sector = 'education' AND status = 'closed' GROUP BY sector, status HAVING OPEN_INITIATIVES <> CLOSED_INITIATIVES ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "\n",
            "Closest Distance by ChromaDB: 0.4369802193351987\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar by ChromaDB)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the percentage of successful open data initiatives in the education sector?\n",
            "SCHEMA: CREATE TABLE open_data_initiatives (id INT, sector VARCHAR(20), status VARCHAR(10)); INSERT INTO open_data_initiatives (id, sector, status) VALUES (1, 'justice', 'open'), (2, 'transportation', 'open'), (3, 'education', 'closed'), (4, 'education', 'open');\n",
            "Original Answer: SELECT 100.0 * COUNT(CASE WHEN status = 'open' THEN 1 END) / COUNT(*) FROM open_data_initiatives WHERE sector = 'education';\n",
            "\n",
            "\n",
            "\n",
            "Generated Answer: SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' AS OPEN_INITIATIVES FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' UNION SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'closed' AS CLOSED_INITIATIVES FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' UNION SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'closed' FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' OR sector = 'education' AND status = 'closed' GROUP BY sector, status HAVING OPEN_INITIATIVES <> CLOSED_INITIATIVES ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE open_data_initiatives (id INT, sector VARCHAR(20), status VARCHAR(10)); INSERT INTO open_data_initiatives (id, sector, status) VALUES (1, 'justice', 'open'), (2, 'transportation', 'open'), (3, 'education', 'closed'), (4, 'education', 'open');\n",
            "Table Created successfully\n",
            "\n",
            "\n",
            "Similar Query: SELECT 100.0 * COUNT(CASE WHEN status = 'open' THEN 1 END) / COUNT(*) FROM open_data_initiatives WHERE sector = 'education';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(Decimal('50.0000000000000000'),)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "EVALUATING SAMPLE: 1\n",
            "Question: What is the average Shariah-compliant investment portfolio return for female investors in the Middle East, grouped by year?\n",
            "SCHEMA: CREATE TABLE Investments (Id INT, InvestorGender VARCHAR(10), Location VARCHAR(20), InvestmentType VARCHAR(20), Return DECIMAL(5,2), InvestmentYear INT); INSERT INTO Investments (Id, InvestorGender, Location, InvestmentType, Return, InvestmentYear) VALUES (1, 'Female', 'Middle East', 'Shariah Compliant', 8.56, 2020), (2, 'Female', 'Middle East', 'Shariah Compliant', 9.15, 2021);\n",
            "Original Answer: SELECT AVG(Return) AS Avg_Return, InvestmentYear FROM Investments WHERE InvestmentType = 'Shariah Compliant' AND InvestorGender = 'Female' GROUP BY InvestmentYear;\n",
            "Generated Answer: SELECT AVG(Return), InvestmentYear FROM Investments WHERE InvestorGender = 'Female' AND Location = 'Middle East' AND InvestmentType = 'Shariah Compliant' GROUP BY InvestmentYear\n",
            "\n",
            "\n",
            "Closest Distance by ChromaDB: 0.09634731399595758\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar by ChromaDB)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the average Shariah-compliant investment portfolio return for female investors in the Middle East, grouped by year?\n",
            "SCHEMA: CREATE TABLE Investments (Id INT, InvestorGender VARCHAR(10), Location VARCHAR(20), InvestmentType VARCHAR(20), Return DECIMAL(5,2), InvestmentYear INT); INSERT INTO Investments (Id, InvestorGender, Location, InvestmentType, Return, InvestmentYear) VALUES (1, 'Female', 'Middle East', 'Shariah Compliant', 8.56, 2020), (2, 'Female', 'Middle East', 'Shariah Compliant', 9.15, 2021);\n",
            "Original Answer: SELECT AVG(Return) AS Avg_Return, InvestmentYear FROM Investments WHERE InvestmentType = 'Shariah Compliant' AND InvestorGender = 'Female' GROUP BY InvestmentYear;\n",
            "\n",
            "\n",
            "\n",
            "Generated Answer: SELECT AVG(Return), InvestmentYear FROM Investments WHERE InvestorGender = 'Female' AND Location = 'Middle East' AND InvestmentType = 'Shariah Compliant' GROUP BY InvestmentYear\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE Investments (Id INT, InvestorGender VARCHAR(10), Location VARCHAR(20), InvestmentType VARCHAR(20), Return DECIMAL(5,2), InvestmentYear INT); INSERT INTO Investments (Id, InvestorGender, Location, InvestmentType, Return, InvestmentYear) VALUES (1, 'Female', 'Middle East', 'Shariah Compliant', 8.56, 2020), (2, 'Female', 'Middle East', 'Shariah Compliant', 9.15, 2021);\n",
            "Table Created successfully\n",
            "\n",
            "\n",
            "Similar Query: SELECT AVG(Return) AS Avg_Return, InvestmentYear FROM Investments WHERE InvestmentType = 'Shariah Compliant' AND InvestorGender = 'Female' GROUP BY InvestmentYear;\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 2 \n",
            "\n",
            "(Decimal('8.5600000000000000'), 2020)\n",
            "(Decimal('9.1500000000000000'), 2021)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "EVALUATING SAMPLE: 2\n",
            "Question: Find the minimum founding year for startups founded by Indigenous or Native entrepreneurs\n",
            "SCHEMA: CREATE TABLE company (id INT, name TEXT, founding_year INT, founder_race TEXT); INSERT INTO company (id, name, founding_year, founder_race) VALUES (1, 'IndigenousTech', 2010, 'Indigenous or Native American'); INSERT INTO company (id, name, founding_year, founder_race) VALUES (2, 'Beta', 2015, 'White');\n",
            "Original Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American';\n",
            "Generated Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American'\n",
            "\n",
            "\n",
            "Closest Distance by ChromaDB: 0.02349647624336921\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar by ChromaDB)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: Find the minimum founding year for startups founded by Indigenous or Native entrepreneurs\n",
            "SCHEMA: CREATE TABLE company (id INT, name TEXT, founding_year INT, founder_race TEXT); INSERT INTO company (id, name, founding_year, founder_race) VALUES (1, 'IndigenousTech', 2010, 'Indigenous or Native American'); INSERT INTO company (id, name, founding_year, founder_race) VALUES (2, 'Beta', 2015, 'White');\n",
            "Original Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American';\n",
            "\n",
            "\n",
            "\n",
            "Generated Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE company (id INT, name TEXT, founding_year INT, founder_race TEXT); INSERT INTO company (id, name, founding_year, founder_race) VALUES (1, 'IndigenousTech', 2010, 'Indigenous or Native American'); INSERT INTO company (id, name, founding_year, founder_race) VALUES (2, 'Beta', 2015, 'White');\n",
            "Table Created successfully\n",
            "\n",
            "\n",
            "Similar Query: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(2010,)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "EVALUATING SAMPLE: 3\n",
            "Question: How many intelligence operations were conducted in 'Africa' in the 'IntelligenceOperations' table?\n",
            "SCHEMA: CREATE TABLE IntelligenceOperations (id INT PRIMARY KEY, operation_name VARCHAR(100), location VARCHAR(50), operation_type VARCHAR(50), start_date DATE, end_date DATE); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (1, 'Operation Red Anvil', 'Africa', 'Surveillance', '2021-01-01', '2021-03-31'); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (2, 'Operation Night Hawk', 'Europe', 'Counterintelligence', '2021-04-01', '2021-06-30');\n",
            "Original Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa';\n",
            "Generated Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa'\n",
            "\n",
            "\n",
            "Closest Distance by ChromaDB: 0.02040534248643003\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar by ChromaDB)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: How many intelligence operations were conducted in 'Africa' in the 'IntelligenceOperations' table?\n",
            "SCHEMA: CREATE TABLE IntelligenceOperations (id INT PRIMARY KEY, operation_name VARCHAR(100), location VARCHAR(50), operation_type VARCHAR(50), start_date DATE, end_date DATE); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (1, 'Operation Red Anvil', 'Africa', 'Surveillance', '2021-01-01', '2021-03-31'); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (2, 'Operation Night Hawk', 'Europe', 'Counterintelligence', '2021-04-01', '2021-06-30');\n",
            "Original Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa';\n",
            "\n",
            "\n",
            "\n",
            "Generated Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE IntelligenceOperations (id INT PRIMARY KEY, operation_name VARCHAR(100), location VARCHAR(50), operation_type VARCHAR(50), start_date DATE, end_date DATE); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (1, 'Operation Red Anvil', 'Africa', 'Surveillance', '2021-01-01', '2021-03-31'); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (2, 'Operation Night Hawk', 'Europe', 'Counterintelligence', '2021-04-01', '2021-06-30');\n",
            "Table Created successfully\n",
            "\n",
            "\n",
            "Similar Query: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(1,)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "EVALUATING SAMPLE: 4\n",
            "Question: What is the total number of space missions led by women?\n",
            "SCHEMA: CREATE TABLE space_missions (id INT, name VARCHAR(255), leader VARCHAR(255), year INT); INSERT INTO space_missions (id, name, leader, year) VALUES (1, 'Mars Rover', 'Dr. Jessica Watkins', 2022); INSERT INTO space_missions (id, name, leader, year) VALUES (2, 'ISS Expedition', 'Anousheh Ansari', 2023);\n",
            "Original Answer: SELECT COUNT(*) FROM space_missions WHERE leader IN (SELECT name FROM astronauts WHERE gender = 'Female');\n",
            "Generated Answer: SELECT COUNT(*) FROM space_missions WHERE leader = 'Anousheh Ansari'\n",
            "\n",
            "\n",
            "Closest Distance by ChromaDB: 0.45358072735233773\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar by ChromaDB)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the total number of space missions led by women?\n",
            "SCHEMA: CREATE TABLE space_missions (id INT, name VARCHAR(255), leader VARCHAR(255), year INT); INSERT INTO space_missions (id, name, leader, year) VALUES (1, 'Mars Rover', 'Dr. Jessica Watkins', 2022); INSERT INTO space_missions (id, name, leader, year) VALUES (2, 'ISS Expedition', 'Anousheh Ansari', 2023);\n",
            "Original Answer: SELECT COUNT(*) FROM space_missions WHERE leader IN (SELECT name FROM astronauts WHERE gender = 'Female');\n",
            "\n",
            "\n",
            "\n",
            "Generated Answer: SELECT COUNT(*) FROM space_missions WHERE leader = 'Anousheh Ansari'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE space_missions (id INT, name VARCHAR(255), leader VARCHAR(255), year INT); INSERT INTO space_missions (id, name, leader, year) VALUES (1, 'Mars Rover', 'Dr. Jessica Watkins', 2022); INSERT INTO space_missions (id, name, leader, year) VALUES (2, 'ISS Expedition', 'Anousheh Ansari', 2023);\n",
            "Table Created successfully\n",
            "\n",
            "\n",
            "Similar Query: SELECT COUNT(*) FROM space_missions WHERE leader IN (SELECT name FROM astronauts WHERE gender = 'Female');\n",
            "Database connected successfully\n",
            "Error executing query: relation \"astronauts\" does not exist\n",
            "LINE 1: ... space_missions WHERE leader IN (SELECT name FROM astronauts...\n",
            "                                                             ^\n",
            "\n",
            "\n",
            "\n",
            "Bad Query execution\n",
            "\n",
            "\n",
            "\n",
            "Match Accuracy: 100.00%\n",
            "\n",
            "\n",
            "Query Successes: 80.00%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}