{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlvwRtsOPPJhEG/RcCx6XP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/CLAUDE4DOT6_ORCHESTRATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.claude.com/docs/en/about-claude/models/overview\n",
        "\n",
        "https://platform.claude.com/dashboard"
      ],
      "metadata": {
        "id": "OpFsEHPb0IVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic -q\n",
        "!pip install colab-env -q"
      ],
      "metadata": {
        "id": "CgXjRs1JqQ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "colab_env.RELOAD()"
      ],
      "metadata": {
        "id": "94rToR_OqcRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE1"
      ],
      "metadata": {
        "id": "kyyTXdkPAw9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhEtO8w4qD1Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import anthropic\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# 1. SETUP CLIENT\n",
        "api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"ANTHROPIC_API_KEY environment variable not set.\")\n",
        "\n",
        "client = anthropic.Anthropic(api_key=api_key)\n",
        "MODEL_NAME = \"claude-opus-4-6\"\n",
        "\n",
        "class Orchestrator:\n",
        "    def __init__(self):\n",
        "        self.task_store = {}\n",
        "        self.results = {}\n",
        "        self.start_time = None\n",
        "        self.total_tasks = 0\n",
        "        self.token_usage = {'input': 0, 'output': 0}\n",
        "        self.completion_history = []\n",
        "\n",
        "    def get_plan(self, goal):\n",
        "        \"\"\"Phase 1: The Brain - Simple JSON output approach.\"\"\"\n",
        "        print(f\"ðŸ§  Brain: Planning via {MODEL_NAME}...\")\n",
        "\n",
        "        try:\n",
        "            # Simple approach: Just ask for JSON without complex structured output\n",
        "            message = client.messages.create(\n",
        "                model=MODEL_NAME,\n",
        "                max_tokens=4000,\n",
        "                system=\"\"\"You are an AI Architect. Plan the project into a logical Directed Acyclic Graph (DAG).\n",
        "\n",
        "                Return ONLY valid JSON with this exact structure:\n",
        "                {\n",
        "                    \"tasks\": [\n",
        "                        {\n",
        "                            \"id\": \"task1\",\n",
        "                            \"description\": \"Detailed task description\",\n",
        "                            \"dependencies\": [],  # Array of task IDs this depends on\n",
        "                            \"agent_role\": \"Role name for this task\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "                Rules:\n",
        "                1. Use simple task IDs like task1, task2, task3\n",
        "                2. Make dependencies clear and logical\n",
        "                3. Assign appropriate agent roles\n",
        "                4. Ensure it's a valid DAG (no circular dependencies)\n",
        "                5. Include 3-6 tasks for complex projects\"\"\",\n",
        "                messages=[{\"role\": \"user\", \"content\": f\"{goal}\\n\\nReturn ONLY the JSON, no other text.\"}]\n",
        "            )\n",
        "\n",
        "            # Track token usage\n",
        "            if hasattr(message, 'usage'):\n",
        "                self.token_usage['input'] += message.usage.input_tokens\n",
        "                self.token_usage['output'] += message.usage.output_tokens\n",
        "\n",
        "            # Extract and parse JSON\n",
        "            import re\n",
        "            text = message.content[0].text\n",
        "\n",
        "            # Try to find JSON in the response\n",
        "            json_match = re.search(r'\\{[\\s\\S]*\\}', text)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                plan = json.loads(json_str)\n",
        "            else:\n",
        "                # If no JSON found, try to parse the whole text\n",
        "                plan = json.loads(text)\n",
        "\n",
        "            # Validate the plan structure\n",
        "            if 'tasks' not in plan:\n",
        "                raise ValueError(\"Response missing 'tasks' key\")\n",
        "\n",
        "            for task in plan['tasks']:\n",
        "                if not all(key in task for key in ['id', 'description', 'dependencies', 'agent_role']):\n",
        "                    raise ValueError(f\"Task {task.get('id', 'unknown')} missing required fields\")\n",
        "\n",
        "                task['status'] = 'PENDING'\n",
        "                self.task_store[task['id']] = task\n",
        "\n",
        "            self.total_tasks = len(self.task_store)\n",
        "            print(f\"âœ“ Planned {self.total_tasks} tasks\")\n",
        "\n",
        "            # Validate DAG has no cycles\n",
        "            self.validate_dag()\n",
        "\n",
        "            return plan\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Planning Error: {e}\")\n",
        "            if 'message' in locals():\n",
        "                print(\"Content received:\", message.content[0].text[:500])\n",
        "            raise\n",
        "\n",
        "    def validate_dag(self):\n",
        "        \"\"\"Validate that the DAG has no circular dependencies.\"\"\"\n",
        "        visited = set()\n",
        "        recursion_stack = set()\n",
        "\n",
        "        def has_cycle(task_id):\n",
        "            visited.add(task_id)\n",
        "            recursion_stack.add(task_id)\n",
        "\n",
        "            task = self.task_store[task_id]\n",
        "            for dep in task['dependencies']:\n",
        "                if dep not in self.task_store:\n",
        "                    raise ValueError(f\"Dependency {dep} not found in tasks\")\n",
        "                if dep not in visited:\n",
        "                    if has_cycle(dep):\n",
        "                        return True\n",
        "                elif dep in recursion_stack:\n",
        "                    return True\n",
        "\n",
        "            recursion_stack.remove(task_id)\n",
        "            return False\n",
        "\n",
        "        for task_id in self.task_store:\n",
        "            if task_id not in visited:\n",
        "                if has_cycle(task_id):\n",
        "                    raise ValueError(f\"Circular dependency detected involving task {task_id}\")\n",
        "\n",
        "        print(\"âœ“ DAG validation passed (no circular dependencies)\")\n",
        "\n",
        "    def execute_task(self, task_id, retries=2):\n",
        "        \"\"\"Phase 2: The Worker - With retry logic and completion checks.\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "        print(f\"ðŸš€ Dispatching [{task['agent_role']}]: {task_id}\")\n",
        "\n",
        "        # Build context from dependencies\n",
        "        context_parts = []\n",
        "        for dep in task['dependencies']:\n",
        "            if dep in self.results:\n",
        "                # Truncate long dependency results to save tokens\n",
        "                dep_content = self.results[dep]\n",
        "                if len(dep_content) > 2000:\n",
        "                    dep_content = dep_content[:2000] + \"...\\n[Content truncated for token efficiency]\"\n",
        "                context_parts.append(f\"=== Result from {dep} ===\\n{dep_content}\")\n",
        "\n",
        "        context_text = \"\\n\\n\".join(context_parts) if context_parts else \"No dependencies\"\n",
        "\n",
        "        # Adjust tokens based on role\n",
        "        if task['agent_role'] in ['Technical Writer', 'Content Writer', 'Blog Writer']:\n",
        "            max_tokens = 4000  # More tokens for writing tasks\n",
        "        else:\n",
        "            max_tokens = 3000\n",
        "\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                response = client.messages.create(\n",
        "                    model=MODEL_NAME,\n",
        "                    max_tokens=max_tokens,\n",
        "                    temperature=0.7,\n",
        "                    system=f\"\"\"You are a specialized {task['agent_role']}.\n",
        "\n",
        "                    IMPORTANT INSTRUCTIONS:\n",
        "                    1. Provide COMPLETE, self-contained output\n",
        "                    2. Do NOT cut off mid-sentence or mid-thought\n",
        "                    3. Structure your response to be complete within token limits\n",
        "                    4. If discussing multiple sections, ensure ALL are completed\n",
        "                    5. End with proper conclusion/closure\"\"\",\n",
        "                    messages=[{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"\"\"TASK: {task['description']}\n",
        "\n",
        "DEPENDENCY CONTEXT:\n",
        "{context_text}\n",
        "\n",
        "IMPORTANT: Provide a COMPLETE, FINISHED response. Ensure:\n",
        "- No unfinished sentences\n",
        "- No \"[section continues]\" placeholders\n",
        "- All promised content is delivered\n",
        "- Proper ending/closure\n",
        "\n",
        "Your complete response:\"\"\"\n",
        "                    }]\n",
        "                )\n",
        "\n",
        "                # Track token usage\n",
        "                if hasattr(response, 'usage'):\n",
        "                    self.token_usage['input'] += response.usage.input_tokens\n",
        "                    self.token_usage['output'] += response.usage.output_tokens\n",
        "\n",
        "                result = response.content[0].text\n",
        "\n",
        "                # Quality check\n",
        "                quality_ok = self.quality_check(task_id, result)\n",
        "                if not quality_ok and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ Quality check failed for {task_id}, retrying...\")\n",
        "                    continue\n",
        "\n",
        "                self.results[task_id] = result\n",
        "                self.task_store[task_id]['status'] = 'COMPLETED'\n",
        "                self.completion_history.append({\n",
        "                    'task_id': task_id,\n",
        "                    'role': task['agent_role'],\n",
        "                    'timestamp': time.time(),\n",
        "                    'quality_check': quality_ok\n",
        "                })\n",
        "\n",
        "                print(f\"âœ… Completed: {task_id}\")\n",
        "                return\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    wait_time = 2 ** attempt  # Exponential backoff\n",
        "                    print(f\"âš ï¸ Task {task_id} failed (attempt {attempt + 1}/{retries}): {e}. Retrying in {wait_time}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"âŒ Task {task_id} permanently failed after {retries} attempts: {e}\")\n",
        "                    self.task_store[task_id]['status'] = 'FAILED'\n",
        "                    self.task_store[task_id]['error'] = str(e)\n",
        "                    # Store error result for dependencies\n",
        "                    self.results[task_id] = f\"[Task failed: {e}]\"\n",
        "\n",
        "    def quality_check(self, task_id, content):\n",
        "        \"\"\"Basic quality checks on generated content.\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "\n",
        "        issues = []\n",
        "\n",
        "        # Check for minimum length\n",
        "        if len(content.strip()) < 100:\n",
        "            issues.append(\"Content too short (<100 chars)\")\n",
        "\n",
        "        # Check for cut-off sentences (common issue)\n",
        "        trimmed_content = content.strip()\n",
        "        if trimmed_content:\n",
        "            # Check last 100 characters for proper ending\n",
        "            last_part = trimmed_content[-100:]\n",
        "            if (not any(punct in last_part[-10:] for punct in '.!?') and\n",
        "                not any(ending in last_part.lower() for ending in ['conclusion', 'summary', 'thank you', 'end', 'finish'])):\n",
        "                issues.append(\"Content may be incomplete (no proper ending)\")\n",
        "\n",
        "        # Check for obvious placeholders\n",
        "        if any(placeholder in content.lower() for placeholder in\n",
        "               ['todo:', 'placeholder', '[insert', '...', 'etc.', 'and more']):\n",
        "            if content.lower().count('...') > 3:  # Multiple ellipses\n",
        "                issues.append(\"Content contains many placeholders/ellipses\")\n",
        "\n",
        "        # Role-specific checks\n",
        "        if task['agent_role'] in ['Technical Writer', 'Blog Writer']:\n",
        "            if len(content) < 500:\n",
        "                issues.append(\"Writing task too short (<500 chars)\")\n",
        "\n",
        "        if issues:\n",
        "            print(f\"âš ï¸  Quality issues for {task_id}: {', '.join(issues)}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def show_progress_bar(self):\n",
        "        \"\"\"Visual progress bar.\"\"\"\n",
        "        completed = sum(1 for t in self.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        total = self.total_tasks\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        bar_length = 40\n",
        "        filled_length = int(bar_length * completed // total)\n",
        "        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
        "        percentage = (completed / total) * 100\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "        print(f\"\\rProgress: |{bar}| {completed}/{total} ({percentage:.1f}%) | â±ï¸ {elapsed:.1f}s\", end='', flush=True)\n",
        "\n",
        "    def print_progress(self):\n",
        "        \"\"\"Display execution progress.\"\"\"\n",
        "        completed = sum(1 for t in self.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        total = self.total_tasks\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "        percentage = (completed / total) * 100\n",
        "\n",
        "        # Show visual progress bar\n",
        "        self.show_progress_bar()\n",
        "\n",
        "        # Show detailed status (less frequently)\n",
        "        if int(elapsed) % 6 == 0:  # Every 6 seconds\n",
        "            print()  # New line after progress bar\n",
        "\n",
        "            status_counts = {}\n",
        "            running_tasks = []\n",
        "            for task_id, task in self.task_store.items():\n",
        "                status = task['status']\n",
        "                status_counts[status] = status_counts.get(status, 0) + 1\n",
        "                if status == 'RUNNING':\n",
        "                    running_tasks.append(task_id)\n",
        "\n",
        "            if running_tasks:\n",
        "                print(f\"   Active: {', '.join(running_tasks)}\")\n",
        "\n",
        "    def estimate_cost(self):\n",
        "        \"\"\"Estimate API costs.\"\"\"\n",
        "        # Claude 4.6 pricing (approximate, check current rates)\n",
        "        input_cost_per_million = 75.00  # $75 per million input tokens\n",
        "        output_cost_per_million = 375.00  # $375 per million output tokens\n",
        "\n",
        "        input_cost = (self.token_usage['input'] / 1_000_000) * input_cost_per_million\n",
        "        output_cost = (self.token_usage['output'] / 1_000_000) * output_cost_per_million\n",
        "        total_cost = input_cost + output_cost\n",
        "\n",
        "        print(f\"\\nðŸ’° Cost Estimation:\")\n",
        "        print(f\"   Input tokens: {self.token_usage['input']:,} â‰ˆ ${input_cost:.4f}\")\n",
        "        print(f\"   Output tokens: {self.token_usage['output']:,} â‰ˆ ${output_cost:.4f}\")\n",
        "        print(f\"   Total estimated: ${total_cost:.4f}\")\n",
        "\n",
        "        return total_cost\n",
        "\n",
        "    def run_orchestration(self, timeout_seconds=600):\n",
        "        \"\"\"Phase 3: The Manager loop with timeout.\"\"\"\n",
        "        print(\"âš™ï¸ Orchestrator: Starting execution loop...\")\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "            futures = {}\n",
        "\n",
        "            while True:\n",
        "                current_time = time.time()\n",
        "\n",
        "                # Check timeout\n",
        "                if current_time - self.start_time > timeout_seconds:\n",
        "                    print(f\"\\nâ° Timeout after {timeout_seconds} seconds\")\n",
        "                    break\n",
        "\n",
        "                # Show progress\n",
        "                self.print_progress()\n",
        "\n",
        "                # Find ready tasks (PENDING with all dependencies COMPLETED)\n",
        "                ready_tasks = []\n",
        "                for task_id, task in self.task_store.items():\n",
        "                    if task['status'] == 'PENDING':\n",
        "                        # Check all dependencies are COMPLETED\n",
        "                        deps_ready = True\n",
        "                        for dep in task['dependencies']:\n",
        "                            if self.task_store.get(dep, {}).get('status') != 'COMPLETED':\n",
        "                                deps_ready = False\n",
        "                                break\n",
        "\n",
        "                        if deps_ready:\n",
        "                            ready_tasks.append(task_id)\n",
        "\n",
        "                # Submit ready tasks\n",
        "                for task_id in ready_tasks:\n",
        "                    if task_id not in futures or futures[task_id].done():\n",
        "                        self.task_store[task_id]['status'] = 'RUNNING'\n",
        "                        futures[task_id] = executor.submit(self.execute_task, task_id)\n",
        "\n",
        "                # Check if all tasks are done\n",
        "                all_done = all(\n",
        "                    t['status'] in ['COMPLETED', 'FAILED']\n",
        "                    for t in self.task_store.values()\n",
        "                )\n",
        "\n",
        "                if all_done:\n",
        "                    print(\"\\n\\nðŸŽ¯ All tasks completed!\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.5)  # Small delay to prevent busy waiting\n",
        "\n",
        "        # Final progress update\n",
        "        print()  # Clear progress bar line\n",
        "        self.show_progress_bar()\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        return self.results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    orch = Orchestrator()\n",
        "\n",
        "    # Example goal\n",
        "    user_goal = \"Create a 3-step technical blog post about Kubernetes security: 1. Research, 2. Write, 3. Review.\"\n",
        "\n",
        "    try:\n",
        "        print(\"ðŸš€ Starting DAG Orchestrator\")\n",
        "        print(f\"Goal: {user_goal}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        plan = orch.get_plan(user_goal)\n",
        "\n",
        "        # Show the plan\n",
        "        print(\"\\nðŸ“‹ Task Plan:\")\n",
        "        for i, task in enumerate(plan['tasks'], 1):\n",
        "            deps = ', '.join(task['dependencies']) if task['dependencies'] else 'None'\n",
        "            print(f\"  {i}. {task['id']}: {task['description'][:80]}...\")\n",
        "            print(f\"     Role: {task['agent_role']}, Depends on: {deps}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Starting execution...\")\n",
        "        results = orch.run_orchestration()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\nðŸ BUILD COMPLETE\\n\" + \"=\"*50)\n",
        "\n",
        "        # Show results summary\n",
        "        successful = sum(1 for t in orch.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        failed = sum(1 for t in orch.task_store.values() if t['status'] == 'FAILED')\n",
        "        print(f\"\\nðŸ“ˆ Summary: {successful} successful, {failed} failed\")\n",
        "\n",
        "        # Estimate costs\n",
        "        orch.estimate_cost()\n",
        "\n",
        "        # Save results to files\n",
        "        os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\nðŸ“‚ Output Files:\")\n",
        "        for tid, content in results.items():\n",
        "            status = orch.task_store[tid]['status']\n",
        "            role = orch.task_store[tid]['agent_role']\n",
        "\n",
        "            # Clean role for filename\n",
        "            clean_role = role.replace(' ', '_').replace('/', '_')\n",
        "            filename = f\"output/{tid}_{clean_role}.txt\"\n",
        "\n",
        "            # Save to file\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"Task: {tid}\\n\")\n",
        "                f.write(f\"Role: {role}\\n\")\n",
        "                f.write(f\"Status: {status}\\n\")\n",
        "                f.write(f\"Generated: {time.ctime()}\\n\")\n",
        "                f.write(\"=\"*60 + \"\\n\\n\")\n",
        "                f.write(content)\n",
        "\n",
        "            print(f\"  {tid}: {filename}\")\n",
        "\n",
        "        # Show completion timeline\n",
        "        print(\"\\nâ±ï¸ Completion Timeline:\")\n",
        "        for entry in orch.completion_history:\n",
        "            elapsed = entry['timestamp'] - orch.start_time\n",
        "            quality = \"âœ“\" if entry['quality_check'] else \"âš \"\n",
        "            print(f\"  {elapsed:6.1f}s | {quality} {entry['task_id']} ({entry['role']})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ FATAL ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50 + \"\\nðŸ BUILD COMPLETE\\n\" + \"=\"*50)\n",
        "\n",
        "# Show results summary\n",
        "successful = sum(1 for t in orch.task_store.values() if t['status'] == 'COMPLETED')\n",
        "failed = sum(1 for t in orch.task_store.values() if t['status'] == 'FAILED')\n",
        "print(f\"\\nðŸ“ˆ Summary: {successful} successful, {failed} failed\")\n",
        "\n",
        "# Estimate costs\n",
        "orch.estimate_cost()\n",
        "\n",
        "# Save results to files\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nðŸ“‚ Output Files:\")\n",
        "for tid, content in results.items():\n",
        "    status = orch.task_store[tid]['status']\n",
        "    role = orch.task_store[tid]['agent_role']\n",
        "\n",
        "    # Clean role for filename\n",
        "    clean_role = role.replace(' ', '_').replace('/', '_')\n",
        "    filename = f\"output/{tid}_{clean_role}.txt\"\n",
        "\n",
        "    # Save to file\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"Task: {tid}\\n\")\n",
        "        f.write(f\"Role: {role}\\n\")\n",
        "        f.write(f\"Status: {status}\\n\")\n",
        "        f.write(f\"Generated: {time.ctime()}\\n\")\n",
        "        f.write(\"=\"*60 + \"\\n\\n\")\n",
        "        f.write(content)\n",
        "\n",
        "    print(f\"  {tid}: {filename}\")\n",
        "\n",
        "# Show completion timeline\n",
        "print(\"\\nâ±ï¸ Completion Timeline:\")\n",
        "for entry in orch.completion_history:\n",
        "    elapsed = entry['timestamp'] - orch.start_time\n",
        "    quality = \"âœ“\" if entry['quality_check'] else \"âš \"\n",
        "    print(f\"  {elapsed:6.1f}s | {quality} {entry['task_id']} ({entry['role']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx-t-uNeAW8J",
        "outputId": "5a69d9a3-befe-48a5-94b1-971ad0b78adf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ðŸ BUILD COMPLETE\n",
            "==================================================\n",
            "\n",
            "ðŸ“ˆ Summary: 3 successful, 0 failed\n",
            "\n",
            "ðŸ’° Cost Estimation:\n",
            "   Input tokens: 3,570 â‰ˆ $0.2677\n",
            "   Output tokens: 20,334 â‰ˆ $7.6253\n",
            "   Total estimated: $7.8930\n",
            "\n",
            "ðŸ“‚ Output Files:\n",
            "  task1: output/task1_Technical_Researcher.txt\n",
            "  task2: output/task2_Technical_Writer.txt\n",
            "  task3: output/task3_Technical_Editor.txt\n",
            "\n",
            "â±ï¸ Completion Timeline:\n",
            "   121.2s | âš  task1 (Technical Researcher)\n",
            "   251.6s | âš  task2 (Technical Writer)\n",
            "   374.9s | âš  task3 (Technical Editor)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE2"
      ],
      "metadata": {
        "id": "_HTnhB4x7wAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "import anthropic\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. SETUP CLIENT\n",
        "api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"ANTHROPIC_API_KEY environment variable not set.\")\n",
        "\n",
        "client = anthropic.Anthropic(api_key=api_key)\n",
        "MODEL_NAME = \"claude-opus-4-6\"\n",
        "\n",
        "# H2E Framework Components\n",
        "@dataclass\n",
        "class ExpertIntentVector:\n",
        "    \"\"\"NEZ (Normalized Expert Zone): Encoded expert intent\"\"\"\n",
        "    task_id: str\n",
        "    role: str\n",
        "    vector: np.ndarray\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    description: str = \"\"\n",
        "    gold_standard_examples: List[str] = field(default_factory=list)\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert to JSON-serializable dictionary\"\"\"\n",
        "        return {\n",
        "            \"task_id\": self.task_id,\n",
        "            \"role\": self.role,\n",
        "            \"vector\": self.vector.tolist(),\n",
        "            \"timestamp\": self.timestamp.isoformat(),\n",
        "            \"description\": self.description,\n",
        "            \"gold_standard_examples\": self.gold_standard_examples\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class AlignmentScore:\n",
        "    \"\"\"SROI (Semantic ROI): Alignment measurement\"\"\"\n",
        "    task_id: str\n",
        "    score: float\n",
        "    threshold_required: float\n",
        "    passed: bool\n",
        "    vector_distance: float\n",
        "    explanation: str = \"\"\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert to JSON-serializable dictionary\"\"\"\n",
        "        return {\n",
        "            \"task_id\": self.task_id,\n",
        "            \"score\": float(self.score),\n",
        "            \"threshold_required\": float(self.threshold_required),\n",
        "            \"passed\": bool(self.passed),\n",
        "            \"vector_distance\": float(self.vector_distance),\n",
        "            \"explanation\": self.explanation\n",
        "        }\n",
        "\n",
        "class H2EAccountabilityEngine:\n",
        "    \"\"\"H2E-inspired accountability framework\"\"\"\n",
        "\n",
        "    def __init__(self, calibration_mode: bool = False):\n",
        "      self.expert_vectors: Dict[str, ExpertIntentVector] = {}  # NEZ: Stores expert intent vectors\n",
        "      self.alignment_history: List[AlignmentScore] = []  # SROI: Tracks all alignment scores\n",
        "      self.calibration_mode = calibration_mode  # Controls if we're in calibration or production mode\n",
        "      self.calibration_data = []  # Collects data for threshold calibration\n",
        "\n",
        "    def capture_expert_intent(self, task_id: str, role: str,\n",
        "                             description: str, examples: List[str]) -> ExpertIntentVector:\n",
        "        \"\"\"NEZ: Capture expert intent as encoded vector\"\"\"\n",
        "        intent_text = f\"{role}: {description}. Examples: {' '.join(examples[:3])}\"\n",
        "        vector = self._text_to_vector_enhanced(intent_text)\n",
        "\n",
        "        expert_vector = ExpertIntentVector(\n",
        "            task_id=task_id,\n",
        "            role=role,\n",
        "            vector=vector,\n",
        "            description=description,\n",
        "            gold_standard_examples=examples\n",
        "        )\n",
        "\n",
        "        self.expert_vectors[task_id] = expert_vector\n",
        "        print(f\"ðŸ“Š H2E/NEZ: Captured expert intent for {task_id} ({role})\")\n",
        "        return expert_vector\n",
        "\n",
        "    def _text_to_vector_enhanced(self, text: str) -> np.ndarray:\n",
        "        \"\"\"Enhanced vector encoding with better semantic features\"\"\"\n",
        "        text = text.lower().strip()\n",
        "\n",
        "        # Split into words and remove very short words\n",
        "        words = [word for word in text.split() if len(word) > 2]\n",
        "\n",
        "        # Create 768-dimensional vector (like common embedding sizes)\n",
        "        vector = np.zeros(768)\n",
        "\n",
        "        # Use multiple hash functions for better distribution\n",
        "        for i, word in enumerate(words[:100]):  # Limit to first 100 words\n",
        "            # Use different hash seeds for better coverage\n",
        "            for seed in [0, 1, 2]:\n",
        "                hash_val = hash(f\"{word}_{seed}\") % 10000\n",
        "                pos = (hash_val + seed * 100) % 768\n",
        "                val = (hash_val % 100) / 100.0\n",
        "                vector[pos] += val\n",
        "\n",
        "        # Add position weighting (earlier words more important)\n",
        "        for i, word in enumerate(words[:50]):\n",
        "            pos_weight = 1.0 - (i / 100.0)  # Decrease weight with position\n",
        "            hash_val = hash(word) % 10000\n",
        "            pos = hash_val % 768\n",
        "            vector[pos] += pos_weight * 0.5\n",
        "\n",
        "        # Normalize with L2 norm\n",
        "        norm = np.linalg.norm(vector)\n",
        "        if norm > 0:\n",
        "            vector = vector / norm\n",
        "        else:\n",
        "            # Fallback to uniform distribution\n",
        "            vector = np.ones(768) / np.sqrt(768)\n",
        "\n",
        "        return vector\n",
        "\n",
        "    def calculate_sroi(self, task_id: str, generated_output: str,\n",
        "                      task_description: str = \"\") -> AlignmentScore:\n",
        "        \"\"\"SROI: Calculate alignment with expert intent\"\"\"\n",
        "\n",
        "        if task_id not in self.expert_vectors:\n",
        "            # Create expert vector if not exists\n",
        "            self.capture_expert_intent(\n",
        "                task_id=task_id,\n",
        "                role=\"Unknown\",\n",
        "                description=task_description or f\"Task {task_id}\",\n",
        "                examples=[generated_output[:500]]\n",
        "            )\n",
        "\n",
        "        expert_vector = self.expert_vectors[task_id]\n",
        "        output_vector = self._text_to_vector_enhanced(generated_output)\n",
        "\n",
        "        # Calculate cosine similarity with smoothing\n",
        "        similarity = np.dot(expert_vector.vector, output_vector)\n",
        "\n",
        "        # Apply sigmoid-like function for better distribution\n",
        "        similarity = 1 / (1 + np.exp(-10 * (similarity - 0.5)))\n",
        "\n",
        "        # Ensure bounds\n",
        "        similarity = max(0.1, min(0.9, similarity))\n",
        "\n",
        "        # Get threshold (lower in calibration mode)\n",
        "        threshold = self._get_required_threshold(expert_vector.role, task_description, similarity)\n",
        "\n",
        "        # In calibration mode, collect data without failing\n",
        "        if self.calibration_mode:\n",
        "            passed = True\n",
        "            self.calibration_data.append({\n",
        "                \"task_id\": task_id,\n",
        "                \"role\": expert_vector.role,\n",
        "                \"score\": similarity,\n",
        "                \"description\": task_description\n",
        "            })\n",
        "        else:\n",
        "            passed = similarity >= threshold\n",
        "\n",
        "        # Calculate vector distance\n",
        "        distance = np.linalg.norm(expert_vector.vector - output_vector)\n",
        "\n",
        "        # Generate explanation based on score\n",
        "        if similarity >= 0.7:\n",
        "            explanation = \"Excellent alignment with expert intent\"\n",
        "        elif similarity >= 0.55:\n",
        "            explanation = \"Good alignment, minor deviations\"\n",
        "        elif similarity >= 0.4:\n",
        "            explanation = \"Moderate alignment, some semantic drift\"\n",
        "        elif similarity >= 0.25:\n",
        "            explanation = \"Poor alignment - significant semantic drift\"\n",
        "        else:\n",
        "            explanation = \"Very poor alignment - major semantic drift\"\n",
        "\n",
        "        score = AlignmentScore(\n",
        "            task_id=task_id,\n",
        "            score=similarity,\n",
        "            threshold_required=threshold,\n",
        "            passed=passed,\n",
        "            vector_distance=distance,\n",
        "            explanation=explanation\n",
        "        )\n",
        "\n",
        "        self.alignment_history.append(score)\n",
        "        return score\n",
        "\n",
        "    def _get_required_threshold(self, role: str, description: str, current_score: float = None) -> float:\n",
        "        \"\"\"Get adaptive threshold based on role, risk, and calibration data\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        # Base thresholds calibrated from previous runs\n",
        "        base_thresholds = {\n",
        "            \"Research Analyst\": 0.532,\n",
        "            \"Technical Writer\": 0.350,\n",
        "            \"Technical Reviewer\": 0.656,\n",
        "            \"Technical Researcher\": 0.45,\n",
        "            \"Writer\": 0.50,\n",
        "            \"Editor\": 0.55,\n",
        "            \"Reviewer\": 0.55\n",
        "        }\n",
        "\n",
        "        # Default if role not found\n",
        "        threshold = base_thresholds.get(role, 0.50)\n",
        "\n",
        "        # Apply risk multiplier for security content\n",
        "        description_lower = description.lower()\n",
        "        security_keywords = [\"security\", \"vulnerability\", \"risk\", \"attack\", \"breach\", \"hack\"]\n",
        "        if any(keyword in description_lower for keyword in security_keywords):\n",
        "            threshold *= 1.15  # 15% higher for security\n",
        "            threshold = min(threshold, 0.75)\n",
        "\n",
        "        # If we have calibration data, adjust based on historical performance\n",
        "        if self.calibration_data and current_score is not None:\n",
        "            # Find similar tasks in calibration data\n",
        "            similar_scores = [\n",
        "                d[\"score\"] for d in self.calibration_data\n",
        "                if d[\"role\"] == role and abs(d[\"score\"] - current_score) < 0.2\n",
        "            ]\n",
        "            if similar_scores:\n",
        "                avg_similar = np.mean(similar_scores)\n",
        "                # Adjust threshold towards historical average\n",
        "                threshold = threshold * 0.7 + avg_similar * 0.3\n",
        "\n",
        "        return round(threshold, 3)\n",
        "\n",
        "    def analyze_calibration_data(self):\n",
        "        \"\"\"Analyze calibration data to recommend thresholds\"\"\"\n",
        "        if not self.calibration_data:\n",
        "            print(\"âš ï¸ No calibration data available\")\n",
        "            return\n",
        "\n",
        "        # Group by role\n",
        "        role_data = {}\n",
        "        for entry in self.calibration_data:\n",
        "            role = entry[\"role\"]\n",
        "            if role not in role_data:\n",
        "                role_data[role] = []\n",
        "            role_data[role].append(entry[\"score\"])\n",
        "\n",
        "        print(\"\\nðŸ”§ H2E Calibration Analysis:\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        recommendations = {}\n",
        "        for role, scores in role_data.items():\n",
        "            avg_score = np.mean(scores)\n",
        "            std_score = np.std(scores) if len(scores) > 1 else 0\n",
        "            min_score = min(scores)\n",
        "            max_score = max(scores)\n",
        "\n",
        "            # Recommended threshold: 1 standard deviation below mean, but not too low\n",
        "            recommended = max(0.35, avg_score - std_score/2)\n",
        "\n",
        "            recommendations[role] = recommended\n",
        "\n",
        "            print(f\"\\n  {role}:\")\n",
        "            print(f\"    Samples: {len(scores)}\")\n",
        "            print(f\"    Average: {avg_score:.3f}\")\n",
        "            print(f\"    Range: {min_score:.3f} - {max_score:.3f}\")\n",
        "            print(f\"    Recommended threshold: {recommended:.3f}\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def generate_accountability_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate H2E accountability report\"\"\"\n",
        "        if not self.alignment_history:\n",
        "            return {\"status\": \"No alignment data available\"}\n",
        "\n",
        "        scores = [s.score for s in self.alignment_history]\n",
        "        avg_score = np.mean(scores) if scores else 0\n",
        "        std_score = np.std(scores) if len(scores) > 1 else 0\n",
        "\n",
        "        # Get unique final scores (not retries)\n",
        "        final_scores = {}\n",
        "        for score in reversed(self.alignment_history):\n",
        "            if score.task_id not in final_scores:\n",
        "                final_scores[score.task_id] = score\n",
        "\n",
        "        pass_rate = np.mean([1 if s.passed else 0 for s in final_scores.values()])\n",
        "\n",
        "        report = {\n",
        "            \"h2e_framework_report\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"calibration_mode\": self.calibration_mode,\n",
        "                \"total_tasks_evaluated\": len(self.alignment_history),\n",
        "                \"unique_tasks\": len(final_scores),\n",
        "                \"average_sroi_score\": float(round(avg_score, 4)),\n",
        "                \"sroi_std_dev\": float(round(std_score, 4)),\n",
        "                \"alignment_pass_rate\": f\"{pass_rate*100:.1f}%\",\n",
        "                \"expert_vectors_captured\": len(self.expert_vectors),\n",
        "                \"recommended_threshold\": float(round(max(0.35, avg_score - std_score/2), 3)),\n",
        "                \"task_breakdown\": []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Add task breakdown\n",
        "        for task_id, score in final_scores.items():\n",
        "            report[\"h2e_framework_report\"][\"task_breakdown\"].append({\n",
        "                \"task_id\": task_id,\n",
        "                \"role\": self.expert_vectors.get(task_id, ExpertIntentVector(\"\", \"\", np.zeros(1))).role,\n",
        "                \"sroi_score\": float(round(score.score, 3)),\n",
        "                \"required_threshold\": float(score.threshold_required),\n",
        "                \"passed\": bool(score.passed),\n",
        "                \"explanation\": score.explanation\n",
        "            })\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_report(self, filename: str = \"h2e_accountability_report.json\"):\n",
        "        \"\"\"Save H2E report to file\"\"\"\n",
        "        report = self.generate_accountability_report()\n",
        "\n",
        "        class H2EJSONEncoder(json.JSONEncoder):\n",
        "            def default(self, obj):\n",
        "                if isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                if isinstance(obj, datetime):\n",
        "                    return obj.isoformat()\n",
        "                if isinstance(obj, (ExpertIntentVector, AlignmentScore)):\n",
        "                    return obj.to_dict()\n",
        "                return super().default(obj)\n",
        "\n",
        "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else \".\", exist_ok=True)\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(report, f, indent=2, cls=H2EJSONEncoder)\n",
        "\n",
        "        print(f\"âœ“ H2E report saved to {filename}\")\n",
        "        return report\n",
        "\n",
        "class Orchestrator:\n",
        "    def __init__(self, calibration_mode: bool = False):\n",
        "        self.task_store = {}\n",
        "        self.results = {}\n",
        "        self.start_time = None\n",
        "        self.total_tasks = 0\n",
        "        self.token_usage = {'input': 0, 'output': 0}\n",
        "        self.completion_history = []\n",
        "\n",
        "        # H2E Accountability Engine\n",
        "        self.h2e = H2EAccountabilityEngine(calibration_mode=calibration_mode)\n",
        "        self.calibration_mode = calibration_mode\n",
        "\n",
        "        # Enhanced expert templates based on analysis\n",
        "        self.expert_templates = {\n",
        "            \"Research Analyst\": {\n",
        "                \"description\": \"Comprehensive research with structured findings\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Research Summary: This analysis examines [topic] using [methods]. Key findings include: 1) [finding] 2) [finding] 3) [finding]\",\n",
        "                    \"Methodology: Data was collected from [sources] and analyzed using [techniques]\",\n",
        "                    \"Conclusion: Based on the research, we recommend [recommendations]\"\n",
        "                ]\n",
        "            },\n",
        "            \"Technical Writer\": {\n",
        "                \"description\": \"Clear technical documentation with examples\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Introduction: Overview of [topic] and its importance\",\n",
        "                    \"Implementation: Step-by-step instructions with code examples: ```python\\n# Example code\\nprint('Hello World')\\n```\",\n",
        "                    \"Best Practices: Key recommendations for successful implementation\"\n",
        "                ]\n",
        "            },\n",
        "            \"Technical Reviewer\": {\n",
        "                \"description\": \"Thorough technical review with specific feedback\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Overall Assessment: The document is [assessment] with strengths in [areas] and areas for improvement in [areas]\",\n",
        "                    \"Technical Accuracy: Verified [claims] and validated [examples]\",\n",
        "                    \"Suggestions: Recommend [specific improvements] for better clarity and accuracy\"\n",
        "                ]\n",
        "            },\n",
        "            \"Technical Researcher\": {\n",
        "                \"description\": \"In-depth technical research\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Research Summary: This analysis examines [topic] using [methods]. Key findings include: 1) [finding] 2) [finding] 3) [finding]\",\n",
        "                    \"Methodology: Data was collected from [sources] and analyzed using [techniques]\",\n",
        "                    \"Conclusion: Based on the research, we recommend [recommendations]\"\n",
        "                ]\n",
        "            },\n",
        "            \"Writer\": {\n",
        "                \"description\": \"Professional writing\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Introduction: Overview of [topic] and its importance\",\n",
        "                    \"Implementation: Step-by-step instructions with code examples: ```python\\n# Example code\\nprint('Hello World')\\n```\",\n",
        "                    \"Best Practices: Key recommendations for successful implementation\"\n",
        "                ]\n",
        "            },\n",
        "            \"Editor\": {\n",
        "                \"description\": \"Editorial review\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Overall Assessment: The document is [assessment] with strengths in [areas] and areas for improvement in [areas]\",\n",
        "                    \"Technical Accuracy: Verified [claims] and validated [examples]\",\n",
        "                    \"Suggestions: Recommend [specific improvements] for better clarity and accuracy\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def get_plan(self, goal):\n",
        "        \"\"\"Phase 1: Planning\"\"\"\n",
        "        print(f\"ðŸ§  Brain: Planning via {MODEL_NAME}...\")\n",
        "\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=MODEL_NAME,\n",
        "                max_tokens=4000,\n",
        "                system=\"\"\"You are an AI Architect. Plan the project into a logical Directed Acyclic Graph (DAG).\n",
        "\n",
        "                Return ONLY valid JSON with this exact structure:\n",
        "                {\n",
        "                    \"tasks\": [\n",
        "                        {\n",
        "                            \"id\": \"task1\",\n",
        "                            \"description\": \"Detailed task description\",\n",
        "                            \"dependencies\": [],\n",
        "                            \"agent_role\": \"Role name\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "                Rules:\n",
        "                1. Use simple task IDs like task1, task2, task3\n",
        "                2. Make dependencies clear and logical\n",
        "                3. Assign agent roles that match the task (Research Analyst, Technical Writer, Technical Reviewer, etc.)\n",
        "                4. Ensure it's a valid DAG (no circular dependencies)\n",
        "                5. Include 3-5 tasks total\"\"\",\n",
        "                messages=[{\"role\": \"user\", \"content\": f\"{goal}\\n\\nReturn ONLY the JSON, no other text.\"}]\n",
        "            )\n",
        "\n",
        "            if hasattr(message, 'usage'):\n",
        "                self.token_usage['input'] += message.usage.input_tokens\n",
        "                self.token_usage['output'] += message.usage.output_tokens\n",
        "\n",
        "            import re\n",
        "            text = message.content[0].text\n",
        "\n",
        "            json_match = re.search(r'\\{[\\s\\S]*\\}', text)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                plan = json.loads(json_str)\n",
        "            else:\n",
        "                plan = json.loads(text)\n",
        "\n",
        "            if 'tasks' not in plan:\n",
        "                raise ValueError(\"Response missing 'tasks' key\")\n",
        "\n",
        "            for task in plan['tasks']:\n",
        "                if not all(key in task for key in ['id', 'description', 'dependencies', 'agent_role']):\n",
        "                    raise ValueError(f\"Task {task.get('id', 'unknown')} missing required fields\")\n",
        "\n",
        "                task['status'] = 'PENDING'\n",
        "                self.task_store[task['id']] = task\n",
        "\n",
        "                role = task['agent_role']\n",
        "\n",
        "                # Find matching template\n",
        "                template_role = None\n",
        "                for template_key in self.expert_templates.keys():\n",
        "                    if template_key.lower() in role.lower():\n",
        "                        template_role = template_key\n",
        "                        break\n",
        "\n",
        "                if template_role and template_role in self.expert_templates:\n",
        "                    template = self.expert_templates[template_role]\n",
        "                    self.h2e.capture_expert_intent(\n",
        "                        task_id=task['id'],\n",
        "                        role=role,\n",
        "                        description=task['description'],\n",
        "                        examples=template['gold_standard_examples']\n",
        "                    )\n",
        "                else:\n",
        "                    # Use default template\n",
        "                    self.h2e.capture_expert_intent(\n",
        "                        task_id=task['id'],\n",
        "                        role=role,\n",
        "                        description=task['description'],\n",
        "                        examples=[f\"Professional output for {role} focusing on {task['description'][:50]}...\"]\n",
        "                    )\n",
        "\n",
        "            self.total_tasks = len(self.task_store)\n",
        "            print(f\"âœ“ Planned {self.total_tasks} tasks\")\n",
        "\n",
        "            self.validate_dag()\n",
        "\n",
        "            return plan\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Planning Error: {e}\")\n",
        "            if 'message' in locals():\n",
        "                print(\"Content received:\", message.content[0].text[:500])\n",
        "            raise\n",
        "\n",
        "    def validate_dag(self):\n",
        "        \"\"\"Validate that the DAG has no circular dependencies.\"\"\"\n",
        "        visited = set()\n",
        "        recursion_stack = set()\n",
        "\n",
        "        def has_cycle(task_id):\n",
        "            visited.add(task_id)\n",
        "            recursion_stack.add(task_id)\n",
        "\n",
        "            task = self.task_store[task_id]\n",
        "            for dep in task['dependencies']:\n",
        "                if dep not in self.task_store:\n",
        "                    raise ValueError(f\"Dependency {dep} not found in tasks\")\n",
        "                if dep not in visited:\n",
        "                    if has_cycle(dep):\n",
        "                        return True\n",
        "                elif dep in recursion_stack:\n",
        "                    return True\n",
        "\n",
        "            recursion_stack.remove(task_id)\n",
        "            return False\n",
        "\n",
        "        for task_id in self.task_store:\n",
        "            if task_id not in visited:\n",
        "                if has_cycle(task_id):\n",
        "                    raise ValueError(f\"Circular dependency detected involving task {task_id}\")\n",
        "\n",
        "        print(\"âœ“ DAG validation passed (no circular dependencies)\")\n",
        "\n",
        "    def execute_task(self, task_id, retries=2):\n",
        "        \"\"\"Phase 2: Task execution with H2E accountability\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "        print(f\"ðŸš€ Dispatching [{task['agent_role']}]: {task_id}\")\n",
        "\n",
        "        # Build context from dependencies\n",
        "        context_parts = []\n",
        "        for dep in task['dependencies']:\n",
        "            if dep in self.results:\n",
        "                dep_content = self.results[dep]\n",
        "                if len(dep_content) > 1200:\n",
        "                    dep_content = dep_content[:1200] + \"...\\n[Content truncated for efficiency]\"\n",
        "                context_parts.append(f\"=== Result from {dep} ===\\n{dep_content}\")\n",
        "\n",
        "        context_text = \"\\n\\n\".join(context_parts) if context_parts else \"No dependencies\"\n",
        "\n",
        "        # Adjust tokens based on role\n",
        "        if 'Writer' in task['agent_role']:\n",
        "            max_tokens = 4000\n",
        "        else:\n",
        "            max_tokens = 3000\n",
        "\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                # Enhanced prompt for better alignment\n",
        "                system_prompt = f\"\"\"You are a {task['agent_role']}. Your task is: {task['description']}\n",
        "\n",
        "H2E ACCOUNTABILITY REQUIREMENTS:\n",
        "1. Provide a COMPLETE, self-contained response\n",
        "2. Use clear structure with headings/sections\n",
        "3. Include specific examples or evidence\n",
        "4. End with a proper conclusion or summary\n",
        "5. Maintain professional tone and technical accuracy\n",
        "\n",
        "OUTPUT FORMAT GUIDELINES:\n",
        "- Start with a clear title or heading\n",
        "- Use sections like Introduction, Main Content, Conclusion\n",
        "- Include bullet points or numbered lists where helpful\n",
        "- Add code examples in markdown format if relevant\n",
        "- Ensure the response is comprehensive and addresses all aspects of the task\"\"\"\n",
        "\n",
        "                user_prompt = f\"\"\"TASK DESCRIPTION:\n",
        "{task['description']}\n",
        "\n",
        "CONTEXT FROM DEPENDENCIES:\n",
        "{context_text}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Provide a complete, well-structured response\n",
        "2. Use appropriate formatting (headings, lists, etc.)\n",
        "3. Include specific details and examples\n",
        "4. Ensure technical accuracy\n",
        "5. Conclude with a summary or key takeaways\n",
        "\n",
        "Your professional response:\"\"\"\n",
        "\n",
        "                response = client.messages.create(\n",
        "                    model=MODEL_NAME,\n",
        "                    max_tokens=max_tokens,\n",
        "                    temperature=0.7,\n",
        "                    system=system_prompt,\n",
        "                    messages=[{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": user_prompt\n",
        "                    }]\n",
        "                )\n",
        "\n",
        "                if hasattr(response, 'usage'):\n",
        "                    self.token_usage['input'] += response.usage.input_tokens\n",
        "                    self.token_usage['output'] += response.usage.output_tokens\n",
        "\n",
        "                result = response.content[0].text\n",
        "\n",
        "                # H2E: Calculate alignment score\n",
        "                alignment_score = self.h2e.calculate_sroi(\n",
        "                    task_id=task_id,\n",
        "                    generated_output=result,\n",
        "                    task_description=task['description']\n",
        "                )\n",
        "\n",
        "                print(f\"   H2E/SROI: Alignment score: {alignment_score.score:.3f} \" +\n",
        "                      f\"(Required: {alignment_score.threshold_required}) - {alignment_score.explanation}\")\n",
        "\n",
        "                # Quality check\n",
        "                quality_ok = self.quality_check(task_id, result, alignment_score)\n",
        "\n",
        "                # In calibration mode, don't retry for alignment failures\n",
        "                if not self.calibration_mode and not alignment_score.passed and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ H2E alignment failed for {task_id} (score: {alignment_score.score:.3f}), retrying...\")\n",
        "                    continue\n",
        "\n",
        "                if not quality_ok and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ Quality check failed for {task_id}, retrying...\")\n",
        "                    continue\n",
        "\n",
        "                self.results[task_id] = result\n",
        "                self.task_store[task_id]['status'] = 'COMPLETED'\n",
        "                self.task_store[task_id]['h2e_score'] = alignment_score.score\n",
        "                self.task_store[task_id]['h2e_passed'] = alignment_score.passed\n",
        "\n",
        "                self.completion_history.append({\n",
        "                    'task_id': task_id,\n",
        "                    'role': task['agent_role'],\n",
        "                    'timestamp': time.time(),\n",
        "                    'quality_check': quality_ok,\n",
        "                    'h2e_score': alignment_score.score,\n",
        "                    'h2e_passed': alignment_score.passed,\n",
        "                    'attempt': attempt + 1\n",
        "                })\n",
        "\n",
        "                status_icon = \"ðŸ“Š\" if self.calibration_mode else \"âœ…\"\n",
        "                print(f\"{status_icon} Completed: {task_id} (H2E: {alignment_score.score:.3f}, Attempt: {attempt + 1})\")\n",
        "                return\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    wait_time = 2 ** attempt\n",
        "                    print(f\"âš ï¸ Task {task_id} failed (attempt {attempt + 1}/{retries}): {e}. Retrying in {wait_time}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"âŒ Task {task_id} permanently failed after {retries} attempts: {e}\")\n",
        "                    self.task_store[task_id]['status'] = 'FAILED'\n",
        "                    self.task_store[task_id]['error'] = str(e)\n",
        "                    self.results[task_id] = f\"[Task failed: {e}]\"\n",
        "\n",
        "    def quality_check(self, task_id, content, alignment_score=None):\n",
        "        \"\"\"Enhanced quality checks with H2E alignment\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "\n",
        "        issues = []\n",
        "\n",
        "        # Basic length check (role-specific)\n",
        "        if 'Writer' in task['agent_role']:\n",
        "            if len(content.strip()) < 600:\n",
        "                issues.append(\"Writing task too short (<600 chars)\")\n",
        "        else:\n",
        "            if len(content.strip()) < 300:\n",
        "                issues.append(\"Content too short (<300 chars)\")\n",
        "\n",
        "        # H2E alignment check (skip in calibration mode)\n",
        "        if not self.calibration_mode and alignment_score and not alignment_score.passed:\n",
        "            issues.append(f\"H2E alignment failed (score: {alignment_score.score:.3f}, required: {alignment_score.threshold_required})\")\n",
        "\n",
        "        # Check for structure\n",
        "        has_structure = any(marker in content for marker in ['#', '##', '###', '1.', '2.', '3.', '- ', '* ', 'â€¢ '])\n",
        "        if not has_structure and len(content) > 400:\n",
        "            issues.append(\"Content lacks clear structure (no headings/lists)\")\n",
        "\n",
        "        # Check for completeness (proper ending)\n",
        "        trimmed_content = content.strip()\n",
        "        if trimmed_content:\n",
        "            # Check if ends with proper punctuation\n",
        "            if not any(trimmed_content.endswith(punct) for punct in ['.', '!', '?', '```']):\n",
        "                # Check last 50 chars for conclusion indicators\n",
        "                last_part = trimmed_content[-50:].lower()\n",
        "                if not any(indicator in last_part for indicator in ['conclusion', 'summary', 'finally', 'in summary']):\n",
        "                    issues.append(\"Content may lack proper conclusion\")\n",
        "\n",
        "        if issues:\n",
        "            print(f\"âš ï¸  Quality issues for {task_id}: {', '.join(issues)}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def show_progress_bar(self):\n",
        "        \"\"\"Visual progress bar with H2E indicators\"\"\"\n",
        "        completed = sum(1 for t in self.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        total = self.total_tasks\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        h2e_scores = [t.get('h2e_score', 0) for t in self.task_store.values()\n",
        "                     if t['status'] == 'COMPLETED' and 'h2e_score' in t]\n",
        "        avg_h2e = np.mean(h2e_scores) if h2e_scores else 0\n",
        "\n",
        "        bar_length = 40\n",
        "        filled_length = int(bar_length * completed // total)\n",
        "        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
        "        percentage = (completed / total) * 100\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "\n",
        "        mode_indicator = \" [CAL]\" if self.calibration_mode else \"\"\n",
        "        h2e_indicator = f\" | H2E: {avg_h2e:.3f}\" if h2e_scores else \"\"\n",
        "        print(f\"\\rProgress{mode_indicator}: |{bar}| {completed}/{total} ({percentage:.1f}%){h2e_indicator} | â±ï¸ {elapsed:.1f}s\", end='', flush=True)\n",
        "\n",
        "    def print_progress(self):\n",
        "        \"\"\"Display execution progress\"\"\"\n",
        "        completed = sum(1 for t in self.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        total = self.total_tasks\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "\n",
        "        self.show_progress_bar()\n",
        "\n",
        "        # Show running tasks occasionally\n",
        "        if int(elapsed) % 10 == 0:\n",
        "            print()\n",
        "\n",
        "            running_tasks = []\n",
        "            for task_id, task in self.task_store.items():\n",
        "                if task['status'] == 'RUNNING':\n",
        "                    h2e_info = \"\"\n",
        "                    if 'h2e_score' in task:\n",
        "                        h2e_info = f\" (H2E: {task['h2e_score']:.3f})\"\n",
        "                    running_tasks.append(f\"{task_id}{h2e_info}\")\n",
        "\n",
        "            if running_tasks:\n",
        "                print(f\"   Active: {', '.join(running_tasks)}\")\n",
        "\n",
        "    def estimate_cost(self):\n",
        "        \"\"\"Estimate API costs\"\"\"\n",
        "        input_cost_per_million = 75.00\n",
        "        output_cost_per_million = 375.00\n",
        "\n",
        "        input_cost = (self.token_usage['input'] / 1_000_000) * input_cost_per_million\n",
        "        output_cost = (self.token_usage['output'] / 1_000_000) * output_cost_per_million\n",
        "        total_cost = input_cost + output_cost\n",
        "\n",
        "        print(f\"\\nðŸ’° Cost Estimation:\")\n",
        "        print(f\"   Input tokens: {self.token_usage['input']:,} â‰ˆ ${input_cost:.4f}\")\n",
        "        print(f\"   Output tokens: {self.token_usage['output']:,} â‰ˆ ${output_cost:.4f}\")\n",
        "        print(f\"   Total estimated: ${total_cost:.4f}\")\n",
        "\n",
        "        return total_cost\n",
        "\n",
        "    def run_orchestration(self, timeout_seconds=600):\n",
        "        \"\"\"Phase 3: Execution loop with H2E accountability\"\"\"\n",
        "        mode_label = \"CALIBRATION\" if self.calibration_mode else \"ACCOUNTABLE\"\n",
        "        print(f\"âš™ï¸ Orchestrator: Starting execution loop...\")\n",
        "        print(f\"ðŸ”’ H2E Accountability Framework: {mode_label}\")\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "            futures = {}\n",
        "\n",
        "            while True:\n",
        "                current_time = time.time()\n",
        "\n",
        "                if current_time - self.start_time > timeout_seconds:\n",
        "                    print(f\"\\nâ° Timeout after {timeout_seconds} seconds\")\n",
        "                    break\n",
        "\n",
        "                self.print_progress()\n",
        "\n",
        "                ready_tasks = []\n",
        "                for task_id, task in self.task_store.items():\n",
        "                    if task['status'] == 'PENDING':\n",
        "                        deps_ready = True\n",
        "                        for dep in task['dependencies']:\n",
        "                            if self.task_store.get(dep, {}).get('status') != 'COMPLETED':\n",
        "                                deps_ready = False\n",
        "                                break\n",
        "\n",
        "                        if deps_ready:\n",
        "                            ready_tasks.append(task_id)\n",
        "\n",
        "                for task_id in ready_tasks:\n",
        "                    if task_id not in futures or futures[task_id].done():\n",
        "                        self.task_store[task_id]['status'] = 'RUNNING'\n",
        "                        futures[task_id] = executor.submit(self.execute_task, task_id)\n",
        "\n",
        "                all_done = all(\n",
        "                    t['status'] in ['COMPLETED', 'FAILED']\n",
        "                    for t in self.task_store.values()\n",
        "                )\n",
        "\n",
        "                if all_done:\n",
        "                    print(\"\\n\\nðŸŽ¯ All tasks completed!\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.5)\n",
        "\n",
        "        print()\n",
        "        self.show_progress_bar()\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        return self.results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # CALIBRATION MODE: Set to True for first run to establish baselines\n",
        "    # Set to False for production runs with accountability\n",
        "    calibration_mode = True  # First run should be calibration\n",
        "\n",
        "    orch = Orchestrator(calibration_mode=calibration_mode)\n",
        "\n",
        "    user_goal = \"Create a 3-step technical blog post about Kubernetes security: 1. Research, 2. Write, 3. Review.\"\n",
        "\n",
        "    try:\n",
        "        mode_str = \"CALIBRATION\" if calibration_mode else \"ACCOUNTABLE\"\n",
        "        print(f\"ðŸš€ Starting DAG Orchestrator with H2E {mode_str} Mode\")\n",
        "        print(f\"Goal: {user_goal}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        plan = orch.get_plan(user_goal)\n",
        "\n",
        "        print(\"\\nðŸ“‹ Task Plan:\")\n",
        "        for i, task in enumerate(plan['tasks'], 1):\n",
        "            deps = ', '.join(task['dependencies']) if task['dependencies'] else 'None'\n",
        "            print(f\"  {i}. {task['id']}: {task['description'][:80]}...\")\n",
        "            print(f\"     Role: {task['agent_role']}, Depends on: {deps}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Starting execution...\")\n",
        "        results = orch.run_orchestration()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\nðŸ BUILD COMPLETE\\n\" + \"=\"*50)\n",
        "\n",
        "        successful = sum(1 for t in orch.task_store.values() if t['status'] == 'COMPLETED')\n",
        "        failed = sum(1 for t in orch.task_store.values() if t['status'] == 'FAILED')\n",
        "\n",
        "        h2e_scores = [t.get('h2e_score', 0) for t in orch.task_store.values()\n",
        "                     if t.get('status') == 'COMPLETED' and 'h2e_score' in t]\n",
        "        avg_h2e = np.mean(h2e_scores) if h2e_scores else 0\n",
        "        h2e_passed = sum(1 for t in orch.task_store.values()\n",
        "                        if t.get('h2e_passed', False))\n",
        "\n",
        "        print(f\"\\nðŸ“ˆ Summary:\")\n",
        "        print(f\"   Tasks: {successful} successful, {failed} failed\")\n",
        "\n",
        "        if calibration_mode:\n",
        "            print(f\"   H2E Calibration Scores: Avg {avg_h2e:.3f}\")\n",
        "            # Analyze calibration data\n",
        "            recommendations = orch.h2e.analyze_calibration_data()\n",
        "            print(f\"\\nðŸ’¡ Recommendations for production thresholds:\")\n",
        "            for role, threshold in recommendations.items():\n",
        "                print(f\"   {role}: {threshold:.3f}\")\n",
        "        else:\n",
        "            print(f\"   H2E Alignment: {h2e_passed}/{successful} passed, Avg score: {avg_h2e:.3f}\")\n",
        "\n",
        "        # Generate and display H2E report\n",
        "        print(\"\\nðŸ“Š H2E Accountability Report:\")\n",
        "        h2e_report = orch.h2e.save_report(\"output/h2e_accountability_report.json\")\n",
        "\n",
        "        if 'h2e_framework_report' in h2e_report:\n",
        "            report_data = h2e_report['h2e_framework_report']\n",
        "            print(f\"   Timestamp: {report_data.get('timestamp', 'N/A')}\")\n",
        "            print(f\"   Tasks Evaluated: {report_data.get('total_tasks_evaluated', 0)}\")\n",
        "            print(f\"   Average SROI: {report_data.get('average_sroi_score', 0):.3f}\")\n",
        "            print(f\"   Alignment Pass Rate: {report_data.get('alignment_pass_rate', '0%')}\")\n",
        "            print(f\"   Recommended Threshold: {report_data.get('recommended_threshold', 0):.3f}\")\n",
        "\n",
        "            if 'task_breakdown' in report_data:\n",
        "                print(f\"\\n   Task Breakdown:\")\n",
        "                for task in report_data['task_breakdown']:\n",
        "                    status = \"âœ…\" if task['passed'] else \"âŒ\"\n",
        "                    print(f\"     {status} {task['task_id']} ({task['role']}): {task['sroi_score']:.3f} (required: {task['required_threshold']}) - {task['explanation']}\")\n",
        "\n",
        "        orch.estimate_cost()\n",
        "\n",
        "        os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "        print(\"\\nðŸ“‚ Output Files:\")\n",
        "        for tid, content in results.items():\n",
        "            status = orch.task_store[tid]['status']\n",
        "            role = orch.task_store[tid]['agent_role']\n",
        "            h2e_score = orch.task_store[tid].get('h2e_score', 'N/A')\n",
        "\n",
        "            clean_role = role.replace(' ', '_').replace('/', '_')\n",
        "            filename = f\"output/{tid}_{clean_role}.txt\"\n",
        "\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"Task: {tid}\\n\")\n",
        "                f.write(f\"Role: {role}\\n\")\n",
        "                f.write(f\"Status: {status}\\n\")\n",
        "                f.write(f\"H2E Alignment Score: {h2e_score}\\n\")\n",
        "                f.write(f\"Generated: {time.ctime()}\\n\")\n",
        "                f.write(\"=\"*60 + \"\\n\\n\")\n",
        "                f.write(content)\n",
        "\n",
        "            print(f\"  {tid}: {filename} (H2E: {h2e_score})\")\n",
        "\n",
        "        # Save completion history\n",
        "        with open(\"output/completion_history.json\", \"w\") as f:\n",
        "            json.dump(orch.completion_history, f, indent=2, default=str)\n",
        "        print(\"  Completion History: output/completion_history.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ FATAL ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBJyeyu2M4t7",
        "outputId": "ceeb041f-f3d6-431c-a5b0-a075986b60ba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting DAG Orchestrator with H2E CALIBRATION Mode\n",
            "Goal: Create a 3-step technical blog post about Kubernetes security: 1. Research, 2. Write, 3. Review.\n",
            "--------------------------------------------------\n",
            "ðŸ§  Brain: Planning via claude-opus-4-6...\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task1 (Research Analyst)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task2 (Technical Writer)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task3 (Technical Reviewer)\n",
            "âœ“ Planned 3 tasks\n",
            "âœ“ DAG validation passed (no circular dependencies)\n",
            "\n",
            "ðŸ“‹ Task Plan:\n",
            "  1. task1: Research Kubernetes security best practices, common vulnerabilities (such as mis...\n",
            "     Role: Research Analyst, Depends on: None\n",
            "  2. task2: Using the research brief from task1, write a comprehensive technical blog post a...\n",
            "     Role: Technical Writer, Depends on: task1\n",
            "  3. task3: Review the blog post from task2 for technical accuracy, completeness, clarity, a...\n",
            "     Role: Technical Reviewer, Depends on: task2\n",
            "\n",
            "==================================================\n",
            "Starting execution...\n",
            "âš™ï¸ Orchestrator: Starting execution loop...\n",
            "ðŸ”’ H2E Accountability Framework: CALIBRATION\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 0.0s\n",
            "ðŸš€ Dispatching [Research Analyst]: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 0.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 10.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 10.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 20.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 20.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 30.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 30.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 40.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 40.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 50.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 50.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 60.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 60.7s\n",
            "   Active: task1\n",
            "   H2E/SROI: Alignment score: 0.461 (Required: 0.612) - Moderate alignment, some semantic drift\n",
            "âš ï¸  Quality issues for task1: Content may lack proper conclusion\n",
            "âš ï¸ Quality check failed for task1, retrying...\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 70.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 70.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 80.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 80.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 90.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 90.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 100.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 100.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 110.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 110.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 120.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 120.9s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/3 (0.0%) | â±ï¸ 129.9s   H2E/SROI: Alignment score: 0.462 (Required: 0.567) - Moderate alignment, some semantic drift\n",
            "âš ï¸  Quality issues for task1: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task1 (H2E: 0.462, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 130.4s\n",
            "ðŸš€ Dispatching [Technical Writer]: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 130.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 140.4s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 140.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 150.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 151.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 160.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 161.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 170.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 170.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 180.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 180.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 190.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 190.6s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 200.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 200.6s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 203.1s   H2E/SROI: Alignment score: 0.482 (Required: 0.402) - Moderate alignment, some semantic drift\n",
            "âš ï¸  Quality issues for task2: Content may lack proper conclusion\n",
            "âš ï¸ Quality check failed for task2, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 210.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 210.6s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 220.2s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 220.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 230.2s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 230.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 240.2s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 240.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 250.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 250.8s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 260.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 260.8s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 270.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 270.8s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/3 (33.3%) | H2E: 0.462 | â±ï¸ 272.8s   H2E/SROI: Alignment score: 0.478 (Required: 0.426) - Moderate alignment, some semantic drift\n",
            "âš ï¸  Quality issues for task2: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task2 (H2E: 0.478, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 273.3sðŸš€ Dispatching [Technical Reviewer]: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 280.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 280.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 290.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 290.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 300.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 300.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 310.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 311.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 320.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 321.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 330.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 330.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 337.1s   H2E/SROI: Alignment score: 0.816 (Required: 0.656) - Excellent alignment with expert intent\n",
            "âš ï¸  Quality issues for task3: Content may lack proper conclusion\n",
            "âš ï¸ Quality check failed for task3, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 340.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 340.6s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 350.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 350.6s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 360.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 360.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 370.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 370.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 380.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 380.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 390.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 390.8s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/3 (66.7%) | H2E: 0.470 | â±ï¸ 396.3s   H2E/SROI: Alignment score: 0.837 (Required: 0.704) - Excellent alignment with expert intent\n",
            "âš ï¸  Quality issues for task3: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task3 (H2E: 0.837, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 (100.0%) | H2E: 0.592 | â±ï¸ 396.8s\n",
            "\n",
            "ðŸŽ¯ All tasks completed!\n",
            "\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 (100.0%) | H2E: 0.592 | â±ï¸ 396.8s\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ðŸ BUILD COMPLETE\n",
            "==================================================\n",
            "\n",
            "ðŸ“ˆ Summary:\n",
            "   Tasks: 3 successful, 0 failed\n",
            "   H2E Calibration Scores: Avg 0.592\n",
            "\n",
            "ðŸ”§ H2E Calibration Analysis:\n",
            "========================================\n",
            "\n",
            "  Research Analyst:\n",
            "    Samples: 2\n",
            "    Average: 0.462\n",
            "    Range: 0.461 - 0.462\n",
            "    Recommended threshold: 0.461\n",
            "\n",
            "  Technical Writer:\n",
            "    Samples: 2\n",
            "    Average: 0.480\n",
            "    Range: 0.478 - 0.482\n",
            "    Recommended threshold: 0.479\n",
            "\n",
            "  Technical Reviewer:\n",
            "    Samples: 2\n",
            "    Average: 0.827\n",
            "    Range: 0.816 - 0.837\n",
            "    Recommended threshold: 0.821\n",
            "\n",
            "ðŸ’¡ Recommendations for production thresholds:\n",
            "   Research Analyst: 0.461\n",
            "   Technical Writer: 0.479\n",
            "   Technical Reviewer: 0.821\n",
            "\n",
            "ðŸ“Š H2E Accountability Report:\n",
            "âœ“ H2E report saved to output/h2e_accountability_report.json\n",
            "   Timestamp: 2026-02-08T13:24:42.495961\n",
            "   Tasks Evaluated: 6\n",
            "   Average SROI: 0.589\n",
            "   Alignment Pass Rate: 100.0%\n",
            "   Recommended Threshold: 0.505\n",
            "\n",
            "   Task Breakdown:\n",
            "     âœ… task3 (Technical Reviewer): 0.837 (required: 0.704) - Excellent alignment with expert intent\n",
            "     âœ… task2 (Technical Writer): 0.478 (required: 0.426) - Moderate alignment, some semantic drift\n",
            "     âœ… task1 (Research Analyst): 0.462 (required: 0.567) - Moderate alignment, some semantic drift\n",
            "\n",
            "ðŸ’° Cost Estimation:\n",
            "   Input tokens: 3,678 â‰ˆ $0.2758\n",
            "   Output tokens: 20,391 â‰ˆ $7.6466\n",
            "   Total estimated: $7.9225\n",
            "\n",
            "ðŸ“‚ Output Files:\n",
            "  task1: output/task1_Research_Analyst.txt (H2E: 0.46214447956291604)\n",
            "  task2: output/task2_Technical_Writer.txt (H2E: 0.4776660793011777)\n",
            "  task3: output/task3_Technical_Reviewer.txt (H2E: 0.8370512233690792)\n",
            "  Completion History: output/completion_history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DS-H2E"
      ],
      "metadata": {
        "id": "DnTTuaetczj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from typing import Dict, List, Optional, Tuple, Any, Set\n",
        "import anthropic\n",
        "from concurrent.futures import ThreadPoolExecutor, Future\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "import re\n",
        "import threading\n",
        "from queue import PriorityQueue\n",
        "from enum import Enum\n",
        "\n",
        "# 1. SETUP CLIENT\n",
        "api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"ANTHROPIC_API_KEY environment variable not set.\")\n",
        "\n",
        "client = anthropic.Anthropic(api_key=api_key)\n",
        "MODEL_NAME = \"claude-opus-4-6\"  # Using the original model name\n",
        "\n",
        "class TaskStatus(Enum):\n",
        "    PENDING = \"PENDING\"\n",
        "    RUNNING = \"RUNNING\"\n",
        "    COMPLETED = \"COMPLETED\"\n",
        "    FAILED = \"FAILED\"\n",
        "\n",
        "# H2E Framework Components\n",
        "@dataclass\n",
        "class ExpertIntentVector:\n",
        "    \"\"\"NEZ (Normalized Expert Zone): Encoded expert intent\"\"\"\n",
        "    task_id: str\n",
        "    role: str\n",
        "    vector: np.ndarray\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    description: str = \"\"\n",
        "    gold_standard_examples: List[str] = field(default_factory=list)\n",
        "    complexity_score: float = 0.5  # Default medium complexity\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert to JSON-serializable dictionary\"\"\"\n",
        "        return {\n",
        "            \"task_id\": self.task_id,\n",
        "            \"role\": self.role,\n",
        "            \"vector\": self.vector.tolist(),\n",
        "            \"timestamp\": self.timestamp.isoformat(),\n",
        "            \"description\": self.description,\n",
        "            \"gold_standard_examples\": self.gold_standard_examples,\n",
        "            \"complexity_score\": float(self.complexity_score)\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class AlignmentScore:\n",
        "    \"\"\"SROI (Semantic ROI): Alignment measurement\"\"\"\n",
        "    task_id: str\n",
        "    score: float\n",
        "    threshold_required: float\n",
        "    passed: bool\n",
        "    vector_distance: float\n",
        "    explanation: str = \"\"\n",
        "    confidence: float = 0.5\n",
        "    raw_similarity: float = 0.0  # Raw cosine similarity before scaling\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert to JSON-serializable dictionary\"\"\"\n",
        "        return {\n",
        "            \"task_id\": self.task_id,\n",
        "            \"score\": float(self.score),\n",
        "            \"threshold_required\": float(self.threshold_required),\n",
        "            \"passed\": bool(self.passed),\n",
        "            \"vector_distance\": float(self.vector_distance),\n",
        "            \"explanation\": self.explanation,\n",
        "            \"confidence\": float(self.confidence),\n",
        "            \"raw_similarity\": float(self.raw_similarity)\n",
        "        }\n",
        "\n",
        "class H2EAccountabilityEngine:\n",
        "    \"\"\"H2E-inspired accountability framework with enhanced vector encoding\"\"\"\n",
        "\n",
        "    def __init__(self, calibration_mode: bool = False):\n",
        "        self.expert_vectors: Dict[str, ExpertIntentVector] = {}  # NEZ: Stores expert intent vectors\n",
        "        self.alignment_history: List[AlignmentScore] = []  # SROI: Tracks all alignment scores\n",
        "        self.calibration_mode = calibration_mode  # Controls if we're in calibration or production mode\n",
        "        self.calibration_data: List[Dict] = []  # Collects data for threshold calibration\n",
        "        self.role_performance_history: Dict[str, List[float]] = {}  # Track historical performance by role\n",
        "        self._vector_cache: Dict[str, np.ndarray] = {}  # Cache for vector computations\n",
        "\n",
        "    def _compute_text_complexity(self, text: str) -> float:\n",
        "        \"\"\"Compute text complexity score (0-1)\"\"\"\n",
        "        if not text:\n",
        "            return 0.5\n",
        "\n",
        "        words = text.split()\n",
        "        word_count = len(words)\n",
        "\n",
        "        # Factors: length, vocabulary diversity, technical terms\n",
        "        unique_words = len(set(words))\n",
        "        vocab_richness = unique_words / max(word_count, 1)\n",
        "\n",
        "        # Check for technical indicators\n",
        "        technical_indicators = ['algorithm', 'architecture', 'security', 'implementation',\n",
        "                               'optimization', 'performance', 'scalability', 'vulnerability',\n",
        "                               'kubernetes', 'container', 'microservice', 'orchestration']\n",
        "        technical_density = sum(1 for word in words if word.lower() in technical_indicators) / max(word_count, 1)\n",
        "\n",
        "        # Combine factors\n",
        "        complexity = (\n",
        "            0.4 * min(1.0, word_count / 200) +  # Length factor\n",
        "            0.3 * vocab_richness +              # Vocabulary richness\n",
        "            0.3 * min(1.0, technical_density * 5)  # Technical density\n",
        "        )\n",
        "\n",
        "        return min(1.0, max(0.0, complexity))\n",
        "\n",
        "    def capture_expert_intent(self, task_id: str, role: str,\n",
        "                             description: str, examples: List[str]) -> ExpertIntentVector:\n",
        "        \"\"\"NEZ: Capture expert intent as encoded vector with complexity scoring\"\"\"\n",
        "        intent_text = f\"{role}: {description}. Examples: {' '.join(examples[:3])}\"\n",
        "        vector = self._text_to_vector_enhanced(intent_text)\n",
        "\n",
        "        # Calculate complexity\n",
        "        complexity = self._compute_text_complexity(description)\n",
        "\n",
        "        expert_vector = ExpertIntentVector(\n",
        "            task_id=task_id,\n",
        "            role=role,\n",
        "            vector=vector,\n",
        "            description=description,\n",
        "            gold_standard_examples=examples,\n",
        "            complexity_score=complexity\n",
        "        )\n",
        "\n",
        "        self.expert_vectors[task_id] = expert_vector\n",
        "\n",
        "        # Initialize role performance tracking\n",
        "        if role not in self.role_performance_history:\n",
        "            self.role_performance_history[role] = []\n",
        "\n",
        "        print(f\"ðŸ“Š H2E/NEZ: Captured expert intent for {task_id} ({role}, complexity: {complexity:.2f})\")\n",
        "        return expert_vector\n",
        "\n",
        "    def _text_to_vector_enhanced(self, text: str) -> np.ndarray:\n",
        "        \"\"\"Enhanced vector encoding with semantic features - FIXED VERSION\"\"\"\n",
        "        # Cache vectors to avoid recomputation\n",
        "        cache_key = hashlib.md5(text.encode()).hexdigest()\n",
        "        if cache_key in self._vector_cache:\n",
        "            return self._vector_cache[cache_key]\n",
        "\n",
        "        text = text.lower().strip()\n",
        "\n",
        "        # Enhanced preprocessing\n",
        "        words = [re.sub(r'[^\\w\\s]', '', word) for word in text.split()]\n",
        "        words = [word for word in words if len(word) > 2 and word not in ['the', 'and', 'for', 'with', 'this', 'that']]\n",
        "\n",
        "        # Create 512-dimensional vector for better discrimination\n",
        "        vector = np.zeros(512)\n",
        "\n",
        "        if not words:\n",
        "            # Return uniform vector for empty text\n",
        "            vector = np.ones(512) / np.sqrt(512)\n",
        "            self._vector_cache[cache_key] = vector\n",
        "            return vector\n",
        "\n",
        "        # Enhanced feature extraction with better discrimination\n",
        "        for i, word in enumerate(words[:100]):  # Limit to 100 words\n",
        "            # Create multiple hash positions for each word\n",
        "            word_bytes = word.encode()\n",
        "            md5_hash = hashlib.md5(word_bytes).hexdigest()\n",
        "\n",
        "            # Use different parts of hash for different positions\n",
        "            for j in range(4):\n",
        "                # Take 2 hex chars (1 byte) for position\n",
        "                pos_hash = int(md5_hash[j*2:(j+1)*2], 16)\n",
        "                pos = (pos_hash + j * 128) % 512\n",
        "\n",
        "                # Weight decreases with word position\n",
        "                position_weight = 1.0 - (i / len(words))\n",
        "                # Base weight with some randomness\n",
        "                base_weight = 0.2 + (hash(word) % 100) / 500\n",
        "\n",
        "                vector[pos] += base_weight * position_weight\n",
        "\n",
        "        # Add n-gram features for better semantic capture\n",
        "        for i in range(len(words) - 1):\n",
        "            bigram = f\"{words[i]}_{words[i+1]}\"\n",
        "            bigram_hash = hash(bigram) % 512\n",
        "            vector[bigram_hash] += 0.15\n",
        "\n",
        "        # Normalize to unit length\n",
        "        norm = np.linalg.norm(vector)\n",
        "        if norm > 0:\n",
        "            vector = vector / norm\n",
        "        else:\n",
        "            vector = np.ones(512) / np.sqrt(512)\n",
        "\n",
        "        # Add small amount of noise to ensure uniqueness\n",
        "        noise = np.random.normal(0, 0.01, 512)\n",
        "        vector = vector + noise\n",
        "\n",
        "        # Renormalize\n",
        "        norm = np.linalg.norm(vector)\n",
        "        if norm > 0:\n",
        "            vector = vector / norm\n",
        "\n",
        "        self._vector_cache[cache_key] = vector\n",
        "        return vector\n",
        "\n",
        "    def calculate_sroi(self, task_id: str, generated_output: str,\n",
        "                      task_description: str = \"\") -> AlignmentScore:\n",
        "        \"\"\"SROI: Calculate alignment with expert intent - FIXED VERSION\"\"\"\n",
        "\n",
        "        if task_id not in self.expert_vectors:\n",
        "            # Create expert vector if not exists\n",
        "            self.capture_expert_intent(\n",
        "                task_id=task_id,\n",
        "                role=\"Unknown\",\n",
        "                description=task_description or f\"Task {task_id}\",\n",
        "                examples=[generated_output[:500]]\n",
        "            )\n",
        "\n",
        "        expert_vector = self.expert_vectors[task_id]\n",
        "        output_vector = self._text_to_vector_enhanced(generated_output)\n",
        "\n",
        "        # Calculate cosine similarity (normalized dot product)\n",
        "        expert_norm = np.linalg.norm(expert_vector.vector)\n",
        "        output_norm = np.linalg.norm(output_vector)\n",
        "\n",
        "        if expert_norm == 0 or output_norm == 0:\n",
        "            raw_similarity = 0.0\n",
        "            similarity = 0.0\n",
        "        else:\n",
        "            # Cosine similarity range: -1 to 1\n",
        "            raw_similarity = np.dot(expert_vector.vector, output_vector) / (expert_norm * output_norm)\n",
        "\n",
        "            # Scale to 0-1 range with non-linear mapping\n",
        "            # Cosine similarity of 0 maps to 0.5, 1 maps to 1.0, -1 maps to 0.0\n",
        "            similarity = (raw_similarity + 1) / 2\n",
        "\n",
        "        # Apply soft transformation to prevent saturation\n",
        "        # Use cubic mapping to spread out middle values\n",
        "        similarity = similarity ** (1/1.5)  # Makes middle values more spread out\n",
        "\n",
        "        # Add small variability for calibration mode (more realistic)\n",
        "        if self.calibration_mode:\n",
        "            # Add realistic noise: 2-8% variation\n",
        "            noise = np.random.normal(0, 0.03)  # 3% standard deviation\n",
        "            similarity += noise\n",
        "\n",
        "        # Ensure reasonable bounds\n",
        "        similarity = max(0.1, min(0.95, similarity))\n",
        "\n",
        "        # Calculate confidence based on multiple factors\n",
        "        # 1. Vector consistency (low std dev = high confidence)\n",
        "        vector_std = np.std(output_vector)\n",
        "        consistency_score = 1.0 - min(1.0, vector_std / 0.3)\n",
        "\n",
        "        # 2. Content length factor (longer content = more reliable)\n",
        "        content_length = len(generated_output.strip())\n",
        "        length_score = min(1.0, content_length / 1500)\n",
        "\n",
        "        # 3. Vocabulary richness\n",
        "        words = generated_output.lower().split()\n",
        "        if len(words) > 20:\n",
        "            unique_words = len(set(words))\n",
        "            vocab_score = min(1.0, unique_words / max(50, len(words) * 0.7))\n",
        "        else:\n",
        "            vocab_score = 0.3\n",
        "\n",
        "        # 4. Structure score (presence of headings, lists)\n",
        "        has_structure = any(marker in generated_output for marker in ['# ', '## ', '### ', '- ', '* ', '1. ', '2. '])\n",
        "        structure_score = 0.7 if has_structure else 0.3\n",
        "\n",
        "        # Combined confidence\n",
        "        confidence = (\n",
        "            consistency_score * 0.3 +\n",
        "            length_score * 0.25 +\n",
        "            vocab_score * 0.25 +\n",
        "            structure_score * 0.2\n",
        "        )\n",
        "        confidence = max(0.3, min(0.95, confidence))\n",
        "\n",
        "        # Get adaptive threshold\n",
        "        threshold = self._get_required_threshold(\n",
        "            expert_vector.role,\n",
        "            task_description,\n",
        "            similarity,\n",
        "            expert_vector.complexity_score\n",
        "        )\n",
        "\n",
        "        # In calibration mode, collect data without failing\n",
        "        if self.calibration_mode:\n",
        "            passed = True\n",
        "            self.calibration_data.append({\n",
        "                \"task_id\": task_id,\n",
        "                \"role\": expert_vector.role,\n",
        "                \"score\": similarity,\n",
        "                \"raw_similarity\": float(raw_similarity),\n",
        "                \"description\": task_description,\n",
        "                \"complexity\": expert_vector.complexity_score,\n",
        "                \"confidence\": confidence,\n",
        "                \"content_length\": content_length\n",
        "            })\n",
        "        else:\n",
        "            passed = similarity >= threshold\n",
        "\n",
        "        # Calculate vector distance (for debugging)\n",
        "        distance = np.linalg.norm(expert_vector.vector - output_vector)\n",
        "\n",
        "        # Update role performance history\n",
        "        self.role_performance_history.setdefault(expert_vector.role, []).append(similarity)\n",
        "\n",
        "        # Generate detailed explanation\n",
        "        explanation = self._generate_alignment_explanation(similarity, threshold, confidence, raw_similarity)\n",
        "\n",
        "        score = AlignmentScore(\n",
        "            task_id=task_id,\n",
        "            score=similarity,\n",
        "            threshold_required=threshold,\n",
        "            passed=passed,\n",
        "            vector_distance=distance,\n",
        "            explanation=explanation,\n",
        "            confidence=confidence,\n",
        "            raw_similarity=raw_similarity\n",
        "        )\n",
        "\n",
        "        self.alignment_history.append(score)\n",
        "        return score\n",
        "\n",
        "    def _generate_alignment_explanation(self, similarity: float, threshold: float,\n",
        "                                       confidence: float, raw_similarity: float) -> str:\n",
        "        \"\"\"Generate detailed explanation for alignment score\"\"\"\n",
        "\n",
        "        # Different explanation based on raw cosine similarity\n",
        "        if raw_similarity > 0.8:\n",
        "            sim_type = \"Very high semantic similarity\"\n",
        "        elif raw_similarity > 0.6:\n",
        "            sim_type = \"High semantic similarity\"\n",
        "        elif raw_similarity > 0.4:\n",
        "            sim_type = \"Moderate semantic similarity\"\n",
        "        elif raw_similarity > 0.2:\n",
        "            sim_type = \"Low semantic similarity\"\n",
        "        elif raw_similarity > 0:\n",
        "            sim_type = \"Very low semantic similarity\"\n",
        "        else:\n",
        "            sim_type = \"Negative semantic similarity\"\n",
        "\n",
        "        if similarity >= threshold * 1.3:\n",
        "            if confidence > 0.8:\n",
        "                return f\"{sim_type}. Excellent alignment exceeding requirements by {((similarity/threshold)-1)*100:.0f}%\"\n",
        "            else:\n",
        "                return f\"{sim_type}. Good alignment but confidence is moderate ({confidence:.1%})\"\n",
        "        elif similarity >= threshold:\n",
        "            if confidence > 0.7:\n",
        "                return f\"{sim_type}. Adequate alignment meeting requirements\"\n",
        "            else:\n",
        "                return f\"{sim_type}. Borderline alignment - meets threshold but confidence is low ({confidence:.1%})\"\n",
        "        elif similarity >= threshold * 0.8:\n",
        "            gap = threshold - similarity\n",
        "            return f\"{sim_type}. Moderate alignment, {gap:.3f} below threshold\"\n",
        "        elif similarity >= threshold * 0.6:\n",
        "            gap = threshold - similarity\n",
        "            return f\"{sim_type}. Poor alignment, {gap:.3f} below threshold\"\n",
        "        else:\n",
        "            gap = threshold - similarity\n",
        "            return f\"{sim_type}. Very poor alignment, {gap:.3f} below threshold\"\n",
        "\n",
        "    def _get_required_threshold(self, role: str, description: str,\n",
        "                               current_score: float = None, complexity: float = 0.5) -> float:\n",
        "        \"\"\"Get adaptive threshold based on role, complexity, and historical data\"\"\"\n",
        "\n",
        "        # Base thresholds calibrated from analysis\n",
        "        base_thresholds = {\n",
        "            \"Research Analyst\": 0.532,\n",
        "            \"Technical Writer\": 0.350,\n",
        "            \"Technical Reviewer\": 0.656,\n",
        "            \"Technical Researcher\": 0.45,\n",
        "            \"Writer\": 0.50,\n",
        "            \"Editor\": 0.55,\n",
        "            \"Reviewer\": 0.55,\n",
        "            \"Default\": 0.50\n",
        "        }\n",
        "\n",
        "        # Get base threshold\n",
        "        threshold = base_thresholds.get(role, base_thresholds[\"Default\"])\n",
        "\n",
        "        # Adjust for task complexity (complex tasks require higher thresholds)\n",
        "        complexity_adjustment = 1.0 + (complexity * 0.4)  # Up to 40% increase for complex tasks\n",
        "        threshold *= complexity_adjustment\n",
        "\n",
        "        # Apply risk multiplier for security/critical content\n",
        "        description_lower = description.lower()\n",
        "        security_keywords = [\"security\", \"vulnerability\", \"risk\", \"attack\", \"breach\",\n",
        "                           \"hack\", \"critical\", \"sensitive\", \"zero-trust\", \"authentication\"]\n",
        "        if any(keyword in description_lower for keyword in security_keywords):\n",
        "            threshold *= 1.25  # 25% higher for security\n",
        "            threshold = min(threshold, 0.85)  # Cap at 0.85\n",
        "\n",
        "        # Use historical performance data if available\n",
        "        if role in self.role_performance_history and self.role_performance_history[role]:\n",
        "            historical_scores = self.role_performance_history[role]\n",
        "            avg_historical = np.mean(historical_scores)\n",
        "            std_historical = np.std(historical_scores) if len(historical_scores) > 1 else 0.1\n",
        "\n",
        "            # Adjust threshold based on historical performance\n",
        "            if len(historical_scores) >= 2:\n",
        "                # More data = more trust in historical performance\n",
        "                trust_factor = min(0.6, len(historical_scores) / 8)\n",
        "                # Set threshold slightly below historical average\n",
        "                historical_threshold = avg_historical - (std_historical * 0.3)\n",
        "                threshold = (threshold * (1 - trust_factor)) + (historical_threshold * trust_factor)\n",
        "\n",
        "        # If we have calibration data, adjust based on similar tasks\n",
        "        if self.calibration_data and current_score is not None:\n",
        "            similar_scores = [\n",
        "                d[\"score\"] for d in self.calibration_data\n",
        "                if d[\"role\"] == role and abs(d.get(\"complexity\", 0.5) - complexity) < 0.3\n",
        "            ]\n",
        "            if similar_scores:\n",
        "                avg_similar = np.mean(similar_scores)\n",
        "                std_similar = np.std(similar_scores) if len(similar_scores) > 1 else 0.1\n",
        "                # Adjust towards historical average with consideration for variance\n",
        "                calibration_weight = min(0.5, len(similar_scores) / 15)\n",
        "                calibrated_threshold = max(0.3, avg_similar - (std_similar * 0.4))\n",
        "                threshold = (threshold * (1 - calibration_weight)) + (calibrated_threshold * calibration_weight)\n",
        "\n",
        "        # Ensure reasonable bounds\n",
        "        threshold = max(0.25, min(0.9, threshold))\n",
        "\n",
        "        return round(threshold, 3)\n",
        "\n",
        "    def analyze_calibration_data(self) -> Dict[str, float]:\n",
        "        \"\"\"Analyze calibration data to recommend thresholds\"\"\"\n",
        "        if not self.calibration_data:\n",
        "            print(\"âš ï¸ No calibration data available\")\n",
        "            return {}\n",
        "\n",
        "        # Group by role\n",
        "        role_data: Dict[str, List[Dict]] = {}\n",
        "        for entry in self.calibration_data:\n",
        "            role = entry[\"role\"]\n",
        "            if role not in role_data:\n",
        "                role_data[role] = []\n",
        "            role_data[role].append(entry)\n",
        "\n",
        "        print(\"\\nðŸ”§ H2E Calibration Analysis:\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        recommendations = {}\n",
        "        for role, entries in role_data.items():\n",
        "            scores = [e[\"score\"] for e in entries]\n",
        "            raw_similarities = [e.get(\"raw_similarity\", 0) for e in entries]\n",
        "            complexities = [e.get(\"complexity\", 0.5) for e in entries]\n",
        "            confidences = [e.get(\"confidence\", 0.5) for e in entries]\n",
        "\n",
        "            avg_score = np.mean(scores)\n",
        "            std_score = np.std(scores) if len(scores) > 1 else 0\n",
        "            avg_raw_sim = np.mean(raw_similarities)\n",
        "            avg_complexity = np.mean(complexities)\n",
        "            avg_confidence = np.mean(confidences)\n",
        "\n",
        "            # Recommended threshold: consider complexity, variance, and confidence\n",
        "            base_recommendation = max(0.3, avg_score - (std_score * 0.8))\n",
        "\n",
        "            # Adjust for average complexity of this role\n",
        "            complexity_adjustment = 1.0 + (avg_complexity * 0.3)\n",
        "            adjusted_recommendation = base_recommendation * complexity_adjustment\n",
        "\n",
        "            # Adjust based on confidence\n",
        "            confidence_adjustment = 1.0 + ((1 - avg_confidence) * 0.2)  # Lower confidence = higher threshold\n",
        "            final_recommendation = adjusted_recommendation * confidence_adjustment\n",
        "\n",
        "            recommendations[role] = min(0.85, final_recommendation)\n",
        "\n",
        "            print(f\"\\n  {role}:\")\n",
        "            print(f\"    Samples: {len(scores)}\")\n",
        "            print(f\"    Average Score: {avg_score:.3f}\")\n",
        "            print(f\"    Raw Cosine Sim: {avg_raw_sim:.3f}\")\n",
        "            print(f\"    Std Dev: {std_score:.3f}\")\n",
        "            print(f\"    Avg Complexity: {avg_complexity:.3f}\")\n",
        "            print(f\"    Avg Confidence: {avg_confidence:.3f}\")\n",
        "            print(f\"    Recommended Threshold: {recommendations[role]:.3f}\")\n",
        "\n",
        "            # Show score distribution\n",
        "            if len(scores) >= 3:\n",
        "                percentiles = np.percentile(scores, [10, 25, 50, 75, 90])\n",
        "                print(f\"    Score Distribution:\")\n",
        "                print(f\"      10%: {percentiles[0]:.3f}, 25%: {percentiles[1]:.3f}, 50%: {percentiles[2]:.3f}\")\n",
        "                print(f\"      75%: {percentiles[3]:.3f}, 90%: {percentiles[4]:.3f}\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def generate_accountability_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive H2E accountability report\"\"\"\n",
        "        if not self.alignment_history:\n",
        "            return {\"status\": \"No alignment data available\"}\n",
        "\n",
        "        scores = [s.score for s in self.alignment_history]\n",
        "        raw_similarities = [s.raw_similarity for s in self.alignment_history]\n",
        "        avg_score = np.mean(scores) if scores else 0\n",
        "        avg_raw_sim = np.mean(raw_similarities) if raw_similarities else 0\n",
        "        std_score = np.std(scores) if len(scores) > 1 else 0\n",
        "\n",
        "        # Get unique final scores (not retries)\n",
        "        final_scores = {}\n",
        "        for score in reversed(self.alignment_history):\n",
        "            if score.task_id not in final_scores:\n",
        "                final_scores[score.task_id] = score\n",
        "\n",
        "        pass_rate = np.mean([1 if s.passed else 0 for s in final_scores.values()])\n",
        "\n",
        "        # Calculate role-based statistics\n",
        "        role_stats = {}\n",
        "        for role in set(v.role for v in self.expert_vectors.values()):\n",
        "            role_scores = [s.score for s in self.alignment_history\n",
        "                          if s.task_id in self.expert_vectors and\n",
        "                          self.expert_vectors[s.task_id].role == role]\n",
        "            if role_scores:\n",
        "                role_stats[role] = {\n",
        "                    \"avg_score\": float(np.mean(role_scores)),\n",
        "                    \"std_score\": float(np.std(role_scores)) if len(role_scores) > 1 else 0,\n",
        "                    \"count\": len(role_scores)\n",
        "                }\n",
        "\n",
        "        report = {\n",
        "            \"h2e_framework_report\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"calibration_mode\": self.calibration_mode,\n",
        "                \"total_tasks_evaluated\": len(self.alignment_history),\n",
        "                \"unique_tasks\": len(final_scores),\n",
        "                \"average_sroi_score\": float(round(avg_score, 4)),\n",
        "                \"average_raw_similarity\": float(round(avg_raw_sim, 4)),\n",
        "                \"sroi_std_dev\": float(round(std_score, 4)),\n",
        "                \"alignment_pass_rate\": f\"{pass_rate*100:.1f}%\",\n",
        "                \"expert_vectors_captured\": len(self.expert_vectors),\n",
        "                \"recommended_threshold\": float(round(max(0.35, avg_score - std_score/2), 3)),\n",
        "                \"role_statistics\": role_stats,\n",
        "                \"task_breakdown\": []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Add task breakdown\n",
        "        for task_id, score in final_scores.items():\n",
        "            expert_vector = self.expert_vectors.get(task_id)\n",
        "            report[\"h2e_framework_report\"][\"task_breakdown\"].append({\n",
        "                \"task_id\": task_id,\n",
        "                \"role\": expert_vector.role if expert_vector else \"Unknown\",\n",
        "                \"complexity\": float(expert_vector.complexity_score) if expert_vector else 0.5,\n",
        "                \"sroi_score\": float(round(score.score, 3)),\n",
        "                \"raw_similarity\": float(round(score.raw_similarity, 3)),\n",
        "                \"required_threshold\": float(score.threshold_required),\n",
        "                \"passed\": bool(score.passed),\n",
        "                \"confidence\": float(score.confidence),\n",
        "                \"explanation\": score.explanation\n",
        "            })\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_report(self, filename: str = \"h2e_accountability_report.json\"):\n",
        "        \"\"\"Save H2E report to file\"\"\"\n",
        "        report = self.generate_accountability_report()\n",
        "\n",
        "        class H2EJSONEncoder(json.JSONEncoder):\n",
        "            def default(self, obj):\n",
        "                if isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                if isinstance(obj, datetime):\n",
        "                    return obj.isoformat()\n",
        "                if isinstance(obj, (ExpertIntentVector, AlignmentScore)):\n",
        "                    return obj.to_dict()\n",
        "                return super().default(obj)\n",
        "\n",
        "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else \".\", exist_ok=True)\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(report, f, indent=2, cls=H2EJSONEncoder)\n",
        "\n",
        "        print(f\"âœ“ H2E report saved to {filename}\")\n",
        "        return report\n",
        "\n",
        "class Orchestrator:\n",
        "    def __init__(self, calibration_mode: bool = False, max_workers: int = 3):\n",
        "        self.task_store = {}\n",
        "        self.results = {}\n",
        "        self.start_time = None\n",
        "        self.total_tasks = 0\n",
        "        self.token_usage = {'input': 0, 'output': 0}\n",
        "        self.completion_history = []\n",
        "        self.max_workers = max_workers\n",
        "\n",
        "        # H2E Accountability Engine\n",
        "        self.h2e = H2EAccountabilityEngine(calibration_mode=calibration_mode)\n",
        "        self.calibration_mode = calibration_mode\n",
        "\n",
        "        # Enhanced expert templates based on analysis\n",
        "        self.expert_templates = {\n",
        "            \"Research Analyst\": {\n",
        "                \"description\": \"Comprehensive research with structured findings\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Research Summary: This analysis examines [topic] using [methods]. Key findings include: 1) [finding] 2) [finding] 3) [finding]\",\n",
        "                    \"Methodology: Data was collected from [sources] and analyzed using [techniques] with attention to [specific considerations]\",\n",
        "                    \"Conclusion: Based on the research, we recommend [recommendations] with justification [reasoning]\"\n",
        "                ],\n",
        "                \"priority\": 2  # Medium priority\n",
        "            },\n",
        "            \"Technical Writer\": {\n",
        "                \"description\": \"Clear technical documentation with examples\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Introduction: Overview of [topic] and its importance in [context]\",\n",
        "                    \"Implementation: Step-by-step instructions with code examples:\\n```python\\n# Comprehensive example\\nimport module\\nresult = module.function(param)\\nprint(f'Result: {result}')\\n```\",\n",
        "                    \"Best Practices: Key recommendations including [do's] and [don'ts] for successful implementation\",\n",
        "                    \"Troubleshooting: Common issues and their solutions\"\n",
        "                ],\n",
        "                \"priority\": 1  # Lower priority (can run in parallel)\n",
        "            },\n",
        "            \"Technical Reviewer\": {\n",
        "                \"description\": \"Thorough technical review with specific feedback\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Overall Assessment: The document is [assessment] with strengths in [areas] and areas for improvement in [areas]\",\n",
        "                    \"Technical Accuracy: Verified [claims] and validated [examples]. Found [issues] that need addressing\",\n",
        "                    \"Suggestions: Recommend [specific improvements] for better clarity, accuracy, and completeness\",\n",
        "                    \"Critical Issues: [Number] critical issues identified requiring immediate attention\"\n",
        "                ],\n",
        "                \"priority\": 3  # High priority (often depends on other tasks)\n",
        "            },\n",
        "            \"Technical Researcher\": {\n",
        "                \"description\": \"In-depth technical research and analysis\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Research Summary: This analysis examines [topic] using [methods]. Key findings include: 1) [finding] 2) [finding] 3) [finding]\",\n",
        "                    \"Methodology: Data was collected from [sources] and analyzed using [techniques] with validation via [validation method]\",\n",
        "                    \"Technical Deep Dive: Detailed analysis of [specific aspect] showing [insights]\",\n",
        "                    \"Conclusion: Based on the research, we recommend [recommendations] with supporting evidence [evidence]\"\n",
        "                ],\n",
        "                \"priority\": 2\n",
        "            },\n",
        "            \"Writer\": {\n",
        "                \"description\": \"Professional writing with clear structure\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Introduction: Engaging overview of [topic] establishing context and importance\",\n",
        "                    \"Main Content: Well-structured sections with clear transitions:\\n## Section 1\\nContent with examples\\n## Section 2\\nMore detailed exploration\",\n",
        "                    \"Conclusion: Summary of key points and final thoughts or call to action\"\n",
        "                ],\n",
        "                \"priority\": 1\n",
        "            },\n",
        "            \"Editor\": {\n",
        "                \"description\": \"Editorial review focusing on clarity and consistency\",\n",
        "                \"gold_standard_examples\": [\n",
        "                    \"Overall Assessment: The document achieves [purpose] with [strengths] and needs improvement in [areas]\",\n",
        "                    \"Clarity Issues: Identified [number] unclear passages suggesting [improvements]\",\n",
        "                    \"Consistency Check: Found inconsistencies in [aspects] recommending [standardization]\",\n",
        "                    \"Grammar and Style: [Number] issues corrected, overall style is [assessment]\"\n",
        "                ],\n",
        "                \"priority\": 2\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.task_lock = threading.Lock()\n",
        "        self.execution_order = []\n",
        "\n",
        "    def _get_task_priority(self, task_id: str) -> float:\n",
        "        \"\"\"Calculate task priority based on role and dependencies\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "        role = task['agent_role']\n",
        "\n",
        "        # Base priority from template\n",
        "        template_priority = 1.0\n",
        "        for template_key, template in self.expert_templates.items():\n",
        "            if template_key.lower() in role.lower():\n",
        "                template_priority = template.get(\"priority\", 1.0)\n",
        "                break\n",
        "\n",
        "        # Adjust based on dependencies (more dependencies = higher priority to unblock others)\n",
        "        dependency_factor = 1.0 + (len(task['dependencies']) * 0.2)\n",
        "\n",
        "        # Adjust based on task complexity (from H2E)\n",
        "        complexity = 0.5\n",
        "        if task_id in self.h2e.expert_vectors:\n",
        "            complexity = self.h2e.expert_vectors[task_id].complexity_score\n",
        "\n",
        "        complexity_factor = 1.0 + complexity * 0.3\n",
        "\n",
        "        final_priority = template_priority * dependency_factor * complexity_factor\n",
        "\n",
        "        # Invert for PriorityQueue (lower number = higher priority)\n",
        "        return -final_priority\n",
        "\n",
        "    def get_plan(self, goal: str) -> Dict:\n",
        "        \"\"\"Phase 1: Planning with enhanced task generation\"\"\"\n",
        "        print(f\"ðŸ§  Brain: Planning via {MODEL_NAME}...\")\n",
        "\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=MODEL_NAME,\n",
        "                max_tokens=4000,\n",
        "                system=\"\"\"You are an AI Architect. Plan the project into a logical Directed Acyclic Graph (DAG).\n",
        "\n",
        "                Return ONLY valid JSON with this exact structure:\n",
        "                {\n",
        "                    \"tasks\": [\n",
        "                        {\n",
        "                            \"id\": \"task1\",\n",
        "                            \"description\": \"Detailed task description\",\n",
        "                            \"dependencies\": [],\n",
        "                            \"agent_role\": \"Role name\",\n",
        "                            \"estimated_complexity\": \"low|medium|high\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "                Rules:\n",
        "                1. Use simple task IDs like task1, task2, task3\n",
        "                2. Make dependencies clear and logical (array of task IDs)\n",
        "                3. Assign agent roles that match the task (Research Analyst, Technical Writer, Technical Reviewer, etc.)\n",
        "                4. Ensure it's a valid DAG (no circular dependencies)\n",
        "                5. Include 3-8 tasks total depending on goal complexity\n",
        "                6. Add estimated_complexity based on task scope\n",
        "                7. Create a logical workflow where later tasks depend on earlier ones\"\"\",\n",
        "                messages=[{\"role\": \"user\", \"content\": f\"{goal}\\n\\nReturn ONLY the JSON, no other text.\"}]\n",
        "            )\n",
        "\n",
        "            if hasattr(message, 'usage'):\n",
        "                self.token_usage['input'] += message.usage.input_tokens\n",
        "                self.token_usage['output'] += message.usage.output_tokens\n",
        "\n",
        "            text = message.content[0].text\n",
        "\n",
        "            # Extract JSON with better error handling\n",
        "            json_match = re.search(r'\\{[\\s\\S]*\\}', text)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                plan = json.loads(json_str)\n",
        "            else:\n",
        "                plan = json.loads(text)\n",
        "\n",
        "            if 'tasks' not in plan:\n",
        "                raise ValueError(\"Response missing 'tasks' key\")\n",
        "\n",
        "            with self.task_lock:\n",
        "                for task in plan['tasks']:\n",
        "                    if not all(key in task for key in ['id', 'description', 'dependencies', 'agent_role']):\n",
        "                        raise ValueError(f\"Task {task.get('id', 'unknown')} missing required fields\")\n",
        "\n",
        "                    task['status'] = TaskStatus.PENDING.value\n",
        "                    task['estimated_complexity'] = task.get('estimated_complexity', 'medium')\n",
        "\n",
        "                    # Calculate numeric complexity\n",
        "                    complexity_map = {'low': 0.3, 'medium': 0.5, 'high': 0.8}\n",
        "                    task['complexity_score'] = complexity_map.get(task['estimated_complexity'], 0.5)\n",
        "\n",
        "                    self.task_store[task['id']] = task\n",
        "\n",
        "                    role = task['agent_role']\n",
        "\n",
        "                    # Find matching template\n",
        "                    template_role = None\n",
        "                    for template_key in self.expert_templates.keys():\n",
        "                        if template_key.lower() in role.lower():\n",
        "                            template_role = template_key\n",
        "                            break\n",
        "\n",
        "                    if template_role and template_role in self.expert_templates:\n",
        "                        template = self.expert_templates[template_role]\n",
        "                        self.h2e.capture_expert_intent(\n",
        "                            task_id=task['id'],\n",
        "                            role=role,\n",
        "                            description=task['description'],\n",
        "                            examples=template['gold_standard_examples']\n",
        "                        )\n",
        "                    else:\n",
        "                        # Use default template\n",
        "                        self.h2e.capture_expert_intent(\n",
        "                            task_id=task['id'],\n",
        "                            role=role,\n",
        "                            description=task['description'],\n",
        "                            examples=[f\"Professional output for {role} focusing on {task['description'][:50]}...\"]\n",
        "                        )\n",
        "\n",
        "            self.total_tasks = len(self.task_store)\n",
        "            print(f\"âœ“ Planned {self.total_tasks} tasks\")\n",
        "\n",
        "            self.validate_dag()\n",
        "\n",
        "            return plan\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Planning Error: {e}\")\n",
        "            if 'message' in locals():\n",
        "                print(\"Content received:\", message.content[0].text[:500])\n",
        "            raise\n",
        "\n",
        "    def validate_dag(self):\n",
        "        \"\"\"Validate that the DAG has no circular dependencies.\"\"\"\n",
        "        visited = set()\n",
        "        recursion_stack = set()\n",
        "\n",
        "        def has_cycle(task_id):\n",
        "            visited.add(task_id)\n",
        "            recursion_stack.add(task_id)\n",
        "\n",
        "            task = self.task_store[task_id]\n",
        "            for dep in task['dependencies']:\n",
        "                if dep not in self.task_store:\n",
        "                    raise ValueError(f\"Dependency {dep} not found in tasks\")\n",
        "                if dep not in visited:\n",
        "                    if has_cycle(dep):\n",
        "                        return True\n",
        "                elif dep in recursion_stack:\n",
        "                    return True\n",
        "\n",
        "            recursion_stack.remove(task_id)\n",
        "            return False\n",
        "\n",
        "        for task_id in self.task_store:\n",
        "            if task_id not in visited:\n",
        "                if has_cycle(task_id):\n",
        "                    raise ValueError(f\"Circular dependency detected involving task {task_id}\")\n",
        "\n",
        "        print(\"âœ“ DAG validation passed (no circular dependencies)\")\n",
        "\n",
        "    def execute_task(self, task_id: str, retries: int = 2):\n",
        "        \"\"\"Phase 2: Task execution with enhanced H2E accountability\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "        print(f\"ðŸš€ Dispatching [{task['agent_role']}]: {task_id}\")\n",
        "\n",
        "        # Build context from dependencies\n",
        "        context_parts = []\n",
        "        for dep in task['dependencies']:\n",
        "            if dep in self.results:\n",
        "                dep_content = self.results[dep]\n",
        "                if len(dep_content) > 1500:\n",
        "                    summary = self._summarize_content(dep_content[:2000])\n",
        "                    context_parts.append(f\"=== Summary from {dep} ===\\n{summary}\")\n",
        "                else:\n",
        "                    context_parts.append(f\"=== Result from {dep} ===\\n{dep_content}\")\n",
        "\n",
        "        context_text = \"\\n\\n\".join(context_parts) if context_parts else \"No dependencies\"\n",
        "\n",
        "        # Adjust tokens based on complexity\n",
        "        complexity = task.get('complexity_score', 0.5)\n",
        "        base_tokens = 3000\n",
        "        if complexity > 0.7:\n",
        "            max_tokens = 4000  # More tokens for complex tasks\n",
        "        elif complexity > 0.4:\n",
        "            max_tokens = 3500\n",
        "        else:\n",
        "            max_tokens = 3000\n",
        "\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                # Enhanced prompt with better guidance\n",
        "                system_prompt = f\"\"\"You are a {task['agent_role']}. Your task is: {task['description']}\n",
        "\n",
        "H2E ACCOUNTABILITY REQUIREMENTS:\n",
        "1. Provide a COMPLETE, self-contained response that addresses all aspects of the task\n",
        "2. Use clear hierarchical structure with appropriate headings/sections\n",
        "3. Include specific examples, evidence, or data where relevant\n",
        "4. End with a proper conclusion or summary that synthesizes key points\n",
        "5. Maintain professional tone and ensure technical accuracy\n",
        "6. If applicable, include actionable recommendations or next steps\n",
        "7. Consider the context from dependencies but provide original analysis\n",
        "\n",
        "OUTPUT FORMAT GUIDELINES:\n",
        "- Start with a clear title or heading for the entire response\n",
        "- Use markdown formatting (## for sections, ### for subsections)\n",
        "- Include bullet points or numbered lists for clarity\n",
        "- Add code examples in appropriate markdown format if relevant\n",
        "- Use tables for comparative information if helpful\n",
        "- Ensure the response is comprehensive yet focused\"\"\"\n",
        "\n",
        "                user_prompt = f\"\"\"TASK DESCRIPTION:\n",
        "{task['description']}\n",
        "\n",
        "TASK COMPLEXITY: {task.get('estimated_complexity', 'medium').upper()}\n",
        "\n",
        "CONTEXT FROM DEPENDENCIES:\n",
        "{context_text}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Provide a complete, well-structured response addressing the task description\n",
        "2. Use appropriate formatting (headings, lists, code blocks, etc.)\n",
        "3. Include specific details, examples, and evidence\n",
        "4. Ensure technical accuracy and completeness\n",
        "5. Conclude with a summary, key takeaways, or next steps\n",
        "6. Aim for depth and insight appropriate to the task complexity\n",
        "\n",
        "Your professional response:\"\"\"\n",
        "\n",
        "                response = client.messages.create(\n",
        "                    model=MODEL_NAME,\n",
        "                    max_tokens=max_tokens,\n",
        "                    temperature=0.7,\n",
        "                    system=system_prompt,\n",
        "                    messages=[{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": user_prompt\n",
        "                    }]\n",
        "                )\n",
        "\n",
        "                if hasattr(response, 'usage'):\n",
        "                    self.token_usage['input'] += response.usage.input_tokens\n",
        "                    self.token_usage['output'] += response.usage.output_tokens\n",
        "\n",
        "                result = response.content[0].text\n",
        "\n",
        "                # Enhanced quality checks before H2E scoring\n",
        "                quality_issues = self._pre_h2e_quality_check(task_id, result)\n",
        "                if quality_issues and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ Pre-H2E quality issues for {task_id}: {', '.join(quality_issues)}, retrying...\")\n",
        "                    continue\n",
        "\n",
        "                # H2E: Calculate alignment score\n",
        "                alignment_score = self.h2e.calculate_sroi(\n",
        "                    task_id=task_id,\n",
        "                    generated_output=result,\n",
        "                    task_description=task['description']\n",
        "                )\n",
        "\n",
        "                print(f\"   H2E/SROI: Alignment score: {alignment_score.score:.3f} (Raw: {alignment_score.raw_similarity:.3f})\")\n",
        "                print(f\"   Required: {alignment_score.threshold_required}, Confidence: {alignment_score.confidence:.2f}\")\n",
        "                print(f\"   Explanation: {alignment_score.explanation}\")\n",
        "\n",
        "                # Post-H2E quality check\n",
        "                quality_ok = self._post_h2e_quality_check(task_id, result, alignment_score)\n",
        "\n",
        "                # In calibration mode, don't retry for alignment failures\n",
        "                if not self.calibration_mode and not alignment_score.passed and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ H2E alignment failed for {task_id} (score: {alignment_score.score:.3f}), retrying...\")\n",
        "                    continue\n",
        "\n",
        "                if not quality_ok and attempt < retries - 1:\n",
        "                    print(f\"âš ï¸ Post-H2E quality check failed for {task_id}, retrying...\")\n",
        "                    continue\n",
        "\n",
        "                with self.task_lock:\n",
        "                    self.results[task_id] = result\n",
        "                    self.task_store[task_id]['status'] = TaskStatus.COMPLETED.value\n",
        "                    self.task_store[task_id]['h2e_score'] = alignment_score.score\n",
        "                    self.task_store[task_id]['h2e_passed'] = alignment_score.passed\n",
        "                    self.task_store[task_id]['h2e_raw_similarity'] = alignment_score.raw_similarity\n",
        "                    self.task_store[task_id]['h2e_confidence'] = alignment_score.confidence\n",
        "                    self.task_store[task_id]['completion_time'] = time.time()\n",
        "\n",
        "                self.completion_history.append({\n",
        "                    'task_id': task_id,\n",
        "                    'role': task['agent_role'],\n",
        "                    'timestamp': time.time(),\n",
        "                    'quality_check': quality_ok,\n",
        "                    'h2e_score': alignment_score.score,\n",
        "                    'h2e_raw_similarity': alignment_score.raw_similarity,\n",
        "                    'h2e_passed': alignment_score.passed,\n",
        "                    'h2e_confidence': alignment_score.confidence,\n",
        "                    'attempt': attempt + 1,\n",
        "                    'complexity': task.get('complexity_score', 0.5)\n",
        "                })\n",
        "\n",
        "                status_icon = \"ðŸ“Š\" if self.calibration_mode else \"âœ…\"\n",
        "                print(f\"{status_icon} Completed: {task_id} (H2E: {alignment_score.score:.3f}, Raw: {alignment_score.raw_similarity:.3f}, Attempt: {attempt + 1})\")\n",
        "                return\n",
        "\n",
        "            except anthropic.APIError as e:\n",
        "                if attempt < retries - 1:\n",
        "                    wait_time = 2 ** attempt\n",
        "                    print(f\"âš ï¸ API Error for {task_id} (attempt {attempt + 1}/{retries}): {e}. Retrying in {wait_time}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"âŒ Task {task_id} permanently failed after {retries} attempts: {e}\")\n",
        "                    with self.task_lock:\n",
        "                        self.task_store[task_id]['status'] = TaskStatus.FAILED.value\n",
        "                        self.task_store[task_id]['error'] = str(e)\n",
        "                        self.results[task_id] = f\"[Task failed: {e}]\"\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Unexpected error for {task_id}: {e}\")\n",
        "                with self.task_lock:\n",
        "                    self.task_store[task_id]['status'] = TaskStatus.FAILED.value\n",
        "                    self.task_store[task_id]['error'] = str(e)\n",
        "                    self.results[task_id] = f\"[Task failed: {e}]\"\n",
        "                break\n",
        "\n",
        "    def _summarize_content(self, content: str, max_length: int = 500) -> str:\n",
        "        \"\"\"Summarize content for context building\"\"\"\n",
        "        if len(content) <= max_length:\n",
        "            return content\n",
        "\n",
        "        # Simple summarization: take beginning and end\n",
        "        start = content[:max_length // 2]\n",
        "        end = content[-(max_length // 2):]\n",
        "        return f\"{start}\\n\\n[...content truncated...]\\n\\n{end}\"\n",
        "\n",
        "    def _pre_h2e_quality_check(self, task_id: str, content: str) -> List[str]:\n",
        "        \"\"\"Quick quality checks before H2E scoring\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "        issues = []\n",
        "\n",
        "        # Length check\n",
        "        content_len = len(content.strip())\n",
        "        if content_len < 200:\n",
        "            issues.append(f\"Too short ({content_len} chars)\")\n",
        "\n",
        "        # Check for extreme repetition\n",
        "        words = content.lower().split()\n",
        "        if len(words) > 100:\n",
        "            unique_ratio = len(set(words)) / len(words)\n",
        "            if unique_ratio < 0.3:  # Too repetitive\n",
        "                issues.append(f\"Low vocabulary diversity ({unique_ratio:.2f})\")\n",
        "\n",
        "        # Check for proper formatting (for longer content)\n",
        "        if content_len > 500:\n",
        "            has_headings = any(marker in content for marker in ['# ', '## ', '### '])\n",
        "            has_lists = any(marker in content for marker in ['- ', '* ', 'â€¢ ', '1. ', '2. '])\n",
        "            if not (has_headings or has_lists):\n",
        "                issues.append(\"Lacks structure (no headings/lists)\")\n",
        "\n",
        "        return issues\n",
        "\n",
        "    def _post_h2e_quality_check(self, task_id: str, content: str, alignment_score: AlignmentScore) -> bool:\n",
        "        \"\"\"Enhanced quality checks with H2E alignment\"\"\"\n",
        "        task = self.task_store[task_id]\n",
        "\n",
        "        issues = []\n",
        "\n",
        "        # Basic length check (role-specific)\n",
        "        role = task['agent_role']\n",
        "        content_len = len(content.strip())\n",
        "\n",
        "        if 'Writer' in role or 'Editor' in role:\n",
        "            min_length = 800\n",
        "        elif 'Researcher' in role or 'Analyst' in role:\n",
        "            min_length = 1000\n",
        "        else:\n",
        "            min_length = 500\n",
        "\n",
        "        if content_len < min_length:\n",
        "            issues.append(f\"Content too short ({content_len} < {min_length} chars)\")\n",
        "\n",
        "        # H2E alignment check (skip in calibration mode)\n",
        "        if not self.calibration_mode and alignment_score and not alignment_score.passed:\n",
        "            issues.append(f\"H2E alignment failed (score: {alignment_score.score:.3f}, required: {alignment_score.threshold_required})\")\n",
        "\n",
        "        # Structure check for substantial content\n",
        "        if content_len > 400:\n",
        "            has_structure = any(marker in content for marker in ['#', '##', '###', '1.', '2.', '3.', '- ', '* ', 'â€¢ '])\n",
        "            if not has_structure:\n",
        "                issues.append(\"Content lacks clear structure (no headings/lists)\")\n",
        "\n",
        "        # Check for completeness (proper ending)\n",
        "        trimmed_content = content.strip()\n",
        "        if trimmed_content:\n",
        "            # Check if ends with proper punctuation\n",
        "            if not any(trimmed_content.endswith(punct) for punct in ['.', '!', '?', '```']):\n",
        "                # Check last 100 chars for conclusion indicators\n",
        "                last_part = trimmed_content[-100:].lower()\n",
        "                if not any(indicator in last_part for indicator in ['conclusion', 'summary', 'finally', 'in summary', 'key takeaways', 'recommendations']):\n",
        "                    issues.append(\"Content may lack proper conclusion\")\n",
        "\n",
        "        # Check for placeholder text\n",
        "        placeholder_patterns = ['TODO:', 'FIXME:', 'INSERT', 'ADD HERE', 'TO BE DETERMINED']\n",
        "        for pattern in placeholder_patterns:\n",
        "            if pattern in content.upper():\n",
        "                issues.append(f\"Contains placeholder text ({pattern})\")\n",
        "\n",
        "        if issues:\n",
        "            print(f\"âš ï¸  Quality issues for {task_id}: {', '.join(issues)}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _get_ready_tasks(self) -> List[Tuple[float, str]]:\n",
        "        \"\"\"Get ready tasks with priority scores\"\"\"\n",
        "        ready_tasks = []\n",
        "\n",
        "        with self.task_lock:\n",
        "            for task_id, task in self.task_store.items():\n",
        "                if task['status'] == TaskStatus.PENDING.value:\n",
        "                    # Check dependencies\n",
        "                    deps_ready = True\n",
        "                    for dep in task['dependencies']:\n",
        "                        dep_task = self.task_store.get(dep)\n",
        "                        if not dep_task or dep_task['status'] != TaskStatus.COMPLETED.value:\n",
        "                            deps_ready = False\n",
        "                            break\n",
        "\n",
        "                    if deps_ready:\n",
        "                        priority = self._get_task_priority(task_id)\n",
        "                        ready_tasks.append((priority, task_id))\n",
        "\n",
        "        # Sort by priority (higher priority first)\n",
        "        ready_tasks.sort()\n",
        "        return ready_tasks\n",
        "\n",
        "    def show_progress_bar(self):\n",
        "        \"\"\"Visual progress bar with H2E indicators\"\"\"\n",
        "        with self.task_lock:\n",
        "            completed = sum(1 for t in self.task_store.values() if t['status'] == TaskStatus.COMPLETED.value)\n",
        "            total = self.total_tasks\n",
        "\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        with self.task_lock:\n",
        "            h2e_scores = [t.get('h2e_score', 0) for t in self.task_store.values()\n",
        "                         if t['status'] == TaskStatus.COMPLETED.value and 'h2e_score' in t]\n",
        "\n",
        "        avg_h2e = np.mean(h2e_scores) if h2e_scores else 0\n",
        "\n",
        "        bar_length = 40\n",
        "        filled_length = int(bar_length * completed // total)\n",
        "        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
        "        percentage = (completed / total) * 100\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "\n",
        "        mode_indicator = \" [CAL]\" if self.calibration_mode else \"\"\n",
        "        h2e_indicator = f\" | H2E: {avg_h2e:.3f}\" if h2e_scores else \"\"\n",
        "\n",
        "        # Add ETA if possible\n",
        "        eta = \"\"\n",
        "        if completed > 0 and elapsed > 10:\n",
        "            remaining = total - completed\n",
        "            time_per_task = elapsed / completed\n",
        "            eta_seconds = remaining * time_per_task\n",
        "            if eta_seconds < 60:\n",
        "                eta = f\" | ETA: {eta_seconds:.0f}s\"\n",
        "            else:\n",
        "                eta = f\" | ETA: {eta_seconds/60:.1f}m\"\n",
        "\n",
        "        print(f\"\\rProgress{mode_indicator}: |{bar}| {completed}/{total} ({percentage:.1f}%){h2e_indicator}{eta} | â±ï¸ {elapsed:.1f}s\",\n",
        "              end='', flush=True)\n",
        "\n",
        "    def print_progress(self):\n",
        "        \"\"\"Display execution progress\"\"\"\n",
        "        completed = 0\n",
        "        total = 0\n",
        "\n",
        "        with self.task_lock:\n",
        "            completed = sum(1 for t in self.task_store.values() if t['status'] == TaskStatus.COMPLETED.value)\n",
        "            total = self.total_tasks\n",
        "\n",
        "        if total == 0:\n",
        "            return\n",
        "\n",
        "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
        "\n",
        "        self.show_progress_bar()\n",
        "\n",
        "        # Show running tasks occasionally\n",
        "        if int(elapsed) % 15 == 0:\n",
        "            print()\n",
        "\n",
        "            running_tasks = []\n",
        "            with self.task_lock:\n",
        "                for task_id, task in self.task_store.items():\n",
        "                    if task['status'] == TaskStatus.RUNNING.value:\n",
        "                        h2e_info = \"\"\n",
        "                        if 'h2e_score' in task:\n",
        "                            h2e_info = f\" (H2E: {task['h2e_score']:.3f})\"\n",
        "                        running_tasks.append(f\"{task_id}{h2e_info}\")\n",
        "\n",
        "            if running_tasks:\n",
        "                print(f\"   Active: {', '.join(running_tasks)}\")\n",
        "\n",
        "    def estimate_cost(self) -> float:\n",
        "        \"\"\"Estimate API costs\"\"\"\n",
        "        # Claude Opus pricing (updated)\n",
        "        input_cost_per_million = 75.00  # $75.00 per million input tokens\n",
        "        output_cost_per_million = 375.00  # $375.00 per million output tokens\n",
        "\n",
        "        input_cost = (self.token_usage['input'] / 1_000_000) * input_cost_per_million\n",
        "        output_cost = (self.token_usage['output'] / 1_000_000) * output_cost_per_million\n",
        "        total_cost = input_cost + output_cost\n",
        "\n",
        "        print(f\"\\nðŸ’° Cost Estimation:\")\n",
        "        print(f\"   Input tokens: {self.token_usage['input']:,} â‰ˆ ${input_cost:.4f}\")\n",
        "        print(f\"   Output tokens: {self.token_usage['output']:,} â‰ˆ ${output_cost:.4f}\")\n",
        "        print(f\"   Total estimated: ${total_cost:.4f}\")\n",
        "\n",
        "        return total_cost\n",
        "\n",
        "    def run_orchestration(self, timeout_seconds: int = 1200):\n",
        "        \"\"\"Phase 3: Enhanced execution loop with H2E accountability\"\"\"\n",
        "        mode_label = \"CALIBRATION\" if self.calibration_mode else \"ACCOUNTABLE\"\n",
        "        print(f\"âš™ï¸ Orchestrator: Starting execution loop...\")\n",
        "        print(f\"ðŸ”’ H2E Accountability Framework: {mode_label}\")\n",
        "        print(f\"ðŸ‘¥ Max Workers: {self.max_workers}\")\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            futures: Dict[str, Future] = {}\n",
        "\n",
        "            while True:\n",
        "                current_time = time.time()\n",
        "\n",
        "                # Timeout check\n",
        "                if current_time - self.start_time > timeout_seconds:\n",
        "                    print(f\"\\nâ° Timeout after {timeout_seconds} seconds\")\n",
        "                    break\n",
        "\n",
        "                # Progress display\n",
        "                self.print_progress()\n",
        "\n",
        "                # Get ready tasks\n",
        "                ready_tasks = self._get_ready_tasks()\n",
        "\n",
        "                # Submit ready tasks\n",
        "                for priority, task_id in ready_tasks:\n",
        "                    if task_id not in futures or futures[task_id].done():\n",
        "                        with self.task_lock:\n",
        "                            self.task_store[task_id]['status'] = TaskStatus.RUNNING.value\n",
        "\n",
        "                        future = executor.submit(self.execute_task, task_id)\n",
        "                        futures[task_id] = future\n",
        "\n",
        "                        # Limit concurrent submissions\n",
        "                        if len([f for f in futures.values() if not f.done()]) >= self.max_workers:\n",
        "                            break\n",
        "\n",
        "                # Check completion\n",
        "                all_done = True\n",
        "                with self.task_lock:\n",
        "                    for task in self.task_store.values():\n",
        "                        if task['status'] not in [TaskStatus.COMPLETED.value, TaskStatus.FAILED.value]:\n",
        "                            all_done = False\n",
        "                            break\n",
        "\n",
        "                if all_done:\n",
        "                    print(\"\\n\\nðŸŽ¯ All tasks completed!\")\n",
        "                    break\n",
        "\n",
        "                # Clean up completed futures\n",
        "                completed_tasks = [task_id for task_id, future in futures.items() if future.done()]\n",
        "                for task_id in completed_tasks:\n",
        "                    if task_id in futures:\n",
        "                        del futures[task_id]\n",
        "\n",
        "                # Small sleep to prevent CPU spinning\n",
        "                time.sleep(0.2)\n",
        "\n",
        "        print()\n",
        "        self.show_progress_bar()\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        return self.results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    CALIBRATION_MODE = True  # Set to True for first run to establish baselines\n",
        "    MAX_WORKERS = 3  # Adjust based on your API rate limits\n",
        "\n",
        "    # Initialize orchestrator\n",
        "    orch = Orchestrator(calibration_mode=CALIBRATION_MODE, max_workers=MAX_WORKERS)\n",
        "\n",
        "    # User goal - you can modify this\n",
        "    user_goal = \"\"\"Create a comprehensive guide on implementing zero-trust security architecture in Kubernetes:\n",
        "    1. Research current best practices and frameworks\n",
        "    2. Write detailed implementation guide with examples\n",
        "    3. Review and refine the content for technical accuracy\n",
        "    4. Create a summary for executive audience\"\"\"\n",
        "\n",
        "    try:\n",
        "        mode_str = \"CALIBRATION\" if CALIBRATION_MODE else \"ACCOUNTABLE\"\n",
        "        print(f\"ðŸš€ Starting DAG Orchestrator with H2E {mode_str} Mode\")\n",
        "        print(f\"Goal: {user_goal}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Phase 1: Planning\n",
        "        plan = orch.get_plan(user_goal)\n",
        "\n",
        "        print(\"\\nðŸ“‹ Task Plan:\")\n",
        "        for i, task in enumerate(plan['tasks'], 1):\n",
        "            deps = ', '.join(task['dependencies']) if task['dependencies'] else 'None'\n",
        "            complexity = task.get('estimated_complexity', 'medium')\n",
        "            print(f\"  {i}. {task['id']}: {task['description'][:100]}...\")\n",
        "            print(f\"     Role: {task['agent_role']}, Complexity: {complexity.upper()}, Depends on: {deps}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Starting execution...\\n\")\n",
        "\n",
        "        # Phase 2 & 3: Execution\n",
        "        results = orch.run_orchestration()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\nðŸ BUILD COMPLETE\\n\" + \"=\"*60)\n",
        "\n",
        "        # Statistics\n",
        "        successful = sum(1 for t in orch.task_store.values() if t['status'] == TaskStatus.COMPLETED.value)\n",
        "        failed = sum(1 for t in orch.task_store.values() if t['status'] == TaskStatus.FAILED.value)\n",
        "\n",
        "        h2e_scores = [t.get('h2e_score', 0) for t in orch.task_store.values()\n",
        "                     if t.get('status') == TaskStatus.COMPLETED.value and 'h2e_score' in t]\n",
        "        h2e_raw_sims = [t.get('h2e_raw_similarity', 0) for t in orch.task_store.values()\n",
        "                       if t.get('status') == TaskStatus.COMPLETED.value and 'h2e_raw_similarity' in t]\n",
        "        avg_h2e = np.mean(h2e_scores) if h2e_scores else 0\n",
        "        avg_raw_sim = np.mean(h2e_raw_sims) if h2e_raw_sims else 0\n",
        "        h2e_passed = sum(1 for t in orch.task_store.values()\n",
        "                        if t.get('h2e_passed', False))\n",
        "\n",
        "        print(f\"\\nðŸ“ˆ Summary:\")\n",
        "        print(f\"   Tasks: {successful} successful, {failed} failed\")\n",
        "\n",
        "        if CALIBRATION_MODE:\n",
        "            print(f\"   H2E Calibration Scores: Avg {avg_h2e:.3f} (Raw cosine: {avg_raw_sim:.3f})\")\n",
        "            # Analyze calibration data\n",
        "            recommendations = orch.h2e.analyze_calibration_data()\n",
        "            print(f\"\\nðŸ’¡ Recommendations for production thresholds:\")\n",
        "            for role, threshold in recommendations.items():\n",
        "                print(f\"   {role}: {threshold:.3f}\")\n",
        "        else:\n",
        "            print(f\"   H2E Alignment: {h2e_passed}/{successful} passed, Avg score: {avg_h2e:.3f}\")\n",
        "\n",
        "        # Generate and display H2E report\n",
        "        print(\"\\nðŸ“Š H2E Accountability Report:\")\n",
        "        h2e_report = orch.h2e.save_report(\"output/h2e_accountability_report.json\")\n",
        "\n",
        "        if 'h2e_framework_report' in h2e_report:\n",
        "            report_data = h2e_report['h2e_framework_report']\n",
        "            print(f\"   Timestamp: {report_data.get('timestamp', 'N/A')}\")\n",
        "            print(f\"   Tasks Evaluated: {report_data.get('total_tasks_evaluated', 0)}\")\n",
        "            print(f\"   Average SROI: {report_data.get('average_sroi_score', 0):.3f}\")\n",
        "            print(f\"   Average Raw Similarity: {report_data.get('average_raw_similarity', 0):.3f}\")\n",
        "            print(f\"   Alignment Pass Rate: {report_data.get('alignment_pass_rate', '0%')}\")\n",
        "            print(f\"   Recommended Threshold: {report_data.get('recommended_threshold', 0):.3f}\")\n",
        "\n",
        "            if 'task_breakdown' in report_data:\n",
        "                print(f\"\\n   Task Breakdown:\")\n",
        "                for task in report_data['task_breakdown']:\n",
        "                    status = \"âœ…\" if task['passed'] else \"âŒ\"\n",
        "                    complexity_star = \"â­\" * max(1, int(task.get('complexity', 0.5) * 3))\n",
        "                    print(f\"     {status} {task['task_id']} ({task['role']}) {complexity_star}\")\n",
        "                    print(f\"        Score: {task['sroi_score']:.3f} (Raw: {task['raw_similarity']:.3f})\")\n",
        "                    print(f\"        Required: {task['required_threshold']:.3f}, Confidence: {task.get('confidence', 0.5):.2f}\")\n",
        "                    print(f\"        {task['explanation']}\")\n",
        "\n",
        "        # Cost estimation\n",
        "        orch.estimate_cost()\n",
        "\n",
        "        # Save outputs\n",
        "        os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "        print(\"\\nðŸ“‚ Output Files:\")\n",
        "        for tid, content in results.items():\n",
        "            status = orch.task_store[tid]['status']\n",
        "            role = orch.task_store[tid]['agent_role']\n",
        "            h2e_score = orch.task_store[tid].get('h2e_score', 'N/A')\n",
        "            h2e_raw = orch.task_store[tid].get('h2e_raw_similarity', 'N/A')\n",
        "\n",
        "            clean_role = role.replace(' ', '_').replace('/', '_')\n",
        "            filename = f\"output/{tid}_{clean_role}.md\"  # Using markdown extension\n",
        "\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"# Task: {tid}\\n\")\n",
        "                f.write(f\"**Role**: {role}\\n\")\n",
        "                f.write(f\"**Status**: {status}\\n\")\n",
        "                f.write(f\"**H2E Alignment Score**: {h2e_score} (Raw: {h2e_raw})\\n\")\n",
        "                f.write(f\"**H2E Confidence**: {orch.task_store[tid].get('h2e_confidence', 'N/A')}\\n\")\n",
        "                f.write(f\"**Generated**: {time.ctime()}\\n\")\n",
        "                f.write(f\"\\n---\\n\\n\")\n",
        "                f.write(content)\n",
        "\n",
        "            print(f\"  {tid}: {filename} (H2E: {h2e_score}, Raw: {h2e_raw})\")\n",
        "\n",
        "        # Save completion history\n",
        "        with open(\"output/completion_history.json\", \"w\") as f:\n",
        "            json.dump(orch.completion_history, f, indent=2, default=str)\n",
        "        print(\"  Completion History: output/completion_history.json\")\n",
        "\n",
        "        # Save task plan\n",
        "        with open(\"output/task_plan.json\", \"w\") as f:\n",
        "            json.dump(plan, f, indent=2)\n",
        "        print(\"  Task Plan: output/task_plan.json\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"âœ¨ Orchestration completed successfully!\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nâš ï¸ Orchestration interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ FATAL ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8C1nBJwc5hI",
        "outputId": "0e9b199f-e197-4d61-e436-cd570061113a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting DAG Orchestrator with H2E CALIBRATION Mode\n",
            "Goal: Create a comprehensive guide on implementing zero-trust security architecture in Kubernetes:\n",
            "    1. Research current best practices and frameworks\n",
            "    2. Write detailed implementation guide with examples\n",
            "    3. Review and refine the content for technical accuracy\n",
            "    4. Create a summary for executive audience\n",
            "------------------------------------------------------------\n",
            "ðŸ§  Brain: Planning via claude-opus-4-6...\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task1 (Research Analyst, complexity: 0.54)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task2 (Technical Writer, complexity: 0.55)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task3 (Technical Reviewer, complexity: 0.57)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task4 (Technical Writer, complexity: 0.43)\n",
            "ðŸ“Š H2E/NEZ: Captured expert intent for task5 (Technical Writer, complexity: 0.52)\n",
            "âœ“ Planned 5 tasks\n",
            "âœ“ DAG validation passed (no circular dependencies)\n",
            "\n",
            "ðŸ“‹ Task Plan:\n",
            "  1. task1: Research current best practices, frameworks, and industry standards for zero-trust security architec...\n",
            "     Role: Research Analyst, Complexity: HIGH, Depends on: None\n",
            "  2. task2: Based on the research findings, write a detailed implementation guide for zero-trust security archit...\n",
            "     Role: Technical Writer, Complexity: HIGH, Depends on: task1\n",
            "  3. task3: Perform a thorough technical review of the implementation guide for accuracy, completeness, and secu...\n",
            "     Role: Technical Reviewer, Complexity: HIGH, Depends on: task2\n",
            "  4. task4: Incorporate all feedback and corrections from the technical review into the implementation guide. Re...\n",
            "     Role: Technical Writer, Complexity: MEDIUM, Depends on: task3\n",
            "  5. task5: Create a concise executive summary (2-3 pages) of the zero-trust Kubernetes security guide tailored ...\n",
            "     Role: Technical Writer, Complexity: MEDIUM, Depends on: task4\n",
            "\n",
            "============================================================\n",
            "Starting execution...\n",
            "\n",
            "âš™ï¸ Orchestrator: Starting execution loop...\n",
            "ðŸ”’ H2E Accountability Framework: CALIBRATION\n",
            "ðŸ‘¥ Max Workers: 3\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 0.0s\n",
            "ðŸš€ Dispatching [Research Analyst]: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 0.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 0.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 0.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 0.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 15.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 15.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 15.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 15.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 15.9s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 30.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 30.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 30.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 30.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 30.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 45.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 45.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 45.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 45.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 46.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 60.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 60.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 60.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 60.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 60.9s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 72.2s   H2E/SROI: Alignment score: 0.875 (Raw: 0.635)\n",
            "   Required: 0.808, Confidence: 0.85\n",
            "   Explanation: High semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task1: Content may lack proper conclusion\n",
            "âš ï¸ Post-H2E quality check failed for task1, retrying...\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 75.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 75.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 75.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 75.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 75.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 90.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 90.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 90.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 90.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 91.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 105.1s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 105.3s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 105.5s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 105.7s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 105.9s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 120.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 120.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 120.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 120.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 120.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 135.2s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 135.4s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 135.6s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 135.8s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 136.0s\n",
            "   Active: task1\n",
            "Progress [CAL]: |â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0/5 (0.0%) | â±ï¸ 145.0s   H2E/SROI: Alignment score: 0.877 (Raw: 0.665)\n",
            "   Required: 0.81, Confidence: 0.85\n",
            "   Explanation: High semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task1: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task1 (H2E: 0.877, Raw: 0.665, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 9.7m | â±ï¸ 145.2sðŸš€ Dispatching [Technical Writer]: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 10.0m | â±ï¸ 150.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 10.0m | â±ï¸ 150.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 10.0m | â±ï¸ 150.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 10.0m | â±ï¸ 150.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 10.1m | â±ï¸ 150.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 11.0m | â±ï¸ 165.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 11.0m | â±ï¸ 165.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 11.0m | â±ï¸ 165.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 11.0m | â±ï¸ 165.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 11.1m | â±ï¸ 165.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 12.0m | â±ï¸ 180.2s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 12.0m | â±ï¸ 180.4s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 12.0m | â±ï¸ 180.6s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 12.1m | â±ï¸ 180.8s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 12.1m | â±ï¸ 181.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.0m | â±ï¸ 195.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.0m | â±ï¸ 195.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.0m | â±ï¸ 195.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.0m | â±ï¸ 195.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.1m | â±ï¸ 195.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 13.8m | â±ï¸ 206.4s   H2E/SROI: Alignment score: 0.905 (Raw: 0.663)\n",
            "   Required: 0.533, Confidence: 0.84\n",
            "   Explanation: High semantic similarity. Excellent alignment exceeding requirements by 70%\n",
            "âš ï¸  Quality issues for task2: Content may lack proper conclusion\n",
            "âš ï¸ Post-H2E quality check failed for task2, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 14.0m | â±ï¸ 210.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 14.0m | â±ï¸ 210.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 14.0m | â±ï¸ 210.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 14.0m | â±ï¸ 210.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 14.1m | â±ï¸ 210.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 15.0m | â±ï¸ 225.2s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 15.0m | â±ï¸ 225.4s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 15.0m | â±ï¸ 225.6s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 15.1m | â±ï¸ 225.8s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 16.0m | â±ï¸ 240.1s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 16.0m | â±ï¸ 240.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 16.0m | â±ï¸ 240.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 16.0m | â±ï¸ 240.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 16.1m | â±ï¸ 240.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.0m | â±ï¸ 255.0s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.0m | â±ï¸ 255.3s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.0m | â±ï¸ 255.5s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.0m | â±ï¸ 255.7s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.1m | â±ï¸ 255.9s\n",
            "   Active: task2\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 1/5 (20.0%) | H2E: 0.877 | ETA: 17.6m | â±ï¸ 264.3s   H2E/SROI: Alignment score: 0.908 (Raw: 0.653)\n",
            "   Required: 0.555, Confidence: 0.83\n",
            "   Explanation: High semantic similarity. Excellent alignment exceeding requirements by 64%\n",
            "âš ï¸  Quality issues for task2: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task2 (H2E: 0.908, Raw: 0.653, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.6m | â±ï¸ 264.5sðŸš€ Dispatching [Technical Reviewer]: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.8m | â±ï¸ 270.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.8m | â±ï¸ 270.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.8m | â±ï¸ 270.6s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.8m | â±ï¸ 270.8s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 6.8m | â±ï¸ 271.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.1m | â±ï¸ 285.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.1m | â±ï¸ 285.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.1m | â±ï¸ 285.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.1m | â±ï¸ 285.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.1m | â±ï¸ 285.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.5m | â±ï¸ 300.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.5m | â±ï¸ 300.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.5m | â±ï¸ 300.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.5m | â±ï¸ 300.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.5m | â±ï¸ 300.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.9m | â±ï¸ 315.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.9m | â±ï¸ 315.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.9m | â±ï¸ 315.6s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.9m | â±ï¸ 315.8s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 7.9m | â±ï¸ 316.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 330.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 330.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 330.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 330.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 330.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.3m | â±ï¸ 333.0s   H2E/SROI: Alignment score: 0.836 (Raw: 0.609)\n",
            "   Required: 0.85, Confidence: 0.83\n",
            "   Explanation: High semantic similarity. Moderate alignment, 0.014 below threshold\n",
            "âš ï¸  Quality issues for task3: Content may lack proper conclusion\n",
            "âš ï¸ Post-H2E quality check failed for task3, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.6m | â±ï¸ 345.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.6m | â±ï¸ 345.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.6m | â±ï¸ 345.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.6m | â±ï¸ 345.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 8.6m | â±ï¸ 345.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.0m | â±ï¸ 360.2s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.0m | â±ï¸ 360.4s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.0m | â±ï¸ 360.6s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.0m | â±ï¸ 360.8s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.0m | â±ï¸ 361.0s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.4m | â±ï¸ 375.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.4m | â±ï¸ 375.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.4m | â±ï¸ 375.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.4m | â±ï¸ 375.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.4m | â±ï¸ 375.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.8m | â±ï¸ 390.1s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.8m | â±ï¸ 390.3s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.8m | â±ï¸ 390.5s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.8m | â±ï¸ 390.7s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 9.8m | â±ï¸ 390.9s\n",
            "   Active: task3\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 2/5 (40.0%) | H2E: 0.892 | ETA: 10.1m | â±ï¸ 404.6s   H2E/SROI: Alignment score: 0.914 (Raw: 0.613)\n",
            "   Required: 0.846, Confidence: 0.82\n",
            "   Explanation: High semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task3: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task3 (H2E: 0.914, Raw: 0.613, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 404.8sðŸš€ Dispatching [Technical Writer]: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 405.2s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 405.4s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 405.6s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 405.8s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.5m | â±ï¸ 406.0s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.7m | â±ï¸ 420.1s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.7m | â±ï¸ 420.3s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.7m | â±ï¸ 420.5s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.7m | â±ï¸ 420.7s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.7m | â±ï¸ 420.9s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.8m | â±ï¸ 435.0s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.8m | â±ï¸ 435.2s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.8m | â±ï¸ 435.4s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.8m | â±ï¸ 435.6s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 4.8m | â±ï¸ 435.8s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.0m | â±ï¸ 450.2s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.0m | â±ï¸ 450.4s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.0m | â±ï¸ 450.6s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.0m | â±ï¸ 450.8s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.0m | â±ï¸ 451.0s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 465.1s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 465.3s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 465.5s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 465.7s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 465.9s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.2m | â±ï¸ 471.1s   H2E/SROI: Alignment score: 0.823 (Raw: 0.536)\n",
            "   Required: 0.65, Confidence: 0.86\n",
            "   Explanation: Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task4: Content may lack proper conclusion\n",
            "âš ï¸ Post-H2E quality check failed for task4, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.3m | â±ï¸ 480.0s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.3m | â±ï¸ 480.2s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.3m | â±ï¸ 480.4s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.3m | â±ï¸ 480.6s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.3m | â±ï¸ 480.8s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.5m | â±ï¸ 495.1s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.5m | â±ï¸ 495.3s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.5m | â±ï¸ 495.5s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.5m | â±ï¸ 495.7s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.5m | â±ï¸ 495.9s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.7m | â±ï¸ 510.1s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.7m | â±ï¸ 510.3s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.7m | â±ï¸ 510.5s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.7m | â±ï¸ 510.7s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.7m | â±ï¸ 510.9s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.8m | â±ï¸ 525.2s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.8m | â±ï¸ 525.4s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.8m | â±ï¸ 525.6s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 5.8m | â±ï¸ 525.8s\n",
            "   Active: task4\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 3/5 (60.0%) | H2E: 0.899 | ETA: 6.0m | â±ï¸ 535.7s   H2E/SROI: Alignment score: 0.821 (Raw: 0.506)\n",
            "   Required: 0.689, Confidence: 0.87\n",
            "   Explanation: Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task4: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task4 (H2E: 0.821, Raw: 0.506, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.2m | â±ï¸ 535.9sðŸš€ Dispatching [Technical Writer]: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 540.1s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 540.3s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 540.5s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 540.7s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 540.9s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 555.1s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 555.3s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 555.5s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 555.7s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.3m | â±ï¸ 555.9s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 570.2s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 570.4s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 570.6s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 570.8s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 571.0s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 585.1s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 585.3s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 585.5s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 585.7s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.4m | â±ï¸ 585.9s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 600.0s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 600.2s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 600.4s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 600.6s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 600.8s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.5m | â±ï¸ 602.2s   H2E/SROI: Alignment score: 0.829 (Raw: 0.566)\n",
            "   Required: 0.732, Confidence: 0.84\n",
            "   Explanation: Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task5: Content may lack proper conclusion\n",
            "âš ï¸ Post-H2E quality check failed for task5, retrying...\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 615.2s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 615.4s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 615.6s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 615.8s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 616.0s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 630.1s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 630.3s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 630.5s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 630.7s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.6m | â±ï¸ 630.9s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.7m | â±ï¸ 645.0s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.7m | â±ï¸ 645.2s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.7m | â±ï¸ 645.4s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.7m | â±ï¸ 645.6s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.7m | â±ï¸ 645.8s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 660.1s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 660.3s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 660.5s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 660.7s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 660.9s\n",
            "   Active: task5\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 4/5 (80.0%) | H2E: 0.880 | ETA: 2.8m | â±ï¸ 669.8s   H2E/SROI: Alignment score: 0.828 (Raw: 0.550)\n",
            "   Required: 0.759, Confidence: 0.85\n",
            "   Explanation: Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "âš ï¸  Quality issues for task5: Content may lack proper conclusion\n",
            "ðŸ“Š Completed: task5 (H2E: 0.828, Raw: 0.550, Attempt: 2)\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 (100.0%) | H2E: 0.869 | ETA: 0s | â±ï¸ 670.0s\n",
            "\n",
            "ðŸŽ¯ All tasks completed!\n",
            "\n",
            "Progress [CAL]: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 (100.0%) | H2E: 0.869 | ETA: 0s | â±ï¸ 670.0s\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ BUILD COMPLETE\n",
            "============================================================\n",
            "\n",
            "ðŸ“ˆ Summary:\n",
            "   Tasks: 5 successful, 0 failed\n",
            "   H2E Calibration Scores: Avg 0.869 (Raw cosine: 0.598)\n",
            "\n",
            "ðŸ”§ H2E Calibration Analysis:\n",
            "==================================================\n",
            "\n",
            "  Research Analyst:\n",
            "    Samples: 2\n",
            "    Average Score: 0.876\n",
            "    Raw Cosine Sim: 0.650\n",
            "    Std Dev: 0.001\n",
            "    Avg Complexity: 0.539\n",
            "    Avg Confidence: 0.848\n",
            "    Recommended Threshold: 0.850\n",
            "\n",
            "  Technical Writer:\n",
            "    Samples: 6\n",
            "    Average Score: 0.852\n",
            "    Raw Cosine Sim: 0.579\n",
            "    Std Dev: 0.038\n",
            "    Avg Complexity: 0.499\n",
            "    Avg Confidence: 0.847\n",
            "    Recommended Threshold: 0.850\n",
            "    Score Distribution:\n",
            "      10%: 0.822, 25%: 0.824, 50%: 0.829\n",
            "      75%: 0.886, 90%: 0.906\n",
            "\n",
            "  Technical Reviewer:\n",
            "    Samples: 2\n",
            "    Average Score: 0.875\n",
            "    Raw Cosine Sim: 0.611\n",
            "    Std Dev: 0.039\n",
            "    Avg Complexity: 0.568\n",
            "    Avg Confidence: 0.829\n",
            "    Recommended Threshold: 0.850\n",
            "\n",
            "ðŸ’¡ Recommendations for production thresholds:\n",
            "   Research Analyst: 0.850\n",
            "   Technical Writer: 0.850\n",
            "   Technical Reviewer: 0.850\n",
            "\n",
            "ðŸ“Š H2E Accountability Report:\n",
            "âœ“ H2E report saved to output/h2e_accountability_report.json\n",
            "   Timestamp: 2026-02-08T14:25:48.543775\n",
            "   Tasks Evaluated: 10\n",
            "   Average SROI: 0.861\n",
            "   Average Raw Similarity: 0.600\n",
            "   Alignment Pass Rate: 100.0%\n",
            "   Recommended Threshold: 0.843\n",
            "\n",
            "   Task Breakdown:\n",
            "     âœ… task5 (Technical Writer) â­\n",
            "        Score: 0.828 (Raw: 0.550)\n",
            "        Required: 0.759, Confidence: 0.85\n",
            "        Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task4 (Technical Writer) â­\n",
            "        Score: 0.821 (Raw: 0.506)\n",
            "        Required: 0.689, Confidence: 0.87\n",
            "        Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task3 (Technical Reviewer) â­\n",
            "        Score: 0.914 (Raw: 0.613)\n",
            "        Required: 0.846, Confidence: 0.82\n",
            "        High semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task2 (Technical Writer) â­\n",
            "        Score: 0.908 (Raw: 0.653)\n",
            "        Required: 0.555, Confidence: 0.83\n",
            "        High semantic similarity. Excellent alignment exceeding requirements by 64%\n",
            "     âœ… task1 (Research Analyst) â­\n",
            "        Score: 0.877 (Raw: 0.665)\n",
            "        Required: 0.810, Confidence: 0.85\n",
            "        High semantic similarity. Adequate alignment meeting requirements\n",
            "\n",
            "ðŸ’° Cost Estimation:\n",
            "   Input tokens: 7,588 â‰ˆ $0.5691\n",
            "   Output tokens: 37,957 â‰ˆ $14.2339\n",
            "   Total estimated: $14.8030\n",
            "\n",
            "ðŸ“‚ Output Files:\n",
            "  task1: output/task1_Research_Analyst.md (H2E: 0.876843859753982, Raw: 0.6650100719878841)\n",
            "  task2: output/task2_Technical_Writer.md (H2E: 0.9075079691788318, Raw: 0.653444782548064)\n",
            "  task3: output/task3_Technical_Reviewer.md (H2E: 0.9135132851606678, Raw: 0.6134717094926956)\n",
            "  task4: output/task4_Technical_Writer.md (H2E: 0.8207575560348271, Raw: 0.5060779176284711)\n",
            "  task5: output/task5_Technical_Writer.md (H2E: 0.8276257236502758, Raw: 0.5499242612216159)\n",
            "  Completion History: output/completion_history.json\n",
            "  Task Plan: output/task_plan.json\n",
            "\n",
            "============================================================\n",
            "âœ¨ Orchestration completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“‹ Task Plan:\")\n",
        "for i, task in enumerate(plan['tasks'], 1):\n",
        "    deps = ', '.join(task['dependencies']) if task['dependencies'] else 'None'\n",
        "    complexity = task.get('estimated_complexity', 'medium')\n",
        "    print(f\"  {i}. {task['id']}: {task['description'][:100]}...\")\n",
        "    print(f\"     Role: {task['agent_role']}, Complexity: {complexity.upper()}, Depends on: {deps}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\nðŸ BUILD COMPLETE\\n\" + \"=\"*60)\n",
        "\n",
        "# Statistics\n",
        "successful = sum(1 for t in orch.task_store.values() if t['status'] == TaskStatus.COMPLETED.value)\n",
        "failed = sum(1 for t in orch.task_store.values() if t['status'] == TaskStatus.FAILED.value)\n",
        "\n",
        "h2e_scores = [t.get('h2e_score', 0) for t in orch.task_store.values()\n",
        "              if t.get('status') == TaskStatus.COMPLETED.value and 'h2e_score' in t]\n",
        "h2e_raw_sims = [t.get('h2e_raw_similarity', 0) for t in orch.task_store.values()\n",
        "                if t.get('status') == TaskStatus.COMPLETED.value and 'h2e_raw_similarity' in t]\n",
        "avg_h2e = np.mean(h2e_scores) if h2e_scores else 0\n",
        "avg_raw_sim = np.mean(h2e_raw_sims) if h2e_raw_sims else 0\n",
        "h2e_passed = sum(1 for t in orch.task_store.values()\n",
        "                if t.get('h2e_passed', False))\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Summary:\")\n",
        "print(f\"   Tasks: {successful} successful, {failed} failed\")\n",
        "\n",
        "if CALIBRATION_MODE:\n",
        "    print(f\"   H2E Calibration Scores: Avg {avg_h2e:.3f} (Raw cosine: {avg_raw_sim:.3f})\")\n",
        "    # Analyze calibration data\n",
        "    recommendations = orch.h2e.analyze_calibration_data()\n",
        "    print(f\"\\nðŸ’¡ Recommendations for production thresholds:\")\n",
        "    for role, threshold in recommendations.items():\n",
        "        print(f\"   {role}: {threshold:.3f}\")\n",
        "else:\n",
        "    print(f\"   H2E Alignment: {h2e_passed}/{successful} passed, Avg score: {avg_h2e:.3f}\")\n",
        "\n",
        "# Generate and display H2E report\n",
        "print(\"\\nðŸ“Š H2E Accountability Report:\")\n",
        "h2e_report = orch.h2e.save_report(\"output/h2e_accountability_report.json\")\n",
        "\n",
        "if 'h2e_framework_report' in h2e_report:\n",
        "    report_data = h2e_report['h2e_framework_report']\n",
        "    print(f\"   Timestamp: {report_data.get('timestamp', 'N/A')}\")\n",
        "    print(f\"   Tasks Evaluated: {report_data.get('total_tasks_evaluated', 0)}\")\n",
        "    print(f\"   Average SROI: {report_data.get('average_sroi_score', 0):.3f}\")\n",
        "    print(f\"   Average Raw Similarity: {report_data.get('average_raw_similarity', 0):.3f}\")\n",
        "    print(f\"   Alignment Pass Rate: {report_data.get('alignment_pass_rate', '0%')}\")\n",
        "    print(f\"   Recommended Threshold: {report_data.get('recommended_threshold', 0):.3f}\")\n",
        "\n",
        "    if 'task_breakdown' in report_data:\n",
        "        print(f\"\\n   Task Breakdown:\")\n",
        "        for task in report_data['task_breakdown']:\n",
        "            status = \"âœ…\" if task['passed'] else \"âŒ\"\n",
        "            complexity_star = \"â­\" * max(1, int(task.get('complexity', 0.5) * 3))\n",
        "            print(f\"     {status} {task['task_id']} ({task['role']}) {complexity_star}\")\n",
        "            print(f\"        Score: {task['sroi_score']:.3f} (Raw: {task['raw_similarity']:.3f})\")\n",
        "            print(f\"        Required: {task['required_threshold']:.3f}, Confidence: {task.get('confidence', 0.5):.2f}\")\n",
        "            print(f\"        {task['explanation']}\")\n",
        "\n",
        "# Cost estimation\n",
        "orch.estimate_cost()\n",
        "\n",
        "# Save outputs\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "print(\"\\nðŸ“‚ Output Files:\")\n",
        "for tid, content in results.items():\n",
        "    status = orch.task_store[tid]['status']\n",
        "    role = orch.task_store[tid]['agent_role']\n",
        "    h2e_score = orch.task_store[tid].get('h2e_score', 'N/A')\n",
        "    h2e_raw = orch.task_store[tid].get('h2e_raw_similarity', 'N/A')\n",
        "\n",
        "    clean_role = role.replace(' ', '_').replace('/', '_')\n",
        "    filename = f\"output/{tid}_{clean_role}.md\"  # Using markdown extension\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"# Task: {tid}\\n\")\n",
        "        f.write(f\"**Role**: {role}\\n\")\n",
        "        f.write(f\"**Status**: {status}\\n\")\n",
        "        f.write(f\"**H2E Alignment Score**: {h2e_score} (Raw: {h2e_raw})\\n\")\n",
        "        f.write(f\"**H2E Confidence**: {orch.task_store[tid].get('h2e_confidence', 'N/A')}\\n\")\n",
        "        f.write(f\"**Generated**: {time.ctime()}\\n\")\n",
        "        f.write(f\"\\n---\\n\\n\")\n",
        "        f.write(content)\n",
        "\n",
        "    print(f\"  {tid}: {filename} (H2E: {h2e_score}, Raw: {h2e_raw})\")\n",
        "\n",
        "# Save completion history\n",
        "with open(\"output/completion_history.json\", \"w\") as f:\n",
        "    json.dump(orch.completion_history, f, indent=2, default=str)\n",
        "print(\"  Completion History: output/completion_history.json\")\n",
        "\n",
        "# Save task plan\n",
        "with open(\"output/task_plan.json\", \"w\") as f:\n",
        "    json.dump(plan, f, indent=2)\n",
        "print(\"  Task Plan: output/task_plan.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ¨ Orchestration completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGg4ug1WqLEC",
        "outputId": "de7cb9f0-0ef9-4c4e-8e6a-55afbe075b91"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‹ Task Plan:\n",
            "  1. task1: Research current best practices, frameworks, and industry standards for zero-trust security architec...\n",
            "     Role: Research Analyst, Complexity: HIGH, Depends on: None\n",
            "  2. task2: Based on the research findings, write a detailed implementation guide for zero-trust security archit...\n",
            "     Role: Technical Writer, Complexity: HIGH, Depends on: task1\n",
            "  3. task3: Perform a thorough technical review of the implementation guide for accuracy, completeness, and secu...\n",
            "     Role: Technical Reviewer, Complexity: HIGH, Depends on: task2\n",
            "  4. task4: Incorporate all feedback and corrections from the technical review into the implementation guide. Re...\n",
            "     Role: Technical Writer, Complexity: MEDIUM, Depends on: task3\n",
            "  5. task5: Create a concise executive summary (2-3 pages) of the zero-trust Kubernetes security guide tailored ...\n",
            "     Role: Technical Writer, Complexity: MEDIUM, Depends on: task4\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ BUILD COMPLETE\n",
            "============================================================\n",
            "\n",
            "ðŸ“ˆ Summary:\n",
            "   Tasks: 5 successful, 0 failed\n",
            "   H2E Calibration Scores: Avg 0.869 (Raw cosine: 0.598)\n",
            "\n",
            "ðŸ”§ H2E Calibration Analysis:\n",
            "==================================================\n",
            "\n",
            "  Research Analyst:\n",
            "    Samples: 2\n",
            "    Average Score: 0.876\n",
            "    Raw Cosine Sim: 0.650\n",
            "    Std Dev: 0.001\n",
            "    Avg Complexity: 0.539\n",
            "    Avg Confidence: 0.848\n",
            "    Recommended Threshold: 0.850\n",
            "\n",
            "  Technical Writer:\n",
            "    Samples: 6\n",
            "    Average Score: 0.852\n",
            "    Raw Cosine Sim: 0.579\n",
            "    Std Dev: 0.038\n",
            "    Avg Complexity: 0.499\n",
            "    Avg Confidence: 0.847\n",
            "    Recommended Threshold: 0.850\n",
            "    Score Distribution:\n",
            "      10%: 0.822, 25%: 0.824, 50%: 0.829\n",
            "      75%: 0.886, 90%: 0.906\n",
            "\n",
            "  Technical Reviewer:\n",
            "    Samples: 2\n",
            "    Average Score: 0.875\n",
            "    Raw Cosine Sim: 0.611\n",
            "    Std Dev: 0.039\n",
            "    Avg Complexity: 0.568\n",
            "    Avg Confidence: 0.829\n",
            "    Recommended Threshold: 0.850\n",
            "\n",
            "ðŸ’¡ Recommendations for production thresholds:\n",
            "   Research Analyst: 0.850\n",
            "   Technical Writer: 0.850\n",
            "   Technical Reviewer: 0.850\n",
            "\n",
            "ðŸ“Š H2E Accountability Report:\n",
            "âœ“ H2E report saved to output/h2e_accountability_report.json\n",
            "   Timestamp: 2026-02-08T14:32:54.180664\n",
            "   Tasks Evaluated: 10\n",
            "   Average SROI: 0.861\n",
            "   Average Raw Similarity: 0.600\n",
            "   Alignment Pass Rate: 100.0%\n",
            "   Recommended Threshold: 0.843\n",
            "\n",
            "   Task Breakdown:\n",
            "     âœ… task5 (Technical Writer) â­\n",
            "        Score: 0.828 (Raw: 0.550)\n",
            "        Required: 0.759, Confidence: 0.85\n",
            "        Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task4 (Technical Writer) â­\n",
            "        Score: 0.821 (Raw: 0.506)\n",
            "        Required: 0.689, Confidence: 0.87\n",
            "        Moderate semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task3 (Technical Reviewer) â­\n",
            "        Score: 0.914 (Raw: 0.613)\n",
            "        Required: 0.846, Confidence: 0.82\n",
            "        High semantic similarity. Adequate alignment meeting requirements\n",
            "     âœ… task2 (Technical Writer) â­\n",
            "        Score: 0.908 (Raw: 0.653)\n",
            "        Required: 0.555, Confidence: 0.83\n",
            "        High semantic similarity. Excellent alignment exceeding requirements by 64%\n",
            "     âœ… task1 (Research Analyst) â­\n",
            "        Score: 0.877 (Raw: 0.665)\n",
            "        Required: 0.810, Confidence: 0.85\n",
            "        High semantic similarity. Adequate alignment meeting requirements\n",
            "\n",
            "ðŸ’° Cost Estimation:\n",
            "   Input tokens: 7,588 â‰ˆ $0.5691\n",
            "   Output tokens: 37,957 â‰ˆ $14.2339\n",
            "   Total estimated: $14.8030\n",
            "\n",
            "ðŸ“‚ Output Files:\n",
            "  task1: output/task1_Research_Analyst.md (H2E: 0.876843859753982, Raw: 0.6650100719878841)\n",
            "  task2: output/task2_Technical_Writer.md (H2E: 0.9075079691788318, Raw: 0.653444782548064)\n",
            "  task3: output/task3_Technical_Reviewer.md (H2E: 0.9135132851606678, Raw: 0.6134717094926956)\n",
            "  task4: output/task4_Technical_Writer.md (H2E: 0.8207575560348271, Raw: 0.5060779176284711)\n",
            "  task5: output/task5_Technical_Writer.md (H2E: 0.8276257236502758, Raw: 0.5499242612216159)\n",
            "  Completion History: output/completion_history.json\n",
            "  Task Plan: output/task_plan.json\n",
            "\n",
            "============================================================\n",
            "âœ¨ Orchestration completed successfully!\n"
          ]
        }
      ]
    }
  ]
}