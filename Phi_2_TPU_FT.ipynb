{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyMK9PmzX5tc+DInFk3bGCqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Phi_2_TPU_FT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/microsoft/phi-2"
      ],
      "metadata": {
        "id": "wJxxCLGCgT-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.47.0 datasets optimum-tpu==0.2.3 torch-xla==2.5.1 -q"
      ],
      "metadata": {
        "id": "5OssPbIFxC_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OxYEVEcquR4D"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from google.colab import drive\n",
        "token=userdata.get('HF_TOKEN')\n",
        "login(token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jax-ai-stack==2025.4.9\n",
        "!pip install -Uq \"jax[tpu]==0.5.3\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip install -Uq tiktoken matplotlib kaggle wandb tpu-info orbax-checkpoint==0.11.12\n",
        "!pip install -Uq datasets"
      ],
      "metadata": {
        "id": "ffW2QzdD1Hod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Ignore the specific JAX warning about skipped cross-host ArrayMetadata validation\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\".*Skipped cross-host ArrayMetadata validation because only one process is found.*\",\n",
        "    category=UserWarning,  # Or Warning if the category is different\n",
        ")\n",
        "\n",
        "# All necessary imports from the original notebook\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import PartitionSpec as P, NamedSharding\n",
        "from jax import random\n",
        "import jax.nn.initializers as init\n",
        "import jax.nn as nn\n",
        "from jax.lib import xla_bridge\n",
        "from jax.experimental.mesh_utils import create_device_mesh\n",
        "import optax\n",
        "import time\n",
        "import orbax.checkpoint as orbax\n",
        "import numpy as np\n",
        "import shutil\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer\n",
        "import tiktoken\n",
        "import flax.nnx as nnx"
      ],
      "metadata": {
        "id": "ZW_q8m5u2Qx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "mesh = jax.make_mesh((1,), ('batch',))"
      ],
      "metadata": {
        "id": "Xq5lXwip01LO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array of random values:\n",
        "x = jax.random.normal(jax.random.key(0), (8192, 8192))\n",
        "# and use jax.device_put to distribute it across devices:\n",
        "# Changed PartitionSpec to use the 'batch' axis to match the mesh\n",
        "y = jax.device_put(x, NamedSharding(mesh, P('batch', None)))\n",
        "jax.debug.visualize_array_sharding(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "dfUMuhve0897",
        "outputId": "58a55e20-05dd-4212-f118-93b45d978235"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m          \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m          \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">          TPU 0          </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla\n",
        "device=torch_xla.device\n"
      ],
      "metadata": {
        "id": "m13fqVAz0SMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq datasets bitsandbytes"
      ],
      "metadata": {
        "id": "gZV7QL4D4rf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft"
      ],
      "metadata": {
        "id": "6bLO289Z9Nen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('WANDB_KEY')\n",
        "import wandb\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "id": "-tcTnjoC_nVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "import torch_xla.core.xla_model as xm\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Authenticate with Hugging Face Hub using your token.\n",
        "try:\n",
        "    token = userdata.get('HF_TOKEN')\n",
        "    login(token=token)\n",
        "except Exception as e:\n",
        "    print(f\"Failed to login to Hugging Face Hub: {e}\")\n",
        "\n",
        "# Load the Phi-2 model and tokenizer without quantization.\n",
        "# BitsAndBytes is not compatible with TPUs.\n",
        "\n",
        "device = xm.xla_device()\n",
        "print(f\"--- Loading non-quantized Phi-2 on {device} ---\")\n",
        "model_name = \"microsoft/Phi-2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "# Load the model with BFloat16 precision, which is a good balance of memory and performance\n",
        "# for TPUs, and then move it to the XLA device.\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Prepare the model for PEFT training\n",
        "model.config.use_cache = False  # Recommended for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "print(\"--- Model loaded successfully! ---\")\n",
        "\n",
        "# Load and format the dataset.\n",
        "print(\"--- Loading dataset... ---\")\n",
        "# Split the dataset into train and test sets to have a proper evaluation\n",
        "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "split_dataset = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = split_dataset['train']\n",
        "eval_dataset = split_dataset['test']\n",
        "\n",
        "def format_data(examples):\n",
        "    formatted_texts = []\n",
        "    for instruction, context, response in zip(examples['instruction'], examples['context'], examples['response']):\n",
        "        formatted_text = f\"Instruction: {instruction}\\n\"\n",
        "        if context:\n",
        "            formatted_text += f\"Context: {context}\\n\"\n",
        "        formatted_text += f\"Response: {response}\"\n",
        "        formatted_texts.append(formatted_text)\n",
        "    return {\"text\": formatted_texts}\n",
        "\n",
        "formatted_train_dataset = train_dataset.map(format_data, batched=True)\n",
        "formatted_eval_dataset = eval_dataset.map(format_data, batched=True)\n",
        "\n",
        "# Tokenize the dataset and add labels for the trainer.\n",
        "def tokenize_function(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_train_dataset = formatted_train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = formatted_eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Define TrainingArguments for TPU and initialize the Trainer.\n",
        "output_dir = \"./phi-2_finetuned\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=1,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    optim=\"adamw_torch_xla\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    logging_steps=500,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "iq-1_jG5A-5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting fine-tuning process... ---\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"--- Fine-tuning completed! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xdK-Dzg3fThI",
        "outputId": "2e98e675-40b7-4bf0-eeb1-2d2303749147"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting fine-tuning process... ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11001' max='13509' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11001/13509 2:14:47 < 30:44, 1.36 it/s, Epoch 0.81/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.187200</td>\n",
              "      <td>0.167103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.180300</td>\n",
              "      <td>0.163098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.161683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>0.161072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.155700</td>\n",
              "      <td>0.160491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.183500</td>\n",
              "      <td>0.160180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.154200</td>\n",
              "      <td>0.159701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.161700</td>\n",
              "      <td>0.159485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.159292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>0.159065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.168800</td>\n",
              "      <td>0.158977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.158782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.150400</td>\n",
              "      <td>0.158705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.146800</td>\n",
              "      <td>0.158623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.158537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.158700</td>\n",
              "      <td>0.158445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.151200</td>\n",
              "      <td>0.158358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.164800</td>\n",
              "      <td>0.158334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.158208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.176400</td>\n",
              "      <td>0.158208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.158130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1099' max='1502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1099/1502 02:07 < 00:46, 8.60 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13509' max='13509' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13509/13509 2:49:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.187200</td>\n",
              "      <td>0.167103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.180300</td>\n",
              "      <td>0.163098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.161683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>0.161072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.155700</td>\n",
              "      <td>0.160491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.183500</td>\n",
              "      <td>0.160180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.154200</td>\n",
              "      <td>0.159701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.161700</td>\n",
              "      <td>0.159485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.159292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>0.159065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.168800</td>\n",
              "      <td>0.158977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.158782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.150400</td>\n",
              "      <td>0.158705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.146800</td>\n",
              "      <td>0.158623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.158537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.158700</td>\n",
              "      <td>0.158445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.151200</td>\n",
              "      <td>0.158358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.164800</td>\n",
              "      <td>0.158334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.158208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.176400</td>\n",
              "      <td>0.158208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.158130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.162300</td>\n",
              "      <td>0.158129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.176400</td>\n",
              "      <td>0.158098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.165600</td>\n",
              "      <td>0.158031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.169200</td>\n",
              "      <td>0.158019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.168300</td>\n",
              "      <td>0.158003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>0.157988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fine-tuning completed! ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and calculate perplexity after training\n",
        "print(\"--- Evaluating model and calculating perplexity... ---\")\n",
        "eval_results = trainer.evaluate()\n",
        "perplexity = math.exp(eval_results['eval_loss'])\n",
        "print(f\"Final Evaluation Loss: {eval_results['eval_loss']:.4f}\")\n",
        "print(f\"Final Perplexity: {perplexity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "o2N71j8SiCho",
        "outputId": "38895aa3-db58-47d2-d419-87b9f7eb4efa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating model and calculating perplexity... ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1502' max='1502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1502/1502 02:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation Loss: 0.1580\n",
            "Final Perplexity: 1.1712\n"
          ]
        }
      ]
    }
  ]
}