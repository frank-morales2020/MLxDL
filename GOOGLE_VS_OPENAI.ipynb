{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlJpiC+m9z4G7/M/oBiY0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/GOOGLE_VS_OPENAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4u3Wf7EqCPq",
        "outputId": "12455ba8-39f2-4ae7-9f1a-de467381f42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "--- ‚öôÔ∏è RUNNING MOCKED DEMONSTRATION ---\n",
            "This simulates the due diligence task and tracks key metrics for the final report.\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "--- üü¢ Running gemini-3-pro-preview Demo: Single, Large Multimodal Context (MOCKED) ---\n",
            "Executing **SINGLE** generate_content call with 4 files...\n",
            "\n",
            "‚úÖ **ARCHITECTURAL SUCCESS**: Task completed in 1.0 seconds.\n",
            "   - Inference Calls Required: **1** (Single point of execution for the whole task).\n",
            "--- Model Output (Snippet) ---\n",
            "‚úÖ **GEMINI RESULT (SINGLE CALL)**: The model successfully analyzed all 1M tokens, PDFs, and the video stream in a single, coherent thought process. The key legal risk (12% equity) is directly tied to the $5M outflow (Audited), and the CEO's video statement was found to be contradictory. Analysis Confidence: HIGH. Inference Calls: 1.\n",
            "\n",
            "================================================================================\n",
            "--- üî¥ Running gpt-5 Demo: Fragmentation / Workaround Required (MOCKED) ---\n",
            "Step 1/4: Video Analysis - Executing Whisper API call for audio transcription...\n",
            "Step 4/4: Final Synthesis (Third inference call, combining fragmented parts)...\n",
            "\n",
            "‚ùå **FRAGMENTED**: Task completed in 2.0 seconds (Synthesis time only).\n",
            "   - Inference Calls Required: **3+** (Synthesis, Legal RAG, Financial RAG) **+ 1** (Whisper API).\n",
            "--- Model Output (Snippet) ---\n",
            "‚ùå **OPENAI SYNTHESIS RESULT (FRAGMENTED)**: The Legal Finding (12% equity) and Financial Finding ($5M outflow) are confirmed. However, the separate Video Transcript contradicts this, calling the clause 'non-binding'. Final risk assessment is **UNCERTAIN** due to conflicting evidence from manually isolated sources. Confidence: LOW. This required three separate API calls plus the Whisper pre-processing.\n",
            "\n",
            "\n",
            "##########################################################################################\n",
            "## ü§ñ OBSERVABILITY AGENT REPORT: Multimodal Due Diligence\n",
            "##########################################################################################\n",
            "### üèÜ Winning Architecture: Single Unified Context (Gemini 3 Pro)\n",
            "---\n",
            "The **Gemini 3 Pro** architecture provided the most definitive and coherent analysis for the 1M-token multimodal task.\n",
            "\n",
            "### üìä Comparative Analysis:\n",
            "| Model | Architecture | Total API Calls (Inference) | Confidence | Time (Simulated) |\n",
            "| :--- | :--- | :--- | :--- | :--- |\n",
            "| Gemini 3 Pro | Single Unified Context | 1 | **HIGH** | 1.0s |\n",
            "| GPT-5 | Fragmented Calls (RAG/Whisper) | 3+ (Synthesis) + 1 (Whisper) | **LOW / UNCERTAIN** | 2.0s |\n",
            "\n",
            "### üîë Key Findings (Why one Succeeded and the other Fragmented):\n",
            "1. **Gemini 3 Pro (Success):**\n",
            "   - **Result:** ‚úÖ **GEMINI RESULT (SINGLE CALL)**: The model successfully analyzed all 1M tokens, PDFs, and the video stream in a single, coherent thought process. The key legal risk (12% equity) is directly tied to the $5M outflow (Audited), and the CEO's video statement was found to be contradictory. Analysis Confidence: HIGH. Inference Calls: 1.\n",
            "   - **Reason:** The model's large context and native multimodal processing treat the entire dataset (PDFs, ZIP, Video) as a single, unified source of truth, enabling immediate cross-referencing.\n",
            "\n",
            "2. **GPT-5 (Fragmented):**\n",
            "   - **Result:** ‚ùå **OPENAI SYNTHESIS RESULT (FRAGMENTED)**: The Legal Finding (12% equity) and Financial Finding ($5M outflow) are confirmed. However, the separate Video Transcript contradicts this, calling the clause 'non-binding'. Final risk assessment is **UNCERTAIN** due to conflicting evidence from manually isolated sources. Confidence: LOW. This required three separate API calls plus the Whisper pre-processing.\n",
            "   - **Reason:** Due to context limitations, the task required a minimum of **4 separate API transactions** (Whisper for audio + 3 Chat/RAG calls for synthesis). This fragmentation introduced ambiguity and prevented the model from reaching a high-confidence conclusion.\n",
            "\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Global list to store results for the final report\n",
        "DEMO_RESULTS = []\n",
        "\n",
        "# --- 1. Client and Model Configuration (Fully Mocked for Execution Safety) ---\n",
        "\n",
        "# Mock the entire client configuration process to prevent KeyErrors and setup errors.\n",
        "class MockClient:\n",
        "    def __init__(self, key=None):\n",
        "        pass\n",
        "\n",
        "    # Mock files service for Gemini (handles file upload/delete)\n",
        "    class files:\n",
        "        @staticmethod\n",
        "        def upload(file):\n",
        "            return type('FileObject', (object,), {\"name\": f\"mock_file_{os.path.basename(file)}\"})\n",
        "        @staticmethod\n",
        "        def delete(name):\n",
        "            pass\n",
        "\n",
        "    # Mock models service for Gemini (handles the single generate_content call)\n",
        "    class models:\n",
        "        @staticmethod\n",
        "        def generate_content(model, contents, config=None):\n",
        "            time.sleep(1) # Simulate network latency\n",
        "            return type('Response', (object,), {\n",
        "                'text': (\n",
        "                    \"‚úÖ **GEMINI RESULT (SINGLE CALL)**: The model successfully analyzed all 1M tokens, PDFs, and the video stream in a single, coherent thought process. \"\n",
        "                    \"The key legal risk (12% equity) is directly tied to the $5M outflow (Audited), and the CEO's video statement was found to be contradictory. \"\n",
        "                    \"Analysis Confidence: HIGH. Inference Calls: 1.\"\n",
        "                )\n",
        "            })\n",
        "\n",
        "    # Mock audio service for OpenAI (Whisper)\n",
        "    class audio:\n",
        "        @staticmethod\n",
        "        def transcriptions(model, file):\n",
        "            time.sleep(0.5) # Simulate Whisper latency\n",
        "            return type('Transcription', (object,), {\n",
        "                'text': \"CEO's Keynote (30:00-40:00): '...and so, the 12% equity clause is effectively non-binding and the $5M is a minor, historical cash adjustment, not a significant risk.'\"\n",
        "            })\n",
        "\n",
        "    # Mock chat completions service for OpenAI (handles the synthesis call)\n",
        "    class chat:\n",
        "        @staticmethod\n",
        "        def completions(model, messages):\n",
        "            time.sleep(2) # Simulate synthesis latency\n",
        "            mock_message = type('Message', (object,), {\n",
        "                'content': (\n",
        "                    \"‚ùå **OPENAI SYNTHESIS RESULT (FRAGMENTED)**: The Legal Finding (12% equity) and Financial Finding ($5M outflow) \"\n",
        "                    \"are confirmed. However, the separate Video Transcript contradicts this, calling the clause 'non-binding'. \"\n",
        "                    \"Final risk assessment is **UNCERTAIN** due to conflicting evidence from manually isolated sources. \"\n",
        "                    \"Confidence: LOW. This required three separate API calls plus the Whisper pre-processing.\"\n",
        "                )\n",
        "            })\n",
        "            return type('Completion', (object,), {\n",
        "                'choices': [\n",
        "                    {'message': mock_message}\n",
        "                ]\n",
        "            })\n",
        "\n",
        "# Instantiate the mock clients (This replaces the need for userdata.get)\n",
        "client_gemini = MockClient()\n",
        "client_openai = MockClient()\n",
        "GEMINI_MODEL_ID = 'gemini-3-pro-preview'\n",
        "OPENAI_MODEL_ID = 'gpt-5'\n",
        "\n",
        "# --- 2. Scenario Setup and Mock Data (For File Access) ---\n",
        "\n",
        "MOCK_FILES = {\n",
        "    \"legal_agreement\": \"data/long_legal_doc.pdf\",\n",
        "    \"financial_audit\": \"data/large_audit_report.pdf\",\n",
        "    \"research_papers\": \"data/patent_set.zip\",\n",
        "    \"video_presentation\": \"data/ceo_keynote.mp4\"\n",
        "}\n",
        "\n",
        "COMPLEX_QUERY = \"Analyze all attached files...\"\n",
        "\n",
        "def create_mock_files():\n",
        "    \"\"\"Creates zero-byte files to pass the Path.exists() check.\"\"\"\n",
        "    Path(\"data\").mkdir(exist_ok=True)\n",
        "    for path in MOCK_FILES.values():\n",
        "        Path(path).touch(exist_ok=True)\n",
        "\n",
        "# --- 3. Gemini 3 Pro Demo (Single API Call Architecture) ---\n",
        "\n",
        "def run_gemini_demo(client, model_id, mock_files, query):\n",
        "    \"\"\"Simulates Gemini 3 Pro's key advantage: single-call processing.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"--- üü¢ Running {model_id} Demo: Single, Large Multimodal Context (MOCKED) ---\")\n",
        "\n",
        "    uploaded_parts = []\n",
        "    for path in mock_files.values():\n",
        "        uploaded_file = client.files.upload(file=path)\n",
        "        uploaded_parts.append(uploaded_file)\n",
        "\n",
        "    contents = [query] + uploaded_parts\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"Executing **SINGLE** generate_content call with {len(uploaded_parts)} files...\")\n",
        "    response = client.models.generate_content(model=model_id, contents=contents)\n",
        "    conceptual_output = response.text.strip()\n",
        "    end_time = time.time()\n",
        "\n",
        "    duration = round(end_time - start_time, 2)\n",
        "\n",
        "    # Store result for report\n",
        "    DEMO_RESULTS.append({\n",
        "        \"Model\": \"Gemini 3 Pro\",\n",
        "        \"Architecture\": \"Single Unified Context\",\n",
        "        \"Calls\": 1,\n",
        "        \"Time\": duration,\n",
        "        \"Confidence\": \"HIGH\",\n",
        "        \"Result\": conceptual_output\n",
        "    })\n",
        "\n",
        "    print(f\"\\n‚úÖ **ARCHITECTURAL SUCCESS**: Task completed in {duration} seconds.\")\n",
        "    print(\"   - Inference Calls Required: **1** (Single point of execution for the whole task).\")\n",
        "    print(\"--- Model Output (Snippet) ---\")\n",
        "    print(conceptual_output)\n",
        "\n",
        "# --- 4. OpenAI GPT-5 Demo (Fragmentation Architecture) ---\n",
        "\n",
        "def run_openai_demo(client, model_id, mock_files, query):\n",
        "    \"\"\"Simulates the multi-step, fragmented approach required.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"--- üî¥ Running {model_id} Demo: Fragmentation / Workaround Required (MOCKED) ---\")\n",
        "\n",
        "    # Step 1: Video Pre-processing (MOCKED)\n",
        "    video_file_path = Path(mock_files[\"video_presentation\"])\n",
        "    print(\"Step 1/4: Video Analysis - Executing Whisper API call for audio transcription...\")\n",
        "    with open(video_file_path, \"rb\") as audio_file:\n",
        "        response_whisper = client.audio.transcriptions(model=\"whisper-1\", file=audio_file)\n",
        "    video_transcript_summary = response_whisper.text\n",
        "\n",
        "    # Steps 2-4: Synthesis (MOCKED)\n",
        "    print(\"Step 4/4: Final Synthesis (Third inference call, combining fragmented parts)...\")\n",
        "    final_prompt = [\n",
        "        {\"role\": \"user\", \"content\": f\"Synthesize all findings...\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = client.chat.completions(model=model_id, messages=final_prompt)\n",
        "    conceptual_output = response.choices[0]['message'].content.strip()\n",
        "    end_time = time.time()\n",
        "\n",
        "    duration = round(end_time - start_time, 2)\n",
        "\n",
        "    # Store result for report\n",
        "    DEMO_RESULTS.append({\n",
        "        \"Model\": \"GPT-5\",\n",
        "        \"Architecture\": \"Fragmented Calls (RAG/Whisper)\",\n",
        "        \"Calls\": \"3+ (Synthesis) + 1 (Whisper)\",\n",
        "        \"Time\": duration,\n",
        "        \"Confidence\": \"LOW / UNCERTAIN\",\n",
        "        \"Result\": conceptual_output\n",
        "    })\n",
        "\n",
        "    print(f\"\\n‚ùå **FRAGMENTED**: Task completed in {duration} seconds (Synthesis time only).\")\n",
        "    print(\"   - Inference Calls Required: **3+** (Synthesis, Legal RAG, Financial RAG) **+ 1** (Whisper API).\")\n",
        "    print(\"--- Model Output (Snippet) ---\")\n",
        "    print(conceptual_output)\n",
        "\n",
        "# --- 5. Observability Agent Report Function ---\n",
        "\n",
        "def generate_observability_report():\n",
        "    \"\"\"Generates the final comparative report based on DEMO_RESULTS.\"\"\"\n",
        "    print(\"\\n\\n\" + \"#\" * 90)\n",
        "    print(\"## ü§ñ OBSERVABILITY AGENT REPORT: Multimodal Due Diligence\")\n",
        "    print(\"#\" * 90)\n",
        "\n",
        "    if not DEMO_RESULTS or len(DEMO_RESULTS) < 2:\n",
        "        print(\"Error: Insufficient data to generate a comparative report.\")\n",
        "        return\n",
        "\n",
        "    # Determine Success based on Confidence and Architecture\n",
        "    gemini_result = DEMO_RESULTS[0]\n",
        "    openai_result = DEMO_RESULTS[1]\n",
        "\n",
        "    success_model = gemini_result if gemini_result[\"Confidence\"] == \"HIGH\" else openai_result # Gemini is the clear winner in this scenario\n",
        "\n",
        "    print(f\"### üèÜ Winning Architecture: {success_model['Architecture']} ({success_model['Model']})\")\n",
        "    print(\"---\")\n",
        "    print(f\"The **{success_model['Model']}** architecture provided the most definitive and coherent analysis for the 1M-token multimodal task.\")\n",
        "\n",
        "    print(\"\\n### üìä Comparative Analysis:\")\n",
        "\n",
        "    print(\"| Model | Architecture | Total API Calls (Inference) | Confidence | Time (Simulated) |\")\n",
        "    print(\"| :--- | :--- | :--- | :--- | :--- |\")\n",
        "\n",
        "    for result in DEMO_RESULTS:\n",
        "        print(f\"| {result['Model']} | {result['Architecture']} | {result['Calls']} | **{result['Confidence']}** | {result['Time']}s |\")\n",
        "\n",
        "    print(\"\\n### üîë Key Findings (Why one Succeeded and the other Fragmented):\")\n",
        "    print(\"1. **Gemini 3 Pro (Success):**\")\n",
        "    print(f\"   - **Result:** {gemini_result['Result']}\")\n",
        "    print(\"   - **Reason:** The model's large context and native multimodal processing treat the entire dataset (PDFs, ZIP, Video) as a single, unified source of truth, enabling immediate cross-referencing.\")\n",
        "\n",
        "    print(\"\\n2. **GPT-5 (Fragmented):**\")\n",
        "    print(f\"   - **Result:** {openai_result['Result']}\")\n",
        "    print(\"   - **Reason:** Due to context limitations, the task required a minimum of **4 separate API transactions** (Whisper for audio + 3 Chat/RAG calls for synthesis). This fragmentation introduced ambiguity and prevented the model from reaching a high-confidence conclusion.\")\n",
        "    print(\"\\n\" + \"=\" * 90)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure the code can run by creating the mock environment\n",
        "    create_mock_files()\n",
        "\n",
        "    # Print header before running demos\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"--- ‚öôÔ∏è RUNNING MOCKED DEMONSTRATION ---\")\n",
        "    print(\"This simulates the due diligence task and tracks key metrics for the final report.\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # 1. Run the Demos\n",
        "    run_gemini_demo(client_gemini, GEMINI_MODEL_ID, MOCK_FILES, COMPLEX_QUERY)\n",
        "    run_openai_demo(client_openai, OPENAI_MODEL_ID, MOCK_FILES, COMPLEX_QUERY)\n",
        "\n",
        "    # 2. Generate the Final Report (The Observability Agent Function)\n",
        "    generate_observability_report()"
      ]
    }
  ]
}