{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNQ44d47MpPkl4c2OjDFjZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MMLU-GPT4vCLAUDE3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/FranxYao/chain-of-thought-hub/tree/main"
      ],
      "metadata": {
        "id": "PgjufKHHv_o0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Preparations"
      ],
      "metadata": {
        "id": "PEnnryG5D82e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSBsCqf0vx7L"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/FranxYao/chain-of-thought-hub.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q tqdm\n",
        "!pip install -q pandas\n",
        "!pip install -q tensor_parallel\n",
        "!pip install -q argparse\n",
        "!pip install -q einops\n",
        "!pip install -q accelerate\n",
        "#!pip install -q torch==2.0.0+cu118\n",
        "!pip install -q torch\n",
        "\n",
        "!pip install colab-env --upgrade -q\n",
        "!pip install openai -q\n",
        "\n",
        "!pip install datasets -q\n",
        "!pip install utils -q"
      ],
      "metadata": {
        "id": "LbMG_F_I9KnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "import IPython\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "S4Z-2YjmwroH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function defitions"
      ],
      "metadata": {
        "id": "JMldWB5ctrTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_answer_mmlu_(pred_str, ans):\n",
        "    pattern = 'the answer is ('\n",
        "    pred = pred_str.lower().split(pattern)\n",
        "\n",
        "    if(len(pred) > 1):\n",
        "        # print(pred)\n",
        "        pred = pred[1][0]\n",
        "        gold = ans.lower()\n",
        "        # print('debug 1, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "    else:\n",
        "        pred = 'C'\n",
        "        # print(ans_str)\n",
        "        gold = ans.lower()\n",
        "        # print('debug 2, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "\n",
        "# extract answer in pred_str and compare with ans_str\n",
        "def test_answer_mmlu_claude_instant(pred_str, ans_str):\n",
        "    pattern = 'the answer is '\n",
        "    pred = pred_str.lower().split(pattern)\n",
        "    if len(pred) == 1:\n",
        "        return False\n",
        "    else:\n",
        "        return pred[1][0] == ans_str.lower()\n",
        "\n",
        "def test_answer_mmlu_claude(pred_str, ans_str):\n",
        "    pattern = 'the answer is '\n",
        "    pred = pred_str.lower().split(pattern)\n",
        "\n",
        "    if(len(pred) > 1):\n",
        "        # print(pred)\n",
        "        pred = pred[1]\n",
        "        for p in pred:\n",
        "            if(p.isalpha()): break\n",
        "        pred = p\n",
        "        print(ans_str)\n",
        "        gold = ans_str.lower()\n",
        "        print('debug 1, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "    else:\n",
        "        pred = 'c'\n",
        "        # print(ans_str)\n",
        "        gold = ans_str.lower()\n",
        "        # print('debug 2, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "\n",
        "def test_answer_mmlu(pred_str, ans_str):\n",
        "    pattern = 'the answer is ('\n",
        "    pred = pred_str.lower().split(pattern)\n",
        "\n",
        "    if(len(pred) > 1):\n",
        "        # print(pred)\n",
        "        pred = pred[1][0]\n",
        "        gold = ans_str.split('A:\\n')[1][0].lower()\n",
        "        # print('debug 1, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "    else:\n",
        "        pred = 'C'\n",
        "        # print(ans_str)\n",
        "        gold = ans_str.split('A:\\n')[1][0].lower()\n",
        "        # print('debug 2, pred %s, gold %s' % (pred, gold))\n",
        "        return pred == gold\n",
        "\n",
        "def parse_pred_ans(filename):\n",
        "    with open(filename) as fd: lines = fd.readlines()\n",
        "    am, a = None, None\n",
        "    num_q, acc = 0, 0\n",
        "    current_mode = 'none'\n",
        "    questions = []\n",
        "    ans_pred = []\n",
        "    ans_gold = []\n",
        "    for l in lines:\n",
        "        if(l.startswith('Q: ')):\n",
        "            if(am is not None and a is not None):\n",
        "                questions.append(q)\n",
        "                ans_pred.append(am)\n",
        "                ans_gold.append(a)\n",
        "                # print(am)\n",
        "                # print(a)\n",
        "                if(test_answer_mmlu(am, a)):\n",
        "                    acc += 1\n",
        "            current_mode = 'q'\n",
        "            q = l\n",
        "            num_q += 1\n",
        "        elif(l.startswith('A_model:')):\n",
        "            current_mode = 'am'\n",
        "            am = l\n",
        "        elif(l.startswith('A:') and not l.startswith(\"A: Let's think step by step\")):\n",
        "            current_mode = 'a'\n",
        "            a = l\n",
        "        else:\n",
        "            if(current_mode == 'q'): q += l\n",
        "            elif(current_mode == 'am'): am += l\n",
        "            elif(current_mode == 'a'): a += l\n",
        "            else:\n",
        "                raise ValueError(current_mode)\n",
        "\n",
        "    questions.append(q)\n",
        "    ans_pred.append(am)\n",
        "    ans_gold.append(a)\n",
        "    # print(am)\n",
        "    # print(a)\n",
        "    if(test_answer_mmlu(am, a)):\n",
        "        acc += 1\n",
        "    print('num_q %d correct %d ratio %.4f' % (num_q, acc, float(acc / num_q)))\n",
        "    return questions, ans_pred, ans_gold\n",
        "\n",
        "def test_finished(ans_model):\n",
        "    if('answer is' in ans_model): return True\n",
        "    else: return False\n",
        "\n",
        "def extract_ans(ans_model):\n",
        "    ans_model = ans_model.split('\\n')\n",
        "    ans = []\n",
        "    residual = []\n",
        "    for li, al in enumerate(ans_model):\n",
        "        ans.append(al)\n",
        "        if('answer is' in al):\n",
        "            break\n",
        "    residual = list(ans_model[li + 1:])\n",
        "    ans = '\\n'.join(ans)\n",
        "    residual = '\\n'.join(residual)\n",
        "    return ans, residual"
      ],
      "metadata": {
        "id": "flLLh6xztdQN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MMLU TASK PREFERENCES BY Frank Morales"
      ],
      "metadata": {
        "id": "dp-HUXrOrvzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TASKSTEST0old = [\n",
        "        'anatomy',\n",
        "        'college_biology',\n",
        "        'college_chemistry',\n",
        "        'college_computer_science',\n",
        "        'college_mathematics',\n",
        "        'college_medicine',\n",
        "        'college_physics',\n",
        "        'computer_security',\n",
        "        'electrical_engineering',\n",
        "        'machine_learning',\n",
        "]\n",
        "\n",
        "TASKSTEST = [\n",
        "        'college_computer_science',\n",
        "        'electrical_engineering',\n",
        "        'machine_learning',\n",
        "]\n",
        "\n",
        "TASKS911 = [\n",
        "        'anatomy',\n",
        "        'college_biology',\n",
        "        'college_chemistry',\n",
        "        'college_computer_science',\n",
        "        'college_mathematics',\n",
        "        'college_medicine',\n",
        "        'college_physics',\n",
        "        'computer_security',\n",
        "        'conceptual_physics',\n",
        "        'econometrics',\n",
        "        'electrical_engineering',\n",
        "        'elementary_mathematics',\n",
        "        'formal_logic',\n",
        "        'global_facts',\n",
        "        'high_school_biology',\n",
        "        'high_school_chemistry',\n",
        "        'high_school_computer_science',\n",
        "        'high_school_european_history',\n",
        "        'high_school_geography',\n",
        "        'high_school_government_and_politics',\n",
        "        'high_school_macroeconomics',\n",
        "        'high_school_mathematics',\n",
        "        'high_school_microeconomics',\n",
        "        'high_school_physics',\n",
        "        'high_school_psychology',\n",
        "        'high_school_statistics',\n",
        "        'high_school_us_history',\n",
        "        'high_school_world_history',\n",
        "        'public_relations',\n",
        "        'security_studies',\n",
        "        'sociology',\n",
        "        'us_foreign_policy',\n",
        "        'virology',\n",
        "        'machine_learning',\n",
        "        'world_religions']"
      ],
      "metadata": {
        "id": "nPqj5gQMpyGd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/outputs\n",
        "\n",
        "# GPT-3.5-Turbo\n",
        "#!python /content/chain-of-thought-hub/MMLU/run_mmlu_gpt_3.5_turbo.py --api_key=${API_KEY}\n",
        "\n",
        "# Claude-v1.3\n",
        "#!python /content/chain-of-thought-hub/MMLU/run_mmlu_claude.py  --api_key=${API_KEY} --engine=claude-v1.3\n"
      ],
      "metadata": {
        "id": "Pty4WhUg0df-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Evaluating GPT-3.5 turbo model on MMLU"
      ],
      "metadata": {
        "id": "Dt2bV-D7DyjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datetime object containing current date and time\n",
        "newYorkTz = pytz.timezone(\"America/New_York\")\n",
        "now = datetime.now(newYorkTz)\n",
        "#print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "#print(\"date and time =\", dt_string)\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "from openai import OpenAI\n",
        "\n",
        "#client = OpenAI()\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "API_KEY= OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "print()\n",
        "print('TEST - OPENAI  - BY FRANK MORALES - %s'%dt_string)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEX22rEw6Ja",
        "outputId": "f0f7367d-cdec-4652-9f75-1f62685fe413"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST - OPENAI  - BY FRANK MORALES - 01/04/2024 20:44:13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content/chain-of-thought-hub/MMLU\n",
        "#from utils import *"
      ],
      "metadata": {
        "id": "Ial35WsU5Unr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/guides/text-generation/json-mode"
      ],
      "metadata": {
        "id": "oNw4b9ID-shx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating GPT-3.5 turbo model on MMLU\n",
        "\n",
        "import openai\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from tenacity import retry, stop_after_attempt, wait_chain, wait_fixed\n",
        "\n",
        "#%cd /content/chain-of-thought-hub/MMLU\n",
        "#from utils import *\n",
        "\n",
        "# parse arguments\n",
        "#import argparse\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument(client.api_key)\n",
        "#parser.add_argument('--api_key', type=str, default='sk')\n",
        "#args = parser.parse_args()\n",
        "#print(args.echo)\n",
        "#args=client.api_key\n",
        "\n",
        "TASKS_ORIGINAL = [\n",
        "        'abstract_algebra',\n",
        "        'anatomy',\n",
        "        'astronomy',\n",
        "        'business_ethics',\n",
        "        'clinical_knowledge',\n",
        "        'college_biology',\n",
        "        'college_chemistry',\n",
        "        'college_computer_science',\n",
        "        'college_mathematics',\n",
        "        'college_medicine',\n",
        "        'college_physics',\n",
        "        'computer_security',\n",
        "        'conceptual_physics',\n",
        "        'econometrics',\n",
        "        'electrical_engineering',\n",
        "        'elementary_mathematics',\n",
        "        'formal_logic',\n",
        "        'global_facts',\n",
        "        'high_school_biology',\n",
        "        'high_school_chemistry',\n",
        "        'high_school_computer_science',\n",
        "        'high_school_european_history',\n",
        "        'high_school_geography',\n",
        "        'high_school_government_and_politics',\n",
        "        'high_school_macroeconomics',\n",
        "        'high_school_mathematics',\n",
        "        'high_school_microeconomics',\n",
        "        'high_school_physics',\n",
        "        'high_school_psychology',\n",
        "        'high_school_statistics',\n",
        "        'high_school_us_history',\n",
        "        'high_school_world_history',\n",
        "        'human_aging',\n",
        "        'human_sexuality',\n",
        "        'international_law',\n",
        "        'jurisprudence',\n",
        "        'logical_fallacies',\n",
        "        'machine_learning',\n",
        "        'management',\n",
        "        'marketing',\n",
        "        'medical_genetics',\n",
        "        'miscellaneous',\n",
        "        'moral_disputes',\n",
        "        'moral_scenarios',\n",
        "        'nutrition',\n",
        "        'philosophy',\n",
        "        'prehistory',\n",
        "        'professional_accounting',\n",
        "        'professional_law',\n",
        "        'professional_medicine',\n",
        "        'professional_psychology',\n",
        "        'public_relations',\n",
        "        'security_studies',\n",
        "        'sociology',\n",
        "        'us_foreign_policy',\n",
        "        'virology',\n",
        "        'world_religions']\n",
        "\n",
        "@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +\n",
        "                       [wait_fixed(5) for i in range(2)] +\n",
        "                       [wait_fixed(10)]))\n",
        "\n",
        "#def completion_with_backoff(**kwargs):\n",
        "#    return openai.ChatCompletion.create(**kwargs)\n",
        "\n",
        "def main(tasks=TASKSTEST):\n",
        "    openai.api_key = openai.api_key\n",
        "    mmlu_prompt = json.load(open('/content/chain-of-thought-hub/MMLU/lib_prompt/mmlu-cot.json'))\n",
        "    for task in tasks:\n",
        "\n",
        "        print()\n",
        "        print('Testing %s ...' % task)\n",
        "        print()\n",
        "\n",
        "        i = 0\n",
        "        acc = 0\n",
        "        task_data = load_dataset(\"lukaemon/mmlu\", task, trust_remote_code=True)\n",
        "        with open('/content/outputs/test_gpt_3.5_turbo_%s.txt' % task, 'w') as fd:\n",
        "            for q_ in tqdm(task_data['test'], total=len(task_data['test'])):\n",
        "                q = q_['input'] + '\\n'\n",
        "                for letter in ['A', 'B', 'C', 'D']:\n",
        "                    q += '(' + letter + ') ' + q_[letter] + ' '\n",
        "                q += \"\\nA: Let's think step by step.\"\n",
        "\n",
        "                prompt_q = mmlu_prompt[task] + \"\\n\\n\" + q\n",
        "                #print(prompt_q)\n",
        "\n",
        "                ### ADDED by Frank Morales 30/03/2023\n",
        "                response = client.chat.completions.create(\n",
        "                  #model=\"gpt-3.5-turbo\",\n",
        "                  model=\"gpt-4\",\n",
        "                  messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_q},\n",
        "                    #{\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "                    #{\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "                  ]\n",
        "                )\n",
        "\n",
        "                 ### ORIGINAL ####\n",
        "                 #response = completion_with_backoff(\n",
        "                    #model=\"gpt-3.5-turbo\",\n",
        "                 #   model=\"gpt-4\",\n",
        "                 #   messages=[\n",
        "                 #           {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "                 #          {\"role\": \"user\", \"content\": prompt_q},\n",
        "                 #       ],\n",
        "                 #   temperature=0.9\n",
        "                 #   )\n",
        "                #print('\\n',response['choices'][0])\n",
        "                #print(response.choices[0].message.content)\n",
        "\n",
        "                ### ADDED by Frank Morales 30/03/2023\n",
        "                ans_model = response.choices[0].message.content\n",
        "\n",
        "                #ans_model = response['choices'][0]['message']['content']\n",
        "\n",
        "                ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "                a = q_['target']\n",
        "                #print(a)\n",
        "                fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "                i += 1\n",
        "\n",
        "                if(test_answer_mmlu_(ans_, a)): acc += 1\n",
        "            print('%s acc %.4f' % (task, acc / len(task_data['test'])))\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "zhINTrXL5Tol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2e44d8-3897-4bd1-ad0c-1421e99e80e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing college_computer_science ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [11:00<00:00,  6.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "college_computer_science acc 0.6900\n",
            "\n",
            "Testing electrical_engineering ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 145/145 [06:27<00:00,  2.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "electrical_engineering acc 0.7586\n",
            "\n",
            "Testing machine_learning ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112/112 [08:48<00:00,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine_learning acc 0.7768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating CLAUDE3 model on MMLU"
      ],
      "metadata": {
        "id": "SshNx_i3FRJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic -q\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "import colab_env\n",
        "import json"
      ],
      "metadata": {
        "id": "c3Sjm72QFmAc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.environ[\"CLAUDE3_API_KEY\"]\n",
        "model=\"claude-3-opus-20240229\"\n",
        "\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "gWysJq8oFfMg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "-QdVaJwQFzwW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI4fRXu5F3pP",
        "outputId": "51df8344-0067-45e5-8f9b-1f9a0ee0b560"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! It's nice to meet you. How are you doing today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# evaluating Claude model on converted MMLU to Claude prompt,\n",
        "# with the option of single or multiple rounds of questions\n",
        "\n",
        "import anthropic\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "#from utils import *\n",
        "\n",
        "\n",
        "TASKS = [\n",
        "        'abstract_algebra',\n",
        "        'anatomy',\n",
        "        'astronomy',\n",
        "        'business_ethics',\n",
        "        'clinical_knowledge',\n",
        "        'college_biology',\n",
        "        'college_chemistry',\n",
        "        'college_computer_science',\n",
        "        'college_mathematics',\n",
        "        'college_medicine',\n",
        "        'college_physics',\n",
        "        'computer_security',\n",
        "        'conceptual_physics',\n",
        "        'econometrics',\n",
        "        'electrical_engineering',\n",
        "        'elementary_mathematics',\n",
        "        'formal_logic',\n",
        "        'global_facts',\n",
        "        'high_school_biology',\n",
        "        'high_school_chemistry',\n",
        "        'high_school_computer_science',\n",
        "        'high_school_european_history',\n",
        "        'high_school_geography',\n",
        "        'high_school_government_and_politics',\n",
        "        'high_school_macroeconomics',\n",
        "        'high_school_mathematics',\n",
        "        'high_school_microeconomics',\n",
        "        'high_school_physics',\n",
        "        'high_school_psychology',\n",
        "        'high_school_statistics',\n",
        "        'high_school_us_history',\n",
        "        'high_school_world_history',\n",
        "        'human_aging',\n",
        "        'human_sexuality',\n",
        "        'international_law',\n",
        "        'jurisprudence',\n",
        "        'logical_fallacies',\n",
        "        'machine_learning',\n",
        "        'management',\n",
        "        'marketing',\n",
        "        'medical_genetics',\n",
        "        'miscellaneous',\n",
        "        'moral_disputes',\n",
        "        'moral_scenarios',\n",
        "        'nutrition',\n",
        "        'philosophy',\n",
        "        'prehistory',\n",
        "        'professional_accounting',\n",
        "        'professional_law',\n",
        "        'professional_medicine',\n",
        "        'professional_psychology',\n",
        "        'public_relations',\n",
        "        'security_studies',\n",
        "        'sociology',\n",
        "        'us_foreign_policy',\n",
        "        'virology',\n",
        "        'world_religions']\n",
        "\n",
        "\n",
        "def get_response(**kwargs):\n",
        "    #client = anthropic.Client(args.anthropic_key)\n",
        "    client = anthropic.Anthropic(\n",
        "    api_key=api_key,)\n",
        "    #response = client.completions(**kwargs)\n",
        "    response = client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
        "    ]\n",
        ")\n",
        "    return response\n",
        "\n",
        "model=\"claude-3-opus-20240229\"\n",
        "\n",
        "def main(tasks=TASKSTEST):\n",
        "    for task in tasks:\n",
        "        print('Testing %s ...' % task)\n",
        "        i = 0\n",
        "        acc = 0\n",
        "        task_data = load_dataset(\"lukaemon/mmlu\", task, trust_remote_code=True)\n",
        "\n",
        "        with open('/content/outputs/test_%s_%s.txt' % (model, task), 'w') as fd:\n",
        "            for q_ in tqdm(task_data['test'], total=len(task_data['test'])):\n",
        "                q = 'Q: '+ q_['input'] + '\\n'\n",
        "                task_mod = task.replace('_', ' ')\n",
        "\n",
        "                # add test prompt based on subject matter\n",
        "                if task_mod in [\"business ethics\",\n",
        "                                \"computer security\",\n",
        "                                \"marketing\"]:\n",
        "                    q += \"Which one of the four choices completes the question correctly, (A), (B), (C) or (D)?\" + \"\\nChoices:\" + \"\\n\"\n",
        "                elif task_mod in [\"college medicine\",\n",
        "                                    \"high school biology\",\n",
        "                                    \"high school european history\",\n",
        "                                    \"high school geography\",\n",
        "                                    \"high school government and politics\",\n",
        "                                    \"high school macroeconomics\",\n",
        "                                    \"moral disputes\"]:\n",
        "                    q += \"Choices:\"\n",
        "                elif task_mod == \"college physics\":\n",
        "                    q += \"Which one of the four choices is correct about the question, (A), (B), (C) or (D)?\" + \"\\nChoices:\" + \"\\n\"\n",
        "                else:\n",
        "                    q += \"Which one of the four choices is correct, (A), (B), (C) or (D)?\" + \"\\nChoices:\" + \"\\n\"\n",
        "\n",
        "                for letter in ['A', 'B', 'C', 'D']:\n",
        "                    q += '(' + letter + ') ' + q_[letter] + ' '\n",
        "\n",
        "                # add step-by-step prompt\n",
        "                q += \"\\nLet's think step by step.\"\n",
        "                q += \"\\nA:\"\n",
        "\n",
        "                # convert to Claude prompt\n",
        "                # load converted prompt based on prompt type\n",
        "\n",
        "                #model=\"claude-3-opus-20240229\",  ### SIMPLE ###\n",
        "\n",
        "                #You can also specify prompt type to either 'single' or 'multiple'.\n",
        "                #'single' refers to a group of demonstration questions with answers being supplied as a part of the prompt,\n",
        "                #whereas 'multiple' refers to having rounds of conversations for demonstration in the prompt\n",
        "\n",
        "                ### SIMPLE ### CHECK BELOW LINE 187, 195, 198\n",
        "                mmlu_prompt = json.load(open('/content/chain-of-thought-hub/MMLU/lib_prompt/mmlu-cot-claude-single.json'))\n",
        "                prompt_q = mmlu_prompt[task] + \"\\n\\n\" + q\n",
        "                claude_prompt = anthropic.HUMAN_PROMPT + prompt_q + anthropic.AI_PROMPT\n",
        "\n",
        "                ### MULTIPLE #### CHECK BELOW LINE 187, 195, 198\n",
        "                #mmlu_prompt = json.load(open('/content/chain-of-thought-hub/MMLU/lib_prompt/mmlu-cot-claude-multiple.json'))\n",
        "                #prompt_q = mmlu_prompt[task] + \"\\n\\n\" + anthropic.HUMAN_PROMPT + \"\\n\" + q\n",
        "                #claude_prompt = prompt_q + anthropic.AI_PROMPT\n",
        "\n",
        "                ### ORIGINAL ###\n",
        "                #if args.prompt_type == 'single':\n",
        "                #    mmlu_prompt = json.load(open('/content/chain-of-thought-hub/MMLU/lib_prompt/mmlu-cot-claude-single.json'))\n",
        "                #    prompt_q = mmlu_prompt[task] + \"\\n\\n\" + q\n",
        "                #    claude_prompt = anthropic.HUMAN_PROMPT + prompt_q + anthropic.AI_PROMPT\n",
        "                #elif args.prompt_type == 'multiple':\n",
        "                #    mmlu_prompt = json.load(open('/content/chain-of-thought-hub/MMLU/lib_prompt/mmlu-cot-claude-multiple.json'))\n",
        "                #    prompt_q = mmlu_prompt[task] + \"\\n\\n\" + anthropic.HUMAN_PROMPT + \"\\n\" + q\n",
        "                #    claude_prompt = prompt_q + anthropic.AI_PROMPT\n",
        "                #else:\n",
        "                #     raise ValueError('Prompt type not supported')\n",
        "\n",
        "                # obtain Claude response\n",
        "                #response = get_response(\n",
        "                #    model=model,\n",
        "                #    prompt=claude_prompt,\n",
        "                #    stop_sequences=[anthropic.HUMAN_PROMPT],\n",
        "                #    max_tokens_to_sample=300,\n",
        "                #    temperature=0\n",
        "                #    )\n",
        "\n",
        "                ## CLAUDE3 API by FRANK MORALES MARCH 30, 2023\n",
        "                response = client.messages.create(\n",
        "                      model=\"claude-3-opus-20240229\",\n",
        "                      max_tokens=1024,\n",
        "                      messages=[\n",
        "                        {\"role\": \"user\", \"content\":claude_prompt }\n",
        "                               ]\n",
        "                                                )\n",
        "                # clean response\n",
        "                #ans_ = response['completion'].strip()\n",
        "\n",
        "                ans_ = response.content[0].text\n",
        "                a = q_['target']\n",
        "                fd.write('%s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "                i += 1\n",
        "\n",
        "                # check answer\n",
        "                if(test_answer_mmlu_claude_instant(ans_, a)): acc += 1\n",
        "            print('%s acc %.4f' % (task, acc / len(task_data['test'])))\n",
        "\n",
        "        # write accuracy to file\n",
        "        with open('/content/outputs/test_%s_%s_acc.txt' % (model, 'single'), 'a') as fd:\n",
        "            fd.write('%s acc %.4f\\n' % (task, acc / len(task_data['test'])))\n",
        "\n",
        "    # write average accuracy to file\n",
        "    acc_list = []\n",
        "    #with open('/content/outputs/test_%s_%s_acc.txt' % (model, args.prompt_type), 'r') as fd2:\n",
        "\n",
        "    # with open('/content/outputs/test_%s_%s_acc.txt' % (model, 'multiple'), 'r') as fd2:\n",
        "    with open('/content/outputs/test_%s_%s_acc.txt' % (model, 'single'), 'r') as fd2:\n",
        "        for line in fd2:\n",
        "            acc_list.append(float(line.split(' ')[2]))\n",
        "    with open('/content/outputs/test_%s_%s_acc.txt' % (model, 'single'), 'a') as fd:\n",
        "        fd.write('Average acc %.4f\\n' % (np.mean(acc_list)))\n",
        "\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "bGP4PZ3uEnLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f980ac3-2167-4334-e37b-1cdce2f09995"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing college_computer_science ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [29:17<00:00, 17.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "college_computer_science acc 0.5700\n",
            "Testing electrical_engineering ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 145/145 [34:27<00:00, 14.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "electrical_engineering acc 0.3517\n",
            "Testing machine_learning ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112/112 [27:58<00:00, 14.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine_learning acc 0.6161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_file='/content/outputs/test_%s_%s_acc.txt' % (model, 'single')\n",
        "#print(acc_file)\n",
        "\n",
        "with open('/content/outputs/test_%s_%s_acc.txt' % (model, 'single'), 'r') as fd:\n",
        "     for line in fd:\n",
        "            print(line)\n",
        "            #acc_list.append(float(line.split(' ')[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkXqsfxKuuIP",
        "outputId": "f223f89b-9c4f-4c95-8005-4569a3200cce"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "college_computer_science acc 0.5700\n",
            "\n",
            "electrical_engineering acc 0.3517\n",
            "\n",
            "machine_learning acc 0.6161\n",
            "\n",
            "Average acc 0.5141\n",
            "\n"
          ]
        }
      ]
    }
  ]
}