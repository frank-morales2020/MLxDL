{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJqvYRAXFVCW18HrU6cgxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Multi_Agent_Solution_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core LangChain packages\n",
        "!pip install langchain langchain-community -q\n",
        "\n",
        "# LLM integrations for OpenAI and xAI\n",
        "!pip install langchain-openai -q\n",
        "\n",
        "# NOTE: The package for xAI/Grok integration in LangChain is called 'langchain-xai'.\n",
        "# Install this package to use Grok models.\n",
        "!pip install langchain-xai -q\n",
        "\n",
        "# Search tool for the Research Agent\n",
        "!pip install duckduckgo-search -q"
      ],
      "metadata": {
        "id": "Bh1E_K_EgNA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall duckduckgo-search -y\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "id": "rpPz6ualiG4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d529fca2",
        "outputId": "434ecca9-8083-4e5f-9e5d-056b89ac0f37"
      },
      "source": [
        "import os\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain_xai import ChatXAI\n",
        "from ddgs import DDGS  # Import the DDGS class\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- 1. Setup and LLM Configuration ---\n",
        "# Configuration for API keys\n",
        "XAI_API_KEY = None\n",
        "OPENAI_API_KEY = None\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    XAI_API_KEY = userdata.get('XAI_KEY')\n",
        "    if not XAI_API_KEY:\n",
        "        print(\"WARNING: XAI_KEY not found in Colab secrets.\")\n",
        "\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if not OPENAI_API_KEY:\n",
        "        print(\"WARNING: OPENAI_API_KEY not found in Colab secrets.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"WARNING: Not in Colab. Attempting to get API keys from environment variables.\")\n",
        "    XAI_API_KEY = os.environ.get('XAI_KEY', None)\n",
        "    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', None)\n",
        "\n",
        "# Define the LLMs to use\n",
        "llms_to_use = {}\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    # Research Agent uses the GPT-4o-mini model, which supports the 'stop' argument.\n",
        "    llms_to_use['research_llm'] = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0.5)\n",
        "else:\n",
        "    print(\"FATAL ERROR: OPENAI_API_KEY not set. The research agent cannot be initialized.\")\n",
        "    exit()\n",
        "\n",
        "if XAI_API_KEY:\n",
        "    # Writing Agent uses the Grok-4 model for content generation.\n",
        "    llms_to_use['writer_llm'] = ChatXAI(model=\"grok-4\", xai_api_key=XAI_API_KEY, temperature=0.7)\n",
        "else:\n",
        "    print(\"WARNING: XAI_API_KEY not set. Only using GPT for the writing agent as a fallback.\")\n",
        "    # Fallback to OpenAI if Grok key is missing\n",
        "    llms_to_use['writer_llm'] = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0.7)\n",
        "\n",
        "print(\"LLMs configured successfully.\")\n",
        "\n",
        "# --- 2. Define Agents and Tools ---\n",
        "print(\"\\nDefining agents and tools...\")\n",
        "\n",
        "# Tool for the Research Agent using DDGS\n",
        "def ddgs_search(query: str) -> str:\n",
        "    \"\"\"Runs a search using DDGS and returns the results.\"\"\"\n",
        "    with DDGS() as ddgs:\n",
        "        results = [r['body'] for r in ddgs.text(query, max_results=5)]\n",
        "        return \"\\n\".join(results)\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"DuckDuckGoSearch\",\n",
        "    description=\"A search tool that uses DuckDuckGo via the ddgs library. Use this for general web searches.\",\n",
        "    func=ddgs_search\n",
        ")\n",
        "\n",
        "\n",
        "# Research Agent: Uses GPT-4o-mini to research a topic\n",
        "research_agent = initialize_agent(\n",
        "    tools=[search_tool],\n",
        "    llm=llms_to_use['research_llm'],\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=False,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# Writing Agent: Uses Grok-4 to write based on research\n",
        "writer_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"research_result\"],\n",
        "    template=\"You are an expert article writer. Your task is to write a concise, professional article based on the following research data. The article should be a maximum of 3 paragraphs.\\n\\nResearch Data:\\n{research_result}\\n\\nArticle:\"\n",
        ")\n",
        "writer_chain = LLMChain(llm=llms_to_use['writer_llm'], prompt=writer_prompt_template)\n",
        "print(\"Agents defined successfully.\")\n",
        "\n",
        "# --- 3. Orchestrate the Workflow ---\n",
        "print(\"\\nStarting the multi-agent workflow...\")\n",
        "\n",
        "# Create the Sequential Chain\n",
        "full_chain = SimpleSequentialChain(chains=[\n",
        "    research_agent,\n",
        "    writer_chain\n",
        "], verbose=False)\n",
        "\n",
        "# Run the workflow with a user query\n",
        "user_query = \"What are the key differences between the Grok 4 and GPT-5 models?\"\n",
        "final_article = full_chain.run(user_query)\n",
        "\n",
        "print(\"\\n--- Final Article Output ---\")\n",
        "print(final_article)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLMs configured successfully.\n",
            "\n",
            "Defining agents and tools...\n",
            "Agents defined successfully.\n",
            "\n",
            "Starting the multi-agent workflow...\n",
            "\n",
            "--- Final Article Output ---\n",
            "### Comparing Grok 4 and GPT-5: Key Differences in AI Capabilities\n",
            "\n",
            "In the rapidly evolving landscape of artificial intelligence, Grok 4 and GPT-5 stand out as advanced language models developed by competing tech giants. Grok 4, created by xAI, focuses on integrating real-time data processing with a commitment to objectivity, setting it apart in scenarios requiring up-to-the-minute information. Meanwhile, GPT-5, from OpenAI, builds on its predecessors by enhancing core functionalities like reasoning and efficiency. Understanding their differences is crucial for users selecting the right tool for tasks ranging from research to creative generation.\n",
            "\n",
            "Grok 4 excels in real-time search capabilities, allowing it to pull and synthesize current web data seamlessly, which is ideal for dynamic environments like market analysis or news aggregation. It also boasts advanced trend analysis, enabling predictive insights based on emerging patterns, and robust document generation tools that produce structured reports with minimal bias. This emphasis on objectivity stems from its design philosophy, aiming to provide balanced, fact-based responses without the hallucinations sometimes seen in other models.\n",
            "\n",
            "In contrast, GPT-5 shines in strong reasoning abilities, tackling complex problem-solving with logical depth and accuracy. Its faster performance ensures quicker response times, making it suitable for high-volume applications, while multimodal skills allow it to handle diverse inputs like text, images, and audio. Ultimately, the choice between Grok 4 and GPT-5 depends on user needs: Grok 4 for real-time, objective insights, and GPT-5 for versatile, reasoning-driven tasks.\n"
          ]
        }
      ]
    }
  ]
}