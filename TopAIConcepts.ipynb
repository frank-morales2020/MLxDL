{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwQAAxQ2BrEX6AVijkqiP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/TopAIConcepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top AI Concepts\n",
        "\n",
        "1. Machine Learning: Core algorithms, statistics, and model training techniques.\n",
        "2. Deep Learning: Hierarchical neural networks learning complex representations automatically.\n",
        "3. Neural Networks: Layered architectures efficiently model nonlinear relationships accurately.\n",
        "4. NLP: Techniques to process and understand natural language text.\n",
        "5. Computer Vision: Algorithms interpreting and analyzing visual data effectively.\n",
        "6. Reinforcement Learning: This is about an agent learning to make decisions by interacting with an environment to maximize a reward. Your description, \"Distributed traffic across multiple servers for reliability,\" describes load balancing or distributed systems, not reinforcement learning.\n",
        "7. Generative Models: Creating new data samples using learned data.\n",
        "8. LLM (Large Language Models): Generates human-like text using massive pre-trained data.\n",
        "9. Transformers: Self-attention-based architecture powering modern AI models.\n",
        "10. Feature Engineering: Designing informative features to improve model performance significantly.\n",
        "11. Supervised Learning:  This involves learning from labeled data to make predictions or classify outcomes. Your description, \"Learns useful representations without labeled data,\" describes Unsupervised Learning.\n",
        "12. Bayesian Learning: Incorporate uncertainty using probabilistic model approaches.\n",
        "13. Prompt Engineering: Crafting effective inputs to guide generative model outputs.\n",
        "\n",
        "To confirm, are you asking me to provide another AI concept, similar to how I presented \"AI Agents,\" or are you simply acknowledging that you'd like me to continue using that format for future explanations?\n",
        "\n",
        "Assuming you'd like another concept, let's delve into Prompt Engineering, which is highly relevant for our Gemini 2.0 flight planning AI, especially if it incorporates large language models for communication or decision support.\n",
        "\n",
        "13. Prompt Engineering: Crafting Effective Inputs to Guide Generative Model Outputs\n",
        "\n",
        "* Concept Explanation:\n",
        "Prompt Engineering involves designing and refining inputs (prompts) to generative AI models, such as Large Language Models (LLMs), to elicit desired outputs. For a Gemini 2.0 flight planning AI, this is crucial for several reasons:\n",
        "\n",
        "* Precise Instructions: We can guide the AI to generate flight plans that adhere to specific regulations, optimize for fuel efficiency, or prioritize safety by providing clear, well-structured prompts.\n",
        "\n",
        "* Contextual Understanding: By including relevant details about weather, air traffic, aircraft type, and passenger needs in the prompt, the AI can develop a deeper understanding of the flight scenario, leading to more informed decisions.\n",
        "* Behavioral Control: Techniques like \"few-shot prompting\" (providing examples) or \"chain-of-thought prompting\" (asking the model to think step-by-step) can steer the AI's reasoning process and output style, ensuring it generates logical and actionable flight plans.\n",
        "* Adapting to Scenarios: Prompt engineering allows us to quickly adapt the AI's behavior to new or unusual flight conditions without retraining the entire model, by simply adjusting the prompt.\n",
        "\n",
        "\n",
        "14. AI Agents: Autonomous systems that perceive, decide, and act.  (This aligns well with our goal of creating an AI agent for flight planning.)\n",
        "15. Fine-Tuning Models: Customizes pre-trained models for domain-specific tasks.\n",
        "16. Multimodal Models: Processes and generates across multiple data types like images, videos, and text.\n",
        "17. Embeddings: Transforms input into machine-readable vector formats.\n",
        "18. Vector Search: Finds similar items using dense vector embeddings.\n",
        "19. Model Evaluation: Assessing predictive performance using validation techniques.\n",
        "20. AI Infrastructure: Deploying scalable systems to support AI operations.\n",
        "21. Generative Adversarial Networks (GANs)\n",
        "GANs consist of a generator and a discriminator. The generator creates new data, and the discriminator tries to distinguish between real and generated data.\n",
        "22. Graph Neural Networks (GNNs)\n",
        "GNNs operate on graph structures. This example uses a very simplified representation to demonstrate the concept of node features and adjacency. A real GNN would use libraries like PyTorch Geometric or DGL.\n",
        "23. Causal Inference\n",
        "Causal inference aims to determine cause-and-effect relationships. This example illustrates the concept of comparing outcomes under different \"treatments\" (e.g., different flight paths) to infer causality, rather than just correlation.\n",
        "24. Explainable AI (XAI)\n",
        "XAI focuses on making AI model decisions understandable to humans. This example conceptually shows how a simple model's \"explanation\" could be extracted.\n",
        "25. Federated Learning\n",
        "Federated Learning allows multiple clients to train a global model collaboratively without sharing their local data. This is a highly conceptual simulation.\n",
        "\n",
        "Overall, it's a good list of key AI concepts! Just those two corrections for Reinforcement Learning and Supervised Learning were needed."
      ],
      "metadata": {
        "id": "BpD1_LW03gXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These examples provide a basic code illustration for each concept. Remember that in a real-world scenario, each of these would involve significantly more complex code, data, and infrastructure, often leveraging specialized libraries and cloud services."
      ],
      "metadata": {
        "id": "p6c5s0ReYjik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mwmHTEmQTYh",
        "outputId": "155f72a7-27f0-4448-df31-351b7270cdc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Machine Learning: Core Algorithms ---\n",
            "Features (X):\n",
            "[1 2 3 4 5]\n",
            "Target (y):\n",
            "[2 4 5 4 5]\n",
            "Model coefficients: 0.60\n",
            "Model intercept: 2.20\n",
            "Prediction for X=6: 5.80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Machine Learning: Core algorithms, statistics, and model training techniques.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "print(\"--- 1. Machine Learning: Core Algorithms ---\")\n",
        "\n",
        "# Sample data for a simple linear regression\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1) # Feature (e.g., hours studied)\n",
        "y = np.array([2, 4, 5, 4, 5])              # Target (e.g., exam score)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction\n",
        "new_X = np.array([[6]]) # Predict score for 6 hours studied\n",
        "prediction = model.predict(new_X)\n",
        "\n",
        "print(f\"Features (X):\\n{X.flatten()}\")\n",
        "print(f\"Target (y):\\n{y}\")\n",
        "print(f\"Model coefficients: {model.coef_[0]:.2f}\")\n",
        "print(f\"Model intercept: {model.intercept_:.2f}\")\n",
        "print(f\"Prediction for X=6: {prediction[0]:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 2. Deep Learning: Hierarchical Neural Networks ---\")\n",
        "\n",
        "# Generate some dummy data for a binary classification problem\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 10) # 100 samples, 10 features\n",
        "y = (np.sum(X, axis=1) > 5).astype(int) # Simple classification rule\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build a simple sequential deep learning model\n",
        "model = keras.Sequential([\n",
        "    # Use Input layer explicitly as the first layer\n",
        "    keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),         # Hidden layer 1\n",
        "    keras.layers.Dense(16, activation='relu'),         # Hidden layer 2\n",
        "    keras.layers.Dense(1, activation='sigmoid')        # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (simplified for demonstration)\n",
        "print(\"Training a simple Deep Learning model...\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=15, batch_size=10, verbose=0) # verbose=0 to suppress output\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "print(f\"Model trained for 15 epochs.\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK741EU6Qhi3",
        "outputId": "6c2c6b32-3430-4e35-8a0a-439cc714868b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Deep Learning: Hierarchical Neural Networks ---\n",
            "Training a simple Deep Learning model...\n",
            "Model trained for 15 epochs.\n",
            "Test Accuracy: 0.8000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Neural Networks: Layered Architectures efficiently model nonlinear relationships accurately.\n",
        "\n",
        "# This example is conceptually similar to Deep Learning (since Deep Learning uses Neural Networks).\n",
        "# Here, we'll demonstrate a slightly simpler MLP (Multi-Layer Perceptron) without explicit\n",
        "# mention of \"deep\" to highlight the core layered architecture.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "print(\"--- 3. Neural Networks: Layered Architectures ---\")\n",
        "\n",
        "# Generate synthetic dataset for classification\n",
        "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a Multi-Layer Perceptron (MLP) Classifier\n",
        "# hidden_layer_sizes defines the number of neurons in each hidden layer.\n",
        "# (100,) means one hidden layer with 100 neurons.\n",
        "# Increased max_iter to allow more time for convergence\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(50, 20), max_iter=500, random_state=42, verbose=False) # Increased from 100\n",
        "\n",
        "# Train the neural network\n",
        "print(\"Training a simple MLP Classifier...\")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = mlp.score(X_test_scaled, y_test)\n",
        "\n",
        "print(f\"MLP Classifier trained.\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfG7OgK3QruM",
        "outputId": "7e0a78dd-5970-45c4-ff9c-08f2fbf7eb2d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Neural Networks: Layered Architectures ---\n",
            "Training a simple MLP Classifier...\n",
            "MLP Classifier trained.\n",
            "Test Accuracy: 0.9500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. NLP: Techniques to process and understand natural language text.\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure necessary NLTK tokenizers are downloaded\n",
        "try:\n",
        "    # Attempt to find the required tokenizers\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('tokenizers/punkt_tab') # Check for punkt_tab as well\n",
        "# Catch the LookupError that occurs if the resource is not found\n",
        "except LookupError:\n",
        "    print(\"Required NLTK tokenizers not found. Downloading...\")\n",
        "    # Download the punkt tokenizer (needed by word_tokenize)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    # Download punkt_tab (needed by sent_tokenize, which word_tokenize uses internally)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    print(\"Required NLTK tokenizers downloaded.\")\n",
        "\n",
        "\n",
        "print(\"--- 4. NLP: Natural Language Processing ---\")\n",
        "\n",
        "text = \"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language.\"\n",
        "\n",
        "# 1. Tokenization: Breaking text into words or sentences\n",
        "# The word_tokenize function internally uses sent_tokenize which requires punkt_tab\n",
        "tokens = word_tokenize(text.lower()) # Convert to lowercase for consistent counting\n",
        "\n",
        "print(f\"Original Text:\\n{text}\")\n",
        "print(f\"\\nWord Tokens:\\n{tokens}\")\n",
        "\n",
        "# 2. Frequency Distribution (a simple form of understanding)\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "print(f\"\\nWord Frequencies:\")\n",
        "for word, count in word_counts.most_common(5): # Show top 5\n",
        "    print(f\"  '{word}': {count}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBLUmeGJQ8It",
        "outputId": "d3c70cd5-b3f7-485d-fdef-2636a4cd70c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. NLP: Natural Language Processing ---\n",
            "Original Text:\n",
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language.\n",
            "\n",
            "Word Tokens:\n",
            "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.']\n",
            "\n",
            "Word Frequencies:\n",
            "  'language': 2\n",
            "  'natural': 1\n",
            "  'processing': 1\n",
            "  '(': 1\n",
            "  'nlp': 1\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Computer Vision: Algorithms interpreting and analyzing visual data effectively.\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image # Pillow library for image processing\n",
        "\n",
        "print(\"--- 5. Computer Vision: Visual Data Analysis ---\")\n",
        "\n",
        "# Create a dummy 10x10 grayscale image (values 0-255)\n",
        "# In a real scenario, you would load an image, e.g., Image.open(\"image.jpg\")\n",
        "dummy_image_array = np.random.randint(0, 256, size=(10, 10), dtype=np.uint8)\n",
        "dummy_image = Image.fromarray(dummy_image_array, mode='L') # 'L' for grayscale\n",
        "\n",
        "print(f\"Original dummy image (first 3x3 pixels):\\n{np.array(dummy_image)[:3, :3]}\")\n",
        "\n",
        "# Example 1: Basic Image Processing - Grayscale Conversion (already grayscale here, so just demonstrate pixel access)\n",
        "# If it were an RGB image, conversion would involve averaging R, G, B channels.\n",
        "# For simplicity, let's just invert the pixel values.\n",
        "inverted_image_array = 255 - dummy_image_array\n",
        "inverted_image = Image.fromarray(inverted_image_array, mode='L')\n",
        "\n",
        "print(f\"\\nInverted dummy image (first 3x3 pixels):\\n{np.array(inverted_image)[:3, :3]}\")\n",
        "\n",
        "# Example 2: Simple Feature Extraction (e.g., calculating average pixel intensity)\n",
        "average_intensity = np.mean(dummy_image_array)\n",
        "print(f\"\\nAverage pixel intensity: {average_intensity:.2f}\\n\")\n",
        "\n",
        "# Note: For actual CV tasks like object detection or image classification,\n",
        "# you would use libraries like OpenCV or deep learning frameworks (TensorFlow, PyTorch)\n",
        "# with pre-trained models. This is a very basic conceptual example."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eGI43dPR29t",
        "outputId": "1d1182f7-9d7b-4467-f582-36e816ca7e5e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Computer Vision: Visual Data Analysis ---\n",
            "Original dummy image (first 3x3 pixels):\n",
            "[[ 46 223 100]\n",
            " [186 138  79]\n",
            " [ 82   1  38]]\n",
            "\n",
            "Inverted dummy image (first 3x3 pixels):\n",
            "[[209  32 155]\n",
            " [ 69 117 176]\n",
            " [173 254 217]]\n",
            "\n",
            "Average pixel intensity: 130.31\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Reinforcement Learning: An agent learning to make decisions by interacting with an environment.\n",
        "\n",
        "# This is a very simplified conceptual example of Q-learning,\n",
        "# demonstrating the agent-environment interaction loop.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 6. Reinforcement Learning: Agent Decision Making ---\")\n",
        "\n",
        "# Define a simple environment (e.g., a 1D grid world)\n",
        "# States: 0 (start), 1, 2, 3 (goal)\n",
        "# Actions: 0 (move left), 1 (move right)\n",
        "# Rewards: +10 for reaching goal, -1 for each step\n",
        "rewards = np.array([-1, -1, -1, 10]) # Reward for being in state i (reaching goal state 3 gives 10)\n",
        "# Transition: state + action_effect (0 for left, 1 for right)\n",
        "# Q-table: rows are states, columns are actions\n",
        "q_table = np.zeros((4, 2)) # 4 states, 2 actions\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 50\n",
        "\n",
        "print(\"Initial Q-table:\\n\", q_table)\n",
        "\n",
        "# RL training loop\n",
        "for episode in range(num_episodes):\n",
        "    current_state = 0 # Start at state 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Choose action (epsilon-greedy policy: explore or exploit)\n",
        "        if np.random.uniform(0, 1) < 0.1: # 10% chance to explore\n",
        "            action = np.random.randint(0, 2)\n",
        "        else: # Exploit\n",
        "            action = np.argmax(q_table[current_state, :])\n",
        "\n",
        "        # Execute action and observe next state and reward\n",
        "        next_state = current_state + (1 if action == 1 else -1)\n",
        "\n",
        "        # Boundary checks\n",
        "        if next_state < 0: next_state = 0\n",
        "        if next_state > 3: next_state = 3\n",
        "\n",
        "        reward = rewards[next_state] # Reward received upon entering next_state\n",
        "\n",
        "        # Update Q-value\n",
        "        # Q(s,a) = Q(s,a) + alpha * (reward + gamma * max(Q(s',a')) - Q(s,a))\n",
        "        q_table[current_state, action] = q_table[current_state, action] + \\\n",
        "                                         learning_rate * (reward + discount_factor * np.max(q_table[next_state, :]) - q_table[current_state, action])\n",
        "\n",
        "        current_state = next_state\n",
        "\n",
        "        if current_state == 3: # Reached goal state\n",
        "            done = True\n",
        "\n",
        "print(f\"\\nQ-table after {num_episodes} episodes of training:\\n\", np.round(q_table, 2))\n",
        "print(\"\\n\")\n",
        "# Interpretation: Higher Q-values indicate better (more rewarding) actions from a given state.\n",
        "# For example, from state 2, moving right (action 1) should have a much higher Q-value than moving left (action 0)\n",
        "# because it leads to the goal."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU8ZuVXVR9gO",
        "outputId": "a2a9c8f8-f47e-4275-c7ce-b595524c3d01"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 6. Reinforcement Learning: Agent Decision Making ---\n",
            "Initial Q-table:\n",
            " [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n",
            "\n",
            "Q-table after 50 episodes of training:\n",
            " [[ 5.71  7.07]\n",
            " [ 5.66  8.5 ]\n",
            " [ 7.06 10.  ]\n",
            " [ 0.    0.  ]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Generative Models: Creating new data samples using learned data.\n",
        "\n",
        "# This example demonstrates a very simple text generation using a Markov chain,\n",
        "# which is a conceptual predecessor to more complex generative models.\n",
        "# It learns probabilities of sequences and then generates based on them.\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "print(\"--- 7. Generative Models: Creating New Data ---\")\n",
        "\n",
        "# Sample text data to learn from\n",
        "text = \"the quick brown fox jumps over the lazy dog. the dog barks. the fox runs.\"\n",
        "\n",
        "# Preprocess the text (simple tokenization)\n",
        "words = text.lower().replace('.', '').split()\n",
        "\n",
        "# Build a simple Markov Chain model\n",
        "# stores: { 'word': [list of words that follow it] }\n",
        "markov_chain = defaultdict(list)\n",
        "for i in range(len(words) - 1):\n",
        "    current_word = words[i]\n",
        "    next_word = words[i+1]\n",
        "    markov_chain[current_word].append(next_word)\n",
        "\n",
        "print(f\"Learned Markov Chain (first 3 entries):\\n{dict(list(markov_chain.items())[:3])}...\")\n",
        "\n",
        "# Generate new text\n",
        "def generate_text(model, start_word, length=10):\n",
        "    generated_sequence = [start_word]\n",
        "    current_word = start_word\n",
        "\n",
        "    for _ in range(length - 1):\n",
        "        if current_word in model and model[current_word]:\n",
        "            next_word = random.choice(model[current_word])\n",
        "            generated_sequence.append(next_word)\n",
        "            current_word = next_word\n",
        "        else:\n",
        "            break # No next word found for this sequence\n",
        "\n",
        "    return ' '.join(generated_sequence)\n",
        "\n",
        "start_word = random.choice(words) # Pick a random starting word\n",
        "generated_sentence = generate_text(markov_chain, start_word, length=8)\n",
        "\n",
        "print(f\"\\nStarting word for generation: '{start_word}'\")\n",
        "print(f\"Generated Text: '{generated_sentence}'\\n\")\n",
        "\n",
        "# Real generative models (GANs, VAEs, Diffusion Models) are far more complex,\n",
        "# learning intricate distributions of data like images, audio, or high-fidelity text.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hq_ITEWSfX7",
        "outputId": "562b3dae-9c57-4263-c25a-bdda3aedc36f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 7. Generative Models: Creating New Data ---\n",
            "Learned Markov Chain (first 3 entries):\n",
            "{'the': ['quick', 'lazy', 'dog', 'fox'], 'quick': ['brown'], 'brown': ['fox']}...\n",
            "\n",
            "Starting word for generation: 'the'\n",
            "Generated Text: 'the dog the quick brown fox runs'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio\n",
        "\n",
        "print(\"--- 8. LLM: Large Language Models ---\")\n",
        "\n",
        "# Mock LLM API call function\n",
        "async def mock_llm_generate(prompt):\n",
        "    \"\"\"\n",
        "    Simulates calling an LLM API to generate text.\n",
        "    In a real application, this would be a network request.\n",
        "    \"\"\"\n",
        "    print(f\"Sending prompt to LLM: '{prompt}'\")\n",
        "    # Simulate a delay for API call\n",
        "    await asyncio.sleep(1)\n",
        "\n",
        "    # Mock responses based on prompt\n",
        "    if \"Python programming\" in prompt:\n",
        "        return \"Python is a high-level, interpreted programming language known for its readability and versatility.\"\n",
        "    elif \"flight planning\" in prompt:\n",
        "        return \"Flight planning involves optimizing routes, considering weather, fuel, and airspace restrictions to ensure a safe and efficient journey.\"\n",
        "    else:\n",
        "        return \"As an AI, I can generate text based on various prompts. How can I assist you further?\"\n",
        "\n",
        "# Example usage\n",
        "async def main():\n",
        "    user_prompt_1 = \"Explain Python programming in one sentence.\"\n",
        "    response_1 = await mock_llm_generate(user_prompt_1)\n",
        "    print(f\"LLM Response 1: {response_1}\\n\")\n",
        "\n",
        "    user_prompt_2 = \"What is involved in flight planning?\"\n",
        "    response_2 = await mock_llm_generate(user_prompt_2)\n",
        "    print(f\"LLM Response 2: {response_2}\\n\")\n",
        "\n",
        "print(\"Simulating LLM interaction...\")\n",
        "await main() # Await the main coroutine directly\n",
        "print(\"LLM simulation complete.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIUryGOffnQe",
        "outputId": "69351cea-ed63-407c-d38f-7789cbf79855"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 8. LLM: Large Language Models ---\n",
            "Simulating LLM interaction...\n",
            "Sending prompt to LLM: 'Explain Python programming in one sentence.'\n",
            "LLM Response 1: Python is a high-level, interpreted programming language known for its readability and versatility.\n",
            "\n",
            "Sending prompt to LLM: 'What is involved in flight planning?'\n",
            "LLM Response 2: Flight planning involves optimizing routes, considering weather, fuel, and airspace restrictions to ensure a safe and efficient journey.\n",
            "\n",
            "LLM simulation complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Transformers: Self-attention-based architecture powering modern AI models.\n",
        "\n",
        "# This is a highly simplified conceptual representation of the self-attention mechanism,\n",
        "# which is the core innovation of Transformers.\n",
        "# A full Transformer implementation involves multiple layers, multi-head attention,\n",
        "# feed-forward networks, layer normalization, and residual connections.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 9. Transformers: Self-Attention Architecture ---\")\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each row of x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def self_attention(query, key, value, mask=None):\n",
        "    \"\"\"\n",
        "    Simplified self-attention mechanism.\n",
        "    query, key, value: matrices representing Q, K, V for a single head.\n",
        "    mask: optional mask for attention (e.g., for causality in decoders).\n",
        "    \"\"\"\n",
        "    # 1. Calculate Attention Scores: Query dot Key transpose\n",
        "    # (Batch, Seq_len, Features) x (Batch, Features, Seq_len) -> (Batch, Seq_len, Seq_len)\n",
        "    scores = np.matmul(query, key.T) # No scaling by sqrt(d_k) for simplicity\n",
        "\n",
        "    # 2. Apply optional mask (e.g., for decoder attention)\n",
        "    if mask is not None:\n",
        "        scores = scores + mask # Mask out unwanted connections (e.g., future tokens)\n",
        "\n",
        "    # 3. Apply Softmax to get Attention Weights\n",
        "    attention_weights = softmax(scores)\n",
        "\n",
        "    # 4. Multiply with Value matrix\n",
        "    output = np.matmul(attention_weights, value)\n",
        "    return output, attention_weights\n",
        "\n",
        "# Example usage: Imagine 3 tokens, each with a 4-dimensional embedding\n",
        "# In reality, Q, K, V are derived from the input embedding via linear transformations.\n",
        "token_embeddings = np.array([\n",
        "    [1.0, 0.0, 1.0, 0.0], # \"The\"\n",
        "    [0.0, 1.0, 0.0, 1.0], # \"cat\"\n",
        "    [1.0, 1.0, 0.0, 0.0]  # \"sits\"\n",
        "])\n",
        "\n",
        "# For self-attention, Q, K, V are all derived from the same input sequence.\n",
        "# For simplicity, we'll use the embeddings directly as Q, K, V\n",
        "Q = token_embeddings\n",
        "K = token_embeddings\n",
        "V = token_embeddings\n",
        "\n",
        "print(f\"Input Embeddings (Q, K, V):\\n{token_embeddings}\")\n",
        "\n",
        "# Calculate self-attention output and weights\n",
        "output, attention_weights = self_attention(Q, K, V)\n",
        "\n",
        "print(f\"\\nSelf-Attention Output:\\n{np.round(output, 3)}\")\n",
        "print(f\"\\nSelf-Attention Weights (how much each token 'attends' to others):\\n{np.round(attention_weights, 3)}\\n\")\n",
        "\n",
        "# For example, attention_weights[0, 1] indicates how much the first token (\"The\")\n",
        "# attends to the second token (\"cat\").\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ5tmBBV1Ork",
        "outputId": "85a0df69-75a8-473b-891e-8b8615f8bc95"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 9. Transformers: Self-Attention Architecture ---\n",
            "Input Embeddings (Q, K, V):\n",
            "[[1. 0. 1. 0.]\n",
            " [0. 1. 0. 1.]\n",
            " [1. 1. 0. 0.]]\n",
            "\n",
            "Self-Attention Output:\n",
            "[[0.91  0.335 0.665 0.09 ]\n",
            " [0.335 0.91  0.09  0.665]\n",
            " [0.788 0.788 0.212 0.212]]\n",
            "\n",
            "Self-Attention Weights (how much each token 'attends' to others):\n",
            "[[0.665 0.09  0.245]\n",
            " [0.09  0.665 0.245]\n",
            " [0.212 0.212 0.576]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Feature Engineering: Designing informative features to improve model performance significantly.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 10. Feature Engineering: Designing Informative Features ---\")\n",
        "\n",
        "# Sample DataFrame with raw features\n",
        "data = {\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'income': [50000, 60000, 75000, 90000, 110000],\n",
        "    'education_years': [12, 16, 18, 16, 20],\n",
        "    'has_children': [0, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original DataFrame:\\n\", df)\n",
        "\n",
        "# Example 1: Creating a new feature by combining existing ones (e.g., income per year of education)\n",
        "df['income_per_education_year'] = df['income'] / df['education_years']\n",
        "\n",
        "# Example 2: Creating a categorical feature from a numerical one (e.g., age groups)\n",
        "df['age_group'] = pd.cut(df['age'], bins=[0, 30, 40, np.inf], labels=['young', 'middle_aged', 'senior'])\n",
        "\n",
        "# Example 3: One-Hot Encoding (for categorical features)\n",
        "# This isn't generating a new feature from others, but transforming existing for ML models\n",
        "df_encoded = pd.get_dummies(df, columns=['age_group'], prefix='age_group')\n",
        "\n",
        "\n",
        "print(\"\\nDataFrame after Feature Engineering:\")\n",
        "print(df_encoded)\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxzq6UyEWJGy",
        "outputId": "f843de69-16b6-418e-dd7a-3934e4204f38"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 10. Feature Engineering: Designing Informative Features ---\n",
            "Original DataFrame:\n",
            "    age  income  education_years  has_children\n",
            "0   25   50000               12             0\n",
            "1   30   60000               16             1\n",
            "2   35   75000               18             0\n",
            "3   40   90000               16             1\n",
            "4   45  110000               20             0\n",
            "\n",
            "DataFrame after Feature Engineering:\n",
            "   age  income  education_years  has_children  income_per_education_year  \\\n",
            "0   25   50000               12             0                4166.666667   \n",
            "1   30   60000               16             1                3750.000000   \n",
            "2   35   75000               18             0                4166.666667   \n",
            "3   40   90000               16             1                5625.000000   \n",
            "4   45  110000               20             0                5500.000000   \n",
            "\n",
            "   age_group_young  age_group_middle_aged  age_group_senior  \n",
            "0             True                  False             False  \n",
            "1             True                  False             False  \n",
            "2            False                   True             False  \n",
            "3            False                   True             False  \n",
            "4            False                  False              True  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Supervised Learning: Learns from labeled data to make predictions or classify outcomes.\n",
        "\n",
        "# This example uses the Iris dataset for classification, which is a classic supervised learning problem.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"--- 11. Supervised Learning: Learning from Labeled Data ---\")\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = iris.target # Target (species: Setosa, Versicolor, Virginica)\n",
        "\n",
        "print(f\"Features (first 5 samples):\\n{X[:5]}\")\n",
        "print(f\"Labels (first 5 samples):\\n{y[:5]}\")\n",
        "print(f\"Target Names: {iris.target_names}\\n\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model (a common supervised learning algorithm)\n",
        "model = LogisticRegression(max_iter=200) # Increase max_iter for convergence warnings\n",
        "\n",
        "# Train the model using the labeled training data\n",
        "print(\"Training Logistic Regression model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model trained on {len(X_train)} samples.\")\n",
        "print(f\"Predictions (first 5 test samples): {y_pred[:5]}\")\n",
        "print(f\"Actual Labels (first 5 test samples): {y_test[:5]}\")\n",
        "print(f\"Accuracy of the model: {accuracy:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8apKPLlIWWvj",
        "outputId": "361a432c-7ef7-4c3d-e3c5-606eb014ddf4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 11. Supervised Learning: Learning from Labeled Data ---\n",
            "Features (first 5 samples):\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "Labels (first 5 samples):\n",
            "[0 0 0 0 0]\n",
            "Target Names: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "Training Logistic Regression model...\n",
            "Model trained on 105 samples.\n",
            "Predictions (first 5 test samples): [1 0 2 1 1]\n",
            "Actual Labels (first 5 test samples): [1 0 2 1 1]\n",
            "Accuracy of the model: 1.0000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Bayesian Learning: Incorporate uncertainty using probabilistic model approaches.\n",
        "\n",
        "# This example demonstrates Bayesian inference for a simple coin toss problem.\n",
        "# We'll estimate the probability of heads (p) given some observed tosses.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import beta\n",
        "\n",
        "print(\"--- 12. Bayesian Learning: Incorporating Uncertainty ---\")\n",
        "\n",
        "# Prior distribution for the probability of heads (p)\n",
        "# Using a Beta distribution: Beta(alpha, beta)\n",
        "# A Beta(1,1) is a uniform prior (all p values equally likely)\n",
        "alpha_prior = 1\n",
        "beta_prior = 1\n",
        "\n",
        "# Observed data: 10 coin tosses, 7 heads (1), 3 tails (0)\n",
        "coin_tosses = [1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
        "num_heads = sum(coin_tosses)\n",
        "num_tails = len(coin_tosses) - num_heads\n",
        "\n",
        "print(f\"Observed data: {len(coin_tosses)} tosses, {num_heads} heads, {num_tails} tails.\")\n",
        "\n",
        "# Update the prior to get the posterior distribution\n",
        "# For Beta-Binomial conjugacy:\n",
        "# Posterior alpha = Prior alpha + Number of Heads\n",
        "# Posterior beta = Prior beta + Number of Tails\n",
        "alpha_posterior = alpha_prior + num_heads\n",
        "beta_posterior = beta_prior + num_tails\n",
        "\n",
        "print(f\"Prior: Beta({alpha_prior}, {beta_prior})\")\n",
        "print(f\"Posterior: Beta({alpha_posterior}, {beta_posterior})\")\n",
        "\n",
        "# Plotting the prior and posterior distributions (conceptual visualization)\n",
        "p_values = np.linspace(0, 1, 100) # Possible values for p (probability of heads)\n",
        "prior_pdf = beta.pdf(p_values, alpha_prior, beta_prior)\n",
        "posterior_pdf = beta.pdf(p_values, alpha_posterior, beta_posterior)\n",
        "\n",
        "print(\"\\nVisualizing prior and posterior distributions (conceptual):\")\n",
        "print(\"  (Imagine a plot where the posterior distribution is narrower and peaked around 0.7)\")\n",
        "\n",
        "# A simple way to report the estimate of p:\n",
        "# The mean of the Beta posterior distribution is alpha_posterior / (alpha_posterior + beta_posterior)\n",
        "estimated_p = alpha_posterior / (alpha_posterior + beta_posterior)\n",
        "print(f\"Estimated probability of heads (posterior mean): {estimated_p:.3f}\\n\")\n",
        "\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.plot(p_values, prior_pdf, label=f'Prior Beta({alpha_prior},{beta_prior})')\n",
        "# plt.plot(p_values, posterior_pdf, label=f'Posterior Beta({alpha_posterior},{beta_posterior})')\n",
        "# plt.title('Bayesian Inference for Coin Toss')\n",
        "# plt.xlabel('Probability of Heads (p)')\n",
        "# plt.ylabel('Probability Density')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show() # Cannot show plots in this environment, but this is how you'd visualize it.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hhBC6r-WlSC",
        "outputId": "ae380cb2-5a50-4ea7-80fa-50549d817e17"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 12. Bayesian Learning: Incorporating Uncertainty ---\n",
            "Observed data: 10 tosses, 7 heads, 3 tails.\n",
            "Prior: Beta(1, 1)\n",
            "Posterior: Beta(8, 4)\n",
            "\n",
            "Visualizing prior and posterior distributions (conceptual):\n",
            "  (Imagine a plot where the posterior distribution is narrower and peaked around 0.7)\n",
            "Estimated probability of heads (posterior mean): 0.667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Prompt Engineering: Crafting effective inputs to guide generative model outputs.\n",
        "\n",
        "print(\"--- 13. Prompt Engineering: Crafting Effective Inputs ---\")\n",
        "\n",
        "# Base instruction for an LLM\n",
        "base_instruction = \"Generate a short story about a brave knight.\"\n",
        "\n",
        "# Adding constraints and specific details\n",
        "# Technique 1: Adding a persona/role\n",
        "persona_prompt = \"Act as a seasoned storyteller. \" + base_instruction + \" Ensure the story is no more than 100 words and includes a dragon.\"\n",
        "\n",
        "# Technique 2: Providing examples (few-shot prompting)\n",
        "few_shot_example = \"\"\"\n",
        "Example:\n",
        "Input: \"Write a haiku about nature.\"\n",
        "Output: \"Green grass, soft breeze, / Birds sing a sweet melody, / Nature's gentle hug.\"\n",
        "\n",
        "Now, \"Write a haiku about a bustling city.\"\n",
        "\"\"\"\n",
        "\n",
        "# Technique 3: Chain-of-Thought prompting (asking the model to think step-by-step)\n",
        "cot_prompt = \"Let's think step by step. First, outline three key plot points for a detective story. Second, write a brief opening paragraph based on the first plot point.\"\n",
        "\n",
        "print(f\"Base Prompt:\\n'{base_instruction}'\\n\")\n",
        "print(f\"Prompt with Persona and Constraints:\\n'{persona_prompt}'\\n\")\n",
        "print(f\"Few-Shot Prompt (Conceptual):\\n'{few_shot_example}'\\n\")\n",
        "print(f\"Chain-of-Thought Prompt (Conceptual):\\n'{cot_prompt}'\\n\")\n",
        "\n",
        "# In a real scenario, these prompts would be sent to an LLM API.\n",
        "# The effectiveness is judged by the quality and relevance of the LLM's output.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEIZCohrWx2j",
        "outputId": "b1765939-76b3-4854-93c3-086bd2e7c11a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 13. Prompt Engineering: Crafting Effective Inputs ---\n",
            "Base Prompt:\n",
            "'Generate a short story about a brave knight.'\n",
            "\n",
            "Prompt with Persona and Constraints:\n",
            "'Act as a seasoned storyteller. Generate a short story about a brave knight. Ensure the story is no more than 100 words and includes a dragon.'\n",
            "\n",
            "Few-Shot Prompt (Conceptual):\n",
            "'\n",
            "Example:\n",
            "Input: \"Write a haiku about nature.\"\n",
            "Output: \"Green grass, soft breeze, / Birds sing a sweet melody, / Nature's gentle hug.\"\n",
            "\n",
            "Now, \"Write a haiku about a bustling city.\"\n",
            "'\n",
            "\n",
            "Chain-of-Thought Prompt (Conceptual):\n",
            "'Let's think step by step. First, outline three key plot points for a detective story. Second, write a brief opening paragraph based on the first plot point.'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Example:\n",
        "The following Python code illustrates various prompt engineering techniques, such as base instructions, adding persona/roles, few-shot prompting, and chain-of-thought prompting. These examples showcase how different prompt structures can influence the generative model's output"
      ],
      "metadata": {
        "id": "v9YlvDCXdkbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Prompt Engineering: Crafting effective inputs to guide generative model outputs.\n",
        "\n",
        "print(\"--- 13. Prompt Engineering: Crafting Effective Inputs ---\")\n",
        "\n",
        "# Base instruction for an LLM\n",
        "base_instruction = \"Generate a short story about a brave knight.\"\n",
        "print(f\"Base Prompt:\\n'{base_instruction}'\\n\")\n",
        "\n",
        "# Adding constraints and specific details\n",
        "# Technique 1: Adding a persona/role\n",
        "persona_prompt = \"Act as a seasoned storyteller. \" + base_instruction + \" Ensure the story is no more than 100 words and includes a dragon.\"\n",
        "print(f\"Prompt with Persona and Constraints:\\n'{persona_prompt}'\\n\")\n",
        "\n",
        "# Technique 2: Providing examples (few-shot prompting)\n",
        "few_shot_example = \"\"\"\n",
        "Example:\n",
        "Input: \"Write a haiku about nature.\"\n",
        "Output: \"Green grass, soft breeze, / Birds sing a sweet melody, / Nature's gentle hug.\"\n",
        "\"\"\"\n",
        "few_shot_prompt = few_shot_example + \"\\nNow, \\\"Write a haiku about a bustling city.\\\"\"\n",
        "print(f\"Few-Shot Prompt (Conceptual):\\n'{few_shot_prompt}'\\n\")\n",
        "\n",
        "# Technique 3: Chain-of-Thought prompting (asking the model to think step-by-step)\n",
        "cot_prompt = \"\"\"Let's think step by step. First, outline three key plot points for a detective story. Second, write a brief opening paragraph based on the first plot point.\"\"\"\n",
        "print(f\"Chain-of-Thought Prompt (Conceptual):\\n'{cot_prompt}'\\n\")\n",
        "\n",
        "# In a real scenario, these prompts would be sent to an LLM API.\n",
        "# The effectiveness is judged by the quality and relevance of the LLM's output."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv6gEc30dVim",
        "outputId": "b1d74454-b0be-4b1f-a87b-3e313eca9000"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 13. Prompt Engineering: Crafting Effective Inputs ---\n",
            "Base Prompt:\n",
            "'Generate a short story about a brave knight.'\n",
            "\n",
            "Prompt with Persona and Constraints:\n",
            "'Act as a seasoned storyteller. Generate a short story about a brave knight. Ensure the story is no more than 100 words and includes a dragon.'\n",
            "\n",
            "Few-Shot Prompt (Conceptual):\n",
            "'\n",
            "Example:\n",
            "Input: \"Write a haiku about nature.\"\n",
            "Output: \"Green grass, soft breeze, / Birds sing a sweet melody, / Nature's gentle hug.\"\n",
            "\n",
            "Now, \"Write a haiku about a bustling city.\"'\n",
            "\n",
            "Chain-of-Thought Prompt (Conceptual):\n",
            "'Let's think step by step. First, outline three key plot points for a detective story. Second, write a brief opening paragraph based on the first plot point.'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. AI Agents: Autonomous systems that perceive, decide, and act.\n",
        "\n",
        "# This is a simple conceptual model of an AI agent for a \"room cleaning\" scenario,\n",
        "# demonstrating the Perceive-Decide-Act cycle.\n",
        "\n",
        "import time\n",
        "\n",
        "print(\"--- 14. AI Agents: Autonomous Systems ---\")\n",
        "\n",
        "class SimpleCleaningAgent:\n",
        "    def __init__(self, name=\"Roomba\"):\n",
        "        self.name = name\n",
        "        self.location = \"room_A\"\n",
        "        self.percepts = {}\n",
        "        self.goal = \"clean_room_A\"\n",
        "        self.actions = {\n",
        "            \"move_to_room_B\": self._move_to_room_B,\n",
        "            \"vacuum_floor\": self._vacuum_floor,\n",
        "            \"report_status\": self._report_status\n",
        "        }\n",
        "        self.cleaned_rooms = []\n",
        "\n",
        "    def perceive(self, environment_state):\n",
        "        \"\"\"\n",
        "        Perceives the current state of the environment.\n",
        "        In a real agent, this would involve sensors, data streams, etc.\n",
        "        \"\"\"\n",
        "        self.percepts = environment_state\n",
        "        print(f\"[{self.name}] Perceiving: {self.percepts}\")\n",
        "\n",
        "    def decide(self):\n",
        "        \"\"\"\n",
        "        Decides the next action based on percepts and internal goals.\n",
        "        This is the 'brain' of the agent.\n",
        "        \"\"\"\n",
        "        if self.location == \"room_A\" and not self.percepts.get(\"room_A_clean\"):\n",
        "            print(f\"[{self.name}] Deciding: Room A is dirty, vacuum.\")\n",
        "            return \"vacuum_floor\"\n",
        "        elif self.location == \"room_A\" and self.percepts.get(\"room_A_clean\") and \"room_A\" not in self.cleaned_rooms:\n",
        "            print(f\"[{self.name}] Deciding: Room A is clean, report.\")\n",
        "            self.cleaned_rooms.append(\"room_A\") # Mark as cleaned\n",
        "            return \"report_status\"\n",
        "        elif self.location == \"room_A\" and self.percepts.get(\"room_A_clean\") and \"room_A\" in self.cleaned_rooms and self.percepts.get(\"room_B_dirty\"):\n",
        "            print(f\"[{self.name}] Deciding: Room A is clean, move to Room B.\")\n",
        "            return \"move_to_room_B\"\n",
        "        elif self.location == \"room_B\" and not self.percepts.get(\"room_B_clean\"):\n",
        "            print(f\"[{self.name}] Deciding: Room B is dirty, vacuum.\")\n",
        "            return \"vacuum_floor\"\n",
        "        else:\n",
        "            print(f\"[{self.name}] Deciding: Nothing to do or goal reached.\")\n",
        "            return None\n",
        "\n",
        "    def act(self, action_name):\n",
        "        \"\"\"\n",
        "        Executes the chosen action.\n",
        "        \"\"\"\n",
        "        if action_name and action_name in self.actions:\n",
        "            print(f\"[{self.name}] Acting: Performing '{action_name}'...\")\n",
        "            self.actions[action_name]()\n",
        "            time.sleep(0.5) # Simulate action time\n",
        "        elif action_name:\n",
        "            print(f\"[{self.name}] Error: Unknown action '{action_name}'\")\n",
        "\n",
        "    # Private action methods\n",
        "    def _move_to_room_B(self):\n",
        "        self.location = \"room_B\"\n",
        "        print(f\"[{self.name}] Moved to Room B.\")\n",
        "\n",
        "    def _vacuum_floor(self):\n",
        "        print(f\"[{self.name}] Vacuuming floor at {self.location}...\")\n",
        "        # In a real system, this would interact with the environment to change its state.\n",
        "        # For this demo, we'll simulate the environment state change.\n",
        "\n",
        "    def _report_status(self):\n",
        "        print(f\"[{self.name}] Reporting: {self.location} is now clean.\")\n",
        "\n",
        "\n",
        "# Simulate an environment\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.state = {\n",
        "            \"room_A_clean\": False,\n",
        "            \"room_B_clean\": True, # Initially room B is clean\n",
        "            \"room_B_dirty\": False\n",
        "        }\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state\n",
        "\n",
        "    def update_state(self, action_performed, agent_location):\n",
        "        if action_performed == \"vacuum_floor\" and agent_location == \"room_A\":\n",
        "            self.state[\"room_A_clean\"] = True\n",
        "            print(\"[Environment] Room A is now clean.\")\n",
        "        if action_performed == \"vacuum_floor\" and agent_location == \"room_B\":\n",
        "            self.state[\"room_B_clean\"] = True\n",
        "            self.state[\"room_B_dirty\"] = False\n",
        "            print(\"[Environment] Room B is now clean.\")\n",
        "\n",
        "# Simulation loop\n",
        "agent = SimpleCleaningAgent()\n",
        "env = Environment()\n",
        "\n",
        "print(\"\\nStarting AI Agent Simulation...\")\n",
        "for i in range(5): # Run for a few steps\n",
        "    print(f\"\\n--- Simulation Step {i+1} ---\")\n",
        "    current_env_state = env.get_state()\n",
        "    agent.perceive(current_env_state)\n",
        "    chosen_action = agent.decide()\n",
        "    if chosen_action:\n",
        "        agent.act(chosen_action)\n",
        "        env.update_state(chosen_action, agent.location)\n",
        "    else:\n",
        "        print(f\"[{agent.name}] No action decided. Agent is idle.\")\n",
        "        break\n",
        "print(\"\\nAI Agent Simulation Ended.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbQ-jVAXW9se",
        "outputId": "28536e14-6919-4387-abf6-d043c681d3d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 14. AI Agents: Autonomous Systems ---\n",
            "\n",
            "Starting AI Agent Simulation...\n",
            "\n",
            "--- Simulation Step 1 ---\n",
            "[Roomba] Perceiving: {'room_A_clean': False, 'room_B_clean': True, 'room_B_dirty': False}\n",
            "[Roomba] Deciding: Room A is dirty, vacuum.\n",
            "[Roomba] Acting: Performing 'vacuum_floor'...\n",
            "[Roomba] Vacuuming floor at room_A...\n",
            "[Environment] Room A is now clean.\n",
            "\n",
            "--- Simulation Step 2 ---\n",
            "[Roomba] Perceiving: {'room_A_clean': True, 'room_B_clean': True, 'room_B_dirty': False}\n",
            "[Roomba] Deciding: Room A is clean, report.\n",
            "[Roomba] Acting: Performing 'report_status'...\n",
            "[Roomba] Reporting: room_A is now clean.\n",
            "\n",
            "--- Simulation Step 3 ---\n",
            "[Roomba] Perceiving: {'room_A_clean': True, 'room_B_clean': True, 'room_B_dirty': False}\n",
            "[Roomba] Deciding: Nothing to do or goal reached.\n",
            "[Roomba] No action decided. Agent is idle.\n",
            "\n",
            "AI Agent Simulation Ended.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Fine-Tuning Models: Customizes pre-trained models for domain-specific tasks.\n",
        "\n",
        "# This is a conceptual example of fine-tuning a pre-trained model.\n",
        "# In practice, fine-tuning involves loading a model trained on a large dataset\n",
        "# (e.g., ImageNet for computer vision, a large text corpus for NLP)\n",
        "# and then training it further on a smaller, specific dataset for a new task.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 15. Fine-Tuning Models: Customizing Pre-trained Models ---\")\n",
        "\n",
        "# --- Step 1: Simulate a \"Pre-trained Model\" ---\n",
        "# This would typically be a large model like VGG, ResNet, BERT, GPT.\n",
        "# Here, we'll create a simple dummy \"base model\".\n",
        "def create_base_model(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "        keras.layers.Dense(128, activation='relu', name='base_dense_1'),\n",
        "        keras.layers.Dense(64, activation='relu', name='base_dense_2'),\n",
        "        # This layer might be considered the \"feature extractor\" output\n",
        "        keras.layers.Dense(32, activation='relu', name='feature_extractor_output')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "base_model = create_base_model((10,)) # Dummy input features of 10\n",
        "base_model.summary(line_length=80)\n",
        "print(\"\\n(Imagine this is a large model pre-trained on a vast general dataset)\\n\")\n",
        "\n",
        "# --- Step 2: Prepare a new, smaller, domain-specific dataset ---\n",
        "# Let's say we have a small dataset for a specific binary classification task.\n",
        "np.random.seed(42)\n",
        "X_new_domain = np.random.rand(50, 10) # 50 samples, 10 features\n",
        "y_new_domain = (np.sum(X_new_domain[:, :5], axis=1) > 2.5).astype(int) # A specific rule\n",
        "\n",
        "# Split new domain data\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(\n",
        "    X_new_domain, y_new_domain, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"New domain dataset: {len(X_new_domain)} samples.\")\n",
        "print(f\"New domain training samples: {len(X_train_new)}\")\n",
        "print(f\"New domain test samples: {len(X_test_new)}\\n\")\n",
        "\n",
        "# --- Step 3: Fine-tuning process ---\n",
        "# 3a. Freeze the base model's layers (optional but common for initial fine-tuning)\n",
        "# This prevents the pre-trained weights from changing during early training on new data.\n",
        "base_model.trainable = False\n",
        "print(\"Base model layers frozen (trainable=False).\")\n",
        "\n",
        "# 3b. Add new classification layers on top of the base model\n",
        "inputs = keras.Input(shape=(10,))\n",
        "x = base_model(inputs, training=False) # Pass inputs through the frozen base model\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid', name='classifier_output')(x)\n",
        "fine_tuned_model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the new model\n",
        "fine_tuned_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nFine-tuned model architecture (new layers added on top of frozen base):\")\n",
        "fine_tuned_model.summary(line_length=80)\n",
        "\n",
        "# 3c. Train only the new layers on the domain-specific data\n",
        "print(\"\\nTraining (fine-tuning) new layers on domain-specific data for 10 epochs...\")\n",
        "fine_tuned_model.fit(X_train_new, y_train_new, epochs=10, verbose=0)\n",
        "\n",
        "# 3d. Unfreeze some or all base model layers (optional) and continue training with a lower learning rate\n",
        "# This allows the pre-trained weights to adapt slightly to the new task.\n",
        "# fine_tuned_model.trainable = True # Uncomment to unfreeze the base model\n",
        "# fine_tuned_model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# fine_tuned_model.fit(X_train_new, y_train_new, epochs=5, verbose=0) # Train for a few more epochs\n",
        "\n",
        "loss, accuracy = fine_tuned_model.evaluate(X_test_new, y_test_new, verbose=0)\n",
        "print(f\"\\nFine-tuning complete.\")\n",
        "print(f\"Test Accuracy on new domain data: {accuracy:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "7mb39pMuXNPh",
        "outputId": "8eb7c670-91e9-4edf-c865-864967a2fee2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 15. Fine-Tuning Models: Customizing Pre-trained Models ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ base_dense_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m1,408\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ base_dense_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ feature_extractor_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ base_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ base_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ feature_extractor_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,744\u001b[0m (45.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,744</span> (45.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,744\u001b[0m (45.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,744</span> (45.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(Imagine this is a large model pre-trained on a vast general dataset)\n",
            "\n",
            "New domain dataset: 50 samples.\n",
            "New domain training samples: 35\n",
            "New domain test samples: 15\n",
            "\n",
            "Base model layers frozen (trainable=False).\n",
            "\n",
            "Fine-tuned model architecture (new layers added on top of frozen base):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ sequential_12 (\u001b[38;5;33mSequential\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │        \u001b[38;5;34m11,744\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ classifier_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m33\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ sequential_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,744</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ classifier_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,777\u001b[0m (46.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,777</span> (46.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,744\u001b[0m (45.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,744</span> (45.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training (fine-tuning) new layers on domain-specific data for 10 epochs...\n",
            "\n",
            "Fine-tuning complete.\n",
            "Test Accuracy on new domain data: 0.4667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Multimodal Models: Processes and generates across multiple data types like images, videos, and text.\n",
        "\n",
        "# This is a conceptual Python example demonstrating how different modalities\n",
        "# (text and \"image features\") might be processed and then combined for a task.\n",
        "# A true multimodal model would involve sophisticated neural networks for each modality\n",
        "# and complex fusion mechanisms (e.g., cross-attention, shared embeddings).\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 16. Multimodal Models: Processing Multiple Data Types ---\")\n",
        "\n",
        "# Simulate input data from different modalities\n",
        "text_input = \"a black cat sitting on a white couch\"\n",
        "# Imagine this is a simplified vector representation from an image encoder\n",
        "image_features_input = np.array([0.8, 0.1, 0.9, 0.2, 0.7]) # e.g., features for \"cat\", \"couch\", \"black\", \"white\"\n",
        "\n",
        "print(f\"Input Text: '{text_input}'\")\n",
        "print(f\"Input Image Features (conceptual): {image_features_input}\\n\")\n",
        "\n",
        "# Step 1: Modality-specific processing (conceptual)\n",
        "# In a real model, this would be a sophisticated text encoder (BERT, GPT)\n",
        "# and an image encoder (ResNet, Vision Transformer).\n",
        "def process_text_modality(text):\n",
        "    # Simulate text embedding (e.g., one-hot, word2vec, BERT embedding)\n",
        "    # Just a dummy hash-based embedding for illustration\n",
        "    text_embedding = np.array([len(text), sum(ord(c) for c in text) % 100, len(text.split())])\n",
        "    print(f\"Processed Text Embedding: {text_embedding}\")\n",
        "    return text_embedding\n",
        "\n",
        "def process_image_modality(image_features):\n",
        "    # Simulate further processing or just pass through\n",
        "    print(f\"Processed Image Features: {image_features}\")\n",
        "    return image_features\n",
        "\n",
        "text_processed = process_text_modality(text_input)\n",
        "image_processed = process_image_modality(image_features_input)\n",
        "\n",
        "# Step 2: Fusion (combining the processed modalities)\n",
        "# Common fusion techniques include concatenation, element-wise sum/product, or attention.\n",
        "def fuse_modalities_simple_concat(text_emb, image_feats):\n",
        "    # Concatenate the embeddings/features\n",
        "    fused_representation = np.concatenate((text_emb, image_feats))\n",
        "    print(f\"Fused Representation (Concatenated): {fused_representation}\")\n",
        "    return fused_representation\n",
        "\n",
        "fused_data = fuse_modalities_simple_concat(text_processed, image_processed)\n",
        "\n",
        "# Step 3: Downstream task (e.g., classification, generation)\n",
        "# The fused representation is then fed into a final classifier or decoder.\n",
        "def multimodal_task_predictor(fused_rep):\n",
        "    # Simulate a simple prediction based on the fused data\n",
        "    # E.g., predict if the image contains an animal and an object.\n",
        "    animal_score = fused_rep[0] + fused_rep[3] # Dummy calculation\n",
        "    object_score = fused_rep[2] + fused_rep[4] # Dummy calculation\n",
        "    print(f\"\\nMultimodal Task Prediction (Conceptual):\")\n",
        "    print(f\"  Likelihood of 'animal': {animal_score:.2f}\")\n",
        "    print(f\"  Likelihood of 'object': {object_score:.2f}\")\n",
        "\n",
        "multimodal_task_predictor(fused_data)\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAsR-P2GXcc7",
        "outputId": "5598383b-4a3e-4dea-bc38-2cd0b36f9ddd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 16. Multimodal Models: Processing Multiple Data Types ---\n",
            "Input Text: 'a black cat sitting on a white couch'\n",
            "Input Image Features (conceptual): [0.8 0.1 0.9 0.2 0.7]\n",
            "\n",
            "Processed Text Embedding: [36  5  8]\n",
            "Processed Image Features: [0.8 0.1 0.9 0.2 0.7]\n",
            "Fused Representation (Concatenated): [36.   5.   8.   0.8  0.1  0.9  0.2  0.7]\n",
            "\n",
            "Multimodal Task Prediction (Conceptual):\n",
            "  Likelihood of 'animal': 36.80\n",
            "  Likelihood of 'object': 8.10\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# 17. Embeddings: Transforms input into machine-readable vector formats.\n",
        "\n",
        "# This example demonstrates word embeddings (specifically, using a pre-trained Word2Vec model conceptually).\n",
        "# Embeddings capture semantic relationships between words.\n",
        "\n",
        "import numpy as np\n",
        "# from gensim.models import Word2Vec # Would typically use a library like gensim or spaCy\n",
        "\n",
        "print(\"--- 17. Embeddings: Transforming Input into Vectors ---\")\n",
        "\n",
        "# Conceptual pre-trained word embeddings (dummy values for illustration)\n",
        "# In reality, these are learned from massive text corpora.\n",
        "word_to_vec_map = {\n",
        "    \"king\": np.array([0.1, 0.2, 0.3, 0.4]),\n",
        "    \"queen\": np.array([0.15, 0.25, 0.35, 0.45]),\n",
        "    \"man\": np.array([0.5, 0.6, 0.7, 0.8]),\n",
        "    \"woman\": np.array([0.55, 0.65, 0.75, 0.85]),\n",
        "    \"apple\": np.array([0.9, 0.8, 0.7, 0.6]),\n",
        "    \"orange\": np.array([0.85, 0.75, 0.65, 0.55]),\n",
        "    \"fruit\": np.array([0.88, 0.78, 0.68, 0.58])\n",
        "}\n",
        "\n",
        "def get_word_embedding(word):\n",
        "    \"\"\"Retrieves the embedding vector for a given word.\"\"\"\n",
        "    return word_to_vec_map.get(word.lower(), np.zeros(4)) # Return zeros if word not found\n",
        "\n",
        "# Example 1: Get embedding for a word\n",
        "word1 = \"king\"\n",
        "embedding1 = get_word_embedding(word1)\n",
        "print(f\"Embedding for '{word1}': {embedding1}\")\n",
        "\n",
        "word2 = \"apple\"\n",
        "embedding2 = get_word_embedding(word2)\n",
        "print(f\"Embedding for '{word2}': {embedding2}\")\n",
        "\n",
        "# Example 2: Demonstrate semantic similarity (conceptual)\n",
        "# Words with similar meanings have similar embeddings (closer in vector space).\n",
        "# We can use cosine similarity to measure this.\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
        "        return 0\n",
        "    return dot_product / (norm_vec1 * norm_vec2)\n",
        "\n",
        "embedding_king = get_word_embedding(\"king\")\n",
        "embedding_queen = get_word_embedding(\"queen\")\n",
        "embedding_man = get_word_embedding(\"man\")\n",
        "# --- FIX START ---\n",
        "embedding_apple = get_word_embedding(\"apple\") # Get the embedding for \"apple\"\n",
        "# --- FIX END ---\n",
        "embedding_fruit = get_word_embedding(\"fruit\")\n",
        "\n",
        "sim_king_queen = cosine_similarity(embedding_king, embedding_queen)\n",
        "sim_king_man = cosine_similarity(embedding_king, embedding_man)\n",
        "sim_apple_fruit = cosine_similarity(embedding_apple, embedding_fruit) # Now embedding_apple is defined\n",
        "\n",
        "print(f\"\\nCosine Similarity between '{word1}' and 'queen': {sim_king_queen:.3f}\")\n",
        "print(f\"Cosine Similarity between '{word1}' and 'man': {sim_king_man:.3f}\")\n",
        "print(f\"Cosine Similarity between '{word2}' and 'fruit': {sim_apple_fruit:.3f}\\n\")\n",
        "\n",
        "# Notice how 'king' and 'queen' have higher similarity than 'king' and 'man',\n",
        "# and 'apple' and 'fruit' also have high similarity, demonstrating semantic relationships."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpO6Mt8zX4S9",
        "outputId": "5269060a-64e8-4ea4-9bfb-f20074363134"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 17. Embeddings: Transforming Input into Vectors ---\n",
            "Embedding for 'king': [0.1 0.2 0.3 0.4]\n",
            "Embedding for 'apple': [0.9 0.8 0.7 0.6]\n",
            "\n",
            "Cosine Similarity between 'king' and 'queen': 0.998\n",
            "Cosine Similarity between 'king' and 'man': 0.969\n",
            "Cosine Similarity between 'apple' and 'fruit': 1.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Vector Search: Finds similar items using dense vector embeddings.\n",
        "\n",
        "# This example demonstrates a basic vector search using cosine similarity\n",
        "# to find the most similar items (documents, images, etc.) to a query vector.\n",
        "# In production, this is often done with specialized vector databases (e.g., Pinecone, Faiss, Weaviate).\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 18. Vector Search: Finding Similar Items ---\")\n",
        "\n",
        "# Database of items, each represented by a vector embedding\n",
        "# Item IDs are just indices for simplicity\n",
        "item_embeddings = {\n",
        "    \"doc1\": np.array([0.1, 0.2, 0.3, 0.4]),\n",
        "    \"doc2\": np.array([0.15, 0.25, 0.35, 0.45]), # Similar to doc1\n",
        "    \"doc3\": np.array([0.8, 0.9, 0.7, 0.6]),\n",
        "    \"doc4\": np.array([0.75, 0.85, 0.65, 0.55]), # Similar to doc3\n",
        "    \"doc5\": np.array([0.4, 0.3, 0.2, 0.1])      # Different from others\n",
        "}\n",
        "\n",
        "print(\"Available Item Embeddings (conceptual):\")\n",
        "for item, emb in item_embeddings.items():\n",
        "    print(f\"  {item}: {emb}\")\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
        "        return 0\n",
        "    return dot_product / (norm_vec1 * norm_vec2)\n",
        "\n",
        "def vector_search(query_vector, item_embeddings, top_k=3):\n",
        "    \"\"\"\n",
        "    Performs a simple vector search to find top_k most similar items.\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "    for item_id, item_vec in item_embeddings.items():\n",
        "        sim = cosine_similarity(query_vector, item_vec)\n",
        "        similarities.append((item_id, sim))\n",
        "\n",
        "    # Sort by similarity in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_k]\n",
        "\n",
        "# Example Query: A query vector for something similar to doc1/doc2\n",
        "query_vector = np.array([0.12, 0.22, 0.32, 0.42])\n",
        "\n",
        "print(f\"\\nQuery Vector: {query_vector}\")\n",
        "\n",
        "# Perform vector search\n",
        "results = vector_search(query_vector, item_embeddings, top_k=2)\n",
        "\n",
        "print(f\"\\nTop 2 similar items to the query:\")\n",
        "for item_id, sim in results:\n",
        "    print(f\"  Item: {item_id}, Similarity: {sim:.3f}\")\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAoA7FyxX9C0",
        "outputId": "d1160017-d684-48f8-a21c-1ee2d2cdcb6a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 18. Vector Search: Finding Similar Items ---\n",
            "Available Item Embeddings (conceptual):\n",
            "  doc1: [0.1 0.2 0.3 0.4]\n",
            "  doc2: [0.15 0.25 0.35 0.45]\n",
            "  doc3: [0.8 0.9 0.7 0.6]\n",
            "  doc4: [0.75 0.85 0.65 0.55]\n",
            "  doc5: [0.4 0.3 0.2 0.1]\n",
            "\n",
            "Query Vector: [0.12 0.22 0.32 0.42]\n",
            "\n",
            "Top 2 similar items to the query:\n",
            "  Item: doc1, Similarity: 1.000\n",
            "  Item: doc2, Similarity: 0.999\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Model Evaluation: Assessing predictive performance using validation techniques.\n",
        "\n",
        "# This example demonstrates basic model evaluation metrics for a binary classification problem:\n",
        "# Accuracy, Precision, Recall, and F1-score.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- 19. Model Evaluation: Assessing Predictive Performance ---\")\n",
        "\n",
        "# Simulate true labels and predicted labels from a binary classification model\n",
        "# True labels (what actually happened)\n",
        "y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
        "# Predicted labels (what the model predicted)\n",
        "y_pred = np.array([1, 1, 1, 0, 0, 1, 0, 1, 1, 0])\n",
        "\n",
        "print(f\"True Labels (y_true): {y_true}\")\n",
        "print(f\"Predicted Labels (y_pred): {y_pred}\\n\")\n",
        "\n",
        "# Calculate common evaluation metrics:\n",
        "\n",
        "# Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
        "# The proportion of correctly classified instances.\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Precision: TP / (TP + FP)\n",
        "# Of all instances predicted as positive, how many were actually positive.\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(f\"Precision (for positive class 1): {precision:.3f}\")\n",
        "\n",
        "# Recall (Sensitivity): TP / (TP + FN)\n",
        "# Of all actual positive instances, how many were correctly identified.\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f\"Recall (for positive class 1): {recall:.3f}\")\n",
        "\n",
        "# F1-Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
        "# The harmonic mean of precision and recall, balancing both.\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"F1-Score (for positive class 1): {f1:.3f}\\n\")\n",
        "\n",
        "# For multi-class classification, you might use 'macro', 'micro', or 'weighted' averages.\n",
        "# Other metrics include ROC AUC, Confusion Matrix, MSE (for regression), etc.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4yvzTMJYFWn",
        "outputId": "0fc2dd01-264a-4570-fc5c-e954e93d5764"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 19. Model Evaluation: Assessing Predictive Performance ---\n",
            "True Labels (y_true): [1 0 1 1 0 1 0 0 1 0]\n",
            "Predicted Labels (y_pred): [1 1 1 0 0 1 0 1 1 0]\n",
            "\n",
            "Accuracy: 0.700\n",
            "Precision (for positive class 1): 0.667\n",
            "Recall (for positive class 1): 0.800\n",
            "F1-Score (for positive class 1): 0.727\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. AI Infrastructure: Deploying scalable systems to support AI operations.\n",
        "\n",
        "# This is a conceptual Python script outlining typical steps in deploying an AI model.\n",
        "# In a real-world scenario, this would involve cloud services (AWS, GCP, Azure),\n",
        "# Docker/Kubernetes, CI/CD pipelines, MLOps tools (MLflow, Kubeflow),\n",
        "# monitoring systems, and API gateways.\n",
        "\n",
        "print(\"--- 20. AI Infrastructure: Deploying Scalable Systems ---\")\n",
        "\n",
        "# --- Step 1: Model Export/Serialization ---\n",
        "# After training, the model needs to be saved in a deployable format.\n",
        "def export_model(model_object, path=\"model.pkl\"):\n",
        "    print(f\"Exporting trained model to: {path} (e.g., using pickle, ONNX, TensorFlow SavedModel)\")\n",
        "    # Example: model_object.save(path) for TensorFlow/Keras\n",
        "    # Example: pickle.dump(model_object, open(path, 'wb')) for scikit-learn\n",
        "    print(\"Model exported successfully.\")\n",
        "\n",
        "# Simulate a trained model object\n",
        "class DummyTrainedModel:\n",
        "    def predict(self, data):\n",
        "        return [0.7, 0.3] # Dummy prediction\n",
        "\n",
        "trained_model = DummyTrainedModel()\n",
        "export_model(trained_model, \"my_classification_model.h5\") # Example path for Keras\n",
        "\n",
        "\n",
        "# --- Step 2: Containerization (e.g., Docker) ---\n",
        "# Packaging the model, its dependencies, and serving code into a portable unit.\n",
        "def create_dockerfile_concept():\n",
        "    print(\"\\nCreating conceptual Dockerfile:\")\n",
        "    dockerfile_content = \"\"\"\n",
        "    # Use a lightweight Python base image\n",
        "    FROM python:3.9-slim-buster\n",
        "\n",
        "    # Set working directory\n",
        "    WORKDIR /app\n",
        "\n",
        "    # Copy dependencies file\n",
        "    COPY requirements.txt .\n",
        "\n",
        "    # Install Python dependencies\n",
        "    RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "    # Copy the exported model and application code\n",
        "    COPY my_classification_model.h5 .\n",
        "    COPY app.py .\n",
        "\n",
        "    # Expose the port the application will run on\n",
        "    EXPOSE 8080\n",
        "\n",
        "    # Command to run the application\n",
        "    CMD [\"python\", \"app.py\"]\n",
        "    \"\"\"\n",
        "    # In reality, this would write to a Dockerfile\n",
        "    print(dockerfile_content)\n",
        "    print(\"Dockerfile concept generated.\")\n",
        "\n",
        "create_dockerfile_concept()\n",
        "\n",
        "# --- Step 3: Deployment (e.g., Kubernetes, serverless) ---\n",
        "# Orchestrating the containerized application for scalability and reliability.\n",
        "def deploy_to_cloud_concept(service_name=\"my-ai-service\"):\n",
        "    print(f\"\\nConceptual Deployment to Cloud (e.g., Kubernetes/GKE, Cloud Run, AWS SageMaker):\")\n",
        "    print(f\"  1. Build Docker image: `docker build -t {service_name}:latest .`\")\n",
        "    print(f\"  2. Push image to container registry: `docker push gcr.io/my-project/{service_name}:latest`\")\n",
        "    print(f\"  3. Deploy to orchestrator/serverless platform (e.g., Kubernetes deployment YAML):\")\n",
        "    deployment_yaml_concept = f\"\"\"\n",
        "    apiVersion: apps/v1\n",
        "    kind: Deployment\n",
        "    metadata:\n",
        "      name: {service_name}-deployment\n",
        "    spec:\n",
        "      replicas: 3 # Scale across 3 instances\n",
        "      selector:\n",
        "        matchLabels:\n",
        "          app: {service_name}\n",
        "      template:\n",
        "        metadata:\n",
        "          labels:\n",
        "            app: {service_name}\n",
        "        spec:\n",
        "          containers:\n",
        "          - name: {service_name}-container\n",
        "            image: gcr.io/my-project/{service_name}:latest\n",
        "            ports:\n",
        "            - containerPort: 8080\n",
        "    \"\"\"\n",
        "    print(deployment_yaml_concept)\n",
        "    print(f\"  {service_name} deployed (conceptually).\")\n",
        "\n",
        "deploy_to_cloud_concept()\n",
        "\n",
        "# --- Step 4: Monitoring and Logging ---\n",
        "# Essential for observing model performance, resource usage, and errors in production.\n",
        "def conceptual_monitoring():\n",
        "    print(\"\\nConceptual Monitoring and Logging:\")\n",
        "    print(\"  - Integrate with Prometheus/Grafana for metrics.\")\n",
        "    print(\"  - Use Cloud Logging/ELK stack for centralized logs.\")\n",
        "    print(\"  - Set up alerts for model drift, error rates, and latency spikes.\")\n",
        "\n",
        "conceptual_monitoring()\n",
        "\n",
        "print(\"\\nAI Infrastructure setup (conceptual) complete.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA7DkW9LYNEl",
        "outputId": "733d5163-c651-4514-ef80-40ba95cd5119"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 20. AI Infrastructure: Deploying Scalable Systems ---\n",
            "Exporting trained model to: my_classification_model.h5 (e.g., using pickle, ONNX, TensorFlow SavedModel)\n",
            "Model exported successfully.\n",
            "\n",
            "Creating conceptual Dockerfile:\n",
            "\n",
            "    # Use a lightweight Python base image\n",
            "    FROM python:3.9-slim-buster\n",
            "\n",
            "    # Set working directory\n",
            "    WORKDIR /app\n",
            "\n",
            "    # Copy dependencies file\n",
            "    COPY requirements.txt .\n",
            "\n",
            "    # Install Python dependencies\n",
            "    RUN pip install --no-cache-dir -r requirements.txt\n",
            "\n",
            "    # Copy the exported model and application code\n",
            "    COPY my_classification_model.h5 .\n",
            "    COPY app.py .\n",
            "\n",
            "    # Expose the port the application will run on\n",
            "    EXPOSE 8080\n",
            "\n",
            "    # Command to run the application\n",
            "    CMD [\"python\", \"app.py\"]\n",
            "    \n",
            "Dockerfile concept generated.\n",
            "\n",
            "Conceptual Deployment to Cloud (e.g., Kubernetes/GKE, Cloud Run, AWS SageMaker):\n",
            "  1. Build Docker image: `docker build -t my-ai-service:latest .`\n",
            "  2. Push image to container registry: `docker push gcr.io/my-project/my-ai-service:latest`\n",
            "  3. Deploy to orchestrator/serverless platform (e.g., Kubernetes deployment YAML):\n",
            "\n",
            "    apiVersion: apps/v1\n",
            "    kind: Deployment\n",
            "    metadata:\n",
            "      name: my-ai-service-deployment\n",
            "    spec:\n",
            "      replicas: 3 # Scale across 3 instances\n",
            "      selector:\n",
            "        matchLabels:\n",
            "          app: my-ai-service\n",
            "      template:\n",
            "        metadata:\n",
            "          labels:\n",
            "            app: my-ai-service\n",
            "        spec:\n",
            "          containers:\n",
            "          - name: my-ai-service-container\n",
            "            image: gcr.io/my-project/my-ai-service:latest\n",
            "            ports:\n",
            "            - containerPort: 8080\n",
            "    \n",
            "  my-ai-service deployed (conceptually).\n",
            "\n",
            "Conceptual Monitoring and Logging:\n",
            "  - Integrate with Prometheus/Grafana for metrics.\n",
            "  - Use Cloud Logging/ELK stack for centralized logs.\n",
            "  - Set up alerts for model drift, error rates, and latency spikes.\n",
            "\n",
            "AI Infrastructure setup (conceptual) complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"--- 21. Generative Adversarial Networks (GANs) ---\")\n",
        "\n",
        "# --- Step 1: Define the Generator ---\n",
        "# The generator takes random noise as input and tries to produce data similar to the training data.\n",
        "def build_generator(latent_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation=\"relu\", input_shape=(latent_dim,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(784, activation=\"sigmoid\") # e.g., for generating flattened 28x28 images\n",
        "    ], name=\"generator\")\n",
        "    return model\n",
        "\n",
        "# --- Step 2: Define the Discriminator ---\n",
        "# The discriminator takes data (real or fake) as input and tries to classify it as real or fake.\n",
        "def build_discriminator(img_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(256, activation=\"relu\", input_shape=img_shape),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation=\"sigmoid\") # Binary classification (real/fake)\n",
        "    ], name=\"discriminator\")\n",
        "    return model\n",
        "\n",
        "# --- Step 3: Compile the Discriminator ---\n",
        "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator = build_discriminator(img_shape=(784,))\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# --- Step 4: Define the GAN (Generator + Discriminator) ---\n",
        "# The GAN model trains the generator by keeping the discriminator's weights frozen.\n",
        "latent_dim = 100\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator.trainable = False # Discriminator is not trained during GAN compilation\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "fake_img = generator(gan_input)\n",
        "gan_output = discriminator(fake_img)\n",
        "gan = keras.Model(gan_input, gan_output, name=\"gan\")\n",
        "\n",
        "gan_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "gan.compile(optimizer=gan_optimizer, loss=\"binary_crossentropy\")\n",
        "\n",
        "print(\"\\nConceptual GAN Setup:\")\n",
        "generator.summary(line_length=80)\n",
        "discriminator.summary(line_length=80)\n",
        "gan.summary(line_length=80)\n",
        "\n",
        "print(\"\\n(In a real scenario, you would train these models iteratively. \"\n",
        "      \"Here, we just set up the architecture.)\")\n",
        "\n",
        "# Example: Generate a dummy image from noise\n",
        "dummy_noise = np.random.rand(1, latent_dim)\n",
        "generated_image = generator.predict(dummy_noise)\n",
        "print(f\"\\nExample generated data (first 10 pixels): {generated_image[0, :10].round(2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "mcX9h3_2aUsg",
        "outputId": "7bd32bd8-4d89-4c45-e905-71c07d644f6d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 21. Generative Adversarial Networks (GANs) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conceptual GAN Setup:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │        \u001b[38;5;34m12,928\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ batch_normalization               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                          │               │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                          │               │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)              │       \u001b[38;5;34m201,488\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ batch_normalization               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                          │               │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                          │               │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,488</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m248,976\u001b[0m (972.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,976</span> (972.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m248,208\u001b[0m (969.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,208</span> (969.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"discriminator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"discriminator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │           \u001b[38;5;34m129\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m233,985\u001b[0m (914.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,985</span> (914.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m233,985\u001b[0m (914.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,985</span> (914.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gan\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gan\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ generator (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)              │       \u001b[38;5;34m248,976\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ discriminator (\u001b[38;5;33mSequential\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │       \u001b[38;5;34m233,985\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ generator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">248,976</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ discriminator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">233,985</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m482,961\u001b[0m (1.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">482,961</span> (1.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m248,208\u001b[0m (969.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,208</span> (969.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m234,753\u001b[0m (917.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,753</span> (917.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(In a real scenario, you would train these models iteratively. Here, we just set up the architecture.)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\n",
            "Example generated data (first 10 pixels): [0.52 0.48 0.5  0.45 0.48 0.49 0.47 0.52 0.54 0.52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"--- 22. Graph Neural Networks (GNNs) ---\")\n",
        "\n",
        "# --- Step 1: Define a simple graph (adjacency matrix) ---\n",
        "# Represents connections between nodes (e.g., airports, waypoints)\n",
        "# A[i,j] = 1 if node i is connected to node j, 0 otherwise\n",
        "adjacency_matrix = np.array([\n",
        "    [0, 1, 1, 0], # Node 0 connected to Node 1, Node 2\n",
        "    [1, 0, 1, 1], # Node 1 connected to Node 0, Node 2, Node 3\n",
        "    [1, 1, 0, 0], # Node 2 connected to Node 0, Node 1\n",
        "    [0, 1, 0, 0]  # Node 3 connected to Node 1\n",
        "])\n",
        "print(\"Adjacency Matrix (Connections):\\n\", adjacency_matrix)\n",
        "\n",
        "# --- Step 2: Define Node Features ---\n",
        "# Represents properties of each node (e.g., airport capacity, weather at waypoint)\n",
        "# Here, 2 features per node for simplicity\n",
        "node_features = np.array([\n",
        "    [0.1, 0.2], # Node 0 features\n",
        "    [0.5, 0.3], # Node 1 features\n",
        "    [0.8, 0.6], # Node 2 features\n",
        "    [0.2, 0.9]  # Node 3 features\n",
        "])\n",
        "print(\"\\nInitial Node Features:\\n\", node_features)\n",
        "\n",
        "# --- Step 3: Conceptual Graph Convolution Operation ---\n",
        "# A very simplified idea of how information propagates.\n",
        "# In a real GNN, this involves learnable weight matrices and aggregation functions.\n",
        "# Here, we'll simply sum features of neighbors for each node.\n",
        "def simple_graph_convolution(features, adj_matrix):\n",
        "    # Multiply features by adjacency matrix to aggregate neighbor features\n",
        "    # (conceptually, not true matrix multiplication for aggregation here)\n",
        "    aggregated_features = np.dot(adj_matrix, features)\n",
        "    return aggregated_features\n",
        "\n",
        "# Apply a conceptual graph convolution\n",
        "updated_node_features = simple_graph_convolution(node_features, adjacency_matrix)\n",
        "\n",
        "print(\"\\nUpdated Node Features (after conceptual graph convolution):\\n\", np.round(updated_node_features, 2))\n",
        "print(\"(This demonstrates how information from neighbors could influence a node's representation.)\")\n",
        "\n",
        "# --- Conceptual Application for Flight Planning ---\n",
        "print(\"\\nConceptual GNN Application for Flight Planning:\")\n",
        "print(\"- Nodes could be airports, waypoints, or airspace sectors.\")\n",
        "print(\"- Edges could represent flight paths or permissible transitions.\")\n",
        "print(\"- Node features could be weather conditions, airport congestion, or fuel prices.\")\n",
        "print(\"- GNNs could learn optimal routes by considering the interconnectedness and features of the entire network.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjBX2q8Qadk7",
        "outputId": "6cb1e0c7-9184-4f59-8f5f-71016ca82faa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 22. Graph Neural Networks (GNNs) ---\n",
            "Adjacency Matrix (Connections):\n",
            " [[0 1 1 0]\n",
            " [1 0 1 1]\n",
            " [1 1 0 0]\n",
            " [0 1 0 0]]\n",
            "\n",
            "Initial Node Features:\n",
            " [[0.1 0.2]\n",
            " [0.5 0.3]\n",
            " [0.8 0.6]\n",
            " [0.2 0.9]]\n",
            "\n",
            "Updated Node Features (after conceptual graph convolution):\n",
            " [[1.3 0.9]\n",
            " [1.1 1.7]\n",
            " [0.6 0.5]\n",
            " [0.5 0.3]]\n",
            "(This demonstrates how information from neighbors could influence a node's representation.)\n",
            "\n",
            "Conceptual GNN Application for Flight Planning:\n",
            "- Nodes could be airports, waypoints, or airspace sectors.\n",
            "- Edges could represent flight paths or permissible transitions.\n",
            "- Node features could be weather conditions, airport congestion, or fuel prices.\n",
            "- GNNs could learn optimal routes by considering the interconnectedness and features of the entire network.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "print(\"--- 23. Causal Inference ---\")\n",
        "\n",
        "# --- Conceptual Scenario: Impact of two different flight paths on delay ---\n",
        "# Imagine two flight paths (Path A and Path B) used for similar routes.\n",
        "# We want to know if one *causes* more delays than the other.\n",
        "\n",
        "# Simulate data for two groups (e.g., flights that took Path A vs. Path B)\n",
        "np.random.seed(42)\n",
        "flights_path_A = np.random.normal(loc=10, scale=3, size=100)  # Delays in minutes for Path A\n",
        "flights_path_B = np.random.normal(loc=12, scale=3.5, size=100) # Delays in minutes for Path B\n",
        "\n",
        "# Introduce a \"causal\" factor for Path B (e.g., frequent unexpected ATC holds)\n",
        "# This isn't statistically rigorous causal inference, but conceptual\n",
        "flights_path_B += np.random.choice([0, 5, 10], size=100, p=[0.7, 0.2, 0.1]) # 30% of Path B flights get extra delay\n",
        "\n",
        "df_causal = pd.DataFrame({\n",
        "    'Flight_ID': range(200),\n",
        "    'Path_Taken': ['A'] * 100 + ['B'] * 100,\n",
        "    'Delay_Minutes': np.concatenate([flights_path_A, flights_path_B])\n",
        "})\n",
        "\n",
        "print(\"Conceptual Flight Data (first 5 rows):\\n\", df_causal.head())\n",
        "print(\"\\nMean delay for Path A:\", np.mean(df_causal[df_causal['Path_Taken'] == 'A']['Delay_Minutes']).round(2))\n",
        "print(\"Mean delay for Path B:\", np.mean(df_causal[df_causal['Path_Taken'] == 'B']['Delay_Minutes']).round(2))\n",
        "\n",
        "# --- Conceptual A/B Test (Randomized Controlled Trial analogy) ---\n",
        "# If we could randomly assign flights to Path A or Path B, then a difference in means\n",
        "# could imply causality. In real life, flights are not randomly assigned.\n",
        "stat, p_value = ttest_ind(df_causal[df_causal['Path_Taken'] == 'A']['Delay_Minutes'],\n",
        "                          df_causal[df_causal['Path_Taken'] == 'B']['Delay_Minutes'])\n",
        "\n",
        "print(f\"\\nConceptual T-test result: p-value = {p_value:.3f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\" (A statistically significant difference suggests Path B might be *causing* more delays.)\")\n",
        "else:\n",
        "    print(\" (No statistically significant difference observed.)\")\n",
        "\n",
        "print(\"\\n(True causal inference often requires more advanced techniques like \"\n",
        "      \"matching, instrumental variables, or deep learning-based causal models to \"\n",
        "      \"account for confounding factors in observational data.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPIo2jMCajK9",
        "outputId": "02e7221b-1c20-4fed-98c1-a373f1489431"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 23. Causal Inference ---\n",
            "Conceptual Flight Data (first 5 rows):\n",
            "    Flight_ID Path_Taken  Delay_Minutes\n",
            "0          0          A      11.490142\n",
            "1          1          A       9.585207\n",
            "2          2          A      11.943066\n",
            "3          3          A      14.569090\n",
            "4          4          A       9.297540\n",
            "\n",
            "Mean delay for Path A: 9.69\n",
            "Mean delay for Path B: 13.63\n",
            "\n",
            "Conceptual T-test result: p-value = 0.000\n",
            " (A statistically significant difference suggests Path B might be *causing* more delays.)\n",
            "\n",
            "(True causal inference often requires more advanced techniques like matching, instrumental variables, or deep learning-based causal models to account for confounding factors in observational data.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"--- 24. Explainable AI (XAI) ---\")\n",
        "\n",
        "# --- Conceptual Scenario: Explaining a flight delay prediction ---\n",
        "# Imagine a simple model that predicts flight delay based on a few factors.\n",
        "\n",
        "# Sample data: [Temperature_Deviation, Wind_Speed_Deviation, Airspace_Congestion_Index]\n",
        "X_features = np.array([\n",
        "    [2, 10, 0.8], # Flight 1: some temp, high wind, high congestion\n",
        "    [-1, 5, 0.2], # Flight 2: lower temp, low wind, low congestion\n",
        "    [5, 15, 0.9], # Flight 3: high temp, very high wind, very high congestion\n",
        "    [0, 2, 0.1]   # Flight 4: normal temp, low wind, very low congestion\n",
        "])\n",
        "# Target: 1 for delayed, 0 for on-time\n",
        "y_labels = np.array([1, 0, 1, 0])\n",
        "\n",
        "feature_names = [\"Temp_Deviation\", \"Wind_Speed_Deviation\", \"Airspace_Congestion\"]\n",
        "\n",
        "# Train a simple Logistic Regression model (an inherently more interpretable model)\n",
        "model_xai = LogisticRegression()\n",
        "model_xai.fit(X_features, y_labels)\n",
        "\n",
        "print(\"Simple Logistic Regression Model trained for delay prediction.\")\n",
        "print(\"Model Coefficients (Feature Importance):\\n\", model_xai.coef_[0].round(2))\n",
        "print(f\"  {feature_names[0]}: {model_xai.coef_[0][0]:.2f}\")\n",
        "print(f\"  {feature_names[1]}: {model_xai.coef_[0][1]:.2f}\")\n",
        "print(f\"  {feature_names[2]}: {model_xai.coef_[0][2]:.2f}\")\n",
        "\n",
        "# --- Conceptual Explanation for a specific prediction ---\n",
        "# For Logistic Regression, coefficients can be seen as a form of explanation.\n",
        "# Larger positive coefficients mean that feature contributes more to the positive class (delay).\n",
        "sample_flight_features = np.array([[3, 12, 0.7]]) # A new flight\n",
        "predicted_delay = model_xai.predict(sample_flight_features)[0]\n",
        "predicted_prob = model_xai.predict_proba(sample_flight_features)[0, 1]\n",
        "\n",
        "print(f\"\\nPredicting for a new flight with features: {sample_flight_features[0]}\")\n",
        "print(f\"Predicted Delay (1=Yes, 0=No): {predicted_delay}\")\n",
        "print(f\"Predicted Probability of Delay: {predicted_prob:.2f}\")\n",
        "\n",
        "print(\"\\nConceptual Explanation (based on feature importance for this simple model):\")\n",
        "print(f\"The model predicted a delay due to a combination of factors. \"\n",
        "      f\"Specifically, 'Wind_Speed_Deviation' (coefficient {model_xai.coef_[0][1]:.2f}) \"\n",
        "      f\"and 'Airspace_Congestion' (coefficient {model_xai.coef_[0][2]:.2f}) \"\n",
        "      f\"had the strongest positive influence on the prediction of delay.\")\n",
        "\n",
        "print(\"\\n(For complex models like Deep Neural Networks, XAI techniques like \"\n",
        "      \"LIME, SHAP, or attention mechanisms are used to provide more granular explanations.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pelQnV5Hao68",
        "outputId": "62a5ef7d-98b6-4c09-ef10-654b4e7a4092"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 24. Explainable AI (XAI) ---\n",
            "Simple Logistic Regression Model trained for delay prediction.\n",
            "Model Coefficients (Feature Importance):\n",
            " [0.33 0.65 0.07]\n",
            "  Temp_Deviation: 0.33\n",
            "  Wind_Speed_Deviation: 0.65\n",
            "  Airspace_Congestion: 0.07\n",
            "\n",
            "Predicting for a new flight with features: [ 3.  12.   0.7]\n",
            "Predicted Delay (1=Yes, 0=No): 1\n",
            "Predicted Probability of Delay: 0.98\n",
            "\n",
            "Conceptual Explanation (based on feature importance for this simple model):\n",
            "The model predicted a delay due to a combination of factors. Specifically, 'Wind_Speed_Deviation' (coefficient 0.65) and 'Airspace_Congestion' (coefficient 0.07) had the strongest positive influence on the prediction of delay.\n",
            "\n",
            "(For complex models like Deep Neural Networks, XAI techniques like LIME, SHAP, or attention mechanisms are used to provide more granular explanations.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"--- 25. Federated Learning (Conceptual) ---\")\n",
        "\n",
        "# --- Conceptual Scenario: Multiple airlines contributing to a global flight delay model ---\n",
        "# Each \"client\" (airline) has its own local dataset and trains a local model.\n",
        "# A central server aggregates these local models to create a better global model.\n",
        "\n",
        "# Step 1: Simulate initial global model weights (simplified as a single number)\n",
        "global_model_weight = 0.5\n",
        "print(f\"Initial Global Model Weight: {global_model_weight:.2f}\")\n",
        "\n",
        "# Step 2: Simulate local data and local model training for multiple clients\n",
        "num_clients = 3\n",
        "client_local_data_impacts = [0.1, 0.8, -0.2] # Simulate how each client's data would 'shift' the weight\n",
        "\n",
        "print(\"\\n--- Federated Learning Rounds ---\")\n",
        "num_rounds = 3\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "    local_model_updates = []\n",
        "    for i in range(num_clients):\n",
        "        # Simulate local training: client updates model based on its data\n",
        "        # For simplicity, let's say client adjusts the global weight based on its 'impact'\n",
        "        local_model_weight = global_model_weight + client_local_data_impacts[i] * 0.1 * np.random.rand()\n",
        "        local_model_updates.append(local_model_weight)\n",
        "        print(f\"  Client {i+1} trains locally, resulting in local weight: {local_model_weight:.2f}\")\n",
        "\n",
        "    # Step 3: Central Server Aggregation (e.g., averaging local model updates)\n",
        "    new_global_model_weight = np.mean(local_model_updates)\n",
        "    print(f\"Central server aggregates local weights. New Global Model Weight: {new_global_model_weight:.2f}\")\n",
        "    global_model_weight = new_global_model_weight\n",
        "\n",
        "print(\"\\n--- Federated Learning Complete ---\")\n",
        "print(f\"Final Global Model Weight: {global_model_weight:.2f}\")\n",
        "\n",
        "print(\"\\n(This is a highly simplified illustration. Real federated learning involves \"\n",
        "      \"complex aggregation algorithms, secure multi-party computation, and communication protocols.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3hJT52ZawWw",
        "outputId": "c5c14b00-6441-4c26-9819-93b250bd16fe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 25. Federated Learning (Conceptual) ---\n",
            "Initial Global Model Weight: 0.50\n",
            "\n",
            "--- Federated Learning Rounds ---\n",
            "\n",
            "Round 1:\n",
            "  Client 1 trains locally, resulting in local weight: 0.51\n",
            "  Client 2 trains locally, resulting in local weight: 0.53\n",
            "  Client 3 trains locally, resulting in local weight: 0.48\n",
            "Central server aggregates local weights. New Global Model Weight: 0.51\n",
            "\n",
            "Round 2:\n",
            "  Client 1 trains locally, resulting in local weight: 0.52\n",
            "  Client 2 trains locally, resulting in local weight: 0.52\n",
            "  Client 3 trains locally, resulting in local weight: 0.51\n",
            "Central server aggregates local weights. New Global Model Weight: 0.51\n",
            "\n",
            "Round 3:\n",
            "  Client 1 trains locally, resulting in local weight: 0.52\n",
            "  Client 2 trains locally, resulting in local weight: 0.52\n",
            "  Client 3 trains locally, resulting in local weight: 0.51\n",
            "Central server aggregates local weights. New Global Model Weight: 0.51\n",
            "\n",
            "--- Federated Learning Complete ---\n",
            "Final Global Model Weight: 0.51\n",
            "\n",
            "(This is a highly simplified illustration. Real federated learning involves complex aggregation algorithms, secure multi-party computation, and communication protocols.)\n"
          ]
        }
      ]
    }
  ]
}