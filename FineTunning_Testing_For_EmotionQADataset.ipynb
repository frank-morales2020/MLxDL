{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTunning_Testing_For_EmotionQADataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMednPdqqiA8"
      },
      "source": [
        "Fine-tunning: https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_Mistral_7b_hfdeployment_dataset_Medmcqa.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install -U tensorboard-plugin-profile -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wddUCBg2et91",
        "outputId": "80a993aa-afc9-489c-be61-e15f1fd10b67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XIfyaExe3GJ",
        "outputId": "c39bce4b-9468-44b8-9358-9d2fc2902d77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir /content/gdrive/MyDrive/model/Mistral-7B-v0.1_Emotion/runs"
      ],
      "metadata": {
        "id": "8cJHKvDsdzEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaKHHOC5fnuv"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "#!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "#!pip install colab-env --quiet\n",
        "\n",
        "\n",
        "!pip install huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_B8ihZJEoEyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbec225-b80a-44a3-d3bb-ceb61346dc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n2Pv_flo8OO"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "\n",
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "peft_model_id = \"frankmorales2020/Mistral-7B-v0.1_Emotion\"\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id, use_fast=True)\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# load into pipeline\n",
        "pipe = pipeline(\"document-question-answering\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "#take a vacation\n",
        "prompt = 'I am going to take a vacation next month.'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "E49ltfAcoiQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9c858e-976a-4493-9e0a-da0afbdfeb27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_szlyqaTFbJB",
        "outputId": "25337a5a-62c8-4302-a7c3-e24beebdebd6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I am going to take a vacation next month. i am feeling very listless right now [/INST] 0 '}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WNFgTleXpW-y",
        "outputId": "f9345e7c-1501-4ade-d469-b49c6edce7d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am feeling very listless right now [/INST] 0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_classificator(ganswer):\n",
        "          if int(ganswer) == 0:\n",
        "            class_label='Sentiment-Label is: Sadness(0)'\n",
        "            print ()\n",
        "          if int(ganswer)  == 1:\n",
        "            class_label='Sentiment-Label is: Joy(1)'\n",
        "            print ()\n",
        "          if int(ganswer) == 2:\n",
        "            class_label='Sentiment-Label is: Love(2)'\n",
        "            print ()\n",
        "          if int(ganswer) == 3:\n",
        "            class_label='Sentiment-Label is: Anger(3)'\n",
        "            print ()\n",
        "          if int(ganswer) == 4:\n",
        "            class_label='Sentiment-Label is: Fear(4)'\n",
        "            print ()\n",
        "          if int(ganswer) == 5:\n",
        "            class_label='Sentiment-Label is: Surprise(5)'\n",
        "            print ()\n",
        "          return class_label"
      ],
      "metadata": {
        "id": "Lkk86bLgrTOk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I am going to take a vacation next month. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "rADBMe-lgfWp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ffmy2TTCg0d-",
        "outputId": "4af65b91-7cb5-4cda-f99a-ef19c24c6e92"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn4dgh5_hK3k",
        "outputId": "c6fea7bd-f37c-4982-b61c-c47ea5446243"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Joy(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I am scared. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "LBgcaRMap0om"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kgjtoBgJqWia",
        "outputId": "23ae41d3-493d-4517-d789-2b9af0366696"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "id": "qJ48TZm8p8p_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b8cfae-071a-4dd3-82ed-1ef074be57a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Fear(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I grab a minute to post, but I feel greedy and wrong. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "print(f'{prompt}')\n",
        "print(f'{ganswer}')\n",
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "id": "f3x4HHhJXIQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b610bdc4-098a-4df7-9b48-cbac4b9f9804"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] I grab a minute to post, but I feel greedy and wrong. [/INST]\n",
            "3\n",
            "\n",
            "Sentiment-Label is: Anger(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'I grab a minute to post, but I feel greedy and wrong.'\n",
        "\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "#print(f'{prompt}')\n",
        "print(f'{ganswer}')\n",
        "\n",
        "#sentiment=label_classificator(ganswer)\n",
        "#print(f'{sentiment}')"
      ],
      "metadata": {
        "id": "ZrdXBbrLjbJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db5c593-03fc-4b4a-9d47-314da5b8a615"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don t even feel that creative [/INST] 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB8DWMO_iEsB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "print(\"Preprocessing dataset Emotion\")\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "\n",
        "# save datasets to disk\n",
        "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
        "dataset[\"validation\"].to_json(\"validation_dataset.json\", orient=\"records\")\n",
        "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hb-chphAuYKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5ccbfc50848046399aff4b93720746fc",
            "1ab4b915c3b8442fa88b76a2f67af9cb",
            "18d9d8364f274d239a1e70aad51c3ad3",
            "74382245357d4510b639d39b08969ccb",
            "9aae504913944b6289778882b541ac87",
            "f397f7e260434e4e85c7292d8c288ccb",
            "2f640c73f3104358ab5a68ff7effdcd4",
            "6eec7996753c4da880feba43c6cdd8f1",
            "badd9c6b14e14476a59a21c7a430dbf7",
            "0ff81071c61743ba9452b44ccd80676d",
            "9799eddd621b4858bc4b6bc56bb4b761"
          ]
        },
        "outputId": "7879ed13-a04a-431b-ffa8-b25f25dcf78a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ccbfc50848046399aff4b93720746fc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "H7v2nuP4uk2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d186729-075d-4055-9f50-190362681989"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eIGQH5sQt9Ob"
      },
      "outputs": [],
      "source": [
        "nrec=10\n",
        "dataset_final_Question=dataset['text'][0:nrec]\n",
        "dataset_final_Answer=dataset['label'][0:nrec]\n",
        "#dataset_final_Messages=dataset['messages'][0:nrec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "G1XAJCQAuFUj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k0FmtsznxfQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7e903d-994e-47b1-edd7-6b9439c0d842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i felt anger when at the end of a telephone call', 'label': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vGdcOx1KuJqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "42d80279-be4e-4713-b75a-51b3ecc4701b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question  Answer\n",
              "0  im feeling rather rotten so im not very ambiti...       0\n",
              "1          im updating my blog because i feel shitty       0\n",
              "2  i never make her separate from me because i do...       0\n",
              "3  i left with my bouquet of red and yellow tulip...       1\n",
              "4    i was feeling a little vain when i did this one       0\n",
              "5  i cant walk into a shop anywhere where i do no...       4\n",
              "6   i felt anger when at the end of a telephone call       3\n",
              "7  i explain why i clung to a relationship with a...       1\n",
              "8  i like to have the same breathless feeling as ...       1\n",
              "9  i jest i feel grumpy tired and pre menstrual w...       3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d92441de-28ca-4ebf-b51e-a9961e0bce13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i cant walk into a shop anywhere where i do no...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i felt anger when at the end of a telephone call</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i explain why i clung to a relationship with a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i like to have the same breathless feeling as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i jest i feel grumpy tired and pre menstrual w...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d92441de-28ca-4ebf-b51e-a9961e0bce13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d92441de-28ca-4ebf-b51e-a9961e0bce13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d92441de-28ca-4ebf-b51e-a9961e0bce13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f9eb634-2877-4cb4-a1b0-491b423e8190\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f9eb634-2877-4cb4-a1b0-491b423e8190')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f9eb634-2877-4cb4-a1b0-491b423e8190 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e311fb1b-3143-4595-a097-e9df2b927457\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e311fb1b-3143-4595-a097-e9df2b927457 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"i like to have the same breathless feeling as a reader eager to see what will happen next\",\n          \"im updating my blog because i feel shitty\",\n          \"i cant walk into a shop anywhere where i do not feel uncomfortable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lQYkNUVOptjy"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3aK3qtgdvKrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397dcd07-1d2e-4ca4-eaed-1d776ef007bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MWKpVGg0oNJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e027116-fbe1-4c89-e6b0-375e279b6942"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i felt anger when at the end of a telephone call', 'label': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "nrec=6\n",
        "eval_dataset[nrec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "38zysyhRJxEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d99549a9-df3c-4ad5-fe6f-dec9a17b3f8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i felt anger when at the end of a telephone call'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "eval_dataset[nrec]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qVk0ZfzTIFDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c855c262-a339-4bab-cc39-83d73b2bd108"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "eval_dataset[nrec]['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfZUrSztRWq"
      },
      "source": [
        "https://nbviewer.org/github/frank-morales2020/MLxDL/blob/main/upload_model_hf.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rec=6"
      ],
      "metadata": {
        "id": "ODWFE09Sh4U_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "prompt =  eval_dataset[rec]['text']\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "MI3lqYqwqUCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "id": "MferVz4zqbH7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "36b63225-d55e-4b64-8152-93f9e167a62c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a friend of mine who always glorifies god told me that he had been visiting his family after a long time away mostly for the purpose of praying with them [/INST] 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qc=str(ganswer).find('[/INST]')\n",
        "ganswer=ganswer[qc+8:len(ganswer)]"
      ],
      "metadata": {
        "id": "BBo7jf0FswJa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "id": "IHDqmPLXsfZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4332ac-c88a-4fb5-e319-ca6576637d71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Anger(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYcYQjqAG2f1"
      },
      "outputs": [],
      "source": [
        "# Inspect the structure of the messages\n",
        "#print(eval_dataset[rand_idx][\"messages\"][:2])\n",
        "\n",
        "#Use the chat template to format the input for the language model\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "prompt = eval_dataset[rec]['text']\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "kaXV_ZL7TPfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286ba6d9-664f-4fc8-ea9e-6a4319abff0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'i felt anger when at the end of a telephone call a friend of mine who always glorifies god told me that he had been visiting his family after a long time away mostly for the purpose of praying with them [/INST] 3 '}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "813ePtXgpTe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2e644b-bbf8-4f26-cb91-13d4c8166ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "i felt anger when at the end of a telephone call\n",
            "\n",
            "Original Answer:\n",
            "3\n",
            "\n",
            "Generated Answer:\n",
            "a friend of mine who always glorifies god told me that he had been visiting his family after a long time away mostly for the purpose of praying with them [/INST] 3\n",
            "\n",
            "The similarity between 2 strings is : 1.0\n"
          ]
        }
      ],
      "source": [
        "oanswer=eval_dataset[rec]['label']\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "#print(ganswer)\n",
        "#rand_idx = randint(0, len(eval_dataset))\n",
        "\n",
        "print(f\"Question:\\n{eval_dataset[rec]['text']}\")\n",
        "print()\n",
        "print(f\"Original Answer:\\n{oanswer}\")\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "  # Utility function to compute similarity\n",
        "def similar(str1, str2):\n",
        "  return SequenceMatcher(None, str1, str2).ratio()\n",
        "\n",
        "# using SequenceMatcher.ratio()\n",
        "\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "# similarity between strings\n",
        "similarity = similar(str(oanswer), str(ganswer))\n",
        "\n",
        "# printing the result\n",
        "print()\n",
        "print (\"The similarity between 2 strings is : \" + str(similarity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "W9Qa5_2gyusl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e456a82-61de-4243-b6d7-890fa4e718b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "number_of_eval_samples = 10\n",
        "eval_dataset.shuffle().select(range(number_of_eval_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iErFtC4BnkN9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")\n",
        "#eval_dataset = load_dataset(\"json\", data_files=\"/content/train_dataset.json\", split=\"train\")\n",
        "#eval_dataset = load_dataset(\"json\", data_files=\"/content/validation_dataset.json\", split=\"train\")\n",
        "\n",
        "def evaluate(sample):\n",
        "\n",
        "    prompt = sample['text']\n",
        "    answer=sample['label']\n",
        "\n",
        "    if answer == None:\n",
        "       answer_original = 'Not possible to get or use'\n",
        "\n",
        "    answer_original = re.sub(\"\\n\", \"\", str(answer))\n",
        "\n",
        "\n",
        "    if len(answer_original)==0:\n",
        "        answer_original='Not possible to get or use'\n",
        "\n",
        "    str_question= sample['text']\n",
        "\n",
        "    prompt = re.sub(\"\\n\", \"\", str_question)\n",
        "\n",
        "    #prompt = eval_dataset[rand_idx]['Question']\n",
        "    outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "    #prompt = pipe.tokenizer.apply_chat_template(sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
        "    #outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
        "    predicted_answer = outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    #print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt)+8:].strip()}\")\n",
        "\n",
        "    oanswer=sample['label']\n",
        "\n",
        "    if oanswer == None:\n",
        "       oanswer = 'Not possible to get or use'\n",
        "\n",
        "    ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    qc=str(ganswer).find('[/INST]')\n",
        "    #print(qc)\n",
        "    if int(qc)<0:\n",
        "       #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "       ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    else:\n",
        "       ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "    #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "    # Utility function to compute similarity\n",
        "    def similar(str1, str2):\n",
        "      return SequenceMatcher(None, str1, str2).ratio()\n",
        "\n",
        "    # using SequenceMatcher.ratio()\n",
        "    # similarity between strings\n",
        "    #ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "\n",
        "    res = similar(str(oanswer), str(ganswer))\n",
        "\n",
        "    # printing the result\n",
        "    #print (\"The similarity between 2 strings is : \" + str(res))\n",
        "\n",
        "    if  res>0.90:\n",
        "          #print ()\n",
        "          #print (\"The similarity between 2 strings is : \" + str(res))\n",
        "          #print(f\"Question:\\n{sample['text']}\")\n",
        "          #print(f\"Original Answer:\\n{answer_original}\")\n",
        "          #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "          #print ()\n",
        "          #if int(ganswer) == 0:\n",
        "          #  print(f'Sentiment-Label is: Sadness(0)')\n",
        "          #  print ()\n",
        "          #if int(ganswer)  == 1:\n",
        "          #  print(f'Sentiment-Label is: Joy(1)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 2:\n",
        "          #  print(f'Sentiment-Label is: Love(2)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 3:\n",
        "          #  print(f'Sentiment-Label is: Anger(3)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 4:\n",
        "          #  print(f'Sentiment-Label is: Fear(4)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 5:\n",
        "          #  print(f'Sentiment-Label is: Surprise(5)')\n",
        "          #  print ()\n",
        "          return 1\n",
        "    else:\n",
        "          #print ()\n",
        "          #print(f\"FULL Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "          #print(f\"Question:\\n{sample['text']}\")\n",
        "          #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "          #print(f\"Original Answer:\\n{oanswer}\")\n",
        "          #print()\n",
        "          return 0\n",
        "    del ganswer\n",
        "success_rate = []\n",
        "number_of_eval_samples = 2000\n",
        "# iterate over eval dataset and predict\n",
        "\n",
        "#for s in tqdm(eval_dataset.shuffle().select(range(number_of_eval_samples))):\n",
        "for n in range(number_of_eval_samples):\n",
        "    s=eval_dataset[n]\n",
        "    success_rate.append(evaluate(s))\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = sum(success_rate)/len(success_rate)\n",
        "\n",
        "#print(f\"Accuracy (Eval dataset and predict) for a sample of {number_of_eval_samples}: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002 train_batch_size: 3 eval_batch_size: 8 seed: 42 gradient_accumulation_steps: 2 total_train_batch_size: 6 optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08 lr_scheduler_type: constant lr_scheduler_warmup_ratio: 0.03 num_epochs: 1\n",
        "\n",
        "--------------\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 5: 80.00%\n",
        "\n",
        "NOTE: validation - Accuracy (Eval dataset and predict) for a sample of 100: 61.00%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 100: 66.00%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 1000: 58.90%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 2000: 59.45%\n",
        "\n",
        "--------------"
      ],
      "metadata": {
        "id": "sjMAqbfhayg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------\n",
        "\n",
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002\n",
        "train_batch_size: 3\n",
        "eval_batch_size: 8\n",
        "seed: 42\n",
        "gradient_accumulation_steps: 2\n",
        "total_train_batch_size: 6\n",
        "optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
        "lr_scheduler_type: constant\n",
        "lr_scheduler_warmup_ratio: 0.03\n",
        "\n",
        "num_epochs: 25\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 2000: 79.95%\n",
        "\n",
        "---------------"
      ],
      "metadata": {
        "id": "TLBbX8FuYXJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------\n",
        "\n",
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002\n",
        "train_batch_size: 3\n",
        "eval_batch_size: 8\n",
        "seed: 42\n",
        "gradient_accumulation_steps: 2\n",
        "total_train_batch_size: 6\n",
        "optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
        "lr_scheduler_type: constant\n",
        "lr_scheduler_warmup_ratio: 0.03\n",
        "\n",
        "num_epochs: 40\n",
        "\n",
        "Accuracy (Eval dataset and predict) for a sample of 2000: 80.70%\n",
        "\n",
        "---------------\n",
        "\n",
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002\n",
        "train_batch_size: 3\n",
        "eval_batch_size: 8\n",
        "seed: 42\n",
        "gradient_accumulation_steps: 2\n",
        "total_train_batch_size: 6\n",
        "optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
        "lr_scheduler_type: constant\n",
        "lr_scheduler_warmup_ratio: 0.03\n",
        "\n",
        "num_epochs: 100\n",
        "\n",
        "Accuracy (Eval dataset and predict) for a sample of 2000: 80%\n",
        "\n",
        "---------------"
      ],
      "metadata": {
        "id": "pcDdGTCnXTtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy (Eval dataset and predict) for a sample of {number_of_eval_samples}: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "OPUeb1SeaXZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec62b825-c506-4227-a072-d0e5dcf14a01"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Eval dataset and predict) for a sample of 2000: 80.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO3nKSoATJ9xsIXOEi5rB8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ccbfc50848046399aff4b93720746fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ab4b915c3b8442fa88b76a2f67af9cb",
              "IPY_MODEL_18d9d8364f274d239a1e70aad51c3ad3",
              "IPY_MODEL_74382245357d4510b639d39b08969ccb"
            ],
            "layout": "IPY_MODEL_9aae504913944b6289778882b541ac87"
          }
        },
        "1ab4b915c3b8442fa88b76a2f67af9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f397f7e260434e4e85c7292d8c288ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_2f640c73f3104358ab5a68ff7effdcd4",
            "value": "Generating train split: "
          }
        },
        "18d9d8364f274d239a1e70aad51c3ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eec7996753c4da880feba43c6cdd8f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_badd9c6b14e14476a59a21c7a430dbf7",
            "value": 1
          }
        },
        "74382245357d4510b639d39b08969ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff81071c61743ba9452b44ccd80676d",
            "placeholder": "​",
            "style": "IPY_MODEL_9799eddd621b4858bc4b6bc56bb4b761",
            "value": " 2000/0 [00:00&lt;00:00, 102615.45 examples/s]"
          }
        },
        "9aae504913944b6289778882b541ac87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f397f7e260434e4e85c7292d8c288ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f640c73f3104358ab5a68ff7effdcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eec7996753c4da880feba43c6cdd8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "badd9c6b14e14476a59a21c7a430dbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ff81071c61743ba9452b44ccd80676d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9799eddd621b4858bc4b6bc56bb4b761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}