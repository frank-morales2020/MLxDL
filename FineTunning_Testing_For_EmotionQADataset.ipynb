{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTunning_Testing_For_EmotionQADataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMednPdqqiA8"
      },
      "source": [
        "Fine-tunning: https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_Mistral_7b_hfdeployment_dataset_Medmcqa.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaKHHOC5fnuv"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "#!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "\n",
        "!pip install huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uUNsFfWxnXto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad45723-3d04-44fd-fee6-ee2aa8dacc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_B8ihZJEoEyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a3de80-7c68-42ed-db58-050367158f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n2Pv_flo8OO"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "\n",
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "peft_model_id = \"frankmorales2020/Mistral-7B-v0.1_Emotion\"\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id, use_fast=True)\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# load into pipeline\n",
        "pipe = pipeline(\"document-question-answering\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "prompt = 'I am going to take a vacation next month.'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "E49ltfAcoiQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_szlyqaTFbJB",
        "outputId": "dd69819a-70fe-4250-ddea-a7ac2252c70e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I am going to take a vacation next month. i feel like i am going to be that person who is going to be very productive while on vacation because i am going to be doing things that i enjoy [/INST] 1 '}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "WNFgTleXpW-y",
        "outputId": "d762c155-02c1-4256-a422-5ef9a5ba140c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i feel like i am going to be that person who is going to be very productive while on vacation because i am going to be doing things that i enjoy [/INST] 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_classificator(ganswer):\n",
        "          if int(ganswer) == 0:\n",
        "            class_label='Sentiment-Label is: Sadness(0)'\n",
        "            print ()\n",
        "          if int(ganswer)  == 1:\n",
        "            class_label='Sentiment-Label is: Joy(1)'\n",
        "            print ()\n",
        "          if int(ganswer) == 2:\n",
        "            class_label='Sentiment-Label is: Love(2)'\n",
        "            print ()\n",
        "          if int(ganswer) == 3:\n",
        "            class_label='Sentiment-Label is: Anger(3)'\n",
        "            print ()\n",
        "          if int(ganswer) == 4:\n",
        "            class_label='Sentiment-Label is: Fear(4)'\n",
        "            print ()\n",
        "          if int(ganswer) == 5:\n",
        "            class_label='Sentiment-Label is: Surprise(5)'\n",
        "            print ()\n",
        "          return class_label"
      ],
      "metadata": {
        "id": "Lkk86bLgrTOk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I am going to take a vacation next month. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "rADBMe-lgfWp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ffmy2TTCg0d-",
        "outputId": "94d337f4-402c-4791-9599-a68424cd13ce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn4dgh5_hK3k",
        "outputId": "51c82b0a-524c-4cad-a179-4ebf1f99be5c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Joy(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I am scared. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "LBgcaRMap0om"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kgjtoBgJqWia",
        "outputId": "bbb8def0-d707-492f-80de-ac2827b5580f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ48TZm8p8p_",
        "outputId": "63bbc0f8-5740-4a70-dbac-69d8d5a04fca"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Fear(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '[INST] I grab a minute to post, but I feel greedy and wrong. [/INST]'\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "print(f'{prompt}')\n",
        "print(f'{ganswer}')\n",
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3x4HHhJXIQr",
        "outputId": "8c41a3fe-ec95-44e2-8e5c-8d3638af4364"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] I grab a minute to post, but I feel greedy and wrong. [/INST]\n",
            "3\n",
            "\n",
            "Sentiment-Label is: Anger(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'I grab a minute to post, but I feel greedy and wrong.'\n",
        "\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "#print(f'{prompt}')\n",
        "print(f'{ganswer}')\n",
        "\n",
        "#sentiment=label_classificator(ganswer)\n",
        "#print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrdXBbrLjbJw",
        "outputId": "9b3dc6cf-061e-4b24-dfc2-2cd3500e4306"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don t know. i just want to write that i am feeling very tender and fragile like the petals of a flower that has just begun to bloom [/INST] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB8DWMO_iEsB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "print(\"Preprocessing dataset Emotion\")\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "\n",
        "# save datasets to disk\n",
        "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
        "dataset[\"validation\"].to_json(\"validation_dataset.json\", orient=\"records\")\n",
        "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb-chphAuYKT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7v2nuP4uk2V",
        "outputId": "5471e59c-f5a3-406d-ba36-c6f397650844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "eIGQH5sQt9Ob"
      },
      "outputs": [],
      "source": [
        "nrec=10\n",
        "dataset_final_Question=dataset['text'][0:nrec]\n",
        "dataset_final_Answer=dataset['label'][0:nrec]\n",
        "#dataset_final_Messages=dataset['messages'][0:nrec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "G1XAJCQAuFUj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0FmtsznxfQb",
        "outputId": "3bf227cc-3ed5-49a4-d930-1a9ef0e634c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i felt anger when at the end of a telephone call', 'label': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "dataset[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "vGdcOx1KuJqq",
        "outputId": "c3cc791c-4ce9-4ec5-95e2-82cb3c6e3dc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question  Answer\n",
              "0  im feeling rather rotten so im not very ambiti...       0\n",
              "1          im updating my blog because i feel shitty       0\n",
              "2  i never make her separate from me because i do...       0\n",
              "3  i left with my bouquet of red and yellow tulip...       1\n",
              "4    i was feeling a little vain when i did this one       0\n",
              "5  i cant walk into a shop anywhere where i do no...       4\n",
              "6   i felt anger when at the end of a telephone call       3\n",
              "7  i explain why i clung to a relationship with a...       1\n",
              "8  i like to have the same breathless feeling as ...       1\n",
              "9  i jest i feel grumpy tired and pre menstrual w...       3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b79b8aa4-0740-40db-9e4e-e2dca77eed7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i cant walk into a shop anywhere where i do no...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i felt anger when at the end of a telephone call</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i explain why i clung to a relationship with a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i like to have the same breathless feeling as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i jest i feel grumpy tired and pre menstrual w...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b79b8aa4-0740-40db-9e4e-e2dca77eed7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b79b8aa4-0740-40db-9e4e-e2dca77eed7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b79b8aa4-0740-40db-9e4e-e2dca77eed7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54647a55-e79b-44cb-9f7e-1ff881b0622d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54647a55-e79b-44cb-9f7e-1ff881b0622d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54647a55-e79b-44cb-9f7e-1ff881b0622d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_03585813-8484-49fc-a835-12513c23006d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_03585813-8484-49fc-a835-12513c23006d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"i like to have the same breathless feeling as a reader eager to see what will happen next\",\n          \"im updating my blog because i feel shitty\",\n          \"i cant walk into a shop anywhere where i do not feel uncomfortable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "lQYkNUVOptjy"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aK3qtgdvKrD",
        "outputId": "a62a317e-603c-4f5b-b46a-5585a5deff97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWKpVGg0oNJQ",
        "outputId": "a7f0b97c-ad88-47d4-aa7f-8253c165dd3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i felt anger when at the end of a telephone call', 'label': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "nrec=6\n",
        "eval_dataset[nrec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "38zysyhRJxEc",
        "outputId": "b496db9a-dc39-41b7-fb14-d6d12a585444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i felt anger when at the end of a telephone call'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "eval_dataset[nrec]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVk0ZfzTIFDU",
        "outputId": "dd749fd7-6efe-4c16-dd5d-e68217d69e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "eval_dataset[nrec]['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfZUrSztRWq"
      },
      "source": [
        "https://nbviewer.org/github/frank-morales2020/MLxDL/blob/main/upload_model_hf.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rec=6"
      ],
      "metadata": {
        "id": "ODWFE09Sh4U_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "prompt =  eval_dataset[rec]['text']\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "MI3lqYqwqUCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa58ec3-0284-4643-b1e9-3936f4a57f35"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MferVz4zqbH7",
        "outputId": "84fba66a-5063-4c81-8cb7-f301823f4870"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'with a friend the friend didnt reciprocate the same feelings [/INST] 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qc=str(ganswer).find('[/INST]')\n",
        "ganswer=ganswer[qc+8:len(ganswer)]"
      ],
      "metadata": {
        "id": "BBo7jf0FswJa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=label_classificator(ganswer)\n",
        "print(f'{sentiment}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHDqmPLXsfZm",
        "outputId": "f637e566-ba81-4113-f9f2-823622dd8678"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment-Label is: Anger(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYcYQjqAG2f1"
      },
      "outputs": [],
      "source": [
        "# Inspect the structure of the messages\n",
        "#print(eval_dataset[rand_idx][\"messages\"][:2])\n",
        "\n",
        "#Use the chat template to format the input for the language model\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "\n",
        "#prompt = generation_pipeline.tokenizer.apply_chat_template(modified_conversation, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "prompt = eval_dataset[rec]['text']\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaXV_ZL7TPfm",
        "outputId": "1bf5aa52-9a97-4f2d-b493-b4217d189aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'i felt anger when at the end of a telephone call with a friend the friend didnt reciprocate the same feelings [/INST] 3 '}]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "813ePtXgpTe3",
        "outputId": "bade4381-277c-406a-b1fd-4a6cce4c1e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "i felt anger when at the end of a telephone call\n",
            "\n",
            "Original Answer:\n",
            "3\n",
            "\n",
            "Generated Answer:\n",
            "with a friend the friend didnt reciprocate the same feelings [/INST] 3\n",
            "\n",
            "The similarity between 2 strings is : 1.0\n"
          ]
        }
      ],
      "source": [
        "oanswer=eval_dataset[rec]['label']\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "#print(ganswer)\n",
        "#rand_idx = randint(0, len(eval_dataset))\n",
        "\n",
        "print(f\"Question:\\n{eval_dataset[rec]['text']}\")\n",
        "print()\n",
        "print(f\"Original Answer:\\n{oanswer}\")\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "  # Utility function to compute similarity\n",
        "def similar(str1, str2):\n",
        "  return SequenceMatcher(None, str1, str2).ratio()\n",
        "\n",
        "# using SequenceMatcher.ratio()\n",
        "\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "# similarity between strings\n",
        "similarity = similar(str(oanswer), str(ganswer))\n",
        "\n",
        "# printing the result\n",
        "print()\n",
        "print (\"The similarity between 2 strings is : \" + str(similarity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Qa5_2gyusl",
        "outputId": "64f831af-2a47-4999-a196-5795c41ea128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "number_of_eval_samples = 10\n",
        "eval_dataset.shuffle().select(range(number_of_eval_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "iErFtC4BnkN9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset.json\", split=\"train\")\n",
        "#eval_dataset = load_dataset(\"json\", data_files=\"/content/train_dataset.json\", split=\"train\")\n",
        "#eval_dataset = load_dataset(\"json\", data_files=\"/content/validation_dataset.json\", split=\"train\")\n",
        "\n",
        "def evaluate(sample):\n",
        "\n",
        "    prompt = sample['text']\n",
        "    answer=sample['label']\n",
        "\n",
        "    if answer == None:\n",
        "       answer_original = 'Not possible to get or use'\n",
        "\n",
        "    answer_original = re.sub(\"\\n\", \"\", str(answer))\n",
        "\n",
        "\n",
        "    if len(answer_original)==0:\n",
        "        answer_original='Not possible to get or use'\n",
        "\n",
        "    str_question= sample['text']\n",
        "\n",
        "    prompt = re.sub(\"\\n\", \"\", str_question)\n",
        "\n",
        "    #prompt = eval_dataset[rand_idx]['Question']\n",
        "    outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "    #prompt = pipe.tokenizer.apply_chat_template(sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
        "    #outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
        "    predicted_answer = outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    #print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt)+8:].strip()}\")\n",
        "\n",
        "    oanswer=sample['label']\n",
        "\n",
        "    if oanswer == None:\n",
        "       oanswer = 'Not possible to get or use'\n",
        "\n",
        "    ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    qc=str(ganswer).find('[/INST]')\n",
        "    #print(qc)\n",
        "    if int(qc)<0:\n",
        "       #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "       ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "    else:\n",
        "       ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "    #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "    # Utility function to compute similarity\n",
        "    def similar(str1, str2):\n",
        "      return SequenceMatcher(None, str1, str2).ratio()\n",
        "\n",
        "    # using SequenceMatcher.ratio()\n",
        "    # similarity between strings\n",
        "    #ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "\n",
        "    res = similar(str(oanswer), str(ganswer))\n",
        "\n",
        "    # printing the result\n",
        "    #print (\"The similarity between 2 strings is : \" + str(res))\n",
        "\n",
        "    if  res>0.90:\n",
        "          #print ()\n",
        "          #print (\"The similarity between 2 strings is : \" + str(res))\n",
        "          #print(f\"Question:\\n{sample['text']}\")\n",
        "          #print(f\"Original Answer:\\n{answer_original}\")\n",
        "          #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "\n",
        "          #print ()\n",
        "          #if int(ganswer) == 0:\n",
        "          #  print(f'Sentiment-Label is: Sadness(0)')\n",
        "          #  print ()\n",
        "          #if int(ganswer)  == 1:\n",
        "          #  print(f'Sentiment-Label is: Joy(1)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 2:\n",
        "          #  print(f'Sentiment-Label is: Love(2)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 3:\n",
        "          #  print(f'Sentiment-Label is: Anger(3)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 4:\n",
        "          #  print(f'Sentiment-Label is: Fear(4)')\n",
        "          #  print ()\n",
        "          #if int(ganswer) == 5:\n",
        "          #  print(f'Sentiment-Label is: Surprise(5)')\n",
        "          #  print ()\n",
        "          return 1\n",
        "    else:\n",
        "          #print ()\n",
        "          #print(f\"FULL Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "          #print(f\"Question:\\n{sample['text']}\")\n",
        "          #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "          #print(f\"Original Answer:\\n{oanswer}\")\n",
        "          #print()\n",
        "          return 0\n",
        "    del ganswer\n",
        "success_rate = []\n",
        "number_of_eval_samples = 2000\n",
        "# iterate over eval dataset and predict\n",
        "\n",
        "#for s in tqdm(eval_dataset.shuffle().select(range(number_of_eval_samples))):\n",
        "for n in range(number_of_eval_samples):\n",
        "    s=eval_dataset[n]\n",
        "    success_rate.append(evaluate(s))\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = sum(success_rate)/len(success_rate)\n",
        "\n",
        "#print(f\"Accuracy (Eval dataset and predict) for a sample of {number_of_eval_samples}: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002 train_batch_size: 3 eval_batch_size: 8 seed: 42 gradient_accumulation_steps: 2 total_train_batch_size: 6 optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08 lr_scheduler_type: constant lr_scheduler_warmup_ratio: 0.03 num_epochs: 1\n",
        "\n",
        "--------------\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 5: 80.00%\n",
        "\n",
        "NOTE: validation - Accuracy (Eval dataset and predict) for a sample of 100: 61.00%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 100: 66.00%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 1000: 58.90%\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 2000: 59.45%\n",
        "\n",
        "--------------"
      ],
      "metadata": {
        "id": "sjMAqbfhayg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002\n",
        "train_batch_size: 3\n",
        "eval_batch_size: 8\n",
        "seed: 42\n",
        "gradient_accumulation_steps: 2\n",
        "total_train_batch_size: 6\n",
        "optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
        "lr_scheduler_type: constant\n",
        "lr_scheduler_warmup_ratio: 0.03\n",
        "num_epochs: 25\n",
        "\n",
        "---------------\n",
        "\n",
        "NOTE: test - Accuracy (Eval dataset and predict) for a sample of 2000: 79.95%\n",
        "\n"
      ],
      "metadata": {
        "id": "TLBbX8FuYXJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters were used during training:\n",
        "\n",
        "learning_rate: 0.0002\n",
        "train_batch_size: 3\n",
        "eval_batch_size: 8\n",
        "seed: 42\n",
        "gradient_accumulation_steps: 2\n",
        "total_train_batch_size: 6\n",
        "optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
        "lr_scheduler_type: constant\n",
        "lr_scheduler_warmup_ratio: 0.03\n",
        "num_epochs: 40\n",
        "\n",
        "---------------\n",
        "\n",
        "Accuracy (Eval dataset and predict) for a sample of 2000: 80.70%"
      ],
      "metadata": {
        "id": "pcDdGTCnXTtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy (Eval dataset and predict) for a sample of {number_of_eval_samples}: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPUeb1SeaXZ6",
        "outputId": "eda3ebe1-563b-47ca-ca25-485404402e3e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Eval dataset and predict) for a sample of 2000: 80.70%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyM0HisA8E/3Ea1xcG+IFasa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}