{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/7_Layers_of_Agentic_AI_Demo_(Python)_with_Gemini_2_0_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import json\n",
        "import sys # Import sys for sys.exit()\n",
        "\n",
        "# --- API Key Setup ---\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata # Keep this as per your instruction\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "if GOOGLE_API_KEY:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "else:\n",
        "    print(\"WARNING: GOOGLE_API_KEY not found in Colab Secrets. Please ensure 'GEMINI' secret is set.\")\n",
        "    print(\"API calls will likely fail for LLM-dependent layers. Exiting.\")\n",
        "    sys.exit(\"API key not found. Please set 'GEMINI' in Colab Secrets.\") # Exit if API key is missing\n",
        "\n",
        "# --- Agent Configuration ---\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\" # As specified by you\n",
        "\n",
        "# Initialize the Gemini model for general responses and agentic decisions\n",
        "try:\n",
        "    AGENTIC_MODEL = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "    RESPONDER_MODEL = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "    print(f\"Gemini model '{AgentConfig.LLM_MODEL_NAME}' initialized for agentic and response generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Failed to initialize Gemini model. Please check your API key and model name. Error: {e}\")\n",
        "    AGENTIC_MODEL = None # Set to None to trigger fallback\n",
        "    RESPONDER_MODEL = None\n",
        "    print(\"Falling back to simulated responses for LLM-dependent layers.\")\n",
        "\n",
        "\n",
        "def experience_layer(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 1: Experience Layer - Handles human-AI interaction (input/output).\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 1: Experience Layer ---\")\n",
        "    print(f\"User provides input: '{user_input}'\")\n",
        "    time.sleep(0.5)\n",
        "    return user_input\n",
        "\n",
        "def discovery_layer(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 2: Discovery Layer - Gathers relevant data and knowledge.\n",
        "    Simulates RAG, vector databases, etc.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 2: Discovery Layer ---\")\n",
        "    print(f\"Agent searching for data related to: '{query}'...\")\n",
        "    time.sleep(1)\n",
        "    simulated_data = {\n",
        "        \"flight planning\": \"Retrieved: 'Aviation regulations, weather forecasts, airport data, aircraft performance metrics.'\",\n",
        "        \"ai agents\": \"Retrieved: 'Agentic frameworks, LLM architectures, knowledge graphs, prompt engineering best practices.'\",\n",
        "        \"weather\": \"Retrieved: 'Current weather patterns, historical climate data, meteorological models.'\",\n",
        "        \"database\": \"Retrieved: 'Customer records, sales figures, product inventories.'\",\n",
        "        \"default query\": \"Retrieved: 'General knowledge base articles, common facts, recent news.'\",\n",
        "    }\n",
        "    # Normalize query for lookup\n",
        "    normalized_query = query.lower()\n",
        "    retrieved_info = simulated_data.get(normalized_query, simulated_data[\"default query\"])\n",
        "    print(f\"Discovery complete: {retrieved_info}\")\n",
        "    return retrieved_info\n",
        "\n",
        "def agent_composition_layer(task: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 3: Agent Composition Layer - Designs agent's structure and role.\n",
        "    Simulates selecting or configuring sub-agents.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 3: Agent Composition Layer ---\")\n",
        "    roles = [\"General Purpose Agent\", \"Research Assistant\", \"Customer Service Agent\", \"Flight Planner\"]\n",
        "    # Attempt to use LLM to select role if available, otherwise random\n",
        "    if AGENTIC_MODEL:\n",
        "        try:\n",
        "            role_prompt = f\"Given the task '{task}', which of the following roles is most suitable for an AI agent? Choose one: {', '.join(roles)}. Respond with only the role name.\"\n",
        "            response = AGENTIC_MODEL.generate_content(role_prompt)\n",
        "            selected_role = response.text.strip()\n",
        "            if selected_role not in roles: # Validate LLM output\n",
        "                selected_role = random.choice(roles)\n",
        "                print(f\"LLM suggested invalid role, falling back to random: {selected_role}\")\n",
        "            else:\n",
        "                print(f\"LLM suggested role: '{selected_role}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error using LLM for role selection: {e}. Falling back to random.\")\n",
        "            selected_role = random.choice(roles)\n",
        "    else:\n",
        "        selected_role = random.choice(roles)\n",
        "\n",
        "    print(f\"Configuring agent structure for task: '{task}'\")\n",
        "    print(f\"Agent assigned role: '{selected_role}'\")\n",
        "    time.sleep(0.5)\n",
        "    return selected_role\n",
        "\n",
        "def reasoning_planning_layer(context: str, role: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 4: Reasoning & Planning Layer - The 'brain' for decision-making and planning.\n",
        "    Uses the AGENTIC_MODEL to generate a plan.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 4: Reasoning & Planning Layer ---\")\n",
        "    print(f\"Agent ({role}) is reasoning and planning based on context: '{context}'...\")\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    plan = \"\"\n",
        "    if AGENTIC_MODEL:\n",
        "        try:\n",
        "            prompt = (\n",
        "                f\"You are an AI agent acting as a '{role}'. \"\n",
        "                f\"Based on the following context, generate a concise step-by-step plan \"\n",
        "                f\"to address the user's request. Focus on actionable steps:\\n\\n\"\n",
        "                f\"Context: {context}\\n\\n\"\n",
        "                f\"Plan:\"\n",
        "            )\n",
        "            response = AGENTIC_MODEL.generate_content(prompt)\n",
        "            plan = response.text.strip()\n",
        "            print(f\"Plan generated by LLM:\\n{plan}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating plan with LLM: {e}. Falling back to simulated plan.\")\n",
        "            plan = (\n",
        "                f\"Plan for '{role}' based on '{context}' (Simulated due to LLM error):\\n\"\n",
        "                f\"  1. Analyze input and retrieved data.\\n\"\n",
        "                f\"  2. Break down the problem into sub-tasks.\\n\"\n",
        "                f\"  3. Identify necessary tools/APIs.\\n\"\n",
        "                f\"  4. Formulate a step-by-step execution strategy.\"\n",
        "            )\n",
        "            print(f\"Simulated plan generated:\\n{plan}\")\n",
        "    else:\n",
        "        plan = (\n",
        "            f\"Plan for '{role}' based on '{context}' (Simulated due to LLM not initialized):\\n\"\n",
        "            f\"  1. Analyze input and retrieved data.\\n\"\n",
        "            f\"  2. Break down the problem into sub-tasks.\\n\"\n",
        "            f\"  3. Identify necessary tools/APIs.\\n\"\n",
        "            f\"  4. Formulate a step-by-step execution strategy.\"\n",
        "        )\n",
        "        print(f\"Simulated plan generated:\\n{plan}\")\n",
        "\n",
        "    time.sleep(1)\n",
        "    return plan\n",
        "\n",
        "def tool_api_layer(action: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 5: Tool & API Layer - Agent performs real actions using external tools/APIs.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 5: Tool & API Layer ---\")\n",
        "    print(f\"Agent executing action via tool/API: '{action}'...\")\n",
        "    time.sleep(1.5)\n",
        "    simulated_tool_results = {\n",
        "        \"fetch weather\": \"Tool result: 'Weather API call successful. Current conditions: Sunny, 28°C in Montreal.'\",\n",
        "        \"search database\": \"Tool result: 'Database query successful. Found 15 relevant records for customer ID 123.'\",\n",
        "        \"send email\": \"Tool result: 'Email sent to recipient@example.com with summary of findings.'\",\n",
        "        \"perform general action\": \"Tool result: 'General action completed successfully.'\",\n",
        "    }\n",
        "    result = simulated_tool_results.get(action.lower(), f\"Tool result: 'Simulated tool '{action}' executed successfully.'\")\n",
        "    print(f\"Tool execution complete: {result}\")\n",
        "    return result\n",
        "\n",
        "def memory_feedback_layer(information: str, action_taken: str) -> str:\n",
        "    \"\"\"\n",
        "    Layer 6: Memory & Feedback Layer - Agent learns, adapts, and recalls.\n",
        "    Simulates long-term memory, self-evaluation.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 6: Memory & Feedback Layer ---\")\n",
        "    print(f\"Agent storing information and feedback: '{information}' and action: '{action_taken}'\")\n",
        "    time.sleep(0.7)\n",
        "    # Using a simple in-memory list for demonstration.\n",
        "    # In a real system, this would be a persistent database (e.g., Firestore).\n",
        "    memory_store = []\n",
        "    memory_store.append({\"info\": information, \"action\": action_taken, \"timestamp\": time.time()})\n",
        "    print(f\"Memory stored. Simulating recall...\")\n",
        "    time.sleep(0.5)\n",
        "    if memory_store:\n",
        "        recalled = memory_store[0] # Recall the first item for simplicity\n",
        "        print(f\"Recalled memory: Info='{recalled['info']}', Action='{recalled['action']}'\")\n",
        "        return f\"Recalled: {recalled['info']}\"\n",
        "    return \"No memory to recall.\"\n",
        "\n",
        "def infrastructure_layer():\n",
        "    \"\"\"\n",
        "    Layer 7: Infrastructure Layer - Technical foundation for deployment and scale.\n",
        "    (Conceptual, not interactive in this script)\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Layer 7: Infrastructure Layer ---\")\n",
        "    print(f\"Infrastructure layer ensuring scalability, security, and model access (e.g., Gemini 2.0).\")\n",
        "    print(f\"This layer handles compute, orchestration, and monitoring.\")\n",
        "    time.sleep(0.5)\n",
        "    print(f\"Infrastructure: Ready for operation.\")\n",
        "\n",
        "def run_agentic_ai_demo(initial_user_query: str):\n",
        "    \"\"\"\n",
        "    Orchestrates the flow through the 7 layers of Agentic AI.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Agentic AI Demo ---\")\n",
        "\n",
        "    # Layer 1: Experience Layer\n",
        "    user_input = experience_layer(initial_user_query)\n",
        "\n",
        "    # Layer 2: Discovery Layer\n",
        "    retrieved_data = discovery_layer(user_input)\n",
        "\n",
        "    # Layer 3: Agent Composition Layer\n",
        "    agent_role = agent_composition_layer(user_input)\n",
        "\n",
        "    # Layer 4: Reasoning & Planning Layer\n",
        "    context_for_planning = f\"User input: '{user_input}', Retrieved data: '{retrieved_data}'\"\n",
        "    agent_plan = reasoning_planning_layer(context_for_planning, agent_role)\n",
        "\n",
        "    # Layer 5: Tool & API Layer (example action based on plan)\n",
        "    # In a real agent, the plan would dictate which tools to use based on the LLM's reasoning.\n",
        "    # Here, we'll pick a relevant tool based on the initial query for demonstration.\n",
        "    tool_output = \"\"\n",
        "    if \"weather\" in user_input.lower():\n",
        "        tool_output = tool_api_layer(\"fetch weather\")\n",
        "    elif \"database\" in user_input.lower():\n",
        "        tool_output = tool_api_layer(\"search database\")\n",
        "    elif \"email\" in user_input.lower():\n",
        "        tool_output = tool_api_layer(\"send email\")\n",
        "    else:\n",
        "        tool_output = tool_api_layer(\"perform general action\")\n",
        "\n",
        "\n",
        "    # Layer 6: Memory & Feedback Layer\n",
        "    memory_feedback_layer(f\"Processed query: '{user_input}', Plan: '{agent_plan}', Tool output: '{tool_output}'\", \"Successfully processed query\")\n",
        "\n",
        "    # Layer 7: Infrastructure Layer\n",
        "    infrastructure_layer()\n",
        "\n",
        "    print(\"\\n--- Agentic AI Demo Complete ---\")\n",
        "    final_response = f\"Your request regarding '{user_input}' has been processed. Details from tools: {tool_output}\"\n",
        "    # Optionally, use RESPONDER_MODEL for final user response if available\n",
        "    if RESPONDER_MODEL:\n",
        "        try:\n",
        "            response_prompt = (\n",
        "                f\"Based on the following information, provide a concise and helpful response to the user:\\n\\n\"\n",
        "                f\"User Query: '{user_input}'\\n\"\n",
        "                f\"Agent Role: '{agent_role}'\\n\"\n",
        "                f\"Agent Plan: '{agent_plan}'\\n\"\n",
        "                f\"Tool Output: '{tool_output}'\\n\\n\"\n",
        "                f\"Final Response:\"\n",
        "            )\n",
        "            llm_final_response = RESPONDER_MODEL.generate_content(response_prompt)\n",
        "            final_response = llm_final_response.text.strip()\n",
        "            print(f\"Final response generated by LLM:\\n{final_response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating final response with LLM: {e}. Using default.\")\n",
        "    print(f\"Final simulated output to user: '{final_response}'\")\n",
        "\n",
        "\n",
        "# --- Run the Demo ---\n",
        "if __name__ == \"__main__\":\n",
        "    # You can change this input to see different simulated behaviors\n",
        "    # Ensure you have the 'GEMINI' secret set in Colab for LLM functionality\n",
        "    run_agentic_ai_demo(\"What is the current weather like?\")\n",
        "    # run_agentic_ai_demo(\"Find information about AI agents.\")\n",
        "    # run_agentic_ai_demo(\"Search the internal database for customer records.\")\n",
        "    # run_agentic_ai_demo(\"Can you send an email about the project status?\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "Gemini model 'gemini-2.5-flash' initialized for agentic and response generation.\n",
            "--- Starting Agentic AI Demo ---\n",
            "\n",
            "--- Layer 1: Experience Layer ---\n",
            "User provides input: 'What is the current weather like?'\n",
            "\n",
            "--- Layer 2: Discovery Layer ---\n",
            "Agent searching for data related to: 'What is the current weather like?'...\n",
            "Discovery complete: Retrieved: 'General knowledge base articles, common facts, recent news.'\n",
            "\n",
            "--- Layer 3: Agent Composition Layer ---\n",
            "LLM suggested role: 'General Purpose Agent'\n",
            "Configuring agent structure for task: 'What is the current weather like?'\n",
            "Agent assigned role: 'General Purpose Agent'\n",
            "\n",
            "--- Layer 4: Reasoning & Planning Layer ---\n",
            "Agent (General Purpose Agent) is reasoning and planning based on context: 'User input: 'What is the current weather like?', Retrieved data: 'Retrieved: 'General knowledge base articles, common facts, recent news.'''...\n",
            "Plan generated by LLM:\n",
            "Plan:\n",
            "1.  **Identify data requirement:** Recognize that \"current weather\" requires real-time, location-specific meteorological data.\n",
            "2.  **Assess data availability:** Determine that 'General knowledge base articles, common facts, recent news' does not contain live weather data.\n",
            "3.  **Communicate limitation:** Inform the user that current live weather information cannot be provided from the available resources.\n",
            "4.  **Suggest next steps:** Advise the user on how they might obtain this information (e.g., specifying a location, or suggesting checking a dedicated weather service/app).\n",
            "\n",
            "--- Layer 5: Tool & API Layer ---\n",
            "Agent executing action via tool/API: 'fetch weather'...\n",
            "Tool execution complete: Tool result: 'Weather API call successful. Current conditions: Sunny, 28°C in Montreal.'\n",
            "\n",
            "--- Layer 6: Memory & Feedback Layer ---\n",
            "Agent storing information and feedback: 'Processed query: 'What is the current weather like?', Plan: 'Plan:\n",
            "1.  **Identify data requirement:** Recognize that \"current weather\" requires real-time, location-specific meteorological data.\n",
            "2.  **Assess data availability:** Determine that 'General knowledge base articles, common facts, recent news' does not contain live weather data.\n",
            "3.  **Communicate limitation:** Inform the user that current live weather information cannot be provided from the available resources.\n",
            "4.  **Suggest next steps:** Advise the user on how they might obtain this information (e.g., specifying a location, or suggesting checking a dedicated weather service/app).', Tool output: 'Tool result: 'Weather API call successful. Current conditions: Sunny, 28°C in Montreal.''' and action: 'Successfully processed query'\n",
            "Memory stored. Simulating recall...\n",
            "Recalled memory: Info='Processed query: 'What is the current weather like?', Plan: 'Plan:\n",
            "1.  **Identify data requirement:** Recognize that \"current weather\" requires real-time, location-specific meteorological data.\n",
            "2.  **Assess data availability:** Determine that 'General knowledge base articles, common facts, recent news' does not contain live weather data.\n",
            "3.  **Communicate limitation:** Inform the user that current live weather information cannot be provided from the available resources.\n",
            "4.  **Suggest next steps:** Advise the user on how they might obtain this information (e.g., specifying a location, or suggesting checking a dedicated weather service/app).', Tool output: 'Tool result: 'Weather API call successful. Current conditions: Sunny, 28°C in Montreal.''', Action='Successfully processed query'\n",
            "\n",
            "--- Layer 7: Infrastructure Layer ---\n",
            "Infrastructure layer ensuring scalability, security, and model access (e.g., Gemini 2.0).\n",
            "This layer handles compute, orchestration, and monitoring.\n",
            "Infrastructure: Ready for operation.\n",
            "\n",
            "--- Agentic AI Demo Complete ---\n",
            "Final response generated by LLM:\n",
            "The current weather in Montreal is Sunny with a temperature of 28°C.\n",
            "Final simulated output to user: 'The current weather in Montreal is Sunny with a temperature of 28°C.'\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "kkEWC31R7_gS",
        "outputId": "da1292c5-cbde-48df-f0db-516e67e3c915"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}