{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiZOxpZpobMVhEyE2FcYlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/crypto_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLv-Vz4WAj23"
      },
      "outputs": [],
      "source": [
        "# ==================== COMPLETE MODEL RETRAINING SCRIPT WITH EARLY STOPPING ====================\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands, AverageTrueRange\n",
        "from ta.volume import on_balance_volume\n",
        "from ta.momentum import RSIIndicator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Import Keras Callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Import imblearn for SMOTE and RUS\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "\n",
        "# Database configurations for NEW models (data from 2023 onwards)\n",
        "db_configs_recent_data = [\n",
        "    {'db_path': '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_SOL.db', 'table_name': 'solusd_1h_data', 'symbol': 'SOL/USD', 'model_path': '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_recent_data_SOL.keras'},\n",
        "    {'db_path': '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_LDO.db', 'table_name': 'ldousd_1h_data', 'symbol': 'LDO/USD', 'model_path': '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_recent_data_LDO.keras'},\n",
        "    {'db_path': '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_TAO.db', 'table_name': 'taousd_1h_data', 'symbol': 'TAO/USD', 'model_path': '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_recent_data_TAO.keras'},\n",
        "    {'db_path': '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data.db',     'table_name': 'ethusd_1h_data', 'symbol': 'ETH/USD', 'model_path': '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_recent_data_ETH.keras'},\n",
        "    {'db_path': '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_BTC.db', 'table_name': 'btcusd_1h_data', 'symbol': 'BTC/USD', 'model_path': '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_recent_data_BTC.keras'}\n",
        "]\n",
        "\n",
        "def load_sqlite_data(symbol_config):\n",
        "    \"\"\"Load data from SQLite database\"\"\"\n",
        "    symbol = symbol_config['symbol']\n",
        "    db_path = symbol_config['db_path']\n",
        "    table_name = symbol_config['table_name']\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    query = f\"SELECT * FROM {table_name} ORDER BY timestamp\"\n",
        "    df = pd.read_sql_query(query, conn, parse_dates=['timestamp'])\n",
        "    conn.close()\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No data in {db_path}/{table_name}\")\n",
        "\n",
        "    if df['timestamp'].dt.tz is None:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize('UTC').dt.tz_convert('America/New_York')\n",
        "    else:\n",
        "        df['timestamp'] = df['timestamp'].dt.tz_convert('America/New_York')\n",
        "\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    df = df[~df.index.duplicated(keep='last')]\n",
        "    return df\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"Calculate technical indicators\"\"\"\n",
        "    df = df.copy()\n",
        "    df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].ffill()\n",
        "\n",
        "    df['RSI'] = RSIIndicator(df['close'], window=14).rsi()\n",
        "    macd = MACD(df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_Signal'] = macd.macd_signal()\n",
        "    bb = BollingerBands(df['close'], window=20, window_dev=2)\n",
        "    df['BB_Upper'] = bb.bollinger_hband()\n",
        "    df['BB_Lower'] = bb.bollinger_lband()\n",
        "    df['OBV'] = on_balance_volume(df['close'], df['volume'])\n",
        "    df['ATR'] = AverageTrueRange(df['high'], df['low'], df['close'], window=14).average_true_range()\n",
        "\n",
        "    return df.dropna()\n",
        "\n",
        "def create_model(input_shape):\n",
        "    \"\"\"Create CNN-LSTM model architecture\"\"\"\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        LSTM(100, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(50),\n",
        "        Dropout(0.3),\n",
        "        Dense(50, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(3, activation='softmax')  # 3 classes: Hold, Buy, Sell\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def prepare_training_data(df, look_back=72):\n",
        "    \"\"\"Prepare data for training\"\"\"\n",
        "    features = ['open', 'high', 'low', 'close', 'volume', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'OBV', 'ATR']\n",
        "\n",
        "    # Calculate indicators\n",
        "    df = calculate_technical_indicators(df)\n",
        "\n",
        "    # Create sequences\n",
        "    X_list, y_list = [], []\n",
        "    for i in range(look_back, len(df)):\n",
        "        X_list.append(df[features].iloc[i-look_back:i].values)\n",
        "        # Create labels based on future price movement\n",
        "        future_return = (df['close'].iloc[i] - df['close'].iloc[i-1]) / df['close'].iloc[i-1]\n",
        "        if future_return > 0.002:  # Buy signal\n",
        "            y_list.append([0, 1, 0])\n",
        "        elif future_return < -0.002:  # Sell signal\n",
        "            y_list.append([0, 0, 1])\n",
        "        else:  # Hold\n",
        "            y_list.append([1, 0, 0])\n",
        "\n",
        "    X = np.array(X_list)\n",
        "    y = np.array(y_list)\n",
        "\n",
        "    # Reshape X to 2D for SMOTE (SMOTE-RUS needs 2D data)\n",
        "    X_reshaped = X.reshape(X.shape[0], -1)\n",
        "\n",
        "    return X_reshaped, y, X.shape[1], X.shape[2]\n",
        "\n",
        "def retrain_single_model(symbol_config, epochs=100, look_back=72):\n",
        "    \"\"\"Retrain model for a single symbol with 1:1:1 SMOTE-RUS and early stopping\"\"\"\n",
        "    symbol = symbol_config['symbol']\n",
        "    model_path = symbol_config['model_path']\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Retraining {symbol} model with a perfect 1:1:1 class balance...\")\n",
        "\n",
        "    try:\n",
        "        # Load and prepare data\n",
        "        df = load_sqlite_data(symbol_config)\n",
        "        df = df[df.index >= '2023-01-01']\n",
        "\n",
        "        if len(df) < 5000:\n",
        "            print(f\"âš ï¸ Insufficient data for {symbol} ({len(df)} rows), skipping...\")\n",
        "            return False\n",
        "\n",
        "        print(f\"ðŸ“Š Training on {len(df)} rows from {df.index[0].date()} to {df.index[-1].date()}\")\n",
        "\n",
        "        # Prepare training data (returns reshaped X for resampling)\n",
        "        X_2d, y, n_steps, n_features = prepare_training_data(df, look_back)\n",
        "\n",
        "        if len(X_2d) == 0:\n",
        "            print(f\"âŒ No training sequences generated for {symbol}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"âœ… Generated {len(X_2d)} training sequences. Initial class distribution: {Counter(np.argmax(y, axis=1))}\")\n",
        "\n",
        "        # Split data before resampling\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_2d, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # --- CORRECTED SMOTE-RUS IMPLEMENTATION ---\n",
        "\n",
        "        # Find the true majority class dynamically\n",
        "        train_counts = Counter(np.argmax(y_train, axis=1))\n",
        "        # Find the class with the maximum count\n",
        "        majority_class_label = max(train_counts, key=train_counts.get)\n",
        "        majority_count = train_counts[majority_class_label]\n",
        "\n",
        "        # Set the target count for ALL classes to be the majority count\n",
        "        target_count = majority_count\n",
        "\n",
        "        sampling_strategy = {\n",
        "            0: target_count, # Hold\n",
        "            1: target_count, # Buy\n",
        "            2: target_count  # Sell\n",
        "        }\n",
        "\n",
        "        pipeline = Pipeline(steps=[\n",
        "            ('o', SMOTE(sampling_strategy=sampling_strategy)),\n",
        "            ('u', RandomUnderSampler(sampling_strategy=sampling_strategy))\n",
        "        ])\n",
        "\n",
        "        X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train)\n",
        "\n",
        "        print(f\"âœ… Training data resampled. New class distribution: {Counter(np.argmax(y_train_resampled, axis=1))}\")\n",
        "\n",
        "        X_train_final = X_train_resampled.reshape(-1, n_steps, n_features)\n",
        "        X_val_final = X_val.reshape(-1, n_steps, n_features)\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_model((n_steps, n_features))\n",
        "\n",
        "        # --- ADDED CALLBACKS FOR EARLY STOPPING ---\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min')\n",
        "        callbacks_list = [early_stopping, model_checkpoint]\n",
        "\n",
        "        print(f\"ðŸ”„ Training {symbol} model for {epochs} epochs with early stopping...\")\n",
        "        history = model.fit(\n",
        "            X_train_final, y_train_resampled,\n",
        "            validation_data=(X_val_final, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=32,\n",
        "            verbose=1,\n",
        "            callbacks=callbacks_list  # Pass the callbacks here\n",
        "        )\n",
        "\n",
        "        # The best model has already been saved by ModelCheckpoint, so we don't need model.save()\n",
        "        print(f\"ðŸ’¾ Best model saved to {model_path} via ModelCheckpoint.\")\n",
        "\n",
        "        # Print final accuracy from the training history\n",
        "        train_acc = history.history['accuracy'][-1]\n",
        "        val_acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"âœ… {symbol} training complete! Final accuracy: Train={train_acc:.4f}, Val={val_acc:.4f}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error retraining {symbol}: {e}\")\n",
        "        return False\n",
        "\n",
        "# ==================== EXECUTE RETRAINING ====================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸš€ Starting model retraining with a perfect 1:1:1 class balance and early stopping...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    successful_retrains = 0\n",
        "    for config in db_configs_recent_data:\n",
        "        if retrain_single_model(config, epochs=100, look_back=72):\n",
        "            successful_retrains += 1\n",
        "\n",
        "    print(f\"\\nðŸŽ‰ Retraining completed! {successful_retrains}/{len(db_configs_recent_data)} models successfully retrained!\")\n",
        "    print(\"âœ… Your new models, with a perfect 33.33% balance, are ready for backtesting.\")"
      ]
    }
  ]
}