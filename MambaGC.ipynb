{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOXWOgrR6Imi4+pGff1znZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MambaGC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kCPlHlLGlup",
        "outputId": "c586d7a0-cea4-49cc-8e31-5f32a4751e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "torch.Size([2, 64, 16])\n",
            "\n",
            "\n",
            "\n",
            "2023-12-08:07:05:07,666 INFO     [utils.py:160] NumExpr defaulting to 8 threads.\n",
            "2023-12-08 07:05:08.451780: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-08 07:05:08.451842: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-08 07:05:08.451875: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-08 07:05:09.535127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-08:07:05:11,906 INFO     [__main__.py:132] Verbosity set to INFO\n",
            "2023-12-08:07:05:20,058 INFO     [__main__.py:205] Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'lambada_openai', 'piqa', 'winogrande']\n",
            "2023-12-08:07:05:20,059 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.\n",
            "2023-12-08:07:05:29,020 WARNING  [task.py:300] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2023-12-08:07:05:29,020 WARNING  [task.py:300] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2023-12-08:07:05:32,422 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:33,703 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:36,293 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:47,221 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:57,302 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:59,369 INFO     [task.py:355] Building contexts for task on rank 0...\n",
            "2023-12-08:07:05:59,441 INFO     [evaluator.py:319] Running loglikelihood requests\n",
            "100% 65719/65719 [01:06<00:00, 995.16it/s] \n",
            "bootstrapping for stddev: perplexity\n",
            "100% 100/100 [00:17<00:00,  5.74it/s]\n",
            "mamba (pretrained=state-spaces/mamba-130m), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 64\n",
            "|    Tasks     |Version|Filter|n-shot|  Metric  | Value |   |Stderr|\n",
            "|--------------|-------|------|-----:|----------|------:|---|-----:|\n",
            "|arc_challenge |Yaml   |none  |     0|acc       | 0.1980|±  |0.0116|\n",
            "|              |       |none  |     0|acc_norm  | 0.2432|±  |0.0125|\n",
            "|arc_easy      |Yaml   |none  |     0|acc       | 0.4794|±  |0.0103|\n",
            "|              |       |none  |     0|acc_norm  | 0.4192|±  |0.0101|\n",
            "|hellaswag     |Yaml   |none  |     0|acc       | 0.3076|±  |0.0046|\n",
            "|              |       |none  |     0|acc_norm  | 0.3523|±  |0.0048|\n",
            "|lambada_openai|Yaml   |none  |     0|perplexity|16.0461|±  |0.5093|\n",
            "|              |       |none  |     0|acc       | 0.4421|±  |0.0069|\n",
            "|piqa          |Yaml   |none  |     0|acc       | 0.6458|±  |0.0112|\n",
            "|              |       |none  |     0|acc_norm  | 0.6317|±  |0.0113|\n",
            "|winogrande    |Yaml   |none  |     0|acc       | 0.5217|±  |0.0140|\n",
            "\n",
            "\n",
            "\n",
            "Loading model state-spaces/mamba-2.8b\n",
            "Number of parameters: 2768345600\n",
            "2023-12-08 07:10:48.607605: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-08 07:10:48.607676: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-08 07:10:48.607718: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-08 07:10:49.839335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[\"My cat wrote all this CUDA code for a new language model and I'm trying to run it on my GPU. I'm using the CUDA-enabled version of the Caffe framework.\\nI'm using the following command to compile the code:\\nnvcc -arch=sm_20 -o my_cat_code my_cat_code.cu\\n\\nI'm getting the following error:\\nnvcc: error: argument to -arch must be a string literal\\n\\nI've tried using the following command:\\nnvcc -arch=\"]\n",
            "Prompt length: 14, generation length: 100\n",
            "state-spaces/mamba-2.8b prompt processing + decoding time: 1018ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/state-spaces/mamba/tree/main\n",
        "\n",
        "#!git clone https://github.com/state-spaces/mamba.git\n",
        "#%cd /content/mamba/\n",
        "#!pip install .\n",
        "\n",
        "from mamba_ssm import Mamba\n",
        "import torch\n",
        "\n",
        "batch, length, dim = 2, 64, 16\n",
        "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
        "model = Mamba(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=16,  # SSM state expansion factor\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape\n",
        "\n",
        "print()\n",
        "#print(f\"{x.shape}\")\n",
        "print(f\"{y.shape}\")\n",
        "print()\n",
        "\n",
        "#!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
        "#%cd lm-evaluation-harness\n",
        "#!pip install -e .\n",
        "\n",
        "## CUDA Resources insttallation to avoid AssertionError: libcuda.so cannot found!\n",
        "#!pip install --quiet --upgrade --pre --no-build-isolation torch==2.1.0 torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "\n",
        "\n",
        "#!nvidia-smi\n",
        "\n",
        "print()\n",
        "\n",
        "#!ls /usr/local/cuda/lib64/stubs/libcuda.so\n",
        "#!rm -rf /lib/x86_64-linux-gnu/libcuda.so\n",
        "#!rm -rf /lib/x86_64-linux-gnu/libcuda.so.1\n",
        "\n",
        "#!ln -s /usr/local/cuda/lib64/stubs/libcuda.so /lib/x86_64-linux-gnu/libcuda.so\n",
        "\n",
        "print()\n",
        "print('Evaluations')\n",
        "!python /content/mamba/evals/lm_harness_eval.py --model mamba --model_args pretrained=state-spaces/mamba-130m --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande --device cuda --batch_size 64\n",
        "print()\n",
        "\n",
        "\n",
        "#!ldconfig -p\n",
        "\n",
        "print()\n",
        "print('Inference')\n",
        "!python /content/mamba/benchmarks/benchmark_generation_mamba_simple.py --model-name \"state-spaces/mamba-2.8b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --topp 0.9 --temperature 0.5\n",
        "print()\n",
        "\n",
        "\n",
        "###python benchmarks/benchmark_generation_mamba_simple.py --model-name \"EleutherAI/pythia-2.8b\" --prompt \"My cat wrote all this CUDA code for a new language model and\" --topp 0.9 --temperature 0.5\n",
        "###python evals/lm_harness_eval.py --model hf --model_args pretrained=EleutherAI/pythia-160m --tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande --device cuda --batch_size 64"
      ]
    }
  ]
}