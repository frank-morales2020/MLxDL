{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMDL0f4e1QDh0+zDD2b0Hvt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c693394988d41d2841bf8c95128faf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8e7f5ef106240e982be47357b36ce7e",
              "IPY_MODEL_887745ae60944980871c03f25d1c78fa",
              "IPY_MODEL_36b19ce3392f42c58d1010f1468ae2e5"
            ],
            "layout": "IPY_MODEL_639fc0a85c8849309844eb4591902a0c"
          }
        },
        "a8e7f5ef106240e982be47357b36ce7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12262201964a43d08394004c86772ea9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41472f8861b84731ad30f7f9be2b4dcd",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "887745ae60944980871c03f25d1c78fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b87af465a441a5912ad640a560c613",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f6cc7c04af84fa885a35765037ceb55",
            "value": 2
          }
        },
        "36b19ce3392f42c58d1010f1468ae2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fcfc1b4db1c4b65b3a1d9740b784386",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b35208228bf94734aaaf71fed782d620",
            "value": "â€‡2/2â€‡[00:08&lt;00:00,â€‡â€‡3.87s/it]"
          }
        },
        "639fc0a85c8849309844eb4591902a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12262201964a43d08394004c86772ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41472f8861b84731ad30f7f9be2b4dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9b87af465a441a5912ad640a560c613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6cc7c04af84fa885a35765037ceb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fcfc1b4db1c4b65b3a1d9740b784386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35208228bf94734aaaf71fed782d620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/deepseek_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwA3AVQ3uK1m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
        "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
        "\n",
        "text = \"An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
        "\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
        "\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo1yV-rAv-Eq",
        "outputId": "0bdf425d-e4de-46de-cff4-ef850059c8fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is a vector of real numbers, and the attention function is a function that maps the query and key-value pairs to the output.\n",
            "\n",
            "The attention function is a key component of the attention mechanism, which is a type of neural network architecture that allows the network to focus on specific parts of the input data. The attention mechanism is used in various applications, such as machine translation, image captioning, and question answering.\n",
            "\n",
            "The attention function is typically implemented using a neural network architecture, where the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q\n",
        "!pip install bitsandbytes -q\n",
        "!pip install -U bitsandbytes -q"
      ],
      "metadata": {
        "id": "ILccAs7vyh8E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"You seem to be using the pipelines sequentially on GPU\")\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "xWcef_467xJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    GenerationConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import bitsandbytes\n",
        "from peft import LoraConfig, PeftModel  # Import LoraConfig from peft\n",
        "\n",
        "# Load the tokenizer and model with 4-bit quantization\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Rank of the LoRA update matrices\n",
        "    lora_alpha=32,  # Scaling factor for the LoRA updates\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],  # Specific target modules for DeepSeek LLM\n",
        "    lora_dropout=0.05,  # Dropout probability for the LoRA layers\n",
        "    bias=\"none\",  # No bias for the LoRA layers\n",
        ")\n",
        "\n",
        "\n",
        "# Apply LoRA\n",
        "# The model is already quantized during loading using bnb_config, and compute dtype is set to bfloat16.)\n",
        "from peft import get_peft_model # Import get_peft_model\n",
        "model = get_peft_model(model, lora_config) # Use get_peft_model to add LoRA to the model\n",
        "\n",
        "# Configure the model for training\n",
        "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
        "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
        "\n",
        "\n",
        "# Load the Spider dataset\n",
        "spider_dataset = load_dataset(\"spider\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [f\"Question: {q} SQL: \" for q in examples[\"question\"]]\n",
        "    targets = examples[\"query\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply preprocessing\n",
        "tokenized_spider = spider_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=\"frankmorales2020/deepseek-llm-7b-base-spider\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_spider[\"train\"],\n",
        "    eval_dataset=tokenized_spider[\"validation\"],\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save and push the fine-tuned model to Hugging Face Hub\n",
        "trainer.save_model()\n",
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "0c693394988d41d2841bf8c95128faf1",
            "a8e7f5ef106240e982be47357b36ce7e",
            "887745ae60944980871c03f25d1c78fa",
            "36b19ce3392f42c58d1010f1468ae2e5",
            "639fc0a85c8849309844eb4591902a0c",
            "12262201964a43d08394004c86772ea9",
            "41472f8861b84731ad30f7f9be2b4dcd",
            "f9b87af465a441a5912ad640a560c613",
            "9f6cc7c04af84fa885a35765037ceb55",
            "4fcfc1b4db1c4b65b3a1d9740b784386",
            "b35208228bf94734aaaf71fed782d620"
          ]
        },
        "id": "TstpYb3m4or7",
        "outputId": "50a1e4f5-50fa-4cad-c560-2370e0d80fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c693394988d41d2841bf8c95128faf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='179' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 179/1750 09:25 < 1:23:35, 0.31 it/s, Epoch 0.10/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}