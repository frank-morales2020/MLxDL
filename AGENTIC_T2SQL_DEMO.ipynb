{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "mMckf6tBA3XT"
      ],
      "authorship_tag": "ABX9TyMHT9jEJjcxA4VskwKJWnQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9bbbdbc2d28462aa88ae925e108a139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a03a3faca39b4fccb3085252484e3969",
              "IPY_MODEL_4d473d5d1a0b4ca89b4ec36358bda9c5",
              "IPY_MODEL_3cb0f50ca6c643a0871daf8bb2c42f1b"
            ],
            "layout": "IPY_MODEL_ebae3af664ac4f78bc58a1d7d2e95137"
          }
        },
        "a03a3faca39b4fccb3085252484e3969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_329533b988b94babbe1fe297f406ea33",
            "placeholder": "​",
            "style": "IPY_MODEL_6d64d7c5ada64451a1cfa1823d07ded0",
            "value": "model.safetensors: 100%"
          }
        },
        "4d473d5d1a0b4ca89b4ec36358bda9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e884224d3af4ff4bbc28ebb381134d9",
            "max": 5964186418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddc7b14e7e47424fa03aad94b9ebde35",
            "value": 5964186418
          }
        },
        "3cb0f50ca6c643a0871daf8bb2c42f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6552f06b9f184621ac5fb3bea3c4cb39",
            "placeholder": "​",
            "style": "IPY_MODEL_92bc482ef09849d58508862770c3c450",
            "value": " 5.96G/5.96G [00:20&lt;00:00, 236MB/s]"
          }
        },
        "ebae3af664ac4f78bc58a1d7d2e95137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329533b988b94babbe1fe297f406ea33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d64d7c5ada64451a1cfa1823d07ded0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e884224d3af4ff4bbc28ebb381134d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc7b14e7e47424fa03aad94b9ebde35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6552f06b9f184621ac5fb3bea3c4cb39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92bc482ef09849d58508862770c3c450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca3736588856480882ee831a9aa9e9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f606f3a3b841e388e4365776ea864d",
              "IPY_MODEL_ab1294830b8d476296dbaf3b7c7f828c",
              "IPY_MODEL_5bdb3587f5124f61af696e6f53de167f"
            ],
            "layout": "IPY_MODEL_4a4a2d777b5d42d2b65672f5143b434a"
          }
        },
        "a7f606f3a3b841e388e4365776ea864d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b458ed91490f4d86a5fd0984dca854bc",
            "placeholder": "​",
            "style": "IPY_MODEL_e6bcc101bb17461a8de67465f018f7fd",
            "value": "generation_config.json: 100%"
          }
        },
        "ab1294830b8d476296dbaf3b7c7f828c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fece31c44c5042369ece94ae9496b574",
            "max": 236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f07cd8449bbc4778b62d530b1c3fcad6",
            "value": 236
          }
        },
        "5bdb3587f5124f61af696e6f53de167f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520299d89c214a678cd6bd76b5907a77",
            "placeholder": "​",
            "style": "IPY_MODEL_910136e6fcc541b089a765c01ffd9ef1",
            "value": " 236/236 [00:00&lt;00:00, 30.5kB/s]"
          }
        },
        "4a4a2d777b5d42d2b65672f5143b434a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b458ed91490f4d86a5fd0984dca854bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bcc101bb17461a8de67465f018f7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fece31c44c5042369ece94ae9496b574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07cd8449bbc4778b62d530b1c3fcad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "520299d89c214a678cd6bd76b5907a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910136e6fcc541b089a765c01ffd9ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "066293afea3d47048f9b3e95981e913b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bd1270252f34bc38e6d2c9a5fcd8bed",
              "IPY_MODEL_2fc5d2cf566646b7ab27cf760b2d87a4",
              "IPY_MODEL_724ed8f60e2b4c13bdcea2e876627c82"
            ],
            "layout": "IPY_MODEL_57dbc6b72479481791aecc44f9413bfb"
          }
        },
        "4bd1270252f34bc38e6d2c9a5fcd8bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201d89f9ee1e437682395f80f1e6a2e9",
            "placeholder": "​",
            "style": "IPY_MODEL_113436ec12484454a5d29a23906cdfdf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2fc5d2cf566646b7ab27cf760b2d87a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e47064839284d14b84d6d834aeb1166",
            "max": 52960,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4860c559a424ba59d71510107693384",
            "value": 52960
          }
        },
        "724ed8f60e2b4c13bdcea2e876627c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09f06b4890e74248aeeb4258f1a18d15",
            "placeholder": "​",
            "style": "IPY_MODEL_a62ff9db0c1a4bc6951c042442f513d4",
            "value": " 53.0k/53.0k [00:00&lt;00:00, 6.64MB/s]"
          }
        },
        "57dbc6b72479481791aecc44f9413bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201d89f9ee1e437682395f80f1e6a2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113436ec12484454a5d29a23906cdfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e47064839284d14b84d6d834aeb1166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4860c559a424ba59d71510107693384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09f06b4890e74248aeeb4258f1a18d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62ff9db0c1a4bc6951c042442f513d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35619fd2341249fb9546b1a93ec350c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5633a66823a4d6e8242365f1fa2f5b2",
              "IPY_MODEL_4b95bc5b4c584d0b8bb71e2c0b1c7664",
              "IPY_MODEL_d3c6156d2b6f4093bc3d2c4c83f0eb30"
            ],
            "layout": "IPY_MODEL_4b549c5fd1c04a1d83e3d504493247b3"
          }
        },
        "b5633a66823a4d6e8242365f1fa2f5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb64b5c92984c8aa855c9de3294d757",
            "placeholder": "​",
            "style": "IPY_MODEL_93d3235867794dd5b040b748574b8510",
            "value": "tokenizer.json: 100%"
          }
        },
        "4b95bc5b4c584d0b8bb71e2c0b1c7664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ac5bb8db254d1f8f93756f4dad5ce1",
            "max": 17209530,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e79f43823b344a41ab8351afd163b790",
            "value": 17209530
          }
        },
        "d3c6156d2b6f4093bc3d2c4c83f0eb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d66c116134b489b878bfa41aa582d09",
            "placeholder": "​",
            "style": "IPY_MODEL_083d6d3e100f4802955604cb7b499c43",
            "value": " 17.2M/17.2M [00:01&lt;00:00, 13.6MB/s]"
          }
        },
        "4b549c5fd1c04a1d83e3d504493247b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb64b5c92984c8aa855c9de3294d757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d3235867794dd5b040b748574b8510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ac5bb8db254d1f8f93756f4dad5ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79f43823b344a41ab8351afd163b790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d66c116134b489b878bfa41aa582d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083d6d3e100f4802955604cb7b499c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9cbc369d9145068a663edd55eba97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b57674ac57740df92954ea5ee6b3a65",
              "IPY_MODEL_d869c05be615435bb7ebd7b90cf15f78",
              "IPY_MODEL_f11fba95613c4fceb81baee5e2b9fbe0"
            ],
            "layout": "IPY_MODEL_6ce005558539472c96810b22ff28bc66"
          }
        },
        "9b57674ac57740df92954ea5ee6b3a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7efc21a46e2c450dbf7843122455e19e",
            "placeholder": "​",
            "style": "IPY_MODEL_c57bfdfcd3104f99aaa61b547c3571ca",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d869c05be615435bb7ebd7b90cf15f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f094d914dd4abca44e3b4e198055f1",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cc979eecb3b42359267bfdc10b77c94",
            "value": 483
          }
        },
        "f11fba95613c4fceb81baee5e2b9fbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66d378ee1c14812b8d4eec65275a7c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c465b82e918b4f629cf7e646548a6553",
            "value": " 483/483 [00:00&lt;00:00, 62.4kB/s]"
          }
        },
        "6ce005558539472c96810b22ff28bc66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efc21a46e2c450dbf7843122455e19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57bfdfcd3104f99aaa61b547c3571ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65f094d914dd4abca44e3b4e198055f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc979eecb3b42359267bfdc10b77c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d66d378ee1c14812b8d4eec65275a7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c465b82e918b4f629cf7e646548a6553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "955036be3e72451aba3620b4e048ae1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee90d9ce822646e1a59c25234eec8516",
              "IPY_MODEL_3ce65000fe1a4871bfe8481457521e44",
              "IPY_MODEL_a155917b132a4cf7a45212b710970db4"
            ],
            "layout": "IPY_MODEL_9a8486fb1aed4e06a3c81f984598b9f5"
          }
        },
        "ee90d9ce822646e1a59c25234eec8516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7dbc8031d5427cb74d96560379643b",
            "placeholder": "​",
            "style": "IPY_MODEL_49c5e57b75ef4bd3a417d14a6acfc604",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "3ce65000fe1a4871bfe8481457521e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07315f5c6d4642718068ff3044c73ab9",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dd67987e750486daee98ab60d415489",
            "value": 167832240
          }
        },
        "a155917b132a4cf7a45212b710970db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2742c9cbe4ed4612a4b2958dd3ebb563",
            "placeholder": "​",
            "style": "IPY_MODEL_d957773264124e0fbb7541132916deec",
            "value": " 168M/168M [00:00&lt;00:00, 351MB/s]"
          }
        },
        "9a8486fb1aed4e06a3c81f984598b9f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7dbc8031d5427cb74d96560379643b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c5e57b75ef4bd3a417d14a6acfc604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07315f5c6d4642718068ff3044c73ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd67987e750486daee98ab60d415489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2742c9cbe4ed4612a4b2958dd3ebb563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d957773264124e0fbb7541132916deec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AGENTIC_T2SQL_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model test"
      ],
      "metadata": {
        "id": "mMckf6tBA3XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step0"
      ],
      "metadata": {
        "id": "opNbjFd-DQvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "hf_api_key = userdata.get('HF_TOKEN')\n",
        "#print(hf_api_key)\n",
        "\n",
        "# Consolidated Installations and Imports\n",
        "!pip install -U langchain-community -q\n",
        "!pip install -U crewai -q\n",
        "!pip install 'crewai[tools]' -q\n",
        "!pip install transformers -U -q\n",
        "!pip install colab-env -q\n",
        "!pip install unsloth -q\n",
        "!pip install torch -q # Ensure torch is installed\n",
        "\n",
        "from crewai.tools import BaseTool\n"
      ],
      "metadata": {
        "id": "yojaDSSzNL-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step1"
      ],
      "metadata": {
        "id": "5buJuvW5CU0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.language_models import BaseChatModel\n",
        "from typing import Any, List, Dict, Optional\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration, Generation # Need Generation for BaseChatModel return type\n",
        "class UnslothCrewAILLM(BaseChatModel):\n",
        "    \"\"\"\n",
        "    Custom Langchain-compatible LLM wrapper for models loaded via Unsloth or Transformers pipeline.\n",
        "    \"\"\"\n",
        "    model: Any # The loaded model object (e.g., from FastLanguageModel)\n",
        "    tokenizer: Any # The loaded tokenizer object\n",
        "    pipeline: Any = None # Optional: the transformers pipeline\n",
        "\n",
        "    # Pass generation parameters during initialization\n",
        "    max_new_tokens: int = 1024\n",
        "    temperature: float = 0.1\n",
        "    do_sample: bool = False\n",
        "    trust_remote_code: bool = True # Keep track if remote code is trusted\n",
        "\n",
        "    def __init__(self, model, tokenizer, pipeline=None, max_new_tokens=1024, temperature=0.1, do_sample=False, trust_remote_code=True):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            pipeline=pipeline,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            do_sample=do_sample, # Determine do_sample based on temperature\n",
        "            trust_remote_code=trust_remote_code,\n",
        "        )\n",
        "        # Set pad token ID on the tokenizer if it's None globally\n",
        "        if self.tokenizer.pad_token_id is None:\n",
        "             self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "\n",
        "    def _generate(\n",
        "        self,\n",
        "        messages: List[BaseMessage],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Any = None, # Typically not needed for simple wrappers\n",
        "        **kwargs: Any, # Langchain/CrewAI might pass additional generation args here\n",
        "    ) -> ChatResult:\n",
        "        \"\"\"\n",
        "        Generates a response from the LLM based on the input messages.\n",
        "        Implements the core generation logic required by BaseChatModel.\n",
        "        \"\"\"\n",
        "        if not messages:\n",
        "             raise ValueError(\"No messages provided to the LLM wrapper.\")\n",
        "\n",
        "        # In CrewAI, the last message content often contains the main prompt from the Task.\n",
        "        # For a text-to-SQL model fine-tuned on a specific prompt format (like the one\n",
        "        # used in the Task description), we need to ensure that format is presented\n",
        "        # to the model. The Task description includes the schema and the query.\n",
        "        # Let's assume the content of the *last* message is the primary input prompt.\n",
        "\n",
        "        final_message_content = messages[-1].content\n",
        "\n",
        "        # Use the pipeline or manual generation based on availability\n",
        "        if self.pipeline:\n",
        "            try:\n",
        "                # Pass generation arguments DIRECTLY to the pipeline call\n",
        "                # Also include stop words if the pipeline supports it (Transformers pipeline does not directly take stop as a list in call)\n",
        "                # Need to handle stop words separately or rely on task description formatting for the model\n",
        "                response = self.pipeline(\n",
        "                    final_message_content,\n",
        "                    num_return_sequences=1,\n",
        "                    return_full_text=False,\n",
        "                    max_new_tokens=self.max_new_tokens, # Use stored or passed value from init\n",
        "                    temperature=self.temperature,     # Use stored or passed value from init\n",
        "                    do_sample=self.do_sample,         # Use stored or passed value from init\n",
        "                    # Add other relevant generation parameters if needed\n",
        "                )\n",
        "                generated_text = response[0].get('generated_text', '').strip() if response else \"\"\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during pipeline generation in wrapper: {e}\")\n",
        "                generated_text = f\"Error generating response: {e}\"\n",
        "\n",
        "        elif self.model and self.tokenizer:\n",
        "            # Fallback to manual generation if pipeline not available or fails\n",
        "            try:\n",
        "                # Encode the prompt text\n",
        "                inputs = self.tokenizer(final_message_content, return_tensors=\"pt\", truncation=True, max_length=self.tokenizer.model_max_length).to(self.model.device)\n",
        "\n",
        "                # Ensure pad_token_id is set before generation\n",
        "                if self.tokenizer.pad_token_id is None:\n",
        "                    self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "                # Pass generation arguments DIRECTLY to model.generate call\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=self.max_new_tokens, # Use stored value from init\n",
        "                    temperature=self.temperature,     # Use stored value from init\n",
        "                    do_sample=self.do_sample,         # Use stored value from init\n",
        "                    pad_token_id=self.tokenizer.pad_token_id,\n",
        "                    stopping_criteria=stop, # Pass stop words from Langchain\n",
        "                    # Add other relevant generation parameters as needed\n",
        "                )\n",
        "                # Decode generated tokens, excluding the input prompt\n",
        "                input_length = inputs.input_ids.shape[1]\n",
        "                generated_ids = outputs[0, input_length:]\n",
        "                generated_text = self.tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during manual generation in wrapper: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc() # Print traceback for debugging manual gen failures\n",
        "                generated_text = f\"Error generating response: {e}\"\n",
        "        else:\n",
        "            generated_text = \"Error: Model or pipeline not loaded in wrapper.\"\n",
        "\n",
        "\n",
        "        # Wrap the generated text in a Langchain ChatGeneration object\n",
        "        # The LLM is expected to output the *answer* based on the prompt (which includes the task)\n",
        "        message = AIMessage(content=generated_text)\n",
        "        generation = ChatGeneration(message=message)\n",
        "\n",
        "        # Return a ChatResult containing the generation\n",
        "        return ChatResult(generations=[generation])\n",
        "\n",
        "    # Implement other required methods (often just raising NotImplementedError unless needed)\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"unsloth_transformer_wrapper\" # Custom type name\n",
        "\n",
        "    # Async methods are usually required by BaseChatModel, implement if needed\n",
        "    # For simplicity, we can delegate async to sync for this example\n",
        "    # Note: A proper async implementation is better for performance\n",
        "    async def _agenerate(\n",
        "        self,\n",
        "        messages: List[BaseMessage],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Any = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> ChatResult:\n",
        "        return self._generate(messages, stop, run_manager, **kwargs)\n"
      ],
      "metadata": {
        "id": "R0q63iNeCCfi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2"
      ],
      "metadata": {
        "id": "4AKD54qkCZaf"
      }
    },
    {
      "source": [
        "fine_tuned_model_id = \"frankmorales2020/deepseek_r1_text2sql_finetuned\"\n",
        "max_seq_length = 2048\n",
        "load_in_4bit = True # This will be passed to unsloth loading\n",
        "from transformers import pipeline, AutoConfig\n",
        "\n",
        "# db_schema definition remains the same\n",
        "db_schema = {\n",
        "    \"tables\": {\n",
        "        \"products\": ['id', 'name', 'price', 'category'],\n",
        "        \"orders\": ['order_id', 'product_id', 'quantity', 'order_date']\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# --- Imports for Direct LLM Interaction with Unsloth ---\n",
        "# We need specific imports from unsloth and transformers\n",
        "try:\n",
        "    from unsloth import FastLanguageModel\n",
        "    # We might still need pipeline from transformers for easy generation after loading\n",
        "    from transformers import pipeline, AutoConfig # Keep AutoConfig for trust_remote_code\n",
        "    import torch\n",
        "    import warnings # Import warnings to suppress potential warnings during loading\n",
        "    print(\"Unsloth, Transformers, and Torch imports successful for direct interaction.\")\n",
        "\n",
        "    # --- Direct LLM Loading and Configuration with Unsloth ---\n",
        "    print(f\"\\n--- Attempting Direct LLM Loading for {fine_tuned_model_id} using Unsloth ---\")\n",
        "\n",
        "    # Reuse configuration parameters defined earlier\n",
        "    # fine_tuned_model_id is already defined\n",
        "    # max_seq_length is already defined\n",
        "    # selected_dtype_str is already defined (Unsloth prefers torch.float16 or torch.bfloat16)\n",
        "    # load_in_4bit is already defined (Unsloth handles quantization)\n",
        "    # llm_for_agents dictionary contains other config like temperature, max_tokens, device_map\n",
        "\n",
        "    # Unsloth recommended dtype (bfloat16 if supported, else float16)\n",
        "    unsloth_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
        "    # You might still pass load_in_4bit to unsloth.from_pretrained if you want 4-bit loading\n",
        "    # but unsloth handles the quantization implementation.\n",
        "\n",
        "    # Load the model and tokenizer using FastLanguageModel\n",
        "    # Pass trust_remote_code and dtype directly\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name = fine_tuned_model_id, # Use the model ID\n",
        "            max_seq_length = max_seq_length,   # Pass max sequence length\n",
        "            dtype = unsloth_dtype,             # Use unsloth's preferred dtype\n",
        "            load_in_4bit = load_in_4bit,       # Request 4-bit loading via unsloth\n",
        "            # device_map is often handled internally by unsloth or transformers load_in_4bit\n",
        "            # device_map=\"auto\", # You could try adding this if needed, but unsloth's 4-bit often handles it\n",
        "            trust_remote_code=True,            # Needed for Deepseek\n",
        "        )\n",
        "    print(\"Model and Tokenizer loaded successfully using Unsloth.\")\n",
        "\n",
        "    # Optional: Create a pipeline for easier text generation\n",
        "    # Using the model and tokenizer loaded above ensures quantization/dtype are applied\n",
        "    # Note: Pipelines with unsloth models can sometimes be tricky.\n",
        "    # Manual generation using model.generate might be more reliable if pipeline fails.\n",
        "    try:\n",
        "        direct_pipeline = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            # Pass generation parameters from the config\n",
        "            max_new_tokens=llm_for_agents.get(\"max_tokens\", 1024), # Use max_tokens config, renamed for pipeline\n",
        "            temperature=llm_for_agents.get(\"temperature\", 0.1),\n",
        "            do_sample=True if llm_for_agents.get(\"temperature\", 0.1) > 0 else False, # Enable sampling if temp > 0\n",
        "            # Add other relevant parameters if needed, might require model-specific ones\n",
        "             pad_token_id=tokenizer.eos_token_id, # Often needed for batching, use EOS if PAD is not set\n",
        "        )\n",
        "        print(\"Text generation pipeline created.\")\n",
        "        use_pipeline = True\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not create transformers pipeline: {e}. Falling back to manual generation.\")\n",
        "        direct_pipeline = None\n",
        "        use_pipeline = False\n",
        "\n",
        "\n",
        "    # --- Define the Query and Schema ---\n",
        "    query_to_send_directly = \"List all orders made after 2023-01-01.\"\n",
        "    db_schema_string_for_prompt = str(db_schema) # Reuse db_schema defined earlier\n",
        "\n",
        "    unsloth_wrapper_pipeline = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=1024, # Use a default or variable if needed\n",
        "            temperature=0.1, # Use a default or variable if needed\n",
        "            do_sample=False, # Use a default or variable if needed\n",
        "            # Set pad token ID if tokenizer doesn't have one, needed for batching but also single generation\n",
        "            pad_token_id=tokenizer.eos_token_id, # Safe default if PAD is None\n",
        "            return_full_text=False, # Important for pipeline to not return the input prompt\n",
        "    )\n",
        "\n",
        "    llm_for_agents = UnslothCrewAILLM(\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      pipeline=unsloth_wrapper_pipeline, # Pass the pipeline if created\n",
        "      max_new_tokens=1024, # Matches original max_tokens\n",
        "      temperature=0.1,   # Matches original temperature\n",
        "      trust_remote_code=True, # Matches original setting\n",
        "     )\n",
        "\n",
        "    # --- Construct the Prompt for Direct LLM ---\n",
        "    # This prompt is manually crafted to guide the LLM towards SQL generation\n",
        "    # Adjusting prompt format might be necessary based on the fine-tuned model's training\n",
        "    prompt_for_direct_llm = f\"\"\"Translate the following natural language query into a SQL query based on the provided database schema.\n",
        "\n",
        "    Database Schema:\n",
        "    {db_schema_string_for_prompt}\n",
        "\n",
        "    Natural Language Query:\n",
        "    {query_to_send_directly}\n",
        "\n",
        "    Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
        "\n",
        "    SQL:\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- Sending direct prompt to LLM ---\")\n",
        "    print(\"Prompt:\")\n",
        "    print(prompt_for_direct_llm)\n",
        "\n",
        "    # --- Call the Direct LLM (using the pipeline or manual generation) ---\n",
        "    if use_pipeline and direct_pipeline:\n",
        "        try:\n",
        "            direct_llm_response = direct_pipeline(\n",
        "                prompt_for_direct_llm,\n",
        "                num_return_sequences=1,\n",
        "                return_full_text=False, # Important for pipeline to not return the input prompt\n",
        "                # Add other generation parameters if needed\n",
        "            )\n",
        "            if direct_llm_response and isinstance(direct_llm_response, list) and len(direct_llm_response) > 0:\n",
        "                 generated_text = direct_llm_response[0].get('generated_text', '').strip()\n",
        "                 # Further post-processing might be needed depending on exact output format\n",
        "                 final_direct_sql = generated_text.split(';')[0].strip() if ';' in generated_text else generated_text.split('\\n')[0].strip()\n",
        "            else:\n",
        "                 final_direct_sql = \"Generation failed or returned empty.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during pipeline generation: {e}\")\n",
        "            final_direct_sql = \"Error during pipeline generation.\"\n",
        "    else:\n",
        "        # Manual generation using model.generate\n",
        "        try:\n",
        "            inputs = tokenizer(prompt_for_direct_llm, return_tensors=\"pt\").to(model.device)\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                #max_new_tokens=llm_for_agents.get(\"max_tokens\", 1024),\n",
        "                #temperature=llm_for_agents.get(\"temperature\", 0.1),\n",
        "                #do_sample=True if llm_for_agents.get(\"temperature\", 0.1) > 0 else False,\n",
        "\n",
        "\n",
        "                max_new_tokens=llm_for_agents.max_new_tokens,\n",
        "                temperature=llm_for_agents.temperature,\n",
        "                do_sample=llm_for_agents.do_sample, # Or calculate based on llm_for_agents.temperature if that's the logic you want\n",
        "\n",
        "\n",
        "\n",
        "                # Add other generation parameters as needed for model.generate\n",
        "                # eos_token_id=tokenizer.eos_token_id,\n",
        "                # pad_token_id=tokenizer.eos_token_id, # Often helpful\n",
        "            )\n",
        "            # Decode the output, skipping the input tokens\n",
        "            generated_text = tokenizer.decode(outputs[0, inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "            # Post-process to try and get just the SQL line\n",
        "            final_direct_sql0 = generated_text.split(';')[0].strip() if ';' in generated_text else generated_text.split('\\n')[0].strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during manual generation: {e}\")\n",
        "            final_direct_sql = \"Error during manual generation.\"\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Direct LLM (Unsloth) Generated SQL ---\")\n",
        "    print(final_direct_sql0)\n",
        "\n",
        "    # With direct interaction, there's no automatic validation or refinement step built-in.\n",
        "    # You would have to manually take this output and potentially:\n",
        "    # 1. Try to execute it against a real database.\n",
        "    # 2. Manually analyze the result or any errors.\n",
        "    # 3. If incorrect, manually formulate a new prompt or correction attempt for the LLM.\n",
        "\n",
        "\n",
        "except ImportError:\n",
        "     print(\"\\n--- Skipping direct LLM interaction example: Unsloth or necessary libraries not installed/configured correctly. ---\")\n",
        "     print(\"Please ensure you have 'unsloth' and 'torch' installed and a compatible GPU/CUDA setup.\")\n",
        "except Exception as e:\n",
        "     print(f\"\\n--- An error occurred during direct LLM interaction (Unsloth): {e} ---\")\n",
        "     import traceback\n",
        "     traceback.print_exc() # Print full traceback for debugging"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e9bbbdbc2d28462aa88ae925e108a139",
            "a03a3faca39b4fccb3085252484e3969",
            "4d473d5d1a0b4ca89b4ec36358bda9c5",
            "3cb0f50ca6c643a0871daf8bb2c42f1b",
            "ebae3af664ac4f78bc58a1d7d2e95137",
            "329533b988b94babbe1fe297f406ea33",
            "6d64d7c5ada64451a1cfa1823d07ded0",
            "5e884224d3af4ff4bbc28ebb381134d9",
            "ddc7b14e7e47424fa03aad94b9ebde35",
            "6552f06b9f184621ac5fb3bea3c4cb39",
            "92bc482ef09849d58508862770c3c450",
            "ca3736588856480882ee831a9aa9e9f8",
            "a7f606f3a3b841e388e4365776ea864d",
            "ab1294830b8d476296dbaf3b7c7f828c",
            "5bdb3587f5124f61af696e6f53de167f",
            "4a4a2d777b5d42d2b65672f5143b434a",
            "b458ed91490f4d86a5fd0984dca854bc",
            "e6bcc101bb17461a8de67465f018f7fd",
            "fece31c44c5042369ece94ae9496b574",
            "f07cd8449bbc4778b62d530b1c3fcad6",
            "520299d89c214a678cd6bd76b5907a77",
            "910136e6fcc541b089a765c01ffd9ef1",
            "066293afea3d47048f9b3e95981e913b",
            "4bd1270252f34bc38e6d2c9a5fcd8bed",
            "2fc5d2cf566646b7ab27cf760b2d87a4",
            "724ed8f60e2b4c13bdcea2e876627c82",
            "57dbc6b72479481791aecc44f9413bfb",
            "201d89f9ee1e437682395f80f1e6a2e9",
            "113436ec12484454a5d29a23906cdfdf",
            "8e47064839284d14b84d6d834aeb1166",
            "c4860c559a424ba59d71510107693384",
            "09f06b4890e74248aeeb4258f1a18d15",
            "a62ff9db0c1a4bc6951c042442f513d4",
            "35619fd2341249fb9546b1a93ec350c1",
            "b5633a66823a4d6e8242365f1fa2f5b2",
            "4b95bc5b4c584d0b8bb71e2c0b1c7664",
            "d3c6156d2b6f4093bc3d2c4c83f0eb30",
            "4b549c5fd1c04a1d83e3d504493247b3",
            "3bb64b5c92984c8aa855c9de3294d757",
            "93d3235867794dd5b040b748574b8510",
            "83ac5bb8db254d1f8f93756f4dad5ce1",
            "e79f43823b344a41ab8351afd163b790",
            "6d66c116134b489b878bfa41aa582d09",
            "083d6d3e100f4802955604cb7b499c43",
            "af9cbc369d9145068a663edd55eba97a",
            "9b57674ac57740df92954ea5ee6b3a65",
            "d869c05be615435bb7ebd7b90cf15f78",
            "f11fba95613c4fceb81baee5e2b9fbe0",
            "6ce005558539472c96810b22ff28bc66",
            "7efc21a46e2c450dbf7843122455e19e",
            "c57bfdfcd3104f99aaa61b547c3571ca",
            "65f094d914dd4abca44e3b4e198055f1",
            "2cc979eecb3b42359267bfdc10b77c94",
            "d66d378ee1c14812b8d4eec65275a7c2",
            "c465b82e918b4f629cf7e646548a6553",
            "955036be3e72451aba3620b4e048ae1b",
            "ee90d9ce822646e1a59c25234eec8516",
            "3ce65000fe1a4871bfe8481457521e44",
            "a155917b132a4cf7a45212b710970db4",
            "9a8486fb1aed4e06a3c81f984598b9f5",
            "9a7dbc8031d5427cb74d96560379643b",
            "49c5e57b75ef4bd3a417d14a6acfc604",
            "07315f5c6d4642718068ff3044c73ab9",
            "0dd67987e750486daee98ab60d415489",
            "2742c9cbe4ed4612a4b2958dd3ebb563",
            "d957773264124e0fbb7541132916deec"
          ]
        },
        "id": "i1WCXODZmRvr",
        "outputId": "d5c1c394-39d9-4166-b8e6-2584e43d0682"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3675121859>:18: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth, Transformers, and Torch imports successful for direct interaction.\n",
            "\n",
            "--- Attempting Direct LLM Loading for frankmorales2020/deepseek_r1_text2sql_finetuned using Unsloth ---\n",
            "Unsloth: WARNING `trust_remote_code` is True.\n",
            "Are you certain you want to do remote code execution?\n",
            "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9bbbdbc2d28462aa88ae925e108a139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca3736588856480882ee831a9aa9e9f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "066293afea3d47048f9b3e95981e913b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35619fd2341249fb9546b1a93ec350c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af9cbc369d9145068a663edd55eba97a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955036be3e72451aba3620b4e048ae1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.6.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and Tokenizer loaded successfully using Unsloth.\n",
            "Warning: Could not create transformers pipeline: name 'llm_for_agents' is not defined. Falling back to manual generation.\n",
            "\n",
            "--- Sending direct prompt to LLM ---\n",
            "Prompt:\n",
            "Translate the following natural language query into a SQL query based on the provided database schema.\n",
            "\n",
            "    Database Schema:\n",
            "    {'tables': {'products': ['id', 'name', 'price', 'category'], 'orders': ['order_id', 'product_id', 'quantity', 'order_date']}}\n",
            "\n",
            "    Natural Language Query:\n",
            "    List all orders made after 2023-01-01.\n",
            "\n",
            "    Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
            "\n",
            "    SQL:\n",
            "    \n",
            "\n",
            "--- Direct LLM (Unsloth) Generated SQL ---\n",
            "SELECT ... FROM ... WHERE ... ORDER BY ...\n",
            "\n",
            "    So, the task is to translate the query into SQL, using the correct table and column names, and using the correct operators and functions.\n",
            "\n",
            "    Example:\n",
            "    If the query was \"List all products with price over $100\", the SQL would be:\n",
            "    SELECT p.name, p.price FROM products p WHERE p.price > 100\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# --- Test Case Definition 1 ---\n",
        "\n",
        "test_query = \"Find the names and prices of all products in the 'Electronics' category.\"\n",
        "expected_sql = \"SELECT name, price FROM products WHERE category = 'Electronics';\" # Define the expected SQL output\n",
        "\n",
        "print(\"\\n--- Running Test Case for Direct LLM Interaction ---\")\n",
        "print(f\"Natural Language Query: {test_query}\")\n",
        "print(f\"Expected SQL: {expected_sql}\")\n",
        "\n",
        "\n",
        "# --- Reuse existing setup (assuming model and tokenizer are already loaded) ---\n",
        "# This block assumes that the previous cells where libraries were installed,\n",
        "# modules were imported, the UnslothCrewAILLM class was defined,\n",
        "# the model and tokenizer were loaded using Unsloth, and llm_for_agents\n",
        "# and db_schema were successfully created and are available.\n",
        "\n",
        "if 'model' not in locals() or 'tokenizer' not in locals() or 'llm_for_agents' not in locals():\n",
        "    print(\"\\nSkipping test: Model, tokenizer, or llm_for_agents not loaded. Please run the model loading cell(s) first.\")\n",
        "else:\n",
        "    try:\n",
        "        # --- Define the Query and Schema for the test ---\n",
        "        # db_schema is already defined in the previous cell\n",
        "        if 'db_schema' not in locals():\n",
        "            print(\"\\nSkipping test: db_schema not defined. Please ensure the schema definition cell was run.\")\n",
        "        else:\n",
        "            db_schema_string_for_prompt = str(db_schema)\n",
        "\n",
        "            # --- Construct the Prompt for the Test LLM Call ---\n",
        "            # Use the test_query defined above\n",
        "            prompt_for_test_llm = f\"\"\"Translate the following natural language query into a SQL query based on the provided database schema.\n",
        "\n",
        "Database Schema:\n",
        "{db_schema_string_for_prompt}\n",
        "\n",
        "Natural Language Query:\n",
        "{test_query}\n",
        "\n",
        "Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
        "\n",
        "SQL:\n",
        "\"\"\"\n",
        "\n",
        "            print(f\"\\n--- Sending test prompt to LLM ---\")\n",
        "            print(\"Prompt:\")\n",
        "            print(prompt_for_test_llm)\n",
        "\n",
        "            # --- Call the Direct LLM (using manual generation as it's more reliable) ---\n",
        "            # We will prefer manual generation for consistent testing\n",
        "            try:\n",
        "                inputs = tokenizer(prompt_for_test_llm, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "                # Ensure pad_token_id is set before generation\n",
        "                if tokenizer.pad_token_id is None:\n",
        "                    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "                # Use generation parameters from the llm_for_agents object\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=llm_for_agents.max_new_tokens, # Use stored value from init\n",
        "                    temperature=llm_for_agents.temperature,     # Use stored value from init\n",
        "                    do_sample=llm_for_agents.do_sample,         # Use stored value from init\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                    # Add other relevant generation parameters as needed\n",
        "                    # eos_token_id=tokenizer.eos_token_id, # Might be needed depending on model training\n",
        "                )\n",
        "\n",
        "                # Decode generated tokens, excluding the input prompt\n",
        "                generated_text = tokenizer.decode(outputs[0, inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "                # Post-process to try and get just the SQL line\n",
        "                # Reuse the same parsing logic as before\n",
        "                generated_sql = generated_text.split(';')[0].strip() if ';' in generated_text else generated_text.split('\\n')[0].strip()\n",
        "\n",
        "                print(f\"\\n--- LLM Generated SQL for Test Case ---\")\n",
        "                print(generated_sql)\n",
        "\n",
        "                # --- Compare Generated SQL with Expected SQL ---\n",
        "                # Simple comparison - might need more sophisticated comparison\n",
        "                # if whitespace or casing variations are acceptable.\n",
        "                if generated_sql.lower() == expected_sql.lower():\n",
        "                    print(\"\\n**Test Passed: Generated SQL matches expected SQL.**\")\n",
        "                else:\n",
        "                    print(\"\\n**Test Failed: Generated SQL does NOT match expected SQL.**\")\n",
        "                    print(f\"Expected: {expected_sql}\")\n",
        "                    print(f\"Got:      {generated_sql}\")\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n--- An error occurred during LLM generation for the test case: {e} ---\")\n",
        "                import traceback\n",
        "                traceback.print_exc() # Print full traceback for debugging\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- An error occurred during the test setup or prompt creation: {e} ---\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print full traceback for debugging"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTwd7apHTlWk",
        "outputId": "ac270275-9c6d-4c39-e49a-74be4fa4b228"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Test Case for Direct LLM Interaction ---\n",
            "Natural Language Query: Find the names and prices of all products in the 'Electronics' category.\n",
            "Expected SQL: SELECT name, price FROM products WHERE category = 'Electronics';\n",
            "\n",
            "--- Sending test prompt to LLM ---\n",
            "Prompt:\n",
            "Translate the following natural language query into a SQL query based on the provided database schema.\n",
            "\n",
            "Database Schema:\n",
            "{'tables': {'products': ['id', 'name', 'price', 'category'], 'orders': ['order_id', 'product_id', 'quantity', 'order_date']}}\n",
            "\n",
            "Natural Language Query:\n",
            "Find the names and prices of all products in the 'Electronics' category.\n",
            "\n",
            "Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
            "\n",
            "SQL:\n",
            "\n",
            "\n",
            "--- LLM Generated SQL for Test Case ---\n",
            "SELECT name, price FROM products WHERE category = 'Electronics'\n",
            "\n",
            "**Test Failed: Generated SQL does NOT match expected SQL.**\n",
            "Expected: SELECT name, price FROM products WHERE category = 'Electronics';\n",
            "Got:      SELECT name, price FROM products WHERE category = 'Electronics'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# --- Test Case Definition 2 ---\n",
        "\n",
        "test_query = \"Find the names and prices of all products in the 'Electronics' category.\"\n",
        "# Corrected expected_sql to match the LLM's output format (no trailing semicolon)\n",
        "expected_sql = \"SELECT name, price FROM products WHERE category = 'Electronics'\"\n",
        "\n",
        "print(\"\\n--- Running Test Case for Direct LLM Interaction ---\")\n",
        "print(f\"Natural Language Query: {test_query}\")\n",
        "print(f\"Expected SQL (for comparison): {expected_sql}\") # Adjusted print message\n",
        "\n",
        "# --- Reuse existing setup (assuming model and tokenizer are already loaded) ---\n",
        "# This block assumes that the previous cells where libraries were installed,\n",
        "# modules were imported, the UnslothCrewAILLM class was defined,\n",
        "# the model and tokenizer were loaded using Unsloth, and llm_for_agents\n",
        "# and db_schema were successfully created and are available.\n",
        "\n",
        "if 'model' not in locals() or 'tokenizer' not in locals() or 'llm_for_agents' not in locals():\n",
        "    print(\"\\nSkipping test: Model, tokenizer, or llm_for_agents not loaded. Please run the model loading cell(s) first.\")\n",
        "else:\n",
        "    try:\n",
        "        # --- Define the Query and Schema for the test ---\n",
        "        # db_schema is already defined in the previous cell\n",
        "        if 'db_schema' not in locals():\n",
        "            print(\"\\nSkipping test: db_schema not defined. Please ensure the schema definition cell was run.\")\n",
        "        else:\n",
        "            db_schema_string_for_prompt = str(db_schema)\n",
        "\n",
        "            # --- Construct the Prompt for the Test LLM Call ---\n",
        "            # Use the test_query defined above\n",
        "            prompt_for_test_llm = f\"\"\"Translate the following natural language query into a SQL query based on the provided database schema.\n",
        "\n",
        "Database Schema:\n",
        "{db_schema_string_for_prompt}\n",
        "\n",
        "Natural Language Query:\n",
        "{test_query}\n",
        "\n",
        "Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
        "\n",
        "SQL:\n",
        "\"\"\"\n",
        "\n",
        "            print(f\"\\n--- Sending test prompt to LLM ---\")\n",
        "            print(\"Prompt:\")\n",
        "            print(prompt_for_test_llm)\n",
        "\n",
        "            # --- Call the Direct LLM (using manual generation as it's more reliable) ---\n",
        "            # We will prefer manual generation for consistent testing\n",
        "            try:\n",
        "                inputs = tokenizer(prompt_for_test_llm, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "                # Ensure pad_token_id is set before generation\n",
        "                if tokenizer.pad_token_id is None:\n",
        "                    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "                # Use generation parameters from the llm_for_agents object\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=llm_for_agents.max_new_tokens, # Use stored value from init\n",
        "                    temperature=llm_for_agents.temperature,     # Use stored value from init\n",
        "                    do_sample=llm_for_agents.do_sample,         # Use stored value from init\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                    # Add other relevant generation parameters as needed\n",
        "                    # eos_token_id=tokenizer.eos_token_id, # Might be needed depending on model training\n",
        "                )\n",
        "\n",
        "                # Decode generated tokens, excluding the input prompt\n",
        "                generated_text = tokenizer.decode(outputs[0, inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "                # Post-process to try and get just the SQL line\n",
        "                # Reuse the same parsing logic as before\n",
        "                # This logic correctly handles cases with or without a trailing semicolon\n",
        "                generated_sql = generated_text.split(';')[0].strip() if ';' in generated_text else generated_text.split('\\n')[0].strip()\n",
        "\n",
        "                print(f\"\\n--- LLM Generated SQL for Test Case ---\")\n",
        "                print(generated_sql)\n",
        "\n",
        "                # --- Compare Generated SQL with Expected SQL ---\n",
        "                # The comparison now expects no trailing semicolon in both\n",
        "                if generated_sql.lower() == expected_sql.lower():\n",
        "                    print(\"\\n**Test Passed: Generated SQL matches expected SQL.**\")\n",
        "                else:\n",
        "                    print(\"\\n**Test Failed: Generated SQL does NOT match expected SQL.**\")\n",
        "                    print(f\"Expected: {expected_sql}\")\n",
        "                    print(f\"Got:      {generated_sql}\")\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n--- An error occurred during LLM generation for the test case: {e} ---\")\n",
        "                import traceback\n",
        "                traceback.print_exc() # Print full traceback for debugging\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- An error occurred during the test setup or prompt creation: {e} ---\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print full traceback for debugging"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRyaeledUrbm",
        "outputId": "3db761a0-fde6-46c3-a047-47aaacc00a39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Test Case for Direct LLM Interaction ---\n",
            "Natural Language Query: Find the names and prices of all products in the 'Electronics' category.\n",
            "Expected SQL (for comparison): SELECT name, price FROM products WHERE category = 'Electronics'\n",
            "\n",
            "--- Sending test prompt to LLM ---\n",
            "Prompt:\n",
            "Translate the following natural language query into a SQL query based on the provided database schema.\n",
            "\n",
            "Database Schema:\n",
            "{'tables': {'products': ['id', 'name', 'price', 'category'], 'orders': ['order_id', 'product_id', 'quantity', 'order_date']}}\n",
            "\n",
            "Natural Language Query:\n",
            "Find the names and prices of all products in the 'Electronics' category.\n",
            "\n",
            "Output ONLY the SQL query string, no additional text, explanation, or formatting like markdown.\n",
            "\n",
            "SQL:\n",
            "\n",
            "\n",
            "--- LLM Generated SQL for Test Case ---\n",
            "SELECT name, price FROM products WHERE category = 'Electronics'\n",
            "\n",
            "**Test Passed: Generated SQL matches expected SQL.**\n"
          ]
        }
      ]
    }
  ]
}