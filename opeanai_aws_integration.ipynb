{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "H0atjSHeJWPM",
        "7nv-T7JDJljU"
      ],
      "authorship_tag": "ABX9TyNDCLx7Ngsr3FPWjIkosXIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/opeanai_aws_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "H0atjSHeJWPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install colab-env --upgrade\n",
        "!pip install openai\n",
        "!pip install boto3\n",
        "!pip install json\n",
        "\n"
      ],
      "metadata": {
        "id": "5QN8HtgsW4lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AWS Credentials"
      ],
      "metadata": {
        "id": "7nv-T7JDJljU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"region\")\n",
        "output=os.getenv(\"output\")\n",
        "FunctionName_ARN=os.getenv(\"AWS_LAMBDA_ARN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUFEoVuuQ6-P",
        "outputId": "cb1d2472-f9d4-4f5e-a43f-721d773f7357"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts and Completions: Definitions"
      ],
      "metadata": {
        "id": "qNfC3bP6J7zy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pHouDBccWjWu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai # The OpenAI Python library provides convenient access to the OpenAI REST API.\n",
        "import boto3  # The AWS SDK for Python (Boto3) provides a Python API for AWS infrastructure services.\n",
        "\n",
        "## INVOKE AWS LAMBDA FUNCTION TO GET OPENAI API\n",
        "def get_api_key():\n",
        "    lambda_client = boto3.client('lambda')\n",
        "    response = lambda_client.invoke(\n",
        "            FunctionName = FunctionName_ARN,\n",
        "            InvocationType = 'RequestResponse'\n",
        "        )\n",
        "\n",
        "    openai_api_key = json.load(response['Payload'])['body']['api_key']\n",
        "    return openai_api_key\n",
        "\n",
        "\n",
        "openai.api_key = get_api_key()\n",
        "\n",
        "## GPT4\n",
        "def lambda_handler_GPT4(prompt):\n",
        "    stream = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            CC=chunk.choices[0].delta.content\n",
        "            print(chunk.choices[0].delta.content, end=\"\")\n",
        "## GPT3.5\n",
        "def lambda_handler_GPT3DOT5(prompt):\n",
        "    model_to_use = \"gpt-3.5-turbo-instruct\"\n",
        "    input_prompt=prompt\n",
        "\n",
        "    openai.api_key = get_api_key()\n",
        "    response = openai.completions.create(\n",
        "      model=model_to_use,\n",
        "      prompt=input_prompt,\n",
        "      temperature=0.8,\n",
        "      max_tokens=512,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0\n",
        "    )\n",
        "    #print(response)\n",
        "    return response\n",
        "    #text_response = response['choices'][0]['text'].strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts and Completions: Executions"
      ],
      "metadata": {
        "id": "oZkZ9mRMReU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"what is the 40% of 30?\"\n",
        "prompt = \"what is the 20.5% of 40?\"\n",
        "prompt = \"what is the 30% of 650?\"\n",
        "prompt = \"As a data scientist,can you explain the concept of regularization in machine learning?\"\n",
        "prompt=\"Write an email to Elon Musk asking him why he bought Twitter for such a huge amount\"\n",
        "\n",
        "prompt='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill.\\n How many dollars did I get back? Explain first before answering.'\n",
        "#prompt='Which country has the most natural lakes? Answer with only the country name.'\n",
        "print('Prompt: %s'%prompt)\n",
        "\n",
        "print()\n",
        "print('Chat Completions - gpt4')\n",
        "print()\n",
        "response=lambda_handler_GPT4(prompt)\n",
        "print()\n",
        "print()\n",
        "print('===========')\n",
        "print()\n",
        "print('Completions - gpt3.5')\n",
        "response=lambda_handler_GPT3DOT5(prompt)\n",
        "print()\n",
        "#print('Answer:%s \\r\\n'%response.choices[0].text)\n",
        "print('Answer (gpt 3.5):%s \\n'%response.choices[0].text, sep='', flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1skLvM4Y4Fr",
        "outputId": "1e2eb6a1-a8de-42b6-feb7-e5d26078b910"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill.\n",
            " How many dollars did I get back? Explain first before answering.\n",
            "\n",
            "Chat Completions - gpt4\n",
            "\n",
            "First, you need to find out the total cost of the ice creams. Multiply the cost of one ice cream ($1.25) by the number of kids (6) to find out the total cost. 1.25 * 6 = $7.5. \n",
            "\n",
            "Then subtract the total cost of the ice creams from the amount you paid with ($10). 10 - 7.5 = $2.5.\n",
            "\n",
            "Therefore, after buying the ice creams, you got $2.5 back.\n",
            "\n",
            "===========\n",
            "\n",
            "Completions - gpt3.5\n",
            "\n",
            "Answer (gpt 3.5):\n",
            "\n",
            "You would get $2.50 back. This is because you paid $10 and the total cost of the ice cream cones was $7.50 (6 x $1.25 = $7.50). To find the amount of change, you would subtract $7.50 from $10, which equals $2.50.  \n",
            "\n"
          ]
        }
      ]
    }
  ]
}