{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuSP9JWLe505sUtSqzyG2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/opeanai_aws_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install colab-env --upgrade\n",
        "!pip install openai\n",
        "!pip install boto3\n",
        "!pip install json\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"region\")\n",
        "output=os.getenv(\"output\")\n",
        "FunctionName_ARN=os.getenv(\"AWS_LAMBDA_ARN\")"
      ],
      "metadata": {
        "id": "5QN8HtgsW4lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "pHouDBccWjWu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import boto3\n",
        "\n",
        "### chat completions\n",
        "openai.api_key = get_api_key()\n",
        "\n",
        "def lambda_handler_cc(prompt):\n",
        "    stream = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        stream=True,\n",
        "    )\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            print(chunk.choices[0].delta.content, end=\"\")\n",
        "\n",
        "\n",
        "\n",
        "### completions\n",
        "\n",
        "\n",
        "def lambda_handler(prompt):\n",
        "    #MODEL\tDESCRIPTION\tCONTEXT WINDOW\tTRAINING DATA\n",
        "#gpt-4-1106-preview\n",
        "    model_to_use = \"gpt-3.5-turbo-instruct\"\n",
        "    #model_to_use = \"gpt-4-0314\"\n",
        "    #model_to_use = \"gpt-4-1106-preview\"\n",
        "    #input_prompt=\"Write an email to Elon Musk asking him why he bought Twitter for such a huge amount\"\n",
        "    input_prompt=prompt\n",
        "\n",
        "    openai.api_key = get_api_key()\n",
        "    response = openai.completions.create(\n",
        "      model=model_to_use,\n",
        "      prompt=input_prompt,\n",
        "      temperature=0.8,\n",
        "      max_tokens=512,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0\n",
        "    )\n",
        "    #print(response)\n",
        "    return response\n",
        "    #text_response = response['choices'][0]['text'].strip()\n",
        "\n",
        "\n",
        "def get_api_key():\n",
        "    lambda_client = boto3.client('lambda')\n",
        "    response = lambda_client.invoke(\n",
        "            FunctionName = FunctionName_ARN,\n",
        "            InvocationType = 'RequestResponse'\n",
        "        )\n",
        "\n",
        "    openai_api_key = json.load(response['Payload'])['body']['api_key']\n",
        "    return openai_api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"what is the 40% of 30?\"\n",
        "prompt = \"what is the 20.5% of 40?\"\n",
        "prompt = \"what is the 30% of 650?\"\n",
        "prompt = \"As a data scientist, \\ncan you explain the concept of regularization in machine learning?\"\n",
        "prompt=\"Write an email to Elon Musk asking him why he bought Twitter for such a huge amount\"\n",
        "\n",
        "prompt='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill.\\n How many dollars did I get back? Explain first before answering.'\n",
        "#prompt='Which country has the most natural lakes? Answer with only the country name.'\n",
        "print('Prompt: %s'%prompt)\n",
        "print()\n",
        "print('chat completions - gpt4')\n",
        "print()\n",
        "lambda_handler_cc(prompt)\n",
        "\n",
        "print()\n",
        "print('===========')\n",
        "print()\n",
        "response=lambda_handler(prompt)\n",
        "print()\n",
        "#print('Answer:%s \\r\\n'%response.choices[0].text)\n",
        "\n",
        "print('Answer (gpt 3.5):%s \\n'%response.choices[0].text, sep='', flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1skLvM4Y4Fr",
        "outputId": "a8d04079-f284-414e-d8a9-26d574fa9f43"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill.\n",
            " How many dollars did I get back? Explain first before answering.\n",
            "\n",
            "chat completions - gpt4\n",
            "\n",
            "First, we need to calculate the total cost of the ice cream cones. With 6 kids and each cone costing $1.25, we multiply 6 by 1.25, getting a total of $7.5. \n",
            "\n",
            "Then, to find out how much change you got back, subtract the total cost of the ice cream cones from the $10 bill. This gives us 10-7.5, which equals $2.5.\n",
            "\n",
            "So, you got back $2.5 as change.\n",
            "===========\n",
            "\n",
            "\n",
            "Answer (gpt 3.5):\n",
            "\n",
            "You would get $2.50 back. \n",
            "\n",
            "Explanation: Since each cone was $1.25, 6 cones would cost $7.50. When you pay with a $10 bill, you are essentially giving $10 to the cashier and receiving $10 worth of goods. Since the ice cream only cost $7.50, the cashier would give you the remaining $2.50 in change.  \n",
            "\n"
          ]
        }
      ]
    }
  ]
}