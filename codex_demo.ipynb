{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8zsQKvu8vwdIYUP9Q3KfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/codex_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/openai/codex"
      ],
      "metadata": {
        "id": "wCpfALDcmun4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "EAtUAc5jcopP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h9oQYsBcIgS"
      },
      "outputs": [],
      "source": [
        "!npm install -g @openai/codex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI, APIError # Import OpenAI client and base APIError\n",
        "\n",
        "# It automatically uses the OPENAI_API_KEY environment variable\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "MFYLlMXMdFrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!codex"
      ],
      "metadata": {
        "id": "dmhZTyIicUmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gpt-3.5-turbo-instruct (similar to the original Codex in its instruction-following approach):"
      ],
      "metadata": {
        "id": "Brvh320zlq9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Get API key from environment variable\n",
        "\n",
        "def generate_python_code(prompt):\n",
        "    try:\n",
        "        # Use client.completions.create for completion models\n",
        "        response = client.completions.create(\n",
        "            model=\"gpt-3.5-turbo-instruct\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=200,  # Adjust as needed for the expected length of the code\n",
        "            n=1,             # Number of code snippets to generate\n",
        "            stop=[\"#\", \"\\n\\n\\n\"], # Stop generating when these sequences are encountered\n",
        "            temperature=0.7, # Controls randomness (0.0 is more deterministic, 1.0 is more random)\n",
        "        )\n",
        "        # The response structure is slightly different; access text via .choices[0].text\n",
        "        return response.choices[0].text.strip()\n",
        "    # Use the new exception handling structure, e.g., APIError or its subclasses\n",
        "    except APIError as e:\n",
        "        print(f\"An OpenAI API error occurred: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"Write a Python function that calculates the factorial of a given number.\"\n",
        "    generated_code = generate_python_code(user_prompt)\n",
        "    if generated_code:\n",
        "        print(\"Generated Python code:\")\n",
        "        print(generated_code)\n",
        "        # You can then execute or further process the generated code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvURoz1elSbM",
        "outputId": "64c2f928-44ea-4d5e-da3e-1ebde7bc6baa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Python code:\n",
            "def factorial(n):\n",
            "    result = 1\n",
            "    for i in range(1, n+1):\n",
            "        result *= i\n",
            "    return result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gpt-4 (often provides more sophisticated and context-aware code):"
      ],
      "metadata": {
        "id": "lHa_y5uDlx9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def generate_python_code_gpt4(prompt):\n",
        "    try:\n",
        "        # This part of the code already uses the newer client.chat.completions.create structure\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=200,\n",
        "            n=1,\n",
        "            stop=[\"#\", \"\\n\\n\\n\"],\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        # Access content via .choices[0].message.content\n",
        "        return response.choices[0].message.content.strip()\n",
        "    # Update exception handling for the newer library\n",
        "    except APIError as e:\n",
        "        print(f\"An OpenAI API error occurred (GPT-4): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred (GPT-4): {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"Write a Python class for a simple to-do list with methods to add tasks, remove tasks, and list tasks.\"\n",
        "    generated_code = generate_python_code_gpt4(user_prompt)\n",
        "    if generated_code:\n",
        "        print(\"Generated Python code (using GPT-4):\")\n",
        "        print(generated_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPfLXVfmAjc",
        "outputId": "d3db699b-9517-4f4a-9b9c-942e8a5051d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Python code (using GPT-4):\n",
            "Here is a simple Python class for a to-do list:\n",
            "\n",
            "```python\n",
            "class ToDoList:\n",
            "    def __init__(self):\n",
            "        self.tasks = []\n",
            "\n",
            "    def add_task(self, task):\n",
            "        self.tasks.append(task)\n",
            "\n",
            "    def remove_task(self, task):\n",
            "        if task in self.tasks:\n",
            "            self.tasks.remove(task)\n",
            "        else:\n",
            "            print(\"Task not found in the list.\")\n",
            "\n",
            "    def list_tasks(self):\n",
            "        for task in self.tasks:\n",
            "            print(task)\n",
            "```\n",
            "\n",
            "In this class, `__init__` is the constructor that initializes an empty list of tasks. The `add_task` method appends a task to the tasks list. The `remove_task` method removes a task from the tasks list if it exists, if not it prints a message saying the task was not found. The `list_tasks` method prints all tasks in the tasks list.\n",
            "\n",
            "You can use this class like this:\n",
            "\n",
            "```python\n",
            "todo = ToDoList()\n",
            "todo.add_task(\"Do laundry\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Considerations:\n",
        "\n",
        "* Prompt Engineering: The quality of the generated code heavily depends on the clarity and detail of your prompt. Be specific about the programming language, the functionality you need, and any constraints or requirements.\n",
        "\n",
        "* Error Handling: The generated code might not always be perfect or error-free. You'll likely need to review, test, and debug it.\n",
        "\n",
        "* Security: Be cautious when executing code generated by an AI, especially if it involves file system access or network operations. Always understand what the code does before running it.\n",
        "\n",
        "* Cost: OpenAI API usage is based on token consumption. Be mindful of the number of tokens in your prompts and the generated code, especially when making frequent or lengthy requests.\n",
        "\n",
        "By using the OpenAI Python library with models like gpt-3.5-turbo-instruct or gpt-4, you can effectively leverage the code generation capabilities that were pioneered by OpenAI Codex within your Python projects. Let me know if you have any specific coding tasks you'd like to try generating!"
      ],
      "metadata": {
        "id": "ofichZw6mUKG"
      }
    }
  ]
}