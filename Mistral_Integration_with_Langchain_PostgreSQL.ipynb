{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "5-6vhZfgBWWn",
        "TTWeLDwRBkqx",
        "3V4bZItQByQ7",
        "0vk3VbT-q4X7",
        "Yo-ZsxiyCl3O",
        "iqneJqxTciYL"
      ],
      "authorship_tag": "ABX9TyMp259gFaArJkz3Zz/MulZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b73d8caee65433d9fbf4a77dfac8479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85773392c21443fab535b4a8cd46d1ad",
              "IPY_MODEL_9158a4083dc94f73bb578d1ebdcc5cc7",
              "IPY_MODEL_ceb9e1568d644ce58cc53346a38d64de"
            ],
            "layout": "IPY_MODEL_19ade79f5bd1409d8fb012c139fd3145"
          }
        },
        "85773392c21443fab535b4a8cd46d1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85e9b43698d424697bdb0289c7d73c3",
            "placeholder": "​",
            "style": "IPY_MODEL_94b708a12dc441ba92b289a79bdd12dc",
            "value": "config.json: 100%"
          }
        },
        "9158a4083dc94f73bb578d1ebdcc5cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f6dc2554322498c9648d0fce18f1bde",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f6267e3f2b349099c0c6190a5855e45",
            "value": 571
          }
        },
        "ceb9e1568d644ce58cc53346a38d64de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fd06f45fd14dbfb37705aabfe77cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_040a2bdc8cc24c2d92844ec643c81c5e",
            "value": " 571/571 [00:00&lt;00:00, 41.7kB/s]"
          }
        },
        "19ade79f5bd1409d8fb012c139fd3145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85e9b43698d424697bdb0289c7d73c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b708a12dc441ba92b289a79bdd12dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f6dc2554322498c9648d0fce18f1bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6267e3f2b349099c0c6190a5855e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63fd06f45fd14dbfb37705aabfe77cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040a2bdc8cc24c2d92844ec643c81c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49e75306399440ba3c0b680b9f92b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e624744e1b345349f8e73a2bf5faac0",
              "IPY_MODEL_c18976d26d93402a8ccfc090c9925c1d",
              "IPY_MODEL_bd4a67d2b569417ab29e97b2d1d3a9ca"
            ],
            "layout": "IPY_MODEL_3ff3f769821148ea99c1e5cc61c51b33"
          }
        },
        "9e624744e1b345349f8e73a2bf5faac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241c5a906c60489e897d93fe5400b632",
            "placeholder": "​",
            "style": "IPY_MODEL_fbb5ee983b7b4b7693846509e425b763",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "c18976d26d93402a8ccfc090c9925c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191cd338d63848edb9f84696058b72b3",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3e2776cd34a455c9aed886017c233b7",
            "value": 25125
          }
        },
        "bd4a67d2b569417ab29e97b2d1d3a9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd7577f56df4ae79f8c6a0449941e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_24aa880ca5e84e1cb5db1b86307d1456",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 1.94MB/s]"
          }
        },
        "3ff3f769821148ea99c1e5cc61c51b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241c5a906c60489e897d93fe5400b632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb5ee983b7b4b7693846509e425b763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "191cd338d63848edb9f84696058b72b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e2776cd34a455c9aed886017c233b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dd7577f56df4ae79f8c6a0449941e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24aa880ca5e84e1cb5db1b86307d1456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab774b45edb4c8fb96061c7052b857b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbe8f85d2a444af49e3082a644bc3064",
              "IPY_MODEL_9501e2dbaa0b4fb8858af3f8eb7288c0",
              "IPY_MODEL_fbf1f39541f7491c81554608a3778a76"
            ],
            "layout": "IPY_MODEL_982a92675b66498b8f55851bdaba3aa6"
          }
        },
        "bbe8f85d2a444af49e3082a644bc3064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09611584c5c42ddbe5a6a04dec38c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_4752584c9628442dbad6e6af29ddf891",
            "value": "Downloading shards: 100%"
          }
        },
        "9501e2dbaa0b4fb8858af3f8eb7288c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e19b33a50904d32b6c8290900c73e7c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_560fbc05b41d4bb4954b5afcf02a712e",
            "value": 2
          }
        },
        "fbf1f39541f7491c81554608a3778a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b21dd7f1764e0d84a03b8df06bdfc4",
            "placeholder": "​",
            "style": "IPY_MODEL_423b1f22ab6a4cc59619c6a0729fbebb",
            "value": " 2/2 [12:02&lt;00:00, 337.73s/it]"
          }
        },
        "982a92675b66498b8f55851bdaba3aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09611584c5c42ddbe5a6a04dec38c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4752584c9628442dbad6e6af29ddf891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e19b33a50904d32b6c8290900c73e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560fbc05b41d4bb4954b5afcf02a712e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5b21dd7f1764e0d84a03b8df06bdfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423b1f22ab6a4cc59619c6a0729fbebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62fe63946a624f0a9718b50191b7dc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31aee17746ce4abfaf7b1fe335086c3f",
              "IPY_MODEL_82a34a1f34cd4ea4863b59cf64323301",
              "IPY_MODEL_93a9341a2b9842bc96a847b58d1d9e18"
            ],
            "layout": "IPY_MODEL_2bb4c9f5eca942a5ae6031a65a9e0fe9"
          }
        },
        "31aee17746ce4abfaf7b1fe335086c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70d07c297f284ada9dcb0002ad501e98",
            "placeholder": "​",
            "style": "IPY_MODEL_10051c111bf841b8b375133c974e4de9",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "82a34a1f34cd4ea4863b59cf64323301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ae13a6ae404993b981b64a10dc91d0",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d425cbba075249c0b7d7bd9dd1c52076",
            "value": 9942981696
          }
        },
        "93a9341a2b9842bc96a847b58d1d9e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa10a6a0ec834703bb43fe276fdeda0b",
            "placeholder": "​",
            "style": "IPY_MODEL_a2efba021c014000ac5c50414735e79f",
            "value": " 9.94G/9.94G [08:13&lt;00:00, 19.6MB/s]"
          }
        },
        "2bb4c9f5eca942a5ae6031a65a9e0fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d07c297f284ada9dcb0002ad501e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10051c111bf841b8b375133c974e4de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12ae13a6ae404993b981b64a10dc91d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d425cbba075249c0b7d7bd9dd1c52076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa10a6a0ec834703bb43fe276fdeda0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2efba021c014000ac5c50414735e79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80eee3187a514ada97b2ba689a9bea67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4551edba712142c5a5579c5d9fbc8f4c",
              "IPY_MODEL_0638b778f1ca46d1ba14982a746bc85a",
              "IPY_MODEL_fb9241e9a7c3484ba64279cd5b332a51"
            ],
            "layout": "IPY_MODEL_5858f2c0a61d4f74bcce66035a60ff7f"
          }
        },
        "4551edba712142c5a5579c5d9fbc8f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b791e4f1383c4f0ab91d2938f2352f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_eaa96ec6c8484924a65592b8c27ec269",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "0638b778f1ca46d1ba14982a746bc85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc832591670f4be39f03981703661e35",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_580c587d43f84bcca6f67c743e8f45af",
            "value": 4540516344
          }
        },
        "fb9241e9a7c3484ba64279cd5b332a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_165f612f0dd5499f9e9732fa9e59b938",
            "placeholder": "​",
            "style": "IPY_MODEL_06db9e8ee6764740a9faafd7ada717b5",
            "value": " 4.54G/4.54G [03:47&lt;00:00, 21.0MB/s]"
          }
        },
        "5858f2c0a61d4f74bcce66035a60ff7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b791e4f1383c4f0ab91d2938f2352f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa96ec6c8484924a65592b8c27ec269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc832591670f4be39f03981703661e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580c587d43f84bcca6f67c743e8f45af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "165f612f0dd5499f9e9732fa9e59b938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06db9e8ee6764740a9faafd7ada717b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca47ade1f3e045b9927c18294f3f8e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66034f94f5b5463982c05406ef45837b",
              "IPY_MODEL_b9cd75023013441380a0a0c4f2ee8680",
              "IPY_MODEL_49d50ec21d144cf2b95d3514375e35f7"
            ],
            "layout": "IPY_MODEL_138be3b455044c7396863acaabaf6f02"
          }
        },
        "66034f94f5b5463982c05406ef45837b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353197d73c9c43f5b65b1d9226c0f2a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f34eae76087d4ef19a68076d7478225b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b9cd75023013441380a0a0c4f2ee8680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e15520d102b4d829910dbc740ae8435",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_729ef11ca5e044269c3906e53349d3af",
            "value": 2
          }
        },
        "49d50ec21d144cf2b95d3514375e35f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa06597d09e24000af9d1b87686d4eb8",
            "placeholder": "​",
            "style": "IPY_MODEL_62feaf3e1cf5462f924116e8490017b3",
            "value": " 2/2 [00:09&lt;00:00,  4.48s/it]"
          }
        },
        "138be3b455044c7396863acaabaf6f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353197d73c9c43f5b65b1d9226c0f2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34eae76087d4ef19a68076d7478225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e15520d102b4d829910dbc740ae8435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729ef11ca5e044269c3906e53349d3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa06597d09e24000af9d1b87686d4eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62feaf3e1cf5462f924116e8490017b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24346810b7d14bba82bf49784787c895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09e75e0ca6904f0093410991897be32a",
              "IPY_MODEL_912060520a13467f823a0421b1d50226",
              "IPY_MODEL_da1fb3a3975649c4ab190cf05096f2c7"
            ],
            "layout": "IPY_MODEL_dfb15ae0536f48ed80d1012a0dea7265"
          }
        },
        "09e75e0ca6904f0093410991897be32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb03faa533b489da43c6a52766a57e4",
            "placeholder": "​",
            "style": "IPY_MODEL_03b8f2680d5c40a896045764b9ac3ecf",
            "value": "generation_config.json: 100%"
          }
        },
        "912060520a13467f823a0421b1d50226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_264abfcfc67a40c7994831d2012c1465",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb9922c810774ed9a7a79b88c55900af",
            "value": 116
          }
        },
        "da1fb3a3975649c4ab190cf05096f2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b34288b8344da6befe8383cfa42365",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef33f7e53ba4d358c67aef9dd846bf7",
            "value": " 116/116 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "dfb15ae0536f48ed80d1012a0dea7265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb03faa533b489da43c6a52766a57e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b8f2680d5c40a896045764b9ac3ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264abfcfc67a40c7994831d2012c1465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9922c810774ed9a7a79b88c55900af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45b34288b8344da6befe8383cfa42365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef33f7e53ba4d358c67aef9dd846bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e82cdff55de34577bb18d62fedf9750b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f0977936de240c7ad5534fcdba9a670",
              "IPY_MODEL_573448466b074bfcaf4c06e92fe1e741",
              "IPY_MODEL_a22ee6a98aa54b64be79ec83bcda1bb4"
            ],
            "layout": "IPY_MODEL_d74ecfe862254277ac50edd61c42590f"
          }
        },
        "7f0977936de240c7ad5534fcdba9a670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35c9582637249a1baabf34d4cd86b78",
            "placeholder": "​",
            "style": "IPY_MODEL_d19f384e0dec4fc2bc4714cd1d15659e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "573448466b074bfcaf4c06e92fe1e741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786b92f2b6824734b8ee83f0542cd52e",
            "max": 1467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeebda1c575948bf8641d168eed9be3e",
            "value": 1467
          }
        },
        "a22ee6a98aa54b64be79ec83bcda1bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d09af4aa20429596c65f4187d843c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff37d54ac1a438681f82af1a160014f",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 125kB/s]"
          }
        },
        "d74ecfe862254277ac50edd61c42590f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35c9582637249a1baabf34d4cd86b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19f384e0dec4fc2bc4714cd1d15659e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "786b92f2b6824734b8ee83f0542cd52e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeebda1c575948bf8641d168eed9be3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61d09af4aa20429596c65f4187d843c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff37d54ac1a438681f82af1a160014f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "587d7b09012a4c31b1372bc6bfe2a7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67ff1b30e5fc4ea3b19ae0ccfb99c6b1",
              "IPY_MODEL_51858ee06ae64b6e8004a8d782a9994d",
              "IPY_MODEL_f66130b9c5c84aa7b589a771224ed413"
            ],
            "layout": "IPY_MODEL_fe86a61546d642869da25063bf626c6a"
          }
        },
        "67ff1b30e5fc4ea3b19ae0ccfb99c6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44867ce524194d9e968c2b44fb50a7a2",
            "placeholder": "​",
            "style": "IPY_MODEL_efe4c5a6583342bda2a255ddcf35947e",
            "value": "tokenizer.model: 100%"
          }
        },
        "51858ee06ae64b6e8004a8d782a9994d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235fe9a9e0914f7088a5f11551fd646b",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9384599d090b4c2eaa211c7606689579",
            "value": 493443
          }
        },
        "f66130b9c5c84aa7b589a771224ed413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ae45c4e42746d4a59c16db0c15fa94",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a50b8bee154b81bb71f7173b9bc1b8",
            "value": " 493k/493k [00:00&lt;00:00, 30.7MB/s]"
          }
        },
        "fe86a61546d642869da25063bf626c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44867ce524194d9e968c2b44fb50a7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe4c5a6583342bda2a255ddcf35947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "235fe9a9e0914f7088a5f11551fd646b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9384599d090b4c2eaa211c7606689579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0ae45c4e42746d4a59c16db0c15fa94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a50b8bee154b81bb71f7173b9bc1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a330f1342f2649f5bea8fd35428c5630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e46411fc287425c8942f7e02aabaf57",
              "IPY_MODEL_3350502752d947a0adaba53028f20c27",
              "IPY_MODEL_46b119a0a59e452d9e930b834e717f89"
            ],
            "layout": "IPY_MODEL_a8eddb3392cf4b10af7f34e531c64175"
          }
        },
        "2e46411fc287425c8942f7e02aabaf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54e6ce9ce5ee4d2284cbfbc4d1f4c3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_076cd988232a465ba725f525fbff8eb6",
            "value": "tokenizer.json: 100%"
          }
        },
        "3350502752d947a0adaba53028f20c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_448c74f1623f422f858153e62c1e69be",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32161545317b44e29ea0a0752ab1fea6",
            "value": 1795303
          }
        },
        "46b119a0a59e452d9e930b834e717f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c01a4c297d9045b99dcb2740f99e0a50",
            "placeholder": "​",
            "style": "IPY_MODEL_ae81a95905b942b0859d761d31366b71",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 1.83MB/s]"
          }
        },
        "a8eddb3392cf4b10af7f34e531c64175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e6ce9ce5ee4d2284cbfbc4d1f4c3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076cd988232a465ba725f525fbff8eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "448c74f1623f422f858153e62c1e69be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32161545317b44e29ea0a0752ab1fea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c01a4c297d9045b99dcb2740f99e0a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae81a95905b942b0859d761d31366b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "597c3ce531ad4dc189c48585e703f16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a26f9926c4874d5abe7da9b0c31ddde4",
              "IPY_MODEL_36a53bf32331444b8cdd518d6bd53375",
              "IPY_MODEL_85836eb4051b4ca096be8c5176dc9fb0"
            ],
            "layout": "IPY_MODEL_9c482f6441f74d7ba43e4d552ba3288a"
          }
        },
        "a26f9926c4874d5abe7da9b0c31ddde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee42719a0bc4db4afc2d6085770ae74",
            "placeholder": "​",
            "style": "IPY_MODEL_572cfe41cd424ea29860562a5222c711",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "36a53bf32331444b8cdd518d6bd53375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f96d1b3f52d54c719bee0fb6614c7d11",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff19e8a2f1bd442098288992846587fd",
            "value": 72
          }
        },
        "85836eb4051b4ca096be8c5176dc9fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b184b99670d94c1a86168a8d3a612416",
            "placeholder": "​",
            "style": "IPY_MODEL_62857f65be8f4f68a0e9f531e0c652e6",
            "value": " 72.0/72.0 [00:00&lt;00:00, 6.02kB/s]"
          }
        },
        "9c482f6441f74d7ba43e4d552ba3288a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee42719a0bc4db4afc2d6085770ae74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572cfe41cd424ea29860562a5222c711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f96d1b3f52d54c719bee0fb6614c7d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff19e8a2f1bd442098288992846587fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b184b99670d94c1a86168a8d3a612416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62857f65be8f4f68a0e9f531e0c652e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Mistral_Integration_with_Langchain_PostgreSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "QR-Ls8u1DWR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "5-6vhZfgBWWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Libraries to access Google Drive and OpenAI resources.\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "II600ZhIB3jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c048ee-0d26-4bf1-85fb-eb8bd9b94df5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions"
      ],
      "metadata": {
        "id": "TTWeLDwRBkqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_document(id,embedding):\n",
        "    #review_embedding=get_embedding(text)\n",
        "    ### INSERT INTO DB\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "    cur.execute(\"\"\"\n",
        "        INSERT INTO documents\n",
        "        (id, embedding)\n",
        "        VALUES ('%s',\n",
        "                '%s')\"\"\" % (id,embedding))\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"INSERT EMBEDDING %s successfully\"%embedding)\n",
        "    conn.close()\n",
        "    cur.close()"
      ],
      "metadata": {
        "id": "p6Qe93gMlSIB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_selection(query):\n",
        "      # PostGRES SQL Settings\n",
        "      import psycopg2 as ps\n",
        "      DB_NAME = \"postgres\"\n",
        "      DB_USER = \"postgres\"\n",
        "      DB_PASS = \"postgres\"\n",
        "      DB_HOST = \"localhost\"\n",
        "      DB_PORT = \"5432\"\n",
        "      conn = ps.connect(database=DB_NAME,\n",
        "                user=DB_USER,\n",
        "                password=DB_PASS,\n",
        "                host=DB_HOST,\n",
        "                port=DB_PORT)\n",
        "      cur = conn.cursor() # creating a cursor\n",
        "      cur.execute(\"\"\"\n",
        "          %s \"\"\"%query)\n",
        "      records = cur.fetchall()\n",
        "      print(\"Total rows are:  \", len(records))\n",
        "      print(\"Printing each row\")\n",
        "      print()\n",
        "      n=0\n",
        "      for row in records:\n",
        "          n=n+1\n",
        "          print(\"ROW %s: \"%n, row)\n",
        "      conn.close()\n",
        "      cur.close()\n",
        "      print()\n",
        "      print(\"QUERY SELECTION successfully\")\n",
        "      print()"
      ],
      "metadata": {
        "id": "2xUxFbS934W5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_extension(extension):\n",
        "      # PostGRES SQL Settings\n",
        "      import psycopg2 as ps\n",
        "      DB_NAME = \"postgres\"\n",
        "      DB_USER = \"postgres\"\n",
        "      DB_PASS = \"postgres\"\n",
        "      DB_HOST = \"localhost\"\n",
        "      DB_PORT = \"5432\"\n",
        "      conn = ps.connect(database=DB_NAME,\n",
        "                user=DB_USER,\n",
        "                password=DB_PASS,\n",
        "                host=DB_HOST,\n",
        "                port=DB_PORT)\n",
        "      cur = conn.cursor() # creating a cursor\n",
        "      cur.execute(\"\"\"DROP EXTENSION IF EXISTS %s CASCADE\"\"\"%extension)\n",
        "      cur.query\n",
        "      conn.commit()\n",
        "      cur.close()\n",
        "      conn.close()\n",
        "\n",
        "      print()\n",
        "      print(\"DROP EXTENSION %s successfully\"%extension)\n",
        "      print()"
      ],
      "metadata": {
        "id": "QWP0GA9Z4X4L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PostgreSQL: Definition and Configuration"
      ],
      "metadata": {
        "id": "3V4bZItQByQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install PSQL WITH DEV Libraries AND PG embedding\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all"
      ],
      "metadata": {
        "id": "5bHMdQLvCGRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239d5a28-843a-45a6-f23e-d42e2dc73988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14 python3-pygments\n",
            "  python3-yaml\n",
            "Suggested packages:\n",
            "  llvm-14-doc python-pygments-doc ttf-bitstream-vera\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14\n",
            "  postgresql-server-dev-all python3-pygments python3-yaml\n",
            "0 upgraded, 13 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 59.8 MB of archives.\n",
            "After this operation, 361 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 binfmt-support amd64 2.2.1-2 [55.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-runtime amd64 1:14.0.0-1ubuntu1.1 [484 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpfm4 amd64 4.11.1+git32-gd0b85fb-1ubuntu0.1 [345 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14 amd64 1:14.0.0-1ubuntu1.1 [12.7 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-pygments all 2.11.2+dfsg-2 [750 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-tools amd64 1:14.0.0-1ubuntu1.1 [404 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-4 amd64 4.8.12-1 [5,766 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-dev amd64 4.8.12-1 [72.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-dev amd64 1:14.0.0-1ubuntu1.1 [37.8 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 postgresql-server-dev-14 amd64 14.10-0ubuntu0.22.04.1 [1,175 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 postgresql-server-dev-all amd64 238 [14.0 kB]\n",
            "Fetched 59.8 MB in 9s (6,880 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 13.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 123615 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Selecting previously unselected package binfmt-support.\n",
            "Preparing to unpack .../01-binfmt-support_2.2.1-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.2.1-2) ...\n",
            "Selecting previously unselected package llvm-14-runtime.\n",
            "Preparing to unpack .../02-llvm-14-runtime_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libpfm4:amd64.\n",
            "Preparing to unpack .../03-libpfm4_4.11.1+git32-gd0b85fb-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Selecting previously unselected package llvm-14.\n",
            "Preparing to unpack .../04-llvm-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../05-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../06-python3-pygments_2.11.2+dfsg-2_all.deb ...\n",
            "Unpacking python3-pygments (2.11.2+dfsg-2) ...\n",
            "Selecting previously unselected package llvm-14-tools.\n",
            "Preparing to unpack .../07-llvm-14-tools_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libz3-4:amd64.\n",
            "Preparing to unpack .../08-libz3-4_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-4:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package libz3-dev:amd64.\n",
            "Preparing to unpack .../09-libz3-dev_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-dev:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package llvm-14-dev.\n",
            "Preparing to unpack .../10-llvm-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-14.\n",
            "Preparing to unpack .../11-postgresql-server-dev-14_14.10-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-14 (14.10-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-all:amd64.\n",
            "Preparing to unpack .../12-postgresql-server-dev-all_238_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-all:amd64 (238) ...\n",
            "Setting up python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up python3-pygments (2.11.2+dfsg-2) ...\n",
            "Setting up libz3-4:amd64 (4.8.12-1) ...\n",
            "Setting up libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Setting up llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up binfmt-support (2.2.1-2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "Setting up llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libz3-dev:amd64 (4.8.12-1) ...\n",
            "Setting up llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up postgresql-server-dev-14 (14.10-0ubuntu0.22.04.1) ...\n",
            "Setting up postgresql-server-dev-all:amd64 (238) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -pr /content/gdrive/MyDrive/tools/pg_embedding /content/\n",
        "%cd /content/pg_embedding/\n",
        "print()\n",
        "print('START: PG embedding COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "#!make uninstall\n",
        "print('END: PG embedding COMPILATION')\n",
        "print()"
      ],
      "metadata": {
        "id": "CHZtNbRxBjX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a2da3f-6564-46b5-dda7-a6aebab1363e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pg_embedding\n",
            "\n",
            "START: PG embedding COMPILATION\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o embedding.o embedding.c\n",
            "g++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -std=c++11 -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o hnswalg.o hnswalg.cpp\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o distfunc.o distfunc.c\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -shared -o embedding.so embedding.o hnswalg.o distfunc.o -lstdc++ -L/usr/lib/x86_64-linux-gnu -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now -L/usr/lib/llvm-14/lib  -Wl,--as-needed  \n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o embedding.bc embedding.c\n",
            "/usr/bin/clang-14 -xc++ -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o hnswalg.bc hnswalg.cpp\n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o distfunc.bc distfunc.c\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  embedding.so '/usr/lib/postgresql/14/lib/embedding.so'\n",
            "/usr/bin/install -c -m 644 .//embedding.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//embedding--0.3.5--0.3.6.sql .//embedding--0.3.5.sql .//embedding--0.3.6.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/embedding'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/embedding/\n",
            "/usr/bin/install -c -m 644 embedding.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 hnswalg.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 distfunc.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o embedding.index.bc embedding/embedding.bc embedding/hnswalg.bc embedding/distfunc.bc\n",
            "END: PG embedding COMPILATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo -u postgres psql -c \"DROP EXTENSION IF EXISTS embedding CASCADE\"\n",
        "\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "print('')\n",
        "print(\"Extensions Available:\")\n",
        "query_selection(\"SELECT name FROM pg_available_extensions order by 1\")\n",
        "print('')\n",
        "print(\"Extensions Used:\")\n",
        "query_selection(\"SELECT * FROM pg_extension\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3HFj_ZuNAKB",
        "outputId": "fb0205d5-8a58-483a-950b-63928f39335f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ALTER ROLE\n",
            "\n",
            "Extensions Available:\n",
            "Total rows are:   47\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  ('adminpack',)\n",
            "ROW 2:  ('amcheck',)\n",
            "ROW 3:  ('autoinc',)\n",
            "ROW 4:  ('bloom',)\n",
            "ROW 5:  ('btree_gin',)\n",
            "ROW 6:  ('btree_gist',)\n",
            "ROW 7:  ('citext',)\n",
            "ROW 8:  ('cube',)\n",
            "ROW 9:  ('dblink',)\n",
            "ROW 10:  ('dict_int',)\n",
            "ROW 11:  ('dict_xsyn',)\n",
            "ROW 12:  ('earthdistance',)\n",
            "ROW 13:  ('embedding',)\n",
            "ROW 14:  ('file_fdw',)\n",
            "ROW 15:  ('fuzzystrmatch',)\n",
            "ROW 16:  ('hstore',)\n",
            "ROW 17:  ('insert_username',)\n",
            "ROW 18:  ('intagg',)\n",
            "ROW 19:  ('intarray',)\n",
            "ROW 20:  ('isn',)\n",
            "ROW 21:  ('lo',)\n",
            "ROW 22:  ('ltree',)\n",
            "ROW 23:  ('moddatetime',)\n",
            "ROW 24:  ('old_snapshot',)\n",
            "ROW 25:  ('pageinspect',)\n",
            "ROW 26:  ('pg_buffercache',)\n",
            "ROW 27:  ('pg_freespacemap',)\n",
            "ROW 28:  ('pg_prewarm',)\n",
            "ROW 29:  ('pg_stat_statements',)\n",
            "ROW 30:  ('pg_surgery',)\n",
            "ROW 31:  ('pg_trgm',)\n",
            "ROW 32:  ('pg_visibility',)\n",
            "ROW 33:  ('pgcrypto',)\n",
            "ROW 34:  ('pgrowlocks',)\n",
            "ROW 35:  ('pgstattuple',)\n",
            "ROW 36:  ('plpgsql',)\n",
            "ROW 37:  ('postgres_fdw',)\n",
            "ROW 38:  ('refint',)\n",
            "ROW 39:  ('seg',)\n",
            "ROW 40:  ('sslinfo',)\n",
            "ROW 41:  ('tablefunc',)\n",
            "ROW 42:  ('tcn',)\n",
            "ROW 43:  ('tsm_system_rows',)\n",
            "ROW 44:  ('tsm_system_time',)\n",
            "ROW 45:  ('unaccent',)\n",
            "ROW 46:  ('uuid-ossp',)\n",
            "ROW 47:  ('xml2',)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n",
            "\n",
            "Extensions Used:\n",
            "Total rows are:   1\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  (13747, 'plpgsql', 10, 11, False, '1.0', None, None)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PostGRES SQL Settings\n",
        "import psycopg2 as ps\n",
        "\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "#!sudo -u postgres psql -c \"DROP EXTENSION vector CASCADE\"\n",
        "#!sudo -u postgres psql -c \"DROP EXTENSION embedding CASCADE\"\n",
        "\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION embedding\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id BIGSERIAL PRIMARY KEY, embedding real[])\"\n",
        "\n",
        "h=\"{1,2,3}\"\n",
        "hh= \"INSERT INTO documents(id, embedding) VALUES (1,'%s'), (2,'{4,5,6}')\"%h\n",
        "print(hh)\n",
        "\n",
        "#del insert_document\n",
        "insert_document(1,'{1,2,3}')\n",
        "insert_document(2,'{4,5,6}')\n",
        "\n",
        "#!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=3, efconstruction=5, efsearch=5)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuZRG19-INLa",
        "outputId": "5a29c107-dc51-4df3-a5d1-c53334f4b6ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ALTER ROLE\n",
            "CREATE EXTENSION\n",
            "ERROR:  table \"documents\" does not exist\n",
            "CREATE TABLE\n",
            "INSERT INTO documents(id, embedding) VALUES (1,'{1,2,3}'), (2,'{4,5,6}')\n",
            "INSERT EMBEDDING {1,2,3} successfully\n",
            "INSERT EMBEDDING {4,5,6} successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -pr /content/gdrive/MyDrive/tools/pgvector /content/\n",
        "%cd /content/pgvector/\n",
        "print()\n",
        "print('START: PG VECTOR COMPILATION')\n",
        "!make\n",
        "!make install\n",
        "#!make uninstall\n",
        "print('END: PG VECTOR COMPILATION')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vsRfc01GoSN",
        "outputId": "ad11dc54-e52e-4b64-c8db-af50f238b1b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pgvector\n",
            "\n",
            "START: PG VECTOR COMPILATION\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  vector.so '/usr/lib/postgresql/14/lib/vector.so'\n",
            "/usr/bin/install -c -m 644 .//vector.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//sql/vector--0.1.0--0.1.1.sql .//sql/vector--0.1.1--0.1.3.sql .//sql/vector--0.1.3--0.1.4.sql .//sql/vector--0.1.4--0.1.5.sql .//sql/vector--0.1.5--0.1.6.sql .//sql/vector--0.1.6--0.1.7.sql .//sql/vector--0.1.7--0.1.8.sql .//sql/vector--0.1.8--0.2.0.sql .//sql/vector--0.2.0--0.2.1.sql .//sql/vector--0.2.1--0.2.2.sql .//sql/vector--0.2.2--0.2.3.sql .//sql/vector--0.2.3--0.2.4.sql .//sql/vector--0.2.4--0.2.5.sql .//sql/vector--0.2.5--0.2.6.sql .//sql/vector--0.2.6--0.2.7.sql .//sql/vector--0.2.7--0.3.0.sql .//sql/vector--0.3.0--0.3.1.sql .//sql/vector--0.3.1--0.3.2.sql .//sql/vector--0.3.2--0.4.0.sql .//sql/vector--0.4.0--0.4.1.sql .//sql/vector--0.4.1--0.4.2.sql .//sql/vector--0.4.2--0.4.3.sql .//sql/vector--0.4.3--0.4.4.sql .//sql/vector--0.4.4--0.5.0.sql .//sql/vector--0.5.0--0.5.1.sql .//sql/vector--0.5.1.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/usr/bin/install -c -m 644   .//src/vector.h '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/vector'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnsw.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfflat.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfkmeans.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/vector.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o vector.index.bc vector/src/hnsw.bc vector/src/hnswbuild.bc vector/src/hnswinsert.bc vector/src/hnswscan.bc vector/src/hnswutils.bc vector/src/hnswvacuum.bc vector/src/ivfbuild.bc vector/src/ivfflat.bc vector/src/ivfinsert.bc vector/src/ivfkmeans.bc vector/src/ivfscan.bc vector/src/ivfutils.bc vector/src/ivfvacuum.bc vector/src/vector.bc\n",
            "END: PG VECTOR COMPILATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo -u postgres psql -c \"DROP EXTENSION IF EXISTS embedding CASCADE\"\n",
        "print('')\n",
        "print(\"Extensions Available:\")\n",
        "query_selection(\"SELECT name FROM pg_available_extensions order by 1\")\n",
        "print('')\n",
        "print(\"Extensions Used:\")\n",
        "query_selection(\"SELECT * FROM pg_extension\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_gzw1GqCbve",
        "outputId": "2493fc3b-69bd-4442-a552-017c1b0f4ece"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extensions Available:\n",
            "Total rows are:   48\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  ('adminpack',)\n",
            "ROW 2:  ('amcheck',)\n",
            "ROW 3:  ('autoinc',)\n",
            "ROW 4:  ('bloom',)\n",
            "ROW 5:  ('btree_gin',)\n",
            "ROW 6:  ('btree_gist',)\n",
            "ROW 7:  ('citext',)\n",
            "ROW 8:  ('cube',)\n",
            "ROW 9:  ('dblink',)\n",
            "ROW 10:  ('dict_int',)\n",
            "ROW 11:  ('dict_xsyn',)\n",
            "ROW 12:  ('earthdistance',)\n",
            "ROW 13:  ('embedding',)\n",
            "ROW 14:  ('file_fdw',)\n",
            "ROW 15:  ('fuzzystrmatch',)\n",
            "ROW 16:  ('hstore',)\n",
            "ROW 17:  ('insert_username',)\n",
            "ROW 18:  ('intagg',)\n",
            "ROW 19:  ('intarray',)\n",
            "ROW 20:  ('isn',)\n",
            "ROW 21:  ('lo',)\n",
            "ROW 22:  ('ltree',)\n",
            "ROW 23:  ('moddatetime',)\n",
            "ROW 24:  ('old_snapshot',)\n",
            "ROW 25:  ('pageinspect',)\n",
            "ROW 26:  ('pg_buffercache',)\n",
            "ROW 27:  ('pg_freespacemap',)\n",
            "ROW 28:  ('pg_prewarm',)\n",
            "ROW 29:  ('pg_stat_statements',)\n",
            "ROW 30:  ('pg_surgery',)\n",
            "ROW 31:  ('pg_trgm',)\n",
            "ROW 32:  ('pg_visibility',)\n",
            "ROW 33:  ('pgcrypto',)\n",
            "ROW 34:  ('pgrowlocks',)\n",
            "ROW 35:  ('pgstattuple',)\n",
            "ROW 36:  ('plpgsql',)\n",
            "ROW 37:  ('postgres_fdw',)\n",
            "ROW 38:  ('refint',)\n",
            "ROW 39:  ('seg',)\n",
            "ROW 40:  ('sslinfo',)\n",
            "ROW 41:  ('tablefunc',)\n",
            "ROW 42:  ('tcn',)\n",
            "ROW 43:  ('tsm_system_rows',)\n",
            "ROW 44:  ('tsm_system_time',)\n",
            "ROW 45:  ('unaccent',)\n",
            "ROW 46:  ('uuid-ossp',)\n",
            "ROW 47:  ('vector',)\n",
            "ROW 48:  ('xml2',)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n",
            "\n",
            "Extensions Used:\n",
            "Total rows are:   2\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  (13747, 'plpgsql', 10, 11, False, '1.0', None, None)\n",
            "ROW 2:  (16384, 'embedding', 10, 2200, True, '0.3.6', None, None)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PostGRES SQL Settings\n",
        "import psycopg2 as ps\n",
        "\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP EXTENSION embedding CASCADE\"\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION vector\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id BIGSERIAL PRIMARY KEY, embedding vector(3))\"\n",
        "\n",
        "insert_document(1,'[1,2,3]')\n",
        "insert_document(2,'[4,5,6]')\n",
        "\n",
        "!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw (embedding vector_l2_ops)\"\n",
        "\n",
        "#!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding ann_cos_ops) WITH (m=3)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXP1e65MejS3",
        "outputId": "d97be9c1-8bee-4c15-c8bb-3118e5544c34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ALTER ROLE\n",
            "DROP EXTENSION\n",
            "CREATE EXTENSION\n",
            "DROP TABLE\n",
            "CREATE TABLE\n",
            "INSERT EMBEDDING [1,2,3] successfully\n",
            "INSERT EMBEDDING [4,5,6] successfully\n",
            "CREATE INDEX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## <-> and <=> Euclidean (L2) and Cosine distances NO Manhattan distance: <~>\n",
        "query_selection(\"SELECT * FROM documents ORDER BY embedding::vector <-> '[3,1,2]' LIMIT 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k04syAHjJnWZ",
        "outputId": "d4af789e-0887-4b73-9648-55ecd157d0f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows are:   2\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  (1, '[1,2,3]')\n",
            "ROW 2:  (2, '[4,5,6]')\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('')\n",
        "print(\"Extensions Available:\")\n",
        "query_selection(\"SELECT name FROM pg_available_extensions order by 1\")\n",
        "print('')\n",
        "print(\"Extensions Used:\")\n",
        "query_selection(\"SELECT * FROM pg_extension\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cYNpki6VpeX",
        "outputId": "947ee743-f323-4dc7-e64d-75c69d4eda0d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extensions Available:\n",
            "Total rows are:   48\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  ('adminpack',)\n",
            "ROW 2:  ('amcheck',)\n",
            "ROW 3:  ('autoinc',)\n",
            "ROW 4:  ('bloom',)\n",
            "ROW 5:  ('btree_gin',)\n",
            "ROW 6:  ('btree_gist',)\n",
            "ROW 7:  ('citext',)\n",
            "ROW 8:  ('cube',)\n",
            "ROW 9:  ('dblink',)\n",
            "ROW 10:  ('dict_int',)\n",
            "ROW 11:  ('dict_xsyn',)\n",
            "ROW 12:  ('earthdistance',)\n",
            "ROW 13:  ('embedding',)\n",
            "ROW 14:  ('file_fdw',)\n",
            "ROW 15:  ('fuzzystrmatch',)\n",
            "ROW 16:  ('hstore',)\n",
            "ROW 17:  ('insert_username',)\n",
            "ROW 18:  ('intagg',)\n",
            "ROW 19:  ('intarray',)\n",
            "ROW 20:  ('isn',)\n",
            "ROW 21:  ('lo',)\n",
            "ROW 22:  ('ltree',)\n",
            "ROW 23:  ('moddatetime',)\n",
            "ROW 24:  ('old_snapshot',)\n",
            "ROW 25:  ('pageinspect',)\n",
            "ROW 26:  ('pg_buffercache',)\n",
            "ROW 27:  ('pg_freespacemap',)\n",
            "ROW 28:  ('pg_prewarm',)\n",
            "ROW 29:  ('pg_stat_statements',)\n",
            "ROW 30:  ('pg_surgery',)\n",
            "ROW 31:  ('pg_trgm',)\n",
            "ROW 32:  ('pg_visibility',)\n",
            "ROW 33:  ('pgcrypto',)\n",
            "ROW 34:  ('pgrowlocks',)\n",
            "ROW 35:  ('pgstattuple',)\n",
            "ROW 36:  ('plpgsql',)\n",
            "ROW 37:  ('postgres_fdw',)\n",
            "ROW 38:  ('refint',)\n",
            "ROW 39:  ('seg',)\n",
            "ROW 40:  ('sslinfo',)\n",
            "ROW 41:  ('tablefunc',)\n",
            "ROW 42:  ('tcn',)\n",
            "ROW 43:  ('tsm_system_rows',)\n",
            "ROW 44:  ('tsm_system_time',)\n",
            "ROW 45:  ('unaccent',)\n",
            "ROW 46:  ('uuid-ossp',)\n",
            "ROW 47:  ('vector',)\n",
            "ROW 48:  ('xml2',)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n",
            "\n",
            "Extensions Used:\n",
            "Total rows are:   2\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  (13747, 'plpgsql', 10, 11, False, '1.0', None, None)\n",
            "ROW 2:  (16414, 'vector', 10, 2200, True, '0.5.1', None, None)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Euclidean (L2) distance index:\n",
        "#CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=3, efconstruction=5, efsearch=5);\n",
        "#SET enable_seqscan = off;\n",
        "#SELECT id FROM documents ORDER BY embedding <-> array[3,3,3] LIMIT 1;\n",
        "\n",
        "# Cosine distance index:\n",
        "#CREATE INDEX ON documents USING hnsw(embedding ann_cos_ops) WITH (dims=3, m=3, efconstruction=5, efsearch=5);\n",
        "#SET enable_seqscan = off;\n",
        "#SELECT id FROM documents ORDER BY embedding <=> array[3,3,3] LIMIT 1;\n",
        "\n",
        "# Manhattan distance index:\n",
        "#CREATE INDEX ON documents USING hnsw(embedding ann_manhattan_ops) WITH (dims=3, m=3, efconstruction=5, efsearch=5);\n",
        "#SET enable_seqscan = off;\n",
        "#SELECT id FROM documents ORDER BY embedding <~> array[3,3,3] LIMIT 1;"
      ],
      "metadata": {
        "id": "DOe_mjxVmeNN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AWS - Document Upload"
      ],
      "metadata": {
        "id": "0vk3VbT-q4X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://platform.openai.com/docs/guides/text-generation\n",
        "%pip install openai==0.28  --root-user-action=ignore\n",
        "%pip install \"unstructured[all-docs]\"\n",
        "!pip install gradio --quiet\n",
        "!pip install xformer --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install pypdf\n",
        "%pip install tiktoken"
      ],
      "metadata": {
        "id": "2_UzTRgRsA7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "961a8556-20ec-4319-d4c6-435cb43c9b71"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting unstructured[all-docs]\n",
            "  Downloading unstructured-0.12.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (5.2.0)\n",
            "Collecting filetype (from unstructured[all-docs])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured[all-docs])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.11.2)\n",
            "Collecting emoji (from unstructured[all-docs])\n",
            "  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from unstructured[all-docs])\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting python-iso639 (from unstructured[all-docs])\n",
            "  Downloading python_iso639-2024.1.2-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured[all-docs])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (1.23.5)\n",
            "Collecting rapidfuzz (from unstructured[all-docs])\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured[all-docs])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (4.5.0)\n",
            "Collecting unstructured-client (from unstructured[all-docs])\n",
            "  Downloading unstructured_client-0.15.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (1.14.1)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs])\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Collecting pdfminer.six (from unstructured[all-docs])\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.5.2)\n",
            "Collecting python-pptx<=0.6.23 (from unstructured[all-docs])\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypandoc (from unstructured[all-docs])\n",
            "  Downloading pypandoc-1.12-py3-none-any.whl (20 kB)\n",
            "Collecting unstructured-inference==0.7.21 (from unstructured[all-docs])\n",
            "  Downloading unstructured_inference-0.7.21-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from unstructured[all-docs])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.2.1)\n",
            "Collecting pypdf (from unstructured[all-docs])\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msg-parser (from unstructured[all-docs])\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (2.0.1)\n",
            "Collecting python-docx (from unstructured[all-docs])\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (3.1.2)\n",
            "Collecting onnx (from unstructured[all-docs])\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]) (1.5.3)\n",
            "Collecting pikepdf (from unstructured[all-docs])\n",
            "  Downloading pikepdf-8.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[all-docs]) (0.20.2)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[all-docs]) (4.8.0.76)\n",
            "Collecting onnxruntime<1.16 (from unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[all-docs]) (4.35.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx<=0.6.23->unstructured[all-docs]) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<=0.6.23->unstructured[all-docs])\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[all-docs]) (23.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[all-docs]) (1.16.0)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured[all-docs])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[all-docs]) (4.66.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->unstructured[all-docs]) (3.20.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]) (41.0.7)\n",
            "Collecting Pillow>=3.3.2 (from python-pptx<=0.6.23->unstructured[all-docs])\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pikepdf->unstructured[all-docs])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[all-docs]) (2023.11.17)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured[all-docs])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting typing-extensions (from unstructured[all-docs])\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.16.0)\n",
            "Collecting coloredlogs (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[all-docs]) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[all-docs]) (1.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[all-docs]) (3.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[all-docs]) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[all-docs]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[all-docs]) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.7.21->unstructured[all-docs]) (2023.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (1.11.4)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading pdfplumber-0.10.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (0.16.0+cu121)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (2.0.7)\n",
            "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (2.1.0)\n",
            "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting pdfminer.six (from unstructured[all-docs])\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading pypdfium2-4.26.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[all-docs]) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[all-docs]) (3.1.1)\n",
            "Building wheels for collected packages: langdetect, iopath, antlr4-python3-runtime\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=c3a6c75ae64e0ef7b50a14dad210b391732fd47111bd303de5e68e6e9b10e2c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=5745a1c0c63bcd3a452421e64f6f47900c805560ff7f57e54f4f757cedb39110\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=97185db587b877cb0a8e3dbe88d990522ffe44c74c3d2e2fcdec9ca3f719826f\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built langdetect iopath antlr4-python3-runtime\n",
            "Installing collected packages: filetype, antlr4-python3-runtime, XlsxWriter, typing-extensions, rapidfuzz, python-multipart, python-magic, python-iso639, pypdfium2, pypdf, pypandoc, portalocker, Pillow, onnx, omegaconf, olefile, mypy-extensions, marshmallow, langdetect, jsonpath-python, humanfriendly, emoji, Deprecated, backoff, unstructured.pytesseract, typing-inspect, python-pptx, python-docx, pytesseract, pikepdf, pdf2image, msg-parser, iopath, coloredlogs, pdfminer.six, onnxruntime, dataclasses-json, unstructured-client, timm, pdfplumber, unstructured, layoutparser, effdet, unstructured-inference\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 Pillow-10.2.0 XlsxWriter-3.1.9 antlr4-python3-runtime-4.9.3 backoff-2.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.3 effdet-0.4.1 emoji-2.9.0 filetype-1.2.0 humanfriendly-10.0 iopath-0.1.10 jsonpath-python-1.0.6 langdetect-1.0.9 layoutparser-0.3.4 marshmallow-3.20.2 msg-parser-1.2.0 mypy-extensions-1.0.0 olefile-0.47 omegaconf-2.3.0 onnx-1.15.0 onnxruntime-1.15.1 pdf2image-1.17.0 pdfminer.six-20221105 pdfplumber-0.10.3 pikepdf-8.11.2 portalocker-2.8.2 pypandoc-1.12 pypdf-3.17.4 pypdfium2-4.26.0 pytesseract-0.3.10 python-docx-1.1.0 python-iso639-2024.1.2 python-magic-0.4.27 python-multipart-0.0.6 python-pptx-0.6.23 rapidfuzz-3.6.1 timm-0.9.12 typing-extensions-4.9.0 typing-inspect-0.9.0 unstructured-0.12.0 unstructured-client-0.15.2 unstructured-inference-0.7.21 unstructured.pytesseract-0.3.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.6/218.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/*.pdf\n",
        "!mkdir -p /content/data/\n",
        "%cd /content/data/\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urls = [\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    'AMZN-2022-Shareholder-Letter.pdf',\n",
        "    'AMZN-2021-Shareholder-Letter.pdf',\n",
        "    'AMZN-2020-Shareholder-Letter.pdf',\n",
        "    'AMZN-2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    dict(year=2022, source=filenames[0]),\n",
        "    dict(year=2021, source=filenames[1]),\n",
        "    dict(year=2020, source=filenames[2]),\n",
        "    dict(year=2019, source=filenames[3])]\n",
        "\n",
        "data_root = \"/content/data/\"\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "    file_path = data_root + filenames[idx]\n",
        "    #print(file_path)\n",
        "    urlretrieve(url, file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJGGZWI_q_Cb",
        "outputId": "3b59ca2a-8255-4789-def0-d5a8e40a1b4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader, PdfWriter\n",
        "import glob\n",
        "\n",
        "local_pdfs = glob.glob(data_root + '*.pdf')\n",
        "\n",
        "for local_pdf in local_pdfs:\n",
        "    pdf_reader = PdfReader(local_pdf)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for pagenum in range(len(pdf_reader.pages)-3):\n",
        "        page = pdf_reader.pages[pagenum]\n",
        "        pdf_writer.add_page(page)\n",
        "\n",
        "    with open(local_pdf, 'wb') as new_file:\n",
        "        new_file.seek(0)\n",
        "        pdf_writer.write(new_file)\n",
        "        new_file.truncate()"
      ],
      "metadata": {
        "id": "FwBAG6UprEbM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "#%cd /content/data\n",
        "\n",
        "documents = []\n",
        "\n",
        "for idx, file in enumerate(filenames):\n",
        "    loader = PyPDFLoader(data_root + file)\n",
        "    document = loader.load()\n",
        "    for document_fragment in document:\n",
        "        document_fragment.metadata = metadata[idx]\n",
        "\n",
        "    documents += document\n",
        "\n",
        "# - in our testing Character split works better with this PDF data set\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 100,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVN8KXBUrI7v",
        "outputId": "4b8f69f6-2317-4d34-a9ef-9699da586321"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Document Pages 25\n",
            "# of Document Chunks: 299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain and LLM Configurations"
      ],
      "metadata": {
        "id": "Yo-ZsxiyCl3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "#!pip install accelerate\n",
        "\n",
        "import torch\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#from transformers import AutoTokenizer, MistralForCausalLM"
      ],
      "metadata": {
        "id": "1ygWwhAGQkpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "9b73d8caee65433d9fbf4a77dfac8479",
            "85773392c21443fab535b4a8cd46d1ad",
            "9158a4083dc94f73bb578d1ebdcc5cc7",
            "ceb9e1568d644ce58cc53346a38d64de",
            "19ade79f5bd1409d8fb012c139fd3145",
            "d85e9b43698d424697bdb0289c7d73c3",
            "94b708a12dc441ba92b289a79bdd12dc",
            "1f6dc2554322498c9648d0fce18f1bde",
            "2f6267e3f2b349099c0c6190a5855e45",
            "63fd06f45fd14dbfb37705aabfe77cc2",
            "040a2bdc8cc24c2d92844ec643c81c5e",
            "c49e75306399440ba3c0b680b9f92b86",
            "9e624744e1b345349f8e73a2bf5faac0",
            "c18976d26d93402a8ccfc090c9925c1d",
            "bd4a67d2b569417ab29e97b2d1d3a9ca",
            "3ff3f769821148ea99c1e5cc61c51b33",
            "241c5a906c60489e897d93fe5400b632",
            "fbb5ee983b7b4b7693846509e425b763",
            "191cd338d63848edb9f84696058b72b3",
            "e3e2776cd34a455c9aed886017c233b7",
            "3dd7577f56df4ae79f8c6a0449941e8b",
            "24aa880ca5e84e1cb5db1b86307d1456",
            "dab774b45edb4c8fb96061c7052b857b",
            "bbe8f85d2a444af49e3082a644bc3064",
            "9501e2dbaa0b4fb8858af3f8eb7288c0",
            "fbf1f39541f7491c81554608a3778a76",
            "982a92675b66498b8f55851bdaba3aa6",
            "f09611584c5c42ddbe5a6a04dec38c9b",
            "4752584c9628442dbad6e6af29ddf891",
            "5e19b33a50904d32b6c8290900c73e7c",
            "560fbc05b41d4bb4954b5afcf02a712e",
            "b5b21dd7f1764e0d84a03b8df06bdfc4",
            "423b1f22ab6a4cc59619c6a0729fbebb",
            "62fe63946a624f0a9718b50191b7dc96",
            "31aee17746ce4abfaf7b1fe335086c3f",
            "82a34a1f34cd4ea4863b59cf64323301",
            "93a9341a2b9842bc96a847b58d1d9e18",
            "2bb4c9f5eca942a5ae6031a65a9e0fe9",
            "70d07c297f284ada9dcb0002ad501e98",
            "10051c111bf841b8b375133c974e4de9",
            "12ae13a6ae404993b981b64a10dc91d0",
            "d425cbba075249c0b7d7bd9dd1c52076",
            "fa10a6a0ec834703bb43fe276fdeda0b",
            "a2efba021c014000ac5c50414735e79f",
            "80eee3187a514ada97b2ba689a9bea67",
            "4551edba712142c5a5579c5d9fbc8f4c",
            "0638b778f1ca46d1ba14982a746bc85a",
            "fb9241e9a7c3484ba64279cd5b332a51",
            "5858f2c0a61d4f74bcce66035a60ff7f",
            "b791e4f1383c4f0ab91d2938f2352f2f",
            "eaa96ec6c8484924a65592b8c27ec269",
            "bc832591670f4be39f03981703661e35",
            "580c587d43f84bcca6f67c743e8f45af",
            "165f612f0dd5499f9e9732fa9e59b938",
            "06db9e8ee6764740a9faafd7ada717b5",
            "ca47ade1f3e045b9927c18294f3f8e61",
            "66034f94f5b5463982c05406ef45837b",
            "b9cd75023013441380a0a0c4f2ee8680",
            "49d50ec21d144cf2b95d3514375e35f7",
            "138be3b455044c7396863acaabaf6f02",
            "353197d73c9c43f5b65b1d9226c0f2a4",
            "f34eae76087d4ef19a68076d7478225b",
            "5e15520d102b4d829910dbc740ae8435",
            "729ef11ca5e044269c3906e53349d3af",
            "aa06597d09e24000af9d1b87686d4eb8",
            "62feaf3e1cf5462f924116e8490017b3",
            "24346810b7d14bba82bf49784787c895",
            "09e75e0ca6904f0093410991897be32a",
            "912060520a13467f823a0421b1d50226",
            "da1fb3a3975649c4ab190cf05096f2c7",
            "dfb15ae0536f48ed80d1012a0dea7265",
            "bdb03faa533b489da43c6a52766a57e4",
            "03b8f2680d5c40a896045764b9ac3ecf",
            "264abfcfc67a40c7994831d2012c1465",
            "eb9922c810774ed9a7a79b88c55900af",
            "45b34288b8344da6befe8383cfa42365",
            "4ef33f7e53ba4d358c67aef9dd846bf7",
            "e82cdff55de34577bb18d62fedf9750b",
            "7f0977936de240c7ad5534fcdba9a670",
            "573448466b074bfcaf4c06e92fe1e741",
            "a22ee6a98aa54b64be79ec83bcda1bb4",
            "d74ecfe862254277ac50edd61c42590f",
            "c35c9582637249a1baabf34d4cd86b78",
            "d19f384e0dec4fc2bc4714cd1d15659e",
            "786b92f2b6824734b8ee83f0542cd52e",
            "eeebda1c575948bf8641d168eed9be3e",
            "61d09af4aa20429596c65f4187d843c1",
            "9ff37d54ac1a438681f82af1a160014f",
            "587d7b09012a4c31b1372bc6bfe2a7e7",
            "67ff1b30e5fc4ea3b19ae0ccfb99c6b1",
            "51858ee06ae64b6e8004a8d782a9994d",
            "f66130b9c5c84aa7b589a771224ed413",
            "fe86a61546d642869da25063bf626c6a",
            "44867ce524194d9e968c2b44fb50a7a2",
            "efe4c5a6583342bda2a255ddcf35947e",
            "235fe9a9e0914f7088a5f11551fd646b",
            "9384599d090b4c2eaa211c7606689579",
            "f0ae45c4e42746d4a59c16db0c15fa94",
            "e0a50b8bee154b81bb71f7173b9bc1b8",
            "a330f1342f2649f5bea8fd35428c5630",
            "2e46411fc287425c8942f7e02aabaf57",
            "3350502752d947a0adaba53028f20c27",
            "46b119a0a59e452d9e930b834e717f89",
            "a8eddb3392cf4b10af7f34e531c64175",
            "54e6ce9ce5ee4d2284cbfbc4d1f4c3b8",
            "076cd988232a465ba725f525fbff8eb6",
            "448c74f1623f422f858153e62c1e69be",
            "32161545317b44e29ea0a0752ab1fea6",
            "c01a4c297d9045b99dcb2740f99e0a50",
            "ae81a95905b942b0859d761d31366b71",
            "597c3ce531ad4dc189c48585e703f16b",
            "a26f9926c4874d5abe7da9b0c31ddde4",
            "36a53bf32331444b8cdd518d6bd53375",
            "85836eb4051b4ca096be8c5176dc9fb0",
            "9c482f6441f74d7ba43e4d552ba3288a",
            "0ee42719a0bc4db4afc2d6085770ae74",
            "572cfe41cd424ea29860562a5222c711",
            "f96d1b3f52d54c719bee0fb6614c7d11",
            "ff19e8a2f1bd442098288992846587fd",
            "b184b99670d94c1a86168a8d3a612416",
            "62857f65be8f4f68a0e9f531e0c652e6"
          ]
        },
        "outputId": "4e533247-0bdb-4a8c-993a-9b62a17e4f13"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b73d8caee65433d9fbf4a77dfac8479"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c49e75306399440ba3c0b680b9f92b86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab774b45edb4c8fb96061c7052b857b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62fe63946a624f0a9718b50191b7dc96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80eee3187a514ada97b2ba689a9bea67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca47ade1f3e045b9927c18294f3f8e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24346810b7d14bba82bf49784787c895"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e82cdff55de34577bb18d62fedf9750b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "587d7b09012a4c31b1372bc6bfe2a7e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a330f1342f2649f5bea8fd35428c5630"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "597c3ce531ad4dc189c48585e703f16b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME='mistralai/Mistral-7B-Instruct-v0.1'\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 512\n",
        "generation_config.temperature = 0.9\n",
        "generation_config.top_p = 0.9\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "#model.to(device)\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "Ni9Z3osgRDtq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "OBoSd2ZSQmOK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Vector Queries"
      ],
      "metadata": {
        "id": "iqneJqxTciYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "import os\n",
        "collection_name='AWS'\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "\n",
        "%pip install colab-env\n",
        "import colab_env\n",
        "\n",
        "connection_string = os.getenv(\"DATABASE_URL\")\n",
        "\n",
        "# https://supabase.com/blog/fewer-dimensions-are-better-pgvector\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "#https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# PostGRES SQL Settings\n",
        "import psycopg2 as ps\n",
        "\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"DROP EXTENSION IF EXISTS vector CASCADE\"\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION embedding\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id BIGSERIAL PRIMARY KEY, embedding real[])\"\n",
        "\n",
        "h=\"{1,2,3}\"\n",
        "hh= \"INSERT INTO documents(id, embedding) VALUES (1,'%s'), (2,'{4,5,6}')\"%h\n",
        "print(hh)\n",
        "\n",
        "#del insert_document\n",
        "insert_document(1,'{1,2,3}')\n",
        "insert_document(2,'{4,5,6}')\n",
        "\n",
        "#!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=3, efconstruction=5, efsearch=5)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX9u6W4FqLgs",
        "outputId": "5aa91fc0-a0bc-4909-91f6-70f401c64082"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colab-env in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dotenv<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from colab-env) (0.21.1)\n",
            "/content\n",
            "/content\n",
            "NOTICE:  drop cascades to column embedding of table documents\n",
            "DROP EXTENSION\n",
            "CREATE EXTENSION\n",
            "DROP TABLE\n",
            "CREATE TABLE\n",
            "INSERT INTO documents(id, embedding) VALUES (1,'{1,2,3}'), (2,'{4,5,6}')\n",
            "INSERT EMBEDDING {1,2,3} successfully\n",
            "INSERT EMBEDDING {4,5,6} successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "#del embeddings\n",
        "print(\"Extension available\")\n",
        "query_selection(\"SELECT name FROM pg_available_extensions order by 1\")\n",
        "print()\n",
        "print(\"Extension used\")\n",
        "query_selection(\"SELECT * FROM pg_extension order by 1\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WAxu1Z2AX7R",
        "outputId": "75b18871-e790-4f6c-a86d-cfe25203be5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extension available\n",
            "Total rows are:   48\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  ('adminpack',)\n",
            "ROW 2:  ('amcheck',)\n",
            "ROW 3:  ('autoinc',)\n",
            "ROW 4:  ('bloom',)\n",
            "ROW 5:  ('btree_gin',)\n",
            "ROW 6:  ('btree_gist',)\n",
            "ROW 7:  ('citext',)\n",
            "ROW 8:  ('cube',)\n",
            "ROW 9:  ('dblink',)\n",
            "ROW 10:  ('dict_int',)\n",
            "ROW 11:  ('dict_xsyn',)\n",
            "ROW 12:  ('earthdistance',)\n",
            "ROW 13:  ('embedding',)\n",
            "ROW 14:  ('file_fdw',)\n",
            "ROW 15:  ('fuzzystrmatch',)\n",
            "ROW 16:  ('hstore',)\n",
            "ROW 17:  ('insert_username',)\n",
            "ROW 18:  ('intagg',)\n",
            "ROW 19:  ('intarray',)\n",
            "ROW 20:  ('isn',)\n",
            "ROW 21:  ('lo',)\n",
            "ROW 22:  ('ltree',)\n",
            "ROW 23:  ('moddatetime',)\n",
            "ROW 24:  ('old_snapshot',)\n",
            "ROW 25:  ('pageinspect',)\n",
            "ROW 26:  ('pg_buffercache',)\n",
            "ROW 27:  ('pg_freespacemap',)\n",
            "ROW 28:  ('pg_prewarm',)\n",
            "ROW 29:  ('pg_stat_statements',)\n",
            "ROW 30:  ('pg_surgery',)\n",
            "ROW 31:  ('pg_trgm',)\n",
            "ROW 32:  ('pg_visibility',)\n",
            "ROW 33:  ('pgcrypto',)\n",
            "ROW 34:  ('pgrowlocks',)\n",
            "ROW 35:  ('pgstattuple',)\n",
            "ROW 36:  ('plpgsql',)\n",
            "ROW 37:  ('postgres_fdw',)\n",
            "ROW 38:  ('refint',)\n",
            "ROW 39:  ('seg',)\n",
            "ROW 40:  ('sslinfo',)\n",
            "ROW 41:  ('tablefunc',)\n",
            "ROW 42:  ('tcn',)\n",
            "ROW 43:  ('tsm_system_rows',)\n",
            "ROW 44:  ('tsm_system_time',)\n",
            "ROW 45:  ('unaccent',)\n",
            "ROW 46:  ('uuid-ossp',)\n",
            "ROW 47:  ('vector',)\n",
            "ROW 48:  ('xml2',)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n",
            "\n",
            "Extension used\n",
            "Total rows are:   2\n",
            "Printing each row\n",
            "\n",
            "ROW 1:  (13747, 'plpgsql', 10, 11, False, '1.0', None, None)\n",
            "ROW 2:  (16523, 'embedding', 10, 2200, True, '0.3.6', None, None)\n",
            "\n",
            "QUERY SELECTION successfully\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = PGEmbedding.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs,\n",
        "    collection_name=collection_name,\n",
        "    connection_string=connection_string,\n",
        ")\n",
        "\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "\n",
        "#query = db.embedding_function.embed_query(query)\n",
        "results_with_scores = db.similarity_search_with_score(query)\n",
        "\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "W8OUhRQ3sYaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c148576-809b-41dd-cefd-ffd2999e12c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "Content: customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.52015233\n",
            "\n",
            "\n",
            "Content: in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52049184\n",
            "\n",
            "\n",
            "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52212244\n",
            "\n",
            "\n",
            "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52272516\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_query_byyear(query, year):\n",
        "\n",
        "    filter={\"year\": year}\n",
        "\n",
        "    results_with_scores = db.similarity_search_with_score(query,\n",
        "      filter=filter)\n",
        "\n",
        "    print()\n",
        "    print('Number of Results for the year %s: %s'%(year,len(results_with_scores)))\n",
        "    print()\n",
        "\n",
        "    if len(results_with_scores) == 0:\n",
        "        print('No results')\n",
        "        exit()\n",
        "        #print(\"-\" * 80)\n",
        "\n",
        "    for doc, score in results_with_scores:\n",
        "        print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n",
        "\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "G61u7U8XvpnY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year=2018\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "similarity_query_byyear(query, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3RHkYzZPiJ0",
        "outputId": "aa9cb3a7-5528-4c29-cc5d-2d67efdd0d4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "\n",
            "Number of Results for the year 2018: 0\n",
            "\n",
            "No results\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year=2019\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "similarity_query_byyear(query, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8nRQonbxVNO",
        "outputId": "46b4154b-be65-4f61-8f78-ee44867046b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "\n",
            "Number of Results for the year 2019: 4\n",
            "\n",
            "Content: AWS has been successful inincreasing the energy efficiency of its facilities and equipment, for instance by using more efficient evaporativecooling in certain data centers instead of traditional air conditioning. A study by 451 Research found that AWS’sinfrastructure is 3.6 times more energy efficient than the median U.S. enterprise data center surveyed. Along withour use of renewable energy, these factors enable AWS to do the same tasks as traditional data centers with an88% lower carbon footprint. And\n",
            "Metadata: {'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
            "Score: 0.5478576\n",
            "\n",
            "\n",
            "Content: institutionsaround the world are transitioning from in-person to virtual classrooms and are running on AWS to help ensurecontinuity of learning. And governments are leveraging AWS as a secure platform to build out new capabilitiesin their efforts to end this pandemic.\n",
            "Metadata: {'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
            "Score: 0.54788256\n",
            "\n",
            "\n",
            "Content: scalable, dependable, and highly secure computing power—whether for vital healthcare work, to help studentscontinue learning, or to keep unprecedented numbers of employees online and productive from home—is criticalin this situation. Hospital networks, pharmaceutical companies, and research labs are using AWS to care forpatients, explore treatments, and mitigate the impacts of COVID-19 in many other ways. Academic institutionsaround the world are transitioning from in-person to virtual classrooms and are\n",
            "Metadata: {'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
            "Score: 0.5816194\n",
            "\n",
            "\n",
            "Content: Service decide where best to allocate resources. InCanada, OTN—one of the world’s largest virtual care networks—is scaling its AWS-powered video service toaccommodate a 4,000% spike in demand to support citizens as the pandemic continues. In Brazil, AWS willprovide the São Paulo State Government with cloud computing infrastructure to guarantee online classes to1 million students in public schools across the state.\n",
            "Metadata: {'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
            "Score: 0.5957121\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year=2020\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "similarity_query_byyear(query, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pULzSE3ix_0Z",
        "outputId": "6ccec9f5-cbe0-49e6-ff1d-7d49eee4cb1a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "\n",
            "Number of Results for the year 2020: 4\n",
            "\n",
            "Content: 100 million smart home devices to Alexa. Amazon Web Services serves millions of customers and ended 2020\n",
            "with a $50 billion annualized run rate. In 1997, we hadn’t invented Prime, Marketplace, Alexa, or AWS.\n",
            "They weren’t even ideas then, and none was preordained. We took great risk with each one and put sweat\n",
            "and ingenuity into each one.\n",
            "Along the way, we’ve created $1.6 trillion of wealth for shareowners. Who are they? Y our Chair is one, and\n",
            "Metadata: {'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}\n",
            "Score: 0.59557676\n",
            "\n",
            "\n",
            "Content: To our shareowners:\n",
            "In Amazon’s 1997 letter to shareholders, our first, I talked about our hope to create an “enduring franchise,”\n",
            "one that would reinvent what it means to serve customers by unlocking the internet’s power. I noted that\n",
            "Amazon had grown from having 158 employees to 614, and that we had surpassed 1.5 million customer\n",
            "accounts. We had just gone public at a split-adjusted stock price of $1.50 per share. I wrote that it was Day 1.\n",
            "Metadata: {'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}\n",
            "Score: 0.61698914\n",
            "\n",
            "\n",
            "Content: their own cost $45 billion from AWS). The difficult part of this estimation exercise is that the direct cost\n",
            "reduction is the smallest portion of the customer benefit of moving to the cloud. The bigger benefit is the\n",
            "increased speed of software development – something that can significantly improve the customer’s\n",
            "competitiveness and top line. We have no reasonable way of estimating that portion of customer value\n",
            "Metadata: {'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}\n",
            "Score: 0.6175814\n",
            "\n",
            "\n",
            "Content: creation.\n",
            "AWS is challenging to estimate because each customer’s workload is so different, but we’ll do it anyway,\n",
            "acknowledging up front that the error bars are high. Direct cost improvements from operating in the cloud\n",
            "versus on premises vary, but a reasonable estimate is 30%. Across AWS’s entire 2020 revenue of $45 billion,\n",
            "that 30% would imply customer value creation of $19 billion (what would have cost them $64 billion on\n",
            "Metadata: {'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}\n",
            "Score: 0.6196974\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year=2021\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "similarity_query_byyear(query, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x-u0Pb_yG9O",
        "outputId": "ffa97626-7ef9-436d-be1f-c75399c39ad1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "\n",
            "Number of Results for the year 2021: 4\n",
            "\n",
            "Content: customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.5201462\n",
            "\n",
            "\n",
            "Content: from working with colleagues and technology on-premises to working remotely. AWS played amajor role in enabling this business continuity. Whether companies saw extraordinary demand spikes, ordemand diminish quickly with reduced external consumption, the cloud’s elasticity to scale capacity up anddown quickly, as well as AWS’s unusually broad functionality helped millions of companies adjust to thesedifficult circumstances.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.5375186\n",
            "\n",
            "\n",
            "Content: back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.5395614\n",
            "\n",
            "\n",
            "Content: kept triggering one of the biggest tensions in product development—where to draw the line on functionality inV1. One early meeting in particular—for our core compute service called Elastic Compute Cloud (“EC2”)—was scheduled for an hour, and took three, as we animatedly debated whether we could launch a computeservice without an accompanying persistent block storage companion (a form of network attached storage).\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.57546854\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year=2022\n",
        "query = \"How has AWS evolved?\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(query)\n",
        "similarity_query_byyear(query, year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0cpWFvpJwc4",
        "outputId": "087c190c-4732-4a0c-f116-9711647e406b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "How has AWS evolved?\n",
            "\n",
            "Number of Results for the year 2022: 4\n",
            "\n",
            "Content: in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5205088\n",
            "\n",
            "\n",
            "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52208495\n",
            "\n",
            "\n",
            "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5228049\n",
            "\n",
            "\n",
            "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5285147\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt and Completions Examples"
      ],
      "metadata": {
        "id": "yM9zL38DQuKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query1 = \"who is the President of the USA?\"\n",
        "query2 = \"Who won the baseball World Series in 2020? and Who Lost\"\n",
        "\n",
        "device=\"cuda\"\n",
        "def prompt_completion(query):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"%s\"%query}\n",
        "    ]\n",
        "\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "    #https://stackoverflow.com/questions/69609401/suppress-huggingface-logging-warning-setting-pad-token-id-to-eos-token-id\n",
        "\n",
        "    generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.batch_decode(generated_ids)\n",
        "    print()\n",
        "    print()\n",
        "    result=decoded[0].replace('<s> [INST] %s [/INST]'%query,\"\")\n",
        "    result=result.replace('</s>',\"\")\n",
        "    print('Prompt: %s'%query)\n",
        "    print('-'*80)\n",
        "    print('Answer: %s'%result)\n",
        "\n",
        "prompt_completion(query)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query1)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query2)\n",
        "\n",
        "query3 = \"what is the 20.5% of 40?\"\n",
        "query4 = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "query5 ='Which country has the most natural lakes? Answer with only the country name.'\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query3)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query4)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query5)\n",
        "\n",
        "\n",
        "query6 = \"How AWS has evolved?\"\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query6)\n",
        "\n",
        "query7 = \"Summarize this: Mistral LLM and Langchain intgegration. Overview and Tutorial with practical examples. Mistral LLM is a large language model developed by Mistral AI, a French startup making waves in\\\n",
        "the tech community. Mistral LLM is a decoder-based language model with 7 billion parameters, which makes it one of the most significant language models available. \\\n",
        "It uses sliding window attention, grouped query attention, and byte-fallback BPE tokenizer to achieve its impressive performance. \\\n",
        "Mistral LLM and Mistral LLM MoE 8x7B are language models developed by Mistral AI, a French startup. Mistral LLM is a decoder-based language model with 7 billion parameters, which makes it one of the most significant language models available. \\\n",
        "On the other hand, Mistral LLM MoE 8x7B[1c] is an open-weight model that employs a Mixture of Expert (MoE) architecture to generate human-like responses. While there is no direct information about the relationship between Mistral LLM and Mistral LLM MoE 8x7B, it is safe to assume that Mistral LLM MoE 8x7B is an extension of Mistral LLM. \\\n",
        "Mistral LLM MoE 8x7B is a larger model than Mistral LLM, with eight experts, each with seven billion parameters.\\\n",
        "Mistral LLM is designed for various natural language processing tasks, including text generation, summarization, and question-answering.\\\n",
        "It has outperformed other large language models, such as Llama 2 13B, on all benchmarks tested.\\\n",
        "Mistral LLM is available to developers via the gpt-4-vision-preview model and the Chat Completions API, which has been updated to support image inputs. \\\n",
        "The model can be used to understand images and answer questions about them. It is best at answering general questions about what is present in the pictures, but it is not yet optimized to answer detailed questions about the location of specific objects in an image.\\\n",
        "Mistral LLM is a significant step forward in natural language processing. Its impressive performance and large parameter count make it a powerful [3] tool for developers working on a wide range of NLP tasks.\\\n",
        "In summary, Mistral LLM is a powerful language model that has been shown to outperform other large language models on all benchmarks tested.\\\n",
        "It is available to developers via the gpt-4-vision-preview model and the Chat Completions API and can be used for a wide range of natural language processing tasks.\\\n",
        "Mistral LLM has been benchmarked against other large language models, such as Llama 2 13B, and it has been shown to outperform all benchmarks tested.\\In particular, Mistral 7B outperforms Llama 2 13B on all metrics measured and is on par with Llama 34B.\\\n",
        "It is important to note that the benchmarks used to compare these models can vary widely, and the results may not be directly comparable.\\\n",
        "However, the fact that Mistral LLM has been shown to outperform other large language models on multiple benchmarks is a testament to its impressive performance.\\\n",
        "LangChain is an open-source AI abstraction library that easily integrates large language models (LLMs) like GPT-4/LLaMa 2 into applications.\\\n",
        "LangChain provides a simplified framework for querying LLMs to generate text, code, translations, and more using Python [9]. LangChain is a generic interface for nearly any LLM, providing a centralized development environment to build and integrate LLM applications with external data sources and software workflows.\\LangChain's integration with LLMs like OpenAI, Cohere, and Hugging Face is fundamental to its functionality [11].\\\n",
        "Mistral LLM is a large language model developed by Mistral AI that has been shown to outperform other large language models, such as Llama 2 13B, on all benchmarks tested.\\\n",
        "Mistral LLM is available to developers via the gpt-4-vision-preview model and the Chat Completions API, which has been updated to support image inputs [12].\\\n",
        "The model can be used to understand images and answer questions about them.\\\n",
        "While there is no direct information about the integration of LangChain and Mistral LLM, LangChain's ability to integrate with nearly any LLM suggests that it can be used with Mistral LLM.\\\n",
        "The combination of LangChain and Mistral LLM could provide a powerful tool for developers working on natural language processing tasks [9-14]. However, it is essential to consider the model's limitations as you explore what use cases it can apply to.\\\n",
        "As an illustration of how the concepts and terms mentioned above work together, we implemented a jyputer notebook thoroughly tested in Google Colab based on GPU T4 devices.\\\n",
        "The notebook covers how we can use Langchain using OpenAI embedding and a PostgreSQL extension called pg_embedding to upload actual documents from AWS S3.\\\n",
        "Also, as a model for LLM, we used mistral/Mistral-7B-v0.1 from the hugging face repository, which created an entire open-source integrated ecosystem to support generative AI solutions.\\\n",
        "I also share a notebook of using MLxDL/Mistral_IN_AWS.ipynb at main · frank-morales2020/MLxDL (github.com)\\\n",
        "You can access this case in my GitHub ML/DL development repository shown below: MLxDL/Mistral_Integration_with_Langchain_PostgreSQL.ipynb at main · frank-morales2020/MLxDL (github.com)\"\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owzp3YYXo-dp",
        "outputId": "f6214c98-42f4-41c3-db7d-2787641353f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Prompt: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Let's reason through this problem step-by-step:\n",
            "\n",
            "1. We know that you bought an ice cream for 6 kids, and each cone cost $1.25. So, the total cost of the ice creams is 6 * $1.25 = $7.50.\n",
            "2. You paid for the ice creams with a $10 bill. Now, we need to determine how much change you received.\n",
            "3. To do this, subtract the total cost of the ice creams from the amount you paid: $10 - $7.50 = $2.50.\n",
            "\n",
            "So, you got back $2.50 in change.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: who is the President of the USA?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  As of my knowledge up to January 31, 2022, the current President of the United States of America is Joe Biden. However, please verify against real-time information sources for accuracy, as this knowledge cutoff date may no longer be up-to-date.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Who won the baseball World Series in 2020? and Who Lost\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  The Los Angeles Dodgers won the 2020 Major League Baseball World Series. They defeated the Tampa Bay Rays in seven games to win their first title since 1988, breaking an 81-year curse. The Dodgers were named the champions despite playing in an empty stadium due to the COVID-19 pandemic.\n",
            "\n",
            "The Tampa Bay Rays were the runners-up in the 2020 World Series. Despite having a strong season, and making their first World Series appearance in franchise history, they fell short to the Dodgers in the end.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: what is the 20.5% of 40?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  The 20.5% of 40 can be calculated by multiplying 40 by 0.205, which gives you the result of 8.2. So, 20.5% of 40 is 8.2.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: As a data scientist, can you explain the concept of regularization in machine learning?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Certainly! Regularization is a technique used in machine learning to prevent overfitting of models. Overfitting occurs when the model becomes too complex and starts to capture noise in the training data rather than the underlying patterns. As a result, the model may perform well on the training data but may not generalize well to new, unseen data. \n",
            "\n",
            "Regularization works by adding a penalty term to the cost function that the model tries to minimize. This penalty term discourages the model from using complex features or fitting the noise in the data. The strength of the penalty is controlled by a hyperparameter, and the amount of regularization used is determined through cross-validation or another technique. \n",
            "\n",
            "There are two main types of regularization: L1 (Lasso) regularization and L2 (Ridge) regularization. L1 regularization adds a penalty of the absolute value of the coefficients, which tends to sparsify the model by setting some coefficients to zero. L2 regularization, on the other hand, adds a penalty of the square of the coefficients, which tends to shrink the coefficients towards zero but not all the way to zero. \n",
            "\n",
            "In summary, regularization is a powerful technique that can help improve the generalization performance of machine learning models by preventing overfitting.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Which country has the most natural lakes? Answer with only the country name.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Canada\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: How AWS has evolved?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  AWS, or Amazon Web Services, has been around for nearly two decades and has grown in many ways over the years. Here are a few key ways that AWS has evolved:\n",
            "\n",
            "1. Cloud computing platform: AWS was founded as a cloud computing platform that provided infrastructure as a service (IaaS) to businesses. Today, AWS offers a wide range of cloud computing services, including IaaS, platform as a service (PaaS), and software as a service (SaaS), as well as various tools and services that help businesses build, run, and manage applications.\n",
            "2. Services: AWS has expanded its service offerings to include a wide range of services that help businesses with different needs. These include compute, storage, databases, networking, analytics, machine learning, and artificial intelligence, among others.\n",
            "3. Global reach: AWS has a global presence, with 70 availability zones and 54 regions around the world. This means that businesses can deploy applications and services to run on AWS in multiple regions, ensuring high availability and resilience.\n",
            "4. Innovation: AWS is known for its innovation and constant improvement. The company frequently releases new products and services to help businesses stay ahead of the curve.\n",
            "5. Security: AWS has a strong focus on security and has implemented various measures to ensure the security of its services and customer data. AWS is also compliant with various security standards and certifications, including HIPAA, PCI DSS, and ISO 27001.\n",
            "\n",
            "Overall, AWS has evolved from a simple cloud computing platform to a comprehensive cloud computing services provider with a global reach and a focus on innovation and security.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Summarize this: Mistral LLM and Langchain intgegration. Overview and Tutorial with practical examples. Mistral LLM is a large language model developed by Mistral AI, a French startup making waves inthe tech community. Mistral LLM is a decoder-based language model with 7 billion parameters, which makes it one of the most significant language models available. It uses sliding window attention, grouped query attention, and byte-fallback BPE tokenizer to achieve its impressive performance. Mistral LLM and Mistral LLM MoE 8x7B are language models developed by Mistral AI, a French startup. Mistral LLM is a decoder-based language model with 7 billion parameters, which makes it one of the most significant language models available. On the other hand, Mistral LLM MoE 8x7B[1c] is an open-weight model that employs a Mixture of Expert (MoE) architecture to generate human-like responses. While there is no direct information about the relationship between Mistral LLM and Mistral LLM MoE 8x7B, it is safe to assume that Mistral LLM MoE 8x7B is an extension of Mistral LLM. Mistral LLM MoE 8x7B is a larger model than Mistral LLM, with eight experts, each with seven billion parameters.Mistral LLM is designed for various natural language processing tasks, including text generation, summarization, and question-answering.It has outperformed other large language models, such as Llama 2 13B, on all benchmarks tested.Mistral LLM is available to developers via the gpt-4-vision-preview model and the Chat Completions API, which has been updated to support image inputs. The model can be used to understand images and answer questions about them. It is best at answering general questions about what is present in the pictures, but it is not yet optimized to answer detailed questions about the location of specific objects in an image.Mistral LLM is a significant step forward in natural language processing. Its impressive performance and large parameter count make it a powerful [3] tool for developers working on a wide range of NLP tasks.In summary, Mistral LLM is a powerful language model that has been shown to outperform other large language models on all benchmarks tested.It is available to developers via the gpt-4-vision-preview model and the Chat Completions API and can be used for a wide range of natural language processing tasks.Mistral LLM has been benchmarked against other large language models, such as Llama 2 13B, and it has been shown to outperform all benchmarks tested.\\In particular, Mistral 7B outperforms Llama 2 13B on all metrics measured and is on par with Llama 34B.It is important to note that the benchmarks used to compare these models can vary widely, and the results may not be directly comparable.However, the fact that Mistral LLM has been shown to outperform other large language models on multiple benchmarks is a testament to its impressive performance.LangChain is an open-source AI abstraction library that easily integrates large language models (LLMs) like GPT-4/LLaMa 2 into applications.LangChain provides a simplified framework for querying LLMs to generate text, code, translations, and more using Python [9]. LangChain is a generic interface for nearly any LLM, providing a centralized development environment to build and integrate LLM applications with external data sources and software workflows.\\LangChain's integration with LLMs like OpenAI, Cohere, and Hugging Face is fundamental to its functionality [11].Mistral LLM is a large language model developed by Mistral AI that has been shown to outperform other large language models, such as Llama 2 13B, on all benchmarks tested.Mistral LLM is available to developers via the gpt-4-vision-preview model and the Chat Completions API, which has been updated to support image inputs [12].The model can be used to understand images and answer questions about them.While there is no direct information about the integration of LangChain and Mistral LLM, LangChain's ability to integrate with nearly any LLM suggests that it can be used with Mistral LLM.The combination of LangChain and Mistral LLM could provide a powerful tool for developers working on natural language processing tasks [9-14]. However, it is essential to consider the model's limitations as you explore what use cases it can apply to.As an illustration of how the concepts and terms mentioned above work together, we implemented a jyputer notebook thoroughly tested in Google Colab based on GPU T4 devices.The notebook covers how we can use Langchain using OpenAI embedding and a PostgreSQL extension called pg_embedding to upload actual documents from AWS S3.Also, as a model for LLM, we used mistral/Mistral-7B-v0.1 from the hugging face repository, which created an entire open-source integrated ecosystem to support generative AI solutions.I also share a notebook of using MLxDL/Mistral_IN_AWS.ipynb at main · frank-morales2020/MLxDL (github.com)You can access this case in my GitHub ML/DL development repository shown below: MLxDL/Mistral_Integration_with_Langchain_PostgreSQL.ipynb at main · frank-morales2020/MLxDL (github.com)\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  In summary, Mistral LLM is a large language model developed by Mistral AI that outperforms other large language models on all benchmarks tested. It is available to developers via the gpt-4-vision-preview model and the Chat Completions API and is suitable for a wide range of natural language processing tasks. LangChain is an open-source AI abstraction library that integrates large language models like GPT-4/LLaMa 2 into applications, providing a simplified framework for querying LLMs. While there is no direct information about the integration of LangChain and Mistral LLM, it is possible to use LangChain with Mistral LLM. A comprehensive tutorial is provided, demonstrating how to use LangChain with OpenAI embedding and a PostgreSQL extension called pg_embedding to upload actual documents from AWS S3 and how to use Mistral LLM for text generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\"\n",
        "def prompt_completion(query):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"%s\"%query}\n",
        "    ]\n",
        "\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "    #https://stackoverflow.com/questions/69609401/suppress-huggingface-logging-warning-setting-pad-token-id-to-eos-token-id\n",
        "\n",
        "    generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.batch_decode(generated_ids)\n",
        "    print()\n",
        "    print()\n",
        "    result=decoded[0].replace('<s> [INST] %s [/INST]'%query,\"\")\n",
        "    result=result.replace('</s>',\"\")\n",
        "    print('Prompt: %s'%query)\n",
        "    print('-'*80)\n",
        "    print('Answer: %s'%result)"
      ],
      "metadata": {
        "id": "afU4WRZlCRH-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query8= \"Summarize this: Introduction In the realm of artificial intelligence (AI[1]) and machine learning (ML), \\\n",
        "three concepts have emerged as significant game-changers: \\ Vector Databases[2], Retrieval Augmented Generation (RAG[3]), \\\n",
        "and Semantic Search[4]. These technologies have revolutionized how we store, retrieve, and interpret data, paving the way for more \\\n",
        "intelligent and efficient systems.\\Vector Database A Vector Database is a type of database that stores data as high-dimensional vectors[5]. \\\n",
        "These databases provide the ability to store and retrieve vectors as high-dimensional points. They add capabilities for efficient and \\\n",
        "fast-looking nearest neighbours in the N-dimensional space. They are typically powered by k-nearest neighbour (k-NN) indexes and \\\n",
        "built with algorithms like the Hierarchical Navigable Small World (HNSW) and Inverted File Index (IVF) algorithms. Vector databases \\\n",
        "are typically used to power vector search cases like visual, semantic, and multimodal search. In computer science, an Inverted Index, \\\n",
        "also referred to as a postings list, postings file, or inverted file, is a database index that stores a mapping from content, such as \\\n",
        "words or numbers, to its locations in a table[6], document or a set of documents. This contrasts with a forward index, which maps from \\\n",
        "documents to content. An inverted index allows fast full-text searches at increased processing costs when a document is added to the database. \\\n",
        "It is the most popular data structure used in document retrieval systems, used on a large scale, for example, in search engines[7].\\\n",
        "There are two main variants of inverted indexes: A record-level inverted index contains a list of references to documents for each word[8]. \\\n",
        "A word-level inverted index also contains each word’s position within a document. The latter form offers more functionality (like phrase searches) \\\n",
        "but needs more processing power and space to be created[8]. The inverted index data structure is a central component of a typical search engine \\\n",
        "indexing algorithm. A goal of a search engine implementation is to optimize the speed of the query: find the documents where word X occurs. \\\n",
        "Once a forward index is developed, which stores lists of words per document, it is next inverted[9] to create an inverted index. Querying \\\n",
        "the forward index would require sequential iteration through each document and to each word to verify a matching document. The time, memory, \\\n",
        "and processing resources to perform such a query are only sometimes technically realistic. Instead of listing the words per document in the forward \\\n",
        "index, the inverted index data structure, which lists the documents per word, is developed. With the inverted index created, the query can be resolved \\\n",
        "by jumping to the word ID (via random access) in the inverted index. In bioinformatics, inverted indexes are crucial in the sequence assembly of short \\\n",
        "fragments of sequenced DNA. One way to find the source of a fragment is to search for it against a reference DNA sequence. \\\n",
        "A small number of mismatches (due to differences between the sequenced DNA and reference DNA, or errors) can be accounted for by dividing the fragment\\\n",
        "into smaller fragments — at least one subfragment is likely to match the reference DNA sequence. \\\n",
        "The matching requires constructing an inverted index of all substrings of a certain length from the reference DNA sequence. Retrieval Augmented Generation (RAG)\\\n",
        "Retrieval Augmented Generation (RAG) is a pattern that works with pre-trained Large Language Models (LLM) and your data to generate responses. \\\n",
        "RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, \\\n",
        "up-to-date information and to give users insight into LLMs’ generative process. It ensures that the model has access to the most current, \\\n",
        "reliable facts and that users have access to its sources, ensuring that its claims can be checked for accuracy and ultimately trusted[10][11].\\\n",
        "RAG is an AI framework that augments the capabilities of a Large Language Model (LLM) like GPT-4 by adding an information retrieval system \\\n",
        "that provides grounding data. This means you can constrain generative AI to your enterprise content sourced from vectorized documents, images, audio, \\\n",
        "and video[5]. Semantic Search Semantic search is a search engine technology that interprets the meaning of words and phrases[12]. \\\n",
        "It seeks to improve search accuracy by understanding the searcher’s intent and the contextual meaning of terms as they appear in the searchable[13] \\\n",
        "database. The results of a semantic search will return content matching the meaning of a query instead of content that matches words in the query. \\\n",
        "Applications with Test Cases As an illustration of how to implement those three concepts, we are using some modified notebooks that I adapted to be \\\n",
        "run with Google Colab. Google Colab, or “Collaboratory,” is a free online service allowing you to run Python code in your browser with access to GPUs \\\n",
        "and TPUs. RAG is a pattern that generates responses with pre-trained LLM and your data. RAG is an AI framework for retrieving facts from an external \\\n",
        "knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs’ generative \\\n",
        "process. It ensures that the model has access to the most current, reliable facts and that users have access to its sources, ensuring that its \\\n",
        "claims can be checked for accuracy and ultimately trusted. In AI’s context, Vector Databases and RAG play crucial roles. Vector Databases efficiently \\\n",
        "store and retrieve high-dimensional data, essential for many AI applications. On the other hand, RAG improves the quality of responses generated \\\n",
        "by Large Language Models by grounding the model on external sources of knowledge[9]. Two examples of using both RAG with vector DataBase and OpenAI API \\\n",
        "embeddings are in the notebooks below, which I modified based on OpenAI models gpt-3.5-turbo-0613 (GPT-3.5) and gpt-4–0613(GPT-4), respectively. \\\n",
        "Notebook with OpenAI MODEL GPT-3.5 Notebook with OpenAI MODEL GPT-4 The Notebooks were tested successfully in the Google Cloud using Google Colab. \\\n",
        "The audience will also learn how to use and install PostgreSQL with the pgvector extension in Google Colab and securely use the OpenAI KEY \\\n",
        "in the Google Cloud. The pgvector extension is a powerful tool that turns PostgreSQL into a vector database. It introduces a dedicated data type, \\\n",
        "operators, and functions that enable efficient storage, manipulation, and analysis of vector data directly within the PostgreSQL database[14]. \\\n",
        "Here are some key features and use cases: Vector storage: The pgvector extension lets you store high-dimensional vectors in PostgreSQL tables. \\\n",
        "It provides a dedicated data type for vector representation, allowing efficient storage and retrieval of vector data. Similarity search: With pgvector, \\\n",
        "you can perform similarity searches based on vector similarity metrics such as cosine similarity or Euclidean distance. \\\n",
        "Natural Language Processing (NLP) and text analysis: pgvector is particularly useful in NLP applications. It allows you to represent \\\n",
        "text documents as vectors using word embeddings or document embeddings. Computer vision: The pgvector extension can handle vector \\\n",
        "representations of images and enable similarity-based image search. Conclusion In conclusion, Vector Databases, Retrieval Augmented Generation, \\\n",
        "and Semantic Search are three powerful technologies shaping AI and ML’s future. By enabling more efficient data storage and retrieval, \\\n",
        "grounding AI models in reliable facts, and interpreting search queries more meaningfully, these technologies pave the way for more intelligent and \\\n",
        "efficient systems. We expect to see more innovative applications and use cases emerge as these technologies evolve.\"\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQkjfWN08G1s",
        "outputId": "a4b33361-a85f-4308-98c2-d302b8fce7c2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Summarize this: Introduction In the realm of artificial intelligence (AI[1]) and machine learning (ML), three concepts have emerged as significant game-changers: \\ Vector Databases[2], Retrieval Augmented Generation (RAG[3]), and Semantic Search[4]. These technologies have revolutionized how we store, retrieve, and interpret data, paving the way for more intelligent and efficient systems.\\Vector Database A Vector Database is a type of database that stores data as high-dimensional vectors[5]. These databases provide the ability to store and retrieve vectors as high-dimensional points. They add capabilities for efficient and fast-looking nearest neighbours in the N-dimensional space. They are typically powered by k-nearest neighbour (k-NN) indexes and built with algorithms like the Hierarchical Navigable Small World (HNSW) and Inverted File Index (IVF) algorithms. Vector databases are typically used to power vector search cases like visual, semantic, and multimodal search. In computer science, an Inverted Index, also referred to as a postings list, postings file, or inverted file, is a database index that stores a mapping from content, such as words or numbers, to its locations in a table[6], document or a set of documents. This contrasts with a forward index, which maps from documents to content. An inverted index allows fast full-text searches at increased processing costs when a document is added to the database. It is the most popular data structure used in document retrieval systems, used on a large scale, for example, in search engines[7].There are two main variants of inverted indexes: A record-level inverted index contains a list of references to documents for each word[8]. A word-level inverted index also contains each word’s position within a document. The latter form offers more functionality (like phrase searches) but needs more processing power and space to be created[8]. The inverted index data structure is a central component of a typical search engine indexing algorithm. A goal of a search engine implementation is to optimize the speed of the query: find the documents where word X occurs. Once a forward index is developed, which stores lists of words per document, it is next inverted[9] to create an inverted index. Querying the forward index would require sequential iteration through each document and to each word to verify a matching document. The time, memory, and processing resources to perform such a query are only sometimes technically realistic. Instead of listing the words per document in the forward index, the inverted index data structure, which lists the documents per word, is developed. With the inverted index created, the query can be resolved by jumping to the word ID (via random access) in the inverted index. In bioinformatics, inverted indexes are crucial in the sequence assembly of short fragments of sequenced DNA. One way to find the source of a fragment is to search for it against a reference DNA sequence. A small number of mismatches (due to differences between the sequenced DNA and reference DNA, or errors) can be accounted for by dividing the fragmentinto smaller fragments — at least one subfragment is likely to match the reference DNA sequence. The matching requires constructing an inverted index of all substrings of a certain length from the reference DNA sequence. Retrieval Augmented Generation (RAG)Retrieval Augmented Generation (RAG) is a pattern that works with pre-trained Large Language Models (LLM) and your data to generate responses. RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs’ generative process. It ensures that the model has access to the most current, reliable facts and that users have access to its sources, ensuring that its claims can be checked for accuracy and ultimately trusted[10][11].RAG is an AI framework that augments the capabilities of a Large Language Model (LLM) like GPT-4 by adding an information retrieval system that provides grounding data. This means you can constrain generative AI to your enterprise content sourced from vectorized documents, images, audio, and video[5]. Semantic Search Semantic search is a search engine technology that interprets the meaning of words and phrases[12]. It seeks to improve search accuracy by understanding the searcher’s intent and the contextual meaning of terms as they appear in the searchable[13] database. The results of a semantic search will return content matching the meaning of a query instead of content that matches words in the query. Applications with Test Cases As an illustration of how to implement those three concepts, we are using some modified notebooks that I adapted to be run with Google Colab. Google Colab, or “Collaboratory,” is a free online service allowing you to run Python code in your browser with access to GPUs and TPUs. RAG is a pattern that generates responses with pre-trained LLM and your data. RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs’ generative process. It ensures that the model has access to the most current, reliable facts and that users have access to its sources, ensuring that its claims can be checked for accuracy and ultimately trusted. In AI’s context, Vector Databases and RAG play crucial roles. Vector Databases efficiently store and retrieve high-dimensional data, essential for many AI applications. On the other hand, RAG improves the quality of responses generated by Large Language Models by grounding the model on external sources of knowledge[9]. Two examples of using both RAG with vector DataBase and OpenAI API embeddings are in the notebooks below, which I modified based on OpenAI models gpt-3.5-turbo-0613 (GPT-3.5) and gpt-4–0613(GPT-4), respectively. Notebook with OpenAI MODEL GPT-3.5 Notebook with OpenAI MODEL GPT-4 The Notebooks were tested successfully in the Google Cloud using Google Colab. The audience will also learn how to use and install PostgreSQL with the pgvector extension in Google Colab and securely use the OpenAI KEY in the Google Cloud. The pgvector extension is a powerful tool that turns PostgreSQL into a vector database. It introduces a dedicated data type, operators, and functions that enable efficient storage, manipulation, and analysis of vector data directly within the PostgreSQL database[14]. Here are some key features and use cases: Vector storage: The pgvector extension lets you store high-dimensional vectors in PostgreSQL tables. It provides a dedicated data type for vector representation, allowing efficient storage and retrieval of vector data. Similarity search: With pgvector, you can perform similarity searches based on vector similarity metrics such as cosine similarity or Euclidean distance. Natural Language Processing (NLP) and text analysis: pgvector is particularly useful in NLP applications. It allows you to represent text documents as vectors using word embeddings or document embeddings. Computer vision: The pgvector extension can handle vector representations of images and enable similarity-based image search. Conclusion In conclusion, Vector Databases, Retrieval Augmented Generation, and Semantic Search are three powerful technologies shaping AI and ML’s future. By enabling more efficient data storage and retrieval, grounding AI models in reliable facts, and interpreting search queries more meaningfully, these technologies pave the way for more intelligent and efficient systems. We expect to see more innovative applications and use cases emerge as these technologies evolve.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Vector Databases are a type of database that stores data as high-dimensional vectors, with the ability to efficiently and quickly find similar vectors. They use k-nearest neighbor (k-NN) indexes, such as the Hierarchical Navigable Small World (HNSW) and Inverted File Index (IVF) algorithms, and are used for a variety of search cases, including visual, semantic, and multi-modal search.\n",
            "\n",
            "Retrieval Augmented Generation (RAG) is a pattern that works with pre-trained Large Language Models (LLMs) to generate responses, by adding an information retrieval system that provides grounding data to ensure that the model has access to the most current, reliable facts and the users have access to its sources.\n",
            "\n",
            "Semantic Search is a search engine technology that interprets the meaning of words and phrases, seeking to improve search accuracy by understanding the searcher's intent and the contextual meaning of terms as they appear in the searchable database. Instead of returning content that matches words in the query, the results of a semantic search will return content matching the meaning of the query.\n",
            "\n",
            "Examples of using RAG with vector DataBase and OpenAI API embeddings include notebooks using OpenAI models gpt-3.5-turbo-0613 (GPT-3.5) and gpt-4–0613(GPT-4), both tested successfully in the Google Cloud using Google Colab. The audience will also learn how to use and install PostgreSQL with the pgvector extension in Google Colab, securely using the OpenAI KEY in the Google Cloud.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token = os.getenv(\"HF_TOKEN\")\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import BitsAndBytesConfig, GenerationConfig, pipeline\n",
        "from transformers import AutoTokenizer, MistralForCausalLM\n",
        "\n",
        "#model = MistralForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\",padding_side=\"left\")\n",
        "#tokenizer.pad_token = tokenizer.eos_token # Most LLMs don't have a pad token by default\n",
        "\n",
        "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# https://github.com/huggingface/transformers/blob/main/src/transformers/models/mistral/modeling_mistral.py\n",
        "\n",
        "# Generate\n",
        "#print()\n",
        "#generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
        "\n",
        "#generate_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "#                pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "#response=tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "#print(response)\n",
        "print()\n",
        "\n",
        "#query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query=\"What is your favourite condiment?\"\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"%s\"%query},\n",
        "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
        "]\n",
        "\n",
        "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "model_inputs = encodeds.to(device)\n",
        "#model.to(device)\n",
        "\n",
        "generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "                pad_token_id=tokenizer.eos_token_id)\n",
        "decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "id": "AY3FuMUBU-9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba07a14e-1b20-470c-fc96-4efb646541dd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!  [INST] Do you have mayonnaise recipes? [/INST] Yes, I'd be happy to share a simple mayonnaise recipe with you! Here it is:\n",
            "\n",
            "Ingredients:\n",
            "\n",
            "* 2 large egg yolks\n",
            "* 1 tablespoon Dijon mustard\n",
            "* 1 tablespoon white vinegar\n",
            "* 1/4 teaspoon salt\n",
            "* 2/3 cup vegetable oil\n",
            "* 1/4 cup olive oil\n",
            "* Salt and pepper to taste\n",
            "\n",
            "Instructions:\n",
            "1. In a small bowl, whisk together the egg yolks, Dijon mustard, white vinegar, and salt.\n",
            "2. Slowly stream in the vegetable oil while whisking, starting with a few drops at a time to prevent the egg mixture from curdling.\n",
            "3. Once the vegetable oil is fully incorporated, whisk in the olive oil in a gentle stream.\n",
            "4. Season with salt and pepper to taste.\n",
            "5. Refrigerate immediately until ready to serve.\n",
            "\n",
            "And that's it! Mayonnaise is a great condiment to have on hand, and it can be used in a variety of dishes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers --upgrade\n",
        "#device = \"cuda\"\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "query = \"who is Barack Obama?\"\n",
        "result = llm(query)\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print()"
      ],
      "metadata": {
        "id": "jREtnaDouFMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0448db28-4f10-452e-d3e5-e0e0cf5faf80"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>who is Barack Obama?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nA: a black American politician and the 44th President of the United States.</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who is Steve Jobs?\"\n",
        "result = llm(query)\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print()"
      ],
      "metadata": {
        "id": "vhbJ_lNEs7IJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "1e05143a-104e-47bf-d0d7-c0ba79e216e9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>who is Steve Jobs?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nUser 1: Founder and CEO of Apple Inc.\n\nBorn in 1957, Steve Jobs was a pivotal figure in the development of personal computing and the popularization of graphical user interfaces. He co-founded Apple Inc., one of the most successful technology companies in history, with his friend Steve Wozniak. He led the company through its early years and played an instrumental role in shaping the Macintosh computer, which revolutionized personal computing by featuring a mouse, graphical interface, and built-in networking capabilities. After being fired from Apple in 1985 due to disagreements over product direction, Jobs went on to found NeXT Computer, which eventually merged with Apple in 1997. During this period, he also founded Pixar Animation Studios, which developed groundbreaking computer animated films such as \"Toy Story\" and \"Finding Nemo.\" Jobs returned to Apple in 2001 and spearheaded the revival of the company under his leadership.</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "#import colab_env\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "#retriever = db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs='1')\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
        "\n",
        "# create a chain to answer questions\n",
        "#qa = RetrievalQA.from_chain_type(\n",
        "#     llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "     llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "query = \"How AWS has evolved?\"\n",
        "\n",
        "result = qa(query)\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print()\n",
        "\n",
        "print()\n",
        "print('CHAIN to answer questions')\n",
        "print(\"-\" * 80)\n",
        "result = qa({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "8m-J59SDN9yO",
        "outputId": "886f58dc-e721-4a01-8226-97de271fb822"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>How AWS has evolved?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>{'query': 'How AWS has evolved?', 'result': '', 'source_documents': [Document(page_content='customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'})]}</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "CHAIN to answer questions\n",
            "--------------------------------------------------------------------------------\n",
            "Query: How AWS has evolved?\n",
            "\n",
            "Result:  AWS has evolved significantly since its initial launch and has become a major player in the cloud computing industry, with an $85B annual revenue run rate business and strong profitability. The long-term decision to continue investing in AWS has played a crucial role in its growth and transformation over the past fifteen years.\n",
            "\n",
            "Context Documents: \n",
            "page_content='customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "\n",
            "page_content='We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}