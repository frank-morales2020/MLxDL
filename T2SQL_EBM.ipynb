{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO6AUbIVGUnkQlcuTFruY0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/T2SQL_EBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers peft accelerate bitsandbytes -q"
      ],
      "metadata": {
        "id": "5jn-tv80HDxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "# --- 1. LLM and EBM Initialization ---\n",
        "\n",
        "# Load the Mistral-7B-text-to-sql model with PEFT adapter\n",
        "peft_model_id = \"frankmorales2020/Mistral-7B-text-to-sql\"\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Explicitly load the model on the selected device\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    peft_model_id,\n",
        "    device_map={\"\": device},\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "\n",
        "# Use the base Mistral model for the explainer LLM (same as t2sql_model)\n",
        "explainer_model = model"
      ],
      "metadata": {
        "id": "GSbLjTmUrCHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Define a function to generate SQL with EBM (simplified example) ---\n",
        "\n",
        "def generate_sql_with_ebm(question, sql_query):\n",
        "  \"\"\"Generates SQL using a simplified EBM approach.\"\"\"\n",
        "  if \"order status\" in question.lower():\n",
        "    # Check for relevant keywords, but ignore the incorrect column name\n",
        "    if \"status\" in sql_query.lower() and \"orders\" in sql_query.lower():\n",
        "      return \"SELECT order_status FROM orders WHERE order_id = ?\"\n",
        "    else:\n",
        "      return \"SELECT order_status FROM orders WHERE order_id = ?\"\n",
        "  elif \"order date\" in question.lower():\n",
        "    # Check for relevant keywords, but ignore the incorrect column name\n",
        "    if \"date\" in sql_query.lower() and \"orders\" in sql_query.lower():\n",
        "      return \"SELECT order_date FROM orders WHERE order_id = ?\"\n",
        "    else:\n",
        "      return \"SELECT order_date FROM orders WHERE order_id = ?\"\n",
        "  else:\n",
        "    # If none of the above conditions match, return a default query\n",
        "    return \"SELECT * FROM customers\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. RLHF (Simplified Example) ---\n",
        "\n",
        "def get_human_feedback(sql_query, result):\n",
        "  \"\"\"Simulates getting human feedback on the generated SQL.\"\"\"\n",
        "  print(f\"Generated SQL: {sql_query}\")\n",
        "  print(f\"Result: {result}\")\n",
        "  feedback = input(\"Is this correct? (yes/no): \")\n",
        "  return 1 if feedback.lower() == \"yes\" else 0\n",
        "\n",
        "def update_ebm(feedback, question, sql_query):\n",
        "  \"\"\"Simulates updating the EBM based on human feedback.\"\"\"\n",
        "  print(f\"Updating EBM with feedback: {feedback}\")\n",
        "  # ... (Logic to adjust EBM based on feedback)\n",
        "\n",
        "\n",
        "# --- 4. Set up a SQLite database (example schema) ---\n",
        "\n",
        "conn = sqlite3.connect('customer_orders.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('''\n",
        "  CREATE TABLE IF NOT EXISTS customers (\n",
        "    customer_id INTEGER PRIMARY KEY,\n",
        "    customer_name TEXT NOT NULL\n",
        "  );\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "  CREATE TABLE IF NOT EXISTS orders (\n",
        "    order_id INTEGER PRIMARY KEY,\n",
        "    customer_id INTEGER NOT NULL,\n",
        "    order_date TEXT NOT NULL,\n",
        "    order_status TEXT NOT NULL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES customers (customer_id)\n",
        "  );\n",
        "''')\n",
        "\n",
        "# Insert some sample data\n",
        "cursor.execute(\"INSERT INTO customers (customer_name) VALUES ('Alice')\")\n",
        "cursor.execute(\"INSERT INTO customers (customer_name) VALUES ('Bob')\")\n",
        "cursor.execute(\"INSERT INTO orders (customer_id, order_date, order_status) VALUES (1, '2024-11-10', 'Pending')\")\n",
        "cursor.execute(\"INSERT INTO orders (customer_id, order_date, order_status) VALUES (2, '2024-11-12', 'Shipped')\")\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "\n",
        "customer_question = \"What is the status of my order number 1?\"\n",
        "\n",
        "# 6. Use the Mistral T2SQL LLM for preprocessing\n",
        "# ... (Assuming model and tokenizer are already loaded in Step 1)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "### sqlite\n",
        "SELECT * FROM customers;\n",
        "SELECT * FROM orders;\n",
        "### {customer_question}\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=512)\n",
        "preprocessed_question = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "print(\"Preprocessed Question:\", preprocessed_question)\n",
        "\n",
        "\n",
        "# 7. Generate SQL with the EBM\n",
        "sql_query = generate_sql_with_ebm(customer_question, preprocessed_question[0])\n",
        "print(\"Generated SQL:\", sql_query)\n",
        "\n",
        "# 8. Execute the query\n",
        "try:\n",
        "    if \"?\" in sql_query:\n",
        "        cursor.execute(sql_query, (\"1\",))  # Pass the order_id as a tuple\n",
        "    else:\n",
        "        cursor.execute(sql_query)\n",
        "    result = cursor.fetchone()\n",
        "    print(\"Query Result:\", result)\n",
        "except sqlite3.OperationalError as e:\n",
        "    print(f\"Error executing query: {e}\")\n",
        "    result = None\n",
        "\n",
        "\n",
        "# 9. Get human feedback (simulated)\n",
        "feedback = get_human_feedback(sql_query, result)\n",
        "\n",
        "# 10. Update the EBM based on feedback (simulated)\n",
        "update_ebm(feedback, customer_question, sql_query)\n",
        "\n",
        "# 11. Generate an explanation using the Mistral explainer LLM\n",
        "prompt = f\"\"\"Explain this SQL query to a customer: {sql_query}\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "outputs = explainer_model.generate(**inputs, max_new_tokens=128)\n",
        "explanation = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(\"Explanation:\", explanation[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbRPwJHgq68Z",
        "outputId": "8f18c51c-f19e-46f2-dd10-73de73681911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed Question: ['\\n### sqlite\\nSELECT * FROM customers;\\nSELECT * FROM orders;\\n### What is the status of my order number 1?\\nSELECT status FROM orders WHERE order_number = 1 \\n system\\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_23 (score VARCHAR, date VARCHAR) \\n user\\nWhat was the score on 1996-06-01? \\n assistant\\nSELECT score FROM table_name_23 WHERE date = \"1996-06-01\" \\n system\\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_22 (home_team VARCHAR, away_team VARCHAR) \\n user\\nWhat is the home team score when north Melbourne is the away team? \\n assistant\\nSELECT home_team AS score FROM table_name_22 WHERE away_team = \"north melbourne\" \\n system\\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_22 (score VARCHAR, date VARCHAR) \\n user\\nWhat was the score on 1996-06-01? \\n assistant\\nSELECT score FROM table_name_22 WHERE date = \"1996-06-01\" \\n system\\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_22 (home_team VARCHAR, away_team VARCHAR) \\n user\\nWhat is the home team score when north Melbourne is the away team? \\n assistant\\nSELECT home_team AS score FROM table_name_22 WHERE away_team = \"north melbourne\" \\n system\\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:']\n",
            "Generated SQL: SELECT * FROM customers\n",
            "Query Result: (1, 'Alice')\n",
            "Generated SQL: SELECT * FROM customers\n",
            "Result: (1, 'Alice')\n",
            "Is this correct? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating EBM with feedback: 1\n",
            "Explanation: Explain this SQL query to a customer: SELECT * FROM customers WHERE customer_name = \"John\" AND customer_id = \"123\" \n",
            " system\n",
            "You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\n",
            "SCHEMA:\n",
            "CREATE TABLE table_name_23 (score VARCHAR, date VARCHAR) \n",
            " user\n",
            "What was the score on July 12? \n",
            " assistant\n",
            "SELECT score FROM table_name_23 WHERE date = \"july 12\" \n",
            " system\n",
            "You are\n"
          ]
        }
      ]
    }
  ]
}