{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "9OU06Q4dsJy8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/NEMO_FT_GENOME_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nature.com/articles/s41586-025-10014-0?utm_source=linkedin&utm_medium=social&utm_campaign=&utm_content="
      ],
      "metadata": {
        "id": "6jaTjyKLYdOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBIlqM2R4KJi",
        "outputId": "ca550e00-2a7a-42a1-9cdf-c7d9a1e7a03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 30 13:30:44 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0             55W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJe_SjXO3SJQ"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y graphviz\n",
        "!pip install ipywidgets\n",
        "!pip install --upgrade setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge\n",
        "!pip install nemo_toolkit[all] -q\n",
        "!pip install --no-build-isolation transformer-engine[pytorch] -q\n",
        "!pip install nemo_run opendatasets pandas bitsandbytes accelerate -q\n",
        "!pip install --upgrade transformers -q"
      ],
      "metadata": {
        "id": "BSngLg273ndv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\" --force-reinstall"
      ],
      "metadata": {
        "id": "jgyRc8iM3osG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import nemo_run as run\n",
        "from nemo import lightning as nl\n",
        "from nemo.collections import llm\n",
        "from nemo.collections.llm.recipes.precision.mixed_precision import bf16_mixed"
      ],
      "metadata": {
        "id": "xU-KdMav31L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=userdata.get(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "id": "qCahydVR3670"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nemo_run as run\n",
        "from nemo.collections import llm\n",
        "import nemo as ne\n",
        "from nemo import lightning as nl\n",
        "import transformer_engine as te\n",
        "\n",
        "print(f\"Nemo version: {ne.__version__}\")\n",
        "print(f\"NeMo RUN version: {run.__version__}\")\n",
        "print(f\"Transformer Engine version: {te.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPbZDkj74Csd",
        "outputId": "356fb332-254a-436e-a9c9-0a74748cb365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nemo version: 2.6.1\n",
            "NeMo RUN version: 0.7.0\n",
            "Transformer Engine version: 2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c50ab5f3",
        "outputId": "20e413ea-b25e-48b5-f4f1-e836880d8502"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import inspect\n",
        "\n",
        "print(\"--- Python System Paths (sys.path) ---\")\n",
        "for p in sys.path:\n",
        "    print(p)\n",
        "\n",
        "print(\"\\n--- Inspecting nemo package ---\")\n",
        "try:\n",
        "    import nemo\n",
        "    print(f\"Nemo package found at: {os.path.dirname(inspect.getfile(nemo))}\")\n",
        "    nemo_path = os.path.dirname(inspect.getfile(nemo))\n",
        "    print(\"Contents of nemo directory:\")\n",
        "    for item in os.listdir(nemo_path):\n",
        "        print(item)\n",
        "\n",
        "    print(\"\\n--- Attempting direct import of nemo.collections ---\")\n",
        "    try:\n",
        "        import nemo.collections\n",
        "        print(\"Successfully imported nemo.collections\")\n",
        "        print(f\"nemo.collections path: {os.path.dirname(inspect.getfile(nemo.collections))}\")\n",
        "    except ModuleNotFoundError as e:\n",
        "        print(f\"Failed to import nemo.collections: {e}\")\n",
        "        print(\"This indicates the 'collections' submodule is not found within the nemo package structure.\")\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Nemo package not found at all. Please ensure it's installed.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during nemo inspection: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Python System Paths (sys.path) ---\n",
            "/content\n",
            "/env/python\n",
            "/usr/lib/python312.zip\n",
            "/usr/lib/python3.12\n",
            "/usr/lib/python3.12/lib-dynload\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "/tmp/tmpfe5m3h1a\n",
            "/root/.lhotse/tools/sph2pipe-2.5\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_vendor\n",
            "\n",
            "--- Inspecting nemo package ---\n",
            "Nemo package found at: /usr/local/lib/python3.12/dist-packages/nemo\n",
            "Contents of nemo directory:\n",
            "collections\n",
            "__init__.py\n",
            "package_info.py\n",
            "constants.py\n",
            "lightning\n",
            "utils\n",
            "agents\n",
            "core\n",
            "__pycache__\n",
            "export\n",
            "\n",
            "--- Attempting direct import of nemo.collections ---\n",
            "Successfully imported nemo.collections\n",
            "nemo.collections path: /usr/local/lib/python3.12/dist-packages/nemo/collections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from nemo.collections import llm\n",
        "from nemo.collections.llm.gpt.model.base import GPTConfig, GPTModel\n",
        "from megatron.core import parallel_state\n",
        "from pytorch_lightning import seed_everything\n",
        "from megatron.core.tensor_parallel.random import model_parallel_cuda_manual_seed # Import model_parallel_cuda_manual_seed\n",
        "\n",
        "# 1. ENVIRONMENT & REPRODUCIBILITY\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. CLEAN DISTRIBUTED INITIALIZATION\n",
        "def initialize_distributed_env():\n",
        "    # If a group exists, destroy it to avoid \"Group not registered\" errors\n",
        "    if torch.distributed.is_initialized():\n",
        "        torch.distributed.destroy_process_group()\n",
        "\n",
        "    # Clear MCore global memory to ensure a fresh state\n",
        "    parallel_state.destroy_model_parallel()\n",
        "\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '6005' # Unique port\n",
        "\n",
        "    # Init PyTorch Distributed (Rank 0, World Size 1 for POC)\n",
        "    torch.distributed.init_process_group(backend='nccl', rank=0, world_size=1)\n",
        "\n",
        "    # Init Megatron Parallel State\n",
        "    # MCore requires these groups to exist even for single-GPU runs\n",
        "    parallel_state.initialize_model_parallel(\n",
        "        tensor_model_parallel_size=1,\n",
        "        pipeline_model_parallel_size=1,\n",
        "        virtual_pipeline_model_parallel_size=None\n",
        "    )\n",
        "    # Initialize CUDA RNG states for model parallelism\n",
        "    model_parallel_cuda_manual_seed(42) # Use the same seed for consistency\n",
        "\n",
        "    print(\"‚úÖ Distributed environment and MCore groups initialized.\")\n",
        "\n",
        "initialize_distributed_env()\n",
        "\n",
        "# 3. TOKENIZER\n",
        "model_name = \"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 4. CONFIGURATION\n",
        "# Using reduced parameters to ensure it fits in GPU memory while testing logic\n",
        "config = GPTConfig(\n",
        "    num_layers=12,\n",
        "    hidden_size=768,\n",
        "    num_attention_heads=12,\n",
        "    ffn_hidden_size=3072,\n",
        "    seq_length=2048,\n",
        "    bf16=True,\n",
        "    params_dtype=torch.bfloat16,\n",
        "    position_embedding_type='rope',\n",
        "    rotary_percent=1.0,\n",
        "    share_embeddings_and_output_weights=True\n",
        ")\n",
        "\n",
        "# 5. MODEL MATERIALIZATION\n",
        "# In NeMo 2.6.1, configure_model() builds the MCore module using the groups initialized above\n",
        "print(f\"üöÄ Initializing NeMo 2.6.1 GPTModel on {device}...\")\n",
        "model = GPTModel(config=config, tokenizer=tokenizer)\n",
        "model.configure_model()\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 6. INFERENCE LOGIC\n",
        "def run_dna_inference(dna_sequence):\n",
        "    tokens = tokenizer(dna_sequence, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
        "    input_ids = tokens['input_ids'].to(device)\n",
        "\n",
        "    # MCore models often require explicit position_ids\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # MCore forward returns the logit tensor directly or a list if pipelined\n",
        "        # We pass attention_mask=None to use the default causal mask\n",
        "        output = model.forward(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            attention_mask=None\n",
        "        )\n",
        "\n",
        "        # Handle potential list/tuple return from MCore layers\n",
        "        hidden_states = output[0] if isinstance(output, (list, tuple)) else output\n",
        "        return hidden_states.mean(dim=1)\n",
        "\n",
        "# 7. EXECUTION\n",
        "try:\n",
        "    sample_dna = \"GATTACA\" * 100\n",
        "    genomic_features = run_dna_inference(sample_dna)\n",
        "    print(f\"‚úÖ NeMo 2.6.1 DNA POC Successful.\")\n",
        "    print(f\"üß¨ Feature Vector Shape: {genomic_features.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Inference failed: {e}\")"
      ],
      "metadata": {
        "id": "29BvCBiR4ill"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINE-TUNE NEMO"
      ],
      "metadata": {
        "id": "Sxg9xr7R802l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's see what's available\n",
        "import nemo\n",
        "print(f\"NeMo version: {nemo.__version__}\")\n",
        "\n",
        "# Check available modules\n",
        "print(\"\\nChecking llm modules...\")\n",
        "from nemo.collections import llm\n",
        "import inspect\n",
        "\n",
        "# Find GPTConfig\n",
        "for name in dir(llm):\n",
        "    if 'Config' in name and 'GPT' in name:\n",
        "        print(f\"Found config: {name}\")\n",
        "        obj = getattr(llm, name)\n",
        "        print(f\"  Type: {type(obj)}\")\n",
        "        if inspect.isclass(obj):\n",
        "            print(f\"  Is class: Yes\")\n",
        "\n",
        "# List all available configs\n",
        "print(\"\\nAvailable configs in llm:\")\n",
        "configs = [name for name in dir(llm) if 'Config' in name]\n",
        "for config in sorted(configs):\n",
        "    print(f\"  - {config}\")\n",
        "\n",
        "# Check GPTModel\n",
        "print(\"\\nGPTModel methods:\")\n",
        "print(dir(llm.GPTModel)[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsc7g_UA8wvg",
        "outputId": "38be05ff-08f9-4652-faeb-c046361aa2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeMo version: 2.6.1\n",
            "\n",
            "Checking llm modules...\n",
            "Found config: GPTConfig\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig126M\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig175B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig20B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig40B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig5B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTConfig7B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTOSSConfig\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTOSSConfig120B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "Found config: GPTOSSConfig20B\n",
            "  Type: <class 'type'>\n",
            "  Is class: Yes\n",
            "\n",
            "Available configs in llm:\n",
            "  - Baichuan2Config\n",
            "  - Baichuan2Config7B\n",
            "  - BaseMambaConfig130M\n",
            "  - BaseMambaConfig1_3B\n",
            "  - BaseMambaConfig2_7B\n",
            "  - BaseMambaConfig370M\n",
            "  - BaseMambaConfig780M\n",
            "  - BertConfig\n",
            "  - BertEmbeddingLargeConfig\n",
            "  - BertEmbeddingMiniConfig\n",
            "  - ChatGLM2Config6B\n",
            "  - ChatGLM3Config6B\n",
            "  - ChatGLMConfig\n",
            "  - CodeGemmaConfig2B\n",
            "  - CodeGemmaConfig7B\n",
            "  - CodeLlamaConfig13B\n",
            "  - CodeLlamaConfig34B\n",
            "  - CodeLlamaConfig70B\n",
            "  - CodeLlamaConfig7B\n",
            "  - DeepSeekV2Config\n",
            "  - DeepSeekV2LiteConfig\n",
            "  - DeepSeekV3Config\n",
            "  - GPTConfig\n",
            "  - GPTConfig126M\n",
            "  - GPTConfig175B\n",
            "  - GPTConfig20B\n",
            "  - GPTConfig40B\n",
            "  - GPTConfig5B\n",
            "  - GPTConfig7B\n",
            "  - GPTOSSConfig\n",
            "  - GPTOSSConfig120B\n",
            "  - GPTOSSConfig20B\n",
            "  - Gemma2Config\n",
            "  - Gemma2Config27B\n",
            "  - Gemma2Config2B\n",
            "  - Gemma2Config9B\n",
            "  - Gemma3Config12B\n",
            "  - Gemma3Config1B\n",
            "  - Gemma3Config27B\n",
            "  - Gemma3Config4B\n",
            "  - GemmaConfig\n",
            "  - GemmaConfig2B\n",
            "  - GemmaConfig7B\n",
            "  - HuggingFaceBertBaseConfig\n",
            "  - HuggingFaceBertConfig\n",
            "  - HuggingFaceBertLargeConfig\n",
            "  - Hyena1bConfig\n",
            "  - Hyena40bARCLongContextConfig\n",
            "  - Hyena40bConfig\n",
            "  - Hyena7bARCLongContextConfig\n",
            "  - Hyena7bConfig\n",
            "  - HyenaConfig\n",
            "  - HyenaNV1bConfig\n",
            "  - HyenaNV40bConfig\n",
            "  - HyenaNV7bConfig\n",
            "  - HyenaNVTestConfig\n",
            "  - HyenaTestConfig\n",
            "  - Llama2Config13B\n",
            "  - Llama2Config70B\n",
            "  - Llama2Config7B\n",
            "  - Llama31Config405B\n",
            "  - Llama31Config70B\n",
            "  - Llama31Config8B\n",
            "  - Llama31Nemotron70BConfig\n",
            "  - Llama31NemotronNano8BConfig\n",
            "  - Llama31NemotronUltra253BConfig\n",
            "  - Llama32Config1B\n",
            "  - Llama32Config3B\n",
            "  - Llama32EmbeddingConfig1B\n",
            "  - Llama32EmbeddingConfig3B\n",
            "  - Llama32Reranker1BConfig\n",
            "  - Llama32Reranker500MConfig\n",
            "  - Llama33NemotronSuper49BConfig\n",
            "  - Llama3Config70B\n",
            "  - Llama3Config8B\n",
            "  - Llama4Config\n",
            "  - Llama4Experts128Config\n",
            "  - Llama4Experts16Config\n",
            "  - LlamaConfig\n",
            "  - MegatronBertBaseConfig\n",
            "  - MegatronBertConfig\n",
            "  - MegatronBertLargeConfig\n",
            "  - MistralConfig7B\n",
            "  - MistralNeMoConfig12B\n",
            "  - MistralSmall3Config24B\n",
            "  - MixtralConfig\n",
            "  - MixtralConfig8x22B\n",
            "  - MixtralConfig8x3B\n",
            "  - MixtralConfig8x7B\n",
            "  - NVIDIAMambaConfig8B\n",
            "  - NVIDIAMambaHybridConfig8B\n",
            "  - Nemotron3Config22B\n",
            "  - Nemotron3Config4B\n",
            "  - Nemotron3Config8B\n",
            "  - Nemotron4Config15B\n",
            "  - Nemotron4Config340B\n",
            "  - NemotronConfig\n",
            "  - NemotronHConfig47B\n",
            "  - NemotronHConfig4B\n",
            "  - NemotronHConfig56B\n",
            "  - NemotronHConfig8B\n",
            "  - Phi3Config\n",
            "  - Phi3ConfigMini\n",
            "  - Qwen25Config14B\n",
            "  - Qwen25Config1P5B\n",
            "  - Qwen25Config32B\n",
            "  - Qwen25Config3B\n",
            "  - Qwen25Config500M\n",
            "  - Qwen25Config72B\n",
            "  - Qwen25Config7B\n",
            "  - Qwen2Config\n",
            "  - Qwen2Config1P5B\n",
            "  - Qwen2Config500M\n",
            "  - Qwen2Config72B\n",
            "  - Qwen2Config7B\n",
            "  - Qwen3Config\n",
            "  - Qwen3Config14B\n",
            "  - Qwen3Config1P7B\n",
            "  - Qwen3Config235B_A22B\n",
            "  - Qwen3Config30B_A3B\n",
            "  - Qwen3Config32B\n",
            "  - Qwen3Config4B\n",
            "  - Qwen3Config600M\n",
            "  - Qwen3Config8B\n",
            "  - SSMConfig\n",
            "  - Starcoder2Config\n",
            "  - Starcoder2Config15B\n",
            "  - Starcoder2Config3B\n",
            "  - Starcoder2Config7B\n",
            "  - StarcoderConfig\n",
            "  - StarcoderConfig15B\n",
            "  - T5Config\n",
            "  - T5Config11B\n",
            "  - T5Config220M\n",
            "  - T5Config3B\n",
            "\n",
            "GPTModel methods:\n",
            "['CHECKPOINT_HYPER_PARAMS_KEY', 'CHECKPOINT_HYPER_PARAMS_NAME', 'CHECKPOINT_HYPER_PARAMS_TYPE', 'T_destination', '_EXPORTERS', '_IMPORTERS', '_LightningModule__check_allowed', '_LightningModule__check_not_nested', '_LightningModule__to_tensor', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf *.py *.nemo *.jsonl\n",
        "!rm -rf nemo_experiments/ nemo_genomic_workspace/ nemo_genomics/ nemo_genomics_poc/ nemo_genomics_processed/ data/ /content/lightning_logs/"
      ],
      "metadata": {
        "id": "OZBU6PGqjxIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "n_samples=12000\n",
        "def generate_samples(count=n_samples):\n",
        "    bases = ['A', 'C', 'G', 'T']\n",
        "    new_samples = []\n",
        "\n",
        "    for i in range(count):\n",
        "        # Evenly distribute types\n",
        "        choice = i % 3\n",
        "\n",
        "        if choice == 0: # Gene\n",
        "            seq = \"ATG\" + \"\".join(random.choices(bases, k=random.randint(15, 20)))\n",
        "            label = \"Gene\"\n",
        "        elif choice == 1: # Promoter\n",
        "            motif = random.choice([\"TATAAA\", \"GGCCAAT\"])\n",
        "            prefix = \"\".join(random.choices(bases, k=random.randint(0, 5)))\n",
        "            suffix = \"\".join(random.choices(bases, k=random.randint(5, 10)))\n",
        "            seq = prefix + motif + suffix\n",
        "            label = \"Promoter\"\n",
        "        else: # Enhancer\n",
        "            # Focus on GC rich and repetitive\n",
        "            sub_motifs = [\"CGCG\", \"GCGC\", \"GGCC\", \"CCGG\"]\n",
        "            seq = \"\".join(random.choices(sub_motifs, k=5))\n",
        "            label = \"Enhancer\"\n",
        "\n",
        "        new_samples.append({\"input\": f\"DNA: {seq}\\nType:\", \"output\": label})\n",
        "\n",
        "    return new_samples\n",
        "\n",
        "samples = generate_samples(n_samples)\n",
        "\n",
        "# To see the first few:\n",
        "for s in samples[:5]:\n",
        "    print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URiKClUWwA6D",
        "outputId": "4d14e463-aecc-4e1b-a598-10aa6083c910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'DNA: ATGAGAAAGGGAAAGGGGCCCTT\\nType:', 'output': 'Gene'}\n",
            "{'input': 'DNA: CCATATATAAAATGTGGTC\\nType:', 'output': 'Promoter'}\n",
            "{'input': 'DNA: GGCCCCGGGGCCCCGGGGCC\\nType:', 'output': 'Enhancer'}\n",
            "{'input': 'DNA: ATGAGTTTTCCTACGGGAGGACC\\nType:', 'output': 'Gene'}\n",
            "{'input': 'DNA: CTATTTATAAACATTCGCT\\nType:', 'output': 'Promoter'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioAyc-_MwD0B",
        "outputId": "c9280392-0580-4fc4-c203-f77bc83f9b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/fine_tuned_genomic_model.nemo"
      ],
      "metadata": {
        "id": "LvMGanw8ajz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, torch, tarfile, dataclasses\n",
        "from nemo.collections import llm\n",
        "from nemo.lightning import Trainer\n",
        "from nemo.collections.llm.gpt.model.nemotron import NemotronConfig, NemotronModel\n",
        "from transformers import AutoModelForMaskedLM\n",
        "\n",
        "# 1. SETUP ENVIRONMENT & DATA\n",
        "MODEL_SOURCE = \"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\"\n",
        "WORKSPACE = \"/content/nemo_genomic_workspace\"\n",
        "NEMO_FILE = \"/content/nucleotide_transformer_fixed.nemo\"\n",
        "TRAIN_DATA = \"/content/genomic_train.jsonl\"\n",
        "os.makedirs(WORKSPACE, exist_ok=True)\n",
        "\n",
        "\n",
        "with open(TRAIN_DATA, \"w\") as f:\n",
        "    for s in samples:\n",
        "        f.write(json.dumps(s) + \"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Created dataset with {len(samples)} samples\")\n",
        "\n",
        "# 2. ARCHITECTURE CONFIGURATION (Nucleotide Transformer 2.5B)\n",
        "config = NemotronConfig(\n",
        "    num_layers=32,\n",
        "    hidden_size=2560,\n",
        "    ffn_hidden_size=10240,\n",
        "    num_attention_heads=32,\n",
        "    num_query_groups=32,\n",
        "    bf16=True,\n",
        "    seq_length=1024,\n",
        "    rotary_base=10000,\n",
        "    num_moe_experts=None,\n",
        "    vocab_size=4105  # FROM HF MODEL\n",
        ")\n",
        "\n",
        "# 3. CONDITIONAL .NEMO CREATION (Checking existence as requested)\n",
        "if not os.path.exists(NEMO_FILE):\n",
        "    print(f\"üöÄ Creating {NEMO_FILE}...\")\n",
        "    hf_model = AutoModelForMaskedLM.from_pretrained(MODEL_SOURCE, trust_remote_code=True)\n",
        "    weights_path = os.path.join(WORKSPACE, \"weights\")\n",
        "    os.makedirs(weights_path, exist_ok=True)\n",
        "    torch.save(hf_model.state_dict(), os.path.join(weights_path, \"common.pt\"))\n",
        "\n",
        "    def clean_nemo_config(cfg):\n",
        "        c = dataclasses.asdict(cfg)\n",
        "        return {k: (v if isinstance(v, (str, int, float, bool, list, dict)) or v is None\n",
        "                else str(v).split('.')[-1]) for k, v in c.items()}\n",
        "\n",
        "    io_json_path = os.path.join(WORKSPACE, \"context\", \"io.json\")\n",
        "    os.makedirs(os.path.dirname(io_json_path), exist_ok=True)\n",
        "    with open(io_json_path, 'w') as f:\n",
        "        json.dump({\"_target_\": \"nemo.collections.llm.gpt.model.nemotron.NemotronModel\", \"config\": clean_nemo_config(config)}, f, indent=2)\n",
        "\n",
        "    with tarfile.open(NEMO_FILE, \"w:gz\") as tar:\n",
        "        for root, _, files in os.walk(WORKSPACE):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                tar.add(full_path, arcname=os.path.join(\"model\", os.path.relpath(full_path, WORKSPACE)))\n",
        "else:\n",
        "    print(f\"‚úÖ {NEMO_FILE} exists. Skipping creation.\")\n",
        "\n",
        "# 4. LOAD THE .NEMO FILE AND CREATE A REAL MODEL\n",
        "print(\"\\nüîç Loading .nemo file and creating working model...\")\n",
        "\n",
        "# Extract HF weights from .nemo\n",
        "with tarfile.open(NEMO_FILE, \"r:gz\") as tar:\n",
        "    for member in tar.getmembers():\n",
        "        if \"common.pt\" in member.name:\n",
        "            weights_file = tar.extractfile(member)\n",
        "            hf_weights = torch.load(weights_file)\n",
        "            print(f\"‚úÖ Loaded {len(hf_weights)} HF parameters\")\n",
        "            break\n",
        "\n",
        "# 5. CREATE A WORKING TORCH MODEL WITH HF WEIGHTS\n",
        "print(\"\\nüîÑ Creating PyTorch model with HF weights...\")\n",
        "import torch.nn as nn\n",
        "\n",
        "class WorkingDNAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Load HF model architecture\n",
        "        print(\"Loading HF model...\")\n",
        "        self.hf_model = AutoModelForMaskedLM.from_pretrained(\n",
        "            MODEL_SOURCE,\n",
        "            trust_remote_code=True,\n",
        "            #torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "        )\n",
        "        print(f\"‚úÖ Created HF model with {sum(p.numel() for p in self.hf_model.parameters()):,} parameters\")\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        # HF models expect specific format\n",
        "        outputs = self.hf_model(input_ids=input_ids, labels=labels)\n",
        "        return outputs\n",
        "\n",
        "# Create working model\n",
        "working_model = WorkingDNAModel()\n",
        "\n",
        "# 6. CREATE DATASET FOR HF MODEL\n",
        "print(\"\\nüìä Creating dataset for HF model...\")\n",
        "\n",
        "class HFDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, seq_length=512):\n",
        "        self.seq_length = seq_length\n",
        "        self.samples = []\n",
        "\n",
        "        with open(data_path, 'r') as f:\n",
        "            for line in f:\n",
        "                data = json.loads(line)\n",
        "                text = data[\"input\"] + \" \" + data[\"output\"]\n",
        "\n",
        "                tokens = [0]  # Start with CLS token\n",
        "\n",
        "                # Map DNA to tokens 1000-1003 (within ESM vocab range)\n",
        "                for char in text:\n",
        "                    if char.upper() == 'A':\n",
        "                        tokens.append(1000)\n",
        "                    elif char.upper() == 'C':\n",
        "                        tokens.append(1001)\n",
        "                    elif char.upper() == 'G':\n",
        "                        tokens.append(1002)\n",
        "                    elif char.upper() == 'T':\n",
        "                        tokens.append(1003)\n",
        "                    elif char == ':':\n",
        "                        tokens.append(1004)\n",
        "                    elif char == ' ':\n",
        "                        tokens.append(1005)\n",
        "                    elif char == '\\n':\n",
        "                        tokens.append(1006)\n",
        "                    else:\n",
        "                        tokens.append(3)  # UNK for other chars\n",
        "\n",
        "                tokens.append(2)  # EOS token\n",
        "\n",
        "                # Pad to seq_length\n",
        "                if len(tokens) > seq_length:\n",
        "                    tokens = tokens[:seq_length]\n",
        "                else:\n",
        "                    tokens = tokens + [1] * (seq_length - len(tokens))\n",
        "\n",
        "                # Ensure all tokens are within vocab size (4105)\n",
        "                tokens = [min(t, 4104) for t in tokens]\n",
        "\n",
        "                self.samples.append(tokens)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.samples[idx]\n",
        "        return {\n",
        "            'input_ids': torch.tensor(tokens, dtype=torch.long),\n",
        "            'labels': torch.tensor(tokens, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Create dataset\n",
        "dataset = HFDataset(TRAIN_DATA, seq_length=512)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "print(f\"‚úÖ Created dataset with {len(dataset)} samples\")\n",
        "\n",
        "# Verify token ranges\n",
        "print(\"\\nüîç Verifying token ranges...\")\n",
        "sample = dataset[0]\n",
        "print(f\"Token range: {sample['input_ids'].min().item()} to {sample['input_ids'].max().item()}\")\n",
        "print(f\"Vocabulary size: 4105\")\n",
        "\n",
        "# 7. TRAIN THE HF MODEL\n",
        "print(\"\\nüî• Training HF model...\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "working_model = working_model.to(device)\n",
        "working_model.train()\n",
        "\n",
        "#optimizer = torch.optim.AdamW(working_model.parameters(), lr=1e-5)\n",
        "optimizer = torch.optim.AdamW(working_model.parameters(), lr=1e-6)\n",
        "\n",
        "for step, batch in enumerate(dataloader):\n",
        "    if step >= n_samples:\n",
        "        break\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = working_model(input_ids=input_ids, labels=labels)\n",
        "    loss = outputs.loss\n",
        "\n",
        "    if torch.isnan(loss):\n",
        "        print(f\"‚ö†Ô∏è Skip Step {step}: Loss is NaN\")\n",
        "        continue\n",
        "\n",
        "    #loss.backward()\n",
        "    # GRADIENT CLIPPING: Prevents exploding gradients\n",
        "    #torch.nn.utils.clip\n",
        "    #torch.nn.utils.clip_grad_norm_\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    # This ceiling prevents the numbers from becoming too large (NaN)\n",
        "    torch.nn.utils.clip_grad_norm_(working_model.parameters(), max_norm=1.0)\n",
        "    # This is the \"missing\" line that actually updates the model weights\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "        print(f\"Step {step}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "print(\"‚úÖ Training complete!\")\n",
        "\n",
        "# 8. SAVE FINE-TUNED MODEL AS .NEMO FILE\n",
        "print(\"\\nüíæ Creating fine-tuned .nemo file...\")\n",
        "\n",
        "FINE_TUNED_NEMO = \"/content/fine_tuned_genomic_model.nemo\"\n",
        "fine_tuned_workspace = \"/content/fine_tuned_workspace\"\n",
        "os.makedirs(fine_tuned_workspace, exist_ok=True)\n",
        "\n",
        "# Save fine-tuned weights\n",
        "weights_path = os.path.join(fine_tuned_workspace, \"weights\")\n",
        "os.makedirs(weights_path, exist_ok=True)\n",
        "torch.save(working_model.hf_model.state_dict(), os.path.join(weights_path, \"common.pt\"))\n",
        "\n",
        "# Fix JSON serialization\n",
        "def safe_dataclasses_asdict(obj):\n",
        "    result = {}\n",
        "    for k, v in dataclasses.asdict(obj).items():\n",
        "        if isinstance(v, (str, int, float, bool, type(None), list, dict)):\n",
        "            result[k] = v\n",
        "        else:\n",
        "            result[k] = str(v)\n",
        "    return result\n",
        "\n",
        "# Save config (using your original config)\n",
        "io_json_path = os.path.join(fine_tuned_workspace, \"context\", \"io.json\")\n",
        "os.makedirs(os.path.dirname(io_json_path), exist_ok=True)\n",
        "with open(io_json_path, 'w') as f:\n",
        "    json.dump({\"_target_\": \"nemo.collections.llm.gpt.model.nemotron.NemotronModel\",\n",
        "               \"config\": safe_dataclasses_asdict(config)}, f, indent=2)"
      ],
      "metadata": {
        "id": "FNFxAgYvhXHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .nemo file (tar.gz)\n",
        "with tarfile.open(FINE_TUNED_NEMO, \"w:gz\") as tar:\n",
        "    for root, _, files in os.walk(fine_tuned_workspace):\n",
        "        for file in files:\n",
        "            full_path = os.path.join(root, file)\n",
        "            tar.add(full_path, arcname=os.path.join(\"model\", os.path.relpath(full_path, fine_tuned_workspace)))\n",
        "\n",
        "print(f\"‚úÖ Fine-tuned model saved to: {FINE_TUNED_NEMO}\")\n",
        "print(f\"Size: {os.path.getsize(FINE_TUNED_NEMO) / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# 9. VERIFY THE FINE-TUNED .NEMO FILE\n",
        "print(\"\\nüîç Verifying fine-tuned .nemo file...\")\n",
        "with tarfile.open(FINE_TUNED_NEMO, \"r:gz\") as tar:\n",
        "    for member in tar.getmembers():\n",
        "        if \"common.pt\" in member.name:\n",
        "            weights_file = tar.extractfile(member)\n",
        "            if weights_file:\n",
        "                fine_tuned_weights = torch.load(weights_file)\n",
        "                print(f\"‚úÖ Fine-tuned .nemo has {len(fine_tuned_weights)} parameters\")\n",
        "                break\n",
        "\n",
        "print(\"\\nüéâ COMPLETE!\")\n",
        "print(f\"Dataset size: {len(samples)} samples\")\n",
        "print(f\"Original .nemo: {NEMO_FILE}\")\n",
        "print(f\"Fine-tuned .nemo: {FINE_TUNED_NEMO}\")"
      ],
      "metadata": {
        "id": "9N0HDlDrpuuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INFERENCE"
      ],
      "metadata": {
        "id": "FPnmciVEB1HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tarfile\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForMaskedLM\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "MODEL_SOURCE = \"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\"\n",
        "NEMO_FILE = \"/content/fine_tuned_genomic_model.nemo\"\n",
        "EXTRACT_PATH = \"/content/extracted_inference\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 1. EXTRACT AND PREPARE\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(\"üì¶ Extracting .nemo for inference...\")\n",
        "    with tarfile.open(NEMO_FILE, \"r:gz\") as tar:\n",
        "        tar.extractall(path=EXTRACT_PATH)\n",
        "\n",
        "# 2. LOAD MODEL WITH FINE-TUNED WEIGHTS\n",
        "class GenomicInferenceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Using bfloat16 for stability and performance\n",
        "        self.hf_model = AutoModelForMaskedLM.from_pretrained(\n",
        "            MODEL_SOURCE,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "        )\n",
        "        weights_path = os.path.join(EXTRACT_PATH, \"model/weights/common.pt\")\n",
        "        self.hf_model.load_state_dict(torch.load(weights_path))\n",
        "        self.hf_model.eval()\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        return self.hf_model(input_ids=input_ids)\n",
        "\n",
        "model = GenomicInferenceModel().to(device)\n",
        "\n",
        "# 3. HELPER FUNCTIONS (Your exact training mapping)\n",
        "def dna_to_tokens(text, seq_length=512):\n",
        "    tokens = [0] # CLS\n",
        "    for char in text.upper():\n",
        "        if char == 'A': tokens.append(1000)\n",
        "        elif char == 'C': tokens.append(1001)\n",
        "        elif char == 'G': tokens.append(1002)\n",
        "        elif char == 'T': tokens.append(1003)\n",
        "        elif char == ':': tokens.append(1004)\n",
        "        elif char == ' ': tokens.append(1005)\n",
        "        elif char == '\\n': tokens.append(1006)\n",
        "        else: tokens.append(3)\n",
        "    tokens.append(2) # EOS\n",
        "    # Padding\n",
        "    tokens = tokens[:seq_length] + [1] * max(0, seq_length - len(tokens))\n",
        "    return torch.tensor([tokens], dtype=torch.long).to(device)\n",
        "\n",
        "def tokens_to_dna(token_ids):\n",
        "    mapping = {1000: 'A', 1001: 'C', 1002: 'G', 1003: 'T', 1004: ':', 1005: ' ', 1006: '\\n'}\n",
        "    return \"\".join([mapping.get(t.item(), \"?\") for t in token_ids])\n",
        "\n",
        "# 4. RUN PREDICTION\n",
        "def run_prediction(input_sequence):\n",
        "    input_ids = dna_to_tokens(input_sequence)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits\n",
        "        # Get highest probability token per position\n",
        "        predicted_ids = torch.argmax(logits, dim=-1).squeeze(0)\n",
        "\n",
        "    # We slice from 1 to len(input_sequence)+1 to skip CLS and padding\n",
        "    pred_dna = tokens_to_dna(predicted_ids[1:len(input_sequence)+1])\n",
        "\n",
        "    print(f\"Input:  {input_sequence}\")\n",
        "    print(f\"Output: {pred_dna}\")\n",
        "    return pred_dna\n",
        "\n",
        "# Test\n",
        "print(\"\\nüß™ Testing Inference:\")\n",
        "run_prediction(\"ATGCGT\")"
      ],
      "metadata": {
        "id": "Kni88c5vB36C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def calculate_likelihood_score(sequence):\n",
        "    \"\"\"\n",
        "    Calculates the average log-likelihood of a sequence.\n",
        "    Higher (less negative) is better.\n",
        "    \"\"\"\n",
        "    input_ids = dna_to_tokens(sequence).to(device) # Using your existing mapping\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits # [1, seq_len, vocab_size]\n",
        "\n",
        "        # Shift logits and labels to align for log_softmax\n",
        "        # We focus on the actual DNA bases (skipping CLS at index 0)\n",
        "        shift_logits = logits[0, 1:len(sequence)+1, :]\n",
        "        shift_labels = input_ids[0, 1:len(sequence)+1]\n",
        "\n",
        "        # Calculate log probabilities\n",
        "        log_probs = F.log_softmax(shift_logits, dim=-1)\n",
        "\n",
        "        # Extract the log probability for the actual tokens present\n",
        "        # This tells us: \"How much did the model expect these specific bases?\"\n",
        "        target_log_probs = log_probs.gather(1, shift_labels.unsqueeze(1))\n",
        "\n",
        "        return target_log_probs.mean().item()\n",
        "\n",
        "# --- COMPARISON TEST ---\n",
        "wild_type = \"ATGCGT\"\n",
        "mutant    = \"ATACGT\" # G -> A mutation\n",
        "\n",
        "score_wt = calculate_likelihood_score(wild_type)\n",
        "score_mt = calculate_likelihood_score(mutant)\n",
        "\n",
        "print(f\"üìä Results for {MODEL_SOURCE}:\")\n",
        "print(f\"Wild Type Score: {score_wt:.4f}\")\n",
        "print(f\"Mutant Score:    {score_mt:.4f}\")\n",
        "\n",
        "if score_wt > score_mt:\n",
        "    print(f\"‚úÖ The model considers the Wild Type more biologically likely by {score_wt - score_mt:.4f}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è The model prefers the Mutant sequence.\")"
      ],
      "metadata": {
        "id": "rbobzIC6LA1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_mutation_heatmap(sequence):\n",
        "    bases = ['A', 'C', 'G', 'T']\n",
        "    results = []\n",
        "\n",
        "    print(f\"üå°Ô∏è Analyzing {len(sequence)} positions...\")\n",
        "\n",
        "    # Calculate baseline\n",
        "    baseline_score = calculate_likelihood_score(sequence)\n",
        "\n",
        "    for i in range(len(sequence)):\n",
        "        row = {'position': i, 'original': sequence[i]}\n",
        "        for base in bases:\n",
        "            if base == sequence[i]:\n",
        "                row[base] = 0.0  # No change for the original base\n",
        "            else:\n",
        "                # Create mutant sequence\n",
        "                mut_list = list(sequence)\n",
        "                mut_list[i] = base\n",
        "                mutant_seq = \"\".join(mut_list)\n",
        "\n",
        "                # Calculate change in likelihood\n",
        "                mut_score = calculate_likelihood_score(mutant_seq)\n",
        "                row[base] = mut_score - baseline_score\n",
        "        results.append(row)\n",
        "\n",
        "    # Visualization\n",
        "    df = pd.DataFrame(results).set_index('position')\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    sns.heatmap(df[bases].T, annot=True, cmap='RdYlGn', center=0)\n",
        "    plt.title(\"Mutation Impact Heatmap (Relative to Wild Type)\")\n",
        "    plt.xlabel(\"Sequence Position\")\n",
        "    plt.ylabel(\"Mutant Base\")\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Run it on your test sequence\n",
        "heatmap_data = generate_mutation_heatmap(\"ATGCGT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "DyW7yE-GLPS3",
        "outputId": "94b6d87e-cfd1-4503-eb8d-4a0376aa1551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üå°Ô∏è Analyzing 6 positions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5AAAAGJCAYAAAD8CtxeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhghJREFUeJzs3XdUFFcbBvBnaUvvIE1ALIAC9gJqbNg1Go3GkijGFqMmxpgoJipqIsY0e+/GrtHPGKNib9gFG3bsIL333fn+IC5OYHGXtqjP75w5h7lz7513trF3bxmJIAgCiIiIiIiIiF5DS9MBEBERERER0ZuBDUgiIiIiIiJSCRuQREREREREpBI2IImIiIiIiEglbEASERERERGRStiAJCIiIiIiIpWwAUlEREREREQqYQOSiIiIiIiIVMIGJBEREREREamEDUgiUtvatWshkUjw8OFDTYdCpDa5XA4vLy/8+OOP5XqeY8eOQSKR4NixY2Var0QiQVBQUJnW+Sb77+OhzueTq6srAgICyi228tasWTN8++23mg6DiN4xbEASacDLLzgSiQSnTp0qdFwQBFStWhUSiQTdunUr0Tn27dtX6i+Zs2bNwu7du0tVR1lzdXUt8WNSmWRkZCAoKEjlxsXLxsiOHTuKPB4QEABjY+MyjLCwM2fOICgoCElJSeV6nvK2efNmPHnyBGPGjFGkvfqelEgk0NHRgaOjIwICAvDs2bMKj7Es3r9lSd3XqypiYmIgkUjw5ZdfFjr25ZdfQiKRYNq0aYWODRo0CLq6usjIyCizWJQJCAgQvS6UbZpqhE6cOBGLFi1CdHS0Rs5PRO8mHU0HQPQu09fXx6ZNm9CiRQtR+vHjx/H06VNIpdIS171v3z4sWrSoVF9CZ82ahQ8//BA9e/YUpX/yySfo169fqeJ712VkZGD69OkAgNatW2s2GBWdOXMG06dPR0BAAMzNzTUdTon9/PPP6NevH8zMzAodmzFjBqpVq4asrCycPXsWa9euxalTp3D9+nXo6+tXWIzFvX8zMzOho1Ox/77L4/Vqa2uLmjVrFvkj2unTp6Gjo4PTp08Xeax+/fowNDQEUL6Px8iRI+Hv76/Yj4yMxNSpUzFixAi0bNlSkV69evVyOf/r9OjRA6ampli8eDFmzJihkRiI6N3DBiSRBnXp0gXbt2/H/PnzRV+ANm3ahIYNGyIuLk6D0Smnra0NbW1tTYdBpLYrV64gPDwcv/76a5HHO3fujEaNGgEAhg0bBmtra/z000/Ys2cP+vbtW5GhKlWRDdny1qJFC6xfvx5paWmKHvT09HSEh4ejb9++2LNnD2QymeLzJioqCg8ePECPHj0UdZTn4+Hr6wtfX1/F/sWLFzF16lT4+vri448/LrfzqkpLSwsffvgh1q9fj+nTp0MikWg6JCJ6B3AIK5EG9e/fH/Hx8QgJCVGk5eTkYMeOHRgwYECh/MrmVD18+BASiQRr164FkD/satGiRQAgGmb10i+//AI/Pz9YWVnBwMAADRs2LDQ0UiKRID09HevWrSs0TEvZHKPFixejTp06kEqlcHBwwOjRowsNd2zdujW8vLxw8+ZNtGnTBoaGhnB0dMScOXPUeOQKX/svv/yCRYsWwc3NDYaGhujQoQOePHkCQRAwc+ZMODk5wcDAAD169EBCQoKojpfDYg8ePIh69epBX18ftWvXxp9//inKl5CQgAkTJsDb2xvGxsYwNTVF586dER4eXiiurKwsBAUFoVatWtDX14e9vT169eqF+/fv4+HDh7CxsQEAxZe+8prX9s8//6Bly5YwMjKCiYkJunbtihs3bojyXL16FQEBAXBzc4O+vj7s7Ozw6aefIj4+XpEnKCgI33zzDQCgWrVqiphfvgYkEgnGjBmD7du3o3bt2jAwMICvry+uXbsGAFi2bBlq1KgBfX19tG7dutBr5+TJk+jTpw+cnZ0hlUpRtWpVfPXVV8jMzBTlezlU98GDB+jYsSOMjIzg4OCAGTNmQBCE1z4eu3fvhp6eHt577z2VHr+XvUz3798Xpd+6dQsffvghLC0toa+vj0aNGmHPnj2vrU+V63zd+/fV18qOHTsgkUhw/PjxQudatmwZJBIJrl+/Xqq4VXm9HjlyRPE6Mzc3R48ePRAREfHax6NFixaQyWQ4e/asIu3cuXPIy8vDhAkTkJaWhrCwMMWxlz2Sr47aUOW9IwgCfvjhBzg5OcHQ0BBt2rQp9D4oiaNHj0IikWDXrl2Fjm3atAkSiQShoaEA1HvtyuVyzJ07F3Xq1IG+vj6qVKmCkSNHIjExsdB52rdvj0ePHokeJyKi8sQeSCINcnV1ha+vLzZv3ozOnTsDyP/Cn5ycjH79+mH+/PklqnfkyJF4/vw5QkJCsGHDhkLH582bh/fffx8DBw5ETk4OtmzZgj59+mDv3r3o2rUrAGDDhg0YNmwYmjRpghEjRgAofphWUFAQpk+fDn9/f4waNQq3b9/GkiVLcOHCBZw+fRq6urqKvImJiejUqRN69eqFvn37YseOHZg4cSK8vb0Vj4O6Nm7ciJycHIwdOxYJCQmYM2cO+vbti7Zt2+LYsWOYOHEi7t27hwULFmDChAlYvXq1qPzdu3fx0Ucf4bPPPsPgwYOxZs0a9OnTB/v370f79u0BAA8ePMDu3bvRp08fVKtWDS9evMCyZcvQqlUr3Lx5Ew4ODgAAmUyGbt264fDhw+jXrx++/PJLpKamIiQkBNevX4e/vz+WLFmCUaNG4YMPPkCvXr0AAD4+Pq+9ztTU1CJ7prOzswulbdiwAYMHD0bHjh3x008/ISMjA0uWLEGLFi1w5coVuLq6AgBCQkLw4MEDDBkyBHZ2drhx4waWL1+OGzdu4OzZs5BIJOjVqxfu3LmDzZs34/fff4e1tTUAKBoWQH7jaM+ePRg9ejQAIDg4GN26dcO3336LxYsX4/PPP0diYiLmzJmDTz/9FEeOHFGU3b59OzIyMjBq1ChYWVnh/PnzWLBgAZ4+fYrt27eLrksmk6FTp05o1qwZ5syZg/3792PatGnIy8t77TC+M2fOwMvLS/R6LM7Lhq6FhYUi7caNG2jevDkcHR0xadIkGBkZYdu2bejZsyd27tyJDz74QGl9qlzn696/r+ratSuMjY2xbds2tGrVSnRs69atqFOnDry8vEoVt42NTbGv10OHDqFz585wc3NDUFAQMjMzsWDBAjRv3hyXL19WvM6K8rIheOrUKcVQ0dOnT6NWrVqoX78+nJyccPr0aTRs2FBx7NVyqpo6dSp++OEHdOnSBV26dMHly5fRoUMH5OTkqFXPf7Vu3RpVq1bFxo0bCz1+GzduRPXq1UU9mKq+dkeOHIm1a9diyJAh+OKLLxAZGYmFCxfiypUrhT5PX31s6tevX6rrISJSiUBEFW7NmjUCAOHChQvCwoULBRMTEyEjI0MQBEHo06eP0KZNG0EQBMHFxUXo2rWrotzRo0cFAMLRo0dF9UVGRgoAhDVr1ijSRo8eLSh7i78810s5OTmCl5eX0LZtW1G6kZGRMHjwYKXxR0ZGCoIgCDExMYKenp7QoUMHQSaTKfItXLhQACCsXr1akdaqVSsBgLB+/XpFWnZ2tmBnZyf07t27yHhf9d/H5OW129jYCElJSYr0wMBAAYBQt25dITc3V5Hev39/QU9PT8jKyhLVCUDYuXOnIi05OVmwt7cX6tevr0jLysoSXd/L80ulUmHGjBmKtNWrVwsAhN9++61Q/HK5XBAEQYiNjRUACNOmTXvtNQtCwXNf3GZkZKTIn5qaKpibmwvDhw8X1RMdHS2YmZmJ0v/7ehAEQdi8ebMAQDhx4oQi7eeffxY9768CIEilUtGxZcuWCQAEOzs7ISUlRZH+8rl5NW9RMQQHBwsSiUR49OiRIm3w4MECAGHs2LGKNLlcLnTt2lXQ09MTYmNjC9XzKicnpyJfZy9f04cOHRJiY2OFJ0+eCDt27BBsbGwEqVQqPHnyRJG3Xbt2gre3t+g1JJfLBT8/P6FmzZqKtKLer6peZ3Hv3/++bvr37y/Y2toKeXl5irSoqChBS0tL9LpUNe6iFPd6rVevnmBrayvEx8cr0sLDwwUtLS1h0KBBxdYrCIJga2srtGvXTrHfsWNHYciQIYIgCELfvn2FPn36KI41atSoUKz/jUvZ51PXrl0V7z9BEITJkycLAIr8jFPmwoULhT5rAwMDBalUKvr8iYmJEXR0dERxqfraPXnypABA2Lhxo+jc+/fvLzJdEARBT09PGDVqlMrXQURUGhzCSqRhffv2RWZmJvbu3YvU1FTs3bu3yOGrZcnAwEDxd2JiIpKTk9GyZUtcvny5RPUdOnQIOTk5GDduHLS0Cj5Whg8fDlNTU/z999+i/MbGxqL5Q3p6emjSpAkePHhQovMDQJ8+fUSLojRt2hQA8PHHH4vmlzZt2hQ5OTmFVtZ0cHAQ9SCYmppi0KBBuHLlimKFQ6lUqrg+mUyG+Ph4GBsbw93dXfTY7dy5E9bW1hg7dmyhOEs7R2nq1KkICQkptHXo0EGULyQkBElJSejfvz/i4uIUm7a2Npo2bYqjR48q8r76esjKykJcXByaNWsGAGq9Jtq1ayfqbXr5HPTu3RsmJiaF0l99vl+NIT09HXFxcfDz84MgCLhy5Uqhc726gurL4bM5OTk4dOhQsTHGx8eLehP/y9/fHzY2NqhatSo+/PBDGBkZYc+ePXBycgKQP4z5yJEj6Nu3r6I3OC4uDvHx8ejYsSPu3r1b7Kqt6l6nKj766CPExMSIhrbv2LEDcrkcH330UZnErUxUVBTCwsIQEBAAS0tLRbqPjw/at2+Pffv2vbaO5s2b49y5c5DJZJDL5Th79iz8/PwUx172OmZkZCAsLEzt3seXn09jx44Vvf/GjRunVj3KDBo0CNnZ2aJpAFu3bkVeXl6R8yRf99rdvn07zMzM0L59e9F7t2HDhjA2Nha9d1+ysLCotHPmiejtwyGsRBpmY2MDf39/bNq0CRkZGZDJZPjwww/L9Zx79+7FDz/8gLCwMNHQx5I2bh49egQAcHd3F6Xr6enBzc1NcfwlJyenQueysLDA1atXS3R+AHB2dhbtv2xMVq1atcj0/84lqlGjRqGYatWqBSB/GKOdnR3kcjnmzZuHxYsXIzIyEjKZTJHXyspK8ff9+/fh7u5eLitDent7i1aFfOmPP/4Q7d+9excA0LZt2yLrMTU1VfydkJCA6dOnY8uWLYiJiRHlS05OVjm20jwHjx8/xtSpU7Fnz55Cz81/Y9DS0oKbm5so7dXn6nWEYuZKLlq0CLVq1UJycjJWr16NEydOiFYbvnfvHgRBwJQpUzBlypQi64iJiYGjo2ORx9S5TlV16tQJZmZm2Lp1K9q1awcgvwFTr149xeNS2riVUfbeBwBPT08cOHAA6enpMDIyUlpHixYtsGvXLoSFhUFXVxfJyclo3rw5AMDPzw/Pnz/Hw4cPERkZiby8PLUbkC9jrFmzpijdxsam2B8TVOXh4YHGjRtj48aNGDp0KID84avNmjVDjRo1RHlVee3evXsXycnJsLW1LfJ8/32PAvmvaS6gQ0QVhQ1IokpgwIABGD58OKKjo9G5c2elt0hQ9gXh1YbM65w8eRLvv/8+3nvvPSxevBj29vbQ1dXFmjVrsGnTppKErzZlK7gW98W+pHWW5blmzZqFKVOm4NNPP8XMmTNhaWkJLS0tjBs3DnK5XO36ytPLeDZs2AA7O7tCx19t3Pbt2xdnzpzBN998g3r16sHY2BhyuRydOnVS67pK+hzIZDK0b98eCQkJmDhxIjw8PGBkZIRnz54hICCgTB9bKyurIhciealJkyaKVVh79uyJFi1aYMCAAbh9+7bicQGACRMmoGPHjkXW8d9Gw0vldZ1SqRQ9e/bErl27sHjxYrx48QKnT5/GrFmzFHlKE3d5e3UepJ6eHiwtLeHh4QEAqFevHgwNDXHq1ClERkaK8lcmgwYNwpdffomnT58iOzsbZ8+excKFC0tUl1wuh62tLTZu3Fjk8VfnHb+UlJSkmJdMRFTe2IAkqgQ++OADjBw5EmfPnsXWrVuV5nv5a/l/Vzb9bw8foLyxuXPnTujr6+PAgQOinpU1a9aoXMd/ubi4AABu374t+nU9JycHkZGRRfaYVTYve2heveY7d+4AgGJY5o4dO9CmTRusWrVKVPa/X96qV6+Oc+fOITc3V+liLeXdW/BywSNbW9tiH//ExEQcPnwY06dPx9SpUxXpL3swX1VeMV+7dg137tzBunXrMGjQIEX6q6sTv0oul+PBgweKnhug8HOljIeHh6Ih8jra2toIDg5GmzZtsHDhQkyaNEnx+tbV1VX7da3Odar7WH/00UdYt24dDh8+jIiICAiCoBi+CqBUcRcXz6vv/f+6desWrK2ti+19BIAGDRooGolSqRS+vr6K8+no6KBx48Y4ffo0IiMjYWtrK3reVfEyxrt374o+n2JjY4v9MUEd/fr1w/jx47F582ZkZmZCV1dX9Pi/pMprt3r16jh06BCaN28uGvKszLNnz5CTkwNPT88yuRYiotfhHEiiSsDY2BhLlixBUFAQunfvrjSfi4sLtLW1ceLECVH64sWLC+V9+aXtv41NbW1tSCQSUa/lw4cPsXv37iLr+G/5ovj7+0NPTw/z588X9eytWrUKycnJipVdK7Pnz5+LluJPSUnB+vXrUa9ePUUPnra2dqGey+3btxeaO9a7d2/ExcUV2QPxsvzLm6Cr8viWRMeOHWFqaopZs2YhNze30PHY2FgABb2D/72uuXPnFiqj7DVVWkXFIAgC5s2bp7TMq4+tIAhYuHAhdHV1FUM4lfH19cX169eLXLW2KK1bt0aTJk0wd+5cZGVlwdbWFq1bt8ayZcsQFRVVKP/Lx7Uo6lynuo+1v78/LC0tsXXrVmzduhVNmjRBtWrVFMdLEzeg/PVqb2+PevXqYd26daJj169fx8GDB9GlS5fXxq6jo4OmTZvi9OnTOH36tGL+40t+fn44ceIEzp49qxjaqg5/f3/o6upiwYIFose+qNd4SVlbW6Nz5874448/sHHjRnTq1Elpj+DrXrt9+/aFTCbDzJkzC5XNy8sr9BxcunQJAAo9bkRE5YU9kESVxODBg1+bx8zMDH369MGCBQsgkUhQvXp17N27t8g5MS+Xdv/iiy/QsWNHaGtro1+/fujatSt+++03dOrUCQMGDEBMTAwWLVqEGjVqFJqD2LBhQxw6dAi//fYbHBwcUK1aNcUCKK+ysbFBYGAgpk+fjk6dOuH999/H7du3sXjxYjRu3LhS3HD7dWrVqoWhQ4fiwoULqFKlClavXo0XL16Iema7deuGGTNmYMiQIfDz88O1a9ewcePGQnOaBg0ahPXr12P8+PE4f/48WrZsifT0dBw6dAiff/45evToAQMDA9SuXRtbt25FrVq1YGlpCS8vL8UtF0rL1NQUS5YswSeffIIGDRqgX79+sLGxwePHj/H333+jefPmWLhwIUxNTfHee+9hzpw5yM3NhaOjIw4ePFhkL93L19R3332Hfv36QVdXF927d39tD9PreHh4oHr16pgwYQKePXsGU1NT7Ny5U2nvkL6+Pvbv34/BgwejadOm+Oeff/D3339j8uTJRQ7ve1WPHj0wc+ZMHD9+vNDCQ8p888036NOnD9auXYvPPvsMixYtQosWLeDt7Y3hw4fDzc0NL168QGhoKJ4+fVrkfUHVvU5l719ldHV10atXL2zZsgXp6en45ZdfCuUpadwAin29/vzzz+jcuTN8fX0xdOhQxW08zMzMVL63aYsWLRSLw/y3kejn54fg4GBFPnXZ2NhgwoQJitvKdOnSBVeuXME///xTpsM+Bw0apJi/XlTjD1DttduqVSuMHDkSwcHBCAsLQ4cOHaCrq4u7d+9i+/btmDdvnmiefEhICJydnXkLDyKqOBW55CsR5Xv1Nh7F+e8tKwQhfzn93r17C4aGhoKFhYUwcuRI4fr164WWls/LyxPGjh0r2NjYCBKJRHRLgFWrVgk1a9YUpFKp4OHhIaxZs0aYNm1aodsG3Lp1S3jvvfcEAwMD0XL3/10m/6WFCxcKHh4egq6urlClShVh1KhRQmJioihPq1athDp16hS61sGDBwsuLi7FPh5FPSYvb+Px888/i/K9vIXC9u3bRelFPfYv6zxw4IDg4+OjeFz+WzYrK0v4+uuvBXt7e8HAwEBo3ry5EBoaKrRq1Upo1aqVKG9GRobw3XffCdWqVRN0dXUFOzs74cMPPxTu37+vyHPmzBmhYcOGgp6e3mtv6aHsel4aPHiw6DYer5br2LGjYGZmJujr6wvVq1cXAgIChIsXLyryPH36VPjggw8Ec3NzwczMTOjTp4/w/PnzImOaOXOm4OjoKGhpaYleAwCE0aNHi/Kq89zcvHlT8Pf3F4yNjQVra2th+PDhQnh4eKHX9cvrvH//vtChQwfB0NBQqFKlijBt2rRCt1hRxsfHRxg6dKgorbj3pEwmE6pXry5Ur15dcauM+/fvC4MGDRLs7OwEXV1dwdHRUejWrZuwY8eOQtf56m08VL3O4t6/yl4rISEhAgBBIpGIbjvyKlXiVqa41+uhQ4eE5s2bCwYGBoKpqanQvXt34ebNm6+t86UDBw4IAAQdHR0hPT1ddCw+Pl7xGJw7d65Q2f/GUtTnk0wmE6ZPn65477Zu3Vq4fv264OLiUurbeLyUnZ0tWFhYCGZmZkJmZmah4+q+dpcvXy40bNhQMDAwEExMTARvb2/h22+/FZ4/fy66Lnt7e+H7779X+RqIiEpLIgilWLWCiOgt4OrqCi8vL+zdu1fTodBrBAQEYMeOHUhLSytxHRs2bMDo0aPx+PFjpQtWEakrLy8PDg4O6N69e6F50kDZvHb/a/fu3RgwYADu378Pe3v7MquXiKg4nANJRETvlIEDB8LZ2RmLFi3SdCj0Ftm9ezdiY2NFCySVt59++gljxoxh45GIKhTnQBIR0TtFS0sL169f13QY9JY4d+4crl69ipkzZ6J+/fpo1apVhZ07NDS0ws5FRPQSeyCJiIiISmjJkiUYNWoUbG1tsX79ek2HQ0RU7jgHkoiIiIiIiFTCHkgiIiIiIiJSCRuQREREREREpBI2IImIiIiIiEglb+UqrAKOajoEqkjRtzUdAVUg4XKYpkOgCqTVqY+mQ6AKJDy6pOkQqAJtdit8v0x6ew0Q3tzvayk5O0tc1lSvdxlGUjm8lQ1IIiIiIiKisiCRcNDmq9iAJCIiIiIiUkKLs/5E+GgQERERERGRStiAJCIiIiIiIpVwCCsREREREZESnAMpxkeDiIiIiIiIVMIeSCIiIiIiIiW02AMpwkeDiIiIiIiIVMIeSCIiIiIiIiUk7HMT4aNBREREREREKmEDkoiIiIiIiFTCIaxERERERERKcBEdMT4aREREREREpBL2QBIRERERESnBRXTE+GgQERERERGRStiAJCIiIiIiqiQWLVoEV1dX6Ovro2nTpjh//nyx+bdv3w4PDw/o6+vD29sb+/btK9f42IAkIiIiIiJSQkuiVeJNXVu3bsX48eMxbdo0XL58GXXr1kXHjh0RExNTZP4zZ86gf//+GDp0KK5cuYKePXuiZ8+euH79emkvWymJIAhCudWuIQKOajoEqkjRtzUdAVUg4XKYpkOgCqTVqY+mQ6AKJDy6pOkQqAJtdlul6RCoAg0Q3tzva6VpW0jQRq38TZs2RePGjbFw4UIAgFwuR9WqVTF27FhMmjSpUP6PPvoI6enp2Lt3ryKtWbNmqFevHpYuXVriuIvDHkgiIiIiIqJykJ2djZSUFNGWnZ1dZN6cnBxcunQJ/v7+ijQtLS34+/sjNDS0yDKhoaGi/ADQsWNHpfnLAhuQRERERERESkiEkm/BwcEwMzMTbcHBwUWeJy4uDjKZDFWqVBGlV6lSBdHR0UWWiY6OVit/WeBtPIiIiIiIiMpBYGAgxo8fL0qTSqUaiqZssAFJRERERERUDqRSqcoNRmtra2hra+PFixei9BcvXsDOzq7IMnZ2dmrlLwscwkpERERERKSMIC/5pgY9PT00bNgQhw8fVqTJ5XIcPnwYvr6+RZbx9fUV5QeAkJAQpfnLAnsgiYiIiIiIKoHx48dj8ODBaNSoEZo0aYK5c+ciPT0dQ4YMAQAMGjQIjo6OinmUX375JVq1aoVff/0VXbt2xZYtW3Dx4kUsX7683GJkA5KIiIiIiEgZNXsSS+Ojjz5CbGwspk6diujoaNSrVw/79+9XLJTz+PFjaGkVDCL18/PDpk2b8P3332Py5MmoWbMmdu/eDS8vr3KLkfeBpDcf7wP5TuF9IN8tvA/ku4X3gXy38D6Q75Y3+T6QkIWUvKx2+7KLo5JgDyQREREREZEyFdgD+SbgIjpERERERESkEjYgiYiIiIiISCUcwkpERERERKQMh7CKsAeSiIiIiIiIVMIeSCIiIiIiImXk7IF8FRuQb4mNG49h1aqDiItNgYeHE76f8hF8fKppOixSgyAIWLA6FNv3XkNKWjYaeDtg2vh2cHWyUFrmQvhTrNp8ETfuxCA2Ph0Lf+gO/5Y1RHkWrAnFviO3ER2TCl0dbdRxt8W4Yc1Rt7Z9eV8SFUMQBCzYH4ntoVFIzcpDfVczTOtTC642hkrLbD79DFtOP8OzhCwAQA07I3ze0RXveVoBAJLSc7FwfyRO305AVFI2LI100c7bGl90doOJAT/uK5IgCJi/YC+2bz+NlNRMNKjvhqBp/eHqaltsuY0bj2PV6hDExuV/lk/5ri98fFwVx7duO4W9ey/gxs0nSE/PwoVzv8DUtOA18/RZPBYv3oez5+4gLi4FtrZmeL97E3w2shP09PgaqCiCIGDBhsvY/s9tpKTnoEHtKpg21g+ujmZKy1y4FoVVO67hxt14xCZkYOHUdvD3cxXlSc/Mxa+rL+Bw6CMkpWTDyc4En/SojX5dPcv5iuh1vKd/gRrD+0DX3BRxpy/jwqggpN57pDS/REsL3kFj4frx+9C3s0bm8xhErt2F6z8sFuUz9XBDvZ++gW2rxtDS0Ubyzfs42XssMp5Elfcl0as4hFWEQ1jfAvv2XcTs4B0YPbob/tw1Ge4eThg2dAHi41M0HRqpYeXmi9jwZxiCvvbHtqX9YaCvi2ET/kR2dp7SMpmZufCoYYOp49oqzePqZIEpX7bBnjWfYOPCvnC0M8PQCX8iISmjPC6DVLTyyGP8ceIZgvrUwtZxDWEo1cbwpeHIzpUpLWNnJsX4btWx4+tG2D6+EZrVtMCYVddwNyodABCTko2YlBx8+34N7Pm2CWYN8MTJWwn4fsutiros+teKlSHY8McxBAX1x7at38DAUIqhwxcgOztXaZl9+y4i+KedGD26K3btDISHuyOGDl+A+PhURZ7MzBy0bFkbn43sWGQdDx5EQxAEzJjeH3//NQWBkz7Elq0n8fvc/5X5NZJyK7dfxYb/3UTQF82xbe77MNDXwbDvDiA7p5jP86w8eFSzxNTRvkrzzF5+DqcuPsWcb1rj7+W9MahnHcxcFIojocobKlT+PL8dDvcvPsH5z4JwsGlf5KVnos2BVdCS6ikvM3E4aozqj4tjZuBvzy4Im/gLPL8dhlpjP1HkMXarivanNiHl1gMcbv0J9vm8j+szF0OWlV0Rl0WkVKVuQF6/fl3TIbwR1q45hD59m6N3bz/UqOGA6dMHQF9fFzt3ntF0aKQiQRCwfvtlfPZJE7RrUR3u1W3w0+ROiIlPx6FT95WWe69ZNYwb1hzt36uhNE/39h7wa+SCqg7mqFnNGpNGv4e09Bzcvh9XHpdCKhAEAeuPP8VnHVzQztsG7g7GmD3AEzEpOTh0Tfnz0sbLGq1qW8HVxhDVbA0xrqsbDKXaCH+UDACoZW+M+UO80MbLGs7WBmhW0wLjurjh6I045Mn462lFEQQB69cfwajPOsG/XV14uDthzuzBiIlJxqFD4UrLrVl3BH37NEfvXr6oUcMe04P6Q19fDzv/LPgsDxjcFiOGd0TdukWPMHmvZR0EzxqEFs1ro2pVa7Rr64NPh/jjYEhYWV8mKSEIAtbvuoHP+tdDO18XuLtZ4qdvWiEmPgOHzihv6L3XuCrGBTRC++auSvOE3XyBnv410bSuPZzsTPBRFw+4u1ni6u3YcrgSUpXHuEG4/sMSPNtzGEnXbiN00LcwcLBF1Z7+SsvY+NXHs/8dxvN9x5H+6Bme7DyAqIOnYNXER5Gn7o9f4fm+Ewib+DMSwyKQ9uAJnv11BNmxCRVxWURKVboGZGpqKpYvX44mTZqgbt26mg6n0svJycONG4/h51cwfEVLSwu+fp4Iu/JAg5GROp5GJSM2IQN+DZ0VaSbGUvh42iHsxvMyO09Orgxb/7oGE2MpPKrblFm9pJ6n8VmIS82Bb62C4ckmBjrwcTFB+EPVRg7I5AL+vvwCGdky1HNVPiwuNSsPxvo60NGudB/3b62nT+MRG5cCP18PRZqJiQHq+rjiSnjRn8uKz3Jfd0WalpYW/Hw9cCUsslTxpKZmwszMqFR1kOqeRqciNjETfvUdFGkmRnrw8bBBWERMqequV7sKjpx9jBdx6RAEAWfDn+PhsxQ0b+hY2rCphIyqOcHA3hbRhwp+6MlNSUPcuXBY+9ZXWi72zBVUadcMJjVdAQDmPu6wadEQUf+cyM8gkcCha2uk3nmINvtXoteLM+hwdhucerQrz8shZQR5ybe3UKWZEHHixAmsWrUKO3fuhIODA3r16oVFixa9tlx2djays8Vd+XrSHEiLGTbwNklMTINMJoeVlako3drKBJEPojUUFakrNiF/OKmVpXj+m7WFIeISSj/U9OiZB/h6xj5kZuXCxsoIq3/pBQtzg1LXSyUTl5oDALAyFn9OWRvrIfbfY8rceZ6G/vMuIztPDkM9bSz41Bs17IpuHCSm5WDJwYfo6+tQ5HEqH7Fx+T3C//1ctrI2RVxs0T8QJCYV/VluZWWCB5EvShzLo0cx+GPjMUz8pleJ6yD1xCZmAgCs/vMZa21ugLh/j5XUlFG+mDL/FFp9vAU62hJItCSY+WULNPbmnHZNMbDL/zE260W8KD3rRTz07ayVlrs5ezl0TY3R7dY/EGQySLS1Ef7d73i46S8AgL6tFXRNjFB70nCEfz8XVyb+AodOLdHyz4U43GYQYk5cKL+LInoNjTYgo6OjsXbtWqxatQopKSno27cvsrOzsXv3btSuXVulOoKDgzF9+nRR2tRpgxAUFFAOEROVjb9CIjDt18OK/aWze5br+ZrWr4pdKz9GYnImtu+9hnFBf2Pb0v6wslC+YAuVnb8uRSNo2x3F/pLh3iWuy9XWEH9OaIS0LBkOhMcgcFME1o+pX6gRmZaVh89WXEWNKkYY3cm1xOej19vz13lMC9qs2F+2ZJQGoynw4kUSho1YhE4dG6Bv3xaaDuet9deRe5g2/7Rif+mMDuV2rg17biI8IhaLg9rD0dYYF65HY8aiUNhaGsKvAXshK4LrgO5ovKzge+fxriNLVI9L385wHdgdZwZ8jaQb92BRzxMN5wbmL6azfjckWvmjRp7+7zBuz10HAEgKvwVrvwao8Vk/NiAr2lvak1hSGmtAdu/eHSdOnEDXrl0xd+5cdOrUCdra2li6dKla9QQGBmL8+PGiND1paFmGWqlZWBhDW1ur0II5cfGpsLY2VVKKNK1N8+rw8Sz4xTgnN39hhfiEDNhaGSvS4xIz4Fmj9ENNDQ104eJkDhcnc9SrY4+OA9Zgx9/XMfLjJqWum16vbR1r+EwoeD/m5AkAgPi0HNiaSRXpcWk58HQwKbYuPR0tuPy7Umudqia49jgVG048xfS+BUMf07PyMHxZOAylOljwqRd0OXy1XLVt64O6r6yUmvPvQinx8fmroL4UH5cCD0+nIuuwMC/6szy+hJ/lL2KSMGjwXNSvVw0zZwxQuzyprk0zZ/h4FKyum5OTvxBWfFImbK0KfqSLS8qEp5tlic+TlZ2HuWsvYsGUdmjdNH+6g7ubJW7dj8fqndfYgKwgT/ccQdy5grnM2v+OeNOvYoWs6IK5qPpVrJAUpnwBs3o/f4ubs5fj0dZ9AIDk63dg5OKA2oEjEbl+N7LjEiHPzUXyTfE6CCkR92HTomFZXhKR2jTWgPznn3/wxRdfYNSoUahZs2aJ65FKpZBKpaI0Ae/G8FUA0NPTQZ06zggNvQV//3oAALlcjrOhtzDw49YajY2UMzbUg7FhwetUEATYWBoi9PITeNbM/yKSlp6NqxHR6N+j7OcCywUBOcWs9klly0hfB0b6BR+3giDA2kQPZ+8kwtMxv8GYlpWHq49S0c9PvS+BgiAgJ6/gl9G0rDwMWxoOPR0tLB7mDamudtlcBCllbKQPYyN9xb4gCLCxNkXo2dvw9KwKAEhLy0T41Yfo3++9IutQfJafvS36LA89exsfD2ylVjwvXuQ3HuvUcUbwrEHQ0uIPCOWpyM9zCwOEhj2HZ/X8W+ykpefg6q1Y9O/qoaya18rLkyM3Tw4tLYkoXUtLArkglLheUk9eWjrS0tJFaZlRMbBr54uk8PwGo46JEayb1sW9JZuLqiI/j6E+BLn4eRNkMkj+fX7lubmIv3ANpu7iBbNMarki/dGzsrgUohLTWAPy1KlTWLVqFRo2bAhPT0988skn6Nevn6bCeaMFDPHHpIlr4eXlAh8fV6xbdwSZmTno1ctP06GRiiQSCQb1aYCl68/B1ckcjnZmmL/6DGytjODforoiX8BXO+DfsgY+7lUPAJCekYPHz5IUx59GpSDibgzMTPXhUMUUGZm5WLrhHNo2rw4bKyMkJmdi065wvIhLQ6fWJf/hhkpHIpFgUCsnLA15BBcbQzhZ6mP+P5GwNdWDv3fBnJkhi6/A39sGA1vm91r9tvc+WnpawcFCivQsGfZefoHz95OwYmT+jwxpWXkYujQcWTkyzPm4NtKy8pCWld8bZmmsB+3/fPGk8iGRSDBoUFssWfoPXFxs4eRkhXnz/4KtrRn8/Qt+EBo8ZB7a+9fFxwNbAwCGDG6LiYHr8z/LvV2wbv1RZGZmo9cHBbd1iI1NRlxcCh4/yu/puHPnOYyMpLC3t4S5uRFevEjCJ4N+h4ODJSZ+2wsJCQW3ALGxUb7YEpUdiUSCQR/UwdLNYXB1MIWjnQnmr78EWytD+Pu5KPIFTNoHfz9XfPx+/pSd9MxcPH5e0AP9NDoNEffjYWYihYOtMYyN9NDY2w4/rzwPqZ4OHKsY4/zVKPzv8D1MGtG0wq+TCtyaux5e349C6t1HSIt8Cp+ZXyLzeQye7D6kyNP20Fo83RWCO4s2AgCe/XUUXt99hozHz5F84x4s6nvCY/wQPFi9U1Em4udVaL71d8ScuIAXR8/BoVNLOHZvg8OtB1X4Nb7z5BzC+iqNNSCbNWuGZs2aYe7cudi6dStWr16N8ePHQy6XIyQkBFWrVoWJSfFDuShfly6NkJCQigXz/0JsbAo8PZ2wYuVYDmF9wwzr3wiZmbmY+sshpKRlo6G3A1b83AtSacHb9PHzZCQmFyzCcP32Cwwet0OxP3vRcQBAz061MTuwI7S1JIh8nIgvDvyFxOQsmJvqw9ujCjbO74ua1ZRP7qfyN6ytMzJzZJi27TZSMvPQoJoZlo+sK+oxfByXhcT0gvsGxqflYtLGCMSmZMPEQAe17I2xYmRdNHfPHxZ382kqrj7K/wLa8cezovMdmtIMjpZcOKmiDB/WHpmZ2Zg6bRNSUjLQsEF1rFw+BlKpriLPk8exSExMU+x36dIICYlpmD9/L2Lj8j/LVy4fI/os37L1JBYu2qfYH/jJbwCA4FmfoNcHvjh9JgKPHsfi0eNYvNd6siim2xHiG5RT+RnWxweZWXmYOv80UtJy0LBOFaz4oSOkeq9+nqciMTlLsX/9ThwGTyx4bmcvPwcA6OlfE7Mn5Pdc/xbYBr+tuYhv5hxDcmo2HGyNMW5wQ/QrRc8mlV7EnBXQMTJAk+UzoGduithTl3C00zDIswsWRTOuXhVS64KVty+O/QE+M79E48XTILW1QubzGNxbthXXZxQsIPl09yFc+CwIdQJHoOH875F6OxIne3+B2NOXKvT6iP5LIgiVZ9zD7du3sWrVKmzYsAFJSUlo37499uzZo3Y9Ao6WQ3RUaUXf1nQEVIGEy2GaDoEqkFanPpoOgSqQ8IhfjN8lm91WaToEqkADhDf4+1rq9pKXNXn7/o9VqokR7u7umDNnDp4+fYrNm5WPGyciIiIiIqKKV2nuA/kqbW1t9OzZEz179tR0KERERERE9C7jbTxEKlUPJBEREREREVVebEASERERERGRSirlEFYiIiIiIqJKgUNYRdiAJCIiIiIiUkIQZCUu+zbegZlDWImIiIiIiEgl7IEkIiIiIiJSRs4hrK9iDyQRERERERGphA1IIiIiIiIiUgmHsBIRERERESnDVVhF2ANJREREREREKmEPJBERERERkTLsgRRhDyQRERERERGphA1IIiIiIiIiUgmHsBIRERERESnDIawi7IEkIiIiIiIilbAHkoiIiIiISBn2QIqwB5KIiIiIiIhUwh5IIiIiIiIiZeTsgXwVeyCJiIiIiIhIJWxAEhERERERkUo4hJWIiIiIiEgZLqIjwgYkERERERGRMmxAinAIKxEREREREamEDUgiIiIiIiJSCYewEhERERERKcMhrCLsgSQiIiIiIiKVsAeSiIiIiIhIGTl7IF/FHkgiIiIiIiJSCXsgiYiIiIiIlOEcSBH2QBIREREREZFK2IAkIiIiIiIilbyVQ1glWWmaDoEqkDwsXNMhUAWKXnZZ0yFQBbLv8pGmQ6AKJL94U9MhUAWq5irRdAhEquEQVhH2QBIREREREZFK3soeSCIiIiIiojLB23iIsAeSiIiIiIiIVMIGJBEREREREamEQ1iJiIiIiIiUkQuajqBSYQ8kERERERGRMnJ5ybdykpCQgIEDB8LU1BTm5uYYOnQo0tKU34kiISEBY8eOhbu7OwwMDODs7IwvvvgCycnJap+bDUgiIiIiIqI3yMCBA3Hjxg2EhIRg7969OHHiBEaMGKE0//Pnz/H8+XP88ssvuH79OtauXYv9+/dj6NChap+bQ1iJiIiIiIiUqWSrsEZERGD//v24cOECGjVqBABYsGABunTpgl9++QUODg6Fynh5eWHnzp2K/erVq+PHH3/Exx9/jLy8POjoqN4sZA8kERERERFROcjOzkZKSopoy87OLlWdoaGhMDc3VzQeAcDf3x9aWlo4d+6cyvUkJyfD1NRUrcYjwAYkERERERFRuQgODoaZmZloCw4OLlWd0dHRsLW1FaXp6OjA0tIS0dHRKtURFxeHmTNnFjvsVRk2IImIiIiIiJSRCyXeAgMDkZycLNoCAwOLPM2kSZMgkUiK3W7dulXqy0lJSUHXrl1Ru3ZtBAUFqV2ecyCJiIiIiIjKgVQqhVQqVSnv119/jYCAgGLzuLm5wc7ODjExMaL0vLw8JCQkwM7Ortjyqamp6NSpE0xMTLBr1y7o6uqqFNur2IAkIiIiIiJSpoIW0bGxsYGNjc1r8/n6+iIpKQmXLl1Cw4YNAQBHjhyBXC5H06ZNlZZLSUlBx44dIZVKsWfPHujr65coTg5hJSIiIiIiekN4enqiU6dOGD58OM6fP4/Tp09jzJgx6Nevn2IF1mfPnsHDwwPnz58HkN947NChA9LT07Fq1SqkpKQgOjoa0dHRkMlkap2fPZBERERERETKVLLbeADAxo0bMWbMGLRr1w5aWlro3bs35s+frziem5uL27dvIyMjAwBw+fJlxQqtNWrUENUVGRkJV1dXlc/NBiQREREREdEbxNLSEps2bVJ63NXVFYIgKPZbt24t2i8NDmElIiIiIiIilbAHkoiIiIiISBl52fTcvS3YA0lEREREREQqYQ8kERERERGRMpVwER1NYgOSiIiIiIhIGQ5hFeEQViIiIiIiIlIJG5BERERERESkEg5hJSIiIiIiUoZzIEXYA0lEREREREQqYQ8kERERERGRMuyBFGEPJBEREREREamEDUgiIiIiIiJSCYewEhERERERKSEIJb8PpKQM46gs2ANJREREREREKmEPJBERERERkTJcREeEPZBERERERESkEvZAViKCIGD+4gPY/uc5pKRmokG9agj6rhdcXWyKLbdxy2msWncMsXGp8KhljymTPoCPt3OR9Q8fvRInT9/Got8D4N/WCwCQmJSOCYGbcPtuFJKS0mFlaYx2retg/BddYGysXy7XSoUJgoAF/0Rie+hzpGbmoX41M0zr4w5XW0OlZTafeootp57hWUIWAKCGvRE+71gN79W2AgAkpedi4T+ROH07AVGJWbA00kU7Hxt80cUNJgZ8+1c2JgNGwLB9T2gZGSPn1lUkLfkJsqgnxZbRsrSB6eAx0G/gB4lUiryop0haMBO59yIqKGoqaxs3HsOqVQcRF5sCDw8nfD/lI/j4VNN0WKQGQRCw8PATbL8Yg9SsPNR3NsXU96vB1dpAaZkt56Kx5fwLPEvKBgDUsDXAqDZOeK+WhShf2ONUzAt5jKtP06ClJYGHnSFWBHhCX1e7XK+Jilf1q7Gw7dcHOqamSLl4GZFTpiPr4SOl+eufPAx9J8dC6dEbNiJy6sxC6R5rlsOi9Xu4NWI0EkMOl2nspAL2QIqwB7ISWbHmKDZsPoWg73tj2x9fwMBAD0NHrUB2dq7SMvv2hyH4lz0YPbI9dm0ZBw93BwwdtQLx8amF8q774yQkksJTebW0JGjXpg6WzBuCA3smYvbMfjhz7i6m/bCzTK+Pirfy8GP8ceIpgvq6Y+tXjWCop43hS8OQnStTWsbOXB/ju1fHjgmNsX1CYzSraYExK6/iblQaACAmORsxydn4tkcN7JnUBLMGeuJkRDy+38zGRWVj3GsQjLp+hOQlsxH7zaeQZ2XCKmg+oKuntIzEyATWs1cAsjzEz/gSMWP6IWXNPMjTUiowcipL+/ZdxOzgHRg9uhv+3DUZ7h5OGDZ0AeLj+Zy+SVadfI4/zkZjWg83bPnMGwZ6WhixLgLZucq/hFYx08NXHZyxfZQ3to/yRlM3M4zZeBt3X2Qo8oQ9TsWIdRHwq2GOLZ95Y9tn3hjQzA5aRfxvp4rjMHIY7AI+wYPvg3Dtg76QZ2bCc91KSPSUf35f6/EhLjZuodhufjwEABD/94FCee0/HQyUYhEXorJWogbk/fv38f3336N///6IiYkBAPzzzz+4ceNGmQb3LhEEAes3nsSo4f7wb+MFj1oOmPNDP8TEpuDQketKy63ZcBx9ezVF755NUKO6HaZ/3xv6+rrYufuCKF/ErWdYvf44Zk3vW6gOM1NDDOjrB+86VeHoYAnfpjUxoK8fLl5+UObXSUUTBAHrjz/BZx1c0c7bBu6Oxpj9cW3EJOfg0LU4peXaeFmjVR1ruNoaopqtIcZ1qw5DqTbCH+Z/2azlYIz5Q73RxssaztaGaFbLEuO6VsfR63HIk/HXtMrEqHs/pG5fjazzJ5D36B6S5gZB29Ia+s1aKS1j3HsQZHExSJo/E7l3b0IW8xzZYecgi35WgZFTWVq75hD69G2O3r39UKOGA6ZPH5D/mb7zjKZDIxUJgoD1Z6IwsrUT2nlawt3OCLM/rIGY1BwcjkhQWq6NhyVauVvA1doArtYGGNfeGYZ6Wrj6pOAH4dn7HuJjXzsMb+WImlUMUc3GAJ29raGnw/4ATbL/dBCeLlyKxJAjyLh1B/e+ngi9Kraw7OCvtExeQiJy4+IUm0Xb1sh6+Agp586L8hl6esB+2BDc//a78r4MIpWp/Ylz/PhxeHt749y5c/jzzz+Rlpbf0xEeHo5p06apXM+RI0dQu3ZtpKQU/lU1OTkZderUwcmTJ9UN74319FkCYuNS4de0piLNxMQAdb2dceVq0UMgcnLzcCPiGfya1VKkaWlpwa9ZTVGZzMwcfB24EVMnfwAba9PXxvIiJhkhR66hccPqpbgiUsfT+CzEpeTA95WhSiYGOvBxMUV4ZLJKdcjkAv6+/AIZ2TLUq2amNF9qVh6M9XWgo80vHJWFdhUHaFtaIzu84IuDkJGOnDs3oOfurbScfpOWyL0fAYtvg1Fl3X7Y/L4Bhu17VETIVA5ycvJw48Zj+Pl5KtK0tLTg6+eJsCv8Qe9N8TQxG3FpufCtXvA5bKKvAx8nY4Q9KTw6qCgyuYB9V+OQmSNHXWcTAEB8Wi6uPk2DpZEuBiy7hpbBFzFo5XVcesjeaU2SVnWCnq0tkk8V/MgjS01DWthVmDSop1IdEl1dWPd8HzHb/xSla+nro+a8XxA5bQZy45T/mEwVQC6UfHsLqT0JatKkSfjhhx8wfvx4mJiYKNLbtm2LhQsXqlzP3LlzMXz4cJiaFm7QmJmZYeTIkfjtt9/QsmXLYuvJzs5Gdna2KE0q5EIq1VU5lsogNi7/n4qVlYko3crKGHFxRf/DSUxMh0wmh5WV8X/KmOBBZIxiP/jnPahf1xX+bbyKjWH8xD9w+NgNZGXlok2r2vgxqE9JLoVKIC41BwBgZSIe7mJtoofYf48pc+d5Gvr/fgnZeXIYSrWxYKg3atgZFZk3MS0HSw5Eoq+fQ9kETmVCyyJ/zqo8Sdw7IU9KgPa/x4qiU8UROp16Ie1/m5C6fQ30ataG2fCvIeTlIfPo3+UaM5W9xMS0fz/Txf8Xra1MEPkgWkNRkbri0vKnnVgbi7+HWBnrIS5V+ZQUALgTnY7+y68jJ08OQz1tzB/gjhr/zoN/mpg/133Rkaf4ppMLPOyNsCcsFp+uuYn/ja1b7PxKKj+6NvnrVOTGxYvSc+LioGtjrVIdlh3aQcfUBDE7donSXacEIvXyFSSGHCmbYKnkOAdSRO0uiGvXruGDDz4olG5ra4s4NX4dCQ8PR6dOnZQe79ChAy5duvTaeoKDg2FmZibagn/ernIcmrLn78uo32yyYsvLUz7PrTQOH7uBsxfuYfK3r++VCPzmffy55SssnjcET57EI/iXPeUSEwF/XYxGw2+OK7bcUgwndbU1xJ/fNsbW8Q3Rr7kjAjdG4F50eqF8aVl5+Gz5VdSwM8LozlyQQ5MMWnWE3ZZjik2iXcIFjSRayH1wG6l/LEFe5B1kHNyN9JD/wahTr7INmIiU+issFg1nnFNspZke4GptgD9H+2DLSG981KQKJu+8h3sx+XMgX3Zk9G1cBb0a2qK2gxEmdXFFNWsD/Hk5pphaqSxZ9+iGJtcvKTYt3dIvSGfb90MkHj+J3JiC59HCvw1MfZvi4YzgUtdPVNbUftWbm5sjKioK1aqJv4BeuXIFjo6FV5NS5sWLF9DVVd5LqKOjg9jY2NfWExgYiPHjx4vSpMIhlePQlLata6Oud0HcOTl5AID4+FTY2hT8+hwfnwYP96J7iywsjKCtrYX4+DRRenx8Kqz/Hap69vw9PH4Sj8YtpojyjP16HRo1qIYNqz5XpNlYm8LG2hTVq9nCzNQQA4cswucj2oviobLR1ssaPi4Fj2tOXv4XjvjUHNiaSRXpcak58HQ0LlT+VXo6WnCxyf+Fuk5VU1x7nIINx59g+kceijzpWXkYviRM0UOpy+GrGpV1/iRybhfMGZf8u1COlrkl5IkFv2JrmVsiN/KO0npkiXHIfRIpSst78hAGvm3KOGKqCBYWxv9+pouHJMa98plOlU9bT0v4VC34nM7Jy2/pxaXlwuaVUSXxaTnwsC96dMhLejpacLHK70ms42iM60/TseFMFKb3rA6bf3s0q9uKexrdbAwQlVT8SBUqOwmHjiIt7Kpi/+VCObrWVsh95XurnrU10m++fsE6PUcHmDX3xe1RY0XpZr7NoO/ijCbh4jmR7kvmI+XCJdzsP6g0l0HqYg+kiNoNyH79+mHixInYvn07JBIJ5HI5Tp8+jQkTJmDQINVfzI6Ojrh+/Tpq1KhR5PGrV6/C3t7+tfVIpVJIpVJxYlblH75qbKQPY6OCW2QIggAbaxOEnrsLT4/8hnhaWhbCrz1G/z6+Rdahp6uDOp6OCD13V3FLDrlcjtBz9/Bxv+YAgBGftkGfD5qIynX/8FcETngfbVrVVhqfIOS/UV42bKlsGenrwEi/4O0nCAKsTfVw9k4iPJ3yhzGnZeXh6qMU9Guh+g8zL+t62SB9Wc+wJWHQ09HC4uE+kHKpd40TMjMgy8wQpckS4iD1aYy8yLsAAImBEfRq1UH6fuWrIedEXIWOg4soTcfRGbJYDnd8E+np6aBOHWeEht6Cv389APmf6WdDb2Hgx601GhspZyTVhpG0oFEnCAKsjXVx9n4yPP9tMKZl5eHq0zT0a2KnVt2CICBXlt8gdbSQwtZEFw/jMkV5HsZnomVNi6KKUzmQp6cjK108yicnJgZmzX2REXELAKBtbATjej6I/mPza+uz/bAXcuPjkXjkuCj92ZIVeLF1hyit3oG/8PCH2Ug8xCGtpFlqNyBnzZqF0aNHo2rVqpDJZKhduzZkMhkGDBiA77//XuV6unTpgilTpqBTp07Q1xffazAzMxPTpk1Dt27d1A3vjSWRSDBoYEssWXEYLi42cHK0xLxF+2FrY6poHALA4OFL0b6tFz7u3wIAMOSTVpg4ZQu86jjBx8sZ6/44iczMHPTq2RhAQa/ifznYW6CqU/7cquMnIxAXnwrvOlVhaCjFvfvRmPP7XjSo5wonR8sKuHqSSCQY1Koqlh58CBcbAzhZGWD+vgewNdODv3fBHIohC6/A38cGA99zAgD89td9tPS0hIOFPtKzZdh76QXO30vCis/qAcj/0jJ0cRiycmSY80ltpGXlIS0r/0cBS2M9aGtx6ffKIv2vLTDp+ynyop5A9uI5TAZ8BllCHLLOFnypsJqxCJlnjyFjX/4w/fQ9m2D90yoYfxiAzFOHoFerDgw79ETy4lmaugwqpYAh/pg0cS28vFzg4+OKdeuO5H+m9/LTdGikIolEgkF+9lh27ClcrPThZCHF/MNPYGuih3aeBf9Th6y+Af/alhjYLP/H8t8OPsJ7NS1gb66X/3l+NQ7nH6ZgxWBPRb2ftnTEwsNP4G5nBA97Q/zvSiwiYzMxt5+7Rq6V8kWtXg+nMZ8h6+FDZD95hqrjv0DOixgkHCwYEVf7jzVIOHgI0es3FhSUSGDb5wPE7twNyMRTmV6uzvpf2c+eI/spV9omzVK7Aamnp4cVK1Zg6tSpuHbtGtLS0lC/fn3UrFnz9YVf8f333+PPP/9ErVq1MGbMGLi753/43bp1C4sWLYJMJsN3371bSxYPH9IGmZk5mDpjB1JSM9GwfjWsXDxctCDQk6fxSEwq+OWrS6d6SEhMw/zFBxAblwpPdwesXDwM1v9ZjKc4Uqkutv95DsG/7EFOTh7sq5ijfTtvjPi0bZleHxVvWDtnZObIMG3rbaRk5qGBmxmWf1ZP1GP4OD4TiekFQ5XiU3MwaWMEYpOzYWKgg1oOxljxWT0098j/knLzSSquPsofDtdx5lnR+Q5N9YWjFRddqCzS/lwPib4+zD+fDC0jY+REhCN++pdAbsHzrW3nCG1Tc8V+7r0IJAR/C9NPPofJR0OR9+I5Ulb+hszjhe8jRm+GLl0aISEhFQvm/4XY2BR4ejphxcqxHML6hhna0iH/8/x/D5CalYcGzqZYPtgTUt2C6QNPErKRmF4wyichLReTdt5DbGoOTPS1UauKEVYM9oRfDXNFnkF+9sjOleOnfQ+RnJkHdztDrAyoDWcr8Q/xVLGeL1sJbUMDuM2aAR1TU6RcuISIgOEQcgo+v6UuztCxEPcUm7Xwg9TRsdDqq1QJvaWrqZaURBBKd2dSmUyGa9euwcXFBRYW6g2hePToEUaNGoUDBw7gZRgSiQQdO3bEokWLCs2zVFnWXyUrR28k+bF9mg6BKlD0ktcvrkVvD/v//aTpEKgCybev03QIVIHOf3v29ZnoreEbeUvTIZSY/NDY12dSQst/QRlGUjmo3QM5btw4eHt7Y+jQoZDJZGjVqhXOnDkDQ0ND7N27F61bt1a5LhcXF+zbtw+JiYm4d+8eBEFAzZo11W6IEhERERERlQsuoiOi9lKMO3bsQN26dQEAf/31Fx48eIBbt27hq6++KvGQUwsLCzRu3BhNmjRh45GIiIiIiKiSUrsBGRcXBzu7/FXE9u3bh759+6JWrVr49NNPce3atTIPkIiIiIiIiCoHtRuQVapUwc2bNyGTybB//360b98eAJCRkQFtbd4egIiIiIiI3iJyecm3t5DacyCHDBmCvn37wt7eHhKJBP7+/gCAc+fOwcPD4zWliYiIiIiI6E2ldgMyKCgIXl5eePLkCfr06QOpVAoA0NbWxqRJk8o8QCIiIiIiIo3hbTxE1G5AAsCHH35YKG3w4MGlDoaIiIiIiIgqrxI1INPT03H8+HE8fvwYOa/cJBUAvvjiizIJjIiIiIiISOPe0rmMJaV2A/LKlSvo0qULMjIykJ6eDktLS8TFxcHQ0BC2trZsQBIREREREb2l1F6F9auvvkL37t2RmJgIAwMDnD17Fo8ePULDhg3xyy+/lEeMREREREREmsFVWEXUbkCGhYXh66+/hpaWFrS1tZGdnY2qVatizpw5mDx5cnnESERERERERJWA2g1IXV1daGnlF7O1tcXjx48BAGZmZnjy5EnZRkdERERERKRJcqHk21tI7TmQ9evXx4ULF1CzZk20atUKU6dORVxcHDZs2AAvL6/yiJGIiIiIiIgqAbV7IGfNmgV7e3sAwI8//ggLCwuMGjUKsbGxWL58eZkHSEREREREpDGcAymidg9ko0aNFH/b2tpi//79ZRoQERERERERVU5q90D+V05ODtLS0soiFiIiIiIiIqrE1GpArlmzBmPHjsXGjRsBAIGBgTAxMYGZmRnat2+P+Pj4cgmSiIiIiIhIEwSZUOLtbaRyA/LHH3/E6NGjcevWLXzxxRcYNWoU1q5dixkzZmD27Nm4desWvv/++/KMlYiIiIiIiDRI5TmQa9euxapVq9C/f39cvHgRTZs2xbZt29C7d28AgJeXFz777LNyC5SIiIiIiKjCvaW34ygplXsgHz9+jBYtWgDIX0hHR0dHdNsOHx8fREVFlX2EREREREREVCmo3IDMzc2FVCpV7Ovp6UFXV1exr6OjA5lMVrbRERERERERUaWh1m08bt68iejoaACAIAi4deuWYgXWuLi4so+OiIiIiIhIk97SxXBKSq0GZLt27SAIBQ9gt27dAAASiQSCIEAikZRtdERERERERFRpqNyAjIyMLM84iIiIiIiIKh2Bi+iIqNyAdHFxKc84iIiIiIiIqJJTeREdIiIiIiIierepNQeSiIiIiIjoncJFdETYgCQiIiIiIlJGJtd0BJUKh7ASERERERGRStRuQLZt2xZJSUmF0lNSUtC2bduyiImIiIiIiKhSEORCibfykpCQgIEDB8LU1BTm5uYYOnQo0tLSVLseQUDnzp0hkUiwe/dutc+tdgPy2LFjyMnJKZSelZWFkydPqh0AERERERERqW7gwIG4ceMGQkJCsHfvXpw4cQIjRoxQqezcuXMhkUhKfG6V50BevXpV8ffNmzcRHR2t2JfJZNi/fz8cHR1LHAgREREREREVLyIiAvv378eFCxfQqFEjAMCCBQvQpUsX/PLLL3BwcFBaNiwsDL/++isuXrwIe3v7Ep1f5QZkvXr1IJFIIJFIihyqamBggAULFpQoCCIiIiIiokqpFKuwZmdnIzs7W5QmlUohlUpLXGdoaCjMzc0VjUcA8Pf3h5aWFs6dO4cPPvigyHIZGRkYMGAAFi1aBDs7uxKfX+UGZGRkJARBgJubG86fPw8bGxvFMT09Pdja2kJbW7vEgZSlFK3CQ2zp7WXa7n1Nh0AVyL5TX02HQBXpSbimI6AKpNVnsKZDoArUrEUTTYdAVO6Cg4Mxffp0Udq0adMQFBRU4jqjo6Nha2srStPR0YGlpaVolOh/ffXVV/Dz80OPHj1KfG5AjQaki4sLAEAu5zK2RERERET0jijFYjiBgYEYP368KE1Z7+OkSZPw008/FVtfREREieLYs2cPjhw5gitXrpSo/KtKdB/Iu3fv4ujRo4iJiSnUoJw6dWqpgyIiIiIiInrTqTNc9euvv0ZAQECxedzc3GBnZ4eYmBhRel5eHhISEpQOTT1y5Aju378Pc3NzUXrv3r3RsmVLHDt2TKUYgRI0IFesWIFRo0bB2toadnZ2ohV8JBIJG5BERERERPTWEEoxB1IdNjY2ommCyvj6+iIpKQmXLl1Cw4YNAeQ3EOVyOZo2bVpkmUmTJmHYsGGiNG9vb/z+++/o3r27WnGq3YD84Ycf8OOPP2LixInqFiUiIiIiIqJS8PT0RKdOnTB8+HAsXboUubm5GDNmDPr166dYgfXZs2do164d1q9fjyZNmsDOzq7I3klnZ2dUq1ZNrfOrfR/IxMRE9OnTR91iREREREREVAY2btwIDw8PtGvXDl26dEGLFi2wfPlyxfHc3Fzcvn0bGRkZZX5utXsg+/Tpg4MHD+Kzzz4r82CIiIiIiIgqlUq4iKilpSU2bdqk9LirqysEofiht687rozaDcgaNWpgypQpOHv2LLy9vaGrqys6/sUXX5QoECIiIiIiIqrc1G5ALl++HMbGxjh+/DiOHz8uOiaRSNiAJCIiIiKit0cFLaLzplC7ARkZGVkecRAREREREVU6QinuA/k2UnsRHSIiIiIiIno3qd0DCQBPnz7Fnj178PjxY+Tk5IiO/fbbb2USGBEREREREVUuajcgDx8+jPfffx9ubm64desWvLy88PDhQwiCgAYNGpRHjERERERERJrBOZAiag9hDQwMxIQJE3Dt2jXo6+tj586dePLkCVq1asX7QxIREREREb3F1G5ARkREYNCgQQAAHR0dZGZmwtjYGDNmzMBPP/1U5gESERERERFpjEwo+fYWUrsBaWRkpJj3aG9vj/v37yuOxcXFlV1kREREREREVKmoPQeyWbNmOHXqFDw9PdGlSxd8/fXXuHbtGv788080a9asPGIkIiIiIiKiSkDtBuRvv/2GtLQ0AMD06dORlpaGrVu3ombNmlyBlYiIiIiI3iq8D6SY2g1INzc3xd9GRkZYunRpmQZERERERERElZPacyDd3NwQHx9fKD0pKUnUuCQiIiIiInrjyeQl395CajcgHz58CJlMVig9Ozsbz549K5OgiIiIiIiIqPJReQjrnj17FH8fOHAAZmZmin2ZTIbDhw/D1dW1TIMjIiIiIiLSJM6BFFO5AdmzZ08AgEQiweDBg0XHdHV14erqil9//bVMgyMiIiIiIqLKQ+UGpFyeP4a3WrVquHDhAqytrcstKCIiIiIiIqp81F6FNTIysjziICIiIiIiqnxkHML6KrUbkDNmzCj2+NSpU0scDBERERERUaXCOZAiajcgd+3aJdrPzc1FZGQkdHR0UL16dTYgiYiIiIiI3lJqNyCvXLlSKC0lJQUBAQH44IMPyiQoIiIiIiKiykDgEFYRte8DWRRTU1NMnz4dU6ZMKYvqiIiIiIiIqBIqkwYkACQnJyM5ObmsqiMiIiIiIqJKRu0hrPPnzxftC4KAqKgobNiwAZ07dy6zwIiIiIiIiDSOi+iIqN2A/P3330X7WlpasLGxweDBgxEYGFhmgREREREREVHlwvtAEhERERERKSOTazqCSkXtBiSVj22bQ/HH2pOIj0tDTXc7fBPYHXW8qyrNf+jANSxdGIKo50mo6myFsV91QvP33EV5Ih/EYMHv+3H5YiRkMjmqudlizu8DYWdvDgD4c/t5HNgXjtsRz5Geno0jp6fAxNSgPC+TXiEIAuYv+gfbd5xFSmomGtSvhqApfeDqYlNsuY2bT2LVmiOIjUuFh7sDpkzuDR9vF8XxqdO34kzoHcTEpsDQUA/161XDhK+6o7pbFUUed69xher9bc4gdO3SoMyuj8rOxo3HsGrVQcTFpsDDwwnfT/kIPj7VNB0WqUEQBCxYdwHb90UgJS0bDerYYdqX78HVyVxpmQtXn2PVtjDcuBuL2PgMLJzeCf7NCz/v9x8l4peVobgQHgWZXI7qzhaYP60jHKqYlOMVUVnh+/vNJwgCFqw5i+17r+e/v70cMG18G7g6WSgtcyH8GVZtuYQbd2IQG5+OhTO7wb9ldaX5p/16GFv/uo7A0e9hcJ/65XEZRCpTuQH56aefqpRv9erVJQ7mXXVw/1XM/XkfJk3pCS8fJ2zecAZjR67Bjr/Gw9LKuFD+8LBH+H7iVoz+sgNatPLA/r/DMeHLP7Bh22jUqGkHAHj6JB7DBy3D+70aYeTn/jAyluL+vRjo6RU85VlZufBtXgu+zWth0bwDFXa9lG/F6sPYsPEEZv84EE6OVpi3cB+GjlyKff+bBKlUt8gy+/65jOA5uzF9al/U9XHBug3HMXTkUuz/azKsrPK/LNapXRXduzaCvb05kpMzsGDxfgwdsQSHD0yFtnbBulnBP/RHyxaein1TE/54UBnt23cRs4N3IGj6ANSt64p1645g2NAF+Gd/EKysTDUdHqlo5dYwbNh1DbO/bQsne1PMW3Mewybtxd+r+0GqV/S/4sysXHi4WaF3Jw+MDSr6M/rx82QMGLcLH3b2xNhBjWFspId7DxMg1dMuz8uhMsL399th5eZL2LAzDLMDO+S/v1efxbBvduPvtZ9AKi3m/V3dGr271MbYKX8XW3/IyXsIvxkNW2uj8gifSG0qNyDXrl0LFxcX1K9fH4JQ+omkmZmZOHz4MLp16wYACAwMRHZ2tuK4trY2Zs6cCX19/VKfq7LbtP4UevZujPc/aAgACJzaA6dP3saeXZcQMKxVofxb/jgD3+Y18cmQ9wAAo8a2x/mz97B981kETu0JAFg8/yD8Wrrji/EFCxs5VbUS1TPgk+YAgEsXHpTHZVExBEHA+g0nMGpEB/i39QYAzJk1EH6tpuDQ4WtKewLXrD+Gvh/6ovcHTQEA06f2wbETN7Fz1zmMGOYPAPioj58iv5OjFcaN7Yoevefg2bMEODtbK46ZmhjAxppfUCq7tWsOoU/f5ujdO/95nT59AI4fu4adO89gxIhOGo6OVCEIAtb/eRWfDWyIdv/2IP40sS2a91mHQ6cj0bVNzSLLvdfEBe81cSny2EtzV59Hq6Yu+GaEryLN2cGs7IKncsX395tPEASs33EFn33SBO1a5Pcg/hTYAc0/WIFDp+6jazv3Isu919QV7zV1fW39L2LT8MO841j5c0+MnPS/sgyd1CBwER0RlW/jMWrUKCQnJyMyMhJt2rTBqlWrsGvXrkKbqtatW4dly5Yp9hcuXIgzZ87gypUruHLlCv744w8sWbJEvat5A+Xm5uHWzedo0qyGIk1LSwtNmlXHtfDHRZa5Fv4YjV/JDwDN/Goq8svlcpw+cRvOLtYYO3INOrT6EQEDFuPY4ZvldyGklqdP4xEblwI/31qKNBMTA9T1ccGV8IdFlsnJzcONm0/h16ygjJaWFvya1VJaJiMjG3/uPgcnJyvF0OWXpv+4E01bfIcP+/2GHX+eLZMfhqhs5eTk4caNx/DzK+gp1tLSgq+fJ8Ku8IefN8XTqFTEJmTAr4GTIs3EWAofT1uE3XxR4nrlcgHHzj2Cq5MZhk7cC78P16DvmJ04dJprFbwJ+P5+OzyNSsl/fzd0VqSZGEvhU9sOYTejS1W3XC7g21kHMLRfA9SsZvX6AkQVROUG5KJFixAVFYVvv/0Wf/31F6pWrYq+ffviwIEDJfriuXHjRowYMUKUtmnTJhw9ehRHjx7Fzz//jG3btr22nuzsbKSkpIi27OxctePRlKTEDMhk8kJDVS2tjBEfn1pkmfi4NFgVlT8uP39CQjoyMnKwbvVx+DaviQXLhqB12zr49quN7G2sJGL/fa5eDjt9ycrKBHFxKUWWSUxMh0wmV6nMxi2nUL/xt6jfZCJOnIrAmuWjoKdbMODgizGdMfeXwVizYhQ6tPfB9B92YMPGE2VxaVSGEhPT/n3OxT3F1sW8TqjyiU3MAABYWYiHiVubGyIuIaPE9cYnZSIjMxcrtlxBy8ZVsWp2d/g3r4axQftxPvx5qWKm8sf399shNiEdAGBlaShKt7YwRNy/x0pqxeaL0NbWwie965WqHioDMqHk21tI5QYkAEilUvTv3x8hISG4efMm6tSpg88//xyurq5IS0tT68T37t2Dt7e3Yl9fXx9aWgXhNGnSBDdvvr7HLDg4GGZmZqLttzl/qhXL2+ZlN3ur1p4YMKgF3D0cEDCsFVq0csef289rOLp30569F/MbdP9ueXmycj3f+10bYteOb/DH2rFwdbHBuAlrRT+sjP6sIxo2cENtTyeMGOqPYZ+2xao1R8s1JqJ3xV+H76BBtxWKLS+vfFbvk//7Wd/W1xUBH9aFZw1rjOjfAK2buWDL3hvlck6id91fIbfQoNNixVZe7+/rt19gw44wBE9qD4lEUi7nICqpEq/CqqWlBYlEAkEQIJOp/2U4KSlJNOcxNjZWdFwul4uOKxMYGIjx48eL0rIl+9SOR1PMLQyhra2FhHhxAzwhPq1QT9NLVtbGiC8qv7VJQZ06WqhW3VaUp1o1W4RdeVh2wZPK2rbxQl2fgrlMOTl5AID4+FTY2hTMV4qPT4WHu2ORdVhYGEFbW6tQz3R8fCqs/zOX0cTEACYmBnB1sUHdui5o4jcZIYevoluXhkXWXdfbBYuXHkROTp5ooSXSLAsL43+fc3FvRFwRzzlVHm18XeHjUbDqcU5u/v/I+MRM2FoVLIIRl5QBz+rWhcqrysJMHzraWqjhYilKr+5sgUvXSzd0jsof399vpjbN3eDjaafYV7y/EzLE7+/EDHjWKH5V9eJcuvoc8UkZaNu3YHFKmVzAT0tOYt2OKziyVbXFLalscA6kmFo9kNnZ2di8eTPat2+PWrVq4dq1a1i4cCEeP34MY+PCq4UWx8nJCdevX1d6/OrVq3ByclJ6/CWpVApTU1PRpmwFy8pIV1cHHrUdcOHcPUWaXC7HhbP34V3Xucgy3nWdceHcfVHaudB7ivy6ujqoXccJjx7GifI8fhQH+//Mg6OKYWykDxdnG8VWo7odbKxNEXr2riJPWloWwq8+Qv26rkXWoaergzq1nRB6rqCMXC5H6Lk7SssAAIT8Sf4vG61Fibj1DGamhmw8VjJ6ejqoU8cZoaG3FGlyuRxnQ2+hXn03DUZGxTE21IOLo5liq+FiARtLQ4ReearIk5aeg6sRMahXu0oxNRVPT1cbXu42iHyaJEp/+DQZDrbq/U+misf395vJ2FAPLk7miq2Gq2X++/vyE0WetPRsXL0ZjXq17YqpqXjvd/DA/1YNxK6VAxSbrbURhn7UACt//qAsLoWoxFT+tvj5559jy5YtqFq1Kj799FNs3rwZ1tYl/+W0S5cumDp1Krp27VpopdXMzExMnz4dXbt2LXH9b5IBg1pg+nc74FnHCXW8nbB5w2lkZuage8/8lTinTd4OG1tTjBnXEQDQ72M/jByyAn+sO4kWLd1xcP9VRNx4hsnTeirq/GRIS0yesAX1G1ZDoyZuCD11ByeP38LS1cMUeeLiUhEfl4onj+MBAPfuRsPQSAo7e3OYmYnH8lPZkkgkGPTJe1iy/CBcXGzg5GiJeQv3wdbWDP7tCoZ2Dx66CO3b+eDjAS0BAEMGtcbE7zbBq05V+Hg5Y90fx5GZmYNePfNXZX3yJA779l9Bcz8PWFoaIzo6CctXHYK+VBetWtYGABw5dh3xcamoW9cVUqkOTp+5jWUrD+HTwW0q/oGg1woY4o9JE9fCy8sFPj75y/xnZuagVy+/1xemSkEikWBQLx8s3XgJro5mcLQzxfy152FrZSi6r2PAN3vg37waPu6Z/xmQnpmLx8+SFcefRqUg4l4czEykins8Du1bD+N/CEEjb3s0reeIkxce42joQ6z/tUfFXiSVCN/fbz6JRIJBH9bH0g3n4epkDkd7U8xfFQpbayP4tyi4r2PA+J3wb1EDH/eqCwBIz8gRv7+jkxFxNxZmplI4VDGFhZkBLMzE86Z1tLVgbWkEN2fl95ek8iG8pXMZS0rlBuTSpUvh7OwMNzc3HD9+HMePHy8y359/qjb/cPLkydi2bRvc3d0xZswY1KqVv7Lk7du3sXDhQuTl5WHy5MmqhvdG69DJB0kJ6Vi26BDi41JRy8Me85cOUQxJjY5KEo1/r1vPBT/M/ghLFoZg8byDqOpihV/mfay4ByQAtGlXB4FTe2DtyuP4dfZfcHa1wU+/DUC9Bq6KPH9uO4cVS44o9kcErAAATJ3ZG917Fj3UkcrO8E/bITMzB1ODtiIlNRMNG7hh5dKRoh70J0/ikJhYMFy5S+cGSEhMx/yF/yA2LgWeHo5YuXQkrP99rehJdXHx8gOs23AcKSmZsLIyQaNG1bH5jy8VQ6J1dLSxccspzJqzGxAEODtbY9I3PdD3Q19Q5dOlSyMkJKRiwfy/EBubAk9PJ6xYOZZD3N4wwz6qh8ysXEz9/ThS0nLQ0MsOK2Z3E90D8vHzFCQmZyn2r9+OweAJexT7s5eeAQD07OCO2d+2BQC0b+GGoC/fw/ItV/DjolOoVtUc86d1RENv+wq6MioNvr/fDsP6N8x/f/9yGClp2Wjo7YAVc3qK7gH5+FkyEpMzFfvXb8dg8Fc7FfuzF50EAPTs6InZgR0qLniiEpAIKi6hGhAQoNIk3jVr1qh88sjISIwaNQohISGKlVwlEgnat2+PxYsXw82tZEM4UnJ2vj4TvTVMJewtfZcIum//vWHpFU/CNR0BVaSqdTUdAVWkqAhNR0AVSGL/uaZDKLGUkSUfpWW67O1bpFDlHsi1a9eW+cmrVauG/fv3IyEhAffu5c8BrFGjBiwtLV9TkoiIiIiIiCpapVgxw9LSEk2aNNF0GERERERERCJyzoEUUWsVViIiIiIiInp3sQFJREREREREKqkUQ1iJiIiIiIgqI0HOIayvYg8kERERERERqYQ9kEREREREREoIcrmmQ6hU2ANJREREREREKmEDkoiIiIiIiFTCIaxERERERERKCLwPpAh7IImIiIiIiEgl7IEkIiIiIiJSgrfxEGMDkoiIiIiISAkOYRXjEFYiIiIiIiJSCRuQREREREREpBIOYSUiIiIiIlKCcyDF2ANJREREREREKmEPJBERERERkRJy9kCKsAeSiIiIiIiIVMIGJBERERERkRKCTCjxVl4SEhIwcOBAmJqawtzcHEOHDkVaWtpry4WGhqJt27YwMjKCqakp3nvvPWRmZqp1bjYgiYiIiIiI3iADBw7EjRs3EBISgr179+LEiRMYMWJEsWVCQ0PRqVMndOjQAefPn8eFCxcwZswYaGmp1ySUCILw1g3qTcnZqekQqAKZSgw1HQJVIEFXX9MhUEV6Eq7pCKgiVa2r6QioIkVFaDoCqkAS+881HUKJRX3QtMRl7XedK8NI8kVERKB27dq4cOECGjVqBADYv38/unTpgqdPn8LBwaHIcs2aNUP79u0xc+bMUp2fPZBERERERERKCHKhxFt2djZSUlJEW3Z2dqniCQ0Nhbm5uaLxCAD+/v7Q0tLCuXNFN1hjYmJw7tw52Nraws/PD1WqVEGrVq1w6tQptc/PBiQREREREVE5CA4OhpmZmWgLDg4uVZ3R0dGwtbUVpeno6MDS0hLR0dFFlnnw4AEAICgoCMOHD8f+/fvRoEEDtGvXDnfv3lXr/GxAEhERERERKVGaHsjAwEAkJyeLtsDAwCLPM2nSJEgkkmK3W7dulega5HI5AGDkyJEYMmQI6tevj99//x3u7u5YvXq1WnXxPpBERERERETlQCqVQiqVqpT366+/RkBAQLF53NzcYGdnh5iYGFF6Xl4eEhISYGdnV2Q5e3t7AEDt2rVF6Z6ennj8+LFK8b3EBiQREREREZGG2djYwMbG5rX5fH19kZSUhEuXLqFhw4YAgCNHjkAul6Np06IX/HF1dYWDgwNu374tSr9z5w46d+6sVpwcwkpERERERKREZbsPpKenJzp16oThw4fj/PnzOH36NMaMGYN+/fopVmB99uwZPDw8cP78eQCARCLBN998g/nz52PHjh24d+8epkyZglu3bmHo0KFqnZ89kERERERERG+QjRs3YsyYMWjXrh20tLTQu3dvzJ8/X3E8NzcXt2/fRkZGhiJt3LhxyMrKwldffYWEhATUrVsXISEhqF69ulrn5n0g6Y3H+0C+W3gfyHcM7wP5buF9IN8tvA/kO+VNvg/kk04NSly26v7LZRhJ5cAeSCIiIiIiIiXKayjqm4pzIImIiIiIiEglbEASERERERGRSt7KIaymeWwXv0sEQ86Je6fcPqPpCKgiGRhoOgKqQGmjZmo6BKpAxkumaDoEIpUIcg5hfRVbWkRERERERKSSt7IHkoiIiIiIqCzI2QMpwh5IIiIiIiIiUgkbkERERERERKQSDmElIiIiIiJSgveBFGMPJBEREREREamEPZBERERERERK8DYeYuyBJCIiIiIiIpWwB5KIiIiIiEgJzoEUYw8kERERERERqYQNSCIiIiIiIlIJh7ASEREREREpwUV0xNiAJCIiIiIiUoINSDEOYSUiIiIiIiKVsAeSiIiIiIhICa7CKsYeSCIiIiIiIlIJG5BERERERESkEg5hJSIiIiIiUkLORXRE2ANJREREREREKmEPJBERERERkRJyuaYjqFzYA0lEREREREQqYQOSiIiIiIiIVMIhrEREREREREpwCKsYeyCJiIiIiIhIJeyBJCIiIiIiUoI9kGLsgSQiIiIiIiKVsAeSiIiIiIhICbmg6QgqF/ZAEhERERERkUrYA0lERERERKQE50CKsQeSiIiIiIiIVMIeSCIiIiIiIiXYAynGHkgiIiIiIiJSCXsgKxFBEDB/SQi277qAlNRMNKjriqDJPeHqYl1suY1bQ7Fq3XHExqfBo5Y9pkx8Hz5eVRXHPxm2DOcvRYrKfNS7KWZ8/4FiP/TcPcxbfBC370XD0EAPPbs3xFejO0BHR7tsL5LKxMaNx7Bq1UHExabAw8MJ30/5CD4+1TQdFpWSIAhYsCkc2w/eRUp6Dhp42mDaqGZwdTBVWmbZ9msICX2MB8+Soa+ng/oeNvh6cAO4OZlVYOT0OoIgYMG6i9j+zy2kpGWjQR07TPuiJVyLeZ4uXH2OVdvDceNOHGITMrAwqAP8mxd+n99/lIhfVp7DhatRkMnlqO5sgfnT2sPB1qQ8L4leQ69bAHRbdIXEwBiyB9eRtWkuhNhnyvN3HQxpt8GiNFn0Y2RMD8jfMTSBtFsAdGo3gsTCFkJaEvLCTyN7zxogK70cr4TKEv9/v5nYAynGHshKZMXa49iw+QyCJvfEtvWjYWCgi6GjVyM7O1dpmX0HwhH8616MHumPXZvGwqOWPYZ+vgrxCWmifH17NcGpkO8U27fjOiuO3br9HMPHrkELv1rYvfkL/D57AI4cv4lf5+8vt2ulktu37yJmB+/A6NHd8OeuyXD3cMKwoQsQH5+i6dColFb+eQMb9kYgaFRTbPu5CwykOhg27RCyc2RKy1y4/gIDurpj689dsHqGP/JkcgybdggZWco/N6jirdwajg27ryPoy5bYtuADGOjrYFjg38jOyVNaJjMrDx5uVpg6toXSPI+fJ2PAV/+Dm7M51v/aHf9b9iE+H9gAUl3+PqxJeh36Qa9NL2Rv+h0Zc0ZDyM6C4Rc/ATq6xZaTPY9E2sTeii3zly8Ux7TMrSAxt0LWzqVInzkUWevnQKd2Y+h/MqG8L4fKCP9/09tCYw3IGTNmICMjQ1Onr3QEQcD6Tacxanhb+LepA49a9pgz8yPExKbg0NGbSsut+eMU+vZqgt49GqFG9SqY/l1P6OvrYefui6J8+vq6sLE2UWzGxvqKY/sOXoV7TXuMGekPF2drNGnkhm++7IyN20KRlp5dbtdMJbN2zSH06dscvXv7oUYNB0yfPgD6+rrYufOMpkOjUhAEAev3ROCzvj5o18wZ7tUs8NNXLRCTkIFDZx8rLbdyuj96tauBms7m8KhmieAvm+N5bDpu3EuowOipOIIgYP2ua/hsYAO083OFu5sVfprYBjHxGTh0+qHScu81cca4IU3QvoXy3om5ay6gVRNnfDO8GWrXsIazgxna+rnCysKgHK6EVKXbtjey//kDeVfPQP7sAbLWzobEzBo69ZT/GAAAkMkgpCQWbOkFDQv584fIWh4E2bVQCHHPIbt9Bdl7VkPH2xfQYn/Am4D/v+ltobFPnOnTpyMtLe31Gd8RT58lIDYuFX5NayjSTEz0UderKq5cfVRkmZzcPNyIeCYqo6WlBb+mNQqV+WtfGJq2mYFuH/6OX+fvR2ZmTkE9OXmQSsW/VutLdZGdnYcbEU/L4vKojOTk5OHGjcfw8/NUpGlpacHXzxNhVx5oMDIqracv0hCbmAm/uvaKNBMjPfjUskHY7ViV60lNz39vm5nolXmMVDJPo1MRm5ABv/qOijQTIyl8PGwRdvNFieuVywUcO/cYrk5mGDrpb/j1WYe+Y3fh0OnI1xemciOxtoeWmRVkty4VJGalQxYZAe1qtYstq2XrCKPgbTCa+Qf0h0yGxMK2+HMZGEHIyuD4ujcA/3+/2eTykm9vI401IAVBKJN6srOzkZKSItqKG/JZWcXG5TemrSyNRelWVsaIiy+6oZ2YmAGZTP7aMt0618PPP36E9ctHYMSnrfG/vy/jm++3Ko638KuFK+GPsPefMMhkcryIScai5Yfz44pNLZPro7KRmJiW/5xbiefEWVuZIC6OQ2DeZLGJmQAAK3N9Ubq1uT7i/j32OnK5gFkrL6CBpw1quViUeYxUMrEJ+aNt/tsraG1hgLjEko/EiU/KREZmLlZsDUPLxlWxKrgr/Ju7Yuz0gzgf/rxUMVPJSUwtAQBCSqIoXUhNVBwriuxhBLLWz0HmwknI2jQXWlb2MPx6HiAtujdZYmQKvc6fIPfU3rILnsoN/3/T20SjkyQkEkmp6wgODsb06dNFadMm90XQd/1KXXd52rPvCqb9sEuxv2x+QLmd66PeTRV/u9e0g421CQJGrsTjJ/FwrmqFFr618O24Lpg2axe+nbINerra+Hx4O1y88hBaWqV/joiosL+OPcC0xWcV+0unti11nTOWnsPdx0nYNLtTqeuikvvr8F1Mm3tCsb/0h87F5C45uTz/h9i2vq4I6O0DAPCsYY0rN15gy96baFLXoVzOS2I6jdtBf8B4xX7m4sAS1SO7cb5g59kDZDyMgPGPm6HbsDVyz/wjzqxvCIPRwZBHP0TO3nUlOh8Rqe5t7UksKY02IGvVqvXaRmRCQvHzeAIDAzF+/HhRmlRW+Rd/aduqNuq+slJqTm7+IhnxCWmwtSn4dSo+Pg0e7vaFygOAhYUhtLW1Ci2YEx+fBmsr4yLLAEBdb2cAwKN/G5AAMOSTlgj4uAViYlNhZmqAZ88T8euC/XByUv5rKVU8Cwvj/Of8PxPu4+JTYW2tfKVOqnzaNKkKn1oFKyzn5OX/d4pPyoKtpaEiPS4pC55ur+9NnLH0HI5dfIo/ZnWEnbVR2QdMKmvj6wIfjw8V+4rP98RM2FoVPDdxiZnwrG5V4vNYmOlDR1sLNf7T21zd2RyXrkeXuF5ST97VM0h/GKHYl+jkDx+XmFpASCn4DiMxsYD86T3VK85Mh/zFU0hsHMXpUgMYjvkJQnYGMpdOBeTKF9miyoP/v+ltotEG5PTp02FmVrql5qVSKaRSqTgxo/hVzioDYyMpjI0K4hYEATbWJgg9dw+e7vm/GqelZSH8+hP079OsyDr0dHVQx9MRoefuwb9NHQCAXC5H6Pl7+PgjP6XnjridP7TJxlq8xLtEIkEV2/wPsb37w2BvZ4Y6Ho6FypPm6OnpoE4dZ4SG3oK/fz0A+c/52dBbGPhxa43GRuoxNtSFsWHBZ5UgCLCxMEBoeBQ83fJ/uEnLyMHVO7Ho37mW0noEQcDMZedx6OxjrJ/VEU52vHWDphkb6sHYsGAOqiAIsLE0ROiVZ/Cskf+jQVp6Dq7eikH/7sXPiSuOnq42vNxtEPkkSZT+8FkyHKrwdVBhsjMhxBYMMxcAyJPjoe3eAPKn9/MT9Q2hXc0TuSf3qF6vVB9aNg4QzocUpOkbwnDsTxDycpG5+Hsg782bsvOu4v9veptotAHZr18/2NoWP0H8XSGRSDBoQHMsWXkELs7WcHK0xLzFB2FrYwr/NgVfMAaPXIH2berg4375DcQhH7fAxKnb4VXbCT5eVbFu0ylkZuagV4+GAIDHT+Lx1z9haNXCHebmhrh9JxrBv+5F4wbV4FGroGdz5brjaOnnDi0tCQ4evo4Va45j7pwB0Nbmym6VTcAQf0yauBZeXi7w8XHFunVH8p/zXsp/NKDKTyKRYND7nli67RpcHUzhWMUY8zeGwdbSEP7NnBX5Ar4/CP9mzvi4mweA/J7HvScisei7NjAy0FXMpTQx1IW+lLdyqAwkEgkGfeCNpZsuw9XRDI72Jpi/9iJsrQzh39xVkS/gm7/g37waPu7pBQBIz8zF42fJiuNPo1MRcS8OZqZSxT0eh/api/E/HkIjH3s0reuAkxee4GjoI6z/tXuFXiOJ5R7ZCWmXjyGPfQYhLgp63YdASI5DXtgpRR6DL39BXtgp5B7fDQCQ9voMedfOQB7/AhJza0i7DYYglyPvwpH8AvqGMPxiDqArRdaaYEgMDAGD/NEKQmoyIHCMXWXH/99vLg5hFdPYt4uymP/4thke0AqZmTmY+sOfSEnNQsN6rli5aAik0oJeiidP4pGYVHDD4C4d6yIhMR3zl4QgNj4Vnu4OWLnoU1hb5X+50NXVRui5e1i/6TQyMnNgX8UMHdp54fNh4vlWJ07fxtKVR5GTmwePWvZY9PsgtGrhXjEXTmrp0qUREhJSsWD+X4iNTYGnpxNWrBzLITBvgWG96iAzKw9TF4UiJT0HDWvbYkWQP6R62oo8j6NTkZiSpdjf/M8dAMCgyQdFdc360g+92tUAVQ7DPqqLzKxcTJ17AilpOWjoZYcVwV0g1Sv4N/w4KkX03F6/E4vBE/5S7M9eGgoA6Nm+FmZ/2wYA0L5FNQR92RLLN1/Bj4tOo5qTOeZP64CGXkVPfaCKkXNwC6CnD/0B4yExNIbs/jVkLJgk6jHUsnGAxLhgFJbEwhr6n34PiZEphLTk/DJzxkBIy/8RQbtqTcUqrsYz/xCdL+27/hASSr6iL1UM/v+mt4VEKKvlUNWkpaWF6Ojo8umBzNj1+jz01hAMzTUdAlWk27xf1jvFgPczfJekBXNF0XeJ8ZIpmg6BKpAEbTQdQokdd/QocdlWz26VYSSVg8Z6IOXsCyYiIiIiokqOzRYxTnAjIiIiIiIilbABSURERERERCrhEn1ERERERERKaGjJmEqLPZBERERERESkEvZAEhERERERKcFFdMTYA0lEREREREQqYQ8kERERERGREuyBFGMPJBEREREREamEDUgiIiIiIqI3SEJCAgYOHAhTU1OYm5tj6NChSEtLK7ZMdHQ0PvnkE9jZ2cHIyAgNGjTAzp071T43G5BERERERERKyOUl38rLwIEDcePGDYSEhGDv3r04ceIERowYUWyZQYMG4fbt29izZw+uXbuGXr16oW/fvrhy5Ypa52YDkoiIiIiI6A0RERGB/fv3Y+XKlWjatClatGiBBQsWYMuWLXj+/LnScmfOnMHYsWPRpEkTuLm54fvvv4e5uTkuXbqk1vnZgCQiIiIiIlKiND2Q2dnZSElJEW3Z2dmliic0NBTm5uZo1KiRIs3f3x9aWlo4d+6c0nJ+fn7YunUrEhISIJfLsWXLFmRlZaF169ZqnZ8NSCIiIiIionIQHBwMMzMz0RYcHFyqOqOjo2FraytK09HRgaWlJaKjo5WW27ZtG3Jzc2FlZQWpVIqRI0di165dqFGjhlrnZwOSiIiIiIioHAQGBiI5OVm0BQYGFpl30qRJkEgkxW63bt0qcSxTpkxBUlISDh06hIsXL2L8+PHo27cvrl27plY9vA8kERERERGREqVZDEcqlUIqlaqU9+uvv0ZAQECxedzc3GBnZ4eYmBhRel5eHhISEmBnZ1dkufv372PhwoW4fv066tSpAwCoW7cuTp48iUWLFmHp0qUqxQiwAUlERERERKRUea6m+iobGxvY2Ni8Np+vry+SkpJw6dIlNGzYEABw5MgRyOVyNG3atMgyGRkZAAAtLfEAVG1tbcjVvEAOYSUiIiIiInpDeHp6olOnThg+fDjOnz+P06dPY8yYMejXrx8cHBwAAM+ePYOHhwfOnz8PAPDw8ECNGjUwcuRInD9/Hvfv38evv/6KkJAQ9OzZU63zswFJRERERESkRGW8D+TGjRvh4eGBdu3aoUuXLmjRogWWL1+uOJ6bm4vbt28reh51dXWxb98+2NjYoHv37vDx8cH69euxbt06dOnSRa1zcwgrERERERHRG8TS0hKbNm1SetzV1RWCIIjSatasiZ07d5b63OyBJCIiIiIiIpWwB5KIiIiIiEgJufD6PO8S9kASERERERGRStgDSUREREREpERF3cbjTcEeSCIiIiIiIlIJG5BERERERESkEg5hJSIiIiIiUoJDWMXYA0lEREREREQqYQ8kERERERGREuyBFGMPJBEREREREamEPZBERERERERKsAdSjD2QREREREREpBI2IImIiIiIiEglEkEQBE0HQaWXnZ2N4OBgBAYGQiqVajocKmd8vt8tfL7fLXy+3y18vt8tfL7pbcAG5FsiJSUFZmZmSE5OhqmpqabDoXLG5/vdwuf73cLn+93C5/vdwueb3gYcwkpEREREREQqYQOSiIiIiIiIVMIGJBEREREREamEDci3hFQqxbRp0zgh+x3B5/vdwuf73cLn+93C5/vdwueb3gZcRIeIiIiIiIhUwh5IIiIiIiIiUgkbkERERERERKQSNiCJiIiIiIhIJWxAEhERERERkUrYgHxLLFq0CK6urtDX10fTpk1x/vx5TYdE5eDEiRPo3r07HBwcIJFIsHv3bk2HROUoODgYjRs3homJCWxtbdGzZ0/cvn1b02FROVmyZAl8fHxgamoKU1NT+Pr64p9//tF0WFRBZs+eDYlEgnHjxmk6FCoHQUFBkEgkos3Dw0PTYRGVCBuQb4GtW7di/PjxmDZtGi5fvoy6deuiY8eOiImJ0XRoVMbS09NRt25dLFq0SNOhUAU4fvw4Ro8ejbNnzyIkJAS5ubno0KED0tPTNR0alQMnJyfMnj0bly5dwsWLF9G2bVv06NEDN27c0HRoVM4uXLiAZcuWwcfHR9OhUDmqU6cOoqKiFNupU6c0HRJRifA2Hm+Bpk2bonHjxli4cCEAQC6Xo2rVqhg7diwmTZqk4eiovEgkEuzatQs9e/bUdChUQWJjY2Fra4vjx4/jvffe03Q4VAEsLS3x888/Y+jQoZoOhcpJWloaGjRogMWLF+OHH35AvXr1MHfuXE2HRWUsKCgIu3fvRlhYmKZDISo19kC+4XJycnDp0iX4+/sr0rS0tODv74/Q0FANRkZEZS05ORlAfqOC3m4ymQxbtmxBeno6fH19NR0OlaPRo0eja9euov/j9Ha6e/cuHBwc4ObmhoEDB+Lx48eaDomoRHQ0HQCVTlxcHGQyGapUqSJKr1KlCm7duqWhqIiorMnlcowbNw7NmzeHl5eXpsOhcnLt2jX4+voiKysLxsbG2LVrF2rXrq3psKicbNmyBZcvX8aFCxc0HQqVs6ZNm2Lt2rVwd3dHVFQUpk+fjpYtW+L69eswMTHRdHhEamEDkojoDTB69Ghcv36dc2becu7u7ggLC0NycjJ27NiBwYMH4/jx42xEvoWePHmCL7/8EiEhIdDX19d0OFTOOnfurPjbx8cHTZs2hYuLC7Zt28Yh6vTGYQPyDWdtbQ1tbW28ePFClP7ixQvY2dlpKCoiKktjxozB3r17ceLECTg5OWk6HCpHenp6qFGjBgCgYcOGuHDhAubNm4dly5ZpODIqa5cuXUJMTAwaNGigSJPJZDhx4gQWLlyI7OxsaGtrazBCKk/m5uaoVasW7t27p+lQiNTGOZBvOD09PTRs2BCHDx9WpMnlchw+fJjzZojecIIgYMyYMdi1axeOHDmCatWqaTokqmByuRzZ2dmaDoPKQbt27XDt2jWEhYUptkaNGmHgwIEICwtj4/Etl5aWhvv378Pe3l7ToRCpjT2Qb4Hx48dj8ODBaNSoEZo0aYK5c+ciPT0dQ4YM0XRoVMbS0tJEv1ZGRkYiLCwMlpaWcHZ21mBkVB5Gjx6NTZs24X//+x9MTEwQHR0NADAzM4OBgYGGo6OyFhgYiM6dO8PZ2RmpqanYtGkTjh07hgMHDmg6NCoHJiYmheYzGxkZwcrKivOc30ITJkxA9+7d4eLigufPn2PatGnQ1tZG//79NR0akdrYgHwLfPTRR4iNjcXUqVMRHR2NevXqYf/+/YUW1qE338WLF9GmTRvF/vjx4wEAgwcPxtq1azUUFZWXJUuWAABat24tSl+zZg0CAgIqPiAqVzExMRg0aBCioqJgZmYGHx8fHDhwAO3bt9d0aERUSk+fPkX//v0RHx8PGxsbtGjRAmfPnoWNjY2mQyNSG+8DSURERERERCrhHEgiIiIiIiJSCRuQREREREREpBI2IImIiIiIiEglbEASERERERGRStiAJCIiIiIiIpWwAUlEREREREQqYQOSiIiIiIiIVMIGJBEREREREamEDUgiIqLXCAgIQM+ePYvNc+zYMUgkEiQlJVVITERERJrABiQR0RsgNjYWo0aNgrOzM6RSKezs7NCxY0ecPn1a06FVGhKJRLGZmZmhefPmOHLkSJnUPW/ePKxdu1ax37p1a4wbN06Ux8/PD1FRUTAzMyuTcxIREVVGbEASEb0BevfujStXrmDdunW4c+cO9uzZg9atWyM+Pl7ToVUqa9asQVRUFE6fPg1ra2t069YNDx48KHW9ZmZmMDc3LzaPnp4e7OzsIJFISn0+IiKiyooNSCKiSi4pKQknT57ETz/9hDZt2sDFxQVNmjRBYGAg3n//fVG+YcOGwcbGBqampmjbti3Cw8NFdc2ePRtVqlSBiYkJhg4dikmTJqFevXqK40X1rPXs2RMBAQGK/ezsbEyYMAGOjo4wMjJC06ZNcezYMcXxtWvXwtzcHAcOHICnpyeMjY3RqVMnREVFiepdvXo16tSpA6lUCnt7e4wZM0ataymKubk57Ozs4OXlhSVLliAzMxMhISEAgOPHj6NJkyaK802aNAl5eXmKsjt27IC3tzcMDAxgZWUFf39/pKenAxAPYQ0ICMDx48cxb948RY/nw4cPixzCunPnTsU1urq64tdffxXF6+rqilmzZuHTTz+FiYkJnJ2dsXz58tdeJxERkaawAUlEVMkZGxvD2NgYu3fvRnZ2ttJ8ffr0QUxMDP755x9cunQJDRo0QLt27ZCQkAAA2LZtG4KCgjBr1ixcvHgR9vb2WLx4sdrxjBkzBqGhodiyZQuuXr2KPn36oFOnTrh7964iT0ZGBn755Rds2LABJ06cwOPHjzFhwgTF8SVLlmD06NEYMWIErl27hj179qBGjRoqX4sqDAwMAAA5OTl49uwZunTpgsaNGyM8PBxLlizBqlWr8MMPPwAAoqKi0L9/f3z66aeIiIjAsWPH0KtXLwiCUKjeefPmwdfXF8OHD0dUVBSioqJQtWrVQvkuXbqEvn37ol+/frh27RqCgoIwZcoU0VBYAPj111/RqFEjXLlyBZ9//jlGjRqF27dvq3ydREREFUogIqJKb8eOHYKFhYWgr68v+Pn5CYGBgUJ4eLji+MmTJwVTU1MhKytLVK569erCsmXLBEEQBF9fX+Hzzz8XHW/atKlQt25dxX6rVq2EL7/8UpSnR48ewuDBgwVBEIRHjx4J2trawrNnz0R52rVrJwQGBgqCIAhr1qwRAAj37t1THF+0aJFQpUoVxb6Dg4Pw3XffFXmtqlxLUQAIu3btEgRBENLT04XPP/9c0NbWFsLDw4XJkycL7u7uglwuF8VkbGwsyGQy4dKlSwIA4eHDh0XWPXjwYKFHjx6K/aIep6NHjwoAhMTEREEQBGHAgAFC+/btRXm++eYboXbt2op9FxcX4eOPP1bsy+VywdbWVliyZInS6yQiItIk9kASEb0BevfujefPn2PPnj3o1KkTjh07hgYNGih6s8LDw5GWlgYrKytFj6WxsTEiIyNx//59AEBERASaNm0qqtfX11etOK5duwaZTIZatWqJznP8+HHFeQDA0NAQ1atXV+zb29sjJiYGABATE4Pnz5+jXbt2RZ5DlWtRpn///jA2NoaJiQl27tyJVatWwcfHBxEREfD19RXNT2zevDnS0tLw9OlT1K1bF+3atYO3tzf69OmDFStWIDExUa3H5r8iIiLQvHlzUVrz5s1x9+5dyGQyRZqPj4/ib4lEAjs7O8VjRUREVNnoaDoAIiJSjb6+Ptq3b4/27dtjypQpGDZsGKZNm4aAgACkpaXB3t5eNBfxpdct/vIqLS2tQsM2c3NzFX+npaVBW1sbly5dgra2tiifsbGx4m9dXV3RMYlEoqj35dBSZUpzLb///jv8/f1hZmYGGxubYvO+SltbGyEhIThz5gwOHjyIBQsW4LvvvsO5c+dQrVo1lespiaIeK7lcXq7nJCIiKin2QBIRvaFq166tWOSlQYMGiI7+f3v3EwrvFsdx/HMlKyw0MkIsNDU2YoOUMv02SlGUhZoJWYySmGFhZDBKKRHWpKyowWKmqNkof0byL0o0zUTqZtjYmNJ07+JXaq659fxW96f7ftWzOD1P55zv8tM5zzl/KjMzU+Xl5SmPyWSSJFmtVoXD4ZQ+jo+PU9r5+fkph90kk0ldX19/tquqqpRMJvX8/PxlHLPZbGjeOTk5KisrUygUSvveSC3/xmw2q7y8/Et4tFqtOjo6SgnHBwcHysnJUXFxsaSfwa2+vl6Tk5M6Pz9XVlaWtra20o6TlZWVsoqYjtVq/XLNysHBgSwWy5fwDQDAd0GABIDf3Ovrq2w2m9bX13V1daVoNKrNzU3Nzs6qpaVFkvTjxw/V1dWptbVVe3t7isViOjw8lMfj0enpqSRpYGBAKysrWl1d1d3dnbxer25ublLGstlsCgQCCgQCur29ldPpTDlV1GKxqLOzU3a7XX6/X9FoVCcnJ5qZmVEgEDBc08TEhObm5rS4uKj7+3udnZ1paWnJcC2/qq+vT4+Pj+rv79ft7a12dnbk9Xo1NDSkjIwMhcPhz8OFHh4e5Pf7FY/HZbVa0/ZXVlamcDisWCyml5eXtCuGLpdLoVBIPp9Pd3d3Wltb0/LycsphQgAAfDdsYQWA31x2drZqamo0Pz+vSCSij48PlZSUqLe3V6Ojo5J+rp4Fg0F5PB51dXUpHo/LbDaroaFBBQUFkqSOjg5FIhGNjIwokUiora1NTqdTu7u7n2N1d3fr8vJSdrtdmZmZGhwcVGNjY8p8VldXNT09LZfLpaenJ5lMJtXW1qq5udlwTQ6HQ4lEQvPz83K73TKZTGpvbzdcy68qKipSMBjU8PCwKisrlZeXp56eHo2NjUmScnNztb+/r4WFBb29vam0tFRzc3NqampK25/b7ZbD4VBFRYXe398VjUa/fFNdXa2NjQ2Nj4/L5/OpsLBQU1NTKVeiAADw3fzx1z9/dgEA/G9MTExoe3tbFxcX//VUAADAN8AWVgAAAACAIQRIAAAAAIAhbGEFAAAAABjCCiQAAAAAwBACJAAAAADAEAIkAAAAAMAQAiQAAAAAwBACJAAAAADAEAIkAAAAAMAQAiQAAAAAwBACJAAAAADAkL8B9PQIuMfD8R4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l927yrMyDsxc",
        "outputId": "ae11f3eb-8d53-4d89-fc06-8c5704fc958c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 13G\n",
            "drwxr-xr-x 1 root root 4.0K Jan 30 18:25 .\n",
            "drwxr-xr-x 3 root root 4.0K Jan 30 18:25 extracted_inference\n",
            "-rw-r--r-- 1 root root 3.8G Jan 30 18:21 fine_tuned_genomic_model.nemo\n",
            "-rw-r--r-- 1 root root 770K Jan 30 17:30 genomic_train.jsonl\n",
            "drwxr-xr-x 4 root root 4.0K Jan 30 14:47 fine_tuned_workspace\n",
            "-rw-r--r-- 1 root root 8.9G Jan 30 14:40 nucleotide_transformer_fixed.nemo\n",
            "drwxr-xr-x 4 root root 4.0K Jan 30 14:31 nemo_genomic_workspace\n",
            "drwxr-xr-x 1 root root 4.0K Jan 30 13:07 ..\n",
            "drwxr-xr-x 1 root root 4.0K Dec  9 14:42 sample_data\n",
            "drwxr-xr-x 4 root root 4.0K Dec  9 14:41 .config\n"
          ]
        }
      ]
    }
  ]
}