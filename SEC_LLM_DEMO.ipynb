{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa1iv6CLpn9GZGiiv9t1gU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/SEC_LLM_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "exz6irZjS3Td",
        "outputId": "1a0dfdc7-b740-44eb-cac4-bd4302495f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "Gemini model 'gemini-2.5-flash' initialized for agentic decisions.\n",
            "Orchestrator Agent: Received a new email to investigate.\n",
            "  -> Analysis Agent: Sending email to LLM for deep analysis...\n",
            "  -> Analysis Agent: Analysis complete. Returning structured data.\n",
            "\n",
            "Orchestrator Agent: All agents have reported. Synthesizing final report...\n",
            "  - Final Conclusion: Investigation complete. Threat level is low.\n",
            "  -> Action Agent: Taking action based on recommendation: 'None'\n",
            "\n",
            "Orchestrator Agent: Final workflow complete.\n",
            "==================================================\n",
            "\n",
            "Orchestrator Agent: Received a new email to investigate.\n",
            "  -> Analysis Agent: Sending email to LLM for deep analysis...\n",
            "  -> Analysis Agent: Analysis complete. Returning structured data.\n",
            "  -> Search Agent: Querying threat intelligence for URL: https://suspicious-payment-link.com/login\n",
            "\n",
            "Orchestrator Agent: All agents have reported. Synthesizing final report...\n",
            "  - Final Conclusion: CRITICAL threat. LLM analysis and threat intelligence both confirm phishing.\n",
            "  -> Action Agent: Taking action based on recommendation: 'Do not click on the link. Report the email as phishing, quarantine it, and block the sender and associated URL.'\n",
            "\n",
            "Orchestrator Agent: Final workflow complete.\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- API Key Setup (as provided by you, directly used) ---\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "if GOOGLE_API_KEY:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "else:\n",
        "    print(\"WARNING: GOOGLE_API_KEY not found in Colab Secrets. Please ensure 'GEMINI' secret is set.\")\n",
        "    print(\"API calls will likely fail. Proceeding with unconfigured API.\")\n",
        "\n",
        "# --- Agent Configuration ---\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "\n",
        "try:\n",
        "    AGENTIC_MODEL = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "    print(f\"Gemini model '{AgentConfig.LLM_MODEL_NAME}' initialized for agentic decisions.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Failed to initialize Gemini model. Please check your API key and model name. Error: {e}\")\n",
        "    AGENTIC_MODEL = None\n",
        "\n",
        "# --- Agent Functions ---\n",
        "# Note: The LLM is used exclusively within the analysis_agent for this demo.\n",
        "\n",
        "def analysis_agent(email_content):\n",
        "    \"\"\"\n",
        "    The Analysis Agent, powered by a Gemini LLM, to analyze email content.\n",
        "    It returns a structured JSON object for programmatic parsing.\n",
        "    \"\"\"\n",
        "    if not AGENTIC_MODEL:\n",
        "        print(\"Analysis Agent: ERROR - LLM model not available.\")\n",
        "        return {\"error\": \"LLM not configured.\"}\n",
        "\n",
        "    print(\"  -> Analysis Agent: Sending email to LLM for deep analysis...\")\n",
        "\n",
        "    # Prompt the LLM to act as a security analyst and return a structured JSON.\n",
        "    # This is a core part of agentic design: giving the LLM a clear role and output format.\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert cybersecurity analyst. Your task is to analyze the following email for signs of a phishing attempt.\n",
        "    Based on your analysis, please return a JSON object with the following structure:\n",
        "    {{\n",
        "      \"is_phishing\": boolean,\n",
        "      \"suspicious_elements\": string[],\n",
        "      \"threat_score\": number,\n",
        "      \"recommended_action\": string,\n",
        "      \"suspicious_url\": string\n",
        "    }}\n",
        "\n",
        "    If the email is legitimate, \"is_phishing\" should be false and \"threat_score\" should be low (e.g., 0.1).\n",
        "    If it is a phishing attempt, \"is_phishing\" should be true and \"threat_score\" should be high (e.g., 0.9).\n",
        "    The \"recommended_action\" should be a brief description of what to do (e.g., \"Quarantine email and block URL.\").\n",
        "\n",
        "    Email to analyze:\n",
        "    ---\n",
        "    {email_content}\n",
        "    ---\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Instruct the model to return a JSON object, which is critical for programmatic use.\n",
        "        response = AGENTIC_MODEL.generate_content(\n",
        "            prompt,\n",
        "            generation_config={\"response_mime_type\": \"application/json\"}\n",
        "        )\n",
        "\n",
        "        # The LLM's response is a string. We must parse it.\n",
        "        json_output = json.loads(response.text)\n",
        "        print(\"  -> Analysis Agent: Analysis complete. Returning structured data.\")\n",
        "        return json_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Analysis Agent: ERROR - LLM call failed or response was invalid. Error: {e}\")\n",
        "        return {\"error\": str(e), \"is_phishing\": False, \"threat_score\": 0.0}\n",
        "\n",
        "def search_agent(url):\n",
        "    \"\"\"(MOCK) Simulates the Search Agent's function, checking external threat intel.\"\"\"\n",
        "    print(f\"  -> Search Agent: Querying threat intelligence for URL: {url}\")\n",
        "    time.sleep(1) # Simulate network latency\n",
        "    if \"suspicious-payment-link.com\" in url:\n",
        "        return {\"threat_intelligence_findings\": \"URL flagged as a known phishing site.\", \"is_malicious\": True}\n",
        "    return {\"threat_intelligence_findings\": \"No known threats found.\", \"is_malicious\": False}\n",
        "\n",
        "def action_agent(recommended_action, url_to_block):\n",
        "    \"\"\"(MOCK) Simulates the Action Agent's function.\"\"\"\n",
        "    print(f\"  -> Action Agent: Taking action based on recommendation: '{recommended_action}'\")\n",
        "    if \"Quarantine\" in recommended_action:\n",
        "        print(f\"  -> Action Agent: Blocking URL '{url_to_block}' and quarantining email.\")\n",
        "        return \"Action taken: Threat neutralized.\"\n",
        "    return \"Action taken: No action required.\"\n",
        "\n",
        "def orchestrator_agent(email_text):\n",
        "    \"\"\"\n",
        "    The Orchestrator Agent. It plans, delegates, and synthesizes the final response.\n",
        "    \"\"\"\n",
        "    print(\"Orchestrator Agent: Received a new email to investigate.\")\n",
        "\n",
        "    # Step 1: Delegate the primary analysis to the LLM-powered Analysis Agent.\n",
        "    analysis_results = analysis_agent(email_text)\n",
        "\n",
        "    if analysis_results.get(\"error\"):\n",
        "        print(f\"Orchestrator Agent: Investigation failed due to an error: {analysis_results['error']}\")\n",
        "        return \"Investigation failed.\"\n",
        "\n",
        "    # Step 2: Delegate external search if a suspicious URL was found.\n",
        "    search_results = {}\n",
        "    if analysis_results.get(\"suspicious_url\"):\n",
        "        search_results = search_agent(analysis_results[\"suspicious_url\"])\n",
        "\n",
        "    # Step 3: Synthesize findings and delegate action.\n",
        "    print(\"\\nOrchestrator Agent: All agents have reported. Synthesizing final report...\")\n",
        "    if analysis_results[\"is_phishing\"] and search_results.get(\"is_malicious\"):\n",
        "        print(f\"  - Final Conclusion: CRITICAL threat. LLM analysis and threat intelligence both confirm phishing.\")\n",
        "        action_agent(analysis_results[\"recommended_action\"], analysis_results[\"suspicious_url\"])\n",
        "    else:\n",
        "        print(\"  - Final Conclusion: Investigation complete. Threat level is low.\")\n",
        "        action_agent(\"None\", None)\n",
        "\n",
        "    print(\"\\nOrchestrator Agent: Final workflow complete.\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- Demo Usage ---\n",
        "\n",
        "# Example 1: A legitimate email\n",
        "legit_email = \"Hello, your Q3 financial report is attached. Please review it at your convenience. Best regards, John from Accounting.\"\n",
        "orchestrator_agent(legit_email)\n",
        "\n",
        "# Example 2: A suspicious, phishing-like email\n",
        "phishing_email = \"Urgent action required! Your account has been compromised. Please update your payment information immediately via this link: https://suspicious-payment-link.com/login\"\n",
        "orchestrator_agent(phishing_email)"
      ]
    }
  ]
}