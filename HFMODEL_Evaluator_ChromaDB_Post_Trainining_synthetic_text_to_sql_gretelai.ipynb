{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "b_dQycoVu1yF"
      ],
      "authorship_tag": "ABX9TyPgNoikLYZnnIMA0S7jPCrl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b11eff3862664918a760515bbe7dab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e67342f37d483d9b119504d71bf6c5",
              "IPY_MODEL_df68a1fd77d04820a349ab1225786249",
              "IPY_MODEL_d3000c58a91f4377a7b0d0b3592af8c6"
            ],
            "layout": "IPY_MODEL_37524bdaeeef49f392b462081785ff66"
          }
        },
        "b8e67342f37d483d9b119504d71bf6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d73415ff63c40528a27acd919f09f92",
            "placeholder": "​",
            "style": "IPY_MODEL_7dfbca8465b142c78861c3d1737fdbea",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "df68a1fd77d04820a349ab1225786249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d711d009e04f3b9ec93f82428c3c88",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4940c0ee0fb846418db7902d6b31b0f2",
            "value": 2
          }
        },
        "d3000c58a91f4377a7b0d0b3592af8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35899b4fd24049109505b55f7cd0b13d",
            "placeholder": "​",
            "style": "IPY_MODEL_0e73464e039142ffadabbb5e51c524f7",
            "value": " 2/2 [00:05&lt;00:00,  2.38s/it]"
          }
        },
        "37524bdaeeef49f392b462081785ff66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d73415ff63c40528a27acd919f09f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dfbca8465b142c78861c3d1737fdbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d711d009e04f3b9ec93f82428c3c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4940c0ee0fb846418db7902d6b31b0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35899b4fd24049109505b55f7cd0b13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e73464e039142ffadabbb5e51c524f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "103a0750ab9e44b98562e2a06764ead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2267460f0a6479d832965488cf2df9f",
              "IPY_MODEL_0a1414978aed4e2f91041b44116b18e8",
              "IPY_MODEL_3aac03c25a144dc1a2a431d2290b056b"
            ],
            "layout": "IPY_MODEL_20a90218a52d492bb91bfe2e8dc83db4"
          }
        },
        "c2267460f0a6479d832965488cf2df9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a700eac6a74291a80a01037b174267",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ec1ec2d3fe49e3b2aac2ecdc59e6aa",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0a1414978aed4e2f91041b44116b18e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6af0ec908ed4fa4971fb857c92e799f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_015b6dc552cf4f508da8b057cf3ff459",
            "value": 3
          }
        },
        "3aac03c25a144dc1a2a431d2290b056b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af5f0a911dd240378f090c81d4cdb009",
            "placeholder": "​",
            "style": "IPY_MODEL_b2fc4cba1cd64f1cb424da821a492476",
            "value": " 3/3 [01:01&lt;00:00, 20.30s/it]"
          }
        },
        "20a90218a52d492bb91bfe2e8dc83db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27a700eac6a74291a80a01037b174267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ec1ec2d3fe49e3b2aac2ecdc59e6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6af0ec908ed4fa4971fb857c92e799f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015b6dc552cf4f508da8b057cf3ff459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af5f0a911dd240378f090c81d4cdb009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2fc4cba1cd64f1cb424da821a492476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9a2449d21e42c0b368e3311625a059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_060d73a8ea564ff08cebada7fcd60a1a",
              "IPY_MODEL_2f0025c828764c259b5c4f48ab77874f",
              "IPY_MODEL_6c963feb987848308329698041ea2206"
            ],
            "layout": "IPY_MODEL_d2adadc05347403886f1b3fd7152e757"
          }
        },
        "060d73a8ea564ff08cebada7fcd60a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fab77cf1c6cd44a3ab94559a40c29655",
            "placeholder": "​",
            "style": "IPY_MODEL_9f0d1a60fbc040799995b1d7847a06a0",
            "value": "100%"
          }
        },
        "2f0025c828764c259b5c4f48ab77874f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8c2eec32174c04a3baf3f9a3b8ea88",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03f9d44cfd9e42d286ddf2ec431307eb",
            "value": 10
          }
        },
        "6c963feb987848308329698041ea2206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a49e24b223214374bb1ed8b41cb4b1d8",
            "placeholder": "​",
            "style": "IPY_MODEL_c3ca61f7bef649a893f909bd62ff7fef",
            "value": " 10/10 [04:34&lt;00:00, 27.66s/it]"
          }
        },
        "d2adadc05347403886f1b3fd7152e757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab77cf1c6cd44a3ab94559a40c29655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0d1a60fbc040799995b1d7847a06a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8c2eec32174c04a3baf3f9a3b8ea88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f9d44cfd9e42d286ddf2ec431307eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a49e24b223214374bb1ed8b41cb4b1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ca61f7bef649a893f909bd62ff7fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/HFMODEL_Evaluator_ChromaDB_Post_Trainining_synthetic_text_to_sql_gretelai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRARIES"
      ],
      "metadata": {
        "id": "53VITjInrs-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q chromadb\n",
        "!pip install -q faiss-gpu\n",
        "!pip install peft  -q\n",
        "\n",
        "!pip install bitsandbytes -q\n",
        "!pip pip install accelerate -q\n",
        "\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install mistral_inference -q\n",
        "\n",
        "!pip install -q evaluate sentence_transformers"
      ],
      "metadata": {
        "id": "zR4yytDbPyOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2189fad0-22ea-4157-b595-cd158510ee81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hERROR: unknown command \"pip\"\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cJWzOH4B81",
        "outputId": "7d5482b2-80ea-4bf5-c17b-347c6f77ab9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 11 18:31:40 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   44C    P8              17W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import colab_env\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "metadata": {
        "id": "zAOOi0pfRZPt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Settings"
      ],
      "metadata": {
        "id": "zi9nbbcSvbWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ckGGJclusZ",
        "outputId": "5f4b87ec-7c1a-4e6d-d77d-79e1bd2b7e71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=True)\n",
        "\n",
        "\n",
        "# Load model and tokenizer\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    token=True\n",
        ")\n",
        "\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b11eff3862664918a760515bbe7dab77",
            "b8e67342f37d483d9b119504d71bf6c5",
            "df68a1fd77d04820a349ab1225786249",
            "d3000c58a91f4377a7b0d0b3592af8c6",
            "37524bdaeeef49f392b462081785ff66",
            "2d73415ff63c40528a27acd919f09f92",
            "7dfbca8465b142c78861c3d1737fdbea",
            "a6d711d009e04f3b9ec93f82428c3c88",
            "4940c0ee0fb846418db7902d6b31b0f2",
            "35899b4fd24049109505b55f7cd0b13d",
            "0e73464e039142ffadabbb5e51c524f7"
          ]
        },
        "id": "4f5pWT8nlz0x",
        "outputId": "fc2bee4d-35ea-425d-bf7a-90e13e7ca000"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b11eff3862664918a760515bbe7dab77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Models and Tokenizer AND ChromaDB Setup"
      ],
      "metadata": {
        "id": "F8UCjMvgdl8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import os\n",
        "\n",
        "from peft import PeftModel # PeftModel is now correctly imported from peft\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "# Logging Setup\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# 1. Configurable Parameters\n",
        "\n",
        "#gretelai/synthetic_text_to_sql\n",
        "DATASET_FILE = \"/content/gdrive/MyDrive/datasets/gretelai_test_dataset.json\"\n",
        "\n",
        "NUM_SAMPLES_TO_PROCESS = int(os.getenv(\"NUM_SAMPLES\", 10))\n",
        "GENERATION_PARAMS = {\n",
        "    \"max_new_tokens\": 256, \"do_sample\": True, \"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95\n",
        "}\n",
        "SIMILARITY_THRESHOLD = 0.85\n",
        "\n",
        "\n",
        "# 2. Load Evaluation Dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=DATASET_FILE, split=\"train\")\n",
        "if NUM_SAMPLES_TO_PROCESS > 0:\n",
        "    eval_dataset = eval_dataset.select(range(NUM_SAMPLES_TO_PROCESS))\n",
        "logging.info(f\"Processing {len(eval_dataset)} samples from the dataset.\")\n",
        "\n",
        "\n",
        "# 3. Load Models and Tokenizer\n",
        "\n",
        "model_id ='/content/gdrive/MyDrive/model/GNNT2SQL/checkpoint-1950/'\n",
        "logging.info(f\"Loading fine-tuned PEFT model from: {model_id}\")\n",
        "\n",
        "# Use PeftModel to load the model, pass the model object and model_id as arguments\n",
        "#model = PeftModel.from_pretrained(mistral_model, model_id)\n",
        "\n",
        "\n",
        "PEFT_MODEL_ID = \"frankmorales2020/Mistral-7B-text-to-sql-flash-attention-2-dataeval\"\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(PEFT_MODEL_ID)\n",
        "tokenizer = AutoTokenizer.from_pretrained(PEFT_MODEL_ID)\n",
        "\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, **GENERATION_PARAMS)\n",
        "logging.info(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "# 4. ChromaDB Setup\n",
        "client = chromadb.PersistentClient(path='db')  # Store embeddings on disk\n",
        "collection = client.get_or_create_collection(name=\"sql_queries_and_embeddings\")\n",
        "\n",
        "# Add Original SQL Queries to ChromaDB\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "original_sql_queries = [\n",
        "    item['messages'][2]['content']\n",
        "    for item in eval_dataset if len(item['messages']) > 2 and item['messages'][2].get('content')\n",
        "]\n",
        "\n",
        "sql_embeddings = embedding_model.encode(original_sql_queries).tolist()\n",
        "collection.add(\n",
        "    embeddings=sql_embeddings,\n",
        "    metadatas=[{\"original_sql\": query} for query in original_sql_queries],\n",
        "    ids=[f\"original_{i}\" for i in range(len(original_sql_queries))]  # Unique IDs\n",
        ")"
      ],
      "metadata": {
        "id": "tOrvw1OpPw_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "103a0750ab9e44b98562e2a06764ead5",
            "c2267460f0a6479d832965488cf2df9f",
            "0a1414978aed4e2f91041b44116b18e8",
            "3aac03c25a144dc1a2a431d2290b056b",
            "20a90218a52d492bb91bfe2e8dc83db4",
            "27a700eac6a74291a80a01037b174267",
            "a5ec1ec2d3fe49e3b2aac2ecdc59e6aa",
            "b6af0ec908ed4fa4971fb857c92e799f",
            "015b6dc552cf4f508da8b057cf3ff459",
            "af5f0a911dd240378f090c81d4cdb009",
            "b2fc4cba1cd64f1cb424da821a492476"
          ]
        },
        "outputId": "d27833e9-b749-4f0a-82ba-b03301743714"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "103a0750ab9e44b98562e2a06764ead5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: original_9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_6\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: original_9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PeftModel to load the model, pass the model object and model_id as arguments\n",
        "#model = PeftModel.from_pretrained(mistral_model, model_id)\n",
        "#pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, **GENERATION_PARAMS)\n",
        "#logging.info(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "#print()\n",
        "#output = pipe(\"What is the percentage of successful open data initiatives in the education sector?\")\n",
        "#print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "mzi-BodP0bo1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postgresql Setup"
      ],
      "metadata": {
        "id": "b_dQycoVu1yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ADDED By FM 01/06/2024\n",
        "!apt-get update -y\n",
        "!apt-get install postgresql-14 -y\n",
        "\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all"
      ],
      "metadata": {
        "id": "fz3g0Q77QTBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895da91e-ee6c-4b46-fab4-5cbd5cf1ebe2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql-14 is already the newest version (14.13-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql-server-dev-all is already the newest version (238).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PostGRES SQL Settings\n",
        "!sudo -u postgres psql -c \"CREATE USER postgres WITH SUPERUSER\"\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFbxBi-HQZT-",
        "outputId": "54fa540f-e043-4b09-91dc-4e34d94da9dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR:  role \"postgres\" already exists\n",
            "ALTER ROLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_create='CREATE TABLE table_name_24 (score VARCHAR, date VARCHAR)'"
      ],
      "metadata": {
        "id": "l5ATm5VvQiAg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_select='SELECT 2009 FROM table_name_50 WHERE 2011 = \"a\"'"
      ],
      "metadata": {
        "id": "iJjf15-aQqco"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def table_creator(query):\n",
        "    import os\n",
        "    import psycopg2 as ps\n",
        "    import pandas as pd\n",
        "\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "                  user=DB_USER,\n",
        "                  password=DB_PASS,\n",
        "                  host=DB_HOST,\n",
        "                  port=DB_PORT)\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Wrap the execute command in a try-except block to handle potential errors\n",
        "    try:\n",
        "        cur.execute(\"\"\"\n",
        "                            %s\n",
        "                            \"\"\"%query)\n",
        "        conn.commit()\n",
        "        print(\"Table Created successfully\")\n",
        "    except Exception as e:\n",
        "        conn.rollback() # Rollback the transaction in case of an error\n",
        "        print(\"Error creating table:\", e)\n",
        "\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "Q5qUFuunQvHU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2 as ps\n",
        "import pandas as pd\n",
        "\n",
        "DB_NAME = \"postgres\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_PASS = \"postgres\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5432\""
      ],
      "metadata": {
        "id": "BqlIz9IYQ3UT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2 as ps\n",
        "import pandas as pd\n",
        "\n",
        "def table_select(query):\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "                      user=DB_USER,\n",
        "                      password=DB_PASS,\n",
        "                      host=DB_HOST,\n",
        "                      port=DB_PORT)\n",
        "    print(\"Database connected successfully\")\n",
        "\n",
        "    #query = query.replace('\"', \"'\") # Replace double quotes with single quotes for potential date values\n",
        "\n",
        "    try:\n",
        "\n",
        "        #df = pd.read_sql_query(\"%s\"%query, con=conn)\n",
        "        #print('rec: %'%df) # Print the resulting DataFrame\n",
        "\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(query)\n",
        "        rows = cur.fetchall()\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print('\\n')\n",
        "        print('Record(s): %s \\n'%len(rows))\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "\n",
        "\n",
        "        eqc=1\n",
        "\n",
        "    except Exception as e:\n",
        "        eqc=0\n",
        "        #conn.rollback() # Rollback the transaction in case of an error\n",
        "        print(\"Error executing query:\", e)\n",
        "        #print('TABLE IS EMPTY')\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    return eqc"
      ],
      "metadata": {
        "id": "ptNXNomUQ0Fy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_creator(QUERY_create)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsMREUeGQ9QQ",
        "outputId": "3a1272b0-6a30-4ca1-ac2a-e59c489b10a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error creating table: relation \"table_name_24\" already exists\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluator"
      ],
      "metadata": {
        "id": "VszcBUuCvLAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluation Function (Exact Match Only)\n",
        "def evaluate(sample):\n",
        "    eqc=0\n",
        "    prompt = pipe.tokenizer.apply_chat_template(sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
        "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
        "    predicted_answer = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "    #print(\"\\n\\n\")\n",
        "    question = sample[\"messages\"][1][\"content\"]\n",
        "    original_answer = sample[\"messages\"][2][\"content\"]\n",
        "\n",
        "\n",
        "    schema=sample[\"messages\"][0]['content']\n",
        "    schema_query=schema[153:len(schema)]\n",
        "\n",
        "    #print(f'Question: {question}')\n",
        "    #print(f'SCHEMA: {schema_query}')\n",
        "    #print(f'Original Answer: {original_answer}')\n",
        "    #print(f'Generated Answer: {predicted_answer}')\n",
        "\n",
        "    if predicted_answer == original_answer:\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print('MATCH')\n",
        "        print(\"\\n\")\n",
        "\n",
        "        print(f'Question: {question}')\n",
        "        print(f'SCHEMA: {schema_query}')\n",
        "        print(f'Original Answer: {original_answer}')\n",
        "        print(f'Generated Answer: {predicted_answer}')\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'SCHEMA QUERY: {schema_query}')\n",
        "        table_creator(schema_query)\n",
        "        print(\"\\n\")\n",
        "        print(f'Generated Answer: {predicted_answer}')\n",
        "        eqc=table_select(predicted_answer)\n",
        "        print(eqc)\n",
        "        print(\"\\n\")\n",
        "        if int(eqc)==1:\n",
        "           print('Good Query execution')\n",
        "        else:\n",
        "           print('Bad Query execution')\n",
        "\n",
        "        #print(\"\\n\")\n",
        "        #print('MATCH')\n",
        "        return 1, eqc\n",
        "\n",
        "    # If not an exact match, check semantic similarity using ChromaDB:\n",
        "    predicted_embedding = embedding_model.encode([predicted_answer]).tolist()[0]\n",
        "    results = collection.query(\n",
        "        query_embeddings=[predicted_embedding],\n",
        "        n_results=1,\n",
        "        include=[\"distances\", \"metadatas\"]\n",
        "    )\n",
        "    closest_distance = results['distances'][0][0]\n",
        "    most_similar_query = results['metadatas'][0][0]['original_sql']\n",
        "    print(\"\\n\")\n",
        "    print(f'Closest Distance: {closest_distance}')\n",
        "\n",
        "    similarity_threshold = SIMILARITY_THRESHOLD\n",
        "\n",
        "    #if closest_distance < similarity_threshold:\n",
        "    if most_similar_query == original_answer:\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print('MATCH (Semantically Similar)')\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'Question: {question}')\n",
        "        print(f'SCHEMA: {schema_query}')\n",
        "        print(f'Original Answer: {original_answer}')\n",
        "        print(f'Generated Answer: {predicted_answer}')\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f'SCHEMA QUERY: {schema_query}')\n",
        "        table_creator(schema_query)\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "        print('Similar Query:', most_similar_query)\n",
        "        eqc=table_select(most_similar_query)\n",
        "        print(\"\\n\")\n",
        "        if int(eqc)==1:\n",
        "           print('Good Query execution')\n",
        "        else:\n",
        "           print('Bad Query execution')\n",
        "        print(\"\\n\")\n",
        "        return 1, eqc\n",
        "\n",
        "    else:\n",
        "        print('NO MATCH')\n",
        "        return 0, eqc\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "# 7. Main Evaluation Loop\n",
        "success_rate = []\n",
        "success_rate_query = []\n",
        "\n",
        "for i, s in enumerate(tqdm(eval_dataset)):\n",
        "    print()\n",
        "    print(f\"Evaluating sample: {i}\")\n",
        "    try:\n",
        "        success_rate.append(evaluate(s))\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error evaluating sample {i}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# 8. Compute and Print Accuracy\n",
        "if len(success_rate) > 0:\n",
        "    # Extract the first element (match success indicator) from each tuple\n",
        "    match_successes = [result[0] for result in success_rate]\n",
        "    accuracy = sum(match_successes) / len(success_rate)\n",
        "    print(f\"\\nMatch Accuracy: {accuracy:.2%}\\n\")\n",
        "\n",
        "    query_successes = [result[1] for result in success_rate]\n",
        "    accuracy = sum(query_successes) / len(query_successes)\n",
        "    print(f\"\\nQuery Successes: {accuracy:.2%}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo samples were successfully evaluated. Check the dataset and evaluation logic.\\n\")\n",
        "\n",
        "\n",
        "# 8. Compute and Print Accuracy\n",
        "#if len(success_rate) > 0:\n",
        "#    accuracy = sum(success_rate) / len(success_rate)\n",
        "#    print(f\"\\nMatch Accuracy: {accuracy:.2%}\\n\")\n",
        "#else:\n",
        "#    print(\"\\nNo samples were successfully evaluated. Check the dataset and evaluation logic.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de9a2449d21e42c0b368e3311625a059",
            "060d73a8ea564ff08cebada7fcd60a1a",
            "2f0025c828764c259b5c4f48ab77874f",
            "6c963feb987848308329698041ea2206",
            "d2adadc05347403886f1b3fd7152e757",
            "fab77cf1c6cd44a3ab94559a40c29655",
            "9f0d1a60fbc040799995b1d7847a06a0",
            "ee8c2eec32174c04a3baf3f9a3b8ea88",
            "03f9d44cfd9e42d286ddf2ec431307eb",
            "a49e24b223214374bb1ed8b41cb4b1d8",
            "c3ca61f7bef649a893f909bd62ff7fef"
          ]
        },
        "id": "pkl430CeQb8Z",
        "outputId": "6b1612f2-5bf4-4ff3-f173-2662586d2201"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de9a2449d21e42c0b368e3311625a059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating sample: 0\n",
            "\n",
            "\n",
            "Closest Distance: 0.373703259188982\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the percentage of successful open data initiatives in the education sector?\n",
            "SCHEMA: CREATE TABLE open_data_initiatives (id INT, sector VARCHAR(20), status VARCHAR(10)); INSERT INTO open_data_initiatives (id, sector, status) VALUES (1, 'justice', 'open'), (2, 'transportation', 'open'), (3, 'education', 'closed'), (4, 'education', 'open');\n",
            "Original Answer: SELECT 100.0 * COUNT(CASE WHEN status = 'open' THEN 1 END) / COUNT(*) FROM open_data_initiatives WHERE sector = 'education';\n",
            "Generated Answer: SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education' AND status = 'open' / SELECT COUNT(*) FROM open_data_initiatives WHERE sector = 'education'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE open_data_initiatives (id INT, sector VARCHAR(20), status VARCHAR(10)); INSERT INTO open_data_initiatives (id, sector, status) VALUES (1, 'justice', 'open'), (2, 'transportation', 'open'), (3, 'education', 'closed'), (4, 'education', 'open');\n",
            "Error creating table: relation \"open_data_initiatives\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT 100.0 * COUNT(CASE WHEN status = 'open' THEN 1 END) / COUNT(*) FROM open_data_initiatives WHERE sector = 'education';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(Decimal('50.0000000000000000'),)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 1\n",
            "\n",
            "\n",
            "Closest Distance: 0.10806215601508348\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the average Shariah-compliant investment portfolio return for female investors in the Middle East, grouped by year?\n",
            "SCHEMA: CREATE TABLE Investments (Id INT, InvestorGender VARCHAR(10), Location VARCHAR(20), InvestmentType VARCHAR(20), Return DECIMAL(5,2), InvestmentYear INT); INSERT INTO Investments (Id, InvestorGender, Location, InvestmentType, Return, InvestmentYear) VALUES (1, 'Female', 'Middle East', 'Shariah Compliant', 8.56, 2020), (2, 'Female', 'Middle East', 'Shariah Compliant', 9.15, 2021);\n",
            "Original Answer: SELECT AVG(Return) AS Avg_Return, InvestmentYear FROM Investments WHERE InvestmentType = 'Shariah Compliant' AND InvestorGender = 'Female' GROUP BY InvestmentYear;\n",
            "Generated Answer: SELECT AVG(Return) FROM Investments WHERE InvestorGender = 'Female' AND Location = 'Middle East' AND InvestmentType = 'Shariah Compliant' GROUP BY InvestmentYear\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE Investments (Id INT, InvestorGender VARCHAR(10), Location VARCHAR(20), InvestmentType VARCHAR(20), Return DECIMAL(5,2), InvestmentYear INT); INSERT INTO Investments (Id, InvestorGender, Location, InvestmentType, Return, InvestmentYear) VALUES (1, 'Female', 'Middle East', 'Shariah Compliant', 8.56, 2020), (2, 'Female', 'Middle East', 'Shariah Compliant', 9.15, 2021);\n",
            "Error creating table: relation \"investments\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT AVG(Return) AS Avg_Return, InvestmentYear FROM Investments WHERE InvestmentType = 'Shariah Compliant' AND InvestorGender = 'Female' GROUP BY InvestmentYear;\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 2 \n",
            "\n",
            "(Decimal('8.5600000000000000'), 2020)\n",
            "(Decimal('9.1500000000000000'), 2021)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 2\n",
            "\n",
            "\n",
            "Closest Distance: 0.023496496649387813\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: Find the minimum founding year for startups founded by Indigenous or Native entrepreneurs\n",
            "SCHEMA: CREATE TABLE company (id INT, name TEXT, founding_year INT, founder_race TEXT); INSERT INTO company (id, name, founding_year, founder_race) VALUES (1, 'IndigenousTech', 2010, 'Indigenous or Native American'); INSERT INTO company (id, name, founding_year, founder_race) VALUES (2, 'Beta', 2015, 'White');\n",
            "Original Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American';\n",
            "Generated Answer: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE company (id INT, name TEXT, founding_year INT, founder_race TEXT); INSERT INTO company (id, name, founding_year, founder_race) VALUES (1, 'IndigenousTech', 2010, 'Indigenous or Native American'); INSERT INTO company (id, name, founding_year, founder_race) VALUES (2, 'Beta', 2015, 'White');\n",
            "Error creating table: relation \"company\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT MIN(founding_year) FROM company WHERE founder_race = 'Indigenous or Native American';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(2010,)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 3\n",
            "\n",
            "\n",
            "Closest Distance: 0.020405342316535704\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: How many intelligence operations were conducted in 'Africa' in the 'IntelligenceOperations' table?\n",
            "SCHEMA: CREATE TABLE IntelligenceOperations (id INT PRIMARY KEY, operation_name VARCHAR(100), location VARCHAR(50), operation_type VARCHAR(50), start_date DATE, end_date DATE); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (1, 'Operation Red Anvil', 'Africa', 'Surveillance', '2021-01-01', '2021-03-31'); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (2, 'Operation Night Hawk', 'Europe', 'Counterintelligence', '2021-04-01', '2021-06-30');\n",
            "Original Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa';\n",
            "Generated Answer: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE IntelligenceOperations (id INT PRIMARY KEY, operation_name VARCHAR(100), location VARCHAR(50), operation_type VARCHAR(50), start_date DATE, end_date DATE); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (1, 'Operation Red Anvil', 'Africa', 'Surveillance', '2021-01-01', '2021-03-31'); INSERT INTO IntelligenceOperations (id, operation_name, location, operation_type, start_date, end_date) VALUES (2, 'Operation Night Hawk', 'Europe', 'Counterintelligence', '2021-04-01', '2021-06-30');\n",
            "Error creating table: relation \"intelligenceoperations\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT COUNT(*) FROM IntelligenceOperations WHERE location = 'Africa';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(1,)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 4\n",
            "\n",
            "\n",
            "Closest Distance: 0.4535806681646883\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the total number of space missions led by women?\n",
            "SCHEMA: CREATE TABLE space_missions (id INT, name VARCHAR(255), leader VARCHAR(255), year INT); INSERT INTO space_missions (id, name, leader, year) VALUES (1, 'Mars Rover', 'Dr. Jessica Watkins', 2022); INSERT INTO space_missions (id, name, leader, year) VALUES (2, 'ISS Expedition', 'Anousheh Ansari', 2023);\n",
            "Original Answer: SELECT COUNT(*) FROM space_missions WHERE leader IN (SELECT name FROM astronauts WHERE gender = 'Female');\n",
            "Generated Answer: SELECT COUNT(*) FROM space_missions WHERE leader = 'Anousheh Ansari'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE space_missions (id INT, name VARCHAR(255), leader VARCHAR(255), year INT); INSERT INTO space_missions (id, name, leader, year) VALUES (1, 'Mars Rover', 'Dr. Jessica Watkins', 2022); INSERT INTO space_missions (id, name, leader, year) VALUES (2, 'ISS Expedition', 'Anousheh Ansari', 2023);\n",
            "Error creating table: relation \"space_missions\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT COUNT(*) FROM space_missions WHERE leader IN (SELECT name FROM astronauts WHERE gender = 'Female');\n",
            "Database connected successfully\n",
            "Error executing query: relation \"astronauts\" does not exist\n",
            "LINE 1: ... space_missions WHERE leader IN (SELECT name FROM astronauts...\n",
            "                                                             ^\n",
            "\n",
            "\n",
            "\n",
            "Bad Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 5\n",
            "\n",
            "\n",
            "Closest Distance: 0.5162188854262053\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: How many products are sold by each supplier?\n",
            "SCHEMA: CREATE TABLE Products (ProductID int, SupplierID int, QuantitySold int);\n",
            "Original Answer: SELECT SupplierID, SUM(QuantitySold) FROM Products GROUP BY SupplierID;\n",
            "Generated Answer: SELECT COUNT(*), SupplierID FROM Products GROUP BY SupplierID\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE Products (ProductID int, SupplierID int, QuantitySold int);\n",
            "Error creating table: relation \"products\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT SupplierID, SUM(QuantitySold) FROM Products GROUP BY SupplierID;\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 0 \n",
            "\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 6\n",
            "\n",
            "\n",
            "Closest Distance: 0.2812768161654202\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the total waste generation in kg for the top 3 countries in 2020?\n",
            "SCHEMA: CREATE TABLE waste_generation (country VARCHAR(255), year INT, amount FLOAT); INSERT INTO waste_generation (country, year, amount) VALUES ('USA', 2020, 500.0), ('Canada', 2020, 350.0), ('Mexico', 2020, 400.0);\n",
            "Original Answer: SELECT wg.country, SUM(wg.amount) as total_waste FROM waste_generation wg WHERE wg.year = 2020 AND wg.country IN ('USA', 'Canada', 'Mexico') GROUP BY wg.country ORDER BY total_waste DESC LIMIT 3;\n",
            "Generated Answer: SELECT SUM(amount) FROM waste_generation WHERE country IN ('USA', 'Canada', 'Mexico') AND year = 2020\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE waste_generation (country VARCHAR(255), year INT, amount FLOAT); INSERT INTO waste_generation (country, year, amount) VALUES ('USA', 2020, 500.0), ('Canada', 2020, 350.0), ('Mexico', 2020, 400.0);\n",
            "Error creating table: relation \"waste_generation\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT wg.country, SUM(wg.amount) as total_waste FROM waste_generation wg WHERE wg.year = 2020 AND wg.country IN ('USA', 'Canada', 'Mexico') GROUP BY wg.country ORDER BY total_waste DESC LIMIT 3;\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 3 \n",
            "\n",
            "('USA', 500.0)\n",
            "('Mexico', 400.0)\n",
            "('Canada', 350.0)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 7\n",
            "\n",
            "\n",
            "Closest Distance: 0.21441722770497446\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: What is the average age of attendees at arts events in California and how many unique events have there been?\n",
            "SCHEMA: CREATE TABLE ca_events (id INT, num_attendees INT, avg_age FLOAT); CREATE TABLE ca_event_types (id INT, event_type VARCHAR(15)); INSERT INTO ca_events (id, num_attendees, avg_age) VALUES (1, 1200, 35.5), (2, 1800, 40.2); INSERT INTO ca_event_types (id, event_type) VALUES (1, 'Dance'), (2, 'Music');\n",
            "Original Answer: SELECT AVG(ce.avg_age), COUNT(DISTINCT cet.event_type) FROM ca_events ce INNER JOIN ca_event_types cet ON TRUE;\n",
            "Generated Answer: SELECT AVG(t2.avg_age), COUNT(DISTINCT t2.id) FROM ca_events AS t1 JOIN ca_event_types AS t2 ON t1.event_type_id = t2.id WHERE t2.event_type = 'Arts'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE ca_events (id INT, num_attendees INT, avg_age FLOAT); CREATE TABLE ca_event_types (id INT, event_type VARCHAR(15)); INSERT INTO ca_events (id, num_attendees, avg_age) VALUES (1, 1200, 35.5), (2, 1800, 40.2); INSERT INTO ca_event_types (id, event_type) VALUES (1, 'Dance'), (2, 'Music');\n",
            "Error creating table: relation \"ca_events\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT AVG(ce.avg_age), COUNT(DISTINCT cet.event_type) FROM ca_events ce INNER JOIN ca_event_types cet ON TRUE;\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(37.85, 2)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 8\n",
            "\n",
            "\n",
            "Closest Distance: 0.03095570453977986\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: Find the average waste generation for chemicals with a carbon footprint above 800.\n",
            "SCHEMA: CREATE TABLE waste_generation (id INT PRIMARY KEY, chemical_id INT, waste_generation INT); INSERT INTO waste_generation (id, chemical_id, waste_generation) VALUES (1, 1, 900); CREATE TABLE environmental_impact (id INT PRIMARY KEY, chemical_id INT, carbon_footprint INT); INSERT INTO environmental_impact (id, chemical_id, carbon_footprint) VALUES (1, 1, 850);\n",
            "Original Answer: SELECT AVG(waste_generation) FROM waste_generation wg JOIN environmental_impact ei ON wg.chemical_id = ei.chemical_id WHERE ei.carbon_footprint > 800;\n",
            "Generated Answer: SELECT AVG(waste_generation) FROM waste_generation AS T1 JOIN environmental_impact AS T2 ON T1.chemical_id = T2.chemical_id WHERE T2.carbon_footprint > 800\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE waste_generation (id INT PRIMARY KEY, chemical_id INT, waste_generation INT); INSERT INTO waste_generation (id, chemical_id, waste_generation) VALUES (1, 1, 900); CREATE TABLE environmental_impact (id INT PRIMARY KEY, chemical_id INT, carbon_footprint INT); INSERT INTO environmental_impact (id, chemical_id, carbon_footprint) VALUES (1, 1, 850);\n",
            "Error creating table: relation \"waste_generation\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT AVG(waste_generation) FROM waste_generation wg JOIN environmental_impact ei ON wg.chemical_id = ei.chemical_id WHERE ei.carbon_footprint > 800;\n",
            "Database connected successfully\n",
            "Error executing query: relation \"environmental_impact\" does not exist\n",
            "LINE 1: ...G(waste_generation) FROM waste_generation wg JOIN environmen...\n",
            "                                                             ^\n",
            "\n",
            "\n",
            "\n",
            "Bad Query execution\n",
            "\n",
            "\n",
            "\n",
            "Evaluating sample: 9\n",
            "\n",
            "\n",
            "Closest Distance: 0.01911803228585384\n",
            "\n",
            "\n",
            "MATCH (Semantically Similar)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question: How many TV shows have the word 'News' in their title?\n",
            "SCHEMA: CREATE TABLE shows (id INT, title TEXT, genre TEXT); INSERT INTO shows (id, title, genre) VALUES (1, 'News Show1', 'News'), (2, 'Entertainment Show2', 'Entertainment'), (3, 'Breaking News Show3', 'News');\n",
            "Original Answer: SELECT COUNT(*) FROM shows WHERE title LIKE '%News%';\n",
            "Generated Answer: SELECT COUNT(*) FROM shows WHERE title LIKE '%News%'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCHEMA QUERY: CREATE TABLE shows (id INT, title TEXT, genre TEXT); INSERT INTO shows (id, title, genre) VALUES (1, 'News Show1', 'News'), (2, 'Entertainment Show2', 'Entertainment'), (3, 'Breaking News Show3', 'News');\n",
            "Error creating table: relation \"shows\" already exists\n",
            "\n",
            "\n",
            "\n",
            "Similar Query: SELECT COUNT(*) FROM shows WHERE title LIKE '%News%';\n",
            "Database connected successfully\n",
            "\n",
            "\n",
            "Record(s): 1 \n",
            "\n",
            "(2,)\n",
            "\n",
            "\n",
            "Good Query execution\n",
            "\n",
            "\n",
            "\n",
            "Match Accuracy: 100.00%\n",
            "\n",
            "\n",
            "Query Successes: 80.00%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}