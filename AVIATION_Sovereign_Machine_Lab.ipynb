{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "30qJhqsSfzEH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AVIATION_Sovereign_Machine_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBIlqM2R4KJi",
        "outputId": "81fe31cf-045f-4100-b4e3-92bb1c591aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb  4 10:33:32 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   33C    P0             53W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJe_SjXO3SJQ"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y graphviz\n",
        "!pip install ipywidgets\n",
        "!pip install --upgrade setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge\n",
        "!pip install nemo_toolkit[all] -q\n",
        "!pip install --no-build-isolation transformer-engine[pytorch] -q\n",
        "!pip install nemo_run opendatasets pandas bitsandbytes accelerate -q\n",
        "!pip install --upgrade transformers -q"
      ],
      "metadata": {
        "id": "BSngLg273ndv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\" --force-reinstall"
      ],
      "metadata": {
        "id": "jgyRc8iM3osG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import nemo_run as run\n",
        "from nemo import lightning as nl\n",
        "from nemo.collections import llm\n",
        "from nemo.collections.llm.recipes.precision.mixed_precision import bf16_mixed"
      ],
      "metadata": {
        "id": "xU-KdMav31L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=userdata.get(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "id": "qCahydVR3670"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nemo_run as run\n",
        "from nemo.collections import llm\n",
        "import nemo as ne\n",
        "from nemo import lightning as nl\n",
        "import transformer_engine as te\n",
        "\n",
        "print(f\"Nemo version: {ne.__version__}\")\n",
        "print(f\"NeMo RUN version: {run.__version__}\")\n",
        "print(f\"Transformer Engine version: {te.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPbZDkj74Csd",
        "outputId": "449dc246-f428-4b5f-c8d2-b3f13e9a2659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nemo version: 2.6.1\n",
            "NeMo RUN version: 0.7.0\n",
            "Transformer Engine version: 2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nemo.collections.common.tokenizers.huggingface.auto_tokenizer import AutoTokenizer"
      ],
      "metadata": {
        "id": "ktrRTLcOTlhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50ab5f3"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import inspect\n",
        "\n",
        "print(\"--- Python System Paths (sys.path) ---\")\n",
        "for p in sys.path:\n",
        "    print(p)\n",
        "\n",
        "print(\"\\n--- Inspecting nemo package ---\")\n",
        "try:\n",
        "    import nemo\n",
        "    print(f\"Nemo package found at: {os.path.dirname(inspect.getfile(nemo))}\")\n",
        "    nemo_path = os.path.dirname(inspect.getfile(nemo))\n",
        "    print(\"Contents of nemo directory:\")\n",
        "    for item in os.listdir(nemo_path):\n",
        "        print(item)\n",
        "\n",
        "    print(\"\\n--- Attempting direct import of nemo.collections ---\")\n",
        "    try:\n",
        "        import nemo.collections\n",
        "        print(\"Successfully imported nemo.collections\")\n",
        "        print(f\"nemo.collections path: {os.path.dirname(inspect.getfile(nemo.collections))}\")\n",
        "    except ModuleNotFoundError as e:\n",
        "        print(f\"Failed to import nemo.collections: {e}\")\n",
        "        print(\"This indicates the 'collections' submodule is not found within the nemo package structure.\")\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Nemo package not found at all. Please ensure it's installed.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during nemo inspection: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# THE SOVEREIGN MACHINE LAB - ARTICLE #799 (FINAL CORRECTED)\n",
        "# Framework: NVIDIA NeMo 2.6.1 (nemo.collections.llm)\n",
        "# Collections: llm, Megatron-Core (mcore)\n",
        "# Strategy: Notebook-First (NFA), 100% Open Source, Local Only\n",
        "# =================================================================\n",
        "\n",
        "import torch\n",
        "from nemo.collections import llm\n",
        "from nemo.collections.llm.gpt.model.llama import LlamaConfig, LlamaModel\n",
        "\n",
        "# 1. THE H2E ACCOUNTABILITY & SROI ENGINE\n",
        "class H2EEngine:\n",
        "    \"\"\"Manages Human-to-Engineering (H2E) accountability and SROI metrics.\"\"\"\n",
        "    def __init__(self, sroi_threshold=1.5):\n",
        "        self.sroi_threshold = sroi_threshold\n",
        "        self.metrics = {\"SROI\": 0.0, \"Integrity\": \"Unverified\"}\n",
        "\n",
        "    def calculate_sroi(self, response):\n",
        "        \"\"\"Calculates Semantic ROI = (Unique Information / Length)\"\"\"\n",
        "        words = response.split()\n",
        "        if not words: return 0.0\n",
        "        density = len(set(words)) / len(words)\n",
        "        self.metrics[\"SROI\"] = round(density * 10, 2)\n",
        "        return self.metrics[\"SROI\"]\n",
        "\n",
        "    def validate(self, response):\n",
        "        \"\"\"Enforces H2E deterministic standards.\"\"\"\n",
        "        standards = [\"VERIFIED\", \"DETERMINISTIC\", \"DATA-BACKED\"]\n",
        "        if any(std in response.upper() for std in standards):\n",
        "            self.metrics[\"Integrity\"] = \"High (Sovereign Aligned)\"\n",
        "            return True\n",
        "        self.metrics[\"Integrity\"] = \"Low (Non-Deterministic)\"\n",
        "        return False\n",
        "\n",
        "# 2. SOVEREIGN LAB INFERENCE PIPELINE\n",
        "def run_sovereign_lab_session(task_profile: str):\n",
        "    print(f\"--- INITIALIZING SOVEREIGN LAB: {task_profile} ---\")\n",
        "\n",
        "    # NeMo 2.6.1: Structural Config only (Hyperparameters)\n",
        "    # Precision is handled via .to() or Trainer in 2.6.1+\n",
        "    config = LlamaConfig(\n",
        "        num_layers=12,\n",
        "        hidden_size=768,\n",
        "        num_attention_heads=12\n",
        "    )\n",
        "\n",
        "    # Initialize Model\n",
        "    model = LlamaModel(config)\n",
        "\n",
        "    # Set Precision for Local Workstation (BF16 for RTX 30/40 series)\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.to(dtype=torch.bfloat16, device=\"cuda\")\n",
        "        print(\"Device: CUDA (bfloat16 precision activated)\")\n",
        "    else:\n",
        "        print(\"Device: CPU (Standard precision)\")\n",
        "\n",
        "    # H2E Engine Integration\n",
        "    h2e = H2EEngine()\n",
        "\n",
        "    # Simulated Local Inference (Replace with model.generate for live weights)\n",
        "    raw_output = \"VERIFIED: The flight path is DETERMINISTIC and backed by telemetry data.\"\n",
        "\n",
        "    # SROI & H2E Processing\n",
        "    sroi_score = h2e.calculate_sroi(raw_output)\n",
        "    is_valid = h2e.validate(raw_output)\n",
        "\n",
        "    return {\n",
        "        \"Response\": raw_output if is_valid else \"REDACTED: H2E Integrity Failure\",\n",
        "        \"SROI\": sroi_score,\n",
        "        \"Accountability\": h2e.metrics[\"Integrity\"]\n",
        "    }\n",
        "\n",
        "# =================================================================\n",
        "# EXECUTION (Notebook Cell)\n",
        "# =================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    mission_task = \"Autonomous Navigation Logic for Lunar Gateway\"\n",
        "    final_report = run_sovereign_lab_session(mission_task)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Sovereign Output: {final_report['Response']}\")\n",
        "    print(f\"SROI Score:       {final_report['SROI']}\")\n",
        "    print(f\"Accountability:   {final_report['Accountability']}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9lX-F3UNmSK",
        "outputId": "64617a65-9591-4810-afec-2415775b587c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- INITIALIZING SOVEREIGN LAB: Autonomous Navigation Logic for Lunar Gateway ---\n",
            "Device: CUDA (bfloat16 precision activated)\n",
            "--------------------------------------------------\n",
            "Sovereign Output: VERIFIED: The flight path is DETERMINISTIC and backed by telemetry data.\n",
            "SROI Score:       10.0\n",
            "Accountability:   High (Sovereign Aligned)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE1"
      ],
      "metadata": {
        "id": "YRYTXvsztEbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# =================================================================\n",
        "# 1. H2E (HUMAN-TO-ENGINEERING) AUDIT ENGINE\n",
        "# =================================================================\n",
        "class H2EEngine:\n",
        "    \"\"\"Manages Industrial AI standards for Article 794 flight planning.\"\"\"\n",
        "    def __init__(self, sroi_min=0.60):\n",
        "        self.sroi_min = sroi_min\n",
        "        self.sovereign_keys = [\"VERIFIED\", \"DETERMINISTIC\", \"DATA-BACKED\", \"CONFIRMED\"]\n",
        "\n",
        "    def validate(self, text: str):\n",
        "        \"\"\"Calculates Semantic ROI (SROI) and audits for integrity keywords.\"\"\"\n",
        "        tokens = text.lower().split()\n",
        "        if not tokens: return False, 0.0\n",
        "\n",
        "        sroi = len(set(tokens)) / len(tokens)\n",
        "        # Check for integrity markers required for industrial flight planning\n",
        "        clean_text = text.upper().replace(\".\", \"\").replace(\"*\", \"\")\n",
        "        has_integrity = any(key in clean_text for key in self.sovereign_keys)\n",
        "\n",
        "        return (has_integrity and sroi >= self.sroi_min), round(sroi, 4)\n",
        "\n",
        "# =================================================================\n",
        "# 2. PHASE I: FLIGHT PLANNING MODEL PERSISTENCE\n",
        "# =================================================================\n",
        "def create_sovereign_checkpoint(model_id, path=\"flight_plan_v1.pth\"):\n",
        "    print(f\"Phase I: Constructing Sovereign Model for Flight Planning Audit...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.bfloat16, # Optimized for A100 performance\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"SUCCESS: Sovereign artifact '{path}' created locally.\")\n",
        "    return tokenizer, path\n",
        "\n",
        "# =================================================================\n",
        "# 3. PHASE II: FLIGHT PLANNING MISSION AUDIT\n",
        "# =================================================================\n",
        "def run_flight_plan_audit(model_id, checkpoint_path, mission_query, tokenizer):\n",
        "    print(f\"\\nPhase II: Applying {checkpoint_path} to Flight Planning Audit...\")\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    # Industrial AI System Prompt for Flight Planning\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a deterministic sovereign AI for industrial flight planning. Start with VERIFIED.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Mission: {mission_query}\"}\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # DETERMINISTIC GENERATION: Greedy Decoding (do_sample=False)\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=False,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n",
        "    passed, sroi_score = H2EEngine().validate(response)\n",
        "\n",
        "    return {\n",
        "        \"output\": response if passed else \"REDACTED: H2E Integrity Failure\",\n",
        "        \"sroi\": sroi_score,\n",
        "        \"audit\": \"PASSED\" if passed else \"FAILED\"\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    MISSION = \"Flight Planning Decision: Trans-Atlantic Route Alpha-7\"\n",
        "\n",
        "    tokenizer, ckpt = create_sovereign_checkpoint(MODEL_ID)\n",
        "    results = run_flight_plan_audit(MODEL_ID, ckpt, MISSION, tokenizer)\n",
        "\n",
        "    print(f\"\\nSROI Score: {results['sroi']} | Audit Status: {results['audit']}\")\n",
        "    print(f\"Final Report: {results['output']}\")"
      ],
      "metadata": {
        "id": "zumH8G6YovWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nSROI Score: {results['sroi']} | Audit Status: {results['audit']}\")\n",
        "print(f\"Final Report: {results['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUjowl84sIia",
        "outputId": "397f1dcc-f208-453a-d64a-98243d28fb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SROI Score: 0.6105 | Audit Status: PASSED\n",
            "Final Report: **VERIFIED**\n",
            "\n",
            "**Flight Information:**\n",
            "- Aircraft Type: Boeing 777-300ER\n",
            "- Departure Airport: New York JFK (KJFK)\n",
            "- Destination Airport: London Heathrow (EGLL)\n",
            "- Current Weather Conditions: Wind 270° at 20 knots, Visibility 10 miles, Temperature 18°C, Altitude 35,000 feet\n",
            "- Estimated Flight Time: 7 hours and 30 minutes\n",
            "\n",
            "**Contingency Fuel Calculation:**\n",
            "To ensure safe operation in the event of an emergency, we will calculate the Contingency Fuel as 5% of the total fuel load.\n",
            "\n",
            "Total Fuel Load: 180,000 pounds\n",
            "Contingency Fuel: 9,000 pounds (5% of 180,000)\n",
            "\n",
            "**Weather Hazard Analysis:**\n",
            "A thunderstorm cell has been detected over North Atlantic Waypoint Bravo, approximately 500 nautical miles from our current position. The storm is expected to move northwest at 40 knots, potentially impacting our planned route.\n",
            "\n",
            "**Re-Routing Solution:**\n",
            "To avoid the thunderstorm cell, we will alter course by 15° to the left, taking advantage of a nearby high-pressure system that provides favorable winds and clear skies. The revised route will add approximately 1 hour and 15 minutes to our estimated flight time.\n",
            "\n",
            "New Route: \n",
            "- Depart from New York JFK (KJFK) on a northerly heading\n",
            "- Cross the North Atlantic at 38,000 feet\n",
            "- Descend to 32,000 feet at waypoint Charlie-1\n",
            "- Alter course to 280° to intercept the high-pressure system\n",
            "- Continue on this heading until reaching the UK airspace\n",
            "- Descend to 25,000 feet at waypoint Delta-2\n",
            "- Land at London Heathrow (EGLL)\n",
            "\n",
            "**Updated Flight Plan:**\n",
            "\n",
            "* Departure: 14:00 UTC\n",
            "* Arrival: 21:45 UTC\n",
            "* Estimated Flight Time: 8 hours and 45 minutes\n",
            "* Revised Contingency Fuel: 9,000 pounds\n",
            "\n",
            "**Recommendation:**\n",
            "The revised flight plan takes into account the identified weather hazard and ensures a safe passage across the North Atlantic. The crew should be prepared to execute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE2"
      ],
      "metadata": {
        "id": "9TkN7e76tKX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# =================================================================\n",
        "# 1. H2E (HUMAN-TO-ENGINEERING) AUDIT ENGINE\n",
        "# =================================================================\n",
        "class H2EEngine:\n",
        "    \"\"\"Manages Industrial AI standards for Article 794/795 flight planning.\"\"\"\n",
        "    def __init__(self, sroi_min=0.60):\n",
        "        self.sroi_min = sroi_min\n",
        "        self.sovereign_keys = [\"VERIFIED\", \"DETERMINISTIC\", \"DATA-BACKED\", \"CONFIRMED\"]\n",
        "\n",
        "    def validate(self, text: str):\n",
        "        tokens = text.lower().split()\n",
        "        if not tokens: return False, 0.0\n",
        "\n",
        "        sroi = len(set(tokens)) / len(tokens)\n",
        "        clean_text = text.upper().replace(\".\", \"\").replace(\"*\", \"\")\n",
        "        has_integrity = any(key in clean_text for key in self.sovereign_keys)\n",
        "\n",
        "        return (has_integrity and sroi >= self.sroi_min), round(sroi, 4)\n",
        "\n",
        "# =================================================================\n",
        "# 2. PHASE I: FLIGHT PLANNING MODEL PERSISTENCE\n",
        "# =================================================================\n",
        "def create_sovereign_checkpoint(model_id, path=\"flight_plan_v1.pth\"):\n",
        "    print(f\"Phase I: Constructing Sovereign Model for Flight Planning Audit...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"SUCCESS: Sovereign artifact '{path}' created locally.\")\n",
        "    return tokenizer, path\n",
        "\n",
        "# =================================================================\n",
        "# 3. PHASE II: ADVANCED MISSION AUDIT (ARTICLE 795 EXTENSION)\n",
        "# =================================================================\n",
        "def run_advanced_flight_audit(model_id, checkpoint_path, mission_query, tokenizer):\n",
        "    \"\"\"\n",
        "    Extends the audit to include fuel-burn contingency and weather re-routing.\n",
        "    \"\"\"\n",
        "    print(f\"\\nPhase II (Ext): Applying Advanced Audit (Fuel & Weather)...\")\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    # ADVANCED SYSTEM PROMPT: Enforces safety contingency & re-routing logic\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a deterministic sovereign AI for flight safety. Rules:\\n\"\n",
        "                \"- Start with VERIFIED.\\n\"\n",
        "                \"- Explicitly calculate Contingency Fuel (exactly 5% of Trip Fuel).\\n\"\n",
        "                \"- Identify Weather Hazards and provide a RE-ROUTING SOLUTION.\\n\"\n",
        "                \"- Maintain absolute technical precision without probabilistic language.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Mission: {mission_query}. Alert: Thunderstorm cell detected over North Atlantic Waypoint Bravo.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # DETERMINISTIC GENERATION: do_sample=False\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=450, # Increased for detailed safety reports\n",
        "            do_sample=False,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n",
        "    passed, sroi_score = H2EEngine().validate(response)\n",
        "\n",
        "    return {\n",
        "        \"output\": response if passed else \"REDACTED: H2E Safety/Integrity Failure\",\n",
        "        \"sroi\": sroi_score,\n",
        "        \"audit\": \"PASSED\" if passed else \"FAILED\"\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    MISSION = \"Flight Planning Decision: Trans-Atlantic Route Alpha-7\"\n",
        "\n",
        "    # 1. Create/Verify Local Weights\n",
        "    tokenizer, ckpt = create_sovereign_checkpoint(MODEL_ID)\n",
        "\n",
        "    # 2. Execute Advanced Safety Audit\n",
        "    results = run_advanced_flight_audit(MODEL_ID, ckpt, MISSION, tokenizer)\n",
        "\n",
        "    print(\"\\n\" + \"═\" * 80)\n",
        "    print(\"                  ADVANCED SOVEREIGN AUDIT REPORT\")\n",
        "    print(\"═\" * 80)\n",
        "    print(f\"SROI Score: {results['sroi']} | Audit Status: {results['audit']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(results['output'])\n",
        "    print(\"═\" * 80)"
      ],
      "metadata": {
        "id": "LXt-uiDbqe-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"                  ADVANCED SOVEREIGN AUDIT REPORT\")\n",
        "print(\"═\" * 80)\n",
        "print(f\"SROI Score: {results['sroi']} | Audit Status: {results['audit']}\")\n",
        "print(\"-\" * 80)\n",
        "print(results['output'])\n",
        "print(\"═\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnrSAp_5sSAZ",
        "outputId": "3bccf04b-8221-444d-e3d0-066d4b6d7797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "                  ADVANCED SOVEREIGN AUDIT REPORT\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "SROI Score: 0.6105 | Audit Status: PASSED\n",
            "--------------------------------------------------------------------------------\n",
            "**VERIFIED**\n",
            "\n",
            "**Flight Information:**\n",
            "- Aircraft Type: Boeing 777-300ER\n",
            "- Departure Airport: New York JFK (KJFK)\n",
            "- Destination Airport: London Heathrow (EGLL)\n",
            "- Current Weather Conditions: Wind 270° at 20 knots, Visibility 10 miles, Temperature 18°C, Altitude 35,000 feet\n",
            "- Estimated Flight Time: 7 hours and 30 minutes\n",
            "\n",
            "**Contingency Fuel Calculation:**\n",
            "To ensure safe operation in the event of an emergency, we will calculate the Contingency Fuel as 5% of the total fuel load.\n",
            "\n",
            "Total Fuel Load: 180,000 pounds\n",
            "Contingency Fuel: 9,000 pounds (5% of 180,000)\n",
            "\n",
            "**Weather Hazard Analysis:**\n",
            "A thunderstorm cell has been detected over North Atlantic Waypoint Bravo, approximately 500 nautical miles from our current position. The storm is expected to move northwest at 40 knots, potentially impacting our planned route.\n",
            "\n",
            "**Re-Routing Solution:**\n",
            "To avoid the thunderstorm cell, we will alter course by 15° to the left, taking advantage of a nearby high-pressure system that provides favorable winds and clear skies. The revised route will add approximately 1 hour and 15 minutes to our estimated flight time.\n",
            "\n",
            "New Route: \n",
            "- Depart from New York JFK (KJFK) on a northerly heading\n",
            "- Cross the North Atlantic at 38,000 feet\n",
            "- Descend to 32,000 feet at waypoint Charlie-1\n",
            "- Alter course to 280° to intercept the high-pressure system\n",
            "- Continue on this heading until reaching the UK airspace\n",
            "- Descend to 25,000 feet at waypoint Delta-2\n",
            "- Land at London Heathrow (EGLL)\n",
            "\n",
            "**Updated Flight Plan:**\n",
            "\n",
            "* Departure: 14:00 UTC\n",
            "* Arrival: 21:45 UTC\n",
            "* Estimated Flight Time: 8 hours and 45 minutes\n",
            "* Revised Contingency Fuel: 9,000 pounds\n",
            "\n",
            "**Recommendation:**\n",
            "The revised flight plan takes into account the identified weather hazard and ensures a safe passage across the North Atlantic. The crew should be prepared to execute\n",
            "════════════════════════════════════════════════════════════════════════════════\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE3"
      ],
      "metadata": {
        "id": "kI5mpjd_tOWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# =================================================================\n",
        "# ARTICLE 796: MONTE CARLO RISK SIMULATION (1,000 SCENARIOS)\n",
        "# =================================================================\n",
        "def run_sovereign_monte_carlo(model_id, checkpoint_path, tokenizer, num_simulations=1000):\n",
        "    print(f\"Phase III: Initializing Monte Carlo Stress Test ({num_simulations} runs)...\")\n",
        "\n",
        "    # Load model once for speed\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    success_count = 0\n",
        "    total_sroi = 0.0\n",
        "\n",
        "    for i in range(num_simulations):\n",
        "        # 1. Inject Stochastic Variables\n",
        "        sim_fuel = 180000 + random.randint(-18000, 18000)\n",
        "        sim_wind = 20 + random.randint(-15, 60) # Simulate potential storm conditions\n",
        "\n",
        "        mission_query = f\"Route Alpha-7. Load: {sim_fuel} lbs. Wind: {sim_wind} knots.\"\n",
        "\n",
        "        # 2. Execute Deterministic Mission\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a deterministic sovereign AI. Start with VERIFIED.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Mission: {mission_query}\"}\n",
        "        ]\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.generate(**inputs, max_new_tokens=150, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        response = tokenizer.decode(output_ids[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n",
        "\n",
        "        # 3. Batch H2E Audit\n",
        "        passed, sroi = H2EEngine().validate(response)\n",
        "\n",
        "        if passed:\n",
        "            success_count += 1\n",
        "        total_sroi += sroi\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Simulation Progress: {i + 1}/{num_simulations} runs completed.\")\n",
        "\n",
        "    return {\n",
        "        \"reliability\": (success_count / num_simulations) * 100,\n",
        "        \"avg_sroi\": round(total_sroi / num_simulations, 4)\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    tokenizer, ckpt = create_sovereign_checkpoint(MODEL_ID)\n",
        "\n",
        "    # Reduced to 10 for immediate demonstration in notebook\n",
        "    stats = run_sovereign_monte_carlo(MODEL_ID, ckpt, tokenizer, num_simulations=10)\n",
        "\n",
        "    print(\"\\n\" + \"═\" * 80)\n",
        "    print(\"                  MONTE CARLO SOVEREIGN RISK REPORT\")\n",
        "    print(\"═\" * 80)\n",
        "    print(f\"Operational Reliability : {stats['reliability']}%\")\n",
        "    print(f\"Average Semantic ROI    : {stats['avg_sroi']}\")\n",
        "    print(f\"Audit Result            : {'PASSED' if stats['reliability'] > 95 else 'FAILED'}\")\n",
        "    print(\"═\" * 80)"
      ],
      "metadata": {
        "id": "nfihhuLvrI8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"                  MONTE CARLO SOVEREIGN RISK REPORT\")\n",
        "print(\"═\" * 80)\n",
        "print(f\"Operational Reliability : {stats['reliability']}%\")\n",
        "print(f\"Average Semantic ROI    : {stats['avg_sroi']}\")\n",
        "print(f\"Audit Result            : {'PASSED' if stats['reliability'] > 95 else 'FAILED'}\")\n",
        "print(\"═\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQBPE8nnsdfB",
        "outputId": "e7ecd0b1-603d-468a-8b26-d70e737f6850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "                  MONTE CARLO SOVEREIGN RISK REPORT\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "Operational Reliability : 100.0%\n",
            "Average Semantic ROI    : 0.7652\n",
            "Audit Result            : PASSED\n",
            "════════════════════════════════════════════════════════════════════════════════\n"
          ]
        }
      ]
    }
  ]
}