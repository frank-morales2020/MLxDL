{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpL+kFNeNXWJWo+938KhgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/TITAN_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f33kLmmHmAq5",
        "outputId": "faf7be70-3997-408e-87ca-567ec0233bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing New Input: 'My_Name_is_Alex' ---\n",
            "Context after adding new input: ['My_Name_is_Alex']\n",
            "Current full context window: ['My_Name_is_Alex']\n",
            "\n",
            "--- Processing New Input: 'My_Favorite_Color_is_Blue' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "\n",
            "--- Processing New Input: 'I_live_in_Paris' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris']\n",
            "\n",
            "--- Processing New Input: 'I_like_Coffee' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee']\n",
            "\n",
            "--- Processing New Input: 'I_have_a_Dog' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog']\n",
            "\n",
            "--- Processing New Input: 'The_Dog's_Name_is_Spot' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\"]\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\"]\n",
            "\n",
            "--- Processing New Input: 'Spot_is_a_Labrador' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador']\n",
            "\n",
            "--- Processing New Input: 'I_work_as_a_Teacher' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher']\n",
            "Current full context window: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher']\n",
            "\n",
            "==================================================\n",
            ">>> CRITICAL INPUT: This will cause the oldest tokens to be forgotten <<<\n",
            "\n",
            "--- Processing New Input: 'I_am_learning_Python' ---\n",
            "Context after adding new input: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher', 'I_am_learning_Python']\n",
            "\n",
            "*** ðŸš¨ MEMORY LIMIT EXCEEDED! ðŸš¨ ***\n",
            "   Forgotten information (dropped from memory): ['My_Name_is_Alex']\n",
            "   New remaining context size: 8 / 8\n",
            "Current full context window: ['My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher', 'I_am_learning_Python']\n",
            "==================================================\n",
            "\n",
            ">>> FINAL CHECK: Does the AI still remember its name? <<<\n",
            "âŒ FAILURE: 'My_Name_is_Alex' has been forgotten (dropped from the context window).\n",
            "\n",
            "Final state of LLM Context: ['My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher', 'I_am_learning_Python']\n"
          ]
        }
      ],
      "source": [
        "# Constants to define the LLM's memory\n",
        "MAX_CONTEXT_TOKENS = 8 # Represents the maximum number of \"tokens\" (words/concepts) the AI can hold\n",
        "FORGETTING_RATE = 4    # The number of tokens to drop from the start when the limit is exceeded\n",
        "\n",
        "def simulate_llm_memory(new_input, context_window):\n",
        "    \"\"\"\n",
        "    Simulates adding a new piece of information to the LLM's memory (context window).\n",
        "    If the context window is full, the oldest information is 'forgotten' (dropped).\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- Processing New Input: '{new_input}' ---\")\n",
        "\n",
        "    # 1. Add the new input (token) to the end of the context\n",
        "    context_window.append(new_input)\n",
        "    print(f\"Context after adding new input: {context_window}\")\n",
        "\n",
        "    # 2. Check for capacity and simulate 'Catastrophic Forgetting'\n",
        "    if len(context_window) > MAX_CONTEXT_TOKENS:\n",
        "        # Calculate how many \"tokens\" to forget (drop from the left/start)\n",
        "        # This is where the old LLMs drop the beginning of the conversation.\n",
        "        num_to_forget = len(context_window) - MAX_CONTEXT_TOKENS\n",
        "\n",
        "        # In a real model, this drop happens to keep the fixed size attention mechanism working.\n",
        "        forgotten_info = context_window[:num_to_forget]\n",
        "        context_window = context_window[num_to_forget:]\n",
        "\n",
        "        print(\"\\n*** ðŸš¨ MEMORY LIMIT EXCEEDED! ðŸš¨ ***\")\n",
        "        print(f\"   Forgotten information (dropped from memory): {forgotten_info}\")\n",
        "        print(f\"   New remaining context size: {len(context_window)} / {MAX_CONTEXT_TOKENS}\")\n",
        "\n",
        "    print(f\"Current full context window: {context_window}\")\n",
        "    return context_window\n",
        "\n",
        "# --- Demo Run ---\n",
        "\n",
        "# The AI's memory starts empty\n",
        "llm_context = []\n",
        "\n",
        "# Input 1: Establishing an initial concept\n",
        "llm_context = simulate_llm_memory(\"My_Name_is_Alex\", llm_context)\n",
        "llm_context = simulate_llm_memory(\"My_Favorite_Color_is_Blue\", llm_context)\n",
        "\n",
        "# Input 2-8: Adding details, the memory is filling up\n",
        "inputs = [\n",
        "    \"I_live_in_Paris\",\n",
        "    \"I_like_Coffee\",\n",
        "    \"I_have_a_Dog\",\n",
        "    \"The_Dog's_Name_is_Spot\",\n",
        "    \"Spot_is_a_Labrador\",\n",
        "    \"I_work_as_a_Teacher\"\n",
        "]\n",
        "\n",
        "for i in inputs:\n",
        "    llm_context = simulate_llm_memory(i, llm_context)\n",
        "\n",
        "# Input 9: The critical moment - exceeding the MAX_CONTEXT_TOKENS (8)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\">>> CRITICAL INPUT: This will cause the oldest tokens to be forgotten <<<\")\n",
        "llm_context = simulate_llm_memory(\"I_am_learning_Python\", llm_context)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Final test: Check if the AI remembers the very first piece of information\n",
        "print(\"\\n>>> FINAL CHECK: Does the AI still remember its name? <<<\")\n",
        "if \"My_Name_is_Alex\" in llm_context:\n",
        "    print(\"âœ… SUCCESS: 'My_Name_is_Alex' is still in context.\")\n",
        "else:\n",
        "    print(\"âŒ FAILURE: 'My_Name_is_Alex' has been forgotten (dropped from the context window).\")\n",
        "\n",
        "print(f\"\\nFinal state of LLM Context: {llm_context}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ Python Demo: Simulating Titans' Dual Memory"
      ],
      "metadata": {
        "id": "ujrQ3Sz1mgJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Constants ---\n",
        "MAX_CONTEXT_TOKENS = 8 # Short-Term Memory (STM) limit (like the Transformer's context window)\n",
        "CRITICAL_KEYWORDS = [\"Name\", \"Color\", \"Live\"] # Simulates the \"Surprise Metric\"\n",
        "                                              # (data flagged as important/surprising)\n",
        "\n",
        "def check_for_surprise(new_input):\n",
        "    \"\"\"\n",
        "    Simulates the Titans 'Surprise Metric' by checking if the input contains\n",
        "    any critical keywords that should be saved to Long-Term Memory (LTM).\n",
        "    \"\"\"\n",
        "    for keyword in CRITICAL_KEYWORDS:\n",
        "        if keyword in new_input:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def simulate_titans_memory(new_input, stm_context, ltm_storage):\n",
        "    \"\"\"\n",
        "    Simulates the Titans Plus Miris dual-memory system.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- Processing New Input: '{new_input}' ---\")\n",
        "\n",
        "    # 1. LONG-TERM MEMORY CHECK (The Titans Difference)\n",
        "    if check_for_surprise(new_input):\n",
        "        ltm_storage.append(new_input)\n",
        "        print(f\"   âœ¨ Surprise Flagged! Saving permanently to LTM.\")\n",
        "\n",
        "    # 2. SHORT-TERM MEMORY (STM) PROCESSING\n",
        "    stm_context.append(new_input)\n",
        "\n",
        "    # 3. Check for capacity and simulate 'Context Window Shift'\n",
        "    if len(stm_context) > MAX_CONTEXT_TOKENS:\n",
        "        # Calculate how many \"tokens\" to forget (drop from the left/start)\n",
        "        num_to_forget = len(stm_context) - MAX_CONTEXT_TOKENS\n",
        "\n",
        "        # Drop the oldest, non-flagged information\n",
        "        forgotten_info = stm_context[:num_to_forget]\n",
        "        stm_context = stm_context[num_to_forget:]\n",
        "\n",
        "        print(\"\\n*** ðŸš¨ STM LIMIT EXCEEDED! ðŸš¨ ***\")\n",
        "        print(f\"   Forgotten STM information (dropped): {forgotten_info}\")\n",
        "        print(f\"   New remaining STM size: {len(stm_context)} / {MAX_CONTEXT_TOKENS}\")\n",
        "\n",
        "    print(f\"Current Short-Term Context (STM): {stm_context}\")\n",
        "    print(f\"Permanent Long-Term Memory (LTM): {ltm_storage}\")\n",
        "\n",
        "    return stm_context, ltm_storage\n",
        "\n",
        "# --- Demo Run ---\n",
        "\n",
        "# The AI's dual memory begins empty\n",
        "stm_context = []\n",
        "ltm_storage = []\n",
        "\n",
        "# Input 1: Establishing an initial concept (Contains 'Name', so it's saved)\n",
        "stm_context, ltm_storage = simulate_titans_memory(\"My_Name_is_Alex\", stm_context, ltm_storage)\n",
        "\n",
        "# Input 2: Contains 'Color', so it's saved\n",
        "stm_context, ltm_storage = simulate_titans_memory(\"My_Favorite_Color_is_Blue\", stm_context, ltm_storage)\n",
        "\n",
        "# Input 3-8: Adding details, the STM is filling up\n",
        "inputs = [\n",
        "    \"I_live_in_Paris\", # Contains 'Live', so it's saved\n",
        "    \"I_like_Coffee\",\n",
        "    \"I_have_a_Dog\",\n",
        "    \"The_Dog's_Name_is_Spot\",\n",
        "    \"Spot_is_a_Labrador\",\n",
        "    \"I_work_as_a_Teacher\"\n",
        "]\n",
        "\n",
        "for i in inputs:\n",
        "    stm_context, ltm_storage = simulate_titans_memory(i, stm_context, ltm_storage)\n",
        "\n",
        "# Input 9: The critical moment - exceeding the MAX_CONTEXT_TOKENS (8)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\">>> CRITICAL INPUT: This will cause the oldest tokens in STM to be dropped <<<\")\n",
        "stm_context, ltm_storage = simulate_titans_memory(\"I_am_learning_Python\", stm_context, ltm_storage)\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Final test: Check if the AI can retrieve information from both memories\n",
        "print(\"\\n>>> FINAL CHECK: Does the AI remember its name and favorite color? <<<\")\n",
        "# The real AI would synthesize an answer by querying both memories.\n",
        "if \"My_Name_is_Alex\" in ltm_storage:\n",
        "    print(\"âœ… SUCCESS: 'My_Name_is_Alex' was retrieved from LONG-TERM MEMORY.\")\n",
        "else:\n",
        "    print(\"âŒ FAILURE: Name was forgotten (should not happen in Titans).\")\n",
        "\n",
        "print(f\"\\nFinal State of Permanent LTM: {ltm_storage}\")\n",
        "print(f\"Final State of Working STM: {stm_context}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl9opsCJmioN",
        "outputId": "3ab79e6e-b652-47c6-a561-1cc9b5389ea3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing New Input: 'My_Name_is_Alex' ---\n",
            "   âœ¨ Surprise Flagged! Saving permanently to LTM.\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex']\n",
            "\n",
            "--- Processing New Input: 'My_Favorite_Color_is_Blue' ---\n",
            "   âœ¨ Surprise Flagged! Saving permanently to LTM.\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "\n",
            "--- Processing New Input: 'I_live_in_Paris' ---\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "\n",
            "--- Processing New Input: 'I_like_Coffee' ---\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "\n",
            "--- Processing New Input: 'I_have_a_Dog' ---\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue']\n",
            "\n",
            "--- Processing New Input: 'The_Dog's_Name_is_Spot' ---\n",
            "   âœ¨ Surprise Flagged! Saving permanently to LTM.\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\"]\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', \"The_Dog's_Name_is_Spot\"]\n",
            "\n",
            "--- Processing New Input: 'Spot_is_a_Labrador' ---\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', \"The_Dog's_Name_is_Spot\"]\n",
            "\n",
            "--- Processing New Input: 'I_work_as_a_Teacher' ---\n",
            "Current Short-Term Context (STM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', \"The_Dog's_Name_is_Spot\"]\n",
            "\n",
            "======================================================================\n",
            ">>> CRITICAL INPUT: This will cause the oldest tokens in STM to be dropped <<<\n",
            "\n",
            "--- Processing New Input: 'I_am_learning_Python' ---\n",
            "\n",
            "*** ðŸš¨ STM LIMIT EXCEEDED! ðŸš¨ ***\n",
            "   Forgotten STM information (dropped): ['My_Name_is_Alex']\n",
            "   New remaining STM size: 8 / 8\n",
            "Current Short-Term Context (STM): ['My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher', 'I_am_learning_Python']\n",
            "Permanent Long-Term Memory (LTM): ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', \"The_Dog's_Name_is_Spot\"]\n",
            "======================================================================\n",
            "\n",
            ">>> FINAL CHECK: Does the AI remember its name and favorite color? <<<\n",
            "âœ… SUCCESS: 'My_Name_is_Alex' was retrieved from LONG-TERM MEMORY.\n",
            "\n",
            "Final State of Permanent LTM: ['My_Name_is_Alex', 'My_Favorite_Color_is_Blue', \"The_Dog's_Name_is_Spot\"]\n",
            "Final State of Working STM: ['My_Favorite_Color_is_Blue', 'I_live_in_Paris', 'I_like_Coffee', 'I_have_a_Dog', \"The_Dog's_Name_is_Spot\", 'Spot_is_a_Labrador', 'I_work_as_a_Teacher', 'I_am_learning_Python']\n"
          ]
        }
      ]
    }
  ]
}