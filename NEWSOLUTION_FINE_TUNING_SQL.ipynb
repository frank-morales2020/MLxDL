{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/NEWSOLUTION_FINE_TUNING_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC7dvZByG6uM"
      },
      "source": [
        "## Libraries Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9cqNuPkh_aG"
      },
      "outputs": [],
      "source": [
        "!pip install datasets networkx -q\n",
        "\n",
        "!pip install torch_geometric -q\n",
        "\n",
        "\n",
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 , L4  IN GOOGLE COLAB\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install mistral_inference -q\n",
        "\n",
        "!pip install trl==0.8.6 -q\n",
        "\n",
        "\n",
        "!pip install torch-geometric -q\n",
        "!pip install sqlparse networkx -q\n",
        "\n",
        "!pip install bitsandbytes -q\n",
        "\n",
        "\n",
        "#!pip uninstall -y torchvision -q\n",
        "!pip install torchvision --no-cache-dir -q\n",
        "#import evaluate\n",
        "\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8Ak2KGyrYOro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9277bd-3fbf-4dda-f69d-02808e348e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "from torch_geometric.nn import GAT\n",
        "\n",
        "from trl import setup_chat_format\n",
        "\n",
        "import colab_env\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsx_NaeSTP2j"
      },
      "source": [
        "## Original Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0DANV3Esq5w"
      },
      "source": [
        "https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Mistral_7B_Instruct_v0_1_for_text_to_SQL_EVALDATA.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsfmK0vECZ3C"
      },
      "source": [
        "* Import Main Components"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XPoZvJrBzyG",
        "outputId": "23f76be4-a48f-41f9-ec66-b8de514946fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 3168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/train_dataset.json\", split=\"train\")"
      ],
      "metadata": {
        "id": "p2XhxxLrsHB6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5f9f2c903a2d48dfaf0c83b1a79d5f5b",
            "48387adab0b54e02906ff27d32ecb65c",
            "8aaa348e65234ab0941b05cdafbc45e4",
            "903f0e871b7b407b80aab540248a6530",
            "1cdf68be93ff465a899589ac49998cf1",
            "d85510e7fa0849f4b0a824ed84992b22",
            "09a7396a73ab428b8246888119b2b038",
            "dea89770d0604e58973146bf2ca73a8f",
            "cac90c57b73049b6a1d1dd4d33516598",
            "f77c1ca9bf9e4f76bcd98e43c264c956",
            "3a3bbad5ec014c15a0ad07fc1972b12a"
          ]
        },
        "outputId": "02714bfb-8b13-4842-d210-8053938f1264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f9f2c903a2d48dfaf0c83b1a79d5f5b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]['messages'][0]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "VOG6LSjFL9Ng",
        "outputId": "7035f636-bcef-4c8d-a05b-a93248869fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_92 (total VARCHAR, finish VARCHAR)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]['messages'][1]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w7PmSu5hMEwE",
        "outputId": "52c4c47a-96a5-4723-c3f8-386e81e98727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How many times was the finish t32?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]['messages'][2]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zO_YHBbrtmrV",
        "outputId": "fa03244c-2c8a-4a4d-a316-b70f0d9eff10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT COUNT(total) FROM table_name_92 WHERE finish = \"t32\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0DfyorMy4TK",
        "outputId": "e2f91b0d-157b-448b-8274-3bbf59dde59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr9FHlz8EEds"
      },
      "source": [
        "* https://stackoverflow.com/questions/70950706/assertionerror-in-torch-geometric-nn-gatconv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolutely! Let's describe the dataflow in the provided code, breaking it down step-by-step:\n",
        "\n",
        "1. **Data Input and Preparation:**\n",
        "   - The process begins by loading the \"sql-create-context\" dataset, which presumably contains pairs of natural language questions and their corresponding SQL queries.\n",
        "   - The dataset is divided into three distinct subsets: training, validation, and testing.\n",
        "   - The Mistral-7B-Instruct-v0.3 language model and its tokenizer are loaded and prepared.\n",
        "\n",
        "2. **Data Transformation with `TextToSQLDataset`:**\n",
        "   - The `TextToSQLDataset` class is responsible for converting raw data into a format suitable for model training and evaluation.\n",
        "   - For each data sample, the following transformations occur:\n",
        "      - Tokenization: The input question and the SQL query (answer) are tokenized using the loaded tokenizer.\n",
        "      - Dependency Parsing: The question is parsed using spaCy to extract the grammatical relationships between words, generating a dependency graph.\n",
        "      - Dictionary Creation: A dictionary is created to store the tokenized input IDs, attention masks, labels (tokenized SQL query), and the dependency edges extracted from parsing.\n",
        "\n",
        "3. **Batching and Shuffling with `DataLoader`:**\n",
        "   - `DataLoader` takes the processed dataset from `TextToSQLDataset` and creates an iterable object for efficient batching.\n",
        "   - Optionally, shuffling is applied to randomize the order of samples within each epoch during training.\n",
        "\n",
        "4. **Forward Pass through `GraphModel`:**\n",
        "   - **Mistral Encoder:** The tokenized input IDs and attention masks are fed into the Mistral model's encoder to obtain contextualized token embeddings.\n",
        "   - **GATv2 Layer:** The GATv2 layer (Graph Attention Network) takes the token embeddings and the dependency edges as input. It applies graph attention mechanisms to incorporate the structural information from the dependency graph into the token representations.\n",
        "   - **Pooling:** The node representations (output of GATv2) are aggregated using a pooling operation (e.g., mean pooling) to obtain a fixed-size representation of the entire input sequence.\n",
        "   - **LM Head:** The pooled representation is passed through a linear layer, which produces logits – unnormalized probabilities for each token in the vocabulary.\n",
        "   - **Loss Calculation:** During training, if labels (correct SQL queries) are available, the cross-entropy loss is calculated between the predicted logits and the true labels. This loss guides the optimization of the model's parameters.\n",
        "\n",
        "5. **Model Optimization with PEFT (LoRA):**\n",
        "   - The `GraphModel` is wrapped with PEFT's LoRA (Low-Rank Adaptation) configuration to enable parameter-efficient fine-tuning.\n",
        "   - During training, only the parameters of the GATv2 layer and the LM head are updated, while the rest of the model parameters remain frozen.\n",
        "   - The Hugging Face Trainer manages the training process, iterating over the dataset, computing gradients, and updating the model's parameters based on the calculated loss.\n",
        "\n",
        "6. **Evaluation:**\n",
        "   - After (or during) training, the model is evaluated on the validation and test sets.\n",
        "   - The `compute_metrics` function decodes the predicted logits and labels back into text and assesses the model's performance using two metrics:\n",
        "      - Semantic Similarity: This metric measures how semantically close the predicted SQL query is to the reference SQL query using SentenceTransformer embeddings.\n",
        "      - Exact Match: This metric checks if the predicted SQL query matches the reference SQL query exactly.\n",
        "\n",
        "7. **Output:**\n",
        "    - The final output is the evaluation results, including semantic similarity and exact match scores, which provide insights into the model's ability to generate accurate SQL queries from natural language questions.\n",
        "\n",
        "Let me know if you have any further questions or would like clarification on any of the steps!\n"
      ],
      "metadata": {
        "id": "QFVMbILY2AeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're absolutely right! I apologize for the error in the previous diagram. The arrow direction was indeed incorrect.\n",
        "\n",
        "Here's the corrected graphical representation of the dataflow, with the arrow pointing *into* the `Trainer`:\n",
        "\n",
        "```\n",
        "+-------------------+          +----------------------+\n",
        "| Dataset Loading   |          | TextToSQLDataset     |\n",
        "|  - sql-create...  | -------> | - Tokenization       |\n",
        "|  - Split: train...|          | - Dependency Parsing |\n",
        "+-------------------+          | - Dict Creation      |\n",
        "                               +----------------------+\n",
        "                                         |\n",
        "                                         v\n",
        "                         +---------------------------+\n",
        "                         | DataLoader                |\n",
        "                         | - Batches, Shuffling (opt)|\n",
        "                         +---------------------------+\n",
        "                                         |\n",
        "                                         v\n",
        "                         +---------------------------+\n",
        "                         | GraphModel                |\n",
        "                         | - Mistral Encoder         |\n",
        "                         | - GATv2 Layer             |\n",
        "                         | - Pooling                 |\n",
        "                         | - LM Head                 |\n",
        "                         | - (Loss Calculation)      |\n",
        "                         +---------------------------+\n",
        "                                         |\n",
        "                                         v\n",
        "            +--------------+          +---------+         +-----------------+\n",
        "            | PEFT (LoRA)  | -------> | Trainer | <------ |Evaluation       |\n",
        "            +--------------+          |         |         |(compute_metrics)|\n",
        "                                      +---------+         +-----------------+\n",
        "                                         |\n",
        "                                         v\n",
        "                                   +-----------------------+\n",
        "                                   | - Semantic Similarity |\n",
        "                                   | - Exact Match         |\n",
        "                                   +-----------------------+\n",
        "```\n",
        "\n",
        "The revised dataflow now accurately shows that the evaluation metrics (semantic similarity and exact match) calculated by the `compute_metrics` function are used by the `Trainer` to assess the model's performance and make decisions during training (e.g., early stopping).\n",
        "\n",
        "Thank you for pointing out the error! I strive to be as accurate as possible in my responses.\n"
      ],
      "metadata": {
        "id": "cMZjJHj12Dnl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "41dafaf96ca84b2c955583ad1265b1a0",
            "938728b4f4964e5491bbf3b029c9e98c",
            "a19d77d1e2f4484d863ec62d4a603b18",
            "ae14bdb3176a42ba98aef20a8ecf9d27",
            "e731ddc82ecc499c9ab3a57737283e5b",
            "13b71a55ebf54ec6bfab6351a093b74f",
            "465bd94268f040fcbc1106cb768ae76f",
            "4ba537bc03cd44d4aab46bba3a074ab4",
            "d0b50569125d4ee5a9c21137e7193691",
            "594b58dfdaca430ba04271820bd5a4d2",
            "191d3dadbcc646e6b8aa97ed0c41afe1"
          ]
        },
        "id": "6horVfRxXtU8",
        "outputId": "ad26e8a3-c8a3-4802-b0ba-d6533e60785b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41dafaf96ca84b2c955583ad1265b1a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "PEFT-Model\n",
            "trainable params: 671,678,496 || all params: 8,389,636,130 || trainable%: 8.0061\n",
            "\n",
            "\n",
            "\n",
            "Iteration/Step: 0\n",
            "Sample ID: 17542\n",
            "Decoded Input: How many seasons took place in aspen, usa?\n",
            "Decoded Target (Labels): SELECT COUNT(season) FROM table_name_34 WHERE location = \"aspen, usa\"\n",
            "\n",
            "Iteration/Step: 0\n",
            "Sample ID: 21654\n",
            "Decoded Input: What is the Attendance number when the Opponent was purdue?\n",
            "Decoded Target (Labels): SELECT attendance FROM table_name_15 WHERE opponent_number = \"purdue\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2259' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2259/13000 1:17:50 < 6:10:25, 0.48 it/s, Epoch 0.17/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Iteration/Step: 1758\n",
            "Sample ID: 3815\n",
            "Decoded Input: How many points did the away team from Melbourne score?\n",
            "Decoded Target (Labels): SELECT away_team AS score FROM table_name_40 WHERE away_team = \"melbourne\"\n",
            "\n",
            "Iteration/Step: 1759\n",
            "Sample ID: 1133\n",
            "Decoded Input: What is the fire control for the sporter target\n",
            "Decoded Target (Labels): SELECT fire_control FROM table_12834315_2 WHERE name = \"Sporter Target\"\n",
            "\n",
            "Iteration/Step: 1759\n",
            "Sample ID: 19711\n",
            "Decoded Input: what is the total number of rank where viewers is 9.38?\n",
            "Decoded Target (Labels): SELECT COUNT(rank__timeslot_) FROM table_15681686_4 WHERE viewers__millions_ = \"9.38\"\n",
            "\n",
            "Iteration/Step: 1760\n",
            "Sample ID: 5566\n",
            "Decoded Input: What is the number of asts when rebs are larger than 1,189?\n",
            "Decoded Target (Labels): SELECT asts FROM table_name_76 WHERE rebs > 1 OFFSET 189\n",
            "\n",
            "Iteration/Step: 1760\n",
            "Sample ID: 17010\n",
            "Decoded Input: How many licenses have mind workstation software?\n",
            "Decoded Target (Labels): SELECT COUNT(license) FROM table_15038373_1 WHERE software = \"Mind WorkStation\"\n",
            "\n",
            "Iteration/Step: 1761\n",
            "Sample ID: 23937\n",
            "Decoded Input: What is the total number of episodes for クロサギ?\n",
            "Decoded Target (Labels): SELECT COUNT(episodes) FROM table_name_13 WHERE japanese_title = \"クロサギ\"\n",
            "\n",
            "Iteration/Step: 1761\n",
            "Sample ID: 3410\n",
            "Decoded Input: What opponent has December 6, 1964 as the date?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_40 WHERE date = \"december 6, 1964\"\n",
            "\n",
            "Iteration/Step: 1762\n",
            "Sample ID: 2064\n",
            "Decoded Input: In which Tournament was Mansour Bahrami Eric Winogradsky\n",
            "Decoded Target (Labels): SELECT tournament FROM table_name_9 WHERE opponent_in_final = \"mansour bahrami eric winogradsky\"\n",
            "\n",
            "Iteration/Step: 1762\n",
            "Sample ID: 10380\n",
            "Decoded Input: What is the total number of games for the opponent in Washington?\n",
            "Decoded Target (Labels): SELECT COUNT(game) FROM table_name_89 WHERE opponent = \"washington\"\n",
            "\n",
            "Iteration/Step: 1763\n",
            "Sample ID: 1640\n",
            "Decoded Input: how many bubbles with category being input\n",
            "Decoded Target (Labels): SELECT COUNT(bubbles) FROM table_1507852_5 WHERE category = \"Input\"\n",
            "\n",
            "Iteration/Step: 1763\n",
            "Sample ID: 3742\n",
            "Decoded Input: On which date is there a performance of more than 8.22.72?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_9 WHERE performance = \"8.22.72\"\n",
            "\n",
            "Iteration/Step: 1764\n",
            "Sample ID: 5595\n",
            "Decoded Input: What is the internet when the position is more than 13?\n",
            "Decoded Target (Labels): SELECT internet FROM table_name_12 WHERE position > 13\n",
            "\n",
            "Iteration/Step: 1764\n",
            "Sample ID: 21811\n",
            "Decoded Input: What is the name of episode number 29 in the series?\n",
            "Decoded Target (Labels): SELECT title FROM table_29273182_1 WHERE no_in_series = 29\n",
            "\n",
            "Iteration/Step: 1765\n",
            "Sample ID: 10299\n",
            "Decoded Input: With 10 as matches, and 469 runs, what is the strike rate?\n",
            "Decoded Target (Labels): SELECT strike_rate FROM table_name_24 WHERE matches = \"10\" AND runs = \"469\"\n",
            "\n",
            "Iteration/Step: 1765\n",
            "Sample ID: 3705\n",
            "Decoded Input: What is the sum of Round with a Pick that is 55?\n",
            "Decoded Target (Labels): SELECT SUM(round) FROM table_name_89 WHERE pick = 55\n",
            "\n",
            "Iteration/Step: 1766\n",
            "Sample ID: 18535\n",
            "Decoded Input: Which Oilers points have an Opponent of san francisco 49ers, and Opponents larger than 19?\n",
            "Decoded Target (Labels): SELECT MAX(oilers_points) FROM table_name_72 WHERE opponent = \"san francisco 49ers\" AND opponents > 19\n",
            "\n",
            "Iteration/Step: 1766\n",
            "Sample ID: 5792\n",
            "Decoded Input: How many students are there?\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM Student\n",
            "\n",
            "Iteration/Step: 1767\n",
            "Sample ID: 12415\n",
            "Decoded Input: When Status of five nations, and a Venue of twickenham , london, and a Opposing Teams of ireland are in?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_42 WHERE status = \"five nations\" AND venue = \"twickenham , london\" AND opposing_teams = \"ireland\"\n",
            "\n",
            "Iteration/Step: 1767\n",
            "Sample ID: 338\n",
            "Decoded Input: What is the Date of the Tournament with a Winning score of −9 (65-71-68-67=271)?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_55 WHERE winning_score = −9(65 - 71 - 68 - 67 = 271)\n",
            "\n",
            "Iteration/Step: 1768\n",
            "Sample ID: 11128\n",
            "Decoded Input: What is the Record for April 13?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_14 WHERE date = \"april 13\"\n",
            "\n",
            "Iteration/Step: 1768\n",
            "Sample ID: 14482\n",
            "Decoded Input: What is the earliest any of these players were born?\n",
            "Decoded Target (Labels): SELECT MIN(year_born) FROM table_12962773_10\n",
            "\n",
            "Iteration/Step: 1769\n",
            "Sample ID: 24971\n",
            "Decoded Input: Name the total number of top 10 with top 25 less than 2 and top 5 more than 0\n",
            "Decoded Target (Labels): SELECT COUNT(top_10) FROM table_name_75 WHERE top_25 < 2 AND top_5 > 0\n",
            "\n",
            "Iteration/Step: 1769\n",
            "Sample ID: 5846\n",
            "Decoded Input: Name the number of location attendance for april 24\n",
            "Decoded Target (Labels): SELECT COUNT(location_attendance) FROM table_17621978_11 WHERE date = \"April 24\"\n",
            "\n",
            "Iteration/Step: 1770\n",
            "Sample ID: 1305\n",
            "Decoded Input: What is the category when Hy Conrad nominated in 2003?\n",
            "Decoded Target (Labels): SELECT category FROM table_name_84 WHERE nominee_s_ = \"hy conrad\" AND year = 2003\n",
            "\n",
            "Iteration/Step: 1770\n",
            "Sample ID: 20825\n",
            "Decoded Input: Name the 2nd leg for team 1 of hamburg\n",
            "Decoded Target (Labels): SELECT 2 AS nd_leg FROM table_name_90 WHERE team_1 = \"hamburg\"\n",
            "\n",
            "Iteration/Step: 1771\n",
            "Sample ID: 4374\n",
            "Decoded Input: What was the latest season with a nick production number of 942?\n",
            "Decoded Target (Labels): SELECT MAX(season__number) FROM table_2655016_10 WHERE nick_prod__number = 942\n",
            "\n",
            "Iteration/Step: 1771\n",
            "Sample ID: 10400\n",
            "Decoded Input: How many races in 2012 season have 0 podiums?\n",
            "Decoded Target (Labels): SELECT COUNT(races) FROM table_23338693_1 WHERE season = 2012 AND podiums = 0\n",
            "\n",
            "Iteration/Step: 1772\n",
            "Sample ID: 12940\n",
            "Decoded Input: What pick number did the linebacker from the denver broncos get?\n",
            "Decoded Target (Labels): SELECT pick FROM table_name_34 WHERE position = \"linebacker\" AND team = \"denver broncos\"\n",
            "\n",
            "Iteration/Step: 1772\n",
            "Sample ID: 17939\n",
            "Decoded Input: Name the Nationality of södertälje sk?\n",
            "Decoded Target (Labels): SELECT nationality FROM table_name_78 WHERE team_from = \"södertälje sk\"\n",
            "\n",
            "Iteration/Step: 1773\n",
            "Sample ID: 25550\n",
            "Decoded Input: Which event had the opponent of shinya aoki and was at 4:56?\n",
            "Decoded Target (Labels): SELECT event FROM table_name_90 WHERE opponent = \"shinya aoki\" AND time = \"4:56\"\n",
            "\n",
            "Iteration/Step: 1773\n",
            "Sample ID: 23275\n",
            "Decoded Input: Where is the Eren Talu bidding project located?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_30 WHERE project = \"eren talu bidding project\"\n",
            "\n",
            "Iteration/Step: 1774\n",
            "Sample ID: 5840\n",
            "Decoded Input: How many lanes was Khadevis Robinson in for heats over 2?\n",
            "Decoded Target (Labels): SELECT COUNT(lane) FROM table_name_21 WHERE heat > 2 AND name = \"khadevis robinson\"\n",
            "\n",
            "Iteration/Step: 1774\n",
            "Sample ID: 14278\n",
            "Decoded Input: What is the average decile for te puru school?\n",
            "Decoded Target (Labels): SELECT AVG(decile) FROM table_name_84 WHERE name = \"te puru school\"\n",
            "\n",
            "Iteration/Step: 1775\n",
            "Sample ID: 3525\n",
            "Decoded Input: How many individuals watched the show that had a bbc ranking of 6?\n",
            "Decoded Target (Labels): SELECT COUNT(viewers) FROM table_24399615_10 WHERE bbc_three_weekly_ranking = \"6\"\n",
            "\n",
            "Iteration/Step: 1775\n",
            "Sample ID: 1493\n",
            "Decoded Input: What is the party for south carolina 3?\n",
            "Decoded Target (Labels): SELECT party FROM table_1342359_39 WHERE district = \"South Carolina 3\"\n",
            "\n",
            "Iteration/Step: 1776\n",
            "Sample ID: 2073\n",
            "Decoded Input: What is the method of the match with chris ade as the opponent?\n",
            "Decoded Target (Labels): SELECT method FROM table_name_70 WHERE opponent = \"chris ade\"\n",
            "\n",
            "Iteration/Step: 1776\n",
            "Sample ID: 9364\n",
            "Decoded Input: Which region had a release format of CD Maxi?\n",
            "Decoded Target (Labels): SELECT region FROM table_name_20 WHERE format = \"cd maxi\"\n",
            "\n",
            "Iteration/Step: 1777\n",
            "Sample ID: 23767\n",
            "Decoded Input: Which Round has an Event of 200 miles of norisring?\n",
            "Decoded Target (Labels): SELECT COUNT(round) FROM table_name_25 WHERE event = \"200 miles of norisring\"\n",
            "\n",
            "Iteration/Step: 1777\n",
            "Sample ID: 20684\n",
            "Decoded Input: What are the average rating and resolution of songs that are in Bangla?\n",
            "Decoded Target (Labels): SELECT AVG(rating), AVG(resolution) FROM song WHERE languages = \"bangla\"\n",
            "\n",
            "Iteration/Step: 1778\n",
            "Sample ID: 19672\n",
            "Decoded Input: Which Sydney has a Gold Coast of yes, an Adelaide of no, and an Auckland of yes?\n",
            "Decoded Target (Labels): SELECT sydney FROM table_name_13 WHERE gold_coast = \"yes\" AND adelaide = \"no\" AND auckland = \"yes\"\n",
            "\n",
            "Iteration/Step: 1778\n",
            "Sample ID: 8616\n",
            "Decoded Input: What Nature reserve number was established on 19961220 20.12.1996\n",
            "Decoded Target (Labels): SELECT MIN(nsg_nr) FROM table_26013618_1 WHERE date_established = \"19961220 20.12.1996\"\n",
            "\n",
            "Iteration/Step: 1779\n",
            "Sample ID: 18179\n",
            "Decoded Input: What was the final score of the Friendly Competition in Manama, Bahrain?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_48 WHERE venue = \"manama, bahrain\" AND competition = \"friendly\"\n",
            "\n",
            "Iteration/Step: 1779\n",
            "Sample ID: 5387\n",
            "Decoded Input: What did Carlton score when they were the Home team?\n",
            "Decoded Target (Labels): SELECT home_team AS score FROM table_name_73 WHERE home_team = \"carlton\"\n",
            "\n",
            "Iteration/Step: 1780\n",
            "Sample ID: 19729\n",
            "Decoded Input: In what round did the player who weights 192lb (87kg) play?\n",
            "Decoded Target (Labels): SELECT MAX(round) FROM table_20861261_4 WHERE weight = \"192lb (87kg)\"\n",
            "\n",
            "Iteration/Step: 1780\n",
            "Sample ID: 25852\n",
            "Decoded Input: What's Dave Fortier's pick number?\n",
            "Decoded Target (Labels): SELECT COUNT(pick__number) FROM table_1213511_2 WHERE player = \"Dave Fortier\"\n",
            "\n",
            "Iteration/Step: 1781\n",
            "Sample ID: 18649\n",
            "Decoded Input: Name the total number of EBIT (US $m) in 2011 and a Earnings per share (¢) larger than 47?\n",
            "Decoded Target (Labels): SELECT COUNT(ebit__us_) AS $m_ FROM table_name_46 WHERE year_to_april = 2011 AND earnings_per_share__¢_ > 47\n",
            "\n",
            "Iteration/Step: 1781\n",
            "Sample ID: 10620\n",
            "Decoded Input: Name the total number of years for quarterfinals\n",
            "Decoded Target (Labels): SELECT COUNT(year) FROM table_name_35 WHERE playoffs = \"quarterfinals\"\n",
            "\n",
            "Iteration/Step: 1782\n",
            "Sample ID: 215\n",
            "Decoded Input: What is the branding for the station located in san jose del monte?\n",
            "Decoded Target (Labels): SELECT branding FROM table_27588823_2 WHERE location = \"San Jose Del Monte\"\n",
            "\n",
            "Iteration/Step: 1782\n",
            "Sample ID: 19463\n",
            "Decoded Input: List the name of tracks belongs to genre Rock or media type is MPEG audio file.\n",
            "Decoded Target (Labels): SELECT T2.name FROM genres AS T1 JOIN tracks AS T2 ON T1.id = T2.genre_id JOIN media_types AS T3 ON T3.id = T2.media_type_id WHERE T1.name = \"Rock\" OR T3.name = \"MPEG audio file\"\n",
            "\n",
            "Iteration/Step: 1783\n",
            "Sample ID: 16970\n",
            "Decoded Input: how many \"Party\" are in district south carolina 2?\n",
            "Decoded Target (Labels): SELECT COUNT(party) FROM table_2668243_22 WHERE district = \"South Carolina 2\"\n",
            "\n",
            "Iteration/Step: 1783\n",
            "Sample ID: 4635\n",
            "Decoded Input: What were the original teams for The Biggest Loser (Season 1)?\n",
            "Decoded Target (Labels): SELECT original_teams FROM table_name_77 WHERE name = \"the biggest loser (season 1)\"\n",
            "\n",
            "Iteration/Step: 1784\n",
            "Sample ID: 24113\n",
            "Decoded Input: What is the 250 cc with a year bigger than 1984?\n",
            "Decoded Target (Labels): SELECT 250 AS _cc FROM table_name_89 WHERE year > 1984\n",
            "\n",
            "Iteration/Step: 1784\n",
            "Sample ID: 3824\n",
            "Decoded Input: Name the number of song for scoreboard being 3rd\n",
            "Decoded Target (Labels): SELECT COUNT(song) FROM table_21234111_6 WHERE scoreboard = \"3rd\"\n",
            "\n",
            "Iteration/Step: 1785\n",
            "Sample ID: 25434\n",
            "Decoded Input: What was the english translation for the song by svetlana loboda?\n",
            "Decoded Target (Labels): SELECT english_translation FROM table_name_77 WHERE artist = \"svetlana loboda\"\n",
            "\n",
            "Iteration/Step: 1785\n",
            "Sample ID: 2092\n",
            "Decoded Input: What's the average number of Laps, that had a start of 25, with a Qual of 138.063?\n",
            "Decoded Target (Labels): SELECT AVG(laps) FROM table_name_21 WHERE start = \"25\" AND qual = \"138.063\"\n",
            "\n",
            "Iteration/Step: 1786\n",
            "Sample ID: 12419\n",
            "Decoded Input: What is Built, when Works Number is \"717\"?\n",
            "Decoded Target (Labels): SELECT built FROM table_name_42 WHERE works_number = \"717\"\n",
            "\n",
            "Iteration/Step: 1786\n",
            "Sample ID: 156\n",
            "Decoded Input: What was the frequency of the Core i7-3610QE?\n",
            "Decoded Target (Labels): SELECT frequency FROM table_name_50 WHERE model_number = \"core i7-3610qe\"\n",
            "\n",
            "Iteration/Step: 1787\n",
            "Sample ID: 24000\n",
            "Decoded Input: On what Date was the Venue Los Angeles?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_90 WHERE venue = \"los angeles\"\n",
            "\n",
            "Iteration/Step: 1787\n",
            "Sample ID: 11562\n",
            "Decoded Input: Find the the name of the customers who have a loan with amount more than 3000.\n",
            "Decoded Target (Labels): SELECT T1.cust_name FROM customer AS T1 JOIN loan AS T2 ON T1.cust_id = T2.cust_id WHERE amount > 3000\n",
            "\n",
            "Iteration/Step: 1788\n",
            "Sample ID: 2837\n",
            "Decoded Input: Number of 13 that has what highest weight?\n",
            "Decoded Target (Labels): SELECT MAX(weight) FROM table_name_44 WHERE number = 13\n",
            "\n",
            "Iteration/Step: 1788\n",
            "Sample ID: 3872\n",
            "Decoded Input: What was the score on October 13?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_94 WHERE date = \"october 13\"\n",
            "\n",
            "Iteration/Step: 1789\n",
            "Sample ID: 509\n",
            "Decoded Input: the episode directed by art dielhenn was what number in the series? \n",
            "Decoded Target (Labels): SELECT no_in_series FROM table_2818164_8 WHERE directed_by = \"Art Dielhenn\"\n",
            "\n",
            "Iteration/Step: 1789\n",
            "Sample ID: 24920\n",
            "Decoded Input: How long was the instrumental version in 1986?\n",
            "Decoded Target (Labels): SELECT length FROM table_name_74 WHERE year = 1986 AND version = \"instrumental\"\n",
            "\n",
            "Iteration/Step: 1790\n",
            "Sample ID: 18402\n",
            "Decoded Input: What record occurred on April 3?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_17 WHERE date = \"april 3\"\n",
            "\n",
            "Iteration/Step: 1790\n",
            "Sample ID: 13689\n",
            "Decoded Input: What position is played by pick 255 overall?\n",
            "Decoded Target (Labels): SELECT position FROM table_10360823_1 WHERE overall = 255\n",
            "\n",
            "Iteration/Step: 1791\n",
            "Sample ID: 20043\n",
            "Decoded Input: What is Season, when Goals is less than 6, and when Team is \"Tarbiat Yazd\"?\n",
            "Decoded Target (Labels): SELECT season FROM table_name_42 WHERE goals < 6 AND team = \"tarbiat yazd\"\n",
            "\n",
            "Iteration/Step: 1791\n",
            "Sample ID: 21847\n",
            "Decoded Input: Who was the opponent on September 8?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_24 WHERE date = \"september 8\"\n",
            "\n",
            "Iteration/Step: 1792\n",
            "Sample ID: 6480\n",
            "Decoded Input: What is the lowest number of members lost when the  net change is −1?\n",
            "Decoded Target (Labels): SELECT MIN(members_lost) FROM table_27671835_3 WHERE net_change = \"−1\"\n",
            "\n",
            "Iteration/Step: 1792\n",
            "Sample ID: 6559\n",
            "Decoded Input: Name the most for first season in the serie a for 7 de octubre\n",
            "Decoded Target (Labels): SELECT MAX(first_season_in_the_serie_a) FROM table_2454589_1 WHERE stadium = \"7 de Octubre\"\n",
            "\n",
            "Iteration/Step: 1793\n",
            "Sample ID: 6824\n",
            "Decoded Input: What's the title for year n.m.?\n",
            "Decoded Target (Labels): SELECT title FROM table_name_43 WHERE year = \"n.m.\"\n",
            "\n",
            "Iteration/Step: 1793\n",
            "Sample ID: 20257\n",
            "Decoded Input: What is the area of cimahi city?\n",
            "Decoded Target (Labels): SELECT area__km²__2005 FROM table_21734764_1 WHERE administrative_division = \"Cimahi City\"\n",
            "\n",
            "Iteration/Step: 1794\n",
            "Sample ID: 5112\n",
            "Decoded Input: What is the average number of events having 1 top-10, fewer than 4 cuts made, and 0 wins?\n",
            "Decoded Target (Labels): SELECT AVG(events) FROM table_name_98 WHERE top_10 = 1 AND wins > 0 AND cuts_made < 4\n",
            "\n",
            "Iteration/Step: 1794\n",
            "Sample ID: 19642\n",
            "Decoded Input: How many NBA years did the player from the United States who was previously on the los angeles lakers have?\n",
            "Decoded Target (Labels): SELECT nba_years_[a_] FROM table_name_58 WHERE nationality = \"united states\" AND previous_team = \"los angeles lakers\"\n",
            "\n",
            "Iteration/Step: 1795\n",
            "Sample ID: 20026\n",
            "Decoded Input: Where was the friendly competition on 17 December 1967 played at?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_72 WHERE competition = \"friendly\" AND date = \"17 december 1967\"\n",
            "\n",
            "Iteration/Step: 1795\n",
            "Sample ID: 2217\n",
            "Decoded Input: Who was partnering when nueza silva played against greece?\n",
            "Decoded Target (Labels): SELECT partnering FROM table_name_8 WHERE against = \"greece\"\n",
            "\n",
            "Iteration/Step: 1796\n",
            "Sample ID: 15522\n",
            "Decoded Input: Which track translates to Flemish Women?\n",
            "Decoded Target (Labels): SELECT track FROM table_name_96 WHERE translation = \"flemish women\"\n",
            "\n",
            "Iteration/Step: 1796\n",
            "Sample ID: 20196\n",
            "Decoded Input: What was the result of the Competition of friendly?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_61 WHERE competition = \"friendly\"\n",
            "\n",
            "Iteration/Step: 1797\n",
            "Sample ID: 745\n",
            "Decoded Input: Which sponsor has Mark Hughes as manager?\n",
            "Decoded Target (Labels): SELECT shirt_sponsor FROM table_name_23 WHERE manager = \"mark hughes\"\n",
            "\n",
            "Iteration/Step: 1797\n",
            "Sample ID: 23300\n",
            "Decoded Input: What's the lowest attendance for October 13, 1968, and is larger than week 5?\n",
            "Decoded Target (Labels): SELECT MIN(attendance) FROM table_name_19 WHERE date = \"october 13, 1968\" AND week > 5\n",
            "\n",
            "Iteration/Step: 1798\n",
            "Sample ID: 10291\n",
            "Decoded Input: List all who wrote for production code 1ark07.\n",
            "Decoded Target (Labels): SELECT written_by FROM table_22835602_1 WHERE production_code = \"1ARK07\"\n",
            "\n",
            "Iteration/Step: 1798\n",
            "Sample ID: 13111\n",
            "Decoded Input: Where were the Womens Doubles in the 1951/1952 season and who won?\n",
            "Decoded Target (Labels): SELECT womens_doubles FROM table_12266757_1 WHERE season = \"1951/1952\"\n",
            "\n",
            "Iteration/Step: 1799\n",
            "Sample ID: 602\n",
            "Decoded Input: What was the team's record on november 10?\n",
            "Decoded Target (Labels): SELECT record FROM table_27700530_9 WHERE date = \"November 10\"\n",
            "\n",
            "Iteration/Step: 1799\n",
            "Sample ID: 4475\n",
            "Decoded Input: Tell me the total number of grid for laps of 52\n",
            "Decoded Target (Labels): SELECT COUNT(grid) FROM table_name_60 WHERE laps = 52\n",
            "\n",
            "Iteration/Step: 1800\n",
            "Sample ID: 8212\n",
            "Decoded Input: What date did Mike Rockenfeller have the fastest lap?\n",
            "Decoded Target (Labels): SELECT date FROM table_24732149_2 WHERE fastest_lap = \"Mike Rockenfeller\"\n",
            "\n",
            "Iteration/Step: 1800\n",
            "Sample ID: 6931\n",
            "Decoded Input: Who is the rider with a yamaha manufacturer and a 17 grid?\n",
            "Decoded Target (Labels): SELECT rider FROM table_name_21 WHERE manufacturer = \"yamaha\" AND grid = \"17\"\n",
            "\n",
            "Iteration/Step: 1801\n",
            "Sample ID: 7938\n",
            "Decoded Input: What is Opponent in The Final, when Date is \"1976\"?\n",
            "Decoded Target (Labels): SELECT opponent_in_the_final FROM table_name_40 WHERE date = 1976\n",
            "\n",
            "Iteration/Step: 1801\n",
            "Sample ID: 10623\n",
            "Decoded Input: What institution joined in 1988?\n",
            "Decoded Target (Labels): SELECT institution FROM table_255188_1 WHERE joined = 1988\n",
            "\n",
            "Iteration/Step: 1802\n",
            "Sample ID: 12237\n",
            "Decoded Input: What is the frequency of the tmm500dbo22gq order part number?\n",
            "Decoded Target (Labels): SELECT frequency FROM table_name_17 WHERE order_part_number = \"tmm500dbo22gq\"\n",
            "\n",
            "Iteration/Step: 1802\n",
            "Sample ID: 10376\n",
            "Decoded Input: What's the Termination of Mission listed that has a Presentation of Credentials for August 29, 1859?\n",
            "Decoded Target (Labels): SELECT termination_of_mission FROM table_name_34 WHERE presentation_of_credentials = \"august 29, 1859\"\n",
            "\n",
            "Iteration/Step: 1803\n",
            "Sample ID: 22643\n",
            "Decoded Input: What Opponent has an Attendance of 74,246?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_49 WHERE attendance = \"74,246\"\n",
            "\n",
            "Iteration/Step: 1803\n",
            "Sample ID: 8288\n",
            "Decoded Input: What was the Michele Alboreto's engine?\n",
            "Decoded Target (Labels): SELECT engine FROM table_name_22 WHERE driver = \"michele alboreto\"\n",
            "\n",
            "Iteration/Step: 1804\n",
            "Sample ID: 24122\n",
            "Decoded Input: Name the most draws\n",
            "Decoded Target (Labels): SELECT MAX(draws) FROM table_18607260_6\n",
            "\n",
            "Iteration/Step: 1804\n",
            "Sample ID: 4378\n",
            "Decoded Input: What road is associated with Carson Valley county?\n",
            "Decoded Target (Labels): SELECT road FROM table_25438110_5 WHERE county = \"Carson Valley\"\n",
            "\n",
            "Iteration/Step: 1805\n",
            "Sample ID: 2591\n",
            "Decoded Input: What is the average number of caps for Meralomas with positions of centre?\n",
            "Decoded Target (Labels): SELECT AVG(caps) FROM table_name_75 WHERE club_province = \"meralomas\" AND position = \"centre\"\n",
            "\n",
            "Iteration/Step: 1805\n",
            "Sample ID: 25026\n",
            "Decoded Input: Which tournament had a result in 2010 and 2012 of a?\n",
            "Decoded Target (Labels): SELECT tournament FROM table_name_49 WHERE 2012 = \"a\" AND 2010 = \"a\"\n",
            "\n",
            "Iteration/Step: 1806\n",
            "Sample ID: 24074\n",
            "Decoded Input: Which Year has a Community Award of jarrod harbrow?\n",
            "Decoded Target (Labels): SELECT SUM(year) FROM table_name_85 WHERE community_award = \"jarrod harbrow\"\n",
            "\n",
            "Iteration/Step: 1806\n",
            "Sample ID: 25227\n",
            "Decoded Input: Show all calendar dates and day Numbers.\n",
            "Decoded Target (Labels): SELECT calendar_date, day_Number FROM Ref_calendar\n",
            "\n",
            "Iteration/Step: 1807\n",
            "Sample ID: 15571\n",
            "Decoded Input: When Jean Alesi had laps less than 24, what was his highest grid?\n",
            "Decoded Target (Labels): SELECT MAX(grid) FROM table_name_75 WHERE driver = \"jean alesi\" AND laps < 24\n",
            "\n",
            "Iteration/Step: 1807\n",
            "Sample ID: 20095\n",
            "Decoded Input: For more than 3 events in the PGA Championship, what is the fewest number of wins?\n",
            "Decoded Target (Labels): SELECT MIN(wins) FROM table_name_33 WHERE tournament = \"pga championship\" AND events > 3\n",
            "\n",
            "Iteration/Step: 1808\n",
            "Sample ID: 15226\n",
            "Decoded Input: What were the laps of aprilia with a grid of 10?\n",
            "Decoded Target (Labels): SELECT laps FROM table_name_72 WHERE manufacturer = \"aprilia\" AND grid = 10\n",
            "\n",
            "Iteration/Step: 1808\n",
            "Sample ID: 22483\n",
            "Decoded Input: What is Tournament, when 2012 is \"Grand Slam Tournaments\"?\n",
            "Decoded Target (Labels): SELECT tournament FROM table_name_35 WHERE 2012 = \"grand slam tournaments\"\n",
            "\n",
            "Iteration/Step: 1809\n",
            "Sample ID: 15160\n",
            "Decoded Input: How many proteins are associated with an institution in a building with at least 20 floors?\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM institution AS T1 JOIN protein AS T2 ON T1.institution_id = T2.institution_id JOIN building AS T3 ON T3.building_id = T1.building_id WHERE T3.floors >= 20\n",
            "\n",
            "Iteration/Step: 1809\n",
            "Sample ID: 17703\n",
            "Decoded Input: What's the format of the single, I Can't Stay?\n",
            "Decoded Target (Labels): SELECT format FROM table_name_6 WHERE single = \"i can't stay\"\n",
            "\n",
            "Iteration/Step: 1810\n",
            "Sample ID: 10989\n",
            "Decoded Input: What's the tie number when the away team was Mansfield Town?\n",
            "Decoded Target (Labels): SELECT tie_no FROM table_name_3 WHERE away_team = \"mansfield town\"\n",
            "\n",
            "Iteration/Step: 1810\n",
            "Sample ID: 21241\n",
            "Decoded Input: What To par has a Country of united states, and a Score of 67-66-78-77=288?\n",
            "Decoded Target (Labels): SELECT to_par FROM table_name_52 WHERE country = \"united states\" AND score = 67 - 66 - 78 - 77 = 288\n",
            "\n",
            "Iteration/Step: 1811\n",
            "Sample ID: 17125\n",
            "Decoded Input: What was the latest round that Derek Pagel was selected with a pick higher than 50?\n",
            "Decoded Target (Labels): SELECT MAX(round) FROM table_name_22 WHERE pick > 50 AND player = \"derek pagel\"\n",
            "\n",
            "Iteration/Step: 1811\n",
            "Sample ID: 15114\n",
            "Decoded Input: What is the highest number of bronze for the United States with more than 1 silver?\n",
            "Decoded Target (Labels): SELECT MAX(bronze) FROM table_name_13 WHERE nation = \"united states\" AND silver > 1\n",
            "\n",
            "Iteration/Step: 1812\n",
            "Sample ID: 12759\n",
            "Decoded Input: What is the title of episode number 14?\n",
            "Decoded Target (Labels): SELECT title FROM table_19161605_2 WHERE _number = 14\n",
            "\n",
            "Iteration/Step: 1812\n",
            "Sample ID: 13007\n",
            "Decoded Input: Who is born on 1982-01-29?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_7 WHERE date_of_birth = \"1982-01-29\"\n",
            "\n",
            "Iteration/Step: 1813\n",
            "Sample ID: 71\n",
            "Decoded Input: What race even has NASCAR Featherlite Modified Series as the championship?\n",
            "Decoded Target (Labels): SELECT event FROM table_name_26 WHERE championship = \"nascar featherlite modified series\"\n",
            "\n",
            "Iteration/Step: 1813\n",
            "Sample ID: 8021\n",
            "Decoded Input: Who has the high assists when the team is Oklahoma City?\n",
            "Decoded Target (Labels): SELECT high_assists FROM table_23285805_8 WHERE team = \"Oklahoma City\"\n",
            "\n",
            "Iteration/Step: 1814\n",
            "Sample ID: 9967\n",
            "Decoded Input: How many Ties have Years of 1919–1925, and a Pct larger than 0.734?\n",
            "Decoded Target (Labels): SELECT SUM(ties) FROM table_name_75 WHERE years = \"1919–1925\" AND pct > 0.734\n",
            "\n",
            "Iteration/Step: 1814\n",
            "Sample ID: 7348\n",
            "Decoded Input: What is Apogee, when Inclination is 65°, and when Launch Date/Time is ( GMT ) is 15 February 1973, 01:11?\n",
            "Decoded Target (Labels): SELECT apogee FROM table_name_48 WHERE inclination = \"65°\" AND launch_date_time___gmt__ = \"15 february 1973, 01:11\"\n",
            "\n",
            "Iteration/Step: 1815\n",
            "Sample ID: 25575\n",
            "Decoded Input: what is the name when death is november 10, 1842?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_80 WHERE death = \"november 10, 1842\"\n",
            "\n",
            "Iteration/Step: 1815\n",
            "Sample ID: 20462\n",
            "Decoded Input: What teams rank is higher than 4 with a speed of 104.574mph?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_91 WHERE rank > 4 AND speed = \"104.574mph\"\n",
            "\n",
            "Iteration/Step: 1816\n",
            "Sample ID: 316\n",
            "Decoded Input: When the USA's captain was Beth Daniel, who was the winning team?\n",
            "Decoded Target (Labels): SELECT winning_team FROM table_name_99 WHERE usa_captain = \"beth daniel\"\n",
            "\n",
            "Iteration/Step: 1816\n",
            "Sample ID: 19558\n",
            "Decoded Input: Show the names of countries that have more than one roller coaster.\n",
            "Decoded Target (Labels): SELECT T1.Name FROM country AS T1 JOIN roller_coaster AS T2 ON T1.Country_ID = T2.Country_ID GROUP BY T1.Name HAVING COUNT(*) > 1\n",
            "\n",
            "Iteration/Step: 1817\n",
            "Sample ID: 20597\n",
            "Decoded Input: What is the height of Patrick Femerling, of the Alba Berlin club?\n",
            "Decoded Target (Labels): SELECT COUNT(height) FROM table_name_36 WHERE current_club = \"alba berlin\" AND player = \"patrick femerling\"\n",
            "\n",
            "Iteration/Step: 1817\n",
            "Sample ID: 21144\n",
            "Decoded Input: What is the Romanization of the Mandarin word whose Rōmaji is ūroncha\n",
            "Decoded Target (Labels): SELECT romanization FROM table_name_81 WHERE source_language = \"mandarin\" AND rōmaji = \"ūroncha\"\n",
            "\n",
            "Iteration/Step: 1818\n",
            "Sample ID: 15968\n",
            "Decoded Input: The plural abbreviation of ll. uses what plural word?\n",
            "Decoded Target (Labels): SELECT plural_word FROM table_name_94 WHERE plural_abbreviation = \"ll.\"\n",
            "\n",
            "Iteration/Step: 1818\n",
            "Sample ID: 19878\n",
            "Decoded Input: What is the to par that has jimmy hines as the player?\n",
            "Decoded Target (Labels): SELECT to_par FROM table_name_46 WHERE player = \"jimmy hines\"\n",
            "\n",
            "Iteration/Step: 1819\n",
            "Sample ID: 12645\n",
            "Decoded Input: Which party had Clair Engle as an incumbent?\n",
            "Decoded Target (Labels): SELECT party FROM table_1342149_6 WHERE incumbent = \"Clair Engle\"\n",
            "\n",
            "Iteration/Step: 1819\n",
            "Sample ID: 18801\n",
            "Decoded Input: What district had someone first elected in 1982?\n",
            "Decoded Target (Labels): SELECT district FROM table_1341522_41 WHERE first_elected = 1982\n",
            "\n",
            "Iteration/Step: 1820\n",
            "Sample ID: 24841\n",
            "Decoded Input: What is the highest pick for a year after 2010, and a round smaller than 1?\n",
            "Decoded Target (Labels): SELECT MAX(pick) FROM table_name_11 WHERE year > 2010 AND round < 1\n",
            "\n",
            "Iteration/Step: 1820\n",
            "Sample ID: 5190\n",
            "Decoded Input: In the game at Glenferrie Oval, what is the home team score?\n",
            "Decoded Target (Labels): SELECT home_team AS score FROM table_name_81 WHERE venue = \"glenferrie oval\"\n",
            "\n",
            "Iteration/Step: 1821\n",
            "Sample ID: 10502\n",
            "Decoded Input: Who answered the 20 questions on 10-07?\n",
            "Decoded Target (Labels): SELECT 20 AS _questions FROM table_1566852_8 WHERE date = \"10-07\"\n",
            "\n",
            "Iteration/Step: 1821\n",
            "Sample ID: 5271\n",
            "Decoded Input: What is the least amount of extra points made in by a player?\n",
            "Decoded Target (Labels): SELECT MIN(extra_points) FROM table_14342210_6\n",
            "\n",
            "Iteration/Step: 1822\n",
            "Sample ID: 77\n",
            "Decoded Input: Who made the decisions in the game whose first star was V. Lecavalier?\n",
            "Decoded Target (Labels): SELECT decision FROM table_27537518_6 WHERE first_star = \"V. Lecavalier\"\n",
            "\n",
            "Iteration/Step: 1822\n",
            "Sample ID: 478\n",
            "Decoded Input: what is the debut year for player terry fulton with games less than 51?\n",
            "Decoded Target (Labels): SELECT AVG(debut_year) FROM table_name_83 WHERE player = \"terry fulton\" AND games < 51\n",
            "\n",
            "Iteration/Step: 1823\n",
            "Sample ID: 17529\n",
            "Decoded Input: What is the percentage of Glendale when La Canada Flintridge is 5%?\n",
            "Decoded Target (Labels): SELECT glendale FROM table_name_20 WHERE la_cañada_flintridge = \"5%\"\n",
            "\n",
            "Iteration/Step: 1823\n",
            "Sample ID: 19597\n",
            "Decoded Input: Name the opponent for august 6\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_79 WHERE date = \"august 6\"\n",
            "\n",
            "Iteration/Step: 1824\n",
            "Sample ID: 433\n",
            "Decoded Input: What was the cargo value in 2005 for all product carriers?\n",
            "Decoded Target (Labels): SELECT 2005 FROM table_name_46 WHERE cargo = \"all product carriers\"\n",
            "\n",
            "Iteration/Step: 1824\n",
            "Sample ID: 8721\n",
            "Decoded Input: Name the mens singles for 1989\n",
            "Decoded Target (Labels): SELECT mens_singles FROM table_14903491_1 WHERE year = 1989\n",
            "\n",
            "Iteration/Step: 1825\n",
            "Sample ID: 12529\n",
            "Decoded Input: What is the total when gold is 1, and rank is more than 4, and bronze is 0?\n",
            "Decoded Target (Labels): SELECT COUNT(total) FROM table_name_1 WHERE gold = 1 AND rank > 4 AND bronze = 0\n",
            "\n",
            "Iteration/Step: 1825\n",
            "Sample ID: 2161\n",
            "Decoded Input: What format has the call sign DZFE?\n",
            "Decoded Target (Labels): SELECT format FROM table_name_42 WHERE call_sign = \"dzfe\"\n",
            "\n",
            "Iteration/Step: 1826\n",
            "Sample ID: 13209\n",
            "Decoded Input: What class is the verb wich its part 3 is heldu\n",
            "Decoded Target (Labels): SELECT class FROM table_1745843_10 WHERE part_3 = \"heldu\"\n",
            "\n",
            "Iteration/Step: 1826\n",
            "Sample ID: 15061\n",
            "Decoded Input: What was the average crowd size at Victoria Park?\n",
            "Decoded Target (Labels): SELECT AVG(crowd) FROM table_name_22 WHERE venue = \"victoria park\"\n",
            "\n",
            "Iteration/Step: 1827\n",
            "Sample ID: 29\n",
            "Decoded Input: What was the score for the home team of essendon?\n",
            "Decoded Target (Labels): SELECT home_team AS score FROM table_name_45 WHERE home_team = \"essendon\"\n",
            "\n",
            "Iteration/Step: 1827\n",
            "Sample ID: 15803\n",
            "Decoded Input: What was Gassaway's record at the fight in mississippi, united states against anthony macias?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_19 WHERE location = \"mississippi, united states\" AND opponent = \"anthony macias\"\n",
            "\n",
            "Iteration/Step: 1828\n",
            "Sample ID: 2288\n",
            "Decoded Input: What is the order number that has Aretha Franklin as the original artist?\n",
            "Decoded Target (Labels): SELECT order__number FROM table_name_97 WHERE original_artist = \"aretha franklin\"\n",
            "\n",
            "Iteration/Step: 1828\n",
            "Sample ID: 14701\n",
            "Decoded Input: What is the sum of the years when the winner was prof. priyambada mohanty hejmadi from orissa?\n",
            "Decoded Target (Labels): SELECT SUM(year) FROM table_name_95 WHERE state = \"orissa\" AND name = \"prof. priyambada mohanty hejmadi\"\n",
            "\n",
            "Iteration/Step: 1829\n",
            "Sample ID: 1832\n",
            "Decoded Input: What is the score when watford was the away team?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_59 WHERE away_team = \"watford\"\n",
            "\n",
            "Iteration/Step: 1829\n",
            "Sample ID: 8284\n",
            "Decoded Input: What year did Zone Rouge first air?\n",
            "Decoded Target (Labels): SELECT first_year_aired FROM table_name_79 WHERE name = \"zone rouge\"\n",
            "\n",
            "Iteration/Step: 1830\n",
            "Sample ID: 21159\n",
            "Decoded Input: Which 1995 has a 1993 of 3r?\n",
            "Decoded Target (Labels): SELECT 1995 FROM table_name_86 WHERE 1993 = \"3r\"\n",
            "\n",
            "Iteration/Step: 1830\n",
            "Sample ID: 305\n",
            "Decoded Input: What is the highest Average, when Goals is \"34\", and when Matches is less than 37?\n",
            "Decoded Target (Labels): SELECT MAX(average) FROM table_name_41 WHERE goals = 34 AND matches < 37\n",
            "\n",
            "Iteration/Step: 1831\n",
            "Sample ID: 22699\n",
            "Decoded Input: What document types do have more than 10000 total access number.\n",
            "Decoded Target (Labels): SELECT document_type_code FROM documents GROUP BY document_type_code HAVING SUM(access_count) > 10000\n",
            "\n",
            "Iteration/Step: 1831\n",
            "Sample ID: 9360\n",
            "Decoded Input: if the bbi is 4/39 what is the average\n",
            "Decoded Target (Labels): SELECT average FROM table_28798161_3 WHERE bbi = \"4/39\"\n",
            "\n",
            "Iteration/Step: 1832\n",
            "Sample ID: 14276\n",
            "Decoded Input: Which Year saw the Production of Wicked at the Helpmann Awards Award ceremony?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_13 WHERE production = \"wicked\" AND award_ceremony = \"helpmann awards\"\n",
            "\n",
            "Iteration/Step: 1832\n",
            "Sample ID: 2197\n",
            "Decoded Input: What years did Orlando have stanley roberts on the team?\n",
            "Decoded Target (Labels): SELECT years_in_orlando FROM table_name_75 WHERE player = \"stanley roberts\"\n",
            "\n",
            "Iteration/Step: 1833\n",
            "Sample ID: 6614\n",
            "Decoded Input: What is the total of port adelaide\n",
            "Decoded Target (Labels): SELECT MAX(total) FROM table_1161065_27 WHERE team = \"Port Adelaide\"\n",
            "\n",
            "Iteration/Step: 1833\n",
            "Sample ID: 3307\n",
            "Decoded Input: Show the most common nationality of pilots.\n",
            "Decoded Target (Labels): SELECT Nationality FROM pilot GROUP BY Nationality ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 1834\n",
            "Sample ID: 11867\n",
            "Decoded Input: Who built the 21 grid car that retired due to suspension?\n",
            "Decoded Target (Labels): SELECT constructor FROM table_name_80 WHERE grid > 21 AND time_retired = \"suspension\"\n",
            "\n",
            "Iteration/Step: 1834\n",
            "Sample ID: 18512\n",
            "Decoded Input: What is the least amount of yards when the average is less than 2.6?\n",
            "Decoded Target (Labels): SELECT MIN(yards) FROM table_name_65 WHERE average < 2.6\n",
            "\n",
            "Iteration/Step: 1835\n",
            "Sample ID: 15731\n",
            "Decoded Input: Which average Home Run has a Game of 89?\n",
            "Decoded Target (Labels): SELECT AVG(home_run) FROM table_name_55 WHERE game = 89\n",
            "\n",
            "Iteration/Step: 1835\n",
            "Sample ID: 10191\n",
            "Decoded Input: What is the total appearances when the total goals is 289?\n",
            "Decoded Target (Labels): SELECT MIN(total_appearances) FROM table_29701419_2 WHERE total_goals = 289\n",
            "\n",
            "Iteration/Step: 1836\n",
            "Sample ID: 8802\n",
            "Decoded Input: What theme name has the original artist of Dolly Parton?\n",
            "Decoded Target (Labels): SELECT theme FROM table_15796100_1 WHERE original_artist = \"Dolly Parton\"\n",
            "\n",
            "Iteration/Step: 1836\n",
            "Sample ID: 9703\n",
            "Decoded Input: What did they do against Memphis?\n",
            "Decoded Target (Labels): SELECT result FROM table_21058823_1 WHERE opponent = \"Memphis\"\n",
            "\n",
            "Iteration/Step: 1837\n",
            "Sample ID: 9436\n",
            "Decoded Input: What unit of length is being used for the route with \"replaced by us 81\" in their remarks section?\n",
            "Decoded Target (Labels): SELECT length FROM table_11336756_6 WHERE remarks = \"Replaced by US 81\"\n",
            "\n",
            "Iteration/Step: 1837\n",
            "Sample ID: 18210\n",
            "Decoded Input: What constructor has an engine of cosworth cr-2 and a driver of luciano burti?\n",
            "Decoded Target (Labels): SELECT constructor FROM table_name_52 WHERE engine_† = \"cosworth cr-2\" AND driver = \"luciano burti\"\n",
            "\n",
            "Iteration/Step: 1838\n",
            "Sample ID: 8403\n",
            "Decoded Input: What is the Record with a Team that is detroit and a Date that is june 10?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_56 WHERE team = \"detroit\" AND date = \"june 10\"\n",
            "\n",
            "Iteration/Step: 1838\n",
            "Sample ID: 1063\n",
            "Decoded Input: What winner has royal st george's golf club as the venue, and 1969 as the year?\n",
            "Decoded Target (Labels): SELECT winner FROM table_name_70 WHERE venue = \"royal st george's golf club\" AND year = \"1969\"\n",
            "\n",
            "Iteration/Step: 1839\n",
            "Sample ID: 8208\n",
            "Decoded Input: Who had the most laps led in monterey, california when scott rarick won the race?\n",
            "Decoded Target (Labels): SELECT most_laps_led FROM table_25668203_2 WHERE location = \"Monterey, California\" AND winning_driver = \"Scott Rarick\"\n",
            "\n",
            "Iteration/Step: 1839\n",
            "Sample ID: 25614\n",
            "Decoded Input: What is the lowest Rank, when Name is Jeremiah Massey, and when Games is less than 20?\n",
            "Decoded Target (Labels): SELECT MIN(rank) FROM table_name_60 WHERE name = \"jeremiah massey\" AND games < 20\n",
            "\n",
            "Iteration/Step: 1840\n",
            "Sample ID: 3275\n",
            "Decoded Input: What is Country, when Score is \"72-65=137\"?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_40 WHERE score = 72 - 65 = 137\n",
            "\n",
            "Iteration/Step: 1840\n",
            "Sample ID: 11914\n",
            "Decoded Input: Who was second for the United States team?\n",
            "Decoded Target (Labels): SELECT second FROM table_name_35 WHERE nation = \"united states\"\n",
            "\n",
            "Iteration/Step: 1841\n",
            "Sample ID: 18072\n",
            "Decoded Input: Who is the player with the pick# 80?\n",
            "Decoded Target (Labels): SELECT player FROM table_22402438_7 WHERE pick__number = 80\n",
            "\n",
            "Iteration/Step: 1841\n",
            "Sample ID: 19054\n",
            "Decoded Input: What is the sum of Against, when Wins is greater than 8, and when Losses is greater than 6?\n",
            "Decoded Target (Labels): SELECT SUM(against) FROM table_name_19 WHERE wins > 8 AND losses > 6\n",
            "\n",
            "Iteration/Step: 1842\n",
            "Sample ID: 1502\n",
            "Decoded Input: Who was the republican candidate in 2013 when Staten Island was 451?\n",
            "Decoded Target (Labels): SELECT 2013 AS _republican_primary FROM table_1108394_6 WHERE staten_island = \"451\"\n",
            "\n",
            "Iteration/Step: 1842\n",
            "Sample ID: 25805\n",
            "Decoded Input: What is the 1998 value with 2r in 2003?\n",
            "Decoded Target (Labels): SELECT 1998 FROM table_name_60 WHERE 2003 = \"2r\"\n",
            "\n",
            "Iteration/Step: 1843\n",
            "Sample ID: 20388\n",
            "Decoded Input: Which film was released in the year 2002?\n",
            "Decoded Target (Labels): SELECT film_name FROM table_name_63 WHERE year = 2002\n",
            "\n",
            "Iteration/Step: 1843\n",
            "Sample ID: 4557\n",
            "Decoded Input: Which 2013 has a 2007 of A, and a Tournament of french open?\n",
            "Decoded Target (Labels): SELECT 2013 FROM table_name_49 WHERE 2007 = \"a\" AND tournament = \"french open\"\n",
            "\n",
            "Iteration/Step: 1844\n",
            "Sample ID: 7725\n",
            "Decoded Input: How many vehicle theft data were recorded for a year with a population of 4465430?\n",
            "Decoded Target (Labels): SELECT COUNT(vehicle_theft) FROM table_26060884_2 WHERE population = 4465430\n",
            "\n",
            "Iteration/Step: 1844\n",
            "Sample ID: 1222\n",
            "Decoded Input: Which Pick has a Nationality of canada, and a Player of dennis maxwell?\n",
            "Decoded Target (Labels): SELECT COUNT(pick) FROM table_name_27 WHERE nationality = \"canada\" AND player = \"dennis maxwell\"\n",
            "\n",
            "Iteration/Step: 1845\n",
            "Sample ID: 14855\n",
            "Decoded Input: Which artist uses a finish of selective gold plating?\n",
            "Decoded Target (Labels): SELECT artist FROM table_name_29 WHERE finish = \"selective gold plating\"\n",
            "\n",
            "Iteration/Step: 1845\n",
            "Sample ID: 10361\n",
            "Decoded Input: What is 你 朋友's Label?\n",
            "Decoded Target (Labels): SELECT label FROM table_name_92 WHERE chinese__simplified_ = \"你 朋友\"\n",
            "\n",
            "Iteration/Step: 1846\n",
            "Sample ID: 19392\n",
            "Decoded Input: How many original air dates did the episode directed by Bethany rooney have?\n",
            "Decoded Target (Labels): SELECT COUNT(original_air_date) FROM table_28859177_3 WHERE directed_by = \"Bethany Rooney\"\n",
            "\n",
            "Iteration/Step: 1846\n",
            "Sample ID: 24800\n",
            "Decoded Input: What place is player johnny miller, who has a to par of +2?\n",
            "Decoded Target (Labels): SELECT place FROM table_name_28 WHERE to_par = \"+2\" AND player = \"johnny miller\"\n",
            "\n",
            "Iteration/Step: 1847\n",
            "Sample ID: 1061\n",
            "Decoded Input: How many goals on average had 644 matches and a rank bigger than 3?\n",
            "Decoded Target (Labels): SELECT AVG(goals) FROM table_name_94 WHERE matches = 644 AND rank > 3\n",
            "\n",
            "Iteration/Step: 1847\n",
            "Sample ID: 6244\n",
            "Decoded Input: What opponent has 3-2 as the score, and anderson (2-6) as a loss?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_6 WHERE score = \"3-2\" AND loss = \"anderson (2-6)\"\n",
            "\n",
            "Iteration/Step: 1848\n",
            "Sample ID: 16989\n",
            "Decoded Input: Find the organisation type description of the organisation detailed as 'quo'.\n",
            "Decoded Target (Labels): SELECT T1.organisation_type_description FROM organisation_Types AS T1 JOIN Organisations AS T2 ON T1.organisation_type = T2.organisation_type WHERE T2.organisation_details = 'quo'\n",
            "\n",
            "Iteration/Step: 1848\n",
            "Sample ID: 15985\n",
            "Decoded Input: What time was the game during week 5?\n",
            "Decoded Target (Labels): SELECT time___et__ FROM table_name_14 WHERE week = 5\n",
            "\n",
            "Iteration/Step: 1849\n",
            "Sample ID: 978\n",
            "Decoded Input: What team is Keith Mccambridge on?\n",
            "Decoded Target (Labels): SELECT college_junior_club_team FROM table_1013129_8 WHERE player = \"Keith McCambridge\"\n",
            "\n",
            "Iteration/Step: 1849\n",
            "Sample ID: 5269\n",
            "Decoded Input: Find the products which have problems reported by both Lacey Bosco and Kenton Champlin?\n",
            "Decoded Target (Labels): SELECT T2.product_name FROM problems AS T1 JOIN product AS T2 JOIN staff AS T3 ON T1.product_id = T2.product_id AND T1.reported_by_staff_id = T3.staff_id WHERE T3.staff_first_name = \"Lacey\" AND T3.staff_last_name = \"Bosco\" INTERSECT SELECT T2.product_name FROM problems AS T1 JOIN product AS T2 JOIN staff AS T3 ON T1.product_id = T2.product_id AND T1.reported_by_staff_id = T3.staff_id WHERE T3.staff_first_name = \"Kenton\" AND T3.staff_last_name = \"Champlin\"\n",
            "\n",
            "Iteration/Step: 1850\n",
            "Sample ID: 14490\n",
            "Decoded Input: Name all of the february\n",
            "Decoded Target (Labels): SELECT february FROM table_1539201_1\n",
            "\n",
            "Iteration/Step: 1850\n",
            "Sample ID: 17913\n",
            "Decoded Input: what is a building that is proposed and will have 32 floors?\n",
            "Decoded Target (Labels): SELECT building FROM table_name_22 WHERE status = \"proposed\" AND floors = 32\n",
            "\n",
            "Iteration/Step: 1851\n",
            "Sample ID: 3971\n",
            "Decoded Input: What was the score when the partner is Rafael Osuna?\n",
            "Decoded Target (Labels): SELECT score FROM table_2215159_2 WHERE partner = \"Rafael Osuna\"\n",
            "\n",
            "Iteration/Step: 1851\n",
            "Sample ID: 10421\n",
            "Decoded Input: What was the outcome of the game played on 19-Sep-2006?\n",
            "Decoded Target (Labels): SELECT outcome FROM table_name_68 WHERE date = \"19-sep-2006\"\n",
            "\n",
            "Iteration/Step: 1852\n",
            "Sample ID: 6678\n",
            "Decoded Input: Find the name of companies whose revenue is smaller than the revenue of all companies based in Austin.\n",
            "Decoded Target (Labels): SELECT name FROM manufacturers WHERE revenue < (SELECT MIN(revenue) FROM manufacturers WHERE headquarter = 'Austin')\n",
            "\n",
            "Iteration/Step: 1852\n",
            "Sample ID: 17543\n",
            "Decoded Input: What's the average year with a rank less than 3?\n",
            "Decoded Target (Labels): SELECT AVG(year) FROM table_name_91 WHERE rank < 3\n",
            "\n",
            "Iteration/Step: 1853\n",
            "Sample ID: 5006\n",
            "Decoded Input: Who wrote the episode with the production code 211?\n",
            "Decoded Target (Labels): SELECT written_by FROM table_27610775_1 WHERE prod_code = 211\n",
            "\n",
            "Iteration/Step: 1853\n",
            "Sample ID: 12869\n",
            "Decoded Input: What is the venue for the game on 1 June 1929 where Richmond was the away team?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_96 WHERE date = \"1 june 1929\" AND away_team = \"richmond\"\n",
            "\n",
            "Iteration/Step: 1854\n",
            "Sample ID: 9092\n",
            "Decoded Input: For the race held on 10/08/86, what was the circuit?\n",
            "Decoded Target (Labels): SELECT circuit FROM table_name_11 WHERE date = \"10/08/86\"\n",
            "\n",
            "Iteration/Step: 1854\n",
            "Sample ID: 2574\n",
            "Decoded Input: Which giant slalom had an Overall number of 25?\n",
            "Decoded Target (Labels): SELECT Giant AS slalom FROM table_name_34 WHERE overall = 25\n",
            "\n",
            "Iteration/Step: 1855\n",
            "Sample ID: 9769\n",
            "Decoded Input: Radio Station/Production Company that has a Role of interviewee & monologues is what radio station?\n",
            "Decoded Target (Labels): SELECT radio_station_production_company FROM table_name_73 WHERE role = \"interviewee & monologues\"\n",
            "\n",
            "Iteration/Step: 1855\n",
            "Sample ID: 10972\n",
            "Decoded Input: Which 2011 has a 1999 of A, and a 2004 of 2r, and a Career SR of 0 / 10?\n",
            "Decoded Target (Labels): SELECT 2011 FROM table_name_96 WHERE 1999 = \"a\" AND 2004 = \"2r\" AND career_sr = \"0 / 10\"\n",
            "\n",
            "Iteration/Step: 1856\n",
            "Sample ID: 24684\n",
            "Decoded Input: On what date was Tie #13 played?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_93 WHERE tie_no = \"13\"\n",
            "\n",
            "Iteration/Step: 1856\n",
            "Sample ID: 15191\n",
            "Decoded Input: Who scored the most point on December 13?\n",
            "Decoded Target (Labels): SELECT high_points FROM table_name_28 WHERE date = \"december 13\"\n",
            "\n",
            "Iteration/Step: 1857\n",
            "Sample ID: 11852\n",
            "Decoded Input: Who was the visitor when phoenix was at home?\n",
            "Decoded Target (Labels): SELECT visitor FROM table_name_35 WHERE home = \"phoenix\"\n",
            "\n",
            "Iteration/Step: 1857\n",
            "Sample ID: 17007\n",
            "Decoded Input: What is the total number of title with a u.s. air date of April 17, 2009\n",
            "Decoded Target (Labels): SELECT COUNT(title) FROM table_12294557_3 WHERE us_airdate = \"April 17, 2009\"\n",
            "\n",
            "Iteration/Step: 1858\n",
            "Sample ID: 23291\n",
            "Decoded Input: What is the partial failure for the Country of russia, and a Failure larger than 0, and a Family of angara, and a Launch larger than 1?\n",
            "Decoded Target (Labels): SELECT AVG(partial_failures) FROM table_name_53 WHERE country = \"russia\" AND failures > 0 AND family = \"angara\" AND launches > 1\n",
            "\n",
            "Iteration/Step: 1858\n",
            "Sample ID: 9761\n",
            "Decoded Input: With a less than 4 rank, and a time less than 24.42 what is the smallest lane?\n",
            "Decoded Target (Labels): SELECT MIN(lane) FROM table_name_52 WHERE rank < 4 AND time < 24.42\n",
            "\n",
            "Iteration/Step: 1859\n",
            "Sample ID: 8901\n",
            "Decoded Input: What country was Brage, built by karljohansverns verft, from?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_23 WHERE builder = \"karljohansverns verft\" AND ship = \"brage\"\n",
            "\n",
            "Iteration/Step: 1859\n",
            "Sample ID: 6462\n",
            "Decoded Input: From what series was Tokio Jokio, directed by Norm McCabe?\n",
            "Decoded Target (Labels): SELECT series FROM table_name_35 WHERE director = \"norm mccabe\" AND title = \"tokio jokio\"\n",
            "\n",
            "Iteration/Step: 1860\n",
            "Sample ID: 16550\n",
            "Decoded Input: Show the minimum, maximum, and average age for all people.\n",
            "Decoded Target (Labels): SELECT MIN(age), MAX(age), AVG(age) FROM people\n",
            "\n",
            "Iteration/Step: 1860\n",
            "Sample ID: 8230\n",
            "Decoded Input: What is the result F-A of the game on 6 march 1993?\n",
            "Decoded Target (Labels): SELECT result_f___a FROM table_name_95 WHERE date = \"6 march 1993\"\n",
            "\n",
            "Iteration/Step: 1861\n",
            "Sample ID: 8087\n",
            "Decoded Input: Which institution has an endowment of $25.9m?\n",
            "Decoded Target (Labels): SELECT institution FROM table_27599216_6 WHERE endowment = \"$25.9M\"\n",
            "\n",
            "Iteration/Step: 1861\n",
            "Sample ID: 20895\n",
            "Decoded Input: What years have a duration of 18 years, and patrizio rispo as the actor?\n",
            "Decoded Target (Labels): SELECT years FROM table_name_26 WHERE duration = \"18 years\" AND actor = \"patrizio rispo\"\n",
            "\n",
            "Iteration/Step: 1862\n",
            "Sample ID: 1638\n",
            "Decoded Input: What was the attendance of the game that had an away team of FK Mogren?\n",
            "Decoded Target (Labels): SELECT attendance FROM table_name_89 WHERE guest = \"fk mogren\"\n",
            "\n",
            "Iteration/Step: 1862\n",
            "Sample ID: 15452\n",
            "Decoded Input: How many viewers in millions watched the episode with the production code 6acx16?\n",
            "Decoded Target (Labels): SELECT us_viewers__million_ FROM table_22261877_1 WHERE production_code = \"6ACX16\"\n",
            "\n",
            "Iteration/Step: 1863\n",
            "Sample ID: 3624\n",
            "Decoded Input: What is the score against the indians after game 2?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_76 WHERE game > 2 AND opponent = \"indians\"\n",
            "\n",
            "Iteration/Step: 1863\n",
            "Sample ID: 10445\n",
            "Decoded Input: What year had a league position of 8/12?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_63 WHERE league_position = \"8/12\"\n",
            "\n",
            "Iteration/Step: 1864\n",
            "Sample ID: 9338\n",
            "Decoded Input: What is the high grid with 27 laps?\n",
            "Decoded Target (Labels): SELECT MAX(grid) FROM table_name_89 WHERE laps = 27\n",
            "\n",
            "Iteration/Step: 1864\n",
            "Sample ID: 17101\n",
            "Decoded Input: What the number of matches when the BBI is 3/27?\n",
            "Decoded Target (Labels): SELECT MIN(matches) FROM table_28846752_9 WHERE bbi = \"3/27\"\n",
            "\n",
            "Iteration/Step: 1865\n",
            "Sample ID: 3136\n",
            "Decoded Input: Who played mens doubles for the 1999 kobe tour?\n",
            "Decoded Target (Labels): SELECT mens_doubles FROM table_28138035_20 WHERE year_location = \"1999 Kobe\"\n",
            "\n",
            "Iteration/Step: 1865\n",
            "Sample ID: 23400\n",
            "Decoded Input: What did United States score in the place t6?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_21 WHERE country = \"united states\" AND place = \"t6\"\n",
            "\n",
            "Iteration/Step: 1866\n",
            "Sample ID: 7884\n",
            "Decoded Input: What are airlines that have some flight departing from airport 'AHD'?\n",
            "Decoded Target (Labels): SELECT T1.Airline FROM AIRLINES AS T1 JOIN FLIGHTS AS T2 ON T1.uid = T2.Airline WHERE T2.SourceAirport = \"AHD\"\n",
            "\n",
            "Iteration/Step: 1866\n",
            "Sample ID: 25854\n",
            "Decoded Input: What is the highest number of bronze medals for nations with under 0 golds?\n",
            "Decoded Target (Labels): SELECT MAX(bronze) FROM table_name_46 WHERE gold < 0\n",
            "\n",
            "Iteration/Step: 1867\n",
            "Sample ID: 3427\n",
            "Decoded Input: What are the manuals with an opus of 147?\n",
            "Decoded Target (Labels): SELECT manuals FROM table_name_2 WHERE opus = \"147\"\n",
            "\n",
            "Iteration/Step: 1867\n",
            "Sample ID: 459\n",
            "Decoded Input: What name that has a DCSF number bigger than 2448 and an Ofsted number of 131319?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_95 WHERE dcsf_number > 2448 AND ofsted_number = 131319\n",
            "\n",
            "Iteration/Step: 1868\n",
            "Sample ID: 24012\n",
            "Decoded Input: Which runner-up has a 10 strokes margin of victory?\n",
            "Decoded Target (Labels): SELECT runner_up FROM table_name_12 WHERE margin_of_victory = \"10 strokes\"\n",
            "\n",
            "Iteration/Step: 1868\n",
            "Sample ID: 11860\n",
            "Decoded Input: On what dates did Jim Jarmusch win the Lifetime Achievement?\n",
            "Decoded Target (Labels): SELECT dates FROM table_name_27 WHERE lifetime_achievement = \"jim jarmusch\"\n",
            "\n",
            "Iteration/Step: 1869\n",
            "Sample ID: 25738\n",
            "Decoded Input: What club does Manuel Fernandes coach?\n",
            "Decoded Target (Labels): SELECT club FROM table_name_88 WHERE head_coach = \"manuel fernandes\"\n",
            "\n",
            "Iteration/Step: 1869\n",
            "Sample ID: 9965\n",
            "Decoded Input: Who were the middle school principal(s) in 2010-2011?\n",
            "Decoded Target (Labels): SELECT middle_school_principal FROM table_25037577_1 WHERE year = \"2010-2011\"\n",
            "\n",
            "Iteration/Step: 1870\n",
            "Sample ID: 4102\n",
            "Decoded Input: What is the lowest number of Gold the Nation of Italy had when it ranked other than 1, and had more than 0 Silver?\n",
            "Decoded Target (Labels): SELECT MIN(gold) FROM table_name_25 WHERE rank > 1 AND nation = \"italy\" AND silver > 0\n",
            "\n",
            "Iteration/Step: 1870\n",
            "Sample ID: 1094\n",
            "Decoded Input: what is the date when the opponent# is iowa?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_42 WHERE opponent_number = \"iowa\"\n",
            "\n",
            "Iteration/Step: 1871\n",
            "Sample ID: 20750\n",
            "Decoded Input: Who was the GT2 winning team when the GT3 winning team was #1 PTG?\n",
            "Decoded Target (Labels): SELECT gt2_winning_team FROM table_11875915_2 WHERE gt3_winning_team = \"#1 PTG\"\n",
            "\n",
            "Iteration/Step: 1871\n",
            "Sample ID: 7335\n",
            "Decoded Input: Name the result for massachusetts 3\n",
            "Decoded Target (Labels): SELECT result FROM table_1341897_23 WHERE district = \"Massachusetts 3\"\n",
            "\n",
            "Iteration/Step: 1872\n",
            "Sample ID: 651\n",
            "Decoded Input: What is the height of the person that weighs 320 pounds?\n",
            "Decoded Target (Labels): SELECT height FROM table_10966926_2 WHERE weight = 320\n",
            "\n",
            "Iteration/Step: 1872\n",
            "Sample ID: 3103\n",
            "Decoded Input: What launched has 158 days (5 months, 8 days) as the time elapsed?\n",
            "Decoded Target (Labels): SELECT launched FROM table_name_91 WHERE time_elapsed = \"158 days (5 months, 8 days)\"\n",
            "\n",
            "Iteration/Step: 1873\n",
            "Sample ID: 17507\n",
            "Decoded Input: What was the crowd when the away team is footscray?\n",
            "Decoded Target (Labels): SELECT crowd FROM table_name_26 WHERE away_team = \"footscray\"\n",
            "\n",
            "Iteration/Step: 1873\n",
            "Sample ID: 7508\n",
            "Decoded Input: What club/province has 41 caps?\n",
            "Decoded Target (Labels): SELECT club_province FROM table_name_66 WHERE caps = 41\n",
            "\n",
            "Iteration/Step: 1874\n",
            "Sample ID: 17284\n",
            "Decoded Input: Name the number of februaries\n",
            "Decoded Target (Labels): SELECT COUNT(february) FROM table_1539201_1\n",
            "\n",
            "Iteration/Step: 1874\n",
            "Sample ID: 6333\n",
            "Decoded Input: Tell me the attendance with a result of l 26–3\n",
            "Decoded Target (Labels): SELECT attendance FROM table_name_12 WHERE result = \"l 26–3\"\n",
            "\n",
            "Iteration/Step: 1875\n",
            "Sample ID: 9550\n",
            "Decoded Input: Did the nominated work of white valentine win an award?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_61 WHERE nominated_work = \"white valentine\"\n",
            "\n",
            "Iteration/Step: 1875\n",
            "Sample ID: 19923\n",
            "Decoded Input: What is the Portuguese word for the English word 'grandfather'?\n",
            "Decoded Target (Labels): SELECT portuguese FROM table_26614365_5 WHERE english = \"Grandfather\"\n",
            "\n",
            "Iteration/Step: 1876\n",
            "Sample ID: 12212\n",
            "Decoded Input: what is the number of points when the place is less than 7, the draw is more than 2 and the artist is piece of cake?\n",
            "Decoded Target (Labels): SELECT COUNT(points) FROM table_name_76 WHERE place < 7 AND draw > 2 AND artist = \"piece of cake\"\n",
            "\n",
            "Iteration/Step: 1876\n",
            "Sample ID: 6157\n",
            "Decoded Input: The UFC 44 event has what method?\n",
            "Decoded Target (Labels): SELECT method FROM table_name_98 WHERE event = \"ufc 44\"\n",
            "\n",
            "Iteration/Step: 1877\n",
            "Sample ID: 17519\n",
            "Decoded Input: What is the sambalpuri saree with a samaleswari temple as sambalpuri language?\n",
            "Decoded Target (Labels): SELECT sambalpuri_saree FROM table_name_22 WHERE sambalpuri_language = \"samaleswari temple\"\n",
            "\n",
            "Iteration/Step: 1877\n",
            "Sample ID: 21455\n",
            "Decoded Input: What is the first name and last name of the customer that has email \"luisg@embraer.com.br\"?\n",
            "Decoded Target (Labels): SELECT FirstName, LastName FROM CUSTOMER WHERE Email = \"luisg@embraer.com.br\"\n",
            "\n",
            "Iteration/Step: 1878\n",
            "Sample ID: 24606\n",
            "Decoded Input: If the grand total is 5814, what is the total non qatar?\n",
            "Decoded Target (Labels): SELECT total_non_qatar FROM table_26214389_3 WHERE grand_total = 5814\n",
            "\n",
            "Iteration/Step: 1878\n",
            "Sample ID: 14384\n",
            "Decoded Input: What is Place, when Prize is \"$381.030\"?\n",
            "Decoded Target (Labels): SELECT place FROM table_name_32 WHERE prize = \"$381.030\"\n",
            "\n",
            "Iteration/Step: 1879\n",
            "Sample ID: 19100\n",
            "Decoded Input: How many republican incumbents first elected in 1974?\n",
            "Decoded Target (Labels): SELECT COUNT(incumbent) FROM table_1341522_41 WHERE party = \"Republican\" AND first_elected = 1974\n",
            "\n",
            "Iteration/Step: 1879\n",
            "Sample ID: 17424\n",
            "Decoded Input: What is the sum of Against, when Status is \"Six Nations\", and when Date is \"30/03/2003\"?\n",
            "Decoded Target (Labels): SELECT SUM(against) FROM table_name_20 WHERE status = \"six nations\" AND date = \"30/03/2003\"\n",
            "\n",
            "Iteration/Step: 1880\n",
            "Sample ID: 22988\n",
            "Decoded Input: Name the date that is a cd\n",
            "Decoded Target (Labels): SELECT date FROM table_name_81 WHERE format = \"cd\"\n",
            "\n",
            "Iteration/Step: 1880\n",
            "Sample ID: 5097\n",
            "Decoded Input: Where was the game played that started at 7:00 p.m.?\n",
            "Decoded Target (Labels): SELECT game_site FROM table_24396664_2 WHERE kickoff = \"7:00 p.m.\"\n",
            "\n",
            "Iteration/Step: 1881\n",
            "Sample ID: 13652\n",
            "Decoded Input: What is the id and detail of the vehicle used in lessons for most of the times?\n",
            "Decoded Target (Labels): SELECT T1.vehicle_id, T1.vehicle_details FROM Vehicles AS T1 JOIN Lessons AS T2 ON T1.vehicle_id = T2.vehicle_id GROUP BY T1.vehicle_id ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 1881\n",
            "Sample ID: 5696\n",
            "Decoded Input: Show the number of trains\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM train\n",
            "\n",
            "Iteration/Step: 1882\n",
            "Sample ID: 5434\n",
            "Decoded Input: What is the average rating stars and title for the oldest movie?\n",
            "Decoded Target (Labels): SELECT AVG(T1.stars), T2.title FROM Rating AS T1 JOIN Movie AS T2 ON T1.mID = T2.mID WHERE T2.year = (SELECT MIN(YEAR) FROM Movie)\n",
            "\n",
            "Iteration/Step: 1882\n",
            "Sample ID: 8635\n",
            "Decoded Input: What is the name, location and seating for the most recently opened track?\n",
            "Decoded Target (Labels): SELECT name, LOCATION, seating FROM track ORDER BY year_opened DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 1883\n",
            "Sample ID: 19809\n",
            "Decoded Input: What is Pronunciation Spelled Free, when Pronunciation Spelled Checked is \"ɑ\"?\n",
            "Decoded Target (Labels): SELECT pronunciation_spelled_free FROM table_name_24 WHERE pronunciation_spelled_checked = \"ɑ\"\n",
            "\n",
            "Iteration/Step: 1883\n",
            "Sample ID: 15146\n",
            "Decoded Input: How many positions were given when 30 points were won? \n",
            "Decoded Target (Labels): SELECT COUNT(position) FROM table_24330803_1 WHERE points = \"30\"\n",
            "\n",
            "Iteration/Step: 1884\n",
            "Sample ID: 1041\n",
            "Decoded Input: Who was the opponent of the game with final score won 4-1?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_17120964_8 WHERE result = \"Won 4-1\"\n",
            "\n",
            "Iteration/Step: 1884\n",
            "Sample ID: 2781\n",
            "Decoded Input: what is the maximum number of hull numbers?\n",
            "Decoded Target (Labels): SELECT MAX(hull_numbers) FROM table_12232526_2\n",
            "\n",
            "Iteration/Step: 1885\n",
            "Sample ID: 17769\n",
            "Decoded Input: Which engine has daimler benz ag as an entrant?\n",
            "Decoded Target (Labels): SELECT engine FROM table_name_7 WHERE entrant = \"daimler benz ag\"\n",
            "\n",
            "Iteration/Step: 1885\n",
            "Sample ID: 1331\n",
            "Decoded Input: Who was the opponent at the game attended by 45,000?\n",
            "Decoded Target (Labels): SELECT opponent_number FROM table_name_73 WHERE attendance = \"45,000\"\n",
            "\n",
            "Iteration/Step: 1886\n",
            "Sample ID: 5679\n",
            "Decoded Input: Round of 9 involved what name?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_67 WHERE round = 9\n",
            "\n",
            "Iteration/Step: 1886\n",
            "Sample ID: 14684\n",
            "Decoded Input: Which venue has 16 against?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_5 WHERE against = 16\n",
            "\n",
            "Iteration/Step: 1887\n",
            "Sample ID: 12438\n",
            "Decoded Input: What is the highest 1937 value that has a 1940 value over 126?\n",
            "Decoded Target (Labels): SELECT MAX(1937) FROM table_name_60 WHERE 1940 > 126\n",
            "\n",
            "Iteration/Step: 1887\n",
            "Sample ID: 12435\n",
            "Decoded Input: What was the date that a player went to the club Doncaster Rovers?\n",
            "Decoded Target (Labels): SELECT exit_date FROM table_name_14 WHERE to_club = \"doncaster rovers\"\n",
            "\n",
            "Iteration/Step: 1888\n",
            "Sample ID: 16804\n",
            "Decoded Input: What classifications does Fish Rap live! has?\n",
            "Decoded Target (Labels): SELECT classification FROM table_2266990_2 WHERE title = \"Fish Rap Live!\"\n",
            "\n",
            "Iteration/Step: 1888\n",
            "Sample ID: 6854\n",
            "Decoded Input: how many areas have townland as kilgilky north?\n",
            "Decoded Target (Labels): SELECT COUNT(area__acres__) FROM table_30120560_1 WHERE townland = \"Kilgilky North\"\n",
            "\n",
            "Iteration/Step: 1889\n",
            "Sample ID: 15450\n",
            "Decoded Input: What is the venue for the friendly competition and score of 4-0?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_53 WHERE score = \"4-0\" AND competition = \"friendly\"\n",
            "\n",
            "Iteration/Step: 1889\n",
            "Sample ID: 5404\n",
            "Decoded Input: Name The Title which has a Track number of 07, and a Record label of emi on 21 april 2006?\n",
            "Decoded Target (Labels): SELECT title FROM table_name_73 WHERE track_number = \"07\" AND record_label = \"emi\" AND release_date = \"21 april 2006\"\n",
            "\n",
            "Iteration/Step: 1890\n",
            "Sample ID: 13075\n",
            "Decoded Input: What is the prothrombin time in Von willebrand disease?\n",
            "Decoded Target (Labels): SELECT prothrombin_time FROM table_1557752_1 WHERE condition = \"Von Willebrand disease\"\n",
            "\n",
            "Iteration/Step: 1890\n",
            "Sample ID: 16758\n",
            "Decoded Input: What is the name of the driver of the vehicle constructed by Bugatti in Anfa?\n",
            "Decoded Target (Labels): SELECT driver FROM table_name_2 WHERE constructor = \"bugatti\" AND location = \"anfa\"\n",
            "\n",
            "Iteration/Step: 1891\n",
            "Sample ID: 25325\n",
            "Decoded Input: When was the attendance at a venue bigger than 35,151?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_36 WHERE crowd > 35 OFFSET 151\n",
            "\n",
            "Iteration/Step: 1891\n",
            "Sample ID: 8377\n",
            "Decoded Input: What event placed bronze earlier than 1987?\n",
            "Decoded Target (Labels): SELECT event FROM table_name_16 WHERE placed = \"bronze\" AND year < 1987\n",
            "\n",
            "Iteration/Step: 1892\n",
            "Sample ID: 22617\n",
            "Decoded Input: What is the engine configuration of the 1.2 mpi engine?\n",
            "Decoded Target (Labels): SELECT engine_configuration FROM table_name_80 WHERE engine_name = \"1.2 mpi\"\n",
            "\n",
            "Iteration/Step: 1892\n",
            "Sample ID: 10868\n",
            "Decoded Input: What is the most recent year for a first elected republican?\n",
            "Decoded Target (Labels): SELECT MAX(first_elected) FROM table_name_36 WHERE party = \"republican\"\n",
            "\n",
            "Iteration/Step: 1893\n",
            "Sample ID: 10078\n",
            "Decoded Input: what country has dubai\n",
            "Decoded Target (Labels): SELECT country FROM table_name_89 WHERE town = \"dubai\"\n",
            "\n",
            "Iteration/Step: 1893\n",
            "Sample ID: 10032\n",
            "Decoded Input: What is the score of the game with Falkirk as the runner-up?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_48 WHERE runner_up = \"falkirk\"\n",
            "\n",
            "Iteration/Step: 1894\n",
            "Sample ID: 17093\n",
            "Decoded Input: What was the round that had 32 winners from previous round?\n",
            "Decoded Target (Labels): SELECT round FROM table_28039032_1 WHERE winners_from_previous_round = \"32\"\n",
            "\n",
            "Iteration/Step: 1894\n",
            "Sample ID: 3203\n",
            "Decoded Input: What is the total number of votes from the Labour Party?\n",
            "Decoded Target (Labels): SELECT COUNT(votes) FROM table_name_23 WHERE party = \"labour\"\n",
            "\n",
            "Iteration/Step: 1895\n",
            "Sample ID: 9227\n",
            "Decoded Input: What day was the grand prix in jerez?\n",
            "Decoded Target (Labels): SELECT date FROM table_1139087_2 WHERE location = \"Jerez\"\n",
            "\n",
            "Iteration/Step: 1895\n",
            "Sample ID: 17082\n",
            "Decoded Input: Name the total number of places which has played more than 18\n",
            "Decoded Target (Labels): SELECT COUNT(place) FROM table_name_59 WHERE played > 18\n",
            "\n",
            "Iteration/Step: 1896\n",
            "Sample ID: 24310\n",
            "Decoded Input: What  us the conjucated form(s)  of  el/ella/ usted when the Vos (*) is muelas / molás?\n",
            "Decoded Target (Labels): SELECT él___ella___usted FROM table_1977630_2 WHERE vos__ * _ = \"muelas / molás\"\n",
            "\n",
            "Iteration/Step: 1896\n",
            "Sample ID: 14663\n",
            "Decoded Input: When did stage 5 occur?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_53 WHERE stage = 5\n",
            "\n",
            "Iteration/Step: 1897\n",
            "Sample ID: 20488\n",
            "Decoded Input: Who did Tony Oakey win against when he had type of w pts 12?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_54 WHERE result = \"win\" AND type = \"w pts 12\"\n",
            "\n",
            "Iteration/Step: 1897\n",
            "Sample ID: 23880\n",
            "Decoded Input: What was the location and attendance for the game on December 12?\n",
            "Decoded Target (Labels): SELECT location_attendance FROM table_name_68 WHERE date = \"december 12\"\n",
            "\n",
            "Iteration/Step: 1898\n",
            "Sample ID: 21524\n",
            "Decoded Input: Tell me the total receipts for tom tancredo\n",
            "Decoded Target (Labels): SELECT total_receipts FROM table_name_44 WHERE candidate = \"tom tancredo\"\n",
            "\n",
            "Iteration/Step: 1898\n",
            "Sample ID: 17034\n",
            "Decoded Input: what is the course at midlothian, illinois for a year before 1934?\n",
            "Decoded Target (Labels): SELECT course FROM table_name_98 WHERE year < 1934 AND location = \"midlothian, illinois\"\n",
            "\n",
            "Iteration/Step: 1899\n",
            "Sample ID: 7826\n",
            "Decoded Input: What is the production code for the episode that had 1.32 million U.S. viewers?\n",
            "Decoded Target (Labels): SELECT production_code FROM table_22347090_6 WHERE us_viewers__million_ = \"1.32\"\n",
            "\n",
            "Iteration/Step: 1899\n",
            "Sample ID: 6848\n",
            "Decoded Input: What season was won by Anthony Yeh?\n",
            "Decoded Target (Labels): SELECT season FROM table_20026849_1 WHERE winner = \"Anthony Yeh\"\n",
            "\n",
            "Iteration/Step: 1900\n",
            "Sample ID: 15755\n",
            "Decoded Input: Name the common name for chironius multiventris septentrionalis\n",
            "Decoded Target (Labels): SELECT common_name FROM table_1850282_7 WHERE species = \"Chironius multiventris septentrionalis\"\n",
            "\n",
            "Iteration/Step: 1900\n",
            "Sample ID: 5312\n",
            "Decoded Input: How many attempts did Charles White make?\n",
            "Decoded Target (Labels): SELECT MIN(attempts) FROM table_11157122_5 WHERE player = \"Charles White\"\n",
            "\n",
            "Iteration/Step: 1901\n",
            "Sample ID: 22637\n",
            "Decoded Input: Which fleet launched on July 30, 1961?\n",
            "Decoded Target (Labels): SELECT fleet FROM table_name_63 WHERE launched = \"july 30, 1961\"\n",
            "\n",
            "Iteration/Step: 1901\n",
            "Sample ID: 301\n",
            "Decoded Input: Who came in 3rd place in 1990?\n",
            "Decoded Target (Labels): SELECT 3 AS rd_place FROM table_name_20 WHERE year = \"1990\"\n",
            "\n",
            "Iteration/Step: 1902\n",
            "Sample ID: 6641\n",
            "Decoded Input: What was the manner of departure for the manager of Cercle Brugge?\n",
            "Decoded Target (Labels): SELECT manner_of_departure FROM table_27374004_3 WHERE team = \"Cercle Brugge\"\n",
            "\n",
            "Iteration/Step: 1902\n",
            "Sample ID: 24159\n",
            "Decoded Input: Where is store 1 located?\n",
            "Decoded Target (Labels): SELECT T2.address FROM store AS T1 JOIN address AS T2 ON T1.address_id = T2.address_id WHERE store_id = 1\n",
            "\n",
            "Iteration/Step: 1903\n",
            "Sample ID: 13313\n",
            "Decoded Input: What compound is yellow?\n",
            "Decoded Target (Labels): SELECT compound_name FROM table_name_2 WHERE colour = \"yellow\"\n",
            "\n",
            "Iteration/Step: 1903\n",
            "Sample ID: 1686\n",
            "Decoded Input: What was the highest number on money list rank for Angela Stanford's career?\n",
            "Decoded Target (Labels): SELECT MAX(money_list_rank) FROM table_14836185_3\n",
            "\n",
            "Iteration/Step: 1904\n",
            "Sample ID: 23440\n",
            "Decoded Input: What is the sum of the earnings for rank 3?\n",
            "Decoded Target (Labels): SELECT SUM(earnings__) AS $__ FROM table_name_39 WHERE rank = 3\n",
            "\n",
            "Iteration/Step: 1904\n",
            "Sample ID: 6453\n",
            "Decoded Input: What is the Decile number for St Mary's Catholic School?\n",
            "Decoded Target (Labels): SELECT decile FROM table_name_33 WHERE name = \"st mary's catholic school\"\n",
            "\n",
            "Iteration/Step: 1905\n",
            "Sample ID: 25083\n",
            "Decoded Input: how many times is the fuel propulsion is cng?\n",
            "Decoded Target (Labels): SELECT COUNT(fleet_series__quantity_) FROM table_10007452_3 WHERE fuel_propulsion = \"CNG\"\n",
            "\n",
            "Iteration/Step: 1905\n",
            "Sample ID: 8271\n",
            "Decoded Input: How many FA cup goals have Jimmy Nicholson as the name, and league cup goals greater than 0?\n",
            "Decoded Target (Labels): SELECT COUNT(fa_cup_goals) FROM table_name_41 WHERE name = \"jimmy nicholson\" AND league_cup_goals > 0\n",
            "\n",
            "Iteration/Step: 1906\n",
            "Sample ID: 22513\n",
            "Decoded Input: How many students did not have any course enrollment?\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM Students WHERE NOT student_id IN (SELECT student_id FROM Student_Course_Enrolment)\n",
            "\n",
            "Iteration/Step: 1906\n",
            "Sample ID: 22537\n",
            "Decoded Input: What year was 7th heaven made?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_24 WHERE film = \"7th heaven\"\n",
            "\n",
            "Iteration/Step: 1907\n",
            "Sample ID: 10716\n",
            "Decoded Input: What frame size has pcm 4 ch/16 bit/48khz as audio coding and dvcam as the format name and 4:1:1 as the color sampling?\n",
            "Decoded Target (Labels): SELECT frame_size FROM table_name_44 WHERE audio_coding = \"pcm 4 ch/16 bit/48khz\" AND format_name = \"dvcam\" AND color_sampling = \"4:1:1\"\n",
            "\n",
            "Iteration/Step: 1907\n",
            "Sample ID: 3205\n",
            "Decoded Input: What is was Date that where Triple was smaller than 26, and Game was 25?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_84 WHERE triple < 26 AND game = 25\n",
            "\n",
            "Iteration/Step: 1908\n",
            "Sample ID: 2879\n",
            "Decoded Input: What was the away team at mcg?\n",
            "Decoded Target (Labels): SELECT away_team FROM table_name_44 WHERE venue = \"mcg\"\n",
            "\n",
            "Iteration/Step: 1908\n",
            "Sample ID: 12208\n",
            "Decoded Input: What is the date of the game when the opponent is the Cleveland Browns?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_98 WHERE opponent = \"cleveland browns\"\n",
            "\n",
            "Iteration/Step: 1909\n",
            "Sample ID: 10420\n",
            "Decoded Input: Who was the opponent at the game when the record was 54-58?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_13 WHERE record = \"54-58\"\n",
            "\n",
            "Iteration/Step: 1909\n",
            "Sample ID: 4076\n",
            "Decoded Input: Elevation of 11,158 feet 3401 m had what route?\n",
            "Decoded Target (Labels): SELECT route FROM table_name_85 WHERE elevation = \"11,158 feet 3401 m\"\n",
            "\n",
            "Iteration/Step: 1910\n",
            "Sample ID: 18078\n",
            "Decoded Input: how many match points rotherham lose\n",
            "Decoded Target (Labels): SELECT match_points FROM table_27987767_2 WHERE losers = \"Rotherham\"\n",
            "\n",
            "Iteration/Step: 1910\n",
            "Sample ID: 11971\n",
            "Decoded Input: What is the weight and dimensions of an N800?\n",
            "Decoded Target (Labels): SELECT weight, _dimensions FROM table_name_42 WHERE model = \"n800\"\n",
            "\n",
            "Iteration/Step: 1911\n",
            "Sample ID: 8943\n",
            "Decoded Input: What was the total amount of matches for Alan Shearer?\n",
            "Decoded Target (Labels): SELECT COUNT(matches) FROM table_name_81 WHERE name = \"alan shearer\"\n",
            "\n",
            "Iteration/Step: 1911\n",
            "Sample ID: 23347\n",
            "Decoded Input: Which positions are the poles 2?\n",
            "Decoded Target (Labels): SELECT position FROM table_22056184_1 WHERE poles = 2\n",
            "\n",
            "Iteration/Step: 1912\n",
            "Sample ID: 13204\n",
            "Decoded Input: Name the maximum discs\n",
            "Decoded Target (Labels): SELECT MAX(discs) FROM table_14562722_2\n",
            "\n",
            "Iteration/Step: 1912\n",
            "Sample ID: 421\n",
            "Decoded Input: What  South Dakota has Bush of Oklahoma?\n",
            "Decoded Target (Labels): SELECT south_dakota FROM table_name_17 WHERE oklahoma = \"bush\"\n",
            "\n",
            "Iteration/Step: 1913\n",
            "Sample ID: 10219\n",
            "Decoded Input: What is the gold when the total is less than 2, and rank is 3 and Canada is the nation?\n",
            "Decoded Target (Labels): SELECT gold FROM table_name_29 WHERE total < 2 AND rank = 3 AND nation = \"canada\"\n",
            "\n",
            "Iteration/Step: 1913\n",
            "Sample ID: 10537\n",
            "Decoded Input: Who directed the Romanian film?\n",
            "Decoded Target (Labels): SELECT director FROM table_name_60 WHERE language = \"romanian\"\n",
            "\n",
            "Iteration/Step: 1914\n",
            "Sample ID: 898\n",
            "Decoded Input: Name the number of opponent with arrowhead stadium\n",
            "Decoded Target (Labels): SELECT COUNT(opponent) FROM table_13258823_2 WHERE game_site = \"Arrowhead Stadium\"\n",
            "\n",
            "Iteration/Step: 1914\n",
            "Sample ID: 1760\n",
            "Decoded Input: What race is in the 5th position?\n",
            "Decoded Target (Labels): SELECT race FROM table_name_61 WHERE position = \"5th\"\n",
            "\n",
            "Iteration/Step: 1915\n",
            "Sample ID: 24439\n",
            "Decoded Input: What is the date of appointment for the date of vacancy of 22 august 2010?\n",
            "Decoded Target (Labels): SELECT date_of_appointment FROM table_26976615_3 WHERE date_of_vacancy = \"22 August 2010\"\n",
            "\n",
            "Iteration/Step: 1915\n",
            "Sample ID: 19880\n",
            "Decoded Input: What Team had less than 1 point with a Zakspeed 871 chassis?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_44 WHERE points < 1 AND chassis = \"zakspeed 871\"\n",
            "\n",
            "Iteration/Step: 1916\n",
            "Sample ID: 6647\n",
            "Decoded Input: What is the smallest number of gold of a country of rank 6, with 2 bronzes?\n",
            "Decoded Target (Labels): SELECT MIN(gold) FROM table_name_71 WHERE bronze = 2 AND rank = 6 AND total > 2\n",
            "\n",
            "Iteration/Step: 1916\n",
            "Sample ID: 11611\n",
            "Decoded Input: What is the name of the episode that had 9.89 million U.S. viewers?\n",
            "Decoded Target (Labels): SELECT title FROM table_24648983_1 WHERE us_viewers__million_ = \"9.89\"\n",
            "\n",
            "Iteration/Step: 1917\n",
            "Sample ID: 14792\n",
            "Decoded Input: what is the period if the player is Hashan Tillakaratne?\n",
            "Decoded Target (Labels): SELECT period FROM table_26041144_16 WHERE player = \"Hashan Tillakaratne\"\n",
            "\n",
            "Iteration/Step: 1917\n",
            "Sample ID: 10202\n",
            "Decoded Input: What is the bore for a 9-cyl radial on a 9 AD?\n",
            "Decoded Target (Labels): SELECT bore FROM table_name_8 WHERE cyl = \"9-cyl radial\" AND name = \"9 ad\"\n",
            "\n",
            "Iteration/Step: 1918\n",
            "Sample ID: 11208\n",
            "Decoded Input: Find the codes of countries that have more than 50 players.\n",
            "Decoded Target (Labels): SELECT country_code FROM players GROUP BY country_code HAVING COUNT(*) > 50\n",
            "\n",
            "Iteration/Step: 1918\n",
            "Sample ID: 23684\n",
            "Decoded Input: What venue had an away team of south melbourne?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_32 WHERE away_team = \"south melbourne\"\n",
            "\n",
            "Iteration/Step: 1919\n",
            "Sample ID: 1143\n",
            "Decoded Input: Which player has a total of 8 (24)?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_8 WHERE total = \"8 (24)\"\n",
            "\n",
            "Iteration/Step: 1919\n",
            "Sample ID: 11272\n",
            "Decoded Input: What is the total for a top-10 in a masters tournament in an event smaller than 4?\n",
            "Decoded Target (Labels): SELECT COUNT(top_10) FROM table_name_52 WHERE tournament = \"masters tournament\" AND events < 4\n",
            "\n",
            "Iteration/Step: 1920\n",
            "Sample ID: 5511\n",
            "Decoded Input: What is the Record of the 1991 Port of Spain Games?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_56 WHERE games = \"1991 port of spain\"\n",
            "\n",
            "Iteration/Step: 1920\n",
            "Sample ID: 5156\n",
            "Decoded Input: How many budget types do we have?\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM Ref_budget_codes\n",
            "\n",
            "Iteration/Step: 1921\n",
            "Sample ID: 21764\n",
            "Decoded Input: How many number in series's are written by Greg Haddrick?\n",
            "Decoded Target (Labels): SELECT COUNT(no_in_series) FROM table_21666472_1 WHERE written_by = \"Greg Haddrick\"\n",
            "\n",
            "Iteration/Step: 1921\n",
            "Sample ID: 9765\n",
            "Decoded Input: What is the result of the game on April 17 against Los Angeles?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_42 WHERE road_team = \"los angeles\" AND date = \"april 17\"\n",
            "\n",
            "Iteration/Step: 1922\n",
            "Sample ID: 6937\n",
            "Decoded Input: What is Replaced By, when Date of Vacancy is \"23 February 2009\"?\n",
            "Decoded Target (Labels): SELECT replaced_by FROM table_name_68 WHERE date_of_vacancy = \"23 february 2009\"\n",
            "\n",
            "Iteration/Step: 1922\n",
            "Sample ID: 11410\n",
            "Decoded Input: what is the pts/game for Charlotte barras and the games is 5?\n",
            "Decoded Target (Labels): SELECT pts_game FROM table_name_78 WHERE games = 5 AND name = \"charlotte barras\"\n",
            "\n",
            "Iteration/Step: 1923\n",
            "Sample ID: 3782\n",
            "Decoded Input: What is the average rank for 57.05 time?\n",
            "Decoded Target (Labels): SELECT AVG(rank) FROM table_name_61 WHERE time < 57.05\n",
            "\n",
            "Iteration/Step: 1923\n",
            "Sample ID: 19817\n",
            "Decoded Input: If the time on Wed aug 25 was 20' 09.25 112.324mph, what was the time on sat Aug 28?\n",
            "Decoded Target (Labels): SELECT sat_28_aug FROM table_26986076_1 WHERE wed_25_aug = \"20' 09.25 112.324mph\"\n",
            "\n",
            "Iteration/Step: 1924\n",
            "Sample ID: 24008\n",
            "Decoded Input: What rider is on an aprilia that went under 18 laps with a grid total of 17?\n",
            "Decoded Target (Labels): SELECT rider FROM table_name_14 WHERE manufacturer = \"aprilia\" AND laps < 18 AND grid = 17\n",
            "\n",
            "Iteration/Step: 1924\n",
            "Sample ID: 25052\n",
            "Decoded Input: What is the geo id when water is 0.457?\n",
            "Decoded Target (Labels): SELECT MIN(geo_id) FROM table_18600760_12 WHERE water__sqmi_ = \"0.457\"\n",
            "\n",
            "Iteration/Step: 1925\n",
            "Sample ID: 8963\n",
            "Decoded Input: How many bronzes did netherlands win?\n",
            "Decoded Target (Labels): SELECT bronze FROM table_name_9 WHERE nation = \"netherlands\"\n",
            "\n",
            "Iteration/Step: 1925\n",
            "Sample ID: 9307\n",
            "Decoded Input: Who had the fastest lap when Al Unser won?\n",
            "Decoded Target (Labels): SELECT fastest_lap FROM table_name_40 WHERE winning_driver = \"al unser\"\n",
            "\n",
            "Iteration/Step: 1926\n",
            "Sample ID: 23874\n",
            "Decoded Input: What was the delivery date of Congresswoman Kirsten Gillibrand's baby boy?\n",
            "Decoded Target (Labels): SELECT date_of_delivery FROM table_name_55 WHERE baby_gender = \"boy\" AND congresswoman = \"kirsten gillibrand\"\n",
            "\n",
            "Iteration/Step: 1926\n",
            "Sample ID: 386\n",
            "Decoded Input: What is the total area of drakenstein and a population less than 251,262?\n",
            "Decoded Target (Labels): SELECT COUNT(area__km_2__) FROM table_name_32 WHERE name = \"drakenstein\" AND population__2011_ < 251 OFFSET 262\n",
            "\n",
            "Iteration/Step: 1927\n",
            "Sample ID: 9939\n",
            "Decoded Input: Who were the batsmen paired for wicket 7?\n",
            "Decoded Target (Labels): SELECT batsmen FROM table_name_83 WHERE wicket = \"7\"\n",
            "\n",
            "Iteration/Step: 1927\n",
            "Sample ID: 14965\n",
            "Decoded Input: What is the Political group for p. maelius capitolinus?\n",
            "Decoded Target (Labels): SELECT political_group FROM table_name_58 WHERE name = \"p. maelius capitolinus\"\n",
            "\n",
            "Iteration/Step: 1928\n",
            "Sample ID: 5021\n",
            "Decoded Input: What date has 9 as the week?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_21 WHERE week = 9\n",
            "\n",
            "Iteration/Step: 1928\n",
            "Sample ID: 8622\n",
            "Decoded Input: What number corresponds to Presidet Yves Krattinger of the Socialist party?\n",
            "Decoded Target (Labels): SELECT number FROM table_name_14 WHERE party = \"socialist party\" AND président = \"yves krattinger\"\n",
            "\n",
            "Iteration/Step: 1929\n",
            "Sample ID: 23727\n",
            "Decoded Input: what is the lowest played when the position is more than 9?\n",
            "Decoded Target (Labels): SELECT MIN(played) FROM table_name_76 WHERE position > 9\n",
            "\n",
            "Iteration/Step: 1929\n",
            "Sample ID: 22191\n",
            "Decoded Input: Which College has a Pick # larger than 25, and a Round of 7, and a Name of chris white?\n",
            "Decoded Target (Labels): SELECT college FROM table_name_13 WHERE pick__number > 25 AND round = 7 AND name = \"chris white\"\n",
            "\n",
            "Iteration/Step: 1930\n",
            "Sample ID: 21727\n",
            "Decoded Input: Name the most year when population of woocoo is 2700\n",
            "Decoded Target (Labels): SELECT MAX(year) FROM table_12576536_1 WHERE population__woocoo_ = 2700\n",
            "\n",
            "Iteration/Step: 1930\n",
            "Sample ID: 6785\n",
            "Decoded Input: What week was the record 0-5?\n",
            "Decoded Target (Labels): SELECT week FROM table_name_96 WHERE record = \"0-5\"\n",
            "\n",
            "Iteration/Step: 1931\n",
            "Sample ID: 25188\n",
            "Decoded Input: What Rider had a Time of 1:01.50.57?\n",
            "Decoded Target (Labels): SELECT rider FROM table_name_46 WHERE time = \"1:01.50.57\"\n",
            "\n",
            "Iteration/Step: 1931\n",
            "Sample ID: 12483\n",
            "Decoded Input: What is the score of the game on February 26 with the Chicago black hawks as the home team and the New York Rangers as the visitor team?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_59 WHERE home = \"chicago black hawks\" AND visitor = \"new york rangers\" AND date = \"february 26\"\n",
            "\n",
            "Iteration/Step: 1932\n",
            "Sample ID: 22283\n",
            "Decoded Input: How many times is vuelta wins when points is more than 0, country is spain and the name is josé pérez-francés?\n",
            "Decoded Target (Labels): SELECT COUNT(vuelta_wins) FROM table_name_67 WHERE points > 0 AND country = \"spain\" AND name = \"josé pérez-francés\"\n",
            "\n",
            "Iteration/Step: 1932\n",
            "Sample ID: 22077\n",
            "Decoded Input: Why did Geninho leave as manager?\n",
            "Decoded Target (Labels): SELECT manner_of_departure FROM table_29414946_3 WHERE outgoing_manager = \"Geninho\"\n",
            "\n",
            "Iteration/Step: 1933\n",
            "Sample ID: 5869\n",
            "Decoded Input: How many of those who stayed in the southeast had 19,600 emigrated or forcibly removed?\n",
            "Decoded Target (Labels): SELECT number_stayed_in_southeast FROM table_name_58 WHERE total_number_emigrated_or_forcibly_removed = \"19,600\"\n",
            "\n",
            "Iteration/Step: 1933\n",
            "Sample ID: 16389\n",
            "Decoded Input: What is the Outcome in the Malaysia Open with Partner Yoo Sang-Hee?\n",
            "Decoded Target (Labels): SELECT outcome FROM table_name_81 WHERE partner = \"yoo sang-hee\" AND venue = \"malaysia open\"\n",
            "\n",
            "Iteration/Step: 1934\n",
            "Sample ID: 11085\n",
            "Decoded Input: Which years had a rank of more than 6 and involved Oleksandr Kosyrin?\n",
            "Decoded Target (Labels): SELECT years FROM table_name_7 WHERE rank > 6 AND name = \"oleksandr kosyrin\"\n",
            "\n",
            "Iteration/Step: 1934\n",
            "Sample ID: 18189\n",
            "Decoded Input: What is the call sign for country station fm 93.1?\n",
            "Decoded Target (Labels): SELECT call_sign FROM table_name_34 WHERE format = \"country\" AND frequency = \"fm 93.1\"\n",
            "\n",
            "Iteration/Step: 1935\n",
            "Sample ID: 13265\n",
            "Decoded Input: What season has a regionalliga süd league, a 1-0 home, and an away of 2-3?\n",
            "Decoded Target (Labels): SELECT season FROM table_name_38 WHERE league = \"regionalliga süd\" AND home = \"1-0\" AND away = \"2-3\"\n",
            "\n",
            "Iteration/Step: 1935\n",
            "Sample ID: 5628\n",
            "Decoded Input: what is the owner of the c501\n",
            "Decoded Target (Labels): SELECT owner FROM table_name_2 WHERE locomotive = \"c501\"\n",
            "\n",
            "Iteration/Step: 1936\n",
            "Sample ID: 9582\n",
            "Decoded Input: What Etymology ranked 12?\n",
            "Decoded Target (Labels): SELECT etymology FROM table_name_58 WHERE rank = 12\n",
            "\n",
            "Iteration/Step: 1936\n",
            "Sample ID: 12271\n",
            "Decoded Input: In what division was there a population density in km2 of 1,604.3 in 2011?\n",
            "Decoded Target (Labels): SELECT administrative_division FROM table_24027047_1 WHERE population_density___km²_2011_ = \"1,604.3\"\n",
            "\n",
            "Iteration/Step: 1937\n",
            "Sample ID: 18847\n",
            "Decoded Input: Where were the 2008 championships with a time of 7:56.90 held?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_3 WHERE meet = \"2008 championships\" AND time = \"7:56.90\"\n",
            "\n",
            "Iteration/Step: 1937\n",
            "Sample ID: 15221\n",
            "Decoded Input: What is the number of games played in the season before 2005?\n",
            "Decoded Target (Labels): SELECT SUM(played) FROM table_name_18 WHERE first_game < 2005\n",
            "\n",
            "Iteration/Step: 1938\n",
            "Sample ID: 7584\n",
            "Decoded Input: Which country is Jim Les from?\n",
            "Decoded Target (Labels): SELECT nationality FROM table_11545282_12 WHERE player = \"Jim Les\"\n",
            "\n",
            "Iteration/Step: 1938\n",
            "Sample ID: 3614\n",
            "Decoded Input: What was the language score when the reading score was 94.47?\n",
            "Decoded Target (Labels): SELECT language FROM table_2534578_1 WHERE reading = \"94.47\"\n",
            "\n",
            "Iteration/Step: 1939\n",
            "Sample ID: 21555\n",
            "Decoded Input: What is the Date when the label was alfa records, and a Catalog of alca-487?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_61 WHERE label = \"alfa records\" AND catalog = \"alca-487\"\n",
            "\n",
            "Iteration/Step: 1939\n",
            "Sample ID: 14480\n",
            "Decoded Input: Who was the incumbent for the election in 1978?\n",
            "Decoded Target (Labels): SELECT incumbent FROM table_27487712_1 WHERE elected = 1978\n",
            "\n",
            "Iteration/Step: 1940\n",
            "Sample ID: 18045\n",
            "Decoded Input: Who directed the episode that aired on july15,2012?\n",
            "Decoded Target (Labels): SELECT directed_by FROM table_20704243_6 WHERE original_air_date = \"July15,2012\"\n",
            "\n",
            "Iteration/Step: 1940\n",
            "Sample ID: 18552\n",
            "Decoded Input: Name the original airdate for mr. buckston\n",
            "Decoded Target (Labels): SELECT original_airdate FROM table_name_23 WHERE identity_ies_ = \"mr. buckston\"\n",
            "\n",
            "Iteration/Step: 1941\n",
            "Sample ID: 21964\n",
            "Decoded Input: Which opponent has 36102 is the attendance?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_23466021_4 WHERE attendance = 36102\n",
            "\n",
            "Iteration/Step: 1941\n",
            "Sample ID: 14445\n",
            "Decoded Input: In what year was his money list rank 3? \n",
            "Decoded Target (Labels): SELECT MIN(year) FROM table_22839669_12 WHERE money_list_rank = 3\n",
            "\n",
            "Iteration/Step: 1942\n",
            "Sample ID: 13081\n",
            "Decoded Input: How much Enrollment has a School of indianapolis tindley?\n",
            "Decoded Target (Labels): SELECT COUNT(enrollment) FROM table_name_32 WHERE school = \"indianapolis tindley\"\n",
            "\n",
            "Iteration/Step: 1942\n",
            "Sample ID: 22026\n",
            "Decoded Input: When the Away team is footscray, what is the Home team playing?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_42 WHERE away_team = \"footscray\"\n",
            "\n",
            "Iteration/Step: 1943\n",
            "Sample ID: 11625\n",
            "Decoded Input: Which brigade has a population of 190?\n",
            "Decoded Target (Labels): SELECT brigade FROM table_name_44 WHERE population = \"190\"\n",
            "\n",
            "Iteration/Step: 1943\n",
            "Sample ID: 8846\n",
            "Decoded Input: What location was fábio maldonado the opponent at?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_26 WHERE opponent = \"fábio maldonado\"\n",
            "\n",
            "Iteration/Step: 1944\n",
            "Sample ID: 7438\n",
            "Decoded Input: Award of troisième prix, and a Year smaller than 2010, and a Director of jan komasa is what film?\n",
            "Decoded Target (Labels): SELECT film FROM table_name_10 WHERE award = \"troisième prix\" AND year < 2010 AND director = \"jan komasa\"\n",
            "\n",
            "Iteration/Step: 1944\n",
            "Sample ID: 6250\n",
            "Decoded Input: What is the Year for Supplier Kooga?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_97 WHERE supplier = \"kooga\"\n",
            "\n",
            "Iteration/Step: 1945\n",
            "Sample ID: 22675\n",
            "Decoded Input: When did the Tournament of the Tour Championship take place?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_10 WHERE tournament = \"the tour championship\"\n",
            "\n",
            "Iteration/Step: 1945\n",
            "Sample ID: 15611\n",
            "Decoded Input: What was the outcome in the championship where the final score was 6–7(1), 2–6, 6–4, 7–5, 6–7(2)?\n",
            "Decoded Target (Labels): SELECT outcome FROM table_2362486_1 WHERE score_in_the_final = \"6–7(1), 2–6, 6–4, 7–5, 6–7(2)\"\n",
            "\n",
            "Iteration/Step: 1946\n",
            "Sample ID: 12251\n",
            "Decoded Input: Which Winner has a Trofeo Fast Team of metauro mobili-pinarello, and a General classification of giuseppe saronni?\n",
            "Decoded Target (Labels): SELECT winner FROM table_name_78 WHERE trofeo_fast_team = \"metauro mobili-pinarello\" AND general_classification = \"giuseppe saronni\"\n",
            "\n",
            "Iteration/Step: 1946\n",
            "Sample ID: 3880\n",
            "Decoded Input: WHAT IS THE LEAD WITH THIRD AS JEANNA SCHRAEDER?\n",
            "Decoded Target (Labels): SELECT lead FROM table_name_83 WHERE third = \"jeanna schraeder\"\n",
            "\n",
            "Iteration/Step: 1947\n",
            "Sample ID: 14985\n",
            "Decoded Input: What numer pick in the draft for jerry marion\n",
            "Decoded Target (Labels): SELECT MAX(overall) FROM table_13758243_1 WHERE player = \"Jerry Marion\"\n",
            "\n",
            "Iteration/Step: 1947\n",
            "Sample ID: 17499\n",
            "Decoded Input: What is the total number of years active listings where Asian Cup played as a captain is Japan 1992?\n",
            "Decoded Target (Labels): SELECT COUNT(years_active) FROM table_272865_20 WHERE asian_cup_played_as_a_captain = \"Japan 1992\"\n",
            "\n",
            "Iteration/Step: 1948\n",
            "Sample ID: 8958\n",
            "Decoded Input: Who was Betty's partner when the surface is hard?\n",
            "Decoded Target (Labels): SELECT partner FROM table_2820584_2 WHERE surface = \"Hard\"\n",
            "\n",
            "Iteration/Step: 1948\n",
            "Sample ID: 15665\n",
            "Decoded Input: Which frequency has voltage of 1.6v and part number kp80524kx300256kc80524kx300256pmg30002002aa?\n",
            "Decoded Target (Labels): SELECT frequency FROM table_name_64 WHERE voltage = \"1.6v\" AND part_number_s_ = \"kp80524kx300256kc80524kx300256pmg30002002aa\"\n",
            "\n",
            "Iteration/Step: 1949\n",
            "Sample ID: 20216\n",
            "Decoded Input: What affiliations have Pick #s under 32?\n",
            "Decoded Target (Labels): SELECT affiliation FROM table_name_28 WHERE pick__number < 32\n",
            "\n",
            "Iteration/Step: 1949\n",
            "Sample ID: 5236\n",
            "Decoded Input: Who is the original operator for the AG Vulcan builder and the Prinzess Irene ship?\n",
            "Decoded Target (Labels): SELECT original_operator FROM table_name_54 WHERE builder = \"ag vulcan\" AND ship = \"prinzess irene\"\n",
            "\n",
            "Iteration/Step: 1950\n",
            "Sample ID: 22053\n",
            "Decoded Input: What was the home team when the visiting team was Toronto?\n",
            "Decoded Target (Labels): SELECT home FROM table_name_22 WHERE visitor = \"toronto\"\n",
            "\n",
            "Iteration/Step: 1950\n",
            "Sample ID: 10861\n",
            "Decoded Input: When was Laurent-Marie-Joseph Imbert / St. Imbert, who was beatified after 1909 and canonised after 1984, martyred?\n",
            "Decoded Target (Labels): SELECT MAX(martyred) FROM table_name_65 WHERE beatified > 1909 AND name = \"laurent-marie-joseph imbert / st. imbert\" AND canonised > 1984\n",
            "\n",
            "Iteration/Step: 1951\n",
            "Sample ID: 6997\n",
            "Decoded Input: What is footscray's away team score?\n",
            "Decoded Target (Labels): SELECT away_team AS score FROM table_name_66 WHERE home_team = \"footscray\"\n",
            "\n",
            "Iteration/Step: 1951\n",
            "Sample ID: 9587\n",
            "Decoded Input: What is the Nominee from the Category that is best costume design?\n",
            "Decoded Target (Labels): SELECT nominee FROM table_name_64 WHERE category = \"best costume design\"\n",
            "\n",
            "Iteration/Step: 1952\n",
            "Sample ID: 17002\n",
            "Decoded Input: Which weapon was used when the Battle of the Planets was Jason?\n",
            "Decoded Target (Labels): SELECT weapon FROM table_name_48 WHERE battle_of_the_planets = \"jason\"\n",
            "\n",
            "Iteration/Step: 1952\n",
            "Sample ID: 22074\n",
            "Decoded Input: What the score of the 1992 game?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_71 WHERE year = \"1992\"\n",
            "\n",
            "Iteration/Step: 1953\n",
            "Sample ID: 2423\n",
            "Decoded Input: What is the original artist that has 11 as the order number?\n",
            "Decoded Target (Labels): SELECT original_artist FROM table_name_69 WHERE order__number = \"11\"\n",
            "\n",
            "Iteration/Step: 1953\n",
            "Sample ID: 23018\n",
            "Decoded Input: What is the maximum speed for total power of ps (kw; bhp)?\n",
            "Decoded Target (Labels): SELECT top_speed FROM table_21154679_1 WHERE max_power = \"PS (kW; bhp)\"\n",
            "\n",
            "Iteration/Step: 1954\n",
            "Sample ID: 15434\n",
            "Decoded Input: What is the lowest attendance for week 2?\n",
            "Decoded Target (Labels): SELECT MIN(attendance) FROM table_name_50 WHERE week = 2\n",
            "\n",
            "Iteration/Step: 1954\n",
            "Sample ID: 20571\n",
            "Decoded Input: On which date did Potts (I) poll at 9%?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_92 WHERE potts__i_ = \"9%\"\n",
            "\n",
            "Iteration/Step: 1955\n",
            "Sample ID: 16919\n",
            "Decoded Input: What is the highest number of draws with 6 losses and less than 15 points?\n",
            "Decoded Target (Labels): SELECT MAX(draw) FROM table_name_94 WHERE lost = 6 AND points < 15\n",
            "\n",
            "Iteration/Step: 1955\n",
            "Sample ID: 16149\n",
            "Decoded Input: What is the toll for light vehicles at the plaza where the toll for heavy vehicles with 2 axles is r87.00?\n",
            "Decoded Target (Labels): SELECT light_vehicle FROM table_1211545_2 WHERE heavy_vehicle__2_axles_ = \"R87.00\"\n",
            "\n",
            "Iteration/Step: 1956\n",
            "Sample ID: 15276\n",
            "Decoded Input: What year did Yuri Omeltchenko win Silver?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_57 WHERE silver = \"yuri omeltchenko\"\n",
            "\n",
            "Iteration/Step: 1956\n",
            "Sample ID: 12287\n",
            "Decoded Input: What's the most against when the draws are more than 0?\n",
            "Decoded Target (Labels): SELECT MAX(against) FROM table_name_43 WHERE draws > 0\n",
            "\n",
            "Iteration/Step: 1957\n",
            "Sample ID: 9574\n",
            "Decoded Input: On what Date is Sheffield Wednesday the Home team?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_61 WHERE home_team = \"sheffield wednesday\"\n",
            "\n",
            "Iteration/Step: 1957\n",
            "Sample ID: 21425\n",
            "Decoded Input: Which position had a goal difference of less than 27, lost more than 13 games, scored less than 42 goals and drew 6 games?\n",
            "Decoded Target (Labels): SELECT MAX(played) FROM table_name_61 WHERE goal_difference < 27 AND losses > 13 AND goals_for < 42 AND draws = 6\n",
            "\n",
            "Iteration/Step: 1958\n",
            "Sample ID: 21979\n",
            "Decoded Input: When was the lock with 10 caps born?\n",
            "Decoded Target (Labels): SELECT date_of_birth__age_ FROM table_name_20 WHERE position = \"lock\" AND caps = 10\n",
            "\n",
            "Iteration/Step: 1958\n",
            "Sample ID: 3422\n",
            "Decoded Input: What is the frequency of the radio station in Indiana that has a call sign of WGNR?\n",
            "Decoded Target (Labels): SELECT frequency FROM table_name_70 WHERE state = \"indiana\" AND call_sign = \"wgnr\"\n",
            "\n",
            "Iteration/Step: 1959\n",
            "Sample ID: 23595\n",
            "Decoded Input: What was the Constructor for the race that had Derek Warwick as its Fastest Lap?\n",
            "Decoded Target (Labels): SELECT constructor FROM table_name_36 WHERE fastest_lap = \"derek warwick\"\n",
            "\n",
            "Iteration/Step: 1959\n",
            "Sample ID: 22094\n",
            "Decoded Input: What is the average crowd size at glenferrie oval?\n",
            "Decoded Target (Labels): SELECT AVG(crowd) FROM table_name_16 WHERE venue = \"glenferrie oval\"\n",
            "\n",
            "Iteration/Step: 1960\n",
            "Sample ID: 16554\n",
            "Decoded Input: What publishers were involved with product number SCUS-97265?\n",
            "Decoded Target (Labels): SELECT publisher FROM table_10875694_11 WHERE product_no = \"SCUS-97265\"\n",
            "\n",
            "Iteration/Step: 1960\n",
            "Sample ID: 13587\n",
            "Decoded Input: What is the percentage of votes received by the party of family rights?\n",
            "Decoded Target (Labels): SELECT _percentage_of_votes FROM table_name_88 WHERE party = \"family rights\"\n",
            "\n",
            "Iteration/Step: 1961\n",
            "Sample ID: 10193\n",
            "Decoded Input: What is the lowest start in a year after 2008?\n",
            "Decoded Target (Labels): SELECT MIN(start) FROM table_name_62 WHERE year > 2008\n",
            "\n",
            "Iteration/Step: 1961\n",
            "Sample ID: 1225\n",
            "Decoded Input: Name the total number of April for game more than 81 and reord of 38-33-10\n",
            "Decoded Target (Labels): SELECT COUNT(april) FROM table_name_46 WHERE record = \"38-33-10\" AND game > 81\n",
            "\n",
            "Iteration/Step: 1962\n",
            "Sample ID: 17929\n",
            "Decoded Input: what team's score is 101?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_42 WHERE score = \"101\"\n",
            "\n",
            "Iteration/Step: 1962\n",
            "Sample ID: 24132\n",
            "Decoded Input: Which opponent has a record of 70-52?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_77 WHERE record = \"70-52\"\n",
            "\n",
            "Iteration/Step: 1963\n",
            "Sample ID: 23420\n",
            "Decoded Input: How many uninterrupted ranks does john dingell have?\n",
            "Decoded Target (Labels): SELECT COUNT(uninterrupted_rank) FROM table_name_87 WHERE name = \"john dingell\"\n",
            "\n",
            "Iteration/Step: 1963\n",
            "Sample ID: 18267\n",
            "Decoded Input: What is the category for the year when Brioude started and the stage is less than 7?\n",
            "Decoded Target (Labels): SELECT COUNT(category) FROM table_name_10 WHERE start = \"brioude\" AND stage < 7\n",
            "\n",
            "Iteration/Step: 1964\n",
            "Sample ID: 4448\n",
            "Decoded Input: What was the distance for the winner or 2nd Waterline?\n",
            "Decoded Target (Labels): SELECT distance FROM table_name_21 WHERE winner_or_2nd = \"waterline\"\n",
            "\n",
            "Iteration/Step: 1964\n",
            "Sample ID: 20242\n",
            "Decoded Input: What was the average crowd size of games held at Glenferrie Oval?\n",
            "Decoded Target (Labels): SELECT AVG(crowd) FROM table_name_43 WHERE venue = \"glenferrie oval\"\n",
            "\n",
            "Iteration/Step: 1965\n",
            "Sample ID: 21311\n",
            "Decoded Input: What instruments does the the song \"Le Pop\" use?\n",
            "Decoded Target (Labels): SELECT instrument FROM instruments AS T1 JOIN songs AS T2 ON T1.songid = T2.songid WHERE title = \"Le Pop\"\n",
            "\n",
            "Iteration/Step: 1965\n",
            "Sample ID: 15905\n",
            "Decoded Input: What is the Birthdate of leon tuck?\n",
            "Decoded Target (Labels): SELECT birthdate FROM table_name_29 WHERE name = \"leon tuck\"\n",
            "\n",
            "Iteration/Step: 1966\n",
            "Sample ID: 16008\n",
            "Decoded Input: How many constructions has a Wheel arrange- ment of 4-4-0?\n",
            "Decoded Target (Labels): SELECT SUM(construct__tion_no) FROM table_name_7 WHERE wheel_arrange__ment = \"4-4-0\"\n",
            "\n",
            "Iteration/Step: 1966\n",
            "Sample ID: 19586\n",
            "Decoded Input: what is the latest episode in the series that had 16.17 million u.s. viewers?\n",
            "Decoded Target (Labels): SELECT MAX(no_in_series) FROM table_25997153_1 WHERE us_viewers__million_ = \"16.17\"\n",
            "\n",
            "Iteration/Step: 1967\n",
            "Sample ID: 2146\n",
            "Decoded Input: Name the location attendance for score of 65-72\n",
            "Decoded Target (Labels): SELECT location_attendance FROM table_17103645_10 WHERE score = \"65-72\"\n",
            "\n",
            "Iteration/Step: 1967\n",
            "Sample ID: 23816\n",
            "Decoded Input: Tell me the 2011 with 2012 of 2r\n",
            "Decoded Target (Labels): SELECT 2011 FROM table_name_40 WHERE 2012 = \"2r\" AND 2010 = \"2r\" AND 2009 = \"2r\"\n",
            "\n",
            "Iteration/Step: 1968\n",
            "Sample ID: 21633\n",
            "Decoded Input: What institution is a NCAA Division i school and part of the NEC conference with a nickname the Blue Devils?\n",
            "Decoded Target (Labels): SELECT institution FROM table_name_48 WHERE classification = \"ncaa division i\" AND current_conference = \"nec\" AND nickname = \"blue devils\"\n",
            "\n",
            "Iteration/Step: 1968\n",
            "Sample ID: 195\n",
            "Decoded Input: What is the aggregate for the first round for K.S.V. Waregem?\n",
            "Decoded Target (Labels): SELECT aggregate FROM table_name_54 WHERE round = \"first round\" AND club = \"k.s.v. waregem\"\n",
            "\n",
            "Iteration/Step: 1969\n",
            "Sample ID: 23796\n",
            "Decoded Input: Which team is in the Southeast with a home at Philips Arena?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_29 WHERE division = \"southeast\" AND home_arena = \"philips arena\"\n",
            "\n",
            "Iteration/Step: 1969\n",
            "Sample ID: 9144\n",
            "Decoded Input: What is the Rank of the rower with a Time of 8:23.02?\n",
            "Decoded Target (Labels): SELECT COUNT(rank) FROM table_name_35 WHERE time = \"8:23.02\"\n",
            "\n",
            "Iteration/Step: 1970\n",
            "Sample ID: 4172\n",
            "Decoded Input: What was the date of the game that had a loss of Johnson (9-8)?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_30 WHERE loss = \"johnson (9-8)\"\n",
            "\n",
            "Iteration/Step: 1970\n",
            "Sample ID: 11881\n",
            "Decoded Input: Which Location has a Silver of japan?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_10 WHERE silver = \"japan\"\n",
            "\n",
            "Iteration/Step: 1971\n",
            "Sample ID: 20977\n",
            "Decoded Input: What is the fewest amount of Pro Bowl appearances any of the players had? \n",
            "Decoded Target (Labels): SELECT MIN(number) FROM table_274117_5\n",
            "\n",
            "Iteration/Step: 1971\n",
            "Sample ID: 25133\n",
            "Decoded Input: What was the score of the match in which mardy fish was the partner?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_72 WHERE partner = \"mardy fish\"\n",
            "\n",
            "Iteration/Step: 1972\n",
            "Sample ID: 6332\n",
            "Decoded Input: What was the lowest attendance at a game when there were fewer than 151 away fans and an opponent of Bury?\n",
            "Decoded Target (Labels): SELECT MIN(attendance) FROM table_name_80 WHERE away_fans < 151 AND opponent = \"bury\"\n",
            "\n",
            "Iteration/Step: 1972\n",
            "Sample ID: 2491\n",
            "Decoded Input: What ship was built in 2012?\n",
            "Decoded Target (Labels): SELECT ship FROM table_name_79 WHERE built = 2012\n",
            "\n",
            "Iteration/Step: 1973\n",
            "Sample ID: 19014\n",
            "Decoded Input: Which district has the least area?\n",
            "Decoded Target (Labels): SELECT district_name FROM district ORDER BY city_area LIMIT 1\n",
            "\n",
            "Iteration/Step: 1973\n",
            "Sample ID: 4648\n",
            "Decoded Input: When Tom Watson (5/6) won the Senior British Open who won the Senior PGA Championship?\n",
            "Decoded Target (Labels): SELECT senior_pga_championship FROM table_name_41 WHERE senior_british_open = \"tom watson (5/6)\"\n",
            "\n",
            "Iteration/Step: 1974\n",
            "Sample ID: 13092\n",
            "Decoded Input: Who won the Silver the Year Katie Curtis Unknown won the Bronze?\n",
            "Decoded Target (Labels): SELECT silver FROM table_name_28 WHERE bronze = \"katie curtis unknown\"\n",
            "\n",
            "Iteration/Step: 1974\n",
            "Sample ID: 22049\n",
            "Decoded Input: What is the position of the player bill simmons?\n",
            "Decoded Target (Labels): SELECT position FROM table_26996293_7 WHERE player = \"Bill Simmons\"\n",
            "\n",
            "Iteration/Step: 1975\n",
            "Sample ID: 13162\n",
            "Decoded Input: What is the earliest year with a label-Nr of st-43?\n",
            "Decoded Target (Labels): SELECT MIN(year) FROM table_name_37 WHERE label - Nr = st - 43\n",
            "\n",
            "Iteration/Step: 1975\n",
            "Sample ID: 22923\n",
            "Decoded Input: on 19 april 1985 how many of number last flew\n",
            "Decoded Target (Labels): SELECT COUNT(number) FROM table_1997759_1 WHERE last_flew = \"19 April 1985\"\n",
            "\n",
            "Iteration/Step: 1976\n",
            "Sample ID: 8505\n",
            "Decoded Input: Which Team has a Record of 17–8?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_74 WHERE record = \"17–8\"\n",
            "\n",
            "Iteration/Step: 1976\n",
            "Sample ID: 17306\n",
            "Decoded Input: How many laps did Valentino rossi have when riding a vehicle manufactured by yamaha?\n",
            "Decoded Target (Labels): SELECT laps FROM table_name_77 WHERE manufacturer = \"yamaha\" AND rider = \"valentino rossi\"\n",
            "\n",
            "Iteration/Step: 1977\n",
            "Sample ID: 5489\n",
            "Decoded Input: On what date was there a game in which the opponent was the Detroit Tigers, and the attendance was 38,639?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_24 WHERE opponent = \"detroit tigers\" AND attendance = \"38,639\"\n",
            "\n",
            "Iteration/Step: 1977\n",
            "Sample ID: 2910\n",
            "Decoded Input: How many Games for Rank 2 Terrell McIntyre?\n",
            "Decoded Target (Labels): SELECT MIN(games) FROM table_name_8 WHERE name = \"terrell mcintyre\" AND rank > 2\n",
            "\n",
            "Iteration/Step: 1978\n",
            "Sample ID: 2921\n",
            "Decoded Input: What is the highest listed year for the partner of Marcel Granollers and a hard surface?\n",
            "Decoded Target (Labels): SELECT MAX(year) FROM table_name_28 WHERE partner = \"marcel granollers\" AND surface = \"hard\"\n",
            "\n",
            "Iteration/Step: 1978\n",
            "Sample ID: 3181\n",
            "Decoded Input: What is the latest season where Al Ahly is the runners-up?\n",
            "Decoded Target (Labels): SELECT MAX(season) FROM table_name_94 WHERE runners_up = \"al ahly\"\n",
            "\n",
            "Iteration/Step: 1979\n",
            "Sample ID: 24880\n",
            "Decoded Input: Name the score for 30 january 2013\n",
            "Decoded Target (Labels): SELECT score FROM table_name_24 WHERE date = \"30 january 2013\"\n",
            "\n",
            "Iteration/Step: 1979\n",
            "Sample ID: 3757\n",
            "Decoded Input: Which state contains the University of Iowa in the mideast region?\n",
            "Decoded Target (Labels): SELECT state FROM table_name_67 WHERE region = \"mideast\" AND host = \"university of iowa\"\n",
            "\n",
            "Iteration/Step: 1980\n",
            "Sample ID: 2902\n",
            "Decoded Input: How many of the cmdlets are the 2008 version?\n",
            "Decoded Target (Labels): SELECT COUNT(cmdlets) FROM table_14465871_2 WHERE version = \"2008\"\n",
            "\n",
            "Iteration/Step: 1980\n",
            "Sample ID: 6459\n",
            "Decoded Input: Where are the headquarters of the company whose sales were 69.2 billion?\n",
            "Decoded Target (Labels): SELECT headquarters FROM table_1682026_3 WHERE sales__billion_$_ = \"69.2\"\n",
            "\n",
            "Iteration/Step: 1981\n",
            "Sample ID: 14542\n",
            "Decoded Input: What Field was played at in an away game against the bayhawks?\n",
            "Decoded Target (Labels): SELECT field FROM table_name_99 WHERE home_away = \"away\" AND opponent = \"bayhawks\"\n",
            "\n",
            "Iteration/Step: 1981\n",
            "Sample ID: 21396\n",
            "Decoded Input: What machine did susan jenness trophy earn the trophy?\n",
            "Decoded Target (Labels): SELECT machine FROM table_name_75 WHERE trophy = \"susan jenness trophy\"\n",
            "\n",
            "Iteration/Step: 1982\n",
            "Sample ID: 20729\n",
            "Decoded Input: Who was Dainty June when Tammy Blanchard was Louise?\n",
            "Decoded Target (Labels): SELECT dainty_june FROM table_name_5 WHERE louise = \"tammy blanchard\"\n",
            "\n",
            "Iteration/Step: 1982\n",
            "Sample ID: 23084\n",
            "Decoded Input: What is Score, when Opponent is \"Daniel Gimeno-Traver\"?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_38 WHERE opponent = \"daniel gimeno-traver\"\n",
            "\n",
            "Iteration/Step: 1983\n",
            "Sample ID: 14630\n",
            "Decoded Input: Which Source has a Clinton of 39% and a Undecided of 7%?\n",
            "Decoded Target (Labels): SELECT source FROM table_name_94 WHERE clinton = \"39%\" AND undecided = \"7%\"\n",
            "\n",
            "Iteration/Step: 1983\n",
            "Sample ID: 18856\n",
            "Decoded Input: What is position of the player with a pick number greater than 315 and a round of 30?\n",
            "Decoded Target (Labels): SELECT position FROM table_name_51 WHERE pick > 315 AND round = 30\n",
            "\n",
            "Iteration/Step: 1984\n",
            "Sample ID: 23429\n",
            "Decoded Input: Name the number of assists for 321 minutes \n",
            "Decoded Target (Labels): SELECT COUNT(assists) FROM table_23184448_4 WHERE minutes = 321\n",
            "\n",
            "Iteration/Step: 1984\n",
            "Sample ID: 12817\n",
            "Decoded Input: What streak start has a total less than 79, 22t as the rank, and tampa bay as the teams?\n",
            "Decoded Target (Labels): SELECT streak_start FROM table_name_28 WHERE total < 79 AND rank = \"22t\" AND teams = \"tampa bay\"\n",
            "\n",
            "Iteration/Step: 1985\n",
            "Sample ID: 5417\n",
            "Decoded Input: What is the highest loss before game 14?\n",
            "Decoded Target (Labels): SELECT MAX(loss) FROM table_name_31 WHERE game < 14\n",
            "\n",
            "Iteration/Step: 1985\n",
            "Sample ID: 18063\n",
            "Decoded Input: How many pick # are there for the goaltender position?\n",
            "Decoded Target (Labels): SELECT MIN(pick__number) FROM table_22402438_7 WHERE position = \"Goaltender\"\n",
            "\n",
            "Iteration/Step: 1986\n",
            "Sample ID: 23398\n",
            "Decoded Input: Who was the Away team at Arden Street Oval?\n",
            "Decoded Target (Labels): SELECT away_team FROM table_name_98 WHERE venue = \"arden street oval\"\n",
            "\n",
            "Iteration/Step: 1986\n",
            "Sample ID: 23405\n",
            "Decoded Input: Which ICAO's IATA is ath?\n",
            "Decoded Target (Labels): SELECT icao FROM table_name_63 WHERE iata = \"ath\"\n",
            "\n",
            "Iteration/Step: 1987\n",
            "Sample ID: 17393\n",
            "Decoded Input: Name the most number in season for leslie hill\n",
            "Decoded Target (Labels): SELECT MAX(no_in_season) FROM table_25604014_9 WHERE directed_by = \"Leslie Hill\"\n",
            "\n",
            "Iteration/Step: 1987\n",
            "Sample ID: 23747\n",
            "Decoded Input: In the tournament that has 15 events, and less than 6 top-25's, how many top-5's did he have?\n",
            "Decoded Target (Labels): SELECT SUM(top_5) FROM table_name_76 WHERE events = 15 AND top_25 < 6\n",
            "\n",
            "Iteration/Step: 1988\n",
            "Sample ID: 16848\n",
            "Decoded Input: what is the media debut for the asian black bear?\n",
            "Decoded Target (Labels): SELECT media_debut FROM table_26615633_3 WHERE species = \"Asian black bear\"\n",
            "\n",
            "Iteration/Step: 1988\n",
            "Sample ID: 17934\n",
            "Decoded Input: Which constructor had a grid number of less than 3 and where the Time/Retired was 1:34:31.522?\n",
            "Decoded Target (Labels): SELECT constructor FROM table_name_55 WHERE grid < 3 AND time_retired = \"1:34:31.522\"\n",
            "\n",
            "Iteration/Step: 1989\n",
            "Sample ID: 15914\n",
            "Decoded Input: Find the name of captains whose rank are either Midshipman or Lieutenant.\n",
            "Decoded Target (Labels): SELECT name FROM captain WHERE rank = 'Midshipman' OR rank = 'Lieutenant'\n",
            "\n",
            "Iteration/Step: 1989\n",
            "Sample ID: 25388\n",
            "Decoded Input: Who scored 68-73-66=207 in South Africa?\n",
            "Decoded Target (Labels): SELECT place FROM table_name_70 WHERE country = \"south africa\" AND score = 68 - 73 - 66 = 207\n",
            "\n",
            "Iteration/Step: 1990\n",
            "Sample ID: 6609\n",
            "Decoded Input: How many episodes were written by Alison McDonald?\n",
            "Decoded Target (Labels): SELECT COUNT(directed_by) FROM table_26961951_4 WHERE written_by = \"Alison McDonald\"\n",
            "\n",
            "Iteration/Step: 1990\n",
            "Sample ID: 24521\n",
            "Decoded Input: What was the result for Pennsylvania 8?\n",
            "Decoded Target (Labels): SELECT result FROM table_2668401_12 WHERE district = \"Pennsylvania 8\"\n",
            "\n",
            "Iteration/Step: 1991\n",
            "Sample ID: 17433\n",
            "Decoded Input: What was the length of the game where the Baltimore Colts were at home?\n",
            "Decoded Target (Labels): SELECT length_of_game FROM table_name_95 WHERE home_team = \"baltimore colts\"\n",
            "\n",
            "Iteration/Step: 1991\n",
            "Sample ID: 15517\n",
            "Decoded Input: What was the record on February 2?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_42 WHERE date = \"february 2\"\n",
            "\n",
            "Iteration/Step: 1992\n",
            "Sample ID: 6347\n",
            "Decoded Input: What was the highest assists for game 3?\n",
            "Decoded Target (Labels): SELECT high_assists FROM table_name_7 WHERE game = 3\n",
            "\n",
            "Iteration/Step: 1992\n",
            "Sample ID: 11029\n",
            "Decoded Input: When has Clark University joined the Conference?\n",
            "Decoded Target (Labels): SELECT MAX(joined) FROM table_1974782_1 WHERE institution = \"Clark University\"\n",
            "\n",
            "Iteration/Step: 1993\n",
            "Sample ID: 21659\n",
            "Decoded Input: WHAT IS THE LOWEST DIAMETER FOR A LATITIDE OF 52.0S?\n",
            "Decoded Target (Labels): SELECT MIN(diameter__km_) FROM table_name_78 WHERE latitude = \"52.0s\"\n",
            "\n",
            "Iteration/Step: 1993\n",
            "Sample ID: 2182\n",
            "Decoded Input: What is the Winner of the Event in Panama City?\n",
            "Decoded Target (Labels): SELECT winner FROM table_name_5 WHERE city = \"panama city\"\n",
            "\n",
            "Iteration/Step: 1994\n",
            "Sample ID: 22126\n",
            "Decoded Input: What is the score of the team that plays in lake oval?\n",
            "Decoded Target (Labels): SELECT away_team AS score FROM table_name_85 WHERE venue = \"lake oval\"\n",
            "\n",
            "Iteration/Step: 1994\n",
            "Sample ID: 953\n",
            "Decoded Input: What was the result of the week 9 game?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_48 WHERE week = 9\n",
            "\n",
            "Iteration/Step: 1995\n",
            "Sample ID: 10949\n",
            "Decoded Input: Name the withdrawn for charles dickens\n",
            "Decoded Target (Labels): SELECT withdrawn FROM table_name_93 WHERE name = \"charles dickens\"\n",
            "\n",
            "Iteration/Step: 1995\n",
            "Sample ID: 1435\n",
            "Decoded Input: Who drove for team Circle Sport?\n",
            "Decoded Target (Labels): SELECT driver_s_ FROM table_1266602_2 WHERE team = \"Circle Sport\"\n",
            "\n",
            "Iteration/Step: 1996\n",
            "Sample ID: 25011\n",
            "Decoded Input: What year was Jordan Hill picked overall number 8?\n",
            "Decoded Target (Labels): SELECT MIN(year) FROM table_name_70 WHERE overall_pick = \"8\" AND name = \"jordan hill\"\n",
            "\n",
            "Iteration/Step: 1996\n",
            "Sample ID: 19548\n",
            "Decoded Input: What is the weekly rank of the episode with a 14 share whose original airdate was April 20, 2010? \n",
            "Decoded Target (Labels): SELECT weekly_rank FROM table_25391981_20 WHERE share = \"14\" AND original_airdate = \"April 20, 2010\"\n",
            "\n",
            "Iteration/Step: 1997\n",
            "Sample ID: 19691\n",
            "Decoded Input: What percentage of the votes did McCain get in Hinds?\n",
            "Decoded Target (Labels): SELECT mccain_percentage FROM table_20799587_1 WHERE county = \"Hinds\"\n",
            "\n",
            "Iteration/Step: 1997\n",
            "Sample ID: 19576\n",
            "Decoded Input: What was the team's result in week 4?\n",
            "Decoded Target (Labels): SELECT result FROM table_14942535_1 WHERE week = 4\n",
            "\n",
            "Iteration/Step: 1998\n",
            "Sample ID: 15623\n",
            "Decoded Input: How many captains have the kitmaker as n/a?\n",
            "Decoded Target (Labels): SELECT COUNT(captain) FROM table_27631756_2 WHERE kitmaker = \"N/A\"\n",
            "\n",
            "Iteration/Step: 1998\n",
            "Sample ID: 23558\n",
            "Decoded Input: Find all the films longer than 100 minutes, or rated PG, except those who cost more than 200 for replacement. List the titles.\n",
            "Decoded Target (Labels): SELECT title FROM film WHERE LENGTH > 100 OR rating = 'PG' EXCEPT SELECT title FROM film WHERE replacement_cost > 200\n",
            "\n",
            "Iteration/Step: 1999\n",
            "Sample ID: 3473\n",
            "Decoded Input: Which home team had a score of 85-101?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_7 WHERE score = \"85-101\"\n",
            "\n",
            "Iteration/Step: 1999\n",
            "Sample ID: 25081\n",
            "Decoded Input: What is every entry on Monday August 22 when the entry for Wednesday August 24 is 22' 50.05 99.141mph?\n",
            "Decoded Target (Labels): SELECT mon_22_aug FROM table_30058355_3 WHERE wed_24_aug = \"22' 50.05 99.141mph\"\n",
            "\n",
            "Iteration/Step: 2000\n",
            "Sample ID: 19371\n",
            "Decoded Input: What is the chassis for a 1952 officine alfieri maserati with an entrant?\n",
            "Decoded Target (Labels): SELECT chassis FROM table_name_92 WHERE entrant = \"officine alfieri maserati\" AND year = 1952\n",
            "\n",
            "Iteration/Step: 2000\n",
            "Sample ID: 5581\n",
            "Decoded Input: What was the record when the visiting team was Ottawa?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_54 WHERE visitor = \"ottawa\"\n",
            "\n",
            "Iteration/Step: 2001\n",
            "Sample ID: 4302\n",
            "Decoded Input: What is the least value for total population in 2001 with a growth rate in 1991-01 of 33.08?\n",
            "Decoded Target (Labels): SELECT MIN(total_population_2001) FROM table_19589113_5 WHERE growth_rate_1991_01 = \"33.08\"\n",
            "\n",
            "Iteration/Step: 2001\n",
            "Sample ID: 967\n",
            "Decoded Input: Who directed episode number 23?\n",
            "Decoded Target (Labels): SELECT directed_by FROM table_21025437_6 WHERE episode_no = 23\n",
            "\n",
            "Iteration/Step: 2002\n",
            "Sample ID: 13615\n",
            "Decoded Input: What is the first election year listed?\n",
            "Decoded Target (Labels): SELECT MIN(first_elected) FROM table_1341472_20\n",
            "\n",
            "Iteration/Step: 2002\n",
            "Sample ID: 11536\n",
            "Decoded Input: What was the film that vadim ilyenko directed?\n",
            "Decoded Target (Labels): SELECT film_name FROM table_10236830_1 WHERE director = \"Vadim Ilyenko\"\n",
            "\n",
            "Iteration/Step: 2003\n",
            "Sample ID: 7151\n",
            "Decoded Input: What is the Week number on December 18, 1960?\n",
            "Decoded Target (Labels): SELECT COUNT(week) FROM table_name_17 WHERE date = \"december 18, 1960\"\n",
            "\n",
            "Iteration/Step: 2003\n",
            "Sample ID: 13571\n",
            "Decoded Input: When colgate is the team how many times did they place fourth?\n",
            "Decoded Target (Labels): SELECT COUNT(fourth_place) FROM table_1571238_2 WHERE team = \"Colgate\"\n",
            "\n",
            "Iteration/Step: 2004\n",
            "Sample ID: 24071\n",
            "Decoded Input: What is the population for a county that has a median income of $69,760?\n",
            "Decoded Target (Labels): SELECT population FROM table_name_25 WHERE median_household_income = \"$69,760\"\n",
            "\n",
            "Iteration/Step: 2004\n",
            "Sample ID: 22810\n",
            "Decoded Input: What's the highest annual interchange for wimbledon railway station?\n",
            "Decoded Target (Labels): SELECT MAX(annual_interchanges__millions__2011_12) FROM table_name_82 WHERE railway_station = \"wimbledon\"\n",
            "\n",
            "Iteration/Step: 2005\n",
            "Sample ID: 15929\n",
            "Decoded Input: What is the sum of the bronze medals of the nation with less than 0 silvers?\n",
            "Decoded Target (Labels): SELECT SUM(bronze) FROM table_name_42 WHERE silver < 0\n",
            "\n",
            "Iteration/Step: 2005\n",
            "Sample ID: 18626\n",
            "Decoded Input: How many numbers were recorded for high points when the team played against Oklahoma City?\n",
            "Decoded Target (Labels): SELECT COUNT(high_points) FROM table_17311783_6 WHERE team = \"Oklahoma City\"\n",
            "\n",
            "Iteration/Step: 2006\n",
            "Sample ID: 20085\n",
            "Decoded Input: What is Samuel Smith's party?\n",
            "Decoded Target (Labels): SELECT party FROM table_2668329_11 WHERE incumbent = \"Samuel Smith\"\n",
            "\n",
            "Iteration/Step: 2006\n",
            "Sample ID: 8299\n",
            "Decoded Input: What was the Attendance during the Tamworth Away game?\n",
            "Decoded Target (Labels): SELECT COUNT(attendance) FROM table_name_9 WHERE away_team = \"tamworth\"\n",
            "\n",
            "Iteration/Step: 2007\n",
            "Sample ID: 14678\n",
            "Decoded Input: What is the ICAO of Nakashibetsu?\n",
            "Decoded Target (Labels): SELECT icao FROM table_name_89 WHERE city = \"nakashibetsu\"\n",
            "\n",
            "Iteration/Step: 2007\n",
            "Sample ID: 12085\n",
            "Decoded Input: What is the earliest February date with a record of 37-13-4 in a game earlier than 54?\n",
            "Decoded Target (Labels): SELECT MIN(february) FROM table_name_52 WHERE record = \"37-13-4\" AND game < 54\n",
            "\n",
            "Iteration/Step: 2008\n",
            "Sample ID: 13851\n",
            "Decoded Input: Name the record for charlotte\n",
            "Decoded Target (Labels): SELECT record FROM table_23281862_10 WHERE team = \"Charlotte\"\n",
            "\n",
            "Iteration/Step: 2008\n",
            "Sample ID: 3201\n",
            "Decoded Input: What is the diff for a club that has a value of 662 for points for?\n",
            "Decoded Target (Labels): SELECT diff FROM table_name_46 WHERE points_for = \"662\"\n",
            "\n",
            "Iteration/Step: 2009\n",
            "Sample ID: 13086\n",
            "Decoded Input: What is the max gross weight of the Robinson R-22?\n",
            "Decoded Target (Labels): SELECT max_gross_weight FROM table_10006830_1 WHERE aircraft = \"Robinson R-22\"\n",
            "\n",
            "Iteration/Step: 2009\n",
            "Sample ID: 1840\n",
            "Decoded Input: Name the drawn with lost of 3 and points of 88\n",
            "Decoded Target (Labels): SELECT drawn FROM table_name_86 WHERE lost = \"3\" AND points = \"88\"\n",
            "\n",
            "Iteration/Step: 2010\n",
            "Sample ID: 8715\n",
            "Decoded Input: Show the race class and number of races in each class.\n",
            "Decoded Target (Labels): SELECT CLASS, COUNT(*) FROM race GROUP BY CLASS\n",
            "\n",
            "Iteration/Step: 2010\n",
            "Sample ID: 21333\n",
            "Decoded Input: When bmw activee is the vehicle type what is the u.s national average electric mix?\n",
            "Decoded Target (Labels): SELECT us_national_average_electric_mix FROM table_24620684_2 WHERE vehicle = \"BMW ActiveE\"\n",
            "\n",
            "Iteration/Step: 2011\n",
            "Sample ID: 20827\n",
            "Decoded Input: What was United States place when the player was Fred Couples?\n",
            "Decoded Target (Labels): SELECT place FROM table_name_26 WHERE country = \"united states\" AND player = \"fred couples\"\n",
            "\n",
            "Iteration/Step: 2011\n",
            "Sample ID: 24301\n",
            "Decoded Input: What was the number of high assists for game 1?\n",
            "Decoded Target (Labels): SELECT high_assists FROM table_name_94 WHERE game = 1\n",
            "\n",
            "Iteration/Step: 2012\n",
            "Sample ID: 8921\n",
            "Decoded Input: What is the average administrative panel of the composition nominated by Taoiseach 0 times with a total less than 4?\n",
            "Decoded Target (Labels): SELECT AVG(administrative_panel) FROM table_name_36 WHERE nominated_by_the_taoiseach = 0 AND total < 4\n",
            "\n",
            "Iteration/Step: 2012\n",
            "Sample ID: 10931\n",
            "Decoded Input: What Winning team has 22 July as a Date?\n",
            "Decoded Target (Labels): SELECT winning_team FROM table_name_79 WHERE date = \"22 july\"\n",
            "\n",
            "Iteration/Step: 2013\n",
            "Sample ID: 13970\n",
            "Decoded Input: Show the names of all the clients with no booking.\n",
            "Decoded Target (Labels): SELECT Customer_Name FROM Clients EXCEPT SELECT T2.Customer_Name FROM Bookings AS T1 JOIN Clients AS T2 ON T1.Customer_ID = T2.Client_ID\n",
            "\n",
            "Iteration/Step: 2013\n",
            "Sample ID: 16644\n",
            "Decoded Input: When was John Hoan Trinh Doan / St. John Hoan, who was beatified in 1909 and canonised after 1988, martyred?\n",
            "Decoded Target (Labels): SELECT MAX(martyred) FROM table_name_64 WHERE beatified = 1909 AND name = \"john hoan trinh doan / st. john hoan\" AND canonised > 1988\n",
            "\n",
            "Iteration/Step: 2014\n",
            "Sample ID: 19511\n",
            "Decoded Input: How many zodiac signs does the month by the Thai name of กันยายน belong to?\n",
            "Decoded Target (Labels): SELECT COUNT(zodiac_sign) FROM table_180802_2 WHERE thai_name = \"กันยายน\"\n",
            "\n",
            "Iteration/Step: 2014\n",
            "Sample ID: 3329\n",
            "Decoded Input: What was the opearint profit (s$m) associated with an expenditure (s$m) of 12,127.8?\n",
            "Decoded Target (Labels): SELECT operating_profit__s$m_ FROM table_161591_2 WHERE expenditure__s$m_ = \"12,127.8\"\n",
            "\n",
            "Iteration/Step: 2015\n",
            "Sample ID: 5154\n",
            "Decoded Input: Which Record has a Location of madison square garden?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_8 WHERE location = \"madison square garden\"\n",
            "\n",
            "Iteration/Step: 2015\n",
            "Sample ID: 7606\n",
            "Decoded Input: For the roll of 651, what was the lowest Decile?\n",
            "Decoded Target (Labels): SELECT MIN(decile) FROM table_name_79 WHERE roll = 651\n",
            "\n",
            "Iteration/Step: 2016\n",
            "Sample ID: 1439\n",
            "Decoded Input: How big was the crowd in game that featured the visiting team of north melbourne?\n",
            "Decoded Target (Labels): SELECT crowd FROM table_name_76 WHERE away_team = \"north melbourne\"\n",
            "\n",
            "Iteration/Step: 2016\n",
            "Sample ID: 18487\n",
            "Decoded Input: Name the high assists for madison square garden 19,763 and record is 39–38\n",
            "Decoded Target (Labels): SELECT high_assists FROM table_27713583_11 WHERE location_attendance = \"Madison Square Garden 19,763\" AND record = \"39–38\"\n",
            "\n",
            "Iteration/Step: 2017\n",
            "Sample ID: 1065\n",
            "Decoded Input: How many losses does Alex Wilkinson have?\n",
            "Decoded Target (Labels): SELECT COUNT(losses) FROM table_name_98 WHERE name = \"alex wilkinson\"\n",
            "\n",
            "Iteration/Step: 2017\n",
            "Sample ID: 5413\n",
            "Decoded Input: What school is in Jeromesville?\n",
            "Decoded Target (Labels): SELECT location FROM table_24935743_2 WHERE school = \"Jeromesville\"\n",
            "\n",
            "Iteration/Step: 2018\n",
            "Sample ID: 14417\n",
            "Decoded Input: What is the lowest apps for rank 3 and 0% wins?\n",
            "Decoded Target (Labels): SELECT MIN(apps) FROM table_name_33 WHERE rank = 3 AND win__percentage < 0\n",
            "\n",
            "Iteration/Step: 2018\n",
            "Sample ID: 269\n",
            "Decoded Input: How many rounds have Fabio Carbone for fastest lap?\n",
            "Decoded Target (Labels): SELECT COUNT(round) FROM table_26137666_3 WHERE fastest_lap = \"Fabio Carbone\"\n",
            "\n",
            "Iteration/Step: 2019\n",
            "Sample ID: 5931\n",
            "Decoded Input: What is the NFL club with pick # 153?\n",
            "Decoded Target (Labels): SELECT nfl_club FROM table_name_60 WHERE pick = 153\n",
            "\n",
            "Iteration/Step: 2019\n",
            "Sample ID: 13197\n",
            "Decoded Input: What is the swimsuit score when the interview was 9.74?\n",
            "Decoded Target (Labels): SELECT swimsuit FROM table_11884814_3 WHERE interview = \"9.74\"\n",
            "\n",
            "Iteration/Step: 2020\n",
            "Sample ID: 4523\n",
            "Decoded Input: Which Opponent has an Attendance of 375?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_65 WHERE attendance = 375\n",
            "\n",
            "Iteration/Step: 2020\n",
            "Sample ID: 9569\n",
            "Decoded Input: What is Country, when Class is \"15 meters\", and when Qualifying Grand Prix is \"Soaring Grand Prix Of United Kingdom\"?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_43 WHERE class = \"15 meters\" AND qualifying_grand_prix = \"soaring grand prix of united kingdom\"\n",
            "\n",
            "Iteration/Step: 2021\n",
            "Sample ID: 13912\n",
            "Decoded Input: On what Date was the match with a Score of 6-2, 6-4?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_64 WHERE score = \"6-2, 6-4\"\n",
            "\n",
            "Iteration/Step: 2021\n",
            "Sample ID: 23378\n",
            "Decoded Input: What is the date of the game played at rich stadium?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_60 WHERE game_site = \"rich stadium\"\n",
            "\n",
            "Iteration/Step: 2022\n",
            "Sample ID: 13226\n",
            "Decoded Input: What is the UNGEGN, when the Value is 10 000?\n",
            "Decoded Target (Labels): SELECT ungegn FROM table_name_34 WHERE value = \"10 000\"\n",
            "\n",
            "Iteration/Step: 2022\n",
            "Sample ID: 17257\n",
            "Decoded Input: What is the highest Points in Position 2 with more than 3 Drawn games?\n",
            "Decoded Target (Labels): SELECT MAX(points) FROM table_name_75 WHERE position = 2 AND drawn > 3\n",
            "\n",
            "Iteration/Step: 2023\n",
            "Sample ID: 14169\n",
            "Decoded Input: Which host has more than 11 episodes?\n",
            "Decoded Target (Labels): SELECT host FROM table_name_95 WHERE _number_of_episodes > 11\n",
            "\n",
            "Iteration/Step: 2023\n",
            "Sample ID: 10105\n",
            "Decoded Input: What year is the event in athens, greece?\n",
            "Decoded Target (Labels): SELECT MAX(year) FROM table_name_19 WHERE venue = \"athens, greece\"\n",
            "\n",
            "Iteration/Step: 2024\n",
            "Sample ID: 1683\n",
            "Decoded Input: What was the Independent Church's Split off/ Continuation?\n",
            "Decoded Target (Labels): SELECT split_off___continuation_of FROM table_name_44 WHERE church_name = \"independent church\"\n",
            "\n",
            "Iteration/Step: 2024\n",
            "Sample ID: 7829\n",
            "Decoded Input: What are the famous titles of the artist \"Triumfall\"?\n",
            "Decoded Target (Labels): SELECT Famous_Title FROM artist WHERE Artist = \"Triumfall\"\n",
            "\n",
            "Iteration/Step: 2025\n",
            "Sample ID: 8515\n",
            "Decoded Input: How many attended tie number 19?\n",
            "Decoded Target (Labels): SELECT SUM(attendance) FROM table_name_76 WHERE tie_no = 19\n",
            "\n",
            "Iteration/Step: 2025\n",
            "Sample ID: 8449\n",
            "Decoded Input: Which team received 4 in race 1?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_68 WHERE race_1 = \"4\"\n",
            "\n",
            "Iteration/Step: 2026\n",
            "Sample ID: 6880\n",
            "Decoded Input: Can you tell me the average Average that has the Rank larger than 4, and the Player of dean minors?\n",
            "Decoded Target (Labels): SELECT AVG(average) FROM table_name_77 WHERE rank > 4 AND player = \"dean minors\"\n",
            "\n",
            "Iteration/Step: 2026\n",
            "Sample ID: 17017\n",
            "Decoded Input: Who won the 250 cc in 1985?\n",
            "Decoded Target (Labels): SELECT 250 AS _cc FROM table_name_19 WHERE year = \"1985\"\n",
            "\n",
            "Iteration/Step: 2027\n",
            "Sample ID: 23389\n",
            "Decoded Input: What is the lowest PI GP when the Reg GP is 1, Murray Bannerman is the Player, and the Pick # is under 58?\n",
            "Decoded Target (Labels): SELECT MIN(pl_gp) FROM table_name_53 WHERE reg_gp = 1 AND player = \"murray bannerman\" AND pick__number < 58\n",
            "\n",
            "Iteration/Step: 2027\n",
            "Sample ID: 23051\n",
            "Decoded Input: What is the total number of To Par, when Total is \"295\"?\n",
            "Decoded Target (Labels): SELECT COUNT(to_par) FROM table_name_38 WHERE total = 295\n",
            "\n",
            "Iteration/Step: 2028\n",
            "Sample ID: 6001\n",
            "Decoded Input: Which opponent has a record of 78-60?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_62 WHERE record = \"78-60\"\n",
            "\n",
            "Iteration/Step: 2028\n",
            "Sample ID: 742\n",
            "Decoded Input: Which Time has Notes of men's speed skating?\n",
            "Decoded Target (Labels): SELECT time FROM table_name_93 WHERE notes = \"men's speed skating\"\n",
            "\n",
            "Iteration/Step: 2029\n",
            "Sample ID: 3157\n",
            "Decoded Input: Where is Terre Haute North located?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_35 WHERE school = \"terre haute north\"\n",
            "\n",
            "Iteration/Step: 2029\n",
            "Sample ID: 21200\n",
            "Decoded Input: What was the titles of the episodes written by ken lazebnik?\n",
            "Decoded Target (Labels): SELECT title FROM table_11111116_7 WHERE written_by = \"Ken LaZebnik\"\n",
            "\n",
            "Iteration/Step: 2030\n",
            "Sample ID: 15673\n",
            "Decoded Input: What was the score when the home team was Toronto?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_89 WHERE home = \"toronto\"\n",
            "\n",
            "Iteration/Step: 2030\n",
            "Sample ID: 7026\n",
            "Decoded Input: Date of October 25, 1964 involves what record?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_1 WHERE date = \"october 25, 1964\"\n",
            "\n",
            "Iteration/Step: 2031\n",
            "Sample ID: 1084\n",
            "Decoded Input: What is the year with 116 laps?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_48 WHERE laps = 116\n",
            "\n",
            "Iteration/Step: 2031\n",
            "Sample ID: 11340\n",
            "Decoded Input: What is the description of role code ED?\n",
            "Decoded Target (Labels): SELECT role_description FROM ROLES WHERE role_code = \"ED\"\n",
            "\n",
            "Iteration/Step: 2032\n",
            "Sample ID: 22370\n",
            "Decoded Input: What is the lowest Gold count if the Bronze is 4 and Silver is greater than 5?\n",
            "Decoded Target (Labels): SELECT MIN(gold) FROM table_name_45 WHERE bronze = 4 AND silver > 5\n",
            "\n",
            "Iteration/Step: 2032\n",
            "Sample ID: 419\n",
            "Decoded Input: What is the length in feet of the Jiangzhou arch?\n",
            "Decoded Target (Labels): SELECT length___ft__ FROM table_name_7 WHERE name = \"jiangzhou arch\"\n",
            "\n",
            "Iteration/Step: 2033\n",
            "Sample ID: 15008\n",
            "Decoded Input: What is the time of the Essendon home team game?\n",
            "Decoded Target (Labels): SELECT time FROM table_name_81 WHERE home_team = \"essendon\"\n",
            "\n",
            "Iteration/Step: 2033\n",
            "Sample ID: 17813\n",
            "Decoded Input: Which gene is ongoing and has an intramuscular route of administration?\n",
            "Decoded Target (Labels): SELECT gene FROM table_name_42 WHERE route_of_administration = \"intramuscular\" AND status = \"ongoing\"\n",
            "\n",
            "Iteration/Step: 2034\n",
            "Sample ID: 16227\n",
            "Decoded Input: What position did Dave Johnson play?\n",
            "Decoded Target (Labels): SELECT position FROM table_1473672_5 WHERE player = \"Dave Johnson\"\n",
            "\n",
            "Iteration/Step: 2034\n",
            "Sample ID: 5059\n",
            "Decoded Input: which opponents in the u.s. championships played after 1945 and had a score of 3–6, 6–4, 2–6, 6–3, 20–18?\n",
            "Decoded Target (Labels): SELECT opponents_in_the_final FROM table_name_5 WHERE championship = \"u.s. championships\" AND year > 1945 AND score = \"3–6, 6–4, 2–6, 6–3, 20–18\"\n",
            "\n",
            "Iteration/Step: 2035\n",
            "Sample ID: 14026\n",
            "Decoded Input: Which player has a pick of 175?\n",
            "Decoded Target (Labels): SELECT player FROM table_name_58 WHERE pick = 175\n",
            "\n",
            "Iteration/Step: 2035\n",
            "Sample ID: 4438\n",
            "Decoded Input: What year was remark #104 us?\n",
            "Decoded Target (Labels): SELECT year FROM table_name_58 WHERE remark = \"#104 us\"\n",
            "\n",
            "Iteration/Step: 2036\n",
            "Sample ID: 16728\n",
            "Decoded Input: What was the Result on October 27, 2002?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_66 WHERE date = \"october 27, 2002\"\n",
            "\n",
            "Iteration/Step: 2036\n",
            "Sample ID: 7429\n",
            "Decoded Input: What is the second party where the first party is Tory and the year is 1820?\n",
            "Decoded Target (Labels): SELECT second_party FROM table_name_88 WHERE first_party = \"tory\" AND year = 1820\n",
            "\n",
            "Iteration/Step: 2037\n",
            "Sample ID: 24575\n",
            "Decoded Input: Which Opponent has a Date of november 21, 1999?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_9 WHERE date = \"november 21, 1999\"\n",
            "\n",
            "Iteration/Step: 2037\n",
            "Sample ID: 25371\n",
            "Decoded Input: Name the year started where car number is 55\n",
            "Decoded Target (Labels): SELECT MAX(year_started) FROM table_1688640_4 WHERE car__number = \"55\"\n",
            "\n",
            "Iteration/Step: 2038\n",
            "Sample ID: 7551\n",
            "Decoded Input: What is the minimum possible for the NJCAA championships?\n",
            "Decoded Target (Labels): SELECT MIN(njcaa_championships) FROM table_22319599_1\n",
            "\n",
            "Iteration/Step: 2038\n",
            "Sample ID: 2414\n",
            "Decoded Input: What is the average word count with crs and subframes lesser than 2?\n",
            "Decoded Target (Labels): SELECT AVG(word__number) FROM table_name_9 WHERE name = \"crs\" AND subframe__number < 2\n",
            "\n",
            "Iteration/Step: 2039\n",
            "Sample ID: 14869\n",
            "Decoded Input: What is the club when the chairman is roger lambrecht?\n",
            "Decoded Target (Labels): SELECT club FROM table_27374004_2 WHERE chairman = \"Roger Lambrecht\"\n",
            "\n",
            "Iteration/Step: 2039\n",
            "Sample ID: 13097\n",
            "Decoded Input: What is Score, when Set 3 is 17-25?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_67 WHERE set_3 = \"17-25\"\n",
            "\n",
            "Iteration/Step: 2040\n",
            "Sample ID: 1646\n",
            "Decoded Input: What is the maximum number of wins in the formula 3 euro series? \n",
            "Decoded Target (Labels): SELECT MAX(wins) FROM table_24330803_1 WHERE series = \"Formula 3 Euro series\"\n",
            "\n",
            "Iteration/Step: 2040\n",
            "Sample ID: 19905\n",
            "Decoded Input: Find the names of all stores in Khanewal District.\n",
            "Decoded Target (Labels): SELECT t1.store_name FROM store AS t1 JOIN store_district AS t2 ON t1.store_id = t2.store_id JOIN district AS t3 ON t2.district_id = t3.district_id WHERE t3.district_name = \"Khanewal District\"\n",
            "\n",
            "Iteration/Step: 2041\n",
            "Sample ID: 5558\n",
            "Decoded Input: What was the opponent on november 8, 1981?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_6 WHERE date = \"november 8, 1981\"\n",
            "\n",
            "Iteration/Step: 2041\n",
            "Sample ID: 3239\n",
            "Decoded Input: What is the latest year rafael nadal was in the French Open, Roger Federer was in Wimbledon, and Roger Federer was in the Australian Open?\n",
            "Decoded Target (Labels): SELECT MAX(year) FROM table_name_71 WHERE french_open = \"rafael nadal\" AND wimbledon = \"roger federer\" AND australian_open = \"roger federer\"\n",
            "\n",
            "Iteration/Step: 2042\n",
            "Sample ID: 4880\n",
            "Decoded Input: Which Score has a Date of 28 february 1953, and a Tie no of 3?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_14 WHERE date = \"28 february 1953\" AND tie_no = \"3\"\n",
            "\n",
            "Iteration/Step: 2042\n",
            "Sample ID: 17728\n",
            "Decoded Input: What is the winning coach total number if the top team in regular season (points) is the Kansas City Spurs (110 points)?\n",
            "Decoded Target (Labels): SELECT COUNT(winning_coach) FROM table_237757_3 WHERE top_team_in_regular_season__points_ = \"Kansas City Spurs (110 points)\"\n",
            "\n",
            "Iteration/Step: 2043\n",
            "Sample ID: 21056\n",
            "Decoded Input: Which team 1 has vfl gummersbach as team 2?\n",
            "Decoded Target (Labels): SELECT team_1 FROM table_name_13 WHERE team_2 = \"vfl gummersbach\"\n",
            "\n",
            "Iteration/Step: 2043\n",
            "Sample ID: 14199\n",
            "Decoded Input: What years were the inactive North Carolina chapter active?\n",
            "Decoded Target (Labels): SELECT charter_range FROM table_name_15 WHERE status = \"inactive\" AND state = \"north carolina\"\n",
            "\n",
            "Iteration/Step: 2044\n",
            "Sample ID: 22289\n",
            "Decoded Input: What's the total of the Morse Taper number when the D (max) is 20 and the B (max) greater than 94?\n",
            "Decoded Target (Labels): SELECT SUM(morse_taper_number) FROM table_name_1 WHERE d__max_ = 20 AND b__max_ > 94\n",
            "\n",
            "Iteration/Step: 2044\n",
            "Sample ID: 9503\n",
            "Decoded Input: Which Altitude (mslm) is the highest one that has an Area (km 2) smaller than 13.01, and a Population of 74536, and a Density (inhabitants/km 2) larger than 5869?\n",
            "Decoded Target (Labels): SELECT MAX(altitude__mslm_) FROM table_name_20 WHERE area__km_2__ < 13.01 AND population = 74536 AND density__inhabitants_km_2__ > 5869\n",
            "\n",
            "Iteration/Step: 2045\n",
            "Sample ID: 18081\n",
            "Decoded Input: What's the IS-2 when the KV-1S is 114?\n",
            "Decoded Target (Labels): SELECT is_2_m1945 FROM table_name_91 WHERE kv_1s_m1942 = \"114\"\n",
            "\n",
            "Iteration/Step: 2045\n",
            "Sample ID: 23159\n",
            "Decoded Input: If the original air date is February 4, 2003, what is the episode title?\n",
            "Decoded Target (Labels): SELECT title FROM table_228973_9 WHERE original_air_date = \"February 4, 2003\"\n",
            "\n",
            "Iteration/Step: 2046\n",
            "Sample ID: 5948\n",
            "Decoded Input: What is every year for joined with the Ravens nickname?\n",
            "Decoded Target (Labels): SELECT joined FROM table_262514_1 WHERE nickname = \"Ravens\"\n",
            "\n",
            "Iteration/Step: 2046\n",
            "Sample ID: 12723\n",
            "Decoded Input: If there are 28 points, what is the time/retired?\n",
            "Decoded Target (Labels): SELECT time_retired FROM table_17330069_1 WHERE points = \"28\"\n",
            "\n",
            "Iteration/Step: 2047\n",
            "Sample ID: 18011\n",
            "Decoded Input: What team has a kit manufacturer of Umbro and Eric Cantona as captain?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_41 WHERE kit_manufacturer = \"umbro\" AND captain = \"eric cantona\"\n",
            "\n",
            "Iteration/Step: 2047\n",
            "Sample ID: 7315\n",
            "Decoded Input: Show the names of aircrafts that are associated with both an airport named \"London Heathrow\" and an airport named \"London Gatwick\"\n",
            "Decoded Target (Labels): SELECT T1.Aircraft FROM aircraft AS T1 JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID JOIN airport AS T3 ON T2.Airport_ID = T3.Airport_ID WHERE T3.Airport_Name = \"London Heathrow\" INTERSECT SELECT T1.Aircraft FROM aircraft AS T1 JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID JOIN airport AS T3 ON T2.Airport_ID = T3.Airport_ID WHERE T3.Airport_Name = \"London Gatwick\"\n",
            "\n",
            "Iteration/Step: 2048\n",
            "Sample ID: 20352\n",
            "Decoded Input: Name the total number of represents for clary sermina delgado cid\n",
            "Decoded Target (Labels): SELECT COUNT(represents) FROM table_26301697_2 WHERE contestant = \"Clary Sermina Delgado Cid\"\n",
            "\n",
            "Iteration/Step: 2048\n",
            "Sample ID: 21993\n",
            "Decoded Input: What is the total for the week in the game against the Chicago Bears\n",
            "Decoded Target (Labels): SELECT COUNT(week) FROM table_name_38 WHERE opponent = \"chicago bears\"\n",
            "\n",
            "Iteration/Step: 2049\n",
            "Sample ID: 332\n",
            "Decoded Input: How many dfb-pokal did kevin-prince boateng have?\n",
            "Decoded Target (Labels): SELECT COUNT(dfb_pokal) FROM table_22167196_1 WHERE player = \"Kevin-Prince Boateng\"\n",
            "\n",
            "Iteration/Step: 2049\n",
            "Sample ID: 10839\n",
            "Decoded Input: What's k. j. choi's to par?\n",
            "Decoded Target (Labels): SELECT to_par FROM table_name_2 WHERE player = \"k. j. choi\"\n",
            "\n",
            "Iteration/Step: 2050\n",
            "Sample ID: 2239\n",
            "Decoded Input: Name the candidates for illinois 15\n",
            "Decoded Target (Labels): SELECT candidates FROM table_1341672_14 WHERE district = \"Illinois 15\"\n",
            "\n",
            "Iteration/Step: 2050\n",
            "Sample ID: 24628\n",
            "Decoded Input: What was the u.s. viewers (millions) when the production code was 4alh19?\n",
            "Decoded Target (Labels): SELECT us_viewers__million_ FROM table_26702204_1 WHERE production_code = \"4ALH19\"\n",
            "\n",
            "Iteration/Step: 2051\n",
            "Sample ID: 25420\n",
            "Decoded Input: What is the lowest altitude of the flight with a mach bigger than 0.905 and a duration of 00:06:17?\n",
            "Decoded Target (Labels): SELECT MIN(altitude__ft_) FROM table_name_80 WHERE mach > 0.905 AND duration = \"00:06:17\"\n",
            "\n",
            "Iteration/Step: 2051\n",
            "Sample ID: 11807\n",
            "Decoded Input: Name the Qual 2 which has the name of katherine legge\n",
            "Decoded Target (Labels): SELECT qual_2 FROM table_name_40 WHERE name = \"katherine legge\"\n",
            "\n",
            "Iteration/Step: 2052\n",
            "Sample ID: 8116\n",
            "Decoded Input: What is the interaction type of the enzyme named 'ALA synthase' and the medicine named 'Aripiprazole'?\n",
            "Decoded Target (Labels): SELECT T1.interaction_type FROM medicine_enzyme_interaction AS T1 JOIN medicine AS T2 ON T1.medicine_id = T2.id JOIN enzyme AS T3 ON T1.enzyme_id = T3.id WHERE T3.name = 'ALA synthase' AND T2.name = 'Aripiprazole'\n",
            "\n",
            "Iteration/Step: 2052\n",
            "Sample ID: 24319\n",
            "Decoded Input: Name the october when the september is dalene kurtis\n",
            "Decoded Target (Labels): SELECT october FROM table_name_47 WHERE september = \"dalene kurtis\"\n",
            "\n",
            "Iteration/Step: 2053\n",
            "Sample ID: 87\n",
            "Decoded Input: What is the 1995 GDP when 1990 GDP is 441 and 1985 GDP is less than 359?\n",
            "Decoded Target (Labels): SELECT MIN(1995) FROM table_name_14 WHERE 1990 = 441 AND 1985 < 359\n",
            "\n",
            "Iteration/Step: 2053\n",
            "Sample ID: 11572\n",
            "Decoded Input: What round was northeastern college player Reggie Lewis drafted in?\n",
            "Decoded Target (Labels): SELECT MIN(round) FROM table_name_26 WHERE college = \"northeastern\" AND player = \"reggie lewis\"\n",
            "\n",
            "Iteration/Step: 2054\n",
            "Sample ID: 20079\n",
            "Decoded Input: What team does Kenny Smith play for?\n",
            "Decoded Target (Labels): SELECT school_club_team FROM table_name_25 WHERE player = \"kenny smith\"\n",
            "\n",
            "Iteration/Step: 2054\n",
            "Sample ID: 14705\n",
            "Decoded Input: How many games or records were played on the Miami Orange Bowl?\n",
            "Decoded Target (Labels): SELECT COUNT(record) FROM table_17386066_2 WHERE stadium = \"Miami Orange Bowl\"\n",
            "\n",
            "Iteration/Step: 2055\n",
            "Sample ID: 20427\n",
            "Decoded Input: Name the record for 1997\n",
            "Decoded Target (Labels): SELECT record FROM table_name_78 WHERE year = \"1997\"\n",
            "\n",
            "Iteration/Step: 2055\n",
            "Sample ID: 10769\n",
            "Decoded Input: Who did the Browns play on October 13, 1968?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_7 WHERE date = \"october 13, 1968\"\n",
            "\n",
            "Iteration/Step: 2056\n",
            "Sample ID: 22257\n",
            "Decoded Input: Record of 3-3-1 had what lowest game?\n",
            "Decoded Target (Labels): SELECT MIN(game) FROM table_name_81 WHERE record = \"3-3-1\"\n",
            "\n",
            "Iteration/Step: 2056\n",
            "Sample ID: 23646\n",
            "Decoded Input: What is the Record on april 13?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_32 WHERE date = \"april 13\"\n",
            "\n",
            "Iteration/Step: 2057\n",
            "Sample ID: 25419\n",
            "Decoded Input: What was the club when home ground was Central Reserve?\n",
            "Decoded Target (Labels): SELECT club FROM table_name_59 WHERE home_ground = \"central reserve\"\n",
            "\n",
            "Iteration/Step: 2057\n",
            "Sample ID: 17294\n",
            "Decoded Input: What week of the season had a date of october 5, 1975?\n",
            "Decoded Target (Labels): SELECT MIN(week) FROM table_name_24 WHERE date = \"october 5, 1975\"\n",
            "\n",
            "Iteration/Step: 2058\n",
            "Sample ID: 14032\n",
            "Decoded Input: What result has a year after 2002?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_35 WHERE year > 2002\n",
            "\n",
            "Iteration/Step: 2058\n",
            "Sample ID: 3748\n",
            "Decoded Input: Which Segment C has a Segment B of fish food?\n",
            "Decoded Target (Labels): SELECT segment_c FROM table_name_54 WHERE segment_b = \"fish food\"\n",
            "\n",
            "Iteration/Step: 2059\n",
            "Sample ID: 508\n",
            "Decoded Input: How much Scored has Losses smaller than 0?\n",
            "Decoded Target (Labels): SELECT SUM(scored) FROM table_name_75 WHERE losses < 0\n",
            "\n",
            "Iteration/Step: 2059\n",
            "Sample ID: 19716\n",
            "Decoded Input: what's the points against with won being 11\n",
            "Decoded Target (Labels): SELECT points_against FROM table_14058433_4 WHERE won = \"11\"\n",
            "\n",
            "Iteration/Step: 2060\n",
            "Sample ID: 25831\n",
            "Decoded Input: What is the average number of goals conceded where more than 19 goals were scored, the team had 31 points, and more than 7 draws?\n",
            "Decoded Target (Labels): SELECT AVG(goals_conceded__gc_) FROM table_name_80 WHERE goals_scored__gf_ > 19 AND points__pts_ = 31 AND draw__pe_ > 7\n",
            "\n",
            "Iteration/Step: 2060\n",
            "Sample ID: 15917\n",
            "Decoded Input: WHAT IS THE TYPE OF LAND WITH A 2007 POPULATION SMALLER THAN 4346, 2010 POPULATION LARGER THAN 3385, FROM BARANGAY OF MANALONGON?\n",
            "Decoded Target (Labels): SELECT geographic_character FROM table_name_10 WHERE population__2007_ < 4346 AND population__2010_ > 3385 AND barangay = \"manalongon\"\n",
            "\n",
            "Iteration/Step: 2061\n",
            "Sample ID: 18783\n",
            "Decoded Input: What is the price of 60 mbps downstream?\n",
            "Decoded Target (Labels): SELECT price FROM table_name_22 WHERE downstream = \"60 mbps\"\n",
            "\n",
            "Iteration/Step: 2061\n",
            "Sample ID: 18173\n",
            "Decoded Input: Who has the lead in the season where Cathrine Norberg is second and Anna Rindeskog is third?\n",
            "Decoded Target (Labels): SELECT lead FROM table_name_70 WHERE second = \"cathrine norberg\" AND third = \"anna rindeskog\"\n",
            "\n",
            "Iteration/Step: 2062\n",
            "Sample ID: 7355\n",
            "Decoded Input: What is the rank associated with 141.48 points?\n",
            "Decoded Target (Labels): SELECT rank FROM table_name_71 WHERE points = 141.48\n",
            "\n",
            "Iteration/Step: 2062\n",
            "Sample ID: 10635\n",
            "Decoded Input: What is Season, when Prize is \"$100,000\"?\n",
            "Decoded Target (Labels): SELECT season FROM table_name_37 WHERE prize = \"$100,000\"\n",
            "\n",
            "Iteration/Step: 2063\n",
            "Sample ID: 23905\n",
            "Decoded Input: What is the total number of 3rd place finishes for racers with 0 titles?\n",
            "Decoded Target (Labels): SELECT SUM(3 AS rd_pl) FROM table_name_31 WHERE titles < 0\n",
            "\n",
            "Iteration/Step: 2063\n",
            "Sample ID: 16126\n",
            "Decoded Input: Can you tell me the Time that has the Opponent of phil baroni?\n",
            "Decoded Target (Labels): SELECT time FROM table_name_75 WHERE opponent = \"phil baroni\"\n",
            "\n",
            "Iteration/Step: 2064\n",
            "Sample ID: 17791\n",
            "Decoded Input: What distance did giovanni lombardi win after stage 5?\n",
            "Decoded Target (Labels): SELECT distance FROM table_name_10 WHERE stage > 5 AND winner = \"giovanni lombardi\"\n",
            "\n",
            "Iteration/Step: 2064\n",
            "Sample ID: 15796\n",
            "Decoded Input: When the Apps were smaller than 22, what's the lowest amount of goals scored in a game?\n",
            "Decoded Target (Labels): SELECT MIN(goals) FROM table_name_33 WHERE apps < 22\n",
            "\n",
            "Iteration/Step: 2065\n",
            "Sample ID: 53\n",
            "Decoded Input: What is the average number of Gold medals when there are 5 bronze medals?\n",
            "Decoded Target (Labels): SELECT AVG(gold) FROM table_name_82 WHERE bronze = 5\n",
            "\n",
            "Iteration/Step: 2065\n",
            "Sample ID: 3076\n",
            "Decoded Input: How many records show Utah as the opponent?\n",
            "Decoded Target (Labels): SELECT COUNT(record) FROM table_22815265_1 WHERE opponent = \"Utah\"\n",
            "\n",
            "Iteration/Step: 2066\n",
            "Sample ID: 19347\n",
            "Decoded Input: What is the church name located in Høyanger?\n",
            "Decoded Target (Labels): SELECT church_name FROM table_178389_1 WHERE location_of_the_church = \"Høyanger\"\n",
            "\n",
            "Iteration/Step: 2066\n",
            "Sample ID: 21172\n",
            "Decoded Input: Which Opponent in the final has an Outcome of winner, and a Date larger than 1992, and a Surface of clay, and a Score in the final of 3–6, 6–2, 6–1?\n",
            "Decoded Target (Labels): SELECT opponent_in_the_final FROM table_name_65 WHERE outcome = \"winner\" AND date > 1992 AND surface = \"clay\" AND score_in_the_final = \"3–6, 6–2, 6–1\"\n",
            "\n",
            "Iteration/Step: 2067\n",
            "Sample ID: 23072\n",
            "Decoded Input: Name the sumof points for year less than 1994 and chassis of lola lc89b\n",
            "Decoded Target (Labels): SELECT SUM(points) FROM table_name_47 WHERE year < 1994 AND chassis = \"lola lc89b\"\n",
            "\n",
            "Iteration/Step: 2067\n",
            "Sample ID: 17849\n",
            "Decoded Input: If the establishment is 49319, what is the sales, receipts or shipments maximum amount?\n",
            "Decoded Target (Labels): SELECT MAX(sales), _receipts, _or_shipments__$1, 000 AS _ FROM table_23802822_1 WHERE establishments = 49319\n",
            "\n",
            "Iteration/Step: 2068\n",
            "Sample ID: 24683\n",
            "Decoded Input: What is the organized date of the stake with an occupation of senior buyer for Wal-mart?\n",
            "Decoded Target (Labels): SELECT organized FROM table_name_67 WHERE occupation = \"senior buyer for wal-mart\"\n",
            "\n",
            "Iteration/Step: 2068\n",
            "Sample ID: 392\n",
            "Decoded Input: Who was the winning driver with the winning team Opel Team Holzer 1, and a round under 9 with the fastest lap being Bernd Schneider?\n",
            "Decoded Target (Labels): SELECT winning_driver FROM table_name_96 WHERE winning_team = \"opel team holzer 1\" AND round < 9 AND fastest_lap = \"bernd schneider\"\n",
            "\n",
            "Iteration/Step: 2069\n",
            "Sample ID: 13522\n",
            "Decoded Input: Which Tournament has a Score of 6–4, 6–2?\n",
            "Decoded Target (Labels): SELECT tournament FROM table_name_62 WHERE score = \"6–4, 6–2\"\n",
            "\n",
            "Iteration/Step: 2069\n",
            "Sample ID: 16461\n",
            "Decoded Input: who is the captain where coach is geoff miles\n",
            "Decoded Target (Labels): SELECT captain FROM table_1165048_1 WHERE coach = \"Geoff Miles\"\n",
            "\n",
            "Iteration/Step: 2070\n",
            "Sample ID: 1033\n",
            "Decoded Input: How many scores have a Place of t5?\n",
            "Decoded Target (Labels): SELECT COUNT(score) FROM table_name_2 WHERE place = \"t5\"\n",
            "\n",
            "Iteration/Step: 2070\n",
            "Sample ID: 23938\n",
            "Decoded Input: What season episode is directed by Skipp Sudduth?\n",
            "Decoded Target (Labels): SELECT season__number FROM table_17356205_1 WHERE directed_by = \"Skipp Sudduth\"\n",
            "\n",
            "Iteration/Step: 2071\n",
            "Sample ID: 9395\n",
            "Decoded Input: List the names and decor of rooms that have a king bed. Sort the list by their price.\n",
            "Decoded Target (Labels): SELECT roomName, decor FROM Rooms WHERE bedtype = 'King' ORDER BY basePrice\n",
            "\n",
            "Iteration/Step: 2071\n",
            "Sample ID: 12471\n",
            "Decoded Input: Which Date has a Score of 6–3, 7–6?\n",
            "Decoded Target (Labels): SELECT SUM(date) FROM table_name_3 WHERE score = \"6–3, 7–6\"\n",
            "\n",
            "Iteration/Step: 2072\n",
            "Sample ID: 18119\n",
            "Decoded Input: What date is for Venue of jjb stadium, and a Result of w?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_14 WHERE venue = \"jjb stadium\" AND result = \"w\"\n",
            "\n",
            "Iteration/Step: 2072\n",
            "Sample ID: 541\n",
            "Decoded Input: What is Etymology, when Rank is 14?\n",
            "Decoded Target (Labels): SELECT etymology FROM table_name_10 WHERE rank = 14\n",
            "\n",
            "Iteration/Step: 2073\n",
            "Sample ID: 25396\n",
            "Decoded Input: Name the land for ada\n",
            "Decoded Target (Labels): SELECT COUNT(land___sqmi__) FROM table_18600760_1 WHERE township = \"Ada\"\n",
            "\n",
            "Iteration/Step: 2073\n",
            "Sample ID: 588\n",
            "Decoded Input: Which Location has Floors smaller than 27, and a Building of 150 elgin?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_71 WHERE floors < 27 AND building = \"150 elgin\"\n",
            "\n",
            "Iteration/Step: 2074\n",
            "Sample ID: 5705\n",
            "Decoded Input: Which Floors has a Location of tower hill?\n",
            "Decoded Target (Labels): SELECT floors FROM table_name_89 WHERE location = \"tower hill\"\n",
            "\n",
            "Iteration/Step: 2074\n",
            "Sample ID: 15227\n",
            "Decoded Input: When the Away team is melbourne, what venue do they play at?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_74 WHERE away_team = \"melbourne\"\n",
            "\n",
            "Iteration/Step: 2075\n",
            "Sample ID: 6933\n",
            "Decoded Input: What is the least rank with more than 16 sets won and less than 1 loss?\n",
            "Decoded Target (Labels): SELECT MIN(rank) FROM table_name_47 WHERE sets_won > 16 AND loss < 1\n",
            "\n",
            "Iteration/Step: 2075\n",
            "Sample ID: 354\n",
            "Decoded Input: What school did Pat Osborn attend? \n",
            "Decoded Target (Labels): SELECT school FROM table_11677100_5 WHERE player = \"Pat Osborn\"\n",
            "\n",
            "Iteration/Step: 2076\n",
            "Sample ID: 2082\n",
            "Decoded Input: What country was the golfer with a score of 72-72-72=216 representing?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_78 WHERE score = 72 - 72 - 72 = 216\n",
            "\n",
            "Iteration/Step: 2076\n",
            "Sample ID: 2571\n",
            "Decoded Input: How many positions had jersey number 32\n",
            "Decoded Target (Labels): SELECT COUNT(position) FROM table_11734041_18 WHERE no_s_ = \"32\"\n",
            "\n",
            "Iteration/Step: 2077\n",
            "Sample ID: 16326\n",
            "Decoded Input: Who was the loser against the New York Giants in 2001?\n",
            "Decoded Target (Labels): SELECT loser FROM table_name_43 WHERE year = 2001 AND winner = \"new york giants\"\n",
            "\n",
            "Iteration/Step: 2077\n",
            "Sample ID: 25845\n",
            "Decoded Input: When was the first game associated with over 4 losses?\n",
            "Decoded Target (Labels): SELECT first_game FROM table_name_89 WHERE lost > 4\n",
            "\n",
            "Iteration/Step: 2078\n",
            "Sample ID: 18725\n",
            "Decoded Input: What Date has the Region Europe and a Catalog of 74321 45851 2?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_33 WHERE region = \"europe\" AND catalog = \"74321 45851 2\"\n",
            "\n",
            "Iteration/Step: 2078\n",
            "Sample ID: 8395\n",
            "Decoded Input: What home team has june 22 as the date?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_87 WHERE date = \"june 22\"\n",
            "\n",
            "Iteration/Step: 2079\n",
            "Sample ID: 25851\n",
            "Decoded Input: What's the record for the game with an attendance of 49,222?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_28 WHERE attendance = \"49,222\"\n",
            "\n",
            "Iteration/Step: 2079\n",
            "Sample ID: 9474\n",
            "Decoded Input: What is the incident number of the incident that occurred in Dantewada, Chattisgarh?\n",
            "Decoded Target (Labels): SELECT incident_no FROM table_name_8 WHERE place = \"dantewada, chattisgarh\"\n",
            "\n",
            "Iteration/Step: 2080\n",
            "Sample ID: 3820\n",
            "Decoded Input: Name the city for thailand\n",
            "Decoded Target (Labels): SELECT city FROM table_name_97 WHERE country = \"thailand\"\n",
            "\n",
            "Iteration/Step: 2080\n",
            "Sample ID: 6326\n",
            "Decoded Input: Which park had most attendances in 2008?\n",
            "Decoded Target (Labels): SELECT T2.park_name FROM home_game AS T1 JOIN park AS T2 ON T1.park_id = T2.park_id WHERE T1.year = 2008 ORDER BY T1.attendance DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 2081\n",
            "Sample ID: 5258\n",
            "Decoded Input: Name the points won for 1230\n",
            "Decoded Target (Labels): SELECT points AS won FROM table_23501776_16 WHERE points = 1230\n",
            "\n",
            "Iteration/Step: 2081\n",
            "Sample ID: 5980\n",
            "Decoded Input: What is Record, when High Rebounds is \"Tyson Chandler (6)\"?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_68 WHERE high_rebounds = \"tyson chandler (6)\"\n",
            "\n",
            "Iteration/Step: 2082\n",
            "Sample ID: 17437\n",
            "Decoded Input: Name the least division\n",
            "Decoded Target (Labels): SELECT MIN(division) FROM table_2361911_2\n",
            "\n",
            "Iteration/Step: 2082\n",
            "Sample ID: 23981\n",
            "Decoded Input: What country did Jonas Geirnaert direct a film in?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_30 WHERE director_s_ = \"jonas geirnaert\"\n",
            "\n",
            "Iteration/Step: 2083\n",
            "Sample ID: 20645\n",
            "Decoded Input: For the game played at the Boston Garden with a score of 118-110, what is the opposing team's record?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_68 WHERE location = \"boston garden\" AND score = \"118-110\"\n",
            "\n",
            "Iteration/Step: 2083\n",
            "Sample ID: 15987\n",
            "Decoded Input: What is the original airdate of episode #31?\n",
            "Decoded Target (Labels): SELECT original_air_date FROM table_28967275_2 WHERE episode__number = 31\n",
            "\n",
            "Iteration/Step: 2084\n",
            "Sample ID: 20896\n",
            "Decoded Input: What is the margin when periyakulam is the constituency?\n",
            "Decoded Target (Labels): SELECT margin FROM table_22754491_1 WHERE constituency = \"Periyakulam\"\n",
            "\n",
            "Iteration/Step: 2084\n",
            "Sample ID: 20744\n",
            "Decoded Input: What location and attendance were there for game 5?\n",
            "Decoded Target (Labels): SELECT location_attendance FROM table_27756474_2 WHERE game = 5\n",
            "\n",
            "Iteration/Step: 2085\n",
            "Sample ID: 18745\n",
            "Decoded Input: Which TV network has a country of origin of Iran?\n",
            "Decoded Target (Labels): SELECT tv_network_s_ FROM table_29799700_2 WHERE country = \"Iran\"\n",
            "\n",
            "Iteration/Step: 2085\n",
            "Sample ID: 10687\n",
            "Decoded Input: What is the title and director for the movie with highest worldwide gross in the year 2000 or before?\n",
            "Decoded Target (Labels): SELECT title, director FROM movie WHERE YEAR <= 2000 ORDER BY gross_worldwide DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 2086\n",
            "Sample ID: 13773\n",
            "Decoded Input: What Tournament of monte carlo had 1996 and a 1987 of nme?\n",
            "Decoded Target (Labels): SELECT 1996 FROM table_name_45 WHERE 1987 = \"nme\" AND tournament = \"monte carlo\"\n",
            "\n",
            "Iteration/Step: 2086\n",
            "Sample ID: 11981\n",
            "Decoded Input: What was the handicap when the prize money was 120s?\n",
            "Decoded Target (Labels): SELECT handicap FROM table_2896329_1 WHERE prize_money = \"120s\"\n",
            "\n",
            "Iteration/Step: 2087\n",
            "Sample ID: 17357\n",
            "Decoded Input: Which census ranking is 57.06 km big?\n",
            "Decoded Target (Labels): SELECT census_ranking FROM table_name_95 WHERE area_km_2 = 57.06\n",
            "\n",
            "Iteration/Step: 2087\n",
            "Sample ID: 24812\n",
            "Decoded Input: Where is the audition city when the venue is upi convention center?\n",
            "Decoded Target (Labels): SELECT audition_city FROM table_28793672_1 WHERE venue = \"UPI Convention Center\"\n",
            "\n",
            "Iteration/Step: 2088\n",
            "Sample ID: 2300\n",
            "Decoded Input: What is the average attendance on October 9, 1983?\n",
            "Decoded Target (Labels): SELECT AVG(attendance) FROM table_name_11 WHERE date = \"october 9, 1983\"\n",
            "\n",
            "Iteration/Step: 2088\n",
            "Sample ID: 11083\n",
            "Decoded Input: What was the score of the game in which the Toronto Maple Leafs were visitors?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_97 WHERE visitor = \"toronto maple leafs\"\n",
            "\n",
            "Iteration/Step: 2089\n",
            "Sample ID: 1488\n",
            "Decoded Input: What is the average number of hosts for parties?\n",
            "Decoded Target (Labels): SELECT AVG(Number_of_hosts) FROM party\n",
            "\n",
            "Iteration/Step: 2089\n",
            "Sample ID: 9264\n",
            "Decoded Input: What is the lost number when the team played 26 games and there were 83 points?\n",
            "Decoded Target (Labels): SELECT lost FROM table_name_32 WHERE played = \"26\" AND points = \"83\"\n",
            "\n",
            "Iteration/Step: 2090\n",
            "Sample ID: 15958\n",
            "Decoded Input: What type of game was held on December 22?\n",
            "Decoded Target (Labels): SELECT type_of_game FROM table_name_57 WHERE date = \"december 22\"\n",
            "\n",
            "Iteration/Step: 2090\n",
            "Sample ID: 25431\n",
            "Decoded Input: What is the average points for a team that lost 4 and played more than 28 games?\n",
            "Decoded Target (Labels): SELECT AVG(points) FROM table_name_56 WHERE lost = 4 AND played > 28\n",
            "\n",
            "Iteration/Step: 2091\n",
            "Sample ID: 12582\n",
            "Decoded Input: At what location was the score W 82-76?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_68 WHERE score = \"w 82-76\"\n",
            "\n",
            "Iteration/Step: 2091\n",
            "Sample ID: 936\n",
            "Decoded Input: Name the 2010 with tournament of grand slam tournaments\n",
            "Decoded Target (Labels): SELECT 2010 FROM table_name_33 WHERE tournament = \"grand slam tournaments\"\n",
            "\n",
            "Iteration/Step: 2092\n",
            "Sample ID: 1995\n",
            "Decoded Input: How many players have an affiliation with University of Maryland?\n",
            "Decoded Target (Labels): SELECT COUNT(player) FROM table_25518547_2 WHERE affiliation = \"University of Maryland\"\n",
            "\n",
            "Iteration/Step: 2092\n",
            "Sample ID: 11598\n",
            "Decoded Input: What is the date of the match with a winner outcome and jim courier as the opponent in the final?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_27 WHERE outcome = \"winner\" AND opponent_in_the_final = \"jim courier\"\n",
            "\n",
            "Iteration/Step: 2093\n",
            "Sample ID: 16911\n",
            "Decoded Input: At Time Warner Cable Arena 12,096, what was the high points?\n",
            "Decoded Target (Labels): SELECT high_points FROM table_name_85 WHERE location_attendance = \"time warner cable arena 12,096\"\n",
            "\n",
            "Iteration/Step: 2093\n",
            "Sample ID: 18483\n",
            "Decoded Input: Where was the tour when  jing junhong li jiawei played womens doubles?\n",
            "Decoded Target (Labels): SELECT year_location FROM table_28138035_20 WHERE womens_doubles = \"Jing Junhong Li Jiawei\"\n",
            "\n",
            "Iteration/Step: 2094\n",
            "Sample ID: 23671\n",
            "Decoded Input: What are the names of the nations with the 3 lowest populations?\n",
            "Decoded Target (Labels): SELECT Name FROM country ORDER BY Population LIMIT 3\n",
            "\n",
            "Iteration/Step: 2094\n",
            "Sample ID: 20586\n",
            "Decoded Input: WHAT IS THE DRAW FOR PERFORMER ANDREA CUBRIC?\n",
            "Decoded Target (Labels): SELECT draw FROM table_name_76 WHERE performer = \"andrea cubric\"\n",
            "\n",
            "Iteration/Step: 2095\n",
            "Sample ID: 5453\n",
            "Decoded Input: What is the date when Aston Villa is the away team?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_98 WHERE away_team = \"aston villa\"\n",
            "\n",
            "Iteration/Step: 2095\n",
            "Sample ID: 6528\n",
            "Decoded Input: What is every affiliation for candidate Daren Ireland?\n",
            "Decoded Target (Labels): SELECT affiliation FROM table_25818630_1 WHERE candidate = \"Daren Ireland\"\n",
            "\n",
            "Iteration/Step: 2096\n",
            "Sample ID: 23379\n",
            "Decoded Input: Name the frequency mhz for fcc and ERP W of 9 watts\n",
            "Decoded Target (Labels): SELECT frequency_mhz FROM table_name_7 WHERE fcc_info = \"fcc\" AND erp_w = \"9 watts\"\n",
            "\n",
            "Iteration/Step: 2096\n",
            "Sample ID: 8275\n",
            "Decoded Input: when was the destroyer launched when it was laid down on 14 august 1942?\n",
            "Decoded Target (Labels): SELECT launched FROM table_name_91 WHERE laid_down = \"14 august 1942\"\n",
            "\n",
            "Iteration/Step: 2097\n",
            "Sample ID: 4800\n",
            "Decoded Input: What is the release format for titles after 1983?\n",
            "Decoded Target (Labels): SELECT release_format FROM table_name_55 WHERE release_date > 1983\n",
            "\n",
            "Iteration/Step: 2097\n",
            "Sample ID: 24339\n",
            "Decoded Input: What is the highest amount of extra points someone got when they scored 28 points but had 0 field goals?\n",
            "Decoded Target (Labels): SELECT MAX(extra_points) FROM table_name_20 WHERE points = 28 AND field_goals < 0\n",
            "\n",
            "Iteration/Step: 2098\n",
            "Sample ID: 2083\n",
            "Decoded Input: What is the match number where the result is ICL World by 8 wickets?\n",
            "Decoded Target (Labels): SELECT match_number FROM table_17103566_1 WHERE result = \"ICL World by 8 wickets\"\n",
            "\n",
            "Iteration/Step: 2098\n",
            "Sample ID: 3985\n",
            "Decoded Input: Name the Score united states of tom watson in united state?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_40 WHERE country = \"united states\" AND player = \"tom watson\"\n",
            "\n",
            "Iteration/Step: 2099\n",
            "Sample ID: 19426\n",
            "Decoded Input: Name the population 2000 census for 77 area\n",
            "Decoded Target (Labels): SELECT population_2000_census FROM table_14986292_1 WHERE area__km²_ = \"77\"\n",
            "\n",
            "Iteration/Step: 2099\n",
            "Sample ID: 7887\n",
            "Decoded Input: Who played the home team during the game on January 6?\n",
            "Decoded Target (Labels): SELECT home FROM table_name_56 WHERE date = \"january 6\"\n",
            "\n",
            "Iteration/Step: 2100\n",
            "Sample ID: 7703\n",
            "Decoded Input: What is the total number that 0 silver?\n",
            "Decoded Target (Labels): SELECT COUNT(total) FROM table_name_14 WHERE silver < 0\n",
            "\n",
            "Iteration/Step: 2100\n",
            "Sample ID: 1506\n",
            "Decoded Input: How much money did James Seddon request?\n",
            "Decoded Target (Labels): SELECT money_requested__£_ FROM table_name_2 WHERE entrepreneur_s_ = \"james seddon\"\n",
            "\n",
            "Iteration/Step: 2101\n",
            "Sample ID: 10795\n",
            "Decoded Input: What are the points for the Seven Sisters RFC club?\n",
            "Decoded Target (Labels): SELECT points FROM table_name_71 WHERE club = \"seven sisters rfc\"\n",
            "\n",
            "Iteration/Step: 2101\n",
            "Sample ID: 13000\n",
            "Decoded Input: What is the score of the United States, which has a to par of +5?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_84 WHERE country = \"united states\" AND to_par = \"+5\"\n",
            "\n",
            "Iteration/Step: 2102\n",
            "Sample ID: 14497\n",
            "Decoded Input: who is the incumbent where the candidates is william v. chappell, jr. (d) unopposed?\n",
            "Decoded Target (Labels): SELECT incumbent FROM table_1341672_10 WHERE candidates = \"William V. Chappell, Jr. (D) Unopposed\"\n",
            "\n",
            "Iteration/Step: 2102\n",
            "Sample ID: 1357\n",
            "Decoded Input: What year did the Ingots, who left after 2007, join?\n",
            "Decoded Target (Labels): SELECT COUNT(year_joined) FROM table_name_48 WHERE mascot = \"ingots\" AND year_left > 2007\n",
            "\n",
            "Iteration/Step: 2103\n",
            "Sample ID: 17207\n",
            "Decoded Input: What team did Johnson (11-7) play for?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_60 WHERE loss = \"johnson (11-7)\"\n",
            "\n",
            "Iteration/Step: 2103\n",
            "Sample ID: 10213\n",
            "Decoded Input: What was the score for south melbourne at home?\n",
            "Decoded Target (Labels): SELECT home_team AS score FROM table_name_2 WHERE home_team = \"south melbourne\"\n",
            "\n",
            "Iteration/Step: 2104\n",
            "Sample ID: 9115\n",
            "Decoded Input: Name the rank timeslot for 18-49 share being 13\n",
            "Decoded Target (Labels): SELECT COUNT(rank__timeslot_) FROM table_20971444_3 WHERE share__18_49_ = 13\n",
            "\n",
            "Iteration/Step: 2104\n",
            "Sample ID: 5671\n",
            "Decoded Input: Find the average hours for the students whose tryout decision is no.\n",
            "Decoded Target (Labels): SELECT AVG(T1.HS) FROM player AS T1 JOIN tryout AS T2 ON T1.pID = T2.pID WHERE T2.decision = 'no'\n",
            "\n",
            "Iteration/Step: 2105\n",
            "Sample ID: 4194\n",
            "Decoded Input: What were the years the building with 44 floors was tallest?\n",
            "Decoded Target (Labels): SELECT years_as_tallest FROM table_name_53 WHERE floors = \"44\"\n",
            "\n",
            "Iteration/Step: 2105\n",
            "Sample ID: 2096\n",
            "Decoded Input: What ride was manufactured by Zierer?\n",
            "Decoded Target (Labels): SELECT ride_name FROM table_name_43 WHERE manufacturer = \"zierer\"\n",
            "\n",
            "Iteration/Step: 2106\n",
            "Sample ID: 20930\n",
            "Decoded Input: what is the date of the tournament in michalovce\n",
            "Decoded Target (Labels): SELECT date FROM table_name_74 WHERE tournament = \"michalovce\"\n",
            "\n",
            "Iteration/Step: 2106\n",
            "Sample ID: 18312\n",
            "Decoded Input: What is the production code for episode 26 in the series?\n",
            "Decoded Target (Labels): SELECT production_code FROM table_1876825_3 WHERE no_in_series = 26\n",
            "\n",
            "Iteration/Step: 2107\n",
            "Sample ID: 8792\n",
            "Decoded Input: How many wins do the Erie Otters have? \n",
            "Decoded Target (Labels): SELECT wins FROM table_17751942_4 WHERE team = \"Erie Otters\"\n",
            "\n",
            "Iteration/Step: 2107\n",
            "Sample ID: 15855\n",
            "Decoded Input: Name the appearance for independence bowl\n",
            "Decoded Target (Labels): SELECT COUNT(appearances) FROM table_2517159_1 WHERE name_of_bowl = \"Independence Bowl\"\n",
            "\n",
            "Iteration/Step: 2108\n",
            "Sample ID: 24249\n",
            "Decoded Input: What was the away score at the game at MCG?\n",
            "Decoded Target (Labels): SELECT away_team AS score FROM table_name_63 WHERE venue = \"mcg\"\n",
            "\n",
            "Iteration/Step: 2108\n",
            "Sample ID: 6072\n",
            "Decoded Input: when was the first performance for the ballet with peter mazurowski in the final cast?\n",
            "Decoded Target (Labels): SELECT first_performance FROM table_name_72 WHERE style = \"ballet\" AND status = \"final cast\" AND name = \"peter mazurowski\"\n",
            "\n",
            "Iteration/Step: 2109\n",
            "Sample ID: 3385\n",
            "Decoded Input: What is the name of the capital, in Arabic, that is called n'djamena in English?\n",
            "Decoded Target (Labels): SELECT arabic_capital_name FROM table_name_7 WHERE english_capital_name = \"n'djamena\"\n",
            "\n",
            "Iteration/Step: 2109\n",
            "Sample ID: 20624\n",
            "Decoded Input: What identities have more than 5 DVD volumes?\n",
            "Decoded Target (Labels): SELECT identity_ies_ FROM table_name_93 WHERE dvd_volume > 5\n",
            "\n",
            "Iteration/Step: 2110\n",
            "Sample ID: 25952\n",
            "Decoded Input: What rank was the swimmer in lane 4?\n",
            "Decoded Target (Labels): SELECT rank FROM table_name_41 WHERE lane = 4\n",
            "\n",
            "Iteration/Step: 2110\n",
            "Sample ID: 3918\n",
            "Decoded Input: What is the status of joe gibbs racing?\n",
            "Decoded Target (Labels): SELECT status FROM table_12001616_4 WHERE entrant = \"Joe Gibbs Racing\"\n",
            "\n",
            "Iteration/Step: 2111\n",
            "Sample ID: 19390\n",
            "Decoded Input: What is the event that is in 8th position?\n",
            "Decoded Target (Labels): SELECT event FROM table_name_70 WHERE position = \"8th\"\n",
            "\n",
            "Iteration/Step: 2111\n",
            "Sample ID: 571\n",
            "Decoded Input: how many times is the co-singer suresh wadkar and the film name is tera dukh mera dukh?\n",
            "Decoded Target (Labels): SELECT COUNT(lyricist) FROM table_11827596_2 WHERE co_singer = \"Suresh Wadkar\" AND film_name = \"Tera Dukh Mera Dukh\"\n",
            "\n",
            "Iteration/Step: 2112\n",
            "Sample ID: 12943\n",
            "Decoded Input: What is the number of 2002 populations having a 2011 population of exactly 5399?\n",
            "Decoded Target (Labels): SELECT COUNT(population__2002_) FROM table_2562572_2 WHERE population__2011_ = 5399\n",
            "\n",
            "Iteration/Step: 2112\n",
            "Sample ID: 24655\n",
            "Decoded Input: what is the total of floors when the name is kölntriangle and rank is less thank 63?\n",
            "Decoded Target (Labels): SELECT SUM(floors) FROM table_name_10 WHERE name = \"kölntriangle\" AND rank < 63\n",
            "\n",
            "Iteration/Step: 2113\n",
            "Sample ID: 523\n",
            "Decoded Input: WHat is the Homeland security distinguished service medal when the medal of honor is Coast guard Medal?\n",
            "Decoded Target (Labels): SELECT homeland_security_distinguished_service_medal FROM table_2104176_1 WHERE medal_of_honor = \"Coast Guard Medal\"\n",
            "\n",
            "Iteration/Step: 2113\n",
            "Sample ID: 14650\n",
            "Decoded Input: Who are the UK co-presenters that have Joe Swash as a co-presenter and Russell Kane as a comedian?\n",
            "Decoded Target (Labels): SELECT COUNT(uk_co_presenter) FROM table_14345690_15 WHERE co_presenter = \"Joe Swash\" AND comedian = \"Russell Kane\"\n",
            "\n",
            "Iteration/Step: 2114\n",
            "Sample ID: 13759\n",
            "Decoded Input: What has the lowest number of wins with GA smaller than 39, more than 2 losses, and ties greater than 0?\n",
            "Decoded Target (Labels): SELECT MIN(wins) FROM table_name_17 WHERE goals_against < 39 AND losses > 2 AND ties > 0\n",
            "\n",
            "Iteration/Step: 2114\n",
            "Sample ID: 14851\n",
            "Decoded Input: What is the CHI (Carvill Hurricane Index) when the NHC advisory number is equal to 49b?\n",
            "Decoded Target (Labels): SELECT chi FROM table_15416002_1 WHERE nhc_advisory_number = \"49B\"\n",
            "\n",
            "Iteration/Step: 2115\n",
            "Sample ID: 2209\n",
            "Decoded Input: Peterson Gym is in what city?\n",
            "Decoded Target (Labels): SELECT city FROM table_name_60 WHERE venue = \"peterson gym\"\n",
            "\n",
            "Iteration/Step: 2115\n",
            "Sample ID: 5313\n",
            "Decoded Input: What was the score on April 22?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_53 WHERE date = \"april 22\"\n",
            "\n",
            "Iteration/Step: 2116\n",
            "Sample ID: 18587\n",
            "Decoded Input: What are the ids of documents which don't have expense budgets?\n",
            "Decoded Target (Labels): SELECT document_id FROM Documents EXCEPT SELECT document_id FROM Documents_with_expenses\n",
            "\n",
            "Iteration/Step: 2116\n",
            "Sample ID: 22972\n",
            "Decoded Input: What is Actor, when Role is \"Kate Manfredi\"?\n",
            "Decoded Target (Labels): SELECT actor FROM table_name_28 WHERE role = \"kate manfredi\"\n",
            "\n",
            "Iteration/Step: 2117\n",
            "Sample ID: 2657\n",
            "Decoded Input: what is the average tries for the season 2008 warrington wolves with an appearance more than 7?\n",
            "Decoded Target (Labels): SELECT AVG(tries) FROM table_name_55 WHERE season = \"2008 warrington wolves\" AND appearance > 7\n",
            "\n",
            "Iteration/Step: 2117\n",
            "Sample ID: 22038\n",
            "Decoded Input: What is Player, when Place is \"T9\", and when Score is \"73-70=143\"?\n",
            "Decoded Target (Labels): SELECT player FROM table_name_90 WHERE place = \"t9\" AND score = 73 - 70 = 143\n",
            "\n",
            "Iteration/Step: 2118\n",
            "Sample ID: 4901\n",
            "Decoded Input: Which Studio has a Rank smaller than 3, and a Director of adrian lyne?\n",
            "Decoded Target (Labels): SELECT studio FROM table_name_71 WHERE rank < 3 AND director = \"adrian lyne\"\n",
            "\n",
            "Iteration/Step: 2118\n",
            "Sample ID: 2041\n",
            "Decoded Input: Name the record for new orleans\n",
            "Decoded Target (Labels): SELECT record FROM table_17355408_4 WHERE team = \"New Orleans\"\n",
            "\n",
            "Iteration/Step: 2119\n",
            "Sample ID: 14361\n",
            "Decoded Input: What were the winnings for the score of 66-64-67-71=268?\n",
            "Decoded Target (Labels): SELECT winnings__$_ FROM table_28498999_4 WHERE score = 66 - 64 - 67 - 71 = 268\n",
            "\n",
            "Iteration/Step: 2119\n",
            "Sample ID: 12644\n",
            "Decoded Input: Who is the Second when Michel Gribi is the lead?\n",
            "Decoded Target (Labels): SELECT second FROM table_name_90 WHERE lead = \"michel gribi\"\n",
            "\n",
            "Iteration/Step: 2120\n",
            "Sample ID: 14491\n",
            "Decoded Input: What score points have olympic gold medalist as the rank points?\n",
            "Decoded Target (Labels): SELECT score_points FROM table_name_19 WHERE rank_points = \"olympic gold medalist\"\n",
            "\n",
            "Iteration/Step: 2120\n",
            "Sample ID: 24952\n",
            "Decoded Input: This engine with a cylinder size of 20 ½” x 26” and a firebox of radial-stay was built when?\n",
            "Decoded Target (Labels): SELECT years_built FROM table_25695027_1 WHERE cylinder_size = \"20 ½” x 26”\" AND firebox = \"Radial-stay\"\n",
            "\n",
            "Iteration/Step: 2121\n",
            "Sample ID: 12507\n",
            "Decoded Input: What's the lowest avg/g for a GP-GS of 12-12 and a gain less than 16?\n",
            "Decoded Target (Labels): SELECT MIN(avg_g) FROM table_name_10 WHERE gp_gs = \"12-12\" AND gain < 16\n",
            "\n",
            "Iteration/Step: 2121\n",
            "Sample ID: 9097\n",
            "Decoded Input: What is the nationality with a lane larger than 1, and a rank larger than 5, for Hsu Chi-Chieh?\n",
            "Decoded Target (Labels): SELECT nationality FROM table_name_24 WHERE lane > 1 AND rank > 5 AND name = \"hsu chi-chieh\"\n",
            "\n",
            "Iteration/Step: 2122\n",
            "Sample ID: 17111\n",
            "Decoded Input: What is Team, when Replaced By is \"Omar Arellano\"?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_5 WHERE replaced_by = \"omar arellano\"\n",
            "\n",
            "Iteration/Step: 2122\n",
            "Sample ID: 13146\n",
            "Decoded Input: What is the score of New York team before game 61?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_63 WHERE game < 61 AND team = \"new york\"\n",
            "\n",
            "Iteration/Step: 2123\n",
            "Sample ID: 25838\n",
            "Decoded Input: What's the venue for the asian games tournament?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_55 WHERE tournament = \"asian games\"\n",
            "\n",
            "Iteration/Step: 2123\n",
            "Sample ID: 15197\n",
            "Decoded Input: What was the record at Memorial Stadium on September 19, 1965?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_59 WHERE game_site = \"memorial stadium\" AND date = \"september 19, 1965\"\n",
            "\n",
            "Iteration/Step: 2124\n",
            "Sample ID: 7774\n",
            "Decoded Input: How many positions is player Tom Glavine?\n",
            "Decoded Target (Labels): SELECT COUNT(position) FROM table_21721351_18 WHERE player = \"Tom Glavine\"\n",
            "\n",
            "Iteration/Step: 2124\n",
            "Sample ID: 23412\n",
            "Decoded Input: Find the first name of students who have cat or dog pet.\n",
            "Decoded Target (Labels): SELECT DISTINCT T1.Fname FROM student AS T1 JOIN has_pet AS T2 ON T1.stuid = T2.stuid JOIN pets AS T3 ON T3.petid = T2.petid WHERE T3.pettype = 'cat' OR T3.pettype = 'dog'\n",
            "\n",
            "Iteration/Step: 2125\n",
            "Sample ID: 4298\n",
            "Decoded Input: Which opponent led to a 5-2 record?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_24560733_1 WHERE record = \"5-2\"\n",
            "\n",
            "Iteration/Step: 2125\n",
            "Sample ID: 21680\n",
            "Decoded Input: What Type of Tunnel is the Downhill Tunnel?\n",
            "Decoded Target (Labels): SELECT type FROM table_name_78 WHERE tunnel = \"downhill\"\n",
            "\n",
            "Iteration/Step: 2126\n",
            "Sample ID: 24044\n",
            "Decoded Input: What is the Attendance with a Date that is november 25, 1965?\n",
            "Decoded Target (Labels): SELECT attendance FROM table_name_96 WHERE date = \"november 25, 1965\"\n",
            "\n",
            "Iteration/Step: 2126\n",
            "Sample ID: 20411\n",
            "Decoded Input: Score of 3–4, and a Attendance larger than 34,609 happened on what date?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_39 WHERE score = \"3–4\" AND attendance > 34 OFFSET 609\n",
            "\n",
            "Iteration/Step: 2127\n",
            "Sample ID: 6431\n",
            "Decoded Input: Year larger than 1975, and a Record of 13–11 is what playoffs?\n",
            "Decoded Target (Labels): SELECT playoffs FROM table_name_54 WHERE year > 1975 AND record = \"13–11\"\n",
            "\n",
            "Iteration/Step: 2127\n",
            "Sample ID: 5520\n",
            "Decoded Input: What was the date when the home team was Essendon?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_9 WHERE home_team = \"essendon\"\n",
            "\n",
            "Iteration/Step: 2128\n",
            "Sample ID: 6821\n",
            "Decoded Input: what the highest number for the opposite of offense for the green bay packers\n",
            "Decoded Target (Labels): SELECT MAX(team_defense_rank) FROM table_1402270_1 WHERE nfl_team = \"Green Bay Packers\"\n",
            "\n",
            "Iteration/Step: 2128\n",
            "Sample ID: 2155\n",
            "Decoded Input: How many teams does Jeff Wyler own?\n",
            "Decoded Target (Labels): SELECT COUNT(team) FROM table_19908313_2 WHERE listed_owner_s_ = \"Jeff Wyler\"\n",
            "\n",
            "Iteration/Step: 2129\n",
            "Sample ID: 11822\n",
            "Decoded Input: What date was the race in 1968 run on?\n",
            "Decoded Target (Labels): SELECT date FROM table_22648285_1 WHERE year = 1968\n",
            "\n",
            "Iteration/Step: 2129\n",
            "Sample ID: 10009\n",
            "Decoded Input: What Country has a number smaller than 3 in 2004 and larger than 1 in 2005?\n",
            "Decoded Target (Labels): SELECT COUNT(2006) FROM table_name_31 WHERE 2004 < 3 AND 2005 > 1\n",
            "\n",
            "Iteration/Step: 2130\n",
            "Sample ID: 24450\n",
            "Decoded Input: Show the most common apartment type code.\n",
            "Decoded Target (Labels): SELECT apt_type_code FROM Apartments GROUP BY apt_type_code ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "Iteration/Step: 2130\n",
            "Sample ID: 21033\n",
            "Decoded Input: Which Team has a Head Coach of michalis pamboris?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_60 WHERE head_coach = \"michalis pamboris\"\n",
            "\n",
            "Iteration/Step: 2131\n",
            "Sample ID: 25532\n",
            "Decoded Input: What country has Dave Barr as a player?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_45 WHERE player = \"dave barr\"\n",
            "\n",
            "Iteration/Step: 2131\n",
            "Sample ID: 2956\n",
            "Decoded Input: Who won in the men singles group in the year when Yoshie Takada won in the women singles?\n",
            "Decoded Target (Labels): SELECT mens_singles FROM table_28138035_13 WHERE womens_singles = \"Yoshie Takada\"\n",
            "\n",
            "Iteration/Step: 2132\n",
            "Sample ID: 4624\n",
            "Decoded Input: List all the distinct product names ordered by product id?\n",
            "Decoded Target (Labels): SELECT DISTINCT product_name FROM product ORDER BY product_id\n",
            "\n",
            "Iteration/Step: 2132\n",
            "Sample ID: 12642\n",
            "Decoded Input: What is the iclandic of the glossary for presenta for mi locaria\n",
            "Decoded Target (Labels): SELECT the_icelandic_of_the_glossary FROM table_13003460_1 WHERE the_basque_of_the_glossary = \"presenta for mi locaria\"\n",
            "\n",
            "Iteration/Step: 2133\n",
            "Sample ID: 7446\n",
            "Decoded Input: What is the lowest Pick # of Saint Vincent College?\n",
            "Decoded Target (Labels): SELECT MIN(pick__number) FROM table_name_78 WHERE college = \"saint vincent college\"\n",
            "\n",
            "Iteration/Step: 2133\n",
            "Sample ID: 5751\n",
            "Decoded Input: Name the most free throws for 4 steals\n",
            "Decoded Target (Labels): SELECT MAX(free_throws) FROM table_23183195_5 WHERE steals = 4\n",
            "\n",
            "Iteration/Step: 2134\n",
            "Sample ID: 9572\n",
            "Decoded Input: What was the destination of the season won by Anwar Syed?\n",
            "Decoded Target (Labels): SELECT destination FROM table_20026849_1 WHERE winner = \"Anwar Syed\"\n",
            "\n",
            "Iteration/Step: 2134\n",
            "Sample ID: 14991\n",
            "Decoded Input: What is the time of lane 3 in heat 5?\n",
            "Decoded Target (Labels): SELECT time FROM table_name_47 WHERE heat = 5 AND lane = 3\n",
            "\n",
            "Iteration/Step: 2135\n",
            "Sample ID: 22687\n",
            "Decoded Input: What rank is Belarus (BLR), which earned 15 medals total?\n",
            "Decoded Target (Labels): SELECT MAX(rank) FROM table_name_44 WHERE nation = \"belarus (blr)\" AND total < 15\n",
            "\n",
            "Iteration/Step: 2135\n",
            "Sample ID: 23733\n",
            "Decoded Input: what's the won with points against being 597\n",
            "Decoded Target (Labels): SELECT won FROM table_13758945_3 WHERE points_against = \"597\"\n",
            "\n",
            "Iteration/Step: 2136\n",
            "Sample ID: 10285\n",
            "Decoded Input: Which To par has a Winning score of 64-68-66-63=261?\n",
            "Decoded Target (Labels): SELECT to_par FROM table_name_22 WHERE winning_score = 64 - 68 - 66 - 63 = 261\n",
            "\n",
            "Iteration/Step: 2136\n",
            "Sample ID: 17915\n",
            "Decoded Input: What is the lowest Wins that has the Team of Olimpia and Draws that's smaller than 4?\n",
            "Decoded Target (Labels): SELECT MIN(wins) FROM table_name_21 WHERE team = \"olimpia\" AND draws < 4\n",
            "\n",
            "Iteration/Step: 2137\n",
            "Sample ID: 4342\n",
            "Decoded Input: Ken Hemenway is in which Round?\n",
            "Decoded Target (Labels): SELECT round FROM table_name_23 WHERE player = \"ken hemenway\"\n",
            "\n",
            "Iteration/Step: 2137\n",
            "Sample ID: 17400\n",
            "Decoded Input: Name the total number of dates for toshiba classic\n",
            "Decoded Target (Labels): SELECT COUNT(date) FROM table_25938117_1 WHERE tournament = \"Toshiba Classic\"\n",
            "\n",
            "Iteration/Step: 2138\n",
            "Sample ID: 14816\n",
            "Decoded Input: How many numbers are there for August when March is 139?\n",
            "Decoded Target (Labels): SELECT COUNT(august_21_22) FROM table_25235489_2 WHERE march_27_29 = \"139\"\n",
            "\n",
            "Iteration/Step: 2138\n",
            "Sample ID: 14862\n",
            "Decoded Input: What was the final score for the match played in Venue H and the opponent was Newcastle United?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_33 WHERE venue = \"h\" AND opponent = \"newcastle united\"\n",
            "\n",
            "Iteration/Step: 2139\n",
            "Sample ID: 2285\n",
            "Decoded Input: What was the Result for the club universidad de guadalajara?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_11 WHERE club = \"club universidad de guadalajara\"\n",
            "\n",
            "Iteration/Step: 2139\n",
            "Sample ID: 24550\n",
            "Decoded Input: What is the dpi of a scanner with the mm dimensions 280 x 95 x 40?\n",
            "Decoded Target (Labels): SELECT dpi FROM table_16409745_1 WHERE dimensions__mm_ = \"280 x 95 x 40\"\n",
            "\n",
            "Iteration/Step: 2140\n",
            "Sample ID: 18915\n",
            "Decoded Input: what is the score when the runner-up is richard krajicek?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_54 WHERE runner_up = \"richard krajicek\"\n",
            "\n",
            "Iteration/Step: 2140\n",
            "Sample ID: 771\n",
            "Decoded Input: Tell me the power for 1935-45\n",
            "Decoded Target (Labels): SELECT power FROM table_name_91 WHERE year = \"1935-45\"\n",
            "\n",
            "Iteration/Step: 2141\n",
            "Sample ID: 20841\n",
            "Decoded Input: What is team 2 where the result is ICL world by 8 wickets?\n",
            "Decoded Target (Labels): SELECT team_2 FROM table_17103566_1 WHERE result = \"ICL World by 8 wickets\"\n",
            "\n",
            "Iteration/Step: 2141\n",
            "Sample ID: 19482\n",
            "Decoded Input: Name the club with date of appointment of 1 november 2007\n",
            "Decoded Target (Labels): SELECT club FROM table_name_67 WHERE date_of_appointment = \"1 november 2007\"\n",
            "\n",
            "Iteration/Step: 2142\n",
            "Sample ID: 5634\n",
            "Decoded Input: how many winners from vietnam\n",
            "Decoded Target (Labels): SELECT winners FROM table_12303563_2 WHERE nation = \"Vietnam\"\n",
            "\n",
            "Iteration/Step: 2142\n",
            "Sample ID: 11172\n",
            "Decoded Input: What is the Country of T6 Place Player Ben Crenshaw?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_57 WHERE place = \"t6\" AND player = \"ben crenshaw\"\n",
            "\n",
            "Iteration/Step: 2143\n",
            "Sample ID: 16343\n",
            "Decoded Input: What is the home for the league 3rd liga (iii)?\n",
            "Decoded Target (Labels): SELECT home FROM table_name_81 WHERE league = \"3rd liga (iii)\"\n",
            "\n",
            "Iteration/Step: 2143\n",
            "Sample ID: 16306\n",
            "Decoded Input: Name the ERP W for glens falls, new york\n",
            "Decoded Target (Labels): SELECT erp_w FROM table_name_56 WHERE city_of_license = \"glens falls, new york\"\n",
            "\n",
            "Iteration/Step: 2144\n",
            "Sample ID: 9738\n",
            "Decoded Input: In which venue does Melbourne play as the home team?\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_62 WHERE home_team = \"melbourne\"\n",
            "\n",
            "Iteration/Step: 2144\n",
            "Sample ID: 13276\n",
            "Decoded Input: What was the 1st leg for Team 2 Concepto Egile?\n",
            "Decoded Target (Labels): SELECT 1 AS st_leg FROM table_name_88 WHERE team_2 = \"concepto egile\"\n",
            "\n",
            "Iteration/Step: 2145\n",
            "Sample ID: 12518\n",
            "Decoded Input: What is the Memory for a Number 32 with a Clock of 2.26ghz?\n",
            "Decoded Target (Labels): SELECT memory FROM table_name_68 WHERE clock = \"2.26ghz\" AND number = 32\n",
            "\n",
            "Iteration/Step: 2145\n",
            "Sample ID: 20443\n",
            "Decoded Input: Which Rim diameter has a Neck diameter of 11.84 (.466)?\n",
            "Decoded Target (Labels): SELECT rim_diameter FROM table_name_27 WHERE neck_diameter = \"11.84 (.466)\"\n",
            "\n",
            "Iteration/Step: 2146\n",
            "Sample ID: 14167\n",
            "Decoded Input: what's the domestic freight with change being +8.0%\n",
            "Decoded Target (Labels): SELECT domestic_freight FROM table_141541_5 WHERE change = \"+8.0%\"\n",
            "\n",
            "Iteration/Step: 2146\n",
            "Sample ID: 2550\n",
            "Decoded Input: What was the Area (km²) when the Population (2011) was 8574, and the Population density was larger than 381.4?\n",
            "Decoded Target (Labels): SELECT AVG(area__km²_) FROM table_name_21 WHERE population__2011_ = 8574 AND population_density > 381.4\n",
            "\n",
            "Iteration/Step: 2147\n",
            "Sample ID: 16472\n",
            "Decoded Input: How many points when the Grid was 1?\n",
            "Decoded Target (Labels): SELECT points FROM table_name_75 WHERE grid = \"1\"\n",
            "\n",
            "Iteration/Step: 2147\n",
            "Sample ID: 4769\n",
            "Decoded Input: Who wrote the title that received 1.211 million total viewers?\n",
            "Decoded Target (Labels): SELECT written_by FROM table_12419515_4 WHERE total_viewers__in_millions_ = \"1.211\"\n",
            "\n",
            "Iteration/Step: 2148\n",
            "Sample ID: 22777\n",
            "Decoded Input: What are the package/options when the TV service is rai 3?\n",
            "Decoded Target (Labels): SELECT package_option FROM table_15887683_1 WHERE television_service = \"Rai 3\"\n",
            "\n",
            "Iteration/Step: 2148\n",
            "Sample ID: 14190\n",
            "Decoded Input: When was the cataglogue EPA 4054 released with a 1/12/57 recorded?\n",
            "Decoded Target (Labels): SELECT release_date FROM table_name_31 WHERE catalogue = \"epa 4054\" AND recorded = \"1/12/57\"\n",
            "\n",
            "Iteration/Step: 2149\n",
            "Sample ID: 755\n",
            "Decoded Input: who visited on november 17?\n",
            "Decoded Target (Labels): SELECT visitor FROM table_name_29 WHERE date = \"november 17\"\n",
            "\n",
            "Iteration/Step: 2149\n",
            "Sample ID: 298\n",
            "Decoded Input: What is the team name when 243 is the total?\n",
            "Decoded Target (Labels): SELECT team_name FROM table_22014431_3 WHERE total = \"243\"\n",
            "\n",
            "Iteration/Step: 2150\n",
            "Sample ID: 25411\n",
            "Decoded Input: What is Opponent, when October is less than 31, and when Game is greater than 7?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_12 WHERE october < 31 AND game > 7\n",
            "\n",
            "Iteration/Step: 2150\n",
            "Sample ID: 260\n",
            "Decoded Input: Which engine did Élie Bayol use when they earned 0 points?\n",
            "Decoded Target (Labels): SELECT engine FROM table_name_74 WHERE points = 0 AND entrant = \"élie bayol\"\n",
            "\n",
            "Iteration/Step: 2151\n",
            "Sample ID: 963\n",
            "Decoded Input: which episode did sarah millican and grayson perry appear in\n",
            "Decoded Target (Labels): SELECT MIN(episode) FROM table_29135051_3 WHERE guest_s_ = \"Sarah Millican and Grayson Perry\"\n",
            "\n",
            "Iteration/Step: 2151\n",
            "Sample ID: 17551\n",
            "Decoded Input: Which Rank has a Reaction of 0.198, and a Time smaller than 46.3?\n",
            "Decoded Target (Labels): SELECT MAX(rank) FROM table_name_98 WHERE react = 0.198 AND time < 46.3\n",
            "\n",
            "Iteration/Step: 2152\n",
            "Sample ID: 8356\n",
            "Decoded Input: List the language used least number of TV Channel. List language and number of TV Channel.\n",
            "Decoded Target (Labels): SELECT LANGUAGE, COUNT(*) FROM TV_Channel GROUP BY LANGUAGE ORDER BY COUNT(*) LIMIT 1\n",
            "\n",
            "Iteration/Step: 2152\n",
            "Sample ID: 13187\n",
            "Decoded Input: What percentage of users were using Internet Explorer during the period in which 2.1% were using mobile browsers?\n",
            "Decoded Target (Labels): SELECT internet_explorer FROM table_name_66 WHERE mobile = \"2.1%\"\n",
            "\n",
            "Iteration/Step: 2153\n",
            "Sample ID: 20693\n",
            "Decoded Input: Which engine has a Year larger than 1969?\n",
            "Decoded Target (Labels): SELECT engine FROM table_name_7 WHERE year > 1969\n",
            "\n",
            "Iteration/Step: 2153\n",
            "Sample ID: 16112\n",
            "Decoded Input: Name the number of package/option for sky primafila 24\n",
            "Decoded Target (Labels): SELECT COUNT(package_option) FROM table_15887683_6 WHERE television_service = \"Sky Primafila 24\"\n",
            "\n",
            "Iteration/Step: 2154\n",
            "Sample ID: 25893\n",
            "Decoded Input: Which level has wale as artist 1?\n",
            "Decoded Target (Labels): SELECT level FROM table_23649244_1 WHERE artist_1 = \"Wale\"\n",
            "\n",
            "Iteration/Step: 2154\n",
            "Sample ID: 376\n",
            "Decoded Input: Name the number of high rebounds for united center 19,335\n",
            "Decoded Target (Labels): SELECT COUNT(high_rebounds) FROM table_22669044_9 WHERE location_attendance = \"United Center 19,335\"\n",
            "\n",
            "Iteration/Step: 2155\n",
            "Sample ID: 24166\n",
            "Decoded Input: What are the timeslot(s) for broadcast on February 22, 2008?\n",
            "Decoded Target (Labels): SELECT timeslot FROM table_16072430_1 WHERE air_date = \"February 22, 2008\"\n",
            "\n",
            "Iteration/Step: 2155\n",
            "Sample ID: 5839\n",
            "Decoded Input: what is the racing club where copa libertadores 1997?\n",
            "Decoded Target (Labels): SELECT copa_libertadores_1997 FROM table_14310205_1 WHERE team = \"Racing Club\"\n",
            "\n",
            "Iteration/Step: 2156\n",
            "Sample ID: 11235\n",
            "Decoded Input: What is the total number of Points 1, when Position is \"7\", and when Drawn is greater than 6?\n",
            "Decoded Target (Labels): SELECT COUNT(points_1) FROM table_name_62 WHERE position = 7 AND drawn > 6\n",
            "\n",
            "Iteration/Step: 2156\n",
            "Sample ID: 16254\n",
            "Decoded Input: What is the lowest Tournaments with Highest Rank of Maegashira 13?\n",
            "Decoded Target (Labels): SELECT MIN(tournaments) FROM table_name_46 WHERE highest_rank = \"maegashira 13\"\n",
            "\n",
            "Iteration/Step: 2157\n",
            "Sample ID: 2462\n",
            "Decoded Input: How many medicines have the FDA approval status 'No' ?\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM medicine WHERE FDA_approved = 'No'\n",
            "\n",
            "Iteration/Step: 2157\n",
            "Sample ID: 15865\n",
            "Decoded Input: What year is Japan the country?\n",
            "Decoded Target (Labels): SELECT year FROM table_12243817_1 WHERE country = \"Japan\"\n",
            "\n",
            "Iteration/Step: 2158\n",
            "Sample ID: 12566\n",
            "Decoded Input: What was the attendance on September 11?\n",
            "Decoded Target (Labels): SELECT MAX(attendance) FROM table_name_10 WHERE date = \"september 11\"\n",
            "\n",
            "Iteration/Step: 2158\n",
            "Sample ID: 22778\n",
            "Decoded Input: Which district is in the province of Piura?\n",
            "Decoded Target (Labels): SELECT districts FROM table_name_36 WHERE province = \"piura\"\n",
            "\n",
            "Iteration/Step: 2159\n",
            "Sample ID: 11163\n",
            "Decoded Input: How many Extra points have Touchdowns of 1, and a Player of ross kidston, and Points smaller than 5?\n",
            "Decoded Target (Labels): SELECT SUM(extra_points) FROM table_name_92 WHERE touchdowns = 1 AND player = \"ross kidston\" AND points < 5\n",
            "\n",
            "Iteration/Step: 2159\n",
            "Sample ID: 8821\n",
            "Decoded Input: Find the average number of followers for the users who had some tweets.\n",
            "Decoded Target (Labels): SELECT AVG(followers) FROM user_profiles WHERE UID IN (SELECT UID FROM tweets)\n",
            "\n",
            "Iteration/Step: 2160\n",
            "Sample ID: 6952\n",
            "Decoded Input: What is the score [A] of the match on 19 September 1998?\n",
            "Decoded Target (Labels): SELECT score_[a_] FROM table_name_49 WHERE date = \"19 september 1998\"\n",
            "\n",
            "Iteration/Step: 2160\n",
            "Sample ID: 21887\n",
            "Decoded Input: How much is the total with a time at 16:00 and score for set 3 of 18–25?\n",
            "Decoded Target (Labels): SELECT total FROM table_name_41 WHERE time = \"16:00\" AND set_3 = \"18–25\"\n",
            "\n",
            "Iteration/Step: 2161\n",
            "Sample ID: 22971\n",
            "Decoded Input: What team has a home of 2-3?\n",
            "Decoded Target (Labels): SELECT teams FROM table_name_75 WHERE home = \"2-3\"\n",
            "\n",
            "Iteration/Step: 2161\n",
            "Sample ID: 9537\n",
            "Decoded Input: If the POS is 3, what is the 08 points?\n",
            "Decoded Target (Labels): SELECT 08 AS _pts FROM table_22011138_7 WHERE pos = 3\n",
            "\n",
            "Iteration/Step: 2162\n",
            "Sample ID: 24873\n",
            "Decoded Input: Name the total number of points for 1952\n",
            "Decoded Target (Labels): SELECT COUNT(points) FROM table_name_89 WHERE year = 1952\n",
            "\n",
            "Iteration/Step: 2162\n",
            "Sample ID: 18311\n",
            "Decoded Input: With a Primary military speciality of astral assault tactics, what is the Secondary military speciality?\n",
            "Decoded Target (Labels): SELECT secondary_military_speciality FROM table_name_58 WHERE primary_military_speciality = \"astral assault tactics\"\n",
            "\n",
            "Iteration/Step: 2163\n",
            "Sample ID: 1092\n",
            "Decoded Input: What 2nd run has a less than 6 rank, and 3 as the total?\n",
            "Decoded Target (Labels): SELECT 2 AS nd_run FROM table_name_69 WHERE rank < 6 AND total = 3\n",
            "\n",
            "Iteration/Step: 2163\n",
            "Sample ID: 24094\n",
            "Decoded Input: Which race did Mercedes win?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_19 WHERE winning_constructor = \"mercedes\"\n",
            "\n",
            "Iteration/Step: 2164\n",
            "Sample ID: 24154\n",
            "Decoded Input: Which mission number has alternate name 1962-f01\n",
            "Decoded Target (Labels): SELECT mission_no FROM table_191323_2 WHERE alt_name = \"1962-F01\"\n",
            "\n",
            "Iteration/Step: 2164\n",
            "Sample ID: 25601\n",
            "Decoded Input: who is first team when dimitris diamantidis play.\n",
            "Decoded Target (Labels): SELECT COUNT(first_team) FROM table_26130295_3 WHERE player = \"Dimitris Diamantidis\"\n",
            "\n",
            "Iteration/Step: 2165\n",
            "Sample ID: 12834\n",
            "Decoded Input: What is the 1st leg result when team 1 is Gambia?\n",
            "Decoded Target (Labels): SELECT 1 AS st_leg FROM table_name_10 WHERE team_1 = \"gambia\"\n",
            "\n",
            "Iteration/Step: 2165\n",
            "Sample ID: 22326\n",
            "Decoded Input: Where was the game when Police S.A. was the opponent?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_78 WHERE opponent_team = \"police s.a.\"\n",
            "\n",
            "Iteration/Step: 2166\n",
            "Sample ID: 21482\n",
            "Decoded Input: What is the highest pick of scott turner, who has a round greater than 2?\n",
            "Decoded Target (Labels): SELECT MAX(pick) FROM table_name_37 WHERE round > 2 AND name = \"scott turner\"\n",
            "\n",
            "Iteration/Step: 2166\n",
            "Sample ID: 24424\n",
            "Decoded Input: What body styles have devaux-hall inline 6 as the engine?\n",
            "Decoded Target (Labels): SELECT body_styles FROM table_name_9 WHERE engine = \"devaux-hall inline 6\"\n",
            "\n",
            "Iteration/Step: 2167\n",
            "Sample ID: 7285\n",
            "Decoded Input: What is in 2002 has a 2001 score 1–0, and a 2000 of 3–0?\n",
            "Decoded Target (Labels): SELECT 2002 FROM table_name_85 WHERE 2001 = \"1–0\" AND 2000 = \"3–0\"\n",
            "\n",
            "Iteration/Step: 2167\n",
            "Sample ID: 2748\n",
            "Decoded Input: Name the high rebounds for march 15\n",
            "Decoded Target (Labels): SELECT high_rebounds FROM table_17432028_1 WHERE date = \"March 15\"\n",
            "\n",
            "Iteration/Step: 2168\n",
            "Sample ID: 19007\n",
            "Decoded Input: What is the points number when rebounds is 4.4?\n",
            "Decoded Target (Labels): SELECT points FROM table_20107762_1 WHERE rebounds = \"4.4\"\n",
            "\n",
            "Iteration/Step: 2168\n",
            "Sample ID: 4462\n",
            "Decoded Input: How many floors does the building on 800 Boylston Street have?\n",
            "Decoded Target (Labels): SELECT MAX(floors) FROM table_name_52 WHERE street_address = \"800 boylston street\"\n",
            "\n",
            "Iteration/Step: 2169\n",
            "Sample ID: 2896\n",
            "Decoded Input: What was the home team when the game was at Windy Hill?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_36 WHERE venue = \"windy hill\"\n",
            "\n",
            "Iteration/Step: 2169\n",
            "Sample ID: 17491\n",
            "Decoded Input: What was the 2009 results that has q1 for 2010, and A as the result for 2011?\n",
            "Decoded Target (Labels): SELECT 2009 FROM table_name_71 WHERE 2010 = \"q1\" AND 2011 = \"a\"\n",
            "\n",
            "Iteration/Step: 2170\n",
            "Sample ID: 4491\n",
            "Decoded Input: What are the year(s) of manufacture for railway number(s) 26 (ii) …63 (ii) , 188–193?\n",
            "Decoded Target (Labels): SELECT year_s__of_manufacture FROM table_name_35 WHERE railway_number_s_ = \"26 (ii) …63 (ii) , 188–193\"\n",
            "\n",
            "Iteration/Step: 2170\n",
            "Sample ID: 24624\n",
            "Decoded Input: Which line offers Fast to Norwood Junction?\n",
            "Decoded Target (Labels): SELECT line FROM table_1612760_1 WHERE service_pattern = \"Fast to Norwood Junction\"\n",
            "\n",
            "Iteration/Step: 2171\n",
            "Sample ID: 13821\n",
            "Decoded Input: What is the average interview score from Kentucky?\n",
            "Decoded Target (Labels): SELECT AVG(interview) FROM table_name_27 WHERE state = \"kentucky\"\n",
            "\n",
            "Iteration/Step: 2171\n",
            "Sample ID: 7626\n",
            "Decoded Input: Can you tell me the Team that has the Laps of 379?\n",
            "Decoded Target (Labels): SELECT team FROM table_name_23 WHERE laps = 379\n",
            "\n",
            "Iteration/Step: 2172\n",
            "Sample ID: 19350\n",
            "Decoded Input: Show all artist name, age, and country ordered by the yeared they joined.\n",
            "Decoded Target (Labels): SELECT name, age, country FROM artist ORDER BY Year_Join\n",
            "\n",
            "Iteration/Step: 2172\n",
            "Sample ID: 10906\n",
            "Decoded Input: What were the high points on April 8?\n",
            "Decoded Target (Labels): SELECT high_points FROM table_27713030_12 WHERE date = \"April 8\"\n",
            "\n",
            "Iteration/Step: 2173\n",
            "Sample ID: 12800\n",
            "Decoded Input: How many different percentages of immigrants are there for the year of 2007 in the countries with 1.2% of the immigrants in the year of 2005?\n",
            "Decoded Target (Labels): SELECT COUNT(_percentage_of_all_immigrants_2007) FROM table_23619212_1 WHERE _percentage_of_all_immigrants_2005 = \"1.2%\"\n",
            "\n",
            "Iteration/Step: 2173\n",
            "Sample ID: 7244\n",
            "Decoded Input: Who won with the fastest lap of daijiro hiura on March 29?\n",
            "Decoded Target (Labels): SELECT race_winner FROM table_name_97 WHERE fastest_lap = \"daijiro hiura\" AND date = \"march 29\"\n",
            "\n",
            "Iteration/Step: 2174\n",
            "Sample ID: 605\n",
            "Decoded Input: How many countries played in the city of ljungskile?\n",
            "Decoded Target (Labels): SELECT COUNT(country) FROM table_28005160_2 WHERE city = \"Ljungskile\"\n",
            "\n",
            "Iteration/Step: 2174\n",
            "Sample ID: 18595\n",
            "Decoded Input: Who was the opponent when the record was 55-14?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_52 WHERE record = \"55-14\"\n",
            "\n",
            "Iteration/Step: 2175\n",
            "Sample ID: 21163\n",
            "Decoded Input: Who is listed under mens singles when the year location is 2009 doha?\n",
            "Decoded Target (Labels): SELECT mens_singles FROM table_28138035_27 WHERE year_location = \"2009 Doha\"\n",
            "\n",
            "Iteration/Step: 2175\n",
            "Sample ID: 9748\n",
            "Decoded Input: List the number of all matches who played in years of 2013 or 2016.\n",
            "Decoded Target (Labels): SELECT COUNT(*) FROM matches WHERE YEAR = 2013 OR YEAR = 2016\n",
            "\n",
            "Iteration/Step: 2176\n",
            "Sample ID: 13654\n",
            "Decoded Input: When did the away team carlton play?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_88 WHERE away_team = \"carlton\"\n",
            "\n",
            "Iteration/Step: 2176\n",
            "Sample ID: 25980\n",
            "Decoded Input: Which is the lowest Round with the Opponent, Paul Cahoon and Location, Amsterdam, Netherlands?\n",
            "Decoded Target (Labels): SELECT MIN(round) FROM table_name_60 WHERE opponent = \"paul cahoon\" AND location = \"amsterdam, netherlands\"\n",
            "\n",
            "Iteration/Step: 2177\n",
            "Sample ID: 19038\n",
            "Decoded Input: What format is Première Chaîne?\n",
            "Decoded Target (Labels): SELECT format FROM table_name_44 WHERE branding = \"première chaîne\"\n",
            "\n",
            "Iteration/Step: 2177\n",
            "Sample ID: 22401\n",
            "Decoded Input: Tell me the name for time of 25.74\n",
            "Decoded Target (Labels): SELECT name FROM table_name_2 WHERE time = 25.74\n",
            "\n",
            "Iteration/Step: 2178\n",
            "Sample ID: 1962\n",
            "Decoded Input: Name the team for november 9\n",
            "Decoded Target (Labels): SELECT team FROM table_15872814_3 WHERE date = \"November 9\"\n",
            "\n",
            "Iteration/Step: 2178\n",
            "Sample ID: 25120\n",
            "Decoded Input: What is Country, when Score is \"73-68=141\"?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_60 WHERE score = 73 - 68 = 141\n",
            "\n",
            "Iteration/Step: 2179\n",
            "Sample ID: 25978\n",
            "Decoded Input: List the total number of institutions founded in Rock Island, Illinois.\n",
            "Decoded Target (Labels): SELECT COUNT(founded) FROM table_18483171_1 WHERE location = \"Rock Island, Illinois\"\n",
            "\n",
            "Iteration/Step: 2179\n",
            "Sample ID: 25967\n",
            "Decoded Input: How many episodes had 9.90 million viewers?\n",
            "Decoded Target (Labels): SELECT COUNT(episode_title) FROM table_12146637_1 WHERE us_viewers__millions_ = \"9.90\"\n",
            "\n",
            "Iteration/Step: 2180\n",
            "Sample ID: 6285\n",
            "Decoded Input: How many parties are named the Center Alliance\n",
            "Decoded Target (Labels): SELECT COUNT(2013 AS _parliamentary_election) FROM table_203802_2 WHERE english_party_name = \"Center Alliance\"\n",
            "\n",
            "Iteration/Step: 2180\n",
            "Sample ID: 20927\n",
            "Decoded Input: What Nominating festival was party of the adjustment film?\n",
            "Decoded Target (Labels): SELECT nominating_festival FROM table_name_69 WHERE film = \"adjustment\"\n",
            "\n",
            "Iteration/Step: 2181\n",
            "Sample ID: 8328\n",
            "Decoded Input: Who was the director of the film that Sister Films received an award for on 2/3/05?\n",
            "Decoded Target (Labels): SELECT director_s_ FROM table_name_48 WHERE date = \"2/3/05\" AND recipient = \"sister films\"\n",
            "\n",
            "Iteration/Step: 2181\n",
            "Sample ID: 258\n",
            "Decoded Input: What was the score in the tournament won by Jan Stephenson?\n",
            "Decoded Target (Labels): SELECT score FROM table_229059_2 WHERE champion = \"Jan Stephenson\"\n",
            "\n",
            "Iteration/Step: 2182\n",
            "Sample ID: 13566\n",
            "Decoded Input: How many departments offer any degree?\n",
            "Decoded Target (Labels): SELECT COUNT(DISTINCT department_id) FROM Degree_Programs\n",
            "\n",
            "Iteration/Step: 2182\n",
            "Sample ID: 7262\n",
            "Decoded Input: What was the championship before 2012 that had Stephane Houdet Michael Jeremiasz as opponents?\n",
            "Decoded Target (Labels): SELECT championship FROM table_name_23 WHERE year < 2012 AND opponents_in_final = \"stephane houdet michael jeremiasz\"\n",
            "\n",
            "Iteration/Step: 2183\n",
            "Sample ID: 5398\n",
            "Decoded Input: What pole position was Rubens Barrichello when he had the fastest lap and a round larger than 11?\n",
            "Decoded Target (Labels): SELECT pole_position FROM table_name_30 WHERE fastest_lap = \"rubens barrichello\" AND round > 11\n",
            "\n",
            "Iteration/Step: 2183\n",
            "Sample ID: 9243\n",
            "Decoded Input: in how many dates the opponen in the final was rushmi chakravarthi\n",
            "Decoded Target (Labels): SELECT COUNT(date) FROM table_29127804_3 WHERE opponent_in_the_final = \"Rushmi Chakravarthi\"\n",
            "\n",
            "Iteration/Step: 2184\n",
            "Sample ID: 14525\n",
            "Decoded Input: What's the enrollment at 41 Johnson?\n",
            "Decoded Target (Labels): SELECT AVG(enrollment) FROM table_name_24 WHERE _number___county = \"41 johnson\"\n",
            "\n",
            "Iteration/Step: 2184\n",
            "Sample ID: 14693\n",
            "Decoded Input: What was the score of the home team when the away team was Geelong?\n",
            "Decoded Target (Labels): SELECT home_team AS score FROM table_name_59 WHERE away_team = \"geelong\"\n",
            "\n",
            "Iteration/Step: 2185\n",
            "Sample ID: 333\n",
            "Decoded Input: What is the june 10-11 when august 21-22 is august 21, 2017?\n",
            "Decoded Target (Labels): SELECT june_10_11 FROM table_25355392_2 WHERE august_21_22 = \"August 21, 2017\"\n",
            "\n",
            "Iteration/Step: 2185\n",
            "Sample ID: 14129\n",
            "Decoded Input: What is the average first round for Utah Jazz team, with a weight smaller than 229?\n",
            "Decoded Target (Labels): SELECT AVG(first_round) FROM table_name_29 WHERE weight < 229 AND team = \"utah jazz\"\n",
            "\n",
            "Iteration/Step: 2186\n",
            "Sample ID: 25367\n",
            "Decoded Input: What is the Model of the Engine with 29 Seats Built in 1941–1942?\n",
            "Decoded Target (Labels): SELECT model FROM table_name_85 WHERE seats = 29 AND built = \"1941–1942\"\n",
            "\n",
            "Iteration/Step: 2186\n",
            "Sample ID: 6394\n",
            "Decoded Input: What day in february was game 53?\n",
            "Decoded Target (Labels): SELECT AVG(february) FROM table_name_96 WHERE game = 53\n",
            "\n",
            "Iteration/Step: 2187\n",
            "Sample ID: 4264\n",
            "Decoded Input: What is the title of the episode directed by Charles Beeson?\n",
            "Decoded Target (Labels): SELECT title FROM table_24649082_1 WHERE directed_by = \"Charles Beeson\"\n",
            "\n",
            "Iteration/Step: 2187\n",
            "Sample ID: 23778\n",
            "Decoded Input: Which  company's type is joint venture, and has principle activities listed as Cargo Airline and an incorporation of China?\n",
            "Decoded Target (Labels): SELECT company FROM table_name_37 WHERE type = \"joint venture\" AND principal_activities = \"cargo airline\" AND incorporated_in = \"china\"\n",
            "\n",
            "Iteration/Step: 2188\n",
            "Sample ID: 19906\n",
            "Decoded Input: Who was from Great Britain in lane 5?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_28 WHERE nationality = \"great britain\" AND lane = 5\n",
            "\n",
            "Iteration/Step: 2188\n",
            "Sample ID: 21557\n",
            "Decoded Input: Which Memory (GB) has a Number of CPUs of 1–6?\n",
            "Decoded Target (Labels): SELECT memory__gb_ FROM table_name_57 WHERE number_of_cpus = \"1–6\"\n",
            "\n",
            "Iteration/Step: 2189\n",
            "Sample ID: 4133\n",
            "Decoded Input: What years was the jersey number(s) smaller than 3?\n",
            "Decoded Target (Labels): SELECT years FROM table_name_1 WHERE jersey_number_s_ < 3\n",
            "\n",
            "Iteration/Step: 2189\n",
            "Sample ID: 8487\n",
            "Decoded Input: Who won the 1973 democratic initial primary for queens of 19%?\n",
            "Decoded Target (Labels): SELECT 1973 AS _democratic_initial_primary FROM table_1108394_24 WHERE queens = \"19_percentage\"\n",
            "\n",
            "Iteration/Step: 2190\n",
            "Sample ID: 22577\n",
            "Decoded Input: What is the average expected life expectancy for countries in the region of Central Africa?\n",
            "Decoded Target (Labels): SELECT AVG(LifeExpectancy) FROM country WHERE Region = \"Central Africa\"\n",
            "\n",
            "Iteration/Step: 2190\n",
            "Sample ID: 21584\n",
            "Decoded Input: Show the names of clubs that have players with position \"Right Wing\".\n",
            "Decoded Target (Labels): SELECT T1.name FROM club AS T1 JOIN player AS T2 ON T1.Club_ID = T2.Club_ID WHERE T2.Position = \"Right Wing\"\n",
            "\n",
            "Iteration/Step: 2191\n",
            "Sample ID: 13876\n",
            "Decoded Input: What was their record when they lost with Lilly (0-1) pitching?\n",
            "Decoded Target (Labels): SELECT record FROM table_name_6 WHERE loss = \"lilly (0-1)\"\n",
            "\n",
            "Iteration/Step: 2191\n",
            "Sample ID: 14741\n",
            "Decoded Input: Who has the high assists when April 26 is the date?\n",
            "Decoded Target (Labels): SELECT high_assists FROM table_23285761_11 WHERE date = \"April 26\"\n",
            "\n",
            "Iteration/Step: 2192\n",
            "Sample ID: 13434\n",
            "Decoded Input: what are all the circuit for 9 september and gt3 winner hector lester allan simonsen\n",
            "Decoded Target (Labels): SELECT circuit FROM table_13079788_3 WHERE date = \"9 September\" AND gt3_winner = \"Hector Lester Allan Simonsen\"\n",
            "\n",
            "Iteration/Step: 2192\n",
            "Sample ID: 3263\n",
            "Decoded Input: Which Label has a Catalog of 7243 8 49494 2 6?\n",
            "Decoded Target (Labels): SELECT label FROM table_name_98 WHERE catalog = \"7243 8 49494 2 6\"\n",
            "\n",
            "Iteration/Step: 2193\n",
            "Sample ID: 13860\n",
            "Decoded Input: What is the greatest first elected for Pennsylvania 10?\n",
            "Decoded Target (Labels): SELECT MAX(first_elected) FROM table_name_56 WHERE district = \"pennsylvania 10\"\n",
            "\n",
            "Iteration/Step: 2193\n",
            "Sample ID: 5277\n",
            "Decoded Input: Name the average rank with larger than 3 and heat more than 5\n",
            "Decoded Target (Labels): SELECT AVG(rank) FROM table_name_24 WHERE lane > 3 AND heat > 5\n",
            "\n",
            "Iteration/Step: 2194\n",
            "Sample ID: 4658\n",
            "Decoded Input: Name the record with result of w 13-11\n",
            "Decoded Target (Labels): SELECT record FROM table_name_51 WHERE result = \"w 13-11\"\n",
            "\n",
            "Iteration/Step: 2194\n",
            "Sample ID: 20138\n",
            "Decoded Input: What is the highest crowd population when the away team is Geelong?\n",
            "Decoded Target (Labels): SELECT MAX(crowd) FROM table_name_33 WHERE away_team = \"geelong\"\n",
            "\n",
            "Iteration/Step: 2195\n",
            "Sample ID: 23231\n",
            "Decoded Input: Who was the Stage 1 winner?\n",
            "Decoded Target (Labels): SELECT winner FROM table_22917458_15 WHERE stage = 1\n",
            "\n",
            "Iteration/Step: 2195\n",
            "Sample ID: 11687\n",
            "Decoded Input: What is the location of the match where the method was submission (armbar) and Mayra Conde was the opponent?\n",
            "Decoded Target (Labels): SELECT location FROM table_name_19 WHERE method = \"submission (armbar)\" AND opponent = \"mayra conde\"\n",
            "\n",
            "Iteration/Step: 2196\n",
            "Sample ID: 9677\n",
            "Decoded Input: What is the Winning score in 1965?\n",
            "Decoded Target (Labels): SELECT winning_score FROM table_name_90 WHERE year = 1965\n",
            "\n",
            "Iteration/Step: 2196\n",
            "Sample ID: 19682\n",
            "Decoded Input: Tell me the label for US region and catalog of 10008-2\n",
            "Decoded Target (Labels): SELECT label FROM table_name_2 WHERE region = \"us\" AND catalog = \"10008-2\"\n",
            "\n",
            "Iteration/Step: 2197\n",
            "Sample ID: 4835\n",
            "Decoded Input: What is the Copa Libertadores 1999 result for team grêmio, who did not qualify for Copa Conmebol 1999?\n",
            "Decoded Target (Labels): SELECT copa_libertadores_1999 FROM table_name_23 WHERE copa_conmebol_1999 = \"did not qualify\" AND team = \"grêmio\"\n",
            "\n",
            "Iteration/Step: 2197\n",
            "Sample ID: 16689\n",
            "Decoded Input: what is the club when the runners-up is 1 and the last final won is 1999?\n",
            "Decoded Target (Labels): SELECT club FROM table_name_35 WHERE runners_up = 1 AND last_final_won = \"1999\"\n",
            "\n",
            "Iteration/Step: 2198\n",
            "Sample ID: 25927\n",
            "Decoded Input: What is the tournament on February 17, 2002?\n",
            "Decoded Target (Labels): SELECT tournament FROM table_name_21 WHERE date = \"february 17, 2002\"\n",
            "\n",
            "Iteration/Step: 2198\n",
            "Sample ID: 22970\n",
            "Decoded Input: What week has a Record of 12-2?\n",
            "Decoded Target (Labels): SELECT week FROM table_name_99 WHERE record = \"12-2\"\n",
            "\n",
            "Iteration/Step: 2199\n",
            "Sample ID: 9840\n",
            "Decoded Input: What is the total silver with a Rank larger than 9, and a Total larger than 1?\n",
            "Decoded Target (Labels): SELECT SUM(silver) FROM table_name_94 WHERE rank > 9 AND total > 1\n",
            "\n",
            "Iteration/Step: 2199\n",
            "Sample ID: 182\n",
            "Decoded Input: What is the name of the artist who produced the shortest song?\n",
            "Decoded Target (Labels): SELECT T1.artist_name FROM song AS T1 JOIN files AS T2 ON T1.f_id = T2.f_id ORDER BY T2.duration LIMIT 1\n",
            "\n",
            "Iteration/Step: 2200\n",
            "Sample ID: 5069\n",
            "Decoded Input: What is the total number for November, larger than 8.53 in February, 20.21 in March, and less than 7.9 in September?\n",
            "Decoded Target (Labels): SELECT COUNT(november) FROM table_name_50 WHERE february > 8.53 AND march = 20.21 AND september < 7.9\n",
            "\n",
            "Iteration/Step: 2200\n",
            "Sample ID: 1718\n",
            "Decoded Input: Can you tell me the Wins that has the Starts larger than 1, and the Top 5 of 3?\n",
            "Decoded Target (Labels): SELECT wins FROM table_name_19 WHERE starts > 1 AND top_5 = 3\n",
            "\n",
            "Iteration/Step: 2201\n",
            "Sample ID: 22561\n",
            "Decoded Input: How many donors have endowment for school named \"Glenn\"?\n",
            "Decoded Target (Labels): SELECT COUNT(DISTINCT T1.donator_name) FROM endowment AS T1 JOIN school AS T2 ON T1.school_id = T2.school_id WHERE T2.school_name = \"Glenn\"\n",
            "\n",
            "Iteration/Step: 2201\n",
            "Sample ID: 5285\n",
            "Decoded Input: What is the notes for the team from Denmark?\n",
            "Decoded Target (Labels): SELECT notes FROM table_name_48 WHERE country = \"denmark\"\n",
            "\n",
            "Iteration/Step: 2202\n",
            "Sample ID: 16243\n",
            "Decoded Input: Name the tries that has a points of 008 8 and games of 27 27\n",
            "Decoded Target (Labels): SELECT tries FROM table_name_98 WHERE points = \"008 8\" AND games = \"27 27\"\n",
            "\n",
            "Iteration/Step: 2202\n",
            "Sample ID: 25708\n",
            "Decoded Input: How many laps did Giancarlo Fisichella do with a grid larger than 15?\n",
            "Decoded Target (Labels): SELECT COUNT(laps) FROM table_name_36 WHERE driver = \"giancarlo fisichella\" AND grid > 15\n",
            "\n",
            "Iteration/Step: 2203\n",
            "Sample ID: 16370\n",
            "Decoded Input: When did the team score 21 goals?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_67 WHERE goal = 21\n",
            "\n",
            "Iteration/Step: 2203\n",
            "Sample ID: 16355\n",
            "Decoded Input: What was the average speed where lap four's time was 22.9049?\n",
            "Decoded Target (Labels): SELECT avg_speed FROM table_23018775_3 WHERE lap_four = \"22.9049\"\n",
            "\n",
            "Iteration/Step: 2204\n",
            "Sample ID: 22647\n",
            "Decoded Input: What was the score June 22?\n",
            "Decoded Target (Labels): SELECT loss FROM table_name_82 WHERE date = \"june 22\"\n",
            "\n",
            "Iteration/Step: 2204\n",
            "Sample ID: 20843\n",
            "Decoded Input: Who was the leader at the summit when the stage was larger than 14, the category was 1, the start was Saint-Girons, and the finish was Cauterets?\n",
            "Decoded Target (Labels): SELECT leader_at_the_summit FROM table_name_78 WHERE stage > 14 AND category = 1 AND start = \"saint-girons\" AND finish = \"cauterets\"\n",
            "\n",
            "Iteration/Step: 2205\n",
            "Sample ID: 23521\n",
            "Decoded Input: When did the Portland Trail Blazers play against Cleveland?\n",
            "Decoded Target (Labels): SELECT date FROM table_23286158_7 WHERE team = \"Cleveland\"\n",
            "\n",
            "Iteration/Step: 2205\n",
            "Sample ID: 21142\n",
            "Decoded Input: What was the attendance of the Mariners game when they had a record of 56–20?\n",
            "Decoded Target (Labels): SELECT attendance FROM table_name_85 WHERE record = \"56–20\"\n",
            "\n",
            "Iteration/Step: 2206\n",
            "Sample ID: 23358\n",
            "Decoded Input: What height was the forward position at Crockett High School?\n",
            "Decoded Target (Labels): SELECT height FROM table_12032893_1 WHERE position = \"Forward\" AND high_school = \"Crockett\"\n",
            "\n",
            "Iteration/Step: 2206\n",
            "Sample ID: 11848\n",
            "Decoded Input: Name the date for clay surface and score of 0–6, 0–6\n",
            "Decoded Target (Labels): SELECT date FROM table_name_75 WHERE surface = \"clay\" AND score = \"0–6, 0–6\"\n",
            "\n",
            "Iteration/Step: 2207\n",
            "Sample ID: 10413\n",
            "Decoded Input: What match number took place on August 3, 2007?\n",
            "Decoded Target (Labels): SELECT MAX(match) FROM table_name_38 WHERE date = \"august 3, 2007\"\n",
            "\n",
            "Iteration/Step: 2207\n",
            "Sample ID: 10872\n",
            "Decoded Input: How many total medals for the nation ranked 7 with 1 silver and under 4 bronzes?\n",
            "Decoded Target (Labels): SELECT AVG(total) FROM table_name_56 WHERE bronze < 4 AND silver = 1 AND rank = \"7\"\n",
            "\n",
            "Iteration/Step: 2208\n",
            "Sample ID: 5714\n",
            "Decoded Input: who is the the womens doubles with mens doubles being reinhold pum karl buchart and mixed doubles being hermann fröhlich lore voit\n",
            "Decoded Target (Labels): SELECT womens_doubles FROM table_15002265_1 WHERE mens_doubles = \"Reinhold Pum Karl Buchart\" AND mixed_doubles = \"Hermann Fröhlich Lore Voit\"\n",
            "\n",
            "Iteration/Step: 2208\n",
            "Sample ID: 9754\n",
            "Decoded Input: What is Result, when Film is \"Dharma Chakram\", and when Award is \"Nandi Award for Best Actor\"?\n",
            "Decoded Target (Labels): SELECT result FROM table_name_87 WHERE film = \"dharma chakram\" AND award = \"nandi award for best actor\"\n",
            "\n",
            "Iteration/Step: 2209\n",
            "Sample ID: 3720\n",
            "Decoded Input: what pitcher scored 4\n",
            "Decoded Target (Labels): SELECT ret_number FROM table_name_63 WHERE records = \"4\"\n",
            "\n",
            "Iteration/Step: 2209\n",
            "Sample ID: 3666\n",
            "Decoded Input: Which games had Philadelphia as home team?\n",
            "Decoded Target (Labels): SELECT game FROM table_name_20 WHERE home_team = \"philadelphia\"\n",
            "\n",
            "Iteration/Step: 2210\n",
            "Sample ID: 16065\n",
            "Decoded Input: What model number has part number cl8064701510101?\n",
            "Decoded Target (Labels): SELECT model_number FROM table_name_69 WHERE part_number_s_ = \"cl8064701510101\"\n",
            "\n",
            "Iteration/Step: 2210\n",
            "Sample ID: 24806\n",
            "Decoded Input: How many years correspond to longitude of 36.8e and diameter greater than 697?\n",
            "Decoded Target (Labels): SELECT COUNT(year_named) FROM table_name_72 WHERE longitude = \"36.8e\" AND diameter__km_ > 697\n",
            "\n",
            "Iteration/Step: 2211\n",
            "Sample ID: 19728\n",
            "Decoded Input: Which staff handled least number of payments? List the full name and the id.\n",
            "Decoded Target (Labels): SELECT T1.first_name, T1.last_name, T1.staff_id FROM staff AS T1 JOIN payment AS T2 ON T1.staff_id = T2.staff_id GROUP BY T1.staff_id ORDER BY COUNT(*) LIMIT 1\n",
            "\n",
            "Iteration/Step: 2211\n",
            "Sample ID: 9633\n",
            "Decoded Input: What region has a bronze label and a catalogue of 202 876-270?\n",
            "Decoded Target (Labels): SELECT region FROM table_name_82 WHERE label = \"bronze\" AND catalogue = \"202 876-270\"\n",
            "\n",
            "Iteration/Step: 2212\n",
            "Sample ID: 531\n",
            "Decoded Input: Which position had a pick of 50?\n",
            "Decoded Target (Labels): SELECT position FROM table_name_35 WHERE pick = 50\n",
            "\n",
            "Iteration/Step: 2212\n",
            "Sample ID: 3344\n",
            "Decoded Input: What is the power when the displacement is 182cid (2,988cc) and the notes are eu spec?\n",
            "Decoded Target (Labels): SELECT power FROM table_name_43 WHERE displacement = \"182cid (2,988cc)\" AND notes = \"eu spec\"\n",
            "\n",
            "Iteration/Step: 2213\n",
            "Sample ID: 25384\n",
            "Decoded Input: Name the name for  plymouth albion orrell\n",
            "Decoded Target (Labels): SELECT name FROM table_22977424_8 WHERE promoted_to_league = \"Plymouth Albion Orrell\"\n",
            "\n",
            "Iteration/Step: 2213\n",
            "Sample ID: 13893\n",
            "Decoded Input: Can you tell me the average Total that had the Silver of 0, and the Rank of 6, and the Gold smaller than 0?\n",
            "Decoded Target (Labels): SELECT AVG(total) FROM table_name_92 WHERE silver = 0 AND rank = \"6\" AND gold < 0\n",
            "\n",
            "Iteration/Step: 2214\n",
            "Sample ID: 17198\n",
            "Decoded Input: What is the pick number of the defensive back?\n",
            "Decoded Target (Labels): SELECT COUNT(overall_pick__number) FROM table_12165135_1 WHERE position = \"Defensive Back\"\n",
            "\n",
            "Iteration/Step: 2214\n",
            "Sample ID: 12887\n",
            "Decoded Input: what are the locations that  joined in 2008\n",
            "Decoded Target (Labels): SELECT location FROM table_11658094_1 WHERE joined = \"2008\"\n",
            "\n",
            "Iteration/Step: 2215\n",
            "Sample ID: 11254\n",
            "Decoded Input: Rank of 6 has what time?\n",
            "Decoded Target (Labels): SELECT time FROM table_name_16 WHERE rank = 6\n",
            "\n",
            "Iteration/Step: 2215\n",
            "Sample ID: 6239\n",
            "Decoded Input: How many goals against were scored when the position was higher than 1 and the played was higher than 10?\n",
            "Decoded Target (Labels): SELECT COUNT(goals_against) FROM table_name_17 WHERE position > 1 AND played > 10\n",
            "\n",
            "Iteration/Step: 2216\n",
            "Sample ID: 13382\n",
            "Decoded Input: What is the method of the match where there was a loss to Carlos Newton in round 1?\n",
            "Decoded Target (Labels): SELECT method FROM table_name_61 WHERE round = \"1\" AND res = \"loss\" AND opponent = \"carlos newton\"\n",
            "\n",
            "Iteration/Step: 2216\n",
            "Sample ID: 24168\n",
            "Decoded Input: If the stage is smaller than 5.0, and the points classification is by Marco Marcato, who is the General classification by?\n",
            "Decoded Target (Labels): SELECT general_classification FROM table_27573848_18 WHERE points_classification = \"Marco Marcato\" AND stage < 5.0\n",
            "\n",
            "Iteration/Step: 2217\n",
            "Sample ID: 9425\n",
            "Decoded Input: Which province has the contestant elixandra tobias carasco?\n",
            "Decoded Target (Labels): SELECT province, _community FROM table_name_81 WHERE contestant = \"elixandra tobias carasco\"\n",
            "\n",
            "Iteration/Step: 2217\n",
            "Sample ID: 20775\n",
            "Decoded Input: Which Top-25 has a Top-5 smaller than 0?\n",
            "Decoded Target (Labels): SELECT SUM(top_25) FROM table_name_3 WHERE top_5 < 0\n",
            "\n",
            "Iteration/Step: 2218\n",
            "Sample ID: 5078\n",
            "Decoded Input: What is the film that Raymond Massey was nominated for?\n",
            "Decoded Target (Labels): SELECT film FROM table_name_94 WHERE nominee = \"raymond massey\"\n",
            "\n",
            "Iteration/Step: 2218\n",
            "Sample ID: 17224\n",
            "Decoded Input: What is earliest year that had a 50km event with a 2nd place result played in London, United Kingdom?\n",
            "Decoded Target (Labels): SELECT MIN(year) FROM table_name_8 WHERE event = \"50km\" AND result = \"2nd\" AND venue = \"london, united kingdom\"\n",
            "\n",
            "Iteration/Step: 2219\n",
            "Sample ID: 5689\n",
            "Decoded Input: Which Round has an Overall smaller than 6?\n",
            "Decoded Target (Labels): SELECT MAX(round) FROM table_name_84 WHERE overall < 6\n",
            "\n",
            "Iteration/Step: 2219\n",
            "Sample ID: 2822\n",
            "Decoded Input: How many total number of attendance were there when the game was held in Anaheim Stadium?\n",
            "Decoded Target (Labels): SELECT COUNT(attendance) FROM table_17972193_1 WHERE game_site = \"Anaheim Stadium\"\n",
            "\n",
            "Iteration/Step: 2220\n",
            "Sample ID: 10341\n",
            "Decoded Input: What country has an ICAO of ENZV?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_85 WHERE icao = \"enzv\"\n",
            "\n",
            "Iteration/Step: 2220\n",
            "Sample ID: 16504\n",
            "Decoded Input: How much Drawn has a Lost of 2, and Played smaller than 14?\n",
            "Decoded Target (Labels): SELECT SUM(drawn) FROM table_name_46 WHERE lost = 2 AND played < 14\n",
            "\n",
            "Iteration/Step: 2221\n",
            "Sample ID: 1463\n",
            "Decoded Input: What is the home of the team with Carlos Boozer (27) as the leading scorer?\n",
            "Decoded Target (Labels): SELECT home FROM table_name_1 WHERE leading_scorer = \"carlos boozer (27)\"\n",
            "\n",
            "Iteration/Step: 2221\n",
            "Sample ID: 6414\n",
            "Decoded Input: Name the venue for 25 may 2008\n",
            "Decoded Target (Labels): SELECT venue FROM table_name_94 WHERE date = \"25 may 2008\"\n",
            "\n",
            "Iteration/Step: 2222\n",
            "Sample ID: 8731\n",
            "Decoded Input: What was the score when Stefan Edberg won?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_64 WHERE winner = \"stefan edberg\"\n",
            "\n",
            "Iteration/Step: 2222\n",
            "Sample ID: 10948\n",
            "Decoded Input: Who vacated his post when his successor was formally installed on May 11, 1966?\n",
            "Decoded Target (Labels): SELECT vacator FROM table_1847180_3 WHERE date_of_successors_formal_installation = \"May 11, 1966\"\n",
            "\n",
            "Iteration/Step: 2223\n",
            "Sample ID: 6201\n",
            "Decoded Input: What is the route/via when the destination is listed as Madurai?\n",
            "Decoded Target (Labels): SELECT route_via FROM table_29202276_2 WHERE destination = \"Madurai\"\n",
            "\n",
            "Iteration/Step: 2223\n",
            "Sample ID: 3787\n",
            "Decoded Input: What is Name, when Weight is \"kg (lb)\", when Club is \"Gezira\", and when Date of Birth is \"1974-02-18\"?\n",
            "Decoded Target (Labels): SELECT name FROM table_name_83 WHERE weight = \"kg (lb)\" AND club = \"gezira\" AND date_of_birth = \"1974-02-18\"\n",
            "\n",
            "Iteration/Step: 2224\n",
            "Sample ID: 24399\n",
            "Decoded Input: What is the Host team that has indianapolis colts as a Visiting team?\n",
            "Decoded Target (Labels): SELECT host_team FROM table_name_71 WHERE visiting_team = \"indianapolis colts\"\n",
            "\n",
            "Iteration/Step: 2224\n",
            "Sample ID: 1693\n",
            "Decoded Input: What catalog has the United Kingdom as the country?\n",
            "Decoded Target (Labels): SELECT catalog FROM table_name_9 WHERE country = \"united kingdom\"\n",
            "\n",
            "Iteration/Step: 2225\n",
            "Sample ID: 17245\n",
            "Decoded Input: What is the Score with a Hoe that is etobicoke kangaroos?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_60 WHERE home = \"etobicoke kangaroos\"\n",
            "\n",
            "Iteration/Step: 2225\n",
            "Sample ID: 11428\n",
            "Decoded Input: Which planet has an orbital period of 11.86 years?\n",
            "Decoded Target (Labels): SELECT planet FROM table_10932739_2 WHERE orbital_period = \"11.86 years\"\n",
            "\n",
            "Iteration/Step: 2226\n",
            "Sample ID: 14588\n",
            "Decoded Input: Name the constituted for labor and scullin ministry\n",
            "Decoded Target (Labels): SELECT constituted FROM table_name_86 WHERE party = \"labor\" AND name = \"scullin ministry\"\n",
            "\n",
            "Iteration/Step: 2226\n",
            "Sample ID: 18844\n",
            "Decoded Input: Which score was associated with an attendance of 275?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_66 WHERE attendance = 275\n",
            "\n",
            "Iteration/Step: 2227\n",
            "Sample ID: 9592\n",
            "Decoded Input: What is Opponent, when Date is December 18, 1988?\n",
            "Decoded Target (Labels): SELECT opponent FROM table_name_7 WHERE date = \"december 18, 1988\"\n",
            "\n",
            "Iteration/Step: 2227\n",
            "Sample ID: 22132\n",
            "Decoded Input: How many times is  keauna mclaughlin / rockne brubaker ranked?\n",
            "Decoded Target (Labels): SELECT COUNT(rank) FROM table_23938357_6 WHERE name = \"Keauna McLaughlin / Rockne Brubaker\"\n",
            "\n",
            "Iteration/Step: 2228\n",
            "Sample ID: 2746\n",
            "Decoded Input: How many chassis used number 34?\n",
            "Decoded Target (Labels): SELECT COUNT(chassis) FROM table_15491596_1 WHERE no = 34\n",
            "\n",
            "Iteration/Step: 2228\n",
            "Sample ID: 1696\n",
            "Decoded Input: How many FG percent values are associated with 59 assists and offensive rebounds under 40?\n",
            "Decoded Target (Labels): SELECT COUNT(fg_pct) FROM table_name_21 WHERE asst = 59 AND off_reb < 40\n",
            "\n",
            "Iteration/Step: 2229\n",
            "Sample ID: 21804\n",
            "Decoded Input: What place was the player who scored 70-69-68=207?\n",
            "Decoded Target (Labels): SELECT place FROM table_name_6 WHERE score = 70 - 69 - 68 = 207\n",
            "\n",
            "Iteration/Step: 2229\n",
            "Sample ID: 18168\n",
            "Decoded Input: Can you tell me the average Total that has the To par smaller than 10, and the Country of south korea?\n",
            "Decoded Target (Labels): SELECT AVG(total) FROM table_name_60 WHERE to_par < 10 AND country = \"south korea\"\n",
            "\n",
            "Iteration/Step: 2230\n",
            "Sample ID: 25433\n",
            "Decoded Input: How many clubs are involved when there are 4 winners from the previous rounds and more than 4 clubs remaining?\n",
            "Decoded Target (Labels): SELECT MIN(clubs_involved) FROM table_name_59 WHERE winners_from_previous_round = \"4\" AND clubs_remaining > 4\n",
            "\n",
            "Iteration/Step: 2230\n",
            "Sample ID: 23761\n",
            "Decoded Input: WHAT IS THE LOSS WITH AN AVERAGE OF 89.9?\n",
            "Decoded Target (Labels): SELECT SUM(loss) FROM table_name_18 WHERE avg_g = 89.9\n",
            "\n",
            "Iteration/Step: 2231\n",
            "Sample ID: 11569\n",
            "Decoded Input: Tell me the report with winner of louis wagner\n",
            "Decoded Target (Labels): SELECT report FROM table_name_51 WHERE winning_driver = \"louis wagner\"\n",
            "\n",
            "Iteration/Step: 2231\n",
            "Sample ID: 5004\n",
            "Decoded Input: If the Steals are 20, what are the blocks?\n",
            "Decoded Target (Labels): SELECT MAX(blocks) FROM table_25342713_5 WHERE steals = 20\n",
            "\n",
            "Iteration/Step: 2232\n",
            "Sample ID: 7539\n",
            "Decoded Input: What film did michaylo ilyenko make with best actor in a supporting role?\n",
            "Decoded Target (Labels): SELECT film_name FROM table_10236830_1 WHERE director = \"Michaylo Ilyenko\" AND nomination = \"Best Actor in a Supporting Role\"\n",
            "\n",
            "Iteration/Step: 2232\n",
            "Sample ID: 20249\n",
            "Decoded Input: Name the date for score of 1-5\n",
            "Decoded Target (Labels): SELECT date FROM table_name_38 WHERE score = \"1-5\"\n",
            "\n",
            "Iteration/Step: 2233\n",
            "Sample ID: 14457\n",
            "Decoded Input: How many entries are listed in poor law union when townland is dromidiclogh?\n",
            "Decoded Target (Labels): SELECT COUNT(poor_law_union) FROM table_30121075_1 WHERE townland = \"Dromidiclogh\"\n",
            "\n",
            "Iteration/Step: 2233\n",
            "Sample ID: 13754\n",
            "Decoded Input: What is the highest uni# of the person with the first name Todd?\n",
            "Decoded Target (Labels): SELECT MAX(uni_number) FROM table_name_32 WHERE first = \"todd\"\n",
            "\n",
            "Iteration/Step: 2234\n",
            "Sample ID: 12148\n",
            "Decoded Input: What is the Country of the Player with a Score of 75-70-74=219?\n",
            "Decoded Target (Labels): SELECT country FROM table_name_13 WHERE score = 75 - 70 - 74 = 219\n",
            "\n",
            "Iteration/Step: 2234\n",
            "Sample ID: 9370\n",
            "Decoded Input: What is the population of the parish with a census ranking of 579 of 5,008?\n",
            "Decoded Target (Labels): SELECT SUM(population) FROM table_name_32 WHERE census_ranking = \"579 of 5,008\"\n",
            "\n",
            "Iteration/Step: 2235\n",
            "Sample ID: 11515\n",
            "Decoded Input: How many villains were in episode 3 (13)?\n",
            "Decoded Target (Labels): SELECT COUNT(villains) FROM table_23170118_2 WHERE episode_number = \"3 (13)\"\n",
            "\n",
            "Iteration/Step: 2235\n",
            "Sample ID: 23567\n",
            "Decoded Input: Who was the home team when Boston is the road team in game 4?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_89 WHERE road_team = \"boston\" AND game = \"game 4\"\n",
            "\n",
            "Iteration/Step: 2236\n",
            "Sample ID: 1669\n",
            "Decoded Input: What score has Toronto Eagles as the home?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_57 WHERE home = \"toronto eagles\"\n",
            "\n",
            "Iteration/Step: 2236\n",
            "Sample ID: 12142\n",
            "Decoded Input: how many 10wi and bbi is 6/101\n",
            "Decoded Target (Labels): SELECT COUNT(10 AS wi) FROM table_28846752_5 WHERE bbi = \"6/101\"\n",
            "\n",
            "Iteration/Step: 2237\n",
            "Sample ID: 24642\n",
            "Decoded Input: Which sport was held in Huntsville at the Von Braun Center as part of the Southern Indoor Football League?\n",
            "Decoded Target (Labels): SELECT sport FROM table_name_76 WHERE city = \"huntsville\" AND venue = \"von braun center\" AND league = \"southern indoor football league\"\n",
            "\n",
            "Iteration/Step: 2237\n",
            "Sample ID: 12606\n",
            "Decoded Input: What day is carlton the home side?\n",
            "Decoded Target (Labels): SELECT date FROM table_name_87 WHERE home_team = \"carlton\"\n",
            "\n",
            "Iteration/Step: 2238\n",
            "Sample ID: 1119\n",
            "Decoded Input: What is the lowest population density of Strakonice (st) with more than 112 settlements?\n",
            "Decoded Target (Labels): SELECT MIN(pop_dens) FROM table_name_66 WHERE district = \"strakonice (st)\" AND noof_settlements > 112\n",
            "\n",
            "Iteration/Step: 2238\n",
            "Sample ID: 15489\n",
            "Decoded Input: What is the lowest Round with Overall of 247 and pick less than 41?\n",
            "Decoded Target (Labels): SELECT MIN(round) FROM table_name_39 WHERE overall = 247 AND pick__number < 41\n",
            "\n",
            "Iteration/Step: 2239\n",
            "Sample ID: 3533\n",
            "Decoded Input: What is the average amount due for all the payments?\n",
            "Decoded Target (Labels): SELECT AVG(amount_due) FROM payments\n",
            "\n",
            "Iteration/Step: 2239\n",
            "Sample ID: 1904\n",
            "Decoded Input: Name the total number of wickets being yuvraj singh\n",
            "Decoded Target (Labels): SELECT COUNT(wickets) FROM table_15700367_2 WHERE name = \"Yuvraj Singh\"\n",
            "\n",
            "Iteration/Step: 2240\n",
            "Sample ID: 7568\n",
            "Decoded Input: What is the Hanja/Kanji of the Province with a Kana of ちゅうせいほくどう?\n",
            "Decoded Target (Labels): SELECT hanja___kanji FROM table_name_10 WHERE kana = \"ちゅうせいほくどう\"\n",
            "\n",
            "Iteration/Step: 2240\n",
            "Sample ID: 25308\n",
            "Decoded Input: What is the Score of the game with a Record of 12–12?\n",
            "Decoded Target (Labels): SELECT score FROM table_name_93 WHERE record = \"12–12\"\n",
            "\n",
            "Iteration/Step: 2241\n",
            "Sample ID: 1392\n",
            "Decoded Input: Show all distinct publishers for books.\n",
            "Decoded Target (Labels): SELECT DISTINCT publisher FROM book_club\n",
            "\n",
            "Iteration/Step: 2241\n",
            "Sample ID: 11322\n",
            "Decoded Input: What is are the highest matches with £5,000 in prize money?\n",
            "Decoded Target (Labels): SELECT MAX(matches) FROM table_name_77 WHERE prize_money = \"£5,000\"\n",
            "\n",
            "Iteration/Step: 2242\n",
            "Sample ID: 3357\n",
            "Decoded Input: For the NBC network, what was the new/returning/same network status?\n",
            "Decoded Target (Labels): SELECT new_returning_same_network FROM table_169766_13 WHERE previous_network = \"NBC\"\n",
            "\n",
            "Iteration/Step: 2242\n",
            "Sample ID: 12202\n",
            "Decoded Input: What is the lowest Floors, when Built is greater than 1970, and when Name is NV Building 3?\n",
            "Decoded Target (Labels): SELECT MIN(floors) FROM table_name_90 WHERE built > 1970 AND name = \"nv building 3\"\n",
            "\n",
            "Iteration/Step: 2243\n",
            "Sample ID: 666\n",
            "Decoded Input: Who are the recipients that won for David Duchovny role/episode?\n",
            "Decoded Target (Labels): SELECT recipients_and_nominees FROM table_name_30 WHERE role_episode = \"david duchovny\" AND result = \"won\"\n",
            "\n",
            "Iteration/Step: 2243\n",
            "Sample ID: 8324\n",
            "Decoded Input: What is the average black value (Hispanic/Non-Hispanic) having a white (Hispanic/Non-Hispanic) under 61.9, Multiracial (Hispanic/Non-Hispanic) under 12.5 and Hispanic under 99.4?\n",
            "Decoded Target (Labels): SELECT AVG(black__both_hispanic_and_non_hispanic_) FROM table_name_99 WHERE white__both_hispanic_and_non_hispanic_ < 61.9 AND multiracial__both_hispanic_and_non_hispanic_ < 12.5 AND hispanic__of_any_race_ < 99.4\n",
            "\n",
            "Iteration/Step: 2244\n",
            "Sample ID: 16609\n",
            "Decoded Input: Bronze larger than 2, and a Rank of 4, and a Total larger than 7 has how many numbers of gold?\n",
            "Decoded Target (Labels): SELECT AVG(gold) FROM table_name_84 WHERE bronze > 2 AND rank = 4 AND total > 7\n",
            "\n",
            "Iteration/Step: 2244\n",
            "Sample ID: 6434\n",
            "Decoded Input: How many teams have channing frye, jason richardson (8) as high rebounds?\n",
            "Decoded Target (Labels): SELECT COUNT(team) FROM table_23285761_11 WHERE high_rebounds = \"Channing Frye, Jason Richardson (8)\"\n",
            "\n",
            "Iteration/Step: 2245\n",
            "Sample ID: 18500\n",
            "Decoded Input: What was the conference when Arizona State won the regular season?\n",
            "Decoded Target (Labels): SELECT conference FROM table_22779004_1 WHERE regular_season_winner = \"Arizona State\"\n",
            "\n",
            "Iteration/Step: 2245\n",
            "Sample ID: 3829\n",
            "Decoded Input: List the numer of miles for 2010.\n",
            "Decoded Target (Labels): SELECT miles__km_ FROM table_28178756_1 WHERE year = 2010\n",
            "\n",
            "Iteration/Step: 2246\n",
            "Sample ID: 16448\n",
            "Decoded Input: What is the largest crowd when melbourne plays at home?\n",
            "Decoded Target (Labels): SELECT MAX(crowd) FROM table_name_98 WHERE home_team = \"melbourne\"\n",
            "\n",
            "Iteration/Step: 2246\n",
            "Sample ID: 25673\n",
            "Decoded Input: Name the genus/species of accession number bx897699.1\n",
            "Decoded Target (Labels): SELECT genus_species FROM table_27155678_2 WHERE accession_number = \"BX897699.1\"\n",
            "\n",
            "Iteration/Step: 2247\n",
            "Sample ID: 20863\n",
            "Decoded Input: How many rebounds were there in 2008?\n",
            "Decoded Target (Labels): SELECT COUNT(rebounds) FROM table_13050003_2 WHERE year = 2008\n",
            "\n",
            "Iteration/Step: 2247\n",
            "Sample ID: 135\n",
            "Decoded Input: What is the duration when Lok Sabha shows fifth?\n",
            "Decoded Target (Labels): SELECT duration FROM table_name_86 WHERE lok_sabha = \"fifth\"\n",
            "\n",
            "Iteration/Step: 2248\n",
            "Sample ID: 9554\n",
            "Decoded Input: What was the stadium in Adelaide, South Australia built for? \n",
            "Decoded Target (Labels): SELECT built_for FROM table_28885977_1 WHERE location = \"Adelaide, South Australia\"\n",
            "\n",
            "Iteration/Step: 2248\n",
            "Sample ID: 25926\n",
            "Decoded Input: when the gdp per emissions (in us dollars per ton) is 3903, what is the maximum annual co2 emissions (in thousands of metric tons)?\n",
            "Decoded Target (Labels): SELECT MAX(annual_co2_emissions__in_thousands_of_metric_tons_) FROM table_2508175_1 WHERE gdp_per_emissions__in_us_dollars_per_ton_ = 3903\n",
            "\n",
            "Iteration/Step: 2249\n",
            "Sample ID: 16524\n",
            "Decoded Input: What is the percentage of females where the state code is a 4?\n",
            "Decoded Target (Labels): SELECT females___percentage_ FROM table_14598_9 WHERE state_ut_code = 4\n",
            "\n",
            "Iteration/Step: 2249\n",
            "Sample ID: 18454\n",
            "Decoded Input: What's the highest level of team Astana since 2007?\n",
            "Decoded Target (Labels): SELECT MAX(level) FROM table_name_96 WHERE team = \"astana\" AND season > 2007\n",
            "\n",
            "Iteration/Step: 2250\n",
            "Sample ID: 14980\n",
            "Decoded Input: What was the location attendance on the date of November 15?\n",
            "Decoded Target (Labels): SELECT location_attendance FROM table_11960610_6 WHERE date = \"November 15\"\n",
            "\n",
            "Iteration/Step: 2250\n",
            "Sample ID: 23490\n",
            "Decoded Input: Which year had a Score of kapunda 14-13-97 tanunda 5-14-44?\n",
            "Decoded Target (Labels): SELECT SUM(year) FROM table_name_53 WHERE score = \"kapunda 14-13-97 tanunda 5-14-44\"\n",
            "\n",
            "Iteration/Step: 2251\n",
            "Sample ID: 11928\n",
            "Decoded Input: Show the id, name of each editor and the number of journal committees they are on.\n",
            "Decoded Target (Labels): SELECT T1.editor_id, T1.Name, COUNT(*) FROM editor AS T1 JOIN journal_committee AS T2 ON T1.Editor_ID = T2.Editor_ID GROUP BY T1.editor_id\n",
            "\n",
            "Iteration/Step: 2251\n",
            "Sample ID: 13173\n",
            "Decoded Input: What is the percentage of Android use when Windows is 1.15%?\n",
            "Decoded Target (Labels): SELECT android FROM table_11381701_3 WHERE windows = \"1.15%\"\n",
            "\n",
            "Iteration/Step: 2252\n",
            "Sample ID: 10555\n",
            "Decoded Input: What is the Height (ft) of the Churchill House with a Height (m) less than 59?\n",
            "Decoded Target (Labels): SELECT COUNT(height__ft_) FROM table_name_12 WHERE name = \"churchill house\" AND height__m_ < 59\n",
            "\n",
            "Iteration/Step: 2252\n",
            "Sample ID: 12030\n",
            "Decoded Input: Who directed the episode that had 5.92 million viewers?\n",
            "Decoded Target (Labels): SELECT directed_by FROM table_25341765_1 WHERE us_viewers__million_ = \"5.92\"\n",
            "\n",
            "Iteration/Step: 2253\n",
            "Sample ID: 14956\n",
            "Decoded Input: Which FSB/HT frequency (MHz) has a SATA larger than 6 and DDR 266/333/400 Registered/ECC memory?\n",
            "Decoded Target (Labels): SELECT fsb_ht_frequency__mhz_ FROM table_name_79 WHERE sata > 6 AND memory = \"ddr 266/333/400 registered/ecc\"\n",
            "\n",
            "Iteration/Step: 2253\n",
            "Sample ID: 14054\n",
            "Decoded Input: Find the names and average salaries of all departments whose average salary is greater than 42000.\n",
            "Decoded Target (Labels): SELECT dept_name, AVG(salary) FROM instructor GROUP BY dept_name HAVING AVG(salary) > 42000\n",
            "\n",
            "Iteration/Step: 2254\n",
            "Sample ID: 12871\n",
            "Decoded Input: What year was Stephenson the builder?\n",
            "Decoded Target (Labels): SELECT built FROM table_name_93 WHERE builder = \"stephenson\"\n",
            "\n",
            "Iteration/Step: 2254\n",
            "Sample ID: 7109\n",
            "Decoded Input: What is the value for New entries, when the value for Fixtures is 2?\n",
            "Decoded Target (Labels): SELECT new_entries FROM table_name_71 WHERE fixtures = 2\n",
            "\n",
            "Iteration/Step: 2255\n",
            "Sample ID: 21292\n",
            "Decoded Input: What week was stefan edberg anders järryd was semifinalist and champion is john mcenroe 7–6, 6–3?\n",
            "Decoded Target (Labels): SELECT week_of FROM table_21584646_10 WHERE semifinalists = \"Stefan Edberg Anders Järryd\" AND champion = \"John McEnroe 7–6, 6–3\"\n",
            "\n",
            "Iteration/Step: 2255\n",
            "Sample ID: 6165\n",
            "Decoded Input: Which Played has a Lost larger than 9, and a Points smaller than 15, and a Position smaller than 12, and a Drawn smaller than 2?\n",
            "Decoded Target (Labels): SELECT AVG(played) FROM table_name_18 WHERE lost > 9 AND points < 15 AND position < 12 AND drawn < 2\n",
            "\n",
            "Iteration/Step: 2256\n",
            "Sample ID: 23260\n",
            "Decoded Input: Which Home team that has a Tie no of 20?\n",
            "Decoded Target (Labels): SELECT home_team FROM table_name_74 WHERE tie_no = \"20\"\n",
            "\n",
            "Iteration/Step: 2256\n",
            "Sample ID: 14562\n",
            "Decoded Input: What is the lowest number of matches played that has more than 0 draws, a percentage of 12.50%, and fewer than 3 losses?\n",
            "Decoded Target (Labels): SELECT MIN(played) FROM table_name_14 WHERE drawn > 0 AND percentage = \"12.50%\" AND lost < 3\n",
            "\n",
            "Iteration/Step: 2257\n",
            "Sample ID: 20736\n",
            "Decoded Input: What is the wins average when 17 games were lost?\n",
            "Decoded Target (Labels): SELECT AVG(wins) FROM table_name_83 WHERE losses = 17\n",
            "\n",
            "Iteration/Step: 2257\n",
            "Sample ID: 18157\n",
            "Decoded Input: Name the 20 questions for 8-04\n",
            "Decoded Target (Labels): SELECT 20 AS _questions FROM table_1566852_5 WHERE date = \"8-04\"\n",
            "\n",
            "Iteration/Step: 2258\n",
            "Sample ID: 10519\n",
            "Decoded Input: Name the Number of electorates (2009 which has a Reserved for ( SC / ST /None) of none, and a Name of jahanabad?\n",
            "Decoded Target (Labels): SELECT MIN(number_of_electorates__2009_) FROM table_name_40 WHERE reserved_for___sc___st__none_ = \"none\" AND name = \"jahanabad\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM, AutoTokenizer,\n",
        "    BitsAndBytesConfig, Trainer, TrainingArguments,\n",
        "    set_seed,\n",
        "    EarlyStoppingCallback,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    TaskType,\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        "    PrefixTuningConfig,\n",
        "    PromptEncoderConfig,\n",
        "    TaskType\n",
        ")\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torch_geometric.nn import GAT\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import evaluate\n",
        "\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"The installed version of bitsandbytes was compiled without GPU support.\")\n",
        "\n",
        "\n",
        "# Load spaCy English model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    # Download if not already downloaded\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# 1. Load and Prepare Data\n",
        "dataset = load_dataset(\"b-mc2/sql-create-context\")[\"train\"].shuffle(seed=42)\n",
        "\n",
        "# Manually define splits\n",
        "train_size = int(0.7 * len(dataset))\n",
        "eval_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - eval_size\n",
        "\n",
        "train_dataset = dataset.select(range(train_size))\n",
        "eval_dataset = dataset.select(range(train_size, train_size + eval_size))\n",
        "test_dataset = dataset.select(range(train_size + eval_size, len(dataset)))\n",
        "\n",
        "# Optionally, load augmented data (if you have it)\n",
        "# train_dataset = load_dataset(\"json\", data_files=\"your_augmented_dataset.json\", split=\"train\")\n",
        "\n",
        "# 2. Mistral Model and Tokenizer\n",
        "#model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "\n",
        "#bnb_config = BitsAndBytesConfig(\n",
        "#    load_in_4bit=True,\n",
        "#    bnb_4bit_use_double_quant=True,\n",
        "#    bnb_4bit_quant_type=\"nf4\",\n",
        "#    bnb_4bit_compute_dtype=torch.bfloat16\n",
        "#)\n",
        "\n",
        "\n",
        "#model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# Model Configuration for Mistral-7B-Instruct-v0.3\n",
        "#config = AutoModelForCausalLM.from_pretrained(model_id).config\n",
        "#config.output_hidden_states = True\n",
        "#config.use_cache = False\n",
        "#config.torch_dtype = torch.float32\n",
        "#config.torch_dtype = torch.bfloat16\n",
        "\n",
        "# Load Model with Quantization\n",
        "#mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "#    model_id,\n",
        "#    attn_implementation=\"flash_attention_2\",  # Optimization\n",
        "#    torch_dtype=torch.bfloat16,\n",
        "#    quantization_config=bnb_config,\n",
        "#     config=config\n",
        "#)\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "#tokenizer.padding_side = \"left\"\n",
        "\n",
        "# Configurable Parameters for fine-tuned model\n",
        "PEFT_MODEL_ID = \"frankmorales2020/Mistral-7B-text-to-sql-flash-attention-2-dataeval\"\n",
        "\n",
        "GENERATION_PARAMS = {\n",
        "    \"max_new_tokens\": 256, \"do_sample\": True, \"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95\n",
        "}\n",
        "\n",
        "\n",
        "import logging\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "\n",
        "# Load Models and Tokenizer\n",
        "logging.info(f\"Loading fine-tuned PEFT model from: {PEFT_MODEL_ID}\")\n",
        "mistral_model = AutoPeftModelForCausalLM.from_pretrained(PEFT_MODEL_ID)\n",
        "tokenizer = AutoTokenizer.from_pretrained(PEFT_MODEL_ID)\n",
        "#pipe = pipeline(\"text-generation\", model=mistral_model, tokenizer=tokenizer, **GENERATION_PARAMS)\n",
        "logging.info(\"Model and tokenizer loaded successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 3. PyTorch Datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class TextToSQLDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "\n",
        "\n",
        "        text = item['question']\n",
        "        target_text = item['answer']\n",
        "\n",
        "\n",
        "        # 1. Tokenization (with padding and truncation)\n",
        "        tokenized_input = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=1024,  # Increase as needed\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokenized_target = self.tokenizer(\n",
        "            target_text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=1024,  # Increase as needed\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Flatten lists (if needed)\n",
        "        tokenized_input = {k: v.squeeze(0) for k, v in tokenized_input.items()}\n",
        "        tokenized_target = {k: v.squeeze(0) for k, v in tokenized_target.items()}\n",
        "\n",
        "\n",
        "        # Print input text and target text for debugging\n",
        "        #print('\\n')\n",
        "        #print(f\"Sample ID: {idx}\")\n",
        "        #print(f\"  - Text: {text}\")\n",
        "        #print(f\"  - Target Text: {target_text}\")\n",
        "        #print('\\n')\n",
        "\n",
        "        sample_ids = torch.tensor([idx])  # Create a tensor with the sample ID\n",
        "\n",
        "        # 2. Dependency Parsing for Edge Extraction\n",
        "        doc = nlp(text)\n",
        "        edges = []\n",
        "        for token in doc:\n",
        "            head_i = token.head.i\n",
        "            if 0 <= head_i < len(doc) and token.dep_ != \"ROOT\" and token.i != head_i:\n",
        "                edges.append([token.i, head_i])\n",
        "\n",
        "        # Edge Index Extraction and Validation\n",
        "        edges = item.get(\"edges\", edges)  # If \"edges\" is already present in data, use that\n",
        "\n",
        "        if not edges:  # Handle empty graphs\n",
        "            num_nodes = len(tokenized_input[\"input_ids\"])\n",
        "            edges = [[i, i] for i in range(num_nodes)]  # Self-loops for isolated nodes\n",
        "        else:\n",
        "            max_index = len(tokenized_input[\"input_ids\"]) - 1\n",
        "            edges = [(src, tgt) for src, tgt in edges if 0 <= src <= max_index and 0 <= tgt <= max_index]\n",
        "\n",
        "        # Create edge index tensor\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        # Convert everything to tensors BEFORE padding/truncation\n",
        "        input_ids = tokenized_input[\"input_ids\"].clone().detach()\n",
        "        attention_mask = tokenized_input[\"attention_mask\"].clone().detach()\n",
        "        labels = tokenized_target[\"input_ids\"].clone().detach()\n",
        "\n",
        "        # Handle potentially empty target sequences\n",
        "        if len(labels) == 0:\n",
        "            labels = torch.tensor([self.tokenizer.pad_token_id], dtype=torch.long)  # Create a single-element tensor with pad token\n",
        "\n",
        "        # Padding and Truncation for consistent input shapes\n",
        "        max_length = 1024  # Adjust if needed\n",
        "\n",
        "        # Ensure that ALL tensors are truncated/padded to the SAME max_length\n",
        "        input_ids = input_ids[:max_length]\n",
        "        attention_mask = attention_mask[:max_length]\n",
        "        labels = labels[:max_length]\n",
        "\n",
        "        # Add padding if necessary\n",
        "        if len(input_ids) < max_length:\n",
        "            pad_length = max_length - len(input_ids)\n",
        "            pad_tensor = torch.full((pad_length,), self.tokenizer.pad_token_id)\n",
        "            input_ids = torch.cat((input_ids, pad_tensor))\n",
        "            attention_mask = torch.cat((attention_mask, torch.zeros(pad_length, dtype=torch.long)))\n",
        "\n",
        "        if len(labels) < max_length:\n",
        "            pad_length = max_length - len(labels)\n",
        "            labels = torch.cat((labels, torch.full((pad_length,), -100)))  # Pad labels with -100\n",
        "\n",
        "        # (Optional) Print statements for debugging\n",
        "        #print(\"\\n\")\n",
        "        #print(\"Original text:\", text)\n",
        "        #print(\"Target text:\", target_text)\n",
        "        #print(\"Tokenized input IDs:\", tokenized_input[\"input_ids\"])\n",
        "        #print(\"Tokenized target IDs:\", tokenized_target[\"input_ids\"])\n",
        "        #print(\"Labels:\", labels)\n",
        "        #print(\"Edge index:\", edge_index)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"edges\": edge_index,\n",
        "            \"sample_ids\": torch.tensor([idx]),  # Add sample_id here\n",
        "        }\n",
        "\n",
        "#train_dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/train_dataset.json\", split=\"train\")\n",
        "#val_dataset   = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/test_dataset.json\", split=\"train\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "#train_dataset = train_dataset.select(range(100))\n",
        "\n",
        "#Reduce train_dataset size for POC\n",
        "POC_sample=26000\n",
        "train_dataset = train_dataset.select(np.random.choice(len(train_dataset), POC_sample, replace=False))\n",
        "train_dataset = TextToSQLDataset(train_dataset, tokenizer)\n",
        "\n",
        "\n",
        "#Minimum: Start with at least 2000-3000 samples.\n",
        "#This should be enough to provide a good initial assessment of your model's performance and potential.\n",
        "\n",
        "#Medium: If your computational resources allow, try 5000-7000 samples.\n",
        "#This could provide a more robust evaluation and potentially lead to better performance.\n",
        "\n",
        "#Maximum: If you have ample resources, consider using the entire dataset (around 10,000 samples).\n",
        "#This would give you the most comprehensive training data possible and potentially lead\n",
        "#to the best model performance.\n",
        "\n",
        "\n",
        "\n",
        "POC_valsample=1\n",
        "eval_dataset = eval_dataset.select(np.random.choice(len(eval_dataset), POC_valsample, replace=False))\n",
        "test_dataset = test_dataset.select(np.random.choice(len(test_dataset), POC_valsample, replace=False))\n",
        "\n",
        "eval_dataset = TextToSQLDataset(eval_dataset, tokenizer)\n",
        "test_dataset = TextToSQLDataset(test_dataset, tokenizer)\n",
        "\n",
        "# Create DataLoader (no collate_fn needed)\n",
        "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 4. GAT Layer and GraphModel\n",
        "class GATLayer(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features, num_heads=8, num_layers=1):\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.gat = GAT(in_channels=in_features, hidden_channels=out_features, heads=num_heads,\n",
        "                        concat=False, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.gat(x, edge_index)\n",
        "\n",
        "    # Make the internal linear layers accessible\n",
        "    def get_lora_target_modules(self):\n",
        "        # Access the linear layers within the GAT convolutions\n",
        "        return [module for module in self.gat.modules() if isinstance(module, torch.nn.Linear)]\n",
        "\n",
        "\n",
        "#  GraphModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "\n",
        "#from transformers import CausalLMOutputWithPast\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "@dataclass\n",
        "class MyCausalLMOutputWithPast:\n",
        "    loss: Optional[torch.FloatTensor] = None\n",
        "    logits: torch.FloatTensor = None\n",
        "    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
        "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
        "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
        "\n",
        "\n",
        "class GraphModel(nn.Module):\n",
        "    def __init__(self, encoder, tokenizer):\n",
        "        super(GraphModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.config = encoder.model.config\n",
        "        self.gatv2 = GATv2Conv(\n",
        "            in_channels=self.config.hidden_size,\n",
        "            out_channels=self.config.hidden_size,\n",
        "            heads=8,\n",
        "            concat=False,\n",
        "        )\n",
        "\n",
        "        # Max Pooling\n",
        "        self.pool = lambda x, batch: torch.max(x, dim=0, keepdim=True)[0]\n",
        "\n",
        "        # Additional Feedforward Layer\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(self.config.hidden_size, self.config.hidden_size * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.config.hidden_size * 2, self.config.hidden_size),\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(self.config.hidden_size, self.config.vocab_size)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Add generation config (you might need to adjust this based on your specific needs)\n",
        "        self.generation_config = encoder.generation_config\n",
        "\n",
        "    # Forward Pass\n",
        "    def forward(self, input_ids, attention_mask, edges, labels=None, inputs_embeds=None, sample_ids=None, output_attentions=False, output_hidden_states=False, return_dict=False):\n",
        "\n",
        "\n",
        "\n",
        "        # Print vocabulary sizes\n",
        "        #print('\\n')\n",
        "        #print(\"Mistral Model Vocab Size:\", self.encoder.config.vocab_size)\n",
        "        #print(\"Tokenizer Vocab Size:\", self.tokenizer.vocab_size)\n",
        "        #print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "        # 1. Token Embeddings (Encoder)\n",
        "        if input_ids is not None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids.to(self.encoder.model.device),\n",
        "                attention_mask=attention_mask.to(self.encoder.model.device),\n",
        "                output_hidden_states=True\n",
        "            )\n",
        "            embeddings = encoder_outputs.hidden_states[-1]\n",
        "        elif inputs_embeds is not None:\n",
        "            embeddings = inputs_embeds\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        # Ensure correct shape for GATv2Conv\n",
        "        if embeddings.dim() > 2:\n",
        "            embeddings = embeddings.view(-1, embeddings.shape[-1])\n",
        "\n",
        "        # 2. Edge Index Creation (Batched, with Enhanced Error Handling)\n",
        "        edge_index = []\n",
        "        node_offset = 0\n",
        "        for i, graph_edges in enumerate(edges):\n",
        "            if graph_edges is None or graph_edges.numel() == 0:  # Check if graph_edges is None or empty\n",
        "                num_nodes = input_ids.size(1)\n",
        "                # Create self-loops for isolated nodes if no edges are provided\n",
        "                graph_edges = torch.arange(node_offset, node_offset + num_nodes, device=embeddings.device)\n",
        "                graph_edges = graph_edges.repeat(2, 1) # Repeat the tensor, not the arange object\n",
        "            else: # Add this else block to handle the case when edges are present\n",
        "                # Ensure graph_edges is a tensor before adding offset\n",
        "                if not isinstance(graph_edges, torch.Tensor):\n",
        "                    graph_edges = torch.tensor(graph_edges, dtype=torch.long, device=embeddings.device)\n",
        "                graph_edges += node_offset  # Now safe to add offset\n",
        "            edge_index.append(graph_edges)\n",
        "            node_offset += input_ids.size(1)\n",
        "        edge_index = torch.cat(edge_index, dim=1)\n",
        "\n",
        "        # 3. GATv2 Layer\n",
        "        graph_out = self.gatv2(embeddings, edge_index)\n",
        "\n",
        "        # 4. Pooling (using max pooling)\n",
        "        batch = torch.arange(len(edges), device=graph_out.device).repeat_interleave(input_ids.size(1))\n",
        "        pooled = self.pool(graph_out, batch).unsqueeze(1)\n",
        "\n",
        "        # Additional Feedforward Layer\n",
        "        pooled = self.ffn(pooled)\n",
        "\n",
        "        # 5. LM Head\n",
        "        logits = self.lm_head(pooled)\n",
        "\n",
        "        from torch.nn import CrossEntropyLoss\n",
        "        # 6. Loss Calculation (if labels provided)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "\n",
        "             # Print Sample IDs first\n",
        "            print(f\"\\nIteration/Step: {trainer.state.global_step}\")\n",
        "            mask = (labels != -100).float()\n",
        "\n",
        "            #for i, sample_id in enumerate(sample_ids):\n",
        "            #    print(f\"Sample ID: {sample_id.item()}\")\n",
        "\n",
        "\n",
        "            # Now decode and print input, target, and loss for each sample\n",
        "            with torch.no_grad():\n",
        "                input_text = self.tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
        "                target_text = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "                for i, sample_id in enumerate(sample_ids):\n",
        "                    print(f\"Sample ID: {sample_id.item()}\")\n",
        "                    print(\"Decoded Input:\", input_text[i])\n",
        "                    print(\"Decoded Target (Labels):\", target_text[i])\n",
        "\n",
        "\n",
        "\n",
        "            # Apply softmax to logits to get probabilities\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Calculate loss\n",
        "            #loss_fct = nn.NLLLoss(ignore_index=-100)  # Use NLLLoss for log probabilities\n",
        "\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "            # Reshape log_probs to match target shape (remove the extra dimension)\n",
        "            log_probs = log_probs.squeeze(1)\n",
        "\n",
        "            #labels = labels[:, 0] ### WORK UNTIL BEFORE THE LAST INTERACTION\n",
        "            #labels = labels.squeeze(1)   # Remove extra dimension from labels ## DON'T work\n",
        "            #labels = labels.view(-1)  # Flatten labels to a 1D tensor DON'T work\n",
        "\n",
        "            labels = labels[:, 0]\n",
        "\n",
        "\n",
        "            loss = loss_fct(log_probs, labels)\n",
        "\n",
        "            #print(f\"Loss mean: {loss.item()}\\n\")\n",
        "\n",
        "            loss_per_sample = (loss * mask).sum(dim=1) / mask.sum(dim=1)\n",
        "            #print(f\"Loss per sample: {loss_per_sample.item()}\")\n",
        "\n",
        "\n",
        "\n",
        "        # 7. Return (Modified to return a tuple)\n",
        "            if labels is not None:\n",
        "                return (loss, logits, None)\n",
        "            else:\n",
        "                return (None, logits, None)\n",
        "\n",
        "        # 7. Return (Modified to consistently return MyCausalLMOutputWithPast)\n",
        "        return MyCausalLMOutputWithPast(\n",
        "            loss=loss,  # Loss will be None during evaluation\n",
        "            logits=logits,\n",
        "            past_key_values=encoder_outputs.past_key_values,\n",
        "            hidden_states=encoder_outputs.hidden_states,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "            #if labels is not None:\n",
        "            #    return (loss, logits, None)\n",
        "            #else:\n",
        "            #    return (None, logits, None)\n",
        "\n",
        "    def prepare_inputs_for_generation(self, input_ids, edges, attention_mask=None, **kwargs):\n",
        "        if isinstance(self, PeftModel):\n",
        "            return self.base_model.prepare_inputs_for_generation(input_ids, edges, attention_mask, **kwargs)\n",
        "\n",
        "        batch_size = input_ids.size(0)\n",
        "        if batch_size > 1:\n",
        "            batched_edges = []\n",
        "            node_offset = 0\n",
        "            for i in range(batch_size):\n",
        "                graph_edges = edges[i]\n",
        "                batched_edges.extend([(src + node_offset, dst + node_offset) for src, dst in graph_edges])\n",
        "                node_offset += input_ids.size(1)\n",
        "            edge_index = torch.tensor(batched_edges, dtype=torch.long).t().contiguous().to(input_ids.device)\n",
        "        else:\n",
        "            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(input_ids.device)\n",
        "\n",
        "        model_inputs = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"edges\": edge_index,\n",
        "            \"past_key_values\": kwargs.get(\"past_key_values\", None),\n",
        "        }\n",
        "        return model_inputs\n",
        "\n",
        "# END GraphModel\n",
        "\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "#del model\n",
        "# Quantize Mistral (before creating GraphModel)\n",
        "mistral_model = prepare_model_for_kbit_training(mistral_model, use_gradient_checkpointing=True)\n",
        "\n",
        "\n",
        "# 5. Model Setup (Define model first)\n",
        "model = GraphModel(mistral_model, tokenizer)  # Pass both mistral_model and tokenizer\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# 6. PEFT Configuration (Use automatic module discovery)\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    #target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\n",
        "        \"gat.gat.convs.0.lin_l\",\n",
        "        \"gat.gat.convs.0.lin_r\",\n",
        "        \"gat.gat.convs.1.lin_l\",\n",
        "        \"gat.gat.convs.1.lin_r\",\n",
        "        \"lm_head\"\n",
        "    ]\n",
        "    #task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "\n",
        "# 7. Apply PEFT\n",
        "model = get_peft_model(model, peft_config)\n",
        "print('\\n\\n')\n",
        "print('PEFT-Model')\n",
        "model.print_trainable_parameters() # To see the trainable parameters\n",
        "print('\\n')\n",
        "\n",
        "# Access the config of the encoder (Mistral model) within your GraphModel\n",
        "model.encoder.config.use_cache = False\n",
        "model.encoder.gradient_checkpointing_enable()  # Enable gradient checkpointing for memory optimization on the Mistral model\n",
        "#model.encoder.model.embed_tokens.requires_grad_(True)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 8. Evaluation Metric (Semantic Similarity)\n",
        "metric = evaluate.load(\"exact_match\")\n",
        "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    all_preds, all_labels = eval_pred\n",
        "\n",
        "    # Convert all elements to tensors, handling different data types\n",
        "    predictions = [torch.tensor(pred) if not isinstance(pred, torch.Tensor) else pred for pred in all_preds]\n",
        "    labels = [torch.tensor(label) if not isinstance(label, torch.Tensor) else label for label in all_labels]\n",
        "\n",
        "    # Filter out any None values before stacking\n",
        "    predictions = [pred for pred in predictions if pred is not None]\n",
        "    labels = [label for label in labels if label is not None]\n",
        "\n",
        "    # Convert to tensors and stack (only if there are predictions/labels)\n",
        "    if predictions:\n",
        "        predictions = torch.stack(predictions).squeeze()\n",
        "    else:\n",
        "        predictions = torch.tensor([])  # Empty tensor if no predictions\n",
        "\n",
        "    if labels:\n",
        "        labels = torch.stack(labels).squeeze()\n",
        "    else:\n",
        "        labels = torch.tensor([])  # Empty tensor if no labels\n",
        "\n",
        "    # Handle cases where only one prediction/label is present (avoid squeezing to a scalar)\n",
        "    if predictions.dim() == 0:\n",
        "        predictions = predictions.unsqueeze(0)\n",
        "    if labels.dim() == 0:\n",
        "        labels = labels.unsqueeze(0)\n",
        "\n",
        "    # Print shapes for debugging\n",
        "    #print('\\n')\n",
        "    #print(f\"Shape of logits in compute_metrics: {predictions.shape}\")\n",
        "    #print(f\"Shape of labels in compute_metrics: {labels.shape}\")\n",
        "    #('\\n')\n",
        "\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    em = metric.compute(predictions=decoded_preds, references=decoded_labels)[\"exact_match\"]\n",
        "\n",
        "    return {\"exact_match\": em}\n",
        "\n",
        "\n",
        "#/content/gdrive/MyDrive/model\n",
        "\n",
        "# 9. Training Arguments and Trainer\n",
        "training_args = TrainingArguments(\n",
        "    \"/content/gdrive/MyDrive/model/GNNPOC-T2SQL\",\n",
        "    logging_dir=\"/content/gdrive/MyDrive/model/GNNPOC-T2SQL\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=1,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    push_to_hub=False,\n",
        "    dataloader_pin_memory=False,\n",
        "    load_best_model_at_end=True,\n",
        "    #gradient_checkpointing=False,\n",
        "    use_legacy_prediction_loop=False,\n",
        "    metric_for_best_model=\"eval_exact_match\",\n",
        "    report_to=\"tensorboard\",\n",
        "    #generation_max_length=2048, # Add this line to increase the generation max length\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch_geometric.data import Batch as GraphBatch  # Note the import\n",
        "import torch\n",
        "import torch_geometric.data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class GraphDataCollatorForSeq2Seq:\n",
        "    def __init__(self, tokenizer, model=None, label_pad_token_id=-100, pad_to_multiple_of=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.label_pad_token_id = label_pad_token_id\n",
        "        self.pad_to_multiple_of = pad_to_multiple_of\n",
        "\n",
        "    def __call__(self, features):\n",
        "        # Separate standard features from graph edges\n",
        "        # Extract labels before padding and handle potentially empty sequences\n",
        "        labels = [feature[\"labels\"] if feature[\"labels\"].numel() > 0\n",
        "                  else torch.tensor([self.label_pad_token_id], dtype=torch.long)\n",
        "                  for feature in features]\n",
        "\n",
        "        # Extract sample_ids\n",
        "        sample_ids = [feature[\"sample_ids\"] for feature in features]\n",
        "\n",
        "        standard_features = [{k: v for k, v in feature.items() if k != \"edges\" and k != \"labels\"} for feature in features]\n",
        "        edges = [feature[\"edges\"] for feature in features]\n",
        "\n",
        "        # Collate standard features (input_ids, attention_mask) using default collator\n",
        "        collated_standard_features =  DataCollatorForSeq2Seq(\n",
        "            tokenizer=self.tokenizer,\n",
        "            model=self.model,\n",
        "            label_pad_token_id=self.label_pad_token_id,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of\n",
        "        )(standard_features)\n",
        "\n",
        "        # Pad input_ids and attention_mask\n",
        "        input_ids = pad_sequence([f['input_ids'] for f in standard_features], batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "        attention_mask = pad_sequence([f['attention_mask'] for f in standard_features], batch_first=True, padding_value=0)\n",
        "\n",
        "         # Pad labels separately\n",
        "        labels = pad_sequence(labels, batch_first=True, padding_value=self.label_pad_token_id)\n",
        "\n",
        "        # Create batch for graph data\n",
        "        graph_data_list = []\n",
        "        for i in range(len(edges)):\n",
        "            # Convert to PyTorch Geometric Data\n",
        "            graph_data_list.append(torch_geometric.data.Data(\n",
        "                x=collated_standard_features['input_ids'][i].unsqueeze(1),  # Node features (input_ids)\n",
        "                edge_index=edges[i],                   # Edge index\n",
        "                # Use num_edges for batch index to ensure correct batching in PyG\n",
        "                batch=torch.tensor([i] * edges[i].size(1))\n",
        "            ))\n",
        "        batched_graph = GraphBatch.from_data_list(graph_data_list)  # Batch graphs\n",
        "\n",
        "        #print(f\"Sample GraphDataCollatorForSeq2Seq ID: {sample_ids}\")\n",
        "\n",
        "         # Include sample_ids in the collated features\n",
        "        collated_features = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"edges\": edges,\n",
        "            \"sample_ids\": sample_ids  # Add sample_ids here\n",
        "        }\n",
        "\n",
        "        return collated_features\n",
        "\n",
        "\n",
        "# 10a.  Data Collator\n",
        "data_collator = GraphDataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8\n",
        ")\n",
        "\n",
        "\n",
        "# 10AA. Training Arguments and Trainer\n",
        "\n",
        "from transformers import Trainer\n",
        "from transformers.trainer_utils import EvalLoopOutput, PredictionOutput,  has_length\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "from transformers.trainer_utils import EvalPrediction\n",
        "from transformers import Trainer, TrainerCallback\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "#from transformers.trainer_pt_utils import nested_truncate  # Updated import#\n",
        "\n",
        "from transformers.trainer_pt_utils import nested_truncate, nested_concat, nested_numpify, nested_detach  # Updated imports\n",
        "\n",
        "\n",
        "######\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from transformers import Trainer\n",
        "from transformers.trainer_utils import EvalPrediction\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def estimated_num_samples(dataloader: DataLoader):\n",
        "    \"\"\"\n",
        "    This function will attempt to determine the number of samples in a DataLoader.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): The DataLoader to estimate the number of samples from.\n",
        "\n",
        "    Returns:\n",
        "        int: The estimated number of samples, or 0 if estimation is not possible.\n",
        "    \"\"\"\n",
        "    if hasattr(dataloader, \"dataset\") and hasattr(dataloader.dataset, \"__len__\"):\n",
        "        return len(dataloader.dataset)  # Use dataset length if available\n",
        "    elif hasattr(dataloader, \"batch_sampler\") and hasattr(dataloader.batch_sampler, \"sampler\") and hasattr(dataloader.batch_sampler.sampler, \"__len__\"):\n",
        "        return len(dataloader.batch_sampler.sampler)  # Use sampler length if available\n",
        "    else:\n",
        "        # If neither is available, return 0\n",
        "        warnings.warn(\"Could not estimate the number of samples in the dataloader. Returning 0.\")\n",
        "        return 0\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    _id=0\n",
        "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "        labels = inputs.pop(\"labels\", None)\n",
        "\n",
        "        print('\\n\\n')\n",
        "        print(\"**** Prediction Step ****\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # Check if loss is present in the outputs\n",
        "            loss = outputs.loss if hasattr(outputs, 'loss') else None\n",
        "            logits = outputs.logits\n",
        "\n",
        "\n",
        "            #loss = outputs.loss\n",
        "            #logits = outputs.logits\n",
        "\n",
        "            # Debugging Logging (ensure labels exist before accessing)\n",
        "            if not prediction_loss_only:\n",
        "                print('\\n\\n')\n",
        "                print(\"Shape of logits in prediction_step:\", logits.shape)\n",
        "                if labels is not None:  # Only print if labels exist\n",
        "                    print(\"Shape of labels in prediction_step:\", labels.shape)\n",
        "\n",
        "            if prediction_loss_only:\n",
        "                if isinstance(loss, torch.Tensor):\n",
        "                    loss = loss.mean().detach()\n",
        "                return (loss, None, None)\n",
        "\n",
        "            max_new_tokens = 1024 - inputs['input_ids'].shape[1]\n",
        "\n",
        "            # Modify this part to handle the generated IDs\n",
        "            if max_new_tokens <= 0:\n",
        "                print('\\n\\n')\n",
        "                print(\"No new tokens to generate. An increase in the sample size for training is required. \")\n",
        "                #print(\"#TOKENS: \",max_new_tokens)\n",
        "                # Input is already at max length, no need to generate\n",
        "                generated_ids = inputs['input_ids']\n",
        "            else:\n",
        "                generated_ids = model.encoder.generate(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    attention_mask=inputs['attention_mask'],\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    num_beams=5\n",
        "                )\n",
        "\n",
        "            # Flatten the generated_ids to a 1D list before decoding\n",
        "            flattened_generated_ids = generated_ids.view(-1).tolist()\n",
        "            predictions=generated_ids\n",
        "\n",
        "            # Now decode using the flattened list\n",
        "            predictions_decoder = self.tokenizer.decode(flattened_generated_ids, skip_special_tokens=True)\n",
        "            Q = self.tokenizer.decode(inputs['input_ids'].view(-1).tolist(), skip_special_tokens=True)\n",
        "            A = self.tokenizer.decode(labels.view(-1).tolist(), skip_special_tokens=True)\n",
        "            #print(\"Sample IDs in prediction_step:\", inputs['sample_ids'][0])\n",
        "\n",
        "\n",
        "            # Debugging Logging\n",
        "            #print(\"Shape of predictions in prediction_step:\", predictions.shape)\n",
        "            if labels is not None:\n",
        "                print('\\n\\n')\n",
        "                # Extract sample_ids\n",
        "                sample_ids = int(self._id)+1  # Use self._id here\n",
        "                #print(\"Sample IDs in prediction_step:\", sample_ids)\n",
        "                print(\"Sample IDs in prediction_step:\", inputs['sample_ids'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                print(\"Question:\", Q)\n",
        "                print(\"Decoded Original Answer BEFORE Predictions:\", A)\n",
        "                print('\\n\\n')\n",
        "\n",
        "                print(\"Decoded Predictions:\", predictions_decoder)\n",
        "                #print(\"Decoded Labels:\", labels_decoder)\n",
        "\n",
        "\n",
        "\n",
        "            return (loss, predictions, labels)\n",
        "\n",
        "    def _prediction_loop(self, dataloader: DataLoader, description: str, prediction_loss_only: Optional[bool] = None, ignore_keys: Optional[List[str]] = None, metric_key_prefix: str = \"eval\") -> Union[Tuple[torch.Tensor, torch.Tensor], EvalPrediction]:\n",
        "\n",
        "        # ... other parts remain same ...\n",
        "\n",
        "         # In case you have a callback that needs length eventually\n",
        "        if has_length(dataloader):\n",
        "            num_samples = len(dataloader.dataset)\n",
        "        # The dataset does not support __len__, estimate the number of samples.\n",
        "        else:\n",
        "            num_samples = estimated_num_samples(dataloader)\n",
        "\n",
        "        # Number of losses has been rounded to a multiple of batch_size and in a distributed training, the number of\n",
        "        # samplers has been rounded to a multiple of batch_size, so we truncate.\n",
        "        if all_losses:\n",
        "            all_losses = all_losses[:num_samples]\n",
        "        if all_preds:\n",
        "            all_preds = nested_truncate(all_preds, num_samples)\n",
        "        if all_labels:\n",
        "            all_labels = nested_truncate(all_labels, num_samples)\n",
        "\n",
        "        # 8.  Compute Metrics and Average Loss\n",
        "        metrics = self.compute_metrics((all_preds, all_labels))\n",
        "        average_loss = torch.mean(torch.stack(all_losses))\n",
        "        metrics[f\"{metric_key_prefix}_loss\"] = average_loss.item()\n",
        "\n",
        "        # 9.  Log the Metrics\n",
        "        self.log(metrics)\n",
        "\n",
        "        # 10. Return Based on Whether It's a Prediction or Evaluation\n",
        "        if prediction_loss_only:\n",
        "            return (metrics, None, None)\n",
        "\n",
        "        return EvalPrediction(predictions=all_preds, label_ids=all_labels, metrics=metrics)\n",
        "\n",
        "\n",
        "    def predict(self, test_dataset: Dataset, ignore_keys: Optional[List[str]] = None) -> PredictionOutput:\n",
        "        test_dataloader = self.get_test_dataloader(test_dataset)\n",
        "        return self.prediction_loop(test_dataloader, description=\"Prediction\")\n",
        "\n",
        "    def evaluate(\n",
        "        self,\n",
        "        eval_dataset: Optional[Dataset] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> Dict[str, float]:\n",
        "        # ... (existing code in Trainer.evaluate)\n",
        "\n",
        "        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
        "        output = self.prediction_loop(\n",
        "            eval_dataloader,\n",
        "            description=\"Evaluation\",\n",
        "            # ...\n",
        "        )\n",
        "\n",
        "        # ... (rest of the existing code)\n",
        "\n",
        "        return output.metrics\n",
        "\n",
        "\n",
        "######\n",
        "\n",
        "# 10A. Trainer (Modified)\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")\n",
        "\n",
        "\n",
        "from transformers import TrainerCallback\n",
        "class LossLoggingCallback(TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step % 50000 == 0:  # Log every 100 steps (adjust as needed)\n",
        "            print(f\"Step {state.global_step} - Loss: {state.loss}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 11. Train the model\n",
        "\n",
        "# Add the Callback to the Trainer\n",
        "trainer.add_callback(LossLoggingCallback())\n",
        "\n",
        "# Add the Early Stopping to the Trainer\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "# 12. Evaluate on the test set\n",
        "#test_results = trainer.evaluate(eval_dataset)\n",
        "#print('\\n\\n')\n",
        "#print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')\n",
        "#print(f'Test Exact Match. (Evaluate on the test set): {test_results[\"eval_exact_match\"]:.4f}')\n",
        "#print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATION-TRAINER"
      ],
      "metadata": {
        "id": "jnxGtqh44nh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Prepare Data\n",
        "dataset = load_dataset(\"b-mc2/sql-create-context\")[\"train\"].shuffle(seed=42)\n",
        "\n",
        "# Manually define splits\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
        "test_dataset = dataset.select(range(train_size + val_size, len(dataset)))\n",
        "\n",
        "\n",
        "POC_valsample=100\n",
        "val_dataset = val_dataset.select(np.random.choice(len(val_dataset), POC_valsample, replace=False))\n",
        "test_dataset = test_dataset.select(np.random.choice(len(test_dataset), POC_valsample, replace=False))\n",
        "\n",
        "\n",
        "val_dataset = TextToSQLDataset(val_dataset, tokenizer)\n",
        "test_dataset = TextToSQLDataset(test_dataset, tokenizer)\n",
        "\n",
        "\n",
        "# 13. Evaluate on the test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print('\\n\\n')\n",
        "#print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')\n",
        "print(f'Test Exact Match. (Evaluate on the test set): {test_results[\"eval_exact_match\"]:.4f}')\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "id": "sgzKGUeY2Yxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATION STAND-ALONE\n"
      ],
      "metadata": {
        "id": "2hAPAwznG6Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM, AutoTokenizer,\n",
        "    BitsAndBytesConfig, Trainer, TrainingArguments,\n",
        "    set_seed,\n",
        "    EarlyStoppingCallback,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    TaskType,\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        "    PrefixTuningConfig,\n",
        "    PromptEncoderConfig,\n",
        "    TaskType\n",
        ")\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torch_geometric.nn import GAT\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import evaluate\n",
        "\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"The installed version of bitsandbytes was compiled without GPU support.\")\n",
        "\n",
        "\n",
        "# Load spaCy English model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    # Download if not already downloaded\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "ENHJRQaU91v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  GraphModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "\n",
        "#from transformers import CausalLMOutputWithPast\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "@dataclass\n",
        "class MyCausalLMOutputWithPast:\n",
        "    loss: Optional[torch.FloatTensor] = None\n",
        "    logits: torch.FloatTensor = None\n",
        "    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
        "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
        "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
        "\n",
        "\n",
        "class GraphModel(nn.Module):\n",
        "    def __init__(self, encoder, tokenizer):\n",
        "        super(GraphModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.config = encoder.model.config\n",
        "        self.gatv2 = GATv2Conv(\n",
        "            in_channels=self.config.hidden_size,\n",
        "            out_channels=self.config.hidden_size,\n",
        "            heads=8,\n",
        "            concat=False,\n",
        "        )\n",
        "\n",
        "        # Max Pooling\n",
        "        self.pool = lambda x, batch: torch.max(x, dim=0, keepdim=True)[0]\n",
        "\n",
        "        # Additional Feedforward Layer\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(self.config.hidden_size, self.config.hidden_size * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.config.hidden_size * 2, self.config.hidden_size),\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(self.config.hidden_size, self.config.vocab_size)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Add generation config (you might need to adjust this based on your specific needs)\n",
        "        self.generation_config = encoder.generation_config\n",
        "\n",
        "    # Forward Pass\n",
        "    #def forward(self, input_ids, attention_mask, edges, labels=None, inputs_embeds=None, sample_ids=None, output_attentions=False, output_hidden_states=False, return_dict=False):\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, edges, labels=None, inputs_embeds=None, sample_ids=None,\n",
        "                output_attentions=None, output_hidden_states=None, return_dict=None):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Print vocabulary sizes\n",
        "        #print('\\n')\n",
        "        #print(\"Mistral Model Vocab Size:\", self.encoder.config.vocab_size)\n",
        "        #print(\"Tokenizer Vocab Size:\", self.tokenizer.vocab_size)\n",
        "        #print('\\n')\n",
        "\n",
        "\n",
        "        # 1. Token Embeddings (Encoder)\n",
        "        if input_ids is not None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids.to(self.encoder.model.device),\n",
        "                attention_mask=attention_mask.to(self.encoder.model.device),\n",
        "                #output_hidden_states=True\n",
        "            )\n",
        "            embeddings = encoder_outputs.hidden_states[-1]\n",
        "            print(\"Encoder output shape:\", embeddings.shape)  # Inspect encoder output\n",
        "\n",
        "        elif inputs_embeds is not None:\n",
        "            embeddings = inputs_embeds\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        # Ensure correct shape for GATv2Conv\n",
        "        if embeddings.dim() > 2:\n",
        "            embeddings = embeddings.view(-1, embeddings.shape[-1])\n",
        "\n",
        "        # 2. Edge Index Creation (Batched, with Enhanced Error Handling)\n",
        "        edge_index = []\n",
        "        node_offset = 0\n",
        "        for i, graph_edges in enumerate(edges):\n",
        "            if graph_edges is None or graph_edges.numel() == 0:  # Check if graph_edges is None or empty\n",
        "                num_nodes = input_ids.size(1)\n",
        "                # Create self-loops for isolated nodes if no edges are provided\n",
        "                graph_edges = torch.arange(node_offset, node_offset + num_nodes, device=embeddings.device)\n",
        "                graph_edges = graph_edges.repeat(2, 1) # Repeat the tensor, not the arange object\n",
        "            else: # Add this else block to handle the case when edges are present\n",
        "                # Ensure graph_edges is a tensor before adding offset\n",
        "                if not isinstance(graph_edges, torch.Tensor):\n",
        "                    graph_edges = torch.tensor(graph_edges, dtype=torch.long, device=embeddings.device)\n",
        "                graph_edges += node_offset  # Now safe to add offset\n",
        "            edge_index.append(graph_edges)\n",
        "            node_offset += input_ids.size(1)\n",
        "        edge_index = torch.cat(edge_index, dim=1)\n",
        "\n",
        "        # 3. GATv2 Layer\n",
        "        graph_out = self.gatv2(embeddings, edge_index)\n",
        "\n",
        "        # 3. GATv2 Layer\n",
        "        graph_out = self.gatv2(embeddings, edge_index)\n",
        "        print(\"GATv2 output shape:\", graph_out.shape)  # Inspect GATv2 output\n",
        "\n",
        "        # Print logits before and after applying logits processor\n",
        "        print(\"Original logits:\", logits)\n",
        "        filtered_logits = logits_processor(None, logits)\n",
        "        print(\"Filtered logits:\", filtered_logits)\n",
        "\n",
        "\n",
        "        # 4. Pooling (using max pooling)\n",
        "        batch = torch.arange(len(edges), device=graph_out.device).repeat_interleave(input_ids.size(1))\n",
        "        pooled = self.pool(graph_out, batch).unsqueeze(1)\n",
        "\n",
        "        # Additional Feedforward Layer\n",
        "        pooled = self.ffn(pooled)\n",
        "\n",
        "        # 5. LM Head\n",
        "        logits = self.lm_head(pooled)\n",
        "\n",
        "        from torch.nn import CrossEntropyLoss\n",
        "        # 6. Loss Calculation (if labels provided)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "\n",
        "             # Print Sample IDs first\n",
        "            print(f\"\\nIteration/Step: {trainer.state.global_step}\")\n",
        "            mask = (labels != -100).float()\n",
        "\n",
        "            #for i, sample_id in enumerate(sample_ids):\n",
        "            #    print(f\"Sample ID: {sample_id.item()}\")\n",
        "\n",
        "\n",
        "            # Now decode and print input, target, and loss for each sample\n",
        "            with torch.no_grad():\n",
        "                input_text = self.tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
        "                target_text = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "                for i, sample_id in enumerate(sample_ids):\n",
        "                    print(f\"Sample ID: {sample_id.item()}\")\n",
        "                    print(\"Decoded Input:\", input_text[i])\n",
        "                    print(\"Decoded Target (Labels):\", target_text[i])\n",
        "\n",
        "\n",
        "\n",
        "            # Apply softmax to logits to get probabilities\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Calculate loss\n",
        "            #loss_fct = nn.NLLLoss(ignore_index=-100)  # Use NLLLoss for log probabilities\n",
        "\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "            # Reshape log_probs to match target shape (remove the extra dimension)\n",
        "            log_probs = log_probs.squeeze(1)\n",
        "\n",
        "\n",
        "            #labels = labels[:, 0] ### WORK UNTIL BEFORE THE LAST INTERACTION\n",
        "            #labels = labels.squeeze(1)   # Remove extra dimension from labels ## DON'T work\n",
        "            #labels = labels.view(-1)  # Flatten labels to a 1D tensor DON'T work\n",
        "\n",
        "            labels = labels[:, 0]\n",
        "\n",
        "            # Calculate loss with the correctly shaped labels\n",
        "            #loss = loss_fct(log_probs, labels[:, 0])  # Access the first element of each label sequence\n",
        "\n",
        "\n",
        "            loss = loss_fct(log_probs, labels)\n",
        "\n",
        "\n",
        "\n",
        "            loss_per_sample = (loss * mask).sum(dim=1) / mask.sum(dim=1)\n",
        "            print(f\"Loss per sample: {loss_per_sample.item()}\")\n",
        "\n",
        "\n",
        "        # 7. Return (Modified to return a tuple)\n",
        "            if labels is not None:\n",
        "                return (loss, logits, None)\n",
        "            else:\n",
        "                return (None, logits, None)\n",
        "\n",
        "        return MyCausalLMOutputWithPast(\n",
        "                loss=loss,\n",
        "                logits=logits,\n",
        "                past_key_values=encoder_outputs.past_key_values,\n",
        "                hidden_states=encoder_outputs.hidden_states,\n",
        "                attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "    def prepare_inputs_for_generation(self, input_ids, edges, attention_mask=None, **kwargs):\n",
        "        if isinstance(self, PeftModel):\n",
        "            return self.base_model.prepare_inputs_for_generation(input_ids, edges, attention_mask, **kwargs)\n",
        "\n",
        "        batch_size = input_ids.size(0)\n",
        "        if batch_size > 1:\n",
        "            batched_edges = []\n",
        "            node_offset = 0\n",
        "            for i in range(batch_size):\n",
        "                graph_edges = edges[i]\n",
        "                batched_edges.extend([(src + node_offset, dst + node_offset) for src, dst in graph_edges])\n",
        "                node_offset += input_ids.size(1)\n",
        "            edge_index = torch.tensor(batched_edges, dtype=torch.long).t().contiguous().to(input_ids.device)\n",
        "        else:\n",
        "            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(input_ids.device)\n",
        "\n",
        "        model_inputs = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"edges\": edge_index,\n",
        "            \"past_key_values\": kwargs.get(\"past_key_values\", None),\n",
        "        }\n",
        "        return model_inputs\n",
        "\n",
        "# END GraphModel"
      ],
      "metadata": {
        "id": "BTT38RlOEhYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch_geometric.data import Batch as GraphBatch  # Note the import\n",
        "import torch\n",
        "import torch_geometric.data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class GraphDataCollatorForSeq2Seq:\n",
        "    def __init__(self, tokenizer, model=None, label_pad_token_id=-100, pad_to_multiple_of=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.label_pad_token_id = label_pad_token_id\n",
        "        self.pad_to_multiple_of = pad_to_multiple_of\n",
        "\n",
        "    def __call__(self, features):\n",
        "        # Separate standard features from graph edges\n",
        "        # Extract labels before padding and handle potentially empty sequences\n",
        "        labels = [feature[\"labels\"] if feature[\"labels\"].numel() > 0\n",
        "                  else torch.tensor([self.label_pad_token_id], dtype=torch.long)\n",
        "                  for feature in features]\n",
        "\n",
        "        # Extract sample_ids\n",
        "        sample_ids = [feature[\"sample_ids\"] for feature in features]\n",
        "\n",
        "        standard_features = [{k: v for k, v in feature.items() if k != \"edges\" and k != \"labels\"} for feature in features]\n",
        "        edges = [feature[\"edges\"] for feature in features]\n",
        "\n",
        "        # Collate standard features (input_ids, attention_mask) using default collator\n",
        "        collated_standard_features =  DataCollatorForSeq2Seq(\n",
        "            tokenizer=self.tokenizer,\n",
        "            model=self.model,\n",
        "            label_pad_token_id=self.label_pad_token_id,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of\n",
        "        )(standard_features)\n",
        "\n",
        "        # Pad input_ids and attention_mask\n",
        "        input_ids = pad_sequence([f['input_ids'] for f in standard_features], batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "        attention_mask = pad_sequence([f['attention_mask'] for f in standard_features], batch_first=True, padding_value=0)\n",
        "\n",
        "         # Pad labels separately\n",
        "        labels = pad_sequence(labels, batch_first=True, padding_value=self.label_pad_token_id)\n",
        "\n",
        "        # Create batch for graph data\n",
        "        graph_data_list = []\n",
        "        for i in range(len(edges)):\n",
        "            # Convert to PyTorch Geometric Data\n",
        "            graph_data_list.append(torch_geometric.data.Data(\n",
        "                x=collated_standard_features['input_ids'][i].unsqueeze(1),  # Node features (input_ids)\n",
        "                edge_index=edges[i],                   # Edge index\n",
        "                # Use num_edges for batch index to ensure correct batching in PyG\n",
        "                batch=torch.tensor([i] * edges[i].size(1))\n",
        "            ))\n",
        "        batched_graph = GraphBatch.from_data_list(graph_data_list)  # Batch graphs\n",
        "\n",
        "        #sample_ids = torch.arange(len(edges)).unsqueeze(1)\n",
        "        #sample_ids = [f[\"sample_id\"] for f in  collated_standard_features]\n",
        "        #sample_ids = [f[\"sample_id\"] for f in features]\n",
        "\n",
        "        #print(f\"Sample GraphDataCollatorForSeq2Seq ID: {sample_ids}\")\n",
        "\n",
        "\n",
        "\n",
        "         # Include sample_ids in the collated features\n",
        "        collated_features = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"edges\": edges,\n",
        "            \"sample_ids\": sample_ids  # Add sample_ids here\n",
        "        }\n",
        "\n",
        "        return collated_features\n"
      ],
      "metadata": {
        "id": "g9qhWPQiQBPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mistral Model and Tokenizer\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Model Configuration\n",
        "config = AutoModelForCausalLM.from_pretrained(model_id).config\n",
        "config.output_hidden_states = True\n",
        "config.use_cache = False\n",
        "#config.torch_dtype = torch.float32\n",
        "config.torch_dtype = torch.bfloat16\n",
        "\n",
        "# Load Model with Quantization\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    attn_implementation=\"flash_attention_2\",  # Optimization\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "75d839b3481c448a8bef168349810a30",
            "e937ccc2b41a454b875de8a81198df9d",
            "fd9dedcf1e4b479ebe681a756f862033",
            "5ef7a83429a84fa394274f80e4518a44",
            "1027cd6bb9544e07a32a6eab6d30b615",
            "11e2a2aa92ae4857bcf55abe15077e70",
            "3857c33fb765437e9dba580c1f2a89bb",
            "ab703f17a4644118aad7a05f99f12d61",
            "9adccca3e26443d2a2a6af76c1b3a468",
            "d5d8427671e44955bace6360233f8690",
            "6737b23112fb4af4babc7e4c4e8db30d",
            "349d950c5a674b4b9d1f33538e2397ac",
            "14ea5188d67f4f27a4e3b31fccb8d53e",
            "edd269889dd7430dadf978bfaffcaf0a",
            "d0d7d09522fb43dcaf995fc2d616aaa3",
            "9ce577369e7140779053fb441cf240d4",
            "979b80aebfd54e33ac040511aaea8dda",
            "a711099cb38c4ac89f7f93aee77abae5",
            "3163a793a4004f29bd76c07dab136f42",
            "f7f1d95449a043aeaea6f887198a6702",
            "b89fa6970e03446485bf0209e72f2fb4",
            "592e1d10f9bd4a999065f9c955711069"
          ]
        },
        "id": "DrXB9McwDzmh",
        "outputId": "e888aa3b-28c8-4e33-afe1-b582e3b50674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75d839b3481c448a8bef168349810a30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "349d950c5a674b4b9d1f33538e2397ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToSQLDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "\n",
        "\n",
        "        text = item['question']\n",
        "        target_text = item['answer']\n",
        "\n",
        "\n",
        "        # 1. Tokenization (with padding and truncation)\n",
        "        tokenized_input = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=1024,  # Increase as needed\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokenized_target = self.tokenizer(\n",
        "            target_text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=1024,  # Increase as needed\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Flatten lists (if needed)\n",
        "        tokenized_input = {k: v.squeeze(0) for k, v in tokenized_input.items()}\n",
        "        tokenized_target = {k: v.squeeze(0) for k, v in tokenized_target.items()}\n",
        "\n",
        "\n",
        "        # Print input text and target text for debugging\n",
        "        #print('\\n')\n",
        "        #print(f\"Sample ID: {idx}\")\n",
        "        #print(f\"  - Text: {text}\")\n",
        "        #print(f\"  - Target Text: {target_text}\")\n",
        "        #print('\\n')\n",
        "\n",
        "        sample_ids = torch.tensor([idx])  # Create a tensor with the sample ID\n",
        "\n",
        "        # 2. Dependency Parsing for Edge Extraction\n",
        "        doc = nlp(text)\n",
        "        edges = []\n",
        "        for token in doc:\n",
        "            head_i = token.head.i\n",
        "            if 0 <= head_i < len(doc) and token.dep_ != \"ROOT\" and token.i != head_i:\n",
        "                edges.append([token.i, head_i])\n",
        "\n",
        "        # Edge Index Extraction and Validation\n",
        "        edges = item.get(\"edges\", edges)  # If \"edges\" is already present in data, use that\n",
        "\n",
        "        if not edges:  # Handle empty graphs\n",
        "            num_nodes = len(tokenized_input[\"input_ids\"])\n",
        "            edges = [[i, i] for i in range(num_nodes)]  # Self-loops for isolated nodes\n",
        "        else:\n",
        "            max_index = len(tokenized_input[\"input_ids\"]) - 1\n",
        "            edges = [(src, tgt) for src, tgt in edges if 0 <= src <= max_index and 0 <= tgt <= max_index]\n",
        "\n",
        "        # Create edge index tensor\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        # Convert everything to tensors BEFORE padding/truncation\n",
        "        input_ids = tokenized_input[\"input_ids\"].clone().detach()\n",
        "        attention_mask = tokenized_input[\"attention_mask\"].clone().detach()\n",
        "        labels = tokenized_target[\"input_ids\"].clone().detach()\n",
        "\n",
        "        # Handle potentially empty target sequences\n",
        "        if len(labels) == 0:\n",
        "            labels = torch.tensor([self.tokenizer.pad_token_id], dtype=torch.long)  # Create a single-element tensor with pad token\n",
        "\n",
        "        # Padding and Truncation for consistent input shapes\n",
        "        max_length = 1024  # Adjust if needed\n",
        "\n",
        "        # Ensure that ALL tensors are truncated/padded to the SAME max_length\n",
        "        input_ids = input_ids[:max_length]\n",
        "        attention_mask = attention_mask[:max_length]\n",
        "        labels = labels[:max_length]\n",
        "\n",
        "        # Add padding if necessary\n",
        "        if len(input_ids) < max_length:\n",
        "            pad_length = max_length - len(input_ids)\n",
        "            pad_tensor = torch.full((pad_length,), self.tokenizer.pad_token_id)\n",
        "            input_ids = torch.cat((input_ids, pad_tensor))\n",
        "            attention_mask = torch.cat((attention_mask, torch.zeros(pad_length, dtype=torch.long)))\n",
        "\n",
        "        if len(labels) < max_length:\n",
        "            pad_length = max_length - len(labels)\n",
        "            labels = torch.cat((labels, torch.full((pad_length,), -100)))  # Pad labels with -100\n",
        "\n",
        "        # (Optional) Print statements for debugging\n",
        "        #print(\"\\n\")\n",
        "        #print(\"Original text:\", text)\n",
        "        #print(\"Target text:\", target_text)\n",
        "        #print(\"Tokenized input IDs:\", tokenized_input[\"input_ids\"])\n",
        "        #print(\"Tokenized target IDs:\", tokenized_target[\"input_ids\"])\n",
        "        #print(\"Labels:\", labels)\n",
        "        #print(\"Edge index:\", edge_index)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"edges\": edge_index,\n",
        "            \"sample_ids\": torch.tensor([idx]),  # Add sample_id here\n",
        "        }"
      ],
      "metadata": {
        "id": "vhh1m2r_DYbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Load and Prepare Data\n",
        "dataset = load_dataset(\"b-mc2/sql-create-context\")[\"train\"].shuffle(seed=42)\n",
        "\n",
        "# Manually define splits\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "eval_dataset = dataset.select(range(train_size, train_size + val_size))\n",
        "test_dataset = dataset.select(range(train_size + val_size, len(dataset)))\n",
        "\n",
        "\n",
        "POC_valsample=2\n",
        "eval_dataset = eval_dataset.select(np.random.choice(len(eval_dataset), POC_valsample, replace=False))\n",
        "test_dataset = test_dataset.select(np.random.choice(len(test_dataset), POC_valsample, replace=False))\n",
        "\n",
        "\n",
        "\n",
        "eval_dataset = TextToSQLDataset(eval_dataset, tokenizer)\n",
        "test_dataset = TextToSQLDataset(test_dataset, tokenizer)"
      ],
      "metadata": {
        "id": "QCe75mw-5mkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = dataset.select(range(train_size, train_size + val_size))\n",
        "eval_dataset = TextToSQLDataset(eval_dataset, tokenizer)\n",
        "eval_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCiF95oQG_Bc",
        "outputId": "058ccb3b-9781-4543-b8ce-a4e14f6ce492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    2,     2,     2,  ..., 29538, 29550, 29572]),\n",
              " 'attention_mask': tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
              " 'labels': tensor([    2,     2,     2,  ..., 29550, 29538, 29550]),\n",
              " 'edges': tensor([[ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
              "         [ 1,  5,  5,  5,  1,  8,  8,  5,  8,  8, 12,  8, 15, 15, 12, 12]]),\n",
              " 'sample_ids': tensor([0])}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ORIGINAL"
      ],
      "metadata": {
        "id": "9QB1kXab0rHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from peft import PeftModel\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset, device=None, edges=None):\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = GraphModel(mistral_model, tokenizer)\n",
        "    #print(model)\n",
        "\n",
        "    model = PeftModel.from_pretrained(model, model_path, is_trainable=False)\n",
        "    #print('\\n')\n",
        "    #print(model)\n",
        "    #print('\\n')\n",
        "\n",
        "    model.to(device)\n",
        "    model.float()\n",
        "\n",
        "    metric = evaluate.load(\"exact_match\")\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    model.eval()\n",
        "    model.encoder.eval()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(eval_dataset)), desc=\"Evaluating\"):\n",
        "            data = eval_dataset[i]\n",
        "\n",
        "            Q = data['input_ids']\n",
        "            A = data['labels']\n",
        "\n",
        "            print('\\n\\n')\n",
        "            print(f\"Sample ID: {i}\")\n",
        "            print(f\"  - Text: {tokenizer.decode(Q, skip_special_tokens=True)}\")\n",
        "            print(f\"  - Target Text: {tokenizer.decode(A, skip_special_tokens=True)}\")\n",
        "            print('\\n')\n",
        "\n",
        "\n",
        "            # Prepare data for the model\n",
        "            input_data = {\n",
        "                \"input_ids\": Q.unsqueeze(0).to(device).long(),\n",
        "                \"attention_mask\": data['attention_mask'].unsqueeze(0).to(device).float()\n",
        "            }\n",
        "\n",
        "            if edges is None:\n",
        "                edges = torch.tensor([[]]).to(device)\n",
        "\n",
        "\n",
        "            # Model inference\n",
        "            model_output = model(**input_data, edges=edges.float())\n",
        "            logits = model_output.logits\n",
        "\n",
        "            if logits.dim() > 2:\n",
        "                logits = logits.squeeze(1)\n",
        "\n",
        "            # Extract predicted tokens\n",
        "            predicted_tokens = logits.argmax(dim=-1).cpu().tolist()\n",
        "\n",
        "\n",
        "            # Print shapes and values for debugging\n",
        "            print(\"\\n\\n\")\n",
        "            #print(\"Model Output:\", model_output)\n",
        "            # Print logits length for debugging\n",
        "            print(\"Logits length:\", logits.shape[1])\n",
        "            print(\"Logits shape:\", logits.shape)\n",
        "            print(\"Logits dtype:\", logits.dtype)\n",
        "            print(\"\\n\")\n",
        "            print(\"Predicted IDs:\", logits.argmax(dim=-1))\n",
        "            print(\"Labels:\", data['labels'])\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Decode predictions and labels for the current sample\n",
        "            decoded_pred = tokenizer.decode(predicted_tokens, skip_special_tokens=True) # Decode for single sample\n",
        "            decoded_label = tokenizer.decode(A.cpu().tolist(), skip_special_tokens=True) # Decode for single sample\n",
        "\n",
        "            # Append the decoded prediction and label for the current sample\n",
        "            all_preds.append(decoded_pred)  # Append decoded prediction for current sample\n",
        "            all_labels.append(decoded_label)  # Append decoded label for current sample\n",
        "\n",
        "    # Calculate exact match\n",
        "    em = metric.compute(predictions=all_preds, references=all_labels)[\"exact_match\"]\n",
        "\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"  Exact Match: {em:.4f}\")\n",
        "\n",
        "    return {\"exact_match\": em}"
      ],
      "metadata": {
        "id": "B0rtK7yb45Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WORKING"
      ],
      "metadata": {
        "id": "AgAXg074JWdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from peft import PeftModel\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset, device=None, edges=None):\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = GraphModel(mistral_model, tokenizer)\n",
        "    model = PeftModel.from_pretrained(model, model_path, is_trainable=False)\n",
        "\n",
        "    model.to(device)\n",
        "    model.float()\n",
        "\n",
        "    metric = evaluate.load(\"exact_match\")\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    model.eval()\n",
        "    model.encoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(eval_dataset)), desc=\"Evaluating\"):\n",
        "            data = eval_dataset[i]\n",
        "\n",
        "            Q = data['input_ids']\n",
        "            A = data['labels']\n",
        "\n",
        "            print('\\n\\n')\n",
        "            print(f\"Sample ID: {i}\")\n",
        "            print(f\"  - Text: {tokenizer.decode(Q, skip_special_tokens=True)}\")\n",
        "            print(f\"  - Target Text: {tokenizer.decode(A, skip_special_tokens=True)}\")\n",
        "            print('\\n')\n",
        "\n",
        "            # Prepare data for the model\n",
        "            input_data = {\n",
        "                \"input_ids\": Q.unsqueeze(0).to(device).long(),\n",
        "                \"attention_mask\": data['attention_mask'].unsqueeze(0).to(device).float()\n",
        "            }\n",
        "\n",
        "            if edges is None:\n",
        "                edges = torch.tensor([[]]).to(device)\n",
        "\n",
        "            try:\n",
        "                # Model inference\n",
        "                model_output = model(**input_data, edges=edges.float())\n",
        "                logits = model_output.logits\n",
        "\n",
        "                # Check for NaN or Inf values in logits\n",
        "                if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
        "                    print(\"WARNING: NaN or Inf values detected in logits!\")\n",
        "\n",
        "                if logits.dim() > 2:\n",
        "                    logits = logits.squeeze(1)\n",
        "                elif logits.dim() == 1:\n",
        "                    logits = logits.unsqueeze(0)  # Add a batch dimension if needed\n",
        "\n",
        "                # Extract predicted tokens\n",
        "                predicted_tokens = logits.argmax(dim=-1).cpu().tolist()\n",
        "\n",
        "                # Print shapes and values for debugging\n",
        "                print(\"\\n\\n\")\n",
        "                print(\"Logits length:\", logits.shape[1])\n",
        "                print(\"Logits shape:\", logits.shape)\n",
        "                print(\"Logits dtype:\", logits.dtype)\n",
        "                print(\"\\n\")\n",
        "                print(\"Predicted IDs:\", logits.argmax(dim=-1))\n",
        "                print(\"Labels:\", data['labels'])\n",
        "                print(\"\\n\")\n",
        "\n",
        "                # Decode predictions and labels for the current sample\n",
        "                decoded_pred = tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "                decoded_label = tokenizer.decode(A.cpu().tolist(), skip_special_tokens=True)\n",
        "\n",
        "                # Print predicted and target answers\n",
        "                print(\"Predicted Answer:\", decoded_pred)\n",
        "                print(\"Target Answer:\", decoded_label)\n",
        "                print(\"\\n\")\n",
        "\n",
        "                # Append the decoded prediction and label for the current sample\n",
        "                all_preds.append(decoded_pred)\n",
        "                all_labels.append(decoded_label)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during evaluation for sample {i}: {e}\")\n",
        "                all_preds.append(\"\")\n",
        "                all_labels.append(\"\")\n",
        "                continue\n",
        "\n",
        "    # Calculate exact match\n",
        "    em = metric.compute(predictions=all_preds, references=all_labels)[\"exact_match\"]\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"  Exact Match: {em:.4f}\")\n",
        "\n",
        "    return {\"exact_match\": em}\n"
      ],
      "metadata": {
        "id": "H5ICCGUcAkCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WORKINg-2"
      ],
      "metadata": {
        "id": "h2dZ6KwetpRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from peft import PeftModel\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", edges=None):\n",
        "    \"\"\"\n",
        "    Evaluates a text-to-SQL model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained PEFT model.\n",
        "        eval_dataset (Dataset): The dataset to evaluate on.\n",
        "        device (str, optional): The device to use for computation (\"cuda\" or \"cpu\"). Defaults to \"cuda\" if available.\n",
        "        edges (torch.Tensor, optional): Precomputed edge indices for the dataset (if applicable).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the exact match score.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model once outside the loop\n",
        "    model = GraphModel(mistral_model, tokenizer)\n",
        "    model = PeftModel.from_pretrained(model, model_path, is_trainable=False)\n",
        "    model.to(device)\n",
        "    model.float()\n",
        "    model.eval()\n",
        "    model.encoder.eval()\n",
        "\n",
        "    metric = evaluate.load(\"exact_match\")\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(eval_dataset)), desc=\"Evaluating\"):\n",
        "            data = eval_dataset[i]\n",
        "\n",
        "            Q = data['input_ids'].to(device).long()\n",
        "            A = data['labels'].to(device).long()\n",
        "            # Check for NaN or Inf values in Q and A\n",
        "            if torch.isnan(Q).any() or torch.isinf(Q).any() or torch.isnan(A).any() or torch.isinf(A).any():\n",
        "                print(\"WARNING: NaN or Inf values detected in input_ids or labels!\")\n",
        "\n",
        "            print('\\n\\n')\n",
        "            print(f\"Sample ID: {i}\")\n",
        "            print(f\"  - Text: {tokenizer.decode(Q, skip_special_tokens=True)}\")\n",
        "            print(f\"  - Target Text: {tokenizer.decode(A, skip_special_tokens=True)}\")\n",
        "            print('\\n')\n",
        "\n",
        "            # Prepare data for the model\n",
        "            input_data = {\n",
        "                \"input_ids\": Q.unsqueeze(0),\n",
        "                \"attention_mask\": data['attention_mask'].unsqueeze(0).to(device).float()\n",
        "            }\n",
        "\n",
        "            if edges is None:\n",
        "                edges = torch.tensor([[]]).to(device)\n",
        "\n",
        "            try:\n",
        "                # Model inference\n",
        "                model_output = model(**input_data, edges=edges.float())\n",
        "                logits = model_output.logits\n",
        "\n",
        "\n",
        "                # Handle potential errors in logits\n",
        "                if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
        "                    print(\"WARNING: NaN or Inf values detected in logits!\")\n",
        "                    logits[torch.isnan(logits)] = 0 # Replace NaN with zero\n",
        "                    logits[torch.isinf(logits)] = 0 # Replace Inf with zero\n",
        "\n",
        "\n",
        "                # Ensure logits has the right dimensions before argmax\n",
        "                if logits.dim() > 2:\n",
        "                    logits = logits.squeeze(1)\n",
        "                elif logits.dim() == 1:\n",
        "                    logits = logits.unsqueeze(0)\n",
        "\n",
        "                # Extract predicted tokens directly on GPU\n",
        "                predicted_ids = logits.argmax(dim=-1)\n",
        "\n",
        "                # Print shapes and values for debugging\n",
        "                print(\"\\n\\n\")\n",
        "                print(\"Logits length:\", logits.shape[1])\n",
        "                print(\"Logits shape:\", logits.shape)\n",
        "                print(\"Logits dtype:\", logits.dtype)\n",
        "                print(\"\\n\")\n",
        "                print(\"Predicted IDs:\", logits.argmax(dim=-1))\n",
        "                print(\"Labels:\", data['labels'])\n",
        "                print(\"\\n\")\n",
        "\n",
        "                # Decode predictions and labels (move to CPU for decoding)\n",
        "                decoded_pred = tokenizer.decode(predicted_ids.cpu(), skip_special_tokens=True)\n",
        "                decoded_label = tokenizer.decode(A.cpu(), skip_special_tokens=True)\n",
        "\n",
        "                print(\"Predicted Answer:\", decoded_pred)\n",
        "                print(\"Target Answer:\", decoded_label)\n",
        "                print(\"\\n\")\n",
        "\n",
        "                all_preds.append(decoded_pred)\n",
        "                all_labels.append(decoded_label)\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if 'out of memory' in str(e):  # Check if it's an OOM error\n",
        "                    torch.cuda.empty_cache()\n",
        "                    print(f\"Out of memory error for sample {i}. Skipping this sample.\")\n",
        "                else:\n",
        "                    print(f\"Error during evaluation for sample {i}: {e}\")\n",
        "                all_preds.append(\"\")  # Add an empty string for the skipped sample\n",
        "                all_labels.append(\"\")\n",
        "\n",
        "    # Calculate exact match\n",
        "    em = metric.compute(predictions=all_preds, references=all_labels)[\"exact_match\"]\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"  Exact Match: {em:.4f}\")\n",
        "\n",
        "    return {\"exact_match\": em}\n"
      ],
      "metadata": {
        "id": "KnKlAiBztm1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/gdrive/MyDrive/model/GNN-T2SQL/checkpoint-250\"\n",
        "!ls -ltha $path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnbQr8aY7iD6",
        "outputId": "c99f5568-adfb-4fba-812a-db1ad81f99b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw------- 1 root root 1.1G Aug  8 16:02 optimizer.pt\n",
            "-rw------- 1 root root  14K Aug  8 16:02 rng_state.pth\n",
            "-rw------- 1 root root 1000 Aug  8 16:02 scheduler.pt\n",
            "-rw------- 1 root root 1.2K Aug  8 16:02 trainer_state.json\n",
            "-rw------- 1 root root  730 Aug  8 16:02 adapter_config.json\n",
            "-rw------- 1 root root 2.3M Aug  8 16:02 adapter_model.safetensors\n",
            "-rw------- 1 root root 5.0K Aug  8 16:02 README.md\n",
            "-rw------- 1 root root 5.1K Aug  8 16:02 training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "path=\"/content/gdrive/MyDrive/model/GNN-T2SQL/checkpoint-250\"\n",
        "results=evaluate_model(path, eval_dataset, device=device)"
      ],
      "metadata": {
        "id": "jDhBe-E0Aouu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WORK-4"
      ],
      "metadata": {
        "id": "K5VetLhm5Bzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from peft import PeftModel\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", edges=None, fake_input=None):\n",
        "    \"\"\"\n",
        "    Evaluates a text-to-SQL model on a given dataset, with optional fake input for testing.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained PEFT model.\n",
        "        eval_dataset (Dataset): The dataset to evaluate on.\n",
        "        device (str, optional): The device to use for computation (\"cuda\" or \"cpu\"). Defaults to \"cuda\" if available.\n",
        "        edges (torch.Tensor, optional): Precomputed edge indices for the dataset (if applicable).\n",
        "        fake_input (str, optional): Fake input text to use instead of the actual dataset input.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing evaluation metrics, including exact match (EM), BLEU score, execution accuracy (if applicable), and others.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model once outside the loop\n",
        "    model = GraphModel(mistral_model, tokenizer)\n",
        "    model = PeftModel.from_pretrained(model, model_path, is_trainable=False)\n",
        "    model.to(device)\n",
        "    model.float()\n",
        "    model.eval()\n",
        "    model.encoder.eval()\n",
        "\n",
        "    metric_em = evaluate.load(\"exact_match\")\n",
        "    metric_bleu = evaluate.load(\"bleu\")\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Only evaluate on one sample if using fake input\n",
        "        for i in tqdm(range(1 if fake_input else len(eval_dataset)), desc=\"Evaluating\"):\n",
        "            if fake_input:\n",
        "                Q = tokenizer(fake_input, return_tensors=\"pt\")['input_ids'].to(device).long()\n",
        "                A = torch.tensor([], device=device).long()  # Empty tensor for labels\n",
        "            else:\n",
        "                data = eval_dataset[i]\n",
        "                Q = data['input_ids'].to(device).long()\n",
        "                A = data['labels'].to(device).long()\n",
        "\n",
        "            # Check for NaN or Inf values in Q and A\n",
        "            if torch.isnan(Q).any() or torch.isinf(Q).any() or (not fake_input and (torch.isnan(A).any() or torch.isinf(A).any())):\n",
        "                print(\"WARNING: NaN or Inf values detected in input_ids or labels!\")\n",
        "                continue  # Skip this sample if there are invalid values\n",
        "\n",
        "            print('\\n\\n')\n",
        "            print(f\"Sample ID: {i}\")\n",
        "             # Convert Q to a NumPy array before decoding\n",
        "            print(f\"  - Text: {tokenizer.decode(Q.cpu().numpy()[0], skip_special_tokens=True)}\")\n",
        "            if not fake_input:\n",
        "                print(f\"  - Target Text: {tokenizer.decode(A, skip_special_tokens=True)}\")\n",
        "            print('\\n')\n",
        "\n",
        "             # Prepare data for the model\n",
        "            input_data = {\n",
        "                \"input_ids\": Q.unsqueeze(0),\n",
        "                \"attention_mask\": data['attention_mask'].unsqueeze(0).to(device).float() if not fake_input else torch.ones_like(Q).unsqueeze(0)\n",
        "            }\n",
        "\n",
        "            if edges is None:\n",
        "                edges = torch.tensor([[]]).to(device)\n",
        "\n",
        "            try:\n",
        "                # Model inference\n",
        "                # Ensure edges is in the correct format (if it's being used by your model)\n",
        "                if edges is not None:\n",
        "                    # Example: If your model expects edges as a 2D tensor of shape (batch_size, num_edges)\n",
        "                    edges = edges.unsqueeze(0)  # Add a batch dimension if necessary\n",
        "                else:\n",
        "                    edges = torch.empty((1, 0), dtype=torch.long, device=device) # Create an empty tensor if no edges are provided\n",
        "\n",
        "                model_output = model(**input_data, edges=edges.float())\n",
        "                logits = model_output.logits\n",
        "\n",
        "\n",
        "\n",
        "                # Handle potential errors in logits\n",
        "                if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
        "                    print(\"WARNING: NaN or Inf values detected in logits!\")\n",
        "                    logits[torch.isnan(logits)] = 0 # Replace NaN with zero\n",
        "                    logits[torch.isinf(logits)] = 0 # Replace Inf with zero\n",
        "\n",
        "\n",
        "                # Ensure logits has the right dimensions before argmax\n",
        "                if logits.dim() > 2:\n",
        "                    logits = logits.squeeze(1)\n",
        "                elif logits.dim() == 1:\n",
        "                    logits = logits.unsqueeze(0)\n",
        "\n",
        "                # Extract predicted tokens directly on GPU\n",
        "                predicted_ids = logits.argmax(dim=-1)\n",
        "\n",
        "                # Convert to list only if it's not already a list\n",
        "                if not isinstance(predicted_ids, list):\n",
        "                    predicted_ids = predicted_ids.cpu().tolist()\n",
        "\n",
        "                # Print the type and shape of predicted_ids for debugging\n",
        "                print(\"Type of predicted_ids:\", type(predicted_ids))\n",
        "                print(\"Shape of predicted_ids:\", predicted_ids.shape)\n",
        "\n",
        "\n",
        "                # Print the shape of hidden_states for debugging\n",
        "                #print(\"Shape of hidden_states:\", hidden_states.shape)  # Add this line\n",
        "\n",
        "                #bsz, q_len, _ = hidden_states.size()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # Always convert predicted_ids to a list, regardless of its dimension\n",
        "                #predicted_ids = predicted_ids.cpu().tolist()\n",
        "\n",
        "\n",
        "\n",
        "                # Print shapes and values for debugging\n",
        "                print(\"\\n\\n\")\n",
        "                print(\"Logits length:\", logits.shape[1])\n",
        "                print(\"Logits shape:\", logits.shape)\n",
        "                print(\"Logits dtype:\", logits.dtype)\n",
        "                print(\"\\n\")\n",
        "                print(\"Predicted IDs:\", predicted_ids)\n",
        "                if not fake_input:\n",
        "                    print(\"Labels:\", data['labels'])\n",
        "                print(\"\\n\")\n",
        "\n",
        "\n",
        "                # Decode predictions and labels\n",
        "                decoded_pred = tokenizer.decode(predicted_ids, skip_special_tokens=True) # Decode the predicted IDs\n",
        "\n",
        "\n",
        "\n",
        "                if not fake_input:\n",
        "                    decoded_label = tokenizer.decode(A.cpu(), skip_special_tokens=True)\n",
        "                    all_labels.append(decoded_label)\n",
        "\n",
        "                print(\"Predicted Answer:\", decoded_pred)\n",
        "                if not fake_input:\n",
        "                    print(\"Target Answer:\", decoded_label)\n",
        "                print(\"\\n\")\n",
        "\n",
        "                all_preds.append(decoded_pred)  # Append even if fake input\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if 'out of memory' in str(e):  # Check if it's an OOM error\n",
        "                    torch.cuda.empty_cache()\n",
        "                    print(f\"Out of memory error for sample {i}. Skipping this sample.\")\n",
        "                else:\n",
        "                    print(f\"Error during evaluation for sample {i}: {e}\")\n",
        "                all_preds.append(\"\")  # Add an empty string for the skipped sample\n",
        "                if not fake_input:\n",
        "                    all_labels.append(\"\")\n",
        "\n",
        "    # Calculate exact match\n",
        "    results = {}\n",
        "    if not fake_input:\n",
        "        em = metric_em.compute(predictions=all_preds, references=all_labels)[\"exact_match\"]\n",
        "        results[\"exact_match\"] = em\n",
        "        # Calculate BLEU score\n",
        "        bleu = metric_bleu.compute(predictions=all_preds, references=all_labels)[\"bleu\"]\n",
        "        results[\"bleu\"] = bleu\n",
        "\n",
        "\n",
        "        # Calculate execution accuracy (if applicable)\n",
        "        # ... (You'll need to implement this based on your specific setup)\n",
        "\n",
        "        print(\"\\nEvaluation Results:\")\n",
        "        print(f\"  Exact Match: {em:.4f}\")\n",
        "        print(f\"  BLEU Score: {bleu:.4f}\")\n",
        "        # Print execution accuracy if calculated\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "wLXgvF2c2dYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your saved model\n",
        "model_path =\"/content/gdrive/MyDrive/model/GNN-T2SQL/checkpoint-250\"\n",
        "\n",
        "# Use the fake input\n",
        "fake_input = \"What is the capital of the USA?\"\n",
        "\n",
        "# Evaluate the model with the fake input\n",
        "results = evaluate_model(model_path, test_dataset, fake_input=fake_input)\n",
        "\n",
        "# Print the results\n",
        "print(results)  # This will likely be an empty dictionary since there's no exact match to compare to\n"
      ],
      "metadata": {
        "id": "IoFItCB25HN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOT WORK"
      ],
      "metadata": {
        "id": "6ndDhOiL5iTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "path=\"/content/GNN-T2SQL/checkpoint-500\"\n",
        "\n",
        "# 1. Load the Entire Model (With Adapter)\n",
        "model = GraphModel(mistral_model, tokenizer)\n",
        "model = PeftModel.from_pretrained(model, path, is_trainable=False)\n",
        "model.to(device)\n",
        "\n",
        "# 3. Create DataLoader with Collator\n",
        "data_collator = GraphDataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8\n",
        ")\n",
        "\n",
        "\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, collate_fn=data_collator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wHgpHWohSUk2",
        "outputId": "5c77f795-ddd4-4fe2-e2d8-8990a76369c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Can't find 'adapter_config.json' at '/content/GNN-T2SQL/checkpoint-500'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/config.py\u001b[0m in \u001b[0;36m_get_peft_type\u001b[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 config_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    206\u001b[0m                     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/GNN-T2SQL/checkpoint-500'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5669ac1820da>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1. Load the Entire Model (With Adapter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmistral_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_trainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             config = PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001b[0;32m--> 453\u001b[0;31m                 PeftConfig._get_peft_type(\n\u001b[0m\u001b[1;32m    454\u001b[0m                     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subfolder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/config.py\u001b[0m in \u001b[0;36m_get_peft_type\u001b[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 )\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can't find '{CONFIG_NAME}' at '{model_id}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mloaded_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at '/content/GNN-T2SQL/checkpoint-500'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=eval_dataloader\n",
        "print(data.dataset[0]['input_ids'])\n",
        "data.dataset[0]['labels']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3oA16mTlVg",
        "outputId": "fc8950d4-e75d-4297-b24e-81842b64f1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    2,     2,     2,  ...,  1070, 22032, 29572])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,     2,     2,  ..., 29502, 29508, 29502])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_dataloader\n",
        "edges=None\n",
        "\n",
        "\n",
        "# 2. Initialize Metrics\n",
        "metric = evaluate.load(\"exact_match\")\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "      #for i in tqdm(range(len(eval_dataset)), desc=\"Evaluating\"):\n",
        "      for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):  # Iterate over the DataLoader\n",
        "          # Extract the data from the batch (assuming batch size 1)\n",
        "          data = batch\n",
        "          #data = eval_dataset[i]\n",
        "          #print(data)\n",
        "\n",
        "          Q = data['input_ids'].squeeze()  # Convert tensor to list\n",
        "          A = data['labels'].squeeze()  # Convert tensor to list\n",
        "\n",
        "          #Q = data['input_ids']\n",
        "          #A = data['labels']\n",
        "\n",
        "          print('\\n\\n')\n",
        "          #print(f\"Sample ID: {i}\")\n",
        "          print(f\"  - Text: {tokenizer.decode(Q.tolist(), skip_special_tokens=True)}\") # Decode after converting to list\n",
        "          print(f\"  - Target Text: {tokenizer.decode(A.tolist(), skip_special_tokens=True)}\") # Decode after converting to list\n",
        "          print('\\n')\n",
        "\n",
        "\n",
        "          # Prepare data for the model, move tensors to the correct device and unsqueeze\n",
        "          data = {k: v.unsqueeze(0).to(device).float() for k, v in data.items() if isinstance(v, torch.Tensor)} # Apply unsqueeze only to tensors\n",
        "\n",
        "          # Convert 'input_ids' to LongTensor\n",
        "          data['input_ids'] = data['input_ids'].long()\n",
        "\n",
        "          # Provide a default 'edges' tensor if None\n",
        "          if edges is None:\n",
        "              edges = torch.tensor([[]]).to(device)\n",
        "          #edges=edges.float()\n",
        "\n",
        "           # Prepare data for the model\n",
        "          input_data = {\n",
        "                \"input_ids\": torch.tensor(Q).unsqueeze(0).to(device).long(),  # Convert list to tensor and unsqueeze\n",
        "                \"attention_mask\": torch.tensor(data['attention_mask']).unsqueeze(0).to(device).float()  # Convert list to tensor and unsqueeze\n",
        "            }\n",
        "\n",
        "          if edges is None:\n",
        "              edges = torch.tensor([[]]).to(device)\n",
        "\n",
        "\n",
        "          # Model inference\n",
        "          #model_output = model(**input_data, edges=edges.float())\n",
        "          #logits = model_output.logits\n",
        "\n",
        "\n",
        "\n",
        "          model_output = model(input_ids=data['input_ids'], attention_mask=data['attention_mask'], edges=edges.float())\n",
        "          logits = model_output.logits\n",
        "\n",
        "          if logits.dim() > 2:\n",
        "              logits = logits.squeeze(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          #all_preds.extend(logits.argmax(dim=-1).cpu().tolist())\n",
        "          #all_labels.extend(A.cpu().tolist())"
      ],
      "metadata": {
        "id": "l9MWtMZTS-tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from peft import PeftModel\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset, device=None, edges=None):\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 1. Load the Entire Model (With Adapter)\n",
        "    model = GraphModel(mistral_model, tokenizer)\n",
        "    model = PeftModel.from_pretrained(model, model_path, is_trainable=False)\n",
        "    model.to(device)\n",
        "\n",
        "    # Explicitly set model to float32 to ensure consistency\n",
        "    model.float()\n",
        "\n",
        "    # 2. Initialize Metrics\n",
        "    metric = evaluate.load(\"exact_match\")\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    # 3. Create DataLoader with Collator\n",
        "    data_collator = GraphDataCollatorForSeq2Seq(\n",
        "        tokenizer,\n",
        "        model=model,\n",
        "        label_pad_token_id=-100,\n",
        "        pad_to_multiple_of=8\n",
        "    )\n",
        "    eval_dataloader = DataLoader(eval_dataset, batch_size=1, collate_fn=data_collator)\n",
        "\n",
        "    # 4. Evaluation Loop\n",
        "    model.eval()\n",
        "    model.encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        #for i in tqdm(range(len(eval_dataset)), desc=\"Evaluating\"):\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):  # Iterate over the DataLoader\n",
        "            # Extract the data from the batch (assuming batch size 1)\n",
        "            #data = batch[0]\n",
        "            #data = eval_dataset[i]\n",
        "\n",
        "\n",
        "            data = batch\n",
        "\n",
        "\n",
        "            Q = data['input_ids']\n",
        "            A = data['labels']\n",
        "\n",
        "            print('\\n\\n')\n",
        "            #print(f\"Sample ID: {i}\")\n",
        "            #print(f\"  - Text: {tokenizer.decode(Q, skip_special_tokens=True)}\")\n",
        "            #print(f\"  - Target Text: {tokenizer.decode(A, skip_special_tokens=True)}\")\n",
        "            #print('\\n')\n",
        "\n",
        "\n",
        "           # Prepare data for the model, move tensors to the correct device and unsqueeze\n",
        "            data = {k: v.unsqueeze(0).to(device).float() for k, v in data.items()}\n",
        "\n",
        "            # Convert 'input_ids' to LongTensor\n",
        "            data['input_ids'] = data['input_ids'].long()\n",
        "\n",
        "            # Unsqueeze the 'edges' tensor to add a batch dimension\n",
        "            if edges is None:\n",
        "                edges = torch.tensor([[]]).unsqueeze(0).to(device)  # Add unsqueeze here\n",
        "\n",
        "\n",
        "            # Model inference\n",
        "            model_output = model(**data, edges=edges.float())  # Pass the entire data dictionary\n",
        "            logits = model_output.logits\n",
        "\n",
        "            if logits.dim() > 2:\n",
        "                logits = logits.squeeze(1)\n",
        "\n",
        "            all_preds.extend(logits.argmax(dim=-1).cpu().tolist())\n",
        "            all_labels.extend(A.cpu().tolist())\n",
        "\n",
        "\n",
        "    # 5. Compute and Print Metrics\n",
        "    decoded_preds = tokenizer.batch_decode(all_preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(all_labels, skip_special_tokens=True)\n",
        "\n",
        "    # Print for debugging\n",
        "    print(f\"Decoded predictions: {decoded_preds}\")\n",
        "    print(f\"Decoded labels: {decoded_labels}\")\n",
        "\n",
        "    em = metric.compute(predictions=decoded_preds, references=decoded_labels)[\"exact_match\"]\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"  Exact Match: {em:.4f}\")"
      ],
      "metadata": {
        "id": "swZN7ciePnxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset.dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYsWpTmqKRKz",
        "outputId": "38517594-529c-4e01-e6c2-9a6e0c612f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'SELECT cover_model FROM table_name_67 WHERE interview_subject = \"joan collins\"',\n",
              " 'question': 'Who was the Cover model in the issue in which the Interview subject was Joan Collins?',\n",
              " 'context': 'CREATE TABLE table_name_67 (cover_model VARCHAR, interview_subject VARCHAR)'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22uMnGaAaFx9",
        "outputId": "5ae9a44e-95a7-4fb0-913c-bd10fc4ab932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    2,     2,     2,  ..., 21384, 21959, 29572]),\n",
              " 'attention_mask': tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
              " 'labels': tensor([    2,     2,     2,  ...,  4263,  1894, 29507]),\n",
              " 'edges': tensor([[ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
              "         [ 1,  4,  4,  1,  4,  7,  5, 13,  8, 12, 12, 13,  4, 15, 13,  1]]),\n",
              " 'sample_ids': tensor([0])}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q=eval_dataset[0]['input_ids']\n",
        "tokenizer.decode(Q, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JKb6UNn6SP6n",
        "outputId": "24b4f729-ace1-4f38-bf01-7cf118ef3b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Who was the Cover model in the issue in which the Interview subject was Joan Collins?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=eval_dataset[0]['labels']\n",
        "tokenizer.decode(A, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0QbKnFM_Z1u1",
        "outputId": "1d23361b-2170-43da-c2a7-f47e6d9d3a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT cover_model FROM table_name_67 WHERE interview_subject = \"joan collins\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8  # Ensure tensors divisible by 8 for optimized performance\n",
        ")\n",
        "\n",
        "# 10. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")\n"
      ],
      "metadata": {
        "id": "t5jjcgcwGaIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA_Uj38H1Wm-"
      },
      "source": [
        "Let's analyze the information you've provided about your `GraphModel`:\n",
        "\n",
        "**Structure Analysis:**\n",
        "\n",
        "* **Encoder (Mistral-7B):** The backbone of your model is the Mistral-7B language model. This model is responsible for understanding the input text and generating meaningful representations (embeddings) for each token. The encoder has a substantial number of parameters (7.5 billion), indicating its large size and capacity to learn complex language patterns.\n",
        "\n",
        "* **GAT Layer:**  You've incorporated a Graph Attention Network (GAT) layer to process the graph structure of your input data. This layer likely learns to weigh the importance of different nodes and edges based on their relationships, which can help capture additional information beyond just the raw text.\n",
        "\n",
        "* **Pooling:** The `pool` operation is used to aggregate the representations from individual nodes into a single representation for the entire graph. The choice of pooling (e.g., mean pooling) depends on your specific task and how you want to combine the node-level information.\n",
        "\n",
        "* **LM Head:** The language model head (`lm_head`) takes the final graph representation and predicts the next token in the sequence. It has a large number of parameters due to the vocabulary size (32,768).\n",
        "\n",
        "**PEFT (Parameter-Efficient Fine-Tuning):**\n",
        "\n",
        "- **Lora (Low-Rank Adaptation):** You are using LoRA, a technique that adds small adapter modules to the model to fine-tune it more efficiently. This allows you to train a smaller number of parameters while still achieving good performance.\n",
        "\n",
        "- **Trainable Parameters:**  Only a small fraction (0.0078%) of the total parameters are trainable, thanks to LoRA. This drastically reduces the computational and memory requirements during training.\n",
        "\n",
        "**Potential Challenges and Considerations:**\n",
        "\n",
        "- **Graph Structure Quality:** The effectiveness of the GAT layer heavily relies on the quality of the graph structure you create from the input text. Dependency parsing is a good starting point, but you might want to explore other ways to construct the graph to better capture the relationships between words and phrases.\n",
        "\n",
        "- **Overfitting with LoRA:** Even with LoRA, overfitting can be a concern, especially with a small dataset. Monitor your validation loss and consider techniques like early stopping or adding more training data (if possible).\n",
        "\n",
        "- **Memory Usage:**  Graph models can be memory intensive, especially with large input sequences or large batch sizes. You might need to experiment with techniques like gradient checkpointing or gradient accumulation to manage memory usage.\n",
        "\n",
        "- **Training Stability:** Training large language models can sometimes be unstable. Experiment with different learning rates, optimizers, and warm-up strategies to find the best settings for your model.\n",
        "\n",
        "- **Evaluation Metrics:** Choose appropriate evaluation metrics that reflect the quality of the generated SQL queries. Consider using both automated metrics (e.g., BLEU score, accuracy) and human evaluation to assess the model's performance.\n",
        "\n",
        "\n",
        "Let me know if you have any specific questions or concerns!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjgBpi5eCiJI"
      },
      "source": [
        "* Original Code - TRAINING ONLY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m9ufONvpW2G"
      },
      "source": [
        "\n",
        "TO BE TEST IT WORK FOR trainer = SFTTrainer( ; from trl import SFTTrainer;\n",
        "\n",
        "max_seq_length = 2048 --- max sequence length for model and packing of the dataset\n",
        "\n",
        " https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Mistral_7B_Instruct_v0_1_for_text_to_SQL_EVALDATA.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9xVfjpHjI9l"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFOcr3UYpRH_"
      },
      "outputs": [],
      "source": [
        "# 8. Evaluation Metric (Semantic Similarity)\n",
        "metric = evaluate.load(\"exact_match\")\n",
        "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = tokenizer.batch_decode(logits, skip_special_tokens=True)\n",
        "    references = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute embeddings for predictions and references\n",
        "    prediction_embeddings = sentence_transformer_model.encode(predictions, convert_to_tensor=True)\n",
        "    reference_embeddings = sentence_transformer_model.encode(references, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    cosine_similarities = util.cos_sim(prediction_embeddings, reference_embeddings)\n",
        "    similarities = torch.diag(cosine_similarities).cpu().numpy()  # Extract similarities for corresponding pairs\n",
        "\n",
        "    # Return average similarity as the metric\n",
        "    em = metric.compute(predictions=predictions, references=references)[\"exact_match\"]\n",
        "    return {\"semantic_similarity\": np.mean(similarities), \"exact_match\": em}\n",
        "\n",
        "# 9. Training Arguments and Trainer\n",
        "training_args = TrainingArguments(\n",
        "    \"graph-T2SQL\",\n",
        "    logging_dir=\"graph-T2SQL\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=1,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    push_to_hub=False,\n",
        "    dataloader_pin_memory=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_semantic_similarity\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Data Collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8  # Ensure tensors divisible by 8 for optimized performance\n",
        ")\n",
        "\n",
        "print('\\n\\n')\n",
        "\n",
        "# 10. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
        "\n",
        "\n",
        "# 11. Train the model\n",
        "print('\\n\\n')\n",
        "trainer.train()\n",
        "print('\\n\\n')\n",
        "\n",
        "# 12. Evaluate on the test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')\n",
        "print(f'Test Exact Match: {test_results[\"eval_exact_match\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPLqrRtAS9r2"
      },
      "source": [
        "## Enhance - 1: Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQckSalcwOv9"
      },
      "outputs": [],
      "source": [
        "!pip install nlpaug -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXlOUvZNSWlz"
      },
      "outputs": [],
      "source": [
        "from nlpaug.augmenter.word import SynonymAug, RandomWordAug\n",
        "from nlpaug.augmenter.sentence import RandomInsertionAug\n",
        "\n",
        "def augment_data(dataset):\n",
        "    augmented_data = []\n",
        "\n",
        "    synonym_aug = SynonymAug(aug_src='wordnet')\n",
        "    insert_aug = RandomInsertionAug(aug_p=0.1)  # Insert with 10% probability\n",
        "    delete_aug = RandomWordAug(action=\"delete\", aug_p=0.05)  # Delete with 5% probability\n",
        "\n",
        "    for item in dataset:\n",
        "        question = item['question']\n",
        "        answer = item['answer']\n",
        "\n",
        "        # Create augmented examples\n",
        "        augmented_questions = [\n",
        "            synonym_aug.augment(question),\n",
        "            insert_aug.augment(question),\n",
        "            delete_aug.augment(question)\n",
        "        ]\n",
        "\n",
        "        # Add original and augmented examples to the dataset\n",
        "        for aug_question in augmented_questions:\n",
        "            augmented_data.append({'question': aug_question, 'answer': answer})\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "# Augment the training dataset\n",
        "train_dataset_augmented = augment_data(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdh2zS5wTKh0"
      },
      "source": [
        "## Enhance - 2: Alternative Architecture: Graph Transformer Network (GTN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCCpH_DmwusS"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwON48w8ScUs"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GTConv\n",
        "\n",
        "class GTNModel(torch.nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(GTNModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.gtn = GTConv(4096, 4096, num_layers=2)  # 2 GTN layers\n",
        "        self.pool = lambda x, batch: torch.mean(x, dim=0, keepdim=True)\n",
        "        self.lm_head = torch.nn.Linear(4096, tokenizer.vocab_size)\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        x = inputs['input_ids'].to(mistral_model.device)\n",
        "        edge_index = inputs['edge_index'].to(mistral_model.device)\n",
        "        embeddings = self.encoder(x).last_hidden_state.cpu()\n",
        "        gtn_out = self.gtn(embeddings, edge_index.cpu())\n",
        "        pooled = self.pool(gtn_out, inputs.get('batch', torch.zeros(gtn_out.size(0)).long()))\n",
        "        out = self.lm_head(pooled.to(mistral_model.device))\n",
        "        return {\"logits\": out}\n",
        "\n",
        "# Replace the model with the GTNModel\n",
        "model = GTNModel(mistral_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyjnyL2RTMpX"
      },
      "source": [
        "## Enhance - 3: Integration Enhance - 1 and Enhance - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMNXPR2XS1RT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch_geometric.nn import GTConv  # For GTN\n",
        "from trl import setup_chat_format\n",
        "from nlpaug.augmenter.word import SynonymAug, RandomWordAug\n",
        "from nlpaug.augmenter.sentence import RandomInsertionAug\n",
        "\n",
        "# ... (rest of the imports and model/tokenizer loading from the original code)\n",
        "\n",
        "# Data Augmentation Function\n",
        "def augment_data(dataset):\n",
        "    augmented_data = []\n",
        "\n",
        "    synonym_aug = SynonymAug(aug_src='wordnet')\n",
        "    insert_aug = RandomInsertionAug(aug_p=0.1)  # Insert with 10% probability\n",
        "    delete_aug = RandomWordAug(action=\"delete\", aug_p=0.05)  # Delete with 5% probability\n",
        "\n",
        "    for item in dataset:\n",
        "        question = item['question']\n",
        "        answer = item['answer']\n",
        "\n",
        "        # Create augmented examples\n",
        "        augmented_questions = [\n",
        "            synonym_aug.augment(question),\n",
        "            insert_aug.augment(question),\n",
        "            delete_aug.augment(question)\n",
        "        ]\n",
        "\n",
        "        # Add original and augmented examples to the dataset\n",
        "        for aug_question in augmented_questions:\n",
        "            augmented_data.append({'question': aug_question, 'answer': answer})\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "# TextToSQLDataset (unchanged from the original code)\n",
        "class TextToSQLDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        #text = item['question'] + \" \" + item['context']\n",
        "        text = item['question']\n",
        "        target_text = item['answer']\n",
        "\n",
        "        tokenized_input = self.tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "        tokenized_target = self.tokenizer(target_text, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "        # Dependency Parsing for Edge Index\n",
        "        doc = nlp(text)\n",
        "        edges = []\n",
        "        for token in doc:\n",
        "            if token.i < len(doc) - 1:\n",
        "                edges.append([token.i, token.head.i])\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        return {\n",
        "            'input_ids': tokenized_input['input_ids'].flatten(),\n",
        "            'attention_mask': tokenized_input['attention_mask'].flatten(),\n",
        "            'labels': tokenized_target['input_ids'].flatten(),\n",
        "            'edge_index': edge_index,\n",
        "        }\n",
        "\n",
        "# GTN Model WITH GTConv\n",
        "from torch_geometric.nn import GTConv\n",
        "\n",
        "class GTNModel(torch.nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(GTNModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.gtn = GTConv(4096, 4096, num_layers=2)  # 2 GTN layers\n",
        "        self.pool = lambda x, batch: torch.mean(x, dim=0, keepdim=True)\n",
        "        self.lm_head = torch.nn.Linear(4096, tokenizer.vocab_size)\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        x = inputs['input_ids'].to(mistral_model.device)\n",
        "        edge_index = inputs['edge_index'].to(mistral_model.device)\n",
        "        embeddings = self.encoder(x).last_hidden_state.cpu()\n",
        "\n",
        "        gtn_out = self.gtn(embeddings, edge_index.cpu())\n",
        "        pooled = self.pool(gtn_out, inputs.get('batch', torch.zeros(gtn_out.size(0)).long()))\n",
        "        out = self.lm_head(pooled.to(mistral_model.device))\n",
        "        return {\"logits\": out}\n",
        "\n",
        "# Replace the model with the GTNModel\n",
        "model = GTNModel(mistral_model)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "\n",
        "# 7. Evaluation Metric (Semantic Similarity)\n",
        "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = tokenizer.batch_decode(logits, skip_special_tokens=True)\n",
        "    references = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Compute embeddings for predictions and references\n",
        "    prediction_embeddings = sentence_transformer_model.encode(predictions, convert_to_tensor=True)\n",
        "    reference_embeddings = sentence_transformer_model.encode(references, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    cosine_similarities = util.cos_sim(prediction_embeddings, reference_embeddings)\n",
        "    similarities = torch.diag(cosine_similarities).cpu().numpy()  # Extract similarities for corresponding pairs\n",
        "\n",
        "    # Return average similarity as the metric\n",
        "    return {\"semantic_similarity\": np.mean(similarities)}\n",
        "\n",
        "\n",
        "# Augment the training dataset\n",
        "train_dataset_augmented = augment_data(train_dataset)\n",
        "\n",
        "# Create datasets (using augmented training data)\n",
        "train_dataset = TextToSQLDataset(train_dataset_augmented, tokenizer)\n",
        "val_dataset = TextToSQLDataset(val_dataset, tokenizer)\n",
        "test_dataset = TextToSQLDataset(test_dataset, tokenizer)\n",
        "\n",
        "# Use the GTNModel\n",
        "model = GTNModel(mistral_model)\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 10. Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = val_dataset,\n",
        "    data_collator=lambda x: x,\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")\n",
        "\n",
        "from transformers import EarlyStoppingCallback\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
        "\n",
        "# 11. Train the model\n",
        "trainer.train()\n",
        "\n",
        "# 12. Evaluate on the test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCYvI4AeUaJu"
      },
      "source": [
        "## Enhance - 4: Regularization Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8neBYzeNUJD_"
      },
      "outputs": [],
      "source": [
        "# ... (other imports)\n",
        "from torch_geometric.nn import GTConv\n",
        "\n",
        "# ... (other classes and functions)\n",
        "\n",
        "# GTN Model with Dropout\n",
        "class GTNModel(torch.nn.Module):\n",
        "    def __init__(self, encoder, dropout_prob=0.1):  # Add dropout probability\n",
        "        super(GTNModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.gtn = GTConv(4096, 4096, num_layers=2)\n",
        "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
        "        self.pool = lambda x, batch: torch.mean(x, dim=0, keepdim=True)\n",
        "        self.lm_head = torch.nn.Linear(4096, tokenizer.vocab_size)\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        # ... (rest of the forward method)\n",
        "        x = inputs['input_ids'].to(mistral_model.device)\n",
        "        edge_index = inputs['edge_index'].to(mistral_model.device)\n",
        "        embeddings = self.encoder(x).last_hidden_state.cpu()\n",
        "\n",
        "\n",
        "        gtn_out = self.gtn(embeddings, edge_index.cpu())\n",
        "        gtn_out = self.dropout(gtn_out)  # Apply dropout after GTN\n",
        "\n",
        "        pooled = self.pool(gtn_out, inputs.get('batch', torch.zeros(gtn_out.size(0)).long()))\n",
        "\n",
        "        out = self.lm_head(pooled.to(mistral_model.device))\n",
        "        return {\"logits\": out}\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "# Create the model with dropout\n",
        "model = GTNModel(mistral_model, dropout_prob=0.1)  # Set dropout probability\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "\n",
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 10. Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = val_dataset,\n",
        "    data_collator=lambda x: x,\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")\n",
        "\n",
        "from transformers import EarlyStoppingCallback\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
        "\n",
        "# 11. Train the model\n",
        "trainer.train()\n",
        "\n",
        "# 12. Evaluate on the test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1syJYIaXvil"
      },
      "source": [
        "## Enhance - 5:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GN68X1NHaED"
      },
      "source": [
        "* MultiTaskDataset: This class combines multiple datasets and assigns task IDs to each sample.\n",
        "\n",
        "* MultiTaskModel: This class extends the model to include a separate head for the classification task.\n",
        "\n",
        "* Task-Specific Forward Pass: The forward method now takes a task_id input and uses the appropriate head based on the task.\n",
        "\n",
        "* Training Loop: The training loop needs to be modified to handle the multi-task dataset and compute losses for both tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoHDHFZGXuyG"
      },
      "outputs": [],
      "source": [
        "class TextToSQLDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, task_id=0):  # Add task_id argument\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.task_id = task_id  # Store task ID\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        question = item['question'] if self.task_id == 0 else item['text']  # Use appropriate field\n",
        "        answer = item['answer'] if self.task_id == 0 else item['label']  # Use appropriate field\n",
        "        # ... (rest of the __getitem__ method for tokenization and graph construction)\n",
        "\n",
        "\n",
        "        item = {'input_ids': input_ids, 'attention_mask': attention_mask,\n",
        "                'edge_index': edge_index, 'task_id': self.task_id}  # Add task_id\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNy48iw6YmA7"
      },
      "outputs": [],
      "source": [
        "# Create the multi-task model with dropout\n",
        "model = MultiTaskModel(mistral_model, dropout_prob=0.1, num_classes=num_classification_classes)\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfHkTCn0Yto7"
      },
      "outputs": [],
      "source": [
        "# ... (other parts of the code)\n",
        "\n",
        "train_dataset_sql = TextToSQLDataset(train_dataset_augmented, tokenizer, task_id=0)\n",
        "train_dataset_classification = TextToSQLDataset(dataset_classification, tokenizer, task_id=1)\n",
        "\n",
        "# Combine datasets (consider balancing them if needed)\n",
        "train_dataset = torch.utils.data.ConcatDataset([train_dataset_sql, train_dataset_classification])\n",
        "\n",
        "# ... (rest of the training and evaluation code, modified for multi-task)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IZVtS_5Y7wC"
      },
      "source": [
        "In the provided code, the new train_dataset brings several enhancements compared to the original version:\n",
        "\n",
        "Data Augmentation: The most significant change is the incorporation of data augmentation. The original train_dataset is passed through the augment_data function, which creates additional training examples by applying techniques like synonym replacement, random word insertion, and random word deletion. This augmented dataset is then used to create the new train_dataset.\n",
        "\n",
        "Benefit: Data augmentation helps the model generalize better to different phrasing and vocabulary variations in natural language input, leading to improved performance on unseen examples.\n",
        "Multi-Task Learning: The new train_dataset is designed to support multi-task learning. It combines examples from both the original text-to-SQL task and an additional classification task. Each example in the dataset is associated with a task_id to indicate which task it belongs to.\n",
        "\n",
        "Benefit: Multi-task learning allows the model to learn shared representations between related tasks, potentially improving performance and generalization on both tasks.\n",
        "Dynamic Padding: While not explicitly mentioned, the code likely uses dynamic padding when creating the train_dataset. This means that each example is padded to the length of the longest sequence in its batch, rather than using a fixed maximum length.\n",
        "\n",
        "Benefit: Dynamic padding reduces unnecessary padding tokens, which can speed up training and potentially improve model performance.\n",
        "\n",
        "Sources and related content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbw0TlBKlWI0"
      },
      "source": [
        "## Enhance - 6: Custom Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AP4hNkmlSyy"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "\n",
        "# Custom Loss Function (integrated)\n",
        "def compute_loss(model, inputs, return_outputs=False):\n",
        "    labels = inputs.pop(\"labels\")\n",
        "    task_ids = inputs.pop(\"task_id\")\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    sql_logits = outputs.logits[task_ids == 0]  # SQL task logits\n",
        "    sql_labels = labels[task_ids == 0]          # SQL task labels\n",
        "    sql_loss = CrossEntropyLoss()(sql_logits, sql_labels)\n",
        "\n",
        "    classification_logits = outputs.logits[task_ids == 1]  # Classification task logits\n",
        "    classification_labels = labels[task_ids == 1]          # Classification task labels\n",
        "    classification_loss = MSELoss()(classification_logits, classification_labels)\n",
        "\n",
        "    # Combine Losses (adjust weights as needed)\n",
        "    loss = 0.5 * sql_loss + 0.5 * classification_loss\n",
        "\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 10. Create Trainer instance (with the custom loss)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=lambda x: x,\n",
        "    compute_metrics=compute_metrics,\n",
        "    compute_loss=compute_loss,  # Pass the custom loss function here\n",
        "    optimizers=(optimizer, None)\n",
        ")\n",
        "\n",
        "# 11. Train the model\n",
        "trainer.train()\n",
        "\n",
        "# 12. Evaluate on the test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f'Test Semantic Similarity: {test_results[\"eval_semantic_similarity\"]:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jnxGtqh44nh8",
        "2hAPAwznG6Gl",
        "9QB1kXab0rHT",
        "AgAXg074JWdR",
        "K5VetLhm5Bzk",
        "6ndDhOiL5iTN",
        "WPLqrRtAS9r2",
        "Sdh2zS5wTKh0",
        "ZyjnyL2RTMpX",
        "wCYvI4AeUaJu",
        "h1syJYIaXvil",
        "Qbw0TlBKlWI0"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO4cjTVDBR6iu2zbvX8AssS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f9f2c903a2d48dfaf0c83b1a79d5f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48387adab0b54e02906ff27d32ecb65c",
              "IPY_MODEL_8aaa348e65234ab0941b05cdafbc45e4",
              "IPY_MODEL_903f0e871b7b407b80aab540248a6530"
            ],
            "layout": "IPY_MODEL_1cdf68be93ff465a899589ac49998cf1"
          }
        },
        "48387adab0b54e02906ff27d32ecb65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85510e7fa0849f4b0a824ed84992b22",
            "placeholder": "​",
            "style": "IPY_MODEL_09a7396a73ab428b8246888119b2b038",
            "value": "Generating train split: "
          }
        },
        "8aaa348e65234ab0941b05cdafbc45e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea89770d0604e58973146bf2ca73a8f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cac90c57b73049b6a1d1dd4d33516598",
            "value": 1
          }
        },
        "903f0e871b7b407b80aab540248a6530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77c1ca9bf9e4f76bcd98e43c264c956",
            "placeholder": "​",
            "style": "IPY_MODEL_3a3bbad5ec014c15a0ad07fc1972b12a",
            "value": " 10000/0 [00:00&lt;00:00, 14963.71 examples/s]"
          }
        },
        "1cdf68be93ff465a899589ac49998cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85510e7fa0849f4b0a824ed84992b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a7396a73ab428b8246888119b2b038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dea89770d0604e58973146bf2ca73a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cac90c57b73049b6a1d1dd4d33516598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f77c1ca9bf9e4f76bcd98e43c264c956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3bbad5ec014c15a0ad07fc1972b12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d839b3481c448a8bef168349810a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e937ccc2b41a454b875de8a81198df9d",
              "IPY_MODEL_fd9dedcf1e4b479ebe681a756f862033",
              "IPY_MODEL_5ef7a83429a84fa394274f80e4518a44"
            ],
            "layout": "IPY_MODEL_1027cd6bb9544e07a32a6eab6d30b615"
          }
        },
        "e937ccc2b41a454b875de8a81198df9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e2a2aa92ae4857bcf55abe15077e70",
            "placeholder": "​",
            "style": "IPY_MODEL_3857c33fb765437e9dba580c1f2a89bb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fd9dedcf1e4b479ebe681a756f862033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab703f17a4644118aad7a05f99f12d61",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9adccca3e26443d2a2a6af76c1b3a468",
            "value": 3
          }
        },
        "5ef7a83429a84fa394274f80e4518a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d8427671e44955bace6360233f8690",
            "placeholder": "​",
            "style": "IPY_MODEL_6737b23112fb4af4babc7e4c4e8db30d",
            "value": " 3/3 [00:05&lt;00:00,  1.85s/it]"
          }
        },
        "1027cd6bb9544e07a32a6eab6d30b615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e2a2aa92ae4857bcf55abe15077e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3857c33fb765437e9dba580c1f2a89bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab703f17a4644118aad7a05f99f12d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9adccca3e26443d2a2a6af76c1b3a468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5d8427671e44955bace6360233f8690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6737b23112fb4af4babc7e4c4e8db30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "349d950c5a674b4b9d1f33538e2397ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14ea5188d67f4f27a4e3b31fccb8d53e",
              "IPY_MODEL_edd269889dd7430dadf978bfaffcaf0a",
              "IPY_MODEL_d0d7d09522fb43dcaf995fc2d616aaa3"
            ],
            "layout": "IPY_MODEL_9ce577369e7140779053fb441cf240d4"
          }
        },
        "14ea5188d67f4f27a4e3b31fccb8d53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979b80aebfd54e33ac040511aaea8dda",
            "placeholder": "​",
            "style": "IPY_MODEL_a711099cb38c4ac89f7f93aee77abae5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "edd269889dd7430dadf978bfaffcaf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3163a793a4004f29bd76c07dab136f42",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7f1d95449a043aeaea6f887198a6702",
            "value": 3
          }
        },
        "d0d7d09522fb43dcaf995fc2d616aaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89fa6970e03446485bf0209e72f2fb4",
            "placeholder": "​",
            "style": "IPY_MODEL_592e1d10f9bd4a999065f9c955711069",
            "value": " 3/3 [00:05&lt;00:00,  1.88s/it]"
          }
        },
        "9ce577369e7140779053fb441cf240d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979b80aebfd54e33ac040511aaea8dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a711099cb38c4ac89f7f93aee77abae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3163a793a4004f29bd76c07dab136f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f1d95449a043aeaea6f887198a6702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b89fa6970e03446485bf0209e72f2fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592e1d10f9bd4a999065f9c955711069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41dafaf96ca84b2c955583ad1265b1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_938728b4f4964e5491bbf3b029c9e98c",
              "IPY_MODEL_a19d77d1e2f4484d863ec62d4a603b18",
              "IPY_MODEL_ae14bdb3176a42ba98aef20a8ecf9d27"
            ],
            "layout": "IPY_MODEL_e731ddc82ecc499c9ab3a57737283e5b"
          }
        },
        "938728b4f4964e5491bbf3b029c9e98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b71a55ebf54ec6bfab6351a093b74f",
            "placeholder": "​",
            "style": "IPY_MODEL_465bd94268f040fcbc1106cb768ae76f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a19d77d1e2f4484d863ec62d4a603b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba537bc03cd44d4aab46bba3a074ab4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0b50569125d4ee5a9c21137e7193691",
            "value": 3
          }
        },
        "ae14bdb3176a42ba98aef20a8ecf9d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_594b58dfdaca430ba04271820bd5a4d2",
            "placeholder": "​",
            "style": "IPY_MODEL_191d3dadbcc646e6b8aa97ed0c41afe1",
            "value": " 3/3 [00:05&lt;00:00,  1.74s/it]"
          }
        },
        "e731ddc82ecc499c9ab3a57737283e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b71a55ebf54ec6bfab6351a093b74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465bd94268f040fcbc1106cb768ae76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ba537bc03cd44d4aab46bba3a074ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b50569125d4ee5a9c21137e7193691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "594b58dfdaca430ba04271820bd5a4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191d3dadbcc646e6b8aa97ed0c41afe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}