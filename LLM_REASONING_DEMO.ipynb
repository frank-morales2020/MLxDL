{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO/75in/6K4DRy9PRQH+Wdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LLM_REASONING_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install datasets -q\n",
        "!pip install torch -q\n",
        "!pip install gymnasium -q"
      ],
      "metadata": {
        "id": "vkg6clLfImBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JLkw_1PNb0hu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "# --- 1. Pure Supervised Fine-tuning (Creating an initial reasoning model) ---\n",
        "#print(\"\\n--- 1. Pure Supervised Fine-tuning ---\")\n",
        "sft_model_name = \"gpt2\"\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(sft_model_name)\n",
        "sft_model = AutoModelForCausalLM.from_pretrained(sft_model_name)\n",
        "\n",
        "# In the \"Pure Supervised Fine-tuning\" section:\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(sft_model_name)\n",
        "if sft_tokenizer.pad_token is None:\n",
        "    sft_tokenizer.pad_token = sft_tokenizer.eos_token\n",
        "\n",
        "class ReasoningDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=64):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx][\"text\"]\n",
        "        encoding = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": encoding[\"input_ids\"].squeeze()\n",
        "        }\n",
        "\n",
        "sft_train_data = [\n",
        "    {\"text\": \"Question: What is the capital of Canada? Answer: Ottawa\"},\n",
        "    {\"text\": \"Question: What is the largest city in Canada? Answer: Toronto\"},\n",
        "    {\"text\": \"Question: What is the official language of Quebec? Answer: French\"}\n",
        "]\n",
        "\n",
        "\n",
        "sft_train_dataset = ReasoningDataset(sft_train_data, sft_tokenizer)\n",
        "sft_train_loader = torch.utils.data.DataLoader(sft_train_dataset, batch_size=2)\n",
        "\n",
        "sft_optimizer = AdamW(sft_model.parameters(), lr=5e-5)\n",
        "sft_epochs = 5"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "n9y_5o-Yb10T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 1. Pure Supervised Fine-tuning ---\")\n",
        "print('\\n')\n",
        "print(\"Creating the SFT model...\")\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(sft_epochs):\n",
        "    sft_model.train()\n",
        "    for batch in sft_train_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(sft_model.device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(sft_model.device)\n",
        "        labels = batch[\"labels\"].to(sft_model.device)\n",
        "        sft_optimizer.zero_grad()\n",
        "        outputs = sft_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        sft_optimizer.step()\n",
        "    print(f\"SFT Epoch {epoch+1} Loss: {loss.item()}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Saving the SFT model...\")\n",
        "sft_model.save_pretrained(\"./sft_reasoning_model\")\n",
        "sft_tokenizer.save_pretrained(\"./sft_reasoning_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OA8Fcmp9z14",
        "outputId": "b23bfe72-eeae-436f-ce05-54b7918ec7d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Pure Supervised Fine-tuning ---\n",
            "\n",
            "\n",
            "Creating the SFT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SFT Epoch 1 Loss: 6.823558807373047\n",
            "SFT Epoch 2 Loss: 1.2183752059936523\n",
            "SFT Epoch 3 Loss: 0.7251948118209839\n",
            "SFT Epoch 4 Loss: 0.7156901955604553\n",
            "SFT Epoch 5 Loss: 0.7075764536857605\n",
            "\n",
            "\n",
            "Saving the SFT model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./sft_reasoning_model/tokenizer_config.json',\n",
              " './sft_reasoning_model/special_tokens_map.json',\n",
              " './sft_reasoning_model/vocab.json',\n",
              " './sft_reasoning_model/merges.txt',\n",
              " './sft_reasoning_model/added_tokens.json',\n",
              " './sft_reasoning_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Reinforcement Learning Fine-tuning (Using the SFT model as initialization) ---\n",
        "print(\"\\n--- 2. Reinforcement Learning Fine-tuning ---\")\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "class FlightWaypointDataset(Dataset):\n",
        "    def __init__(self, input_texts, num_waypoints, tokenizer):\n",
        "        self.input_texts = input_texts\n",
        "        self.num_waypoints = num_waypoints\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.input_texts[idx]\n",
        "        num_waypoint = self.num_waypoints[idx]\n",
        "\n",
        "        encoding = self.tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"label\": torch.tensor(num_waypoint, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "!rm -rf *.pth\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "rl_epochs = 300\n",
        "batch_size = 32\n",
        "lr=1e-5\n",
        "\n",
        "#sft_model_name = \"gpt2\"\n",
        "#sft_tokenizer = AutoTokenizer.from_pretrained(sft_model_name)\n",
        "#if sft_tokenizer.pad_token is None:\n",
        "#    sft_tokenizer.pad_token = sft_tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Early stopping initialization\n",
        "best_val_loss = np.inf\n",
        "patience = 3\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "# 1. Load and Prepare the Dataset\n",
        "dataset = load_dataset(\"frankmorales2020/flight_plan_waypoints\")\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "train_size = int(0.8 * len(dataset[\"train\"]))\n",
        "val_size = len(dataset[\"train\"]) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset[\"train\"], [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "# Access the underlying data using the original dataset and the indices from the subset\n",
        "train_dataset_processed = FlightWaypointDataset(\n",
        "    [dataset[\"train\"][i][\"input\"] for i in train_dataset.indices],\n",
        "    [dataset[\"train\"][i][\"label\"] for i in train_dataset.indices],\n",
        "    sft_tokenizer\n",
        ")\n",
        "train_loader = DataLoader(train_dataset_processed, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset_processed = FlightWaypointDataset(\n",
        "    [dataset[\"train\"][i][\"input\"] for i in val_dataset.indices],\n",
        "    [dataset[\"train\"][i][\"label\"] for i in val_dataset.indices],\n",
        "    sft_tokenizer\n",
        ")\n",
        "val_loader = DataLoader(val_dataset_processed, batch_size=batch_size, shuffle=False)  # No need to shuffle validation data\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset_processed)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset_processed)}\")\n",
        "\n",
        "\n",
        "# 2. Load the Pre-trained Model (Corrected)\n",
        "sft_model = AutoModelForCausalLM.from_pretrained(\"./sft_reasoning_model\")  # Load from sft_reasoning_model directory\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(\"./sft_reasoning_model\")\n",
        "if sft_tokenizer.pad_token is None:\n",
        "    sft_tokenizer.pad_token = sft_tokenizer.eos_token\n",
        "\n",
        "# 3. Define the RLAgent (Waypoint Predictor) - CORRECTED\n",
        "class RLAgent(torch.nn.Module):\n",
        "    def __init__(self, sft_model, sft_tokenizer):\n",
        "        super().__init__()\n",
        "        self.sft_model = sft_model\n",
        "        self.sft_tokenizer = sft_tokenizer\n",
        "        self.waypoint_predictor = torch.nn.Linear(sft_model.config.hidden_size, 1)\n",
        "\n",
        "        # Unfreeze language model parameters (important for fine-tuning)\n",
        "        for param in self.sft_model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        #print('\\n')\n",
        "        #print(\"Input IDs shape:\", input_ids.shape)\n",
        "        #print(\"Attention Mask shape:\", attention_mask.shape)\n",
        "        #print('\\n')\n",
        "\n",
        "        outputs = self.sft_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "\n",
        "        # Averaging the last 4 hidden states (or experiment with other numbers)\n",
        "        hidden_states = torch.stack(outputs.hidden_states[-4:]).mean(0)[:, 0, :]\n",
        "        #hidden_states.retain_grad()\n",
        "\n",
        "        # Debugging: Print hidden states shape and grad\n",
        "        #print(\"Hidden states shape:\", hidden_states.shape)\n",
        "        #print(\"Hidden states grad:\", hidden_states.grad)\n",
        "\n",
        "        predicted_numberofwaypoints = self.waypoint_predictor(hidden_states)\n",
        "        #predicted_numberofwaypoints.retain_grad()  # Add this line\n",
        "\n",
        "\n",
        "        # Debugging: Print prediction shape and grad\n",
        "        #print('\\n')\n",
        "        #print(\"Predicted waypoints shape:\", predicted_numberofwaypoints.shape)\n",
        "        #print(\"Predicted waypoints grad:\", predicted_numberofwaypoints.grad)\n",
        "\n",
        "\n",
        "        return predicted_numberofwaypoints\n",
        "\n",
        "\n",
        "    def predict_numberofwaypoints(self, input_text):\n",
        "        encoding = self.sft_tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        input_ids = encoding[\"input_ids\"].to(self.sft_model.device)\n",
        "        attention_mask = encoding[\"attention_mask\"].to(self.sft_model.device)\n",
        "        with torch.no_grad():\n",
        "            predicted_numberofwaypoints = self.forward(input_ids, attention_mask)\n",
        "        return predicted_numberofwaypoints.item()\n",
        "\n",
        "# 4. Set up Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "rl_model = RLAgent(sft_model, sft_tokenizer).to(device)\n",
        "rl_optimizer = AdamW(rl_model.parameters(), lr=lr)\n",
        "\n",
        "# Ensure waypoint_predictor parameters are trainable\n",
        "for name, param in rl_model.named_parameters():\n",
        "    #print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")\n",
        "    if \"waypoint_predictor\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "scheduler = StepLR(rl_optimizer, step_size=2, gamma=0.1)  # Reduce LR by 0.1 every 2 epochs\n",
        "\n",
        "print('\\n')\n",
        "print(f\"Total Epoch: {rl_epochs}\")\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "max_steps = (len(train_dataset_processed) // int(batch_size)) * int(rl_epochs)\n",
        "# Correct for the dropped batch if it's incomplete\n",
        "\n",
        "#print(f\"Total Steps before correction: {max_steps}\")\n",
        "#print('\\n')\n",
        "\n",
        "# Correct for the dropped batch if it's incomplete\n",
        "if len(train_dataset_processed) % batch_size != 0:\n",
        "    max_steps -= (rl_epochs) - ((len(train_dataset_processed) % batch_size) / batch_size) * rl_epochs\n",
        "\n",
        "\n",
        "print(f\"Total Steps: {max_steps}\")\n",
        "\n",
        "\n",
        "def custom_loss(predicted_numberofwaypoints, num_waypoints_target, reward_weight=0.1):\n",
        "    original_loss = loss_fn(predicted_numberofwaypoints.squeeze(), num_waypoints_target)\n",
        "    reward_loss = -reward_weight * rewards.mean()  # Negative to maximize reward\n",
        "    total_loss = original_loss + reward_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "\n",
        "# 5. Training Loop\n",
        "for epoch in range(rl_epochs):\n",
        "    rl_model.train()\n",
        "    total_loss = 0\n",
        "    total_reward = 0  # Track total reward\n",
        "    scheduler.step()  # Update learning rate\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        num_waypoints_target = batch[\"label\"].to(device)\n",
        "\n",
        "        predicted_numberofwaypoints = rl_model(input_ids, attention_mask)\n",
        "\n",
        "\n",
        "        # Calculate Reward Score - Example using inverse difference (Corrected)\n",
        "        rewards = 1 / (1 + torch.abs(predicted_numberofwaypoints.squeeze() - num_waypoints_target))\n",
        "        reward = rewards.mean().item()  # Calculate average reward\n",
        "\n",
        "\n",
        "        # Loss function can still be used for parameter updates\n",
        "        loss = loss_fn(predicted_numberofwaypoints.squeeze(), num_waypoints_target)\n",
        "\n",
        "        #loss = custom_loss(predicted_numberofwaypoints, num_waypoints_target, reward_weight=0.1)  # Adjust reward_weight as needed\n",
        "\n",
        "        # Debugging: Print loss and gradients\n",
        "\n",
        "        #print(\"Loss:\", loss.item())\n",
        "        #print(\"Loss grad:\", loss.grad)\n",
        "        #print('\\n')\n",
        "\n",
        "\n",
        "        #for name, param in rl_model.named_parameters():\n",
        "        #    if param.grad is not None:\n",
        "        #        print(f\"Parameter: {name}, Grad Norm: {param.grad.norm()}\")\n",
        "        #    else:\n",
        "        #        print(f\"Parameter: {name}, Grad: None\")\n",
        "\n",
        "        # Alternatively, you could use a policy gradient approach\n",
        "        # and update parameters based on the reward directly\n",
        "\n",
        "        rl_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        rl_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_reward += reward  # Accumulate reward\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    avg_reward = total_reward / len(train_loader)  # Calculate average reward\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}, Average Reward: {avg_reward:.4f}\")\n",
        "\n",
        "\n",
        "    # Validation loop (after each epoch)\n",
        "    rl_model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            num_waypoints_target = batch[\"label\"].to(device)\n",
        "\n",
        "            predicted_numberofwaypoints = rl_model(input_ids, attention_mask)\n",
        "            loss = loss_fn(predicted_numberofwaypoints.squeeze(), num_waypoints_target)  # Use original loss for validation\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_without_improvement = 0\n",
        "        # Save the best model (optional)\n",
        "        torch.save(rl_model.state_dict(), \"fine_tuned_rl_best_model.pth\")\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break  # Exit the training loop\n",
        "\n",
        "\n",
        "# 6. Save the Fine-tuned Model\n",
        "torch.save(rl_model.state_dict(), \"./fine_tuned_rl_agent.pth\")\n",
        "print(\"\\nFine-tuned RL agent model saved to ./fine_tuned_rl_agent.pth\")\n",
        "\n",
        "#rl_model.waypoint_predictor.weight.requires_grad = True\n",
        "#rl_model.waypoint_predictor.bias.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zadpT8TAJZ7f",
        "outputId": "916e705c-706f-47e1-e373-acfc2534646c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Reinforcement Learning Fine-tuning ---\n",
            "Train dataset size: 1600\n",
            "Validation dataset size: 400\n",
            "\n",
            "\n",
            "Total Epoch: 300\n",
            "\n",
            "\n",
            "Total Steps: 15000\n",
            "Epoch 1, Average Loss: 11.2898, Average Reward: 0.3986\n",
            "Validation Loss: 3.9722\n",
            "Epoch 2, Average Loss: 4.6988, Average Reward: 0.4646\n",
            "Validation Loss: 3.9719\n",
            "Epoch 3, Average Loss: 4.3585, Average Reward: 0.4599\n",
            "Validation Loss: 3.8952\n",
            "Epoch 4, Average Loss: 4.6743, Average Reward: 0.4472\n",
            "Validation Loss: 3.9076\n",
            "Epoch 5, Average Loss: 4.6194, Average Reward: 0.4565\n",
            "Validation Loss: 3.9230\n",
            "Epoch 6, Average Loss: 4.7148, Average Reward: 0.4531\n",
            "Validation Loss: 3.9234\n",
            "Early stopping triggered!\n",
            "\n",
            "Fine-tuned RL agent model saved to ./fine_tuned_rl_agent.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the model architecture (assuming RLAgent class is defined)\n",
        "sft_model = AutoModelForCausalLM.from_pretrained(\"./sft_reasoning_model\")\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(\"./sft_reasoning_model\")\n",
        "rl_model = RLAgent(sft_model, sft_tokenizer)\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load(\"./fine_tuned_rl_best_model.pth\")\n",
        "\n",
        "# Load weights into the model\n",
        "rl_model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "# Define your flight plan text:\n",
        "data=val_dataset[359]\n",
        "data['input']\n",
        "data['label']\n",
        "flight_plan_text = data['input']\n",
        "actual_numberofwaypoint=data['label']\n",
        "\n",
        "# Call predict_numberofwaypoints to get the prediction:\n",
        "predicted_waypoints = rl_model.predict_numberofwaypoints(flight_plan_text)\n",
        "\n",
        "# Print the prediction:\n",
        "print('\\n')\n",
        "print(f\"Flight Plan Text: {flight_plan_text}\")\n",
        "print(f\"Predicted number of waypoints: {round(predicted_waypoints)}\")\n",
        "print(f\"Actual number of waypoints: {actual_numberofwaypoint}\")\n",
        "#delta=round(predicted_waypoints)-actual_numberofwaypoint\n",
        "#print(f\"Delta waypoints number: {delta}\")\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQTKrBHoYjH3",
        "outputId": "00646e91-9bbc-4fc7-80f3-a5408114ac26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Flight Plan Text: Calculate the waypoints from PVG to SJU. Departure: 2024-04-17, Aircraft: Boeing 777, Weather: Rainy\n",
            "Predicted number of waypoints: 6\n",
            "Actual number of waypoints: 6\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RLAgent(torch.nn.Module):\n",
        "    def __init__(self, sft_model, sft_tokenizer):\n",
        "        super().__init__()\n",
        "        self.sft_model = sft_model\n",
        "        self.sft_tokenizer = sft_tokenizer\n",
        "        self.waypoint_predictor = torch.nn.Linear(sft_model.config.hidden_size, 1)\n",
        "\n",
        "        # Unfreeze language model parameters (important for fine-tuning)\n",
        "        for param in self.sft_model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        outputs = self.sft_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "\n",
        "        # Averaging the last 4 hidden states (or experiment with other numbers)\n",
        "        hidden_states = torch.stack(outputs.hidden_states[-4:]).mean(0)[:, 0, :]\n",
        "\n",
        "        predicted_numberofwaypoints = self.waypoint_predictor(hidden_states)\n",
        "\n",
        "        return predicted_numberofwaypoints\n",
        "\n",
        "\n",
        "    def predict_numberofwaypoints(self, input_text):\n",
        "        encoding = self.sft_tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        input_ids = encoding[\"input_ids\"].to(self.sft_model.device)\n",
        "        attention_mask = encoding[\"attention_mask\"].to(self.sft_model.device)\n",
        "        with torch.no_grad():\n",
        "            predicted_numberofwaypoints = self.forward(input_ids, attention_mask)\n",
        "        return predicted_numberofwaypoints.item()"
      ],
      "metadata": {
        "id": "8oma87Dyh5Cp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "#print(\"\\n--- 3. Distillation ---\")\n",
        "\n",
        "#from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Load Teacher Model\n",
        "sft_model = AutoModelForCausalLM.from_pretrained(\"./sft_reasoning_model\")\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(\"./sft_reasoning_model\")\n",
        "teacher_model = RLAgent(sft_model, sft_tokenizer).to(device) # assuming 'device' is defined as before\n",
        "teacher_tokenizer = AutoTokenizer.from_pretrained(\"./sft_reasoning_model\")\n",
        "\n",
        "# Load teacher model weights\n",
        "state_dict = torch.load(\"./fine_tuned_rl_agent.pth\", map_location=device)  # Load on the same device\n",
        "teacher_model.load_state_dict(state_dict)\n",
        "teacher_model.eval()  # Set to evaluation mode\n",
        "\n",
        "# 2. Define Student Model\n",
        "#student_model_name = \"bert-base-uncased\"\n",
        "#student_model_name = \"distilbert-base-uncased\"  # Smaller than bert-base-uncased\n",
        "#student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
        "#student_model = torch.nn.Linear(student_tokenizer.vocab_size, teacher_tokenizer.vocab_size).to(device)\n",
        "#student_model.train()\n",
        "\n",
        "# 2. Define Student Model\n",
        "# Use a smaller, pre-trained model as the student model\n",
        "student_model_name = \"distilbert-base-uncased\"  # Smaller than bert-base-uncased\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
        "student_model = AutoModel.from_pretrained(student_model_name).to(device)\n",
        "student_model.train()\n",
        "\n",
        "\n",
        "# Add a linear layer on top for prediction\n",
        "hidden_size = student_model.config.hidden_size\n",
        "output_size = 1  # For waypoint prediction\n",
        "prediction_layer = torch.nn.Linear(hidden_size, output_size).to(device)\n",
        "prediction_layer.train()\n",
        "\n",
        "\n",
        "# 3. Distillation Data\n",
        "distill_data = [\n",
        "    'Input: Calculate the waypoints from MBJ to AMS. Departure: 2024-04-19, Aircraft: Boeing 747, Weather: Stormy',\n",
        "    'Input: Calculate the waypoints from MDW to SJU. Departure: 2024-12-22, Aircraft: Airbus A320, Weather: Snowy',\n",
        "    'Input: Calculate the waypoints from DTW to SEA. Departure: 2024-09-11, Aircraft: Airbus A320, Weather: Partly Cloudy'\n",
        "]\n",
        "\n",
        "# 4. Distillation Loop\n",
        "#distill_optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n",
        "\n",
        "distill_optimizer = torch.optim.AdamW(list(student_model.parameters()) + list(prediction_layer.parameters()), lr=5e-5)\n",
        "distill_epochs = 10"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EaUWsxeXhMUz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "source": [
        "print(\"\\n--- 3. Distillation ---\")\n",
        "for epoch in range(distill_epochs):\n",
        "    total_loss = 0\n",
        "    for text in distill_data:\n",
        "        # Teacher prediction\n",
        "        predicted_waypoints = teacher_model.predict_numberofwaypoints(text)\n",
        "\n",
        "        # Target sequence for distillation (not used for MSE loss)\n",
        "        # teacher_output_text = f\"Predicted Waypoints: {predicted_waypoints}\"\n",
        "        # teacher_target = teacher_tokenizer(teacher_output_text, return_tensors=\"pt\").input_ids.squeeze().to(device)\n",
        "\n",
        "        # Student prediction - Update to use the pre-trained student model and prediction layer\n",
        "        student_input = student_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "        student_outputs = student_model(**student_input)\n",
        "        student_logits = prediction_layer(student_outputs.last_hidden_state[:, 0, :])\n",
        "\n",
        "        # Reshape student_logits to match the target shape (1D tensor with 1 element)\n",
        "        student_logits = student_logits.view(-1)\n",
        "\n",
        "        # Calculate and apply loss (use MSE loss for waypoint prediction)\n",
        "        loss = F.mse_loss(student_logits, torch.tensor([predicted_waypoints], device=device))\n",
        "        distill_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        distill_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Distillation Epoch {epoch+1} Loss: {total_loss / len(distill_data)}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6BB2VqV6rEe",
        "outputId": "74058a5d-2e9d-46ed-df9f-c3da73afb3e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Distillation ---\n",
            "Distillation Epoch 1 Loss: 20.516501744588215\n",
            "Distillation Epoch 2 Loss: 4.883150577545166\n",
            "Distillation Epoch 3 Loss: 0.5096774883568287\n",
            "Distillation Epoch 4 Loss: 0.1139904862890641\n",
            "Distillation Epoch 5 Loss: 0.10458541909853618\n",
            "Distillation Epoch 6 Loss: 0.03858725090685766\n",
            "Distillation Epoch 7 Loss: 0.03599905284045235\n",
            "Distillation Epoch 8 Loss: 0.013790201162919402\n",
            "Distillation Epoch 9 Loss: 0.04426688700914383\n",
            "Distillation Epoch 10 Loss: 0.021623721268648904\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# --- 4. Inference-time Scaling (Using the distilled model in a simple agent) ---\n",
        "print(\"\\n--- 4. Inference-time Scaling with Distilled Model ---\")\n",
        "\n",
        "# Assuming student_model, student_tokenizer, prediction_layer are defined from the Distillation section\n",
        "\n",
        "class SimpleFlightAgent:\n",
        "    def __init__(self, reasoner, prediction_layer, tokenizer, knowledge_base):\n",
        "        self.reasoner = reasoner  # The student model (DistilBERT in this case)\n",
        "        self.prediction_layer = prediction_layer  # The linear layer for prediction\n",
        "        self.tokenizer = tokenizer  # The student tokenizer\n",
        "        self.knowledge = knowledge_base\n",
        "\n",
        "    def plan_flight(self, flight_details):\n",
        "        \"\"\"\n",
        "        Generates a flight plan (number of waypoints) using the distilled model.\n",
        "\n",
        "        Args:\n",
        "            flight_details (str): A string containing flight details\n",
        "                                  in the format:\n",
        "                                  \"Input: Calculate the waypoints from [origin] to [destination].\n",
        "                                  Departure: [date], Aircraft: [aircraft_type], Weather: [weather]\"\n",
        "\n",
        "        Returns:\n",
        "            str: The predicted number of waypoints.\n",
        "        \"\"\"\n",
        "        # Tokenize the flight details prompt\n",
        "        student_input = self.tokenizer(flight_details, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(self.reasoner.device)\n",
        "\n",
        "        # Get the prediction from the student model and prediction layer\n",
        "        with torch.no_grad():  # No need to calculate gradients during inference\n",
        "            student_outputs = self.reasoner(**student_input)\n",
        "            predicted_waypoints = self.prediction_layer(student_outputs.last_hidden_state[:, 0, :])\n",
        "            predicted_waypoints = round(predicted_waypoints.item())\n",
        "\n",
        "        return f\"Predicted number of waypoints: {predicted_waypoints}\"\n",
        "\n",
        "\n",
        "        #return f\"Predicted number of waypoints: {predicted_waypoints.item()}\"\n",
        "\n",
        "# Create an instance of the agent\n",
        "agent_knowledge = {\"flight_info\": \"Direct flights are sometimes available between major cities.\"}\n",
        "flight_agent = SimpleFlightAgent(student_model, prediction_layer, student_tokenizer, agent_knowledge)  # Pass the student model and prediction layer\n",
        "\n",
        "\n",
        "# Example usage\n",
        "data=val_dataset[359]\n",
        "data['input']\n",
        "data['label']\n",
        "flight_plan_text = data['input']\n",
        "actual_numberofwaypoint=data['label']\n",
        "\n",
        "# Define your flight plan text:\n",
        "flight_plan_text = data['input']\n",
        "actual_numberofwaypoint=data['label']\n",
        "flight_details = f\"Input: {flight_plan_text}\"\n",
        "flight_plan = flight_agent.plan_flight(flight_details)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"flight_details: {flight_details}\")\n",
        "print(f\"Number of waypoints: {flight_plan}\")\n",
        "\n",
        "print(\"\\n--- End of Full Sequence ---\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaFp3zQcrqYo",
        "outputId": "744a8f5b-818a-4b76-a4fd-660b1d18f098"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Inference-time Scaling with Distilled Model ---\n",
            "\n",
            "\n",
            "flight_details: Input: Calculate the waypoints from PVG to SJU. Departure: 2024-04-17, Aircraft: Boeing 777, Weather: Rainy\n",
            "Number of waypoints: Predicted number of waypoints: 6\n",
            "\n",
            "--- End of Full Sequence ---\n"
          ]
        }
      ]
    }
  ]
}