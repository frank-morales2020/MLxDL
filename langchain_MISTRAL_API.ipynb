{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuSv+gdvyz2WZkyqIHLIsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/langchain_MISTRAL_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/v0.1/docs/integrations/chat/mistralai/"
      ],
      "metadata": {
        "id": "fhU5a5KgH8fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install mistralai --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNEFwWlYIZRd",
        "outputId": "1074b16a-9e18-453f-f97d-c70ce6d18c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-core langchain-mistralai -q"
      ],
      "metadata": {
        "id": "qQQzdVI0ItWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mistralai\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "import os\n",
        "import colab_env\n",
        "import json\n",
        "\n",
        "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        "client = MistralClient(api_key=api_key)"
      ],
      "metadata": {
        "id": "8_Tazt7eINpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "\n",
        "# If api_key is not passed, default behavior is to use the `MISTRAL_API_KEY` environment variable.\n",
        "llm = ChatMistralAI(api_key=api_key,model_name='open-mixtral-8x7b')\n",
        "\n",
        "messages = [HumanMessage(content=\"knock knock\")]\n",
        "response=llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "DNPHA2CoHpru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2"
      ],
      "metadata": {
        "id": "pH2vnSD2jjp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community -q"
      ],
      "metadata": {
        "id": "FRLhfkD6kLkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"the capital of canada?\")]\n",
        "response = llm(messages)"
      ],
      "metadata": {
        "id": "ghGAau9YmR_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "l_6yuZ7ymnA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "Rtmv1ZpXeQvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "%cd /content/\n",
        "!wget \"https://www.dropbox.com/s/f6bmb19xdg0xedm/paul_graham_essay.txt?dl=1\" -O pg_essay.txt\n",
        "#!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt' -O pg_essay.txt"
      ],
      "metadata": {
        "id": "PMhCRBKveVeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q\n",
        "#!pip install langchain-core -q\n",
        "!pip install langchain-community -q\n",
        "!pip install langchain-anthropic -q"
      ],
      "metadata": {
        "id": "598t6tCqeklJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader('/content/pg_essay.txt')\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "LghxcCC4erDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "78kgSN4Aevvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "id": "WsW6xwC_e3Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu -q\n",
        "!pip install faiss-cpu -q"
      ],
      "metadata": {
        "id": "UzonPfD9e7UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain_community.embeddings import CohereEmbeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "#embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "vector = FAISS.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "ySPrTMRhfCmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# create a chain to answer questions\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
      ],
      "metadata": {
        "id": "Ht_DRR8WfJnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt=\"say something about AI\"\n",
        "prompt=\"What did the author do growing up?\"\n",
        "#formatted_prompt = [HumanMessage(content=\"%s\"%prompt)]\n",
        "formatted_prompt = f\"Instruct: Answer the following question.\\n{prompt}\\n\"\n",
        "result = qa({\"query\": formatted_prompt})"
      ],
      "metadata": {
        "id": "0YJEJurTfOtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "#print('chain to answer questions')\n",
        "print(\"-\" * 80)\n",
        "print()\n",
        "result = qa({\"query\": prompt})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "ClmDCxFBhH5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}