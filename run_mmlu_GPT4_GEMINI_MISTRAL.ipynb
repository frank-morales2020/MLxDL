{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1+M0s6BKy47GdPfNksXNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/run_mmlu_GPT4_GEMINI_MISTRAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/neulab/gemini-benchmark/tree/main"
      ],
      "metadata": {
        "id": "6gyhqLVaa4J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/neulab/gemini-benchmark.git"
      ],
      "metadata": {
        "id": "e1M1jyAlatKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gemini-benchmark/benchmarking"
      ],
      "metadata": {
        "id": "72mnecxXbEC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install litellm -q\n",
        "\n",
        "!pip install colab-env --upgrade -q\n",
        "!pip install openai -q\n",
        "\n",
        "!pip install mistralai --quiet"
      ],
      "metadata": {
        "id": "n3WOBNPbbu17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import colab_env\n",
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "DIWzQcZAj2RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "Ep2anuh1eIhd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "d5G_Gu6zeTGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9hhgxpjbIL",
        "outputId": "44f6181e-cf9c-456b-e873-4e80ab6c3a2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: run_mmlu.py [-h] [--openai_api_key OPENAI_API_KEY]\n",
            "                   [--model_name {gpt-3.5-turbo,gpt-4-1106-preview,gemini-pro,mixtral}] [--cot]\n",
            "                   [--num_examples NUM_EXAMPLES]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --openai_api_key OPENAI_API_KEY\n",
            "  --model_name {gpt-3.5-turbo,gpt-4-1106-preview,gemini-pro,mixtral}\n",
            "  --cot\n",
            "  --num_examples NUM_EXAMPLES\n",
            "                        Number of examples included in the current prompt input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://litellm.vercel.app/docs/exception_mapping"
      ],
      "metadata": {
        "id": "hgsSXbZsmbpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBahsof4DYa4",
        "outputId": "c9ab7b56-6492-4712-e7f4-8d97b65b2589"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Cloud SDK 476.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/compute/docs/regions-zones"
      ],
      "metadata": {
        "id": "4AYibmmqEwlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud init"
      ],
      "metadata": {
        "id": "4W697ejAike8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gcloud info"
      ],
      "metadata": {
        "id": "BwV2KN9sDqz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py"
      ],
      "metadata": {
        "id": "oRCemArMiCAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/gemini-benchmark/benchmarking/MMLU/utils.py"
      ],
      "metadata": {
        "id": "6pMYcMGUwiGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GEMINI\n"
      ],
      "metadata": {
        "id": "KM_aXmmw7WzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GID=1\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GEMINI')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "TpmqgR0j02mK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TASKS = [\n",
        "    \"machine_learning\",\n",
        "    \"college_computer_science\",\n",
        "]\n",
        "print(TASKS)"
      ],
      "metadata": {
        "id": "JWn50cGaou_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecae1519-b62f-4a8a-87c4-b35899b23fbe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['machine_learning', 'college_computer_science']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### GEMINI\n",
        "%rm -rf /content/outputs/\n",
        "%mkdir /content/outputs\n",
        "\n",
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py --model_name gemini-pro --num_examples 5"
      ],
      "metadata": {
        "id": "geeyklfXrsjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1c594c-52bd-4830-db5f-297631fe6270"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing machine_learning ...\n",
            "100% 112/112 [02:04<00:00,  1.11s/it]\n",
            "machine_learning acc 0.4821\n",
            "Testing college_computer_science ...\n",
            "100% 100/100 [02:05<00:00,  1.26s/it]\n",
            "college_computer_science acc 0.4500\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open('/content/outputs/gemini-pro_simple_accs.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "#print('average: %s'%data['all'])\n",
        "print(TASKS)\n",
        "# Check if 'all' key contains a list or dictionary\n",
        "if isinstance(data['all'], (list, dict)):\n",
        "    for value in data['all']:\n",
        "        print(value)\n",
        "else:\n",
        "    # Handle the float value appropriately\n",
        "    print(\"GEMINI-MMLU Average for TWO tasks:\", data['all'])\n",
        "\n",
        "# Closing file\n",
        "f.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGijRiB87Mj5",
        "outputId": "8b5f4836-b276-4079-beb9-7a0b0fb7da1a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['machine_learning', 'college_computer_science']\n",
            "GEMINI-MMLU Average for TWO tasks: 0.4669811320754717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAZZQdEx53VN",
        "outputId": "e46b750d-d74c-4bb5-ed03-313fdafa4250"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine_learning': 0.48214285714285715, 'college_computer_science': 0.45, 'all': 0.4669811320754717}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPENAI"
      ],
      "metadata": {
        "id": "SPEsGdC87afE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%rm -rf /content/outputs/\n",
        "#%mkdir /content/outputs\n",
        "%mkdir -p  /content/data/dev\n",
        "%cd /content/\n",
        "\n",
        "# choose from 'gpt-3.5-turbo', 'gpt-4-1106-preview', 'gemini-pro', 'mixtral'\n",
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py --openai_api_key $OPENAI_API_KEY --model_name gpt-4-1106-preview  --num_examples 5"
      ],
      "metadata": {
        "id": "MZTcpSy9dqEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open('/content/outputs/gpt-4-1106-preview_simple_accs.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "#print('average: %s'%data['all'])\n",
        "print(TASKS)\n",
        "# Check if 'all' key contains a list or dictionary\n",
        "if isinstance(data['all'], (list, dict)):\n",
        "    for value in data['all']:\n",
        "        print(value)\n",
        "else:\n",
        "    # Handle the float value appropriately\n",
        "    print(\"OPENAI-MMLU Average for TWO tasks:\", data['all'])\n",
        "\n",
        "# Closing file\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSAeXeVhE9l2",
        "outputId": "54564ef2-805f-4333-9e1b-41eeed16d60e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['machine_learning', 'college_computer_science']\n",
            "OPENAI-MMLU Average for TWO tasks: 0.7358490566037735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57N6jgAYFFa5",
        "outputId": "46d58913-1dbf-4ae4-dca3-5af6be5fa7d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine_learning': 0.75, 'college_computer_science': 0.72, 'all': 0.7358490566037735}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py"
      ],
      "metadata": {
        "id": "HSiftZeYLCOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MISTRAL"
      ],
      "metadata": {
        "id": "3ok2us7NOUjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing machine_learning ...\n",
        "100% 112/112 [04:18<00:00,  2.31s/it]\n",
        "machine_learning acc 0.5268\n",
        "\n",
        "Testing college_computer_science ...\n",
        "100% 100/100 [08:44<00:00,  5.24s/it]\n",
        "college_computer_science acc 0.3600"
      ],
      "metadata": {
        "id": "90AKkE1djQhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### MIXTRAL\n",
        "%mkdir -p /content/outputs/mistralai/\n",
        "\n",
        "# /content/gemini-benchmark/outputs/MMLU/mixtral\n",
        "\n",
        "### open-mixtral-8x7b ###\n",
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py --model_name mixtral --num_examples 5"
      ],
      "metadata": {
        "id": "8W0RkmPhJdx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "#/content/outputs/mistralai/Mistral-7B-Instruct-v0.1_simple_outputs.json\n",
        "f = open('/content/outputs/mistralai/Mistral-7B-Instruct-v0.1_simple_accs.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "#print('average: %s'%data['all'])\n",
        "print(TASKS)\n",
        "# Check if 'all' key contains a list or dictionary\n",
        "if isinstance(data['all'], (list, dict)):\n",
        "    for value in data['all']:\n",
        "        print(value)\n",
        "else:\n",
        "    # Handle the float value appropriately\n",
        "    print(\"Open-mixtral-8x7b-MMLU Average for TWO tasks:\", data['all'])\n",
        "\n",
        "# Closing file\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pdkCKUPtCDB",
        "outputId": "cfac6deb-068e-44ca-c034-a96a6c82301f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['machine_learning', 'college_computer_science']\n",
            "Open-mixtral-8x7b-MMLU Average for TWO tasks: 0.4339622641509434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqZhwug9tDHX",
        "outputId": "9f0b6633-d241-4793-e37c-6c37fef09917"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine_learning': 0.5178571428571429, 'college_computer_science': 0.34, 'all': 0.4339622641509434}\n"
          ]
        }
      ]
    }
  ]
}