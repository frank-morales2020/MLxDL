{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Mixtral_8x7B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysI7Fhp6dZcb"
      },
      "outputs": [],
      "source": [
        "#https://platform.openai.com/docs/guides/text-generation\n",
        "\n",
        "!pip install gradio --quiet\n",
        "!pip install xformer --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "\n",
        "\n",
        "%pip install openai==0.28  --root-user-action=ignore\n",
        "%pip install tiktoken\n",
        "\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77HXC7IGdvZR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "### T4\n",
        "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "#MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "### A100\n",
        "# https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "MODEL_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "# https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n",
        "#Quantization\n",
        "#Quantization techniques reduces memory and computational costs by representing weights and activations\n",
        "#with lower-precision data types like 8-bit integers (int8). This enables loading larger models you normally wouldn’t\n",
        "#be able to fit into memory, and speeding up inference. Transformers supports the AWQ and GPTQ quantization\n",
        "#algorithms and it supports 8-bit and 4-bit quantization with bitsandbytes.\n",
        "\n",
        "\n",
        "#( load_in_8bit = Falseload_in_4bit = Falsellm_int8_threshold = 6.0llm_int8_skip_modules = Nonellm_int8_enable_fp32_cpu_offload = Falsellm_int8_has_fp16_weight = False\n",
        "#bnb_4bit_compute_dtype = None\n",
        "# bnb_4bit_quant_type = 'fp4'bnb_4bit_use_double_quant = False**kwargs )\n",
        "\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    load_in_8bit_fp32_cpu_offload=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 1024\n",
        "generation_config.temperature = 0.8\n",
        "generation_config.top_p = 0.95\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDhUCRg-eBTn"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "782wTX6DlS2o",
        "outputId": "7a4e79f9-d4ff-4190-99a4-c6494ba15cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Prompt: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  First, let's calculate the total cost of the ice creams. Since each cone costs $1.25 and there are 6 kids, you would pay 6 times $1.25, which equals $7.50. \n",
            "\n",
            "Next, to find out how much money you'd get back after paying with a $10 bill, subtract the total cost from the amount you gave. In this case, it would be $10.00 (the amount of the $10 bill) minus $7.50 (the total cost of the ice creams). \n",
            "\n",
            "Doing this calculation gives you $2.50. So, you would get $2.50 back.\n",
            "\n",
            "Here's the calculation for you:\n",
            "Total cost = Number of kids * Cost per cone\n",
            "= 6 * $1.25\n",
            "= $7.50\n",
            "\n",
            "Money returned = Money paid - Total cost\n",
            "= $10.00 - $7.50\n",
            "= $2.50\n",
            "So, you get $2.50 back.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: who is the President of the USA?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  I don't have real-time capabilities, so the information I provide might be outdated. As of my last update, the President of the United States is Joe Biden. He took office on January 20, 2021. However, I recommend checking the latest sources to confirm, as this information may have changed.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Who won the baseball World Series in 2020? and Who Lost\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  The 2020 baseball World Series was won by the Los Angeles Dodgers. They defeated the Tampa Bay Rays in six games, clinching the title on October 27, 2020. This was the Dodgers' seventh World Series championship in franchise history, and their first since 1988.\n",
            "\n",
            "The Tampa Bay Rays were the losing team in this series. Although they put up a strong fight, they were ultimately unable to overcome the Dodgers and secure the championship. Despite the loss, the Rays had a successful season and made it to the World Series after defeating the New York Yankees and the Houston Astros in the American League playoffs.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: what is the 20.5% of 40?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  To find 20.5% of 40, you can use the following formula:\n",
            "\n",
            "(percentage / 100) × whole = part\n",
            "\n",
            "In this case, the percentage is 20.5 and the whole is 40. Plugging these values into the formula, you get:\n",
            "\n",
            "(20.5 / 100) × 40 = 8.2\n",
            "\n",
            "So, 20.5% of 40 is 8.2.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: As a data scientist, can you explain the concept of regularization in machine learning?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Sure, I'd be happy to explain the concept of regularization in machine learning!\n",
            "\n",
            "Regularization is a technique used in machine learning to prevent overfitting, which occurs when a model learns the noise in the training data and performs poorly on unseen data. This can happen when a model has too many parameters relative to the number of observations, allowing it to fit the training data too closely.\n",
            "\n",
            "Regularization adds a penalty term to the loss function of a model, which encourages the model to have smaller coefficients or weights. This helps to reduce the complexity of the model, and in turn, helps to prevent overfitting.\n",
            "\n",
            "There are two common types of regularization techniques used in machine learning: L1 regularization (also known as Lasso regularization) and L2 regularization (also known as Ridge regularization).\n",
            "\n",
            "L1 regularization adds a penalty term to the loss function that is equal to the absolute value of the magnitude of the coefficients, multiplied by a regularization parameter (also known as the alpha or lambda parameter). This has the effect of shrinking some of the coefficients to zero, which can help to create a sparse model with fewer features.\n",
            "\n",
            "L2 regularization adds a penalty term to the loss function that is equal to the square of the magnitude of the coefficients, multiplied by a regularization parameter. This has the effect of spreading the coefficient values more evenly, and tends to keep all coefficients non-zero.\n",
            "\n",
            "Regularization can be applied to a wide variety of models, including linear regression, logistic regression, and neural networks. The regularization parameter is a hyperparameter that needs to be tuned for each model and dataset.\n",
            "\n",
            "In summary, regularization is a powerful technique for preventing overfitting and improving the generalization performance of machine learning models. By adding a penalty term to the loss function, regularization encourages the model to have smaller coefficients or weights, reducing the complexity of the model and improving its performance on unseen data.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Which country has the most natural lakes? Answer with only the country name.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Canada\n",
            "\n",
            "While it's a common misconception that Russia has the most natural lakes, Canada is the country with the most natural lakes. This is largely due to the vast number of small lakes in its vast territory, as well as the presence of the Great Lakes, which it shares with the United States.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: How AWS has evolved?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Amazon Web Services (AWS) has evolved significantly since its launch in 2006. Here are some key milestones in its evolution:\n",
            "\n",
            "1. Early Services: When AWS was first introduced, it offered a limited set of services, including Simple Storage Service (S3), Simple Queue Service (SQS), and Elastic Compute Cloud (EC2). These services allowed developers to build and host applications in the cloud.\n",
            "2. Expansion of Services: Over time, AWS expanded its portfolio of services to include a wide range of offerings, such as databases (RDS, DynamoDB), machine learning (SageMaker, Comprehend), and analytics (Kinesis, QuickSight). This enabled customers to build increasingly sophisticated applications without having to manage the underlying infrastructure.\n",
            "3. Global Infrastructure: AWS has built a global infrastructure to support its services. Today, it has 81 Availability Zones across 25 geographic regions. This has allowed AWS to offer low-latency services to customers around the world.\n",
            "4. Security and Compliance: As AWS has grown, it has placed a significant emphasis on security and compliance. It has achieved numerous certifications and accreditations, such as SOC 1, SOC 2, and PCI-DSS, and offers a range of security services, such as AWS Identity and Access Management (IAM), and AWS Key Management Service (KMS).\n",
            "5. Partner Ecosystem: AWS has also built a vast ecosystem of partners, including technology companies, consulting firms, and systems integrators. This has allowed AWS to offer a wide range of solutions that are tailored to specific industries and use cases.\n",
            "6. Emerging Technologies: AWS has been quick to embrace emerging technologies, such as artificial intelligence (AI), blockchain, and Internet of Things (IoT). It has introduced a range of services in these areas, such as Amazon SageMaker, Amazon Quantum Ledger Database (QLDB), and AWS IoT Greengrass.\n",
            "\n",
            "Overall, AWS has evolved from a simple set of services to a comprehensive cloud platform that offers a wide range of capabilities. It has also placed a strong emphasis on security, compliance, and partner ecosystem, making it a trusted choice for businesses of all sizes.\n"
          ]
        }
      ],
      "source": [
        "query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query1 = \"who is the President of the USA?\"\n",
        "query2 = \"Who won the baseball World Series in 2020? and Who Lost\"\n",
        "\n",
        "device=\"cuda\"\n",
        "def prompt_completion(query):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"%s\"%query}\n",
        "    ]\n",
        "\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "    #https://stackoverflow.com/questions/69609401/suppress-huggingface-logging-warning-setting-pad-token-id-to-eos-token-id\n",
        "\n",
        "    generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.batch_decode(generated_ids)\n",
        "    print()\n",
        "    print()\n",
        "    result=decoded[0].replace('<s> [INST] %s [/INST]'%query,\"\")\n",
        "    result=result.replace('</s>',\"\")\n",
        "    print('Prompt: %s'%query)\n",
        "    print('-'*80)\n",
        "    print('Answer: %s'%result)\n",
        "\n",
        "prompt_completion(query)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query1)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query2)\n",
        "\n",
        "query3 = \"what is the 20.5% of 40?\"\n",
        "query4 = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "query5 ='Which country has the most natural lakes? Answer with only the country name.'\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query3)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query4)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query5)\n",
        "\n",
        "\n",
        "query6 = \"How AWS has evolved?\"\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query6)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNH/+8zlrWmaa758oSpXHO1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}