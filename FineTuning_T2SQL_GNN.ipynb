{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_T2SQL_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 , L4  IN GOOGLE COLAB\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install datasets trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install mistral_inference -q\n",
        "\n",
        "!pip install trl==0.8.6 -q\n",
        "\n",
        "\n",
        "!pip install torch-geometric -q\n",
        "!pip install sqlparse networkx -q\n",
        "\n",
        "!pip install bitsandbytes -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65JpttRiGxVK",
        "outputId": "40c14671-50fb-45ca-b59b-719be562d19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "#print(access_token_write)\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "     pipeline,\n",
        ")\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "outputs": [],
      "source": [
        "# set device\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtE9TuSMlUEc",
        "outputId": "dea74aff-d53b-494a-d97c-738f6b638b94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapRov3hl4fT",
        "outputId": "8d079324-424e-4237-a7b9-edb77926a8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Mon Jul 15 00:10:57 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              45W / 350W |      5MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDRUVm6oalJQ"
      },
      "source": [
        "MISTRAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gZ0pkdVaIF8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #24 JUNE 2024\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "mistral_model, tokenizer = setup_chat_format(mistral_model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuD2ZqXNSobM"
      },
      "source": [
        "GNN #0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XRo0s6QE-4va",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "0d25ba5d829f421280b49839f85a866f",
            "1bc0b0f012794b0fa3b9b170a67b01c7",
            "ec4ab9d9933140ee8d843b7b325eb9b5",
            "5fd3b1d407a34900a574fab97edd335a",
            "05998e922a0a48d0b56024f782c4b574",
            "d694c09e46694b5da0c5bb4ebcb7e8fe",
            "e0e1140782ab4e808fb1c20d00b8cda1",
            "91646663865c44cba6980f9b71f0f4aa",
            "5a560eba074c4944bb088361121b14f4",
            "47736f19ce504699b9241c877828da3a",
            "ddab0084eecd4b9e8473b48725725e2b"
          ]
        },
        "outputId": "f69ca8b1-2e0a-4a8c-96b3-7c1946166cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting to GNN:   0%|          | 0/1250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d25ba5d829f421280b49839f85a866f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: 1000\n"
          ]
        }
      ],
      "source": [
        "import colab_env\n",
        "import os\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "from huggingface_hub import login\n",
        "#print(access_token_write)\n",
        "login(\n",
        " token=access_token_write,\n",
        " add_to_git_credential=True\n",
        ")\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        " AutoModelForCausalLM,\n",
        " AutoTokenizer,\n",
        " BitsAndBytesConfig,\n",
        " AutoTokenizer,\n",
        " TrainingArguments,\n",
        " pipeline,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# set device\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "mistral_model, tokenizer = setup_chat_format(mistral_model, tokenizer)\n",
        "\n",
        "# GNN\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from torch_geometric.data import Data, Batch # Import Batch here\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool # Import global_mean_pool here\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# 1. Graph Construction\n",
        "def sql_to_graph(question, schema, answer):\n",
        " # TODO: Replace with actual conversion logic (this is the most crucial part)\n",
        " # Example: You might use SQL parsing libraries and heuristics to extract entities and\n",
        " nodes = [\"SELECT\", \"*\", \"FROM\", \"table1\", \"WHERE\", \"column1\", \">\", \"5\"]\n",
        " edges = [(0, 1), (0, 3), (3, 5), (5, 6), (6, 7)]\n",
        " node_features = torch.eye(len(nodes))\n",
        " edge_features = torch.ones(len(edges), 1)\n",
        " # Attempt to convert the answer to an integer. If it fails, assume it's a string and\n",
        " try:\n",
        "  answer_tensor = torch.tensor([int(answer)])\n",
        " except ValueError:\n",
        "  answer_tensor = torch.tensor([0]) # Replace 0 with a suitable default value or e\n",
        " answer_tokens = answer.split()\n",
        " answer_tensor = torch.tensor([0] * len(answer_tokens)) # Replace 0 with appropriate\n",
        " return Data(x=node_features, edge_index=torch.tensor(edges).t().contiguous(), y=answer_tensor, edge_attr=edge_features)\n",
        "\n",
        "class SQLGraphDataset(Dataset):\n",
        " def __init__(self, data):\n",
        "  self.data = data\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        " def __getitem__(self, index):\n",
        "  entry = self.data[index]\n",
        "  question = entry[\"question\"]\n",
        "  schema = entry[\"context\"]\n",
        "  answer = entry[\"answer\"]\n",
        "  return sql_to_graph(question, schema, answer)\n",
        "\n",
        "# 1. Placeholder Conversion Function\n",
        "def convert_to_gnn(dataset):\n",
        " # TODO: Replace with actual conversion logic\n",
        " # This should iterate through the dataset and call sql_to_graph for each entry\n",
        " dataset_gnn = []\n",
        " for i in tqdm(range(len(dataset)), desc=\"Converting to GNN\"):\n",
        "  question = dataset[i][\"question\"]\n",
        "  schema = dataset[i][\"context\"]\n",
        "  answer = dataset[i][\"answer\"]\n",
        "  graph = sql_to_graph(question, schema, answer)\n",
        "  dataset_gnn.append(graph)\n",
        " return dataset_gnn\n",
        "\n",
        "# 2. GNN Model\n",
        "from torch_geometric.nn import GATConv\n",
        "class SQLGNN(torch.nn.Module): # Inherit from torch.nn.Module\n",
        " def __init__(self, input_dim, hidden_dim, output_dim, heads=8):\n",
        "  super(SQLGNN, self).__init__() # Call superclass constructor\n",
        "  self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
        "  self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=0.6)\n",
        "\n",
        " def forward(self, data):\n",
        "  x, edge_index, batch = data.x.to(device), data.edge_index.to(device), data.batch.to(device)  # Move graph data to GPU\n",
        "  x = F.elu(self.conv1(x, edge_index))\n",
        "  x = F.dropout(x, p=0.6, training=self.training)\n",
        "  x = self.conv2(x, edge_index)\n",
        "  x = global_mean_pool(x, batch)  # Global Mean Pooling for graph-level representation\n",
        "  return x\n",
        "\n",
        " # Add this method to explicitly define saving state dictionary\n",
        " def save_state_dict(self, filepath):\n",
        "    torch.save(super().state_dict(), filepath)\n",
        "\n",
        "# 3. Load and Prepare Data\n",
        "dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
        "dataset = dataset.shuffle(seed=42).select(range(1250))\n",
        "\n",
        "# Convert to GNN format\n",
        "dataset_gnn = convert_to_gnn(dataset)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(dataset_gnn))\n",
        "print(f'train size: {train_size}')\n",
        "\n",
        "train_dataset = dataset_gnn[:train_size]\n",
        "val_dataset = dataset_gnn[train_size:]\n",
        "\n",
        "# Define a custom collate function to handle batching of graphs and text data\n",
        "def collate_fn(batch):\n",
        "    graphs = [item for item in batch]\n",
        "    # Since each item is a Data object, extract relevant attributes\n",
        "    # Access the original data from the dataset using the index stored in the Data object\n",
        "    questions = [dataset[i]['question'] for i in range(len(batch))] # Use the index of item in the batch\n",
        "    schemas = [dataset[i]['context'] for i in range(len(batch))]     # Use the index of item in the batch\n",
        "    answers = [item.y for item in batch]\n",
        "\n",
        "    # Batch the graphs and return\n",
        "    return Batch.from_data_list(graphs), questions, schemas, answers\n",
        "\n",
        "#train_loader = DataLoader(train_dataset, collate_fn=collate_fn)\n",
        "#val_loader = DataLoader(val_dataset, collate_fn=collate_fn)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "\n",
        "# 4. Initialize Model, Loss, and Optimizer\n",
        "input_dim = train_dataset[0].num_node_features\n",
        "hidden_dim = 64\n",
        "output_dim = 128 # Assuming a generation task for simplicity\n",
        "model = SQLGNN(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# For generation:\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # Ignore padding in loss calculation\n",
        "# For classification:\n",
        "# criterion = torch.nn.BCEWithLogitsLoss() # Or other suitable loss\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# 5. Training and Evaluation Functions\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "tokenizer.padding_side = 'left'\n",
        "import torch.nn.functional as F  # Import F for the loss function\n",
        "\n",
        "def train(model, mistral_model, loader, optimizer, mistral_optimizer, epoch, num_epochs):\n",
        "    model.train()\n",
        "    mistral_model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(loader, total=len(loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for data, questions, schemas, answers in loop:\n",
        "        optimizer.zero_grad()\n",
        "        mistral_optimizer.zero_grad()\n",
        "\n",
        "        # GNN Forward Pass\n",
        "        data = data.to(device) # Move graph data to GPU\n",
        "        graph_embeddings = model(data)  # Get embeddings from GNN\n",
        "\n",
        "        # Prepare Mistral Input\n",
        "        mistral_inputs = [f\"Question: {q}\\nSchema: {s}\\nGraph Embedding: {g}\" for q, s, g in zip(questions, schemas, graph_embeddings)]\n",
        "\n",
        "        # Set padding side to left before tokenizing\n",
        "        tokenizer.padding_side = 'left'\n",
        "\n",
        "        # Tokenize and generate SQL using Mistral, increase max length\n",
        "        tokenized_inputs = tokenizer(mistral_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device) # Increased max_length\n",
        "\n",
        "\n",
        "        # Get logits for loss calculation (instead of generating)\n",
        "        outputs = mistral_model(**tokenized_inputs, labels=tokenized_inputs[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mistral_optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    #Save GNN model - UNCOMMENT THESE LINES\n",
        "    model.save_state_dict(f\"gnn_model_epoch_{epoch+1}.pth\")\n",
        "    print(f\"GNN Model saved to gnn_model_epoch_{epoch+1}.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcr2HeJZe_DE",
        "outputId": "42af558d-f770-48bb-ad2c-d165353e1839"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr7OMzRCf8C_",
        "outputId": "b415f434-3909-4a3b-d89e-f01274a5a32e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, mistral_model, loader, bleu):\n",
        "    model.eval()\n",
        "    mistral_model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, questions, schemas, answers in tqdm(loader, desc=\"Evaluating\"):\n",
        "            graph_embeddings = model(data)\n",
        "\n",
        "            # Prepare Mistral Input\n",
        "            mistral_inputs = [f\"Question: {q}\\nSchema: {s}\\nGraph Embedding: {g}\" for q, s, g in zip(questions, schemas, graph_embeddings)]\n",
        "\n",
        "            # Tokenize and generate SQL using Mistral\n",
        "            tokenized_inputs = tokenizer(mistral_inputs, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            output_sequences = mistral_model.generate(**tokenized_inputs, max_new_tokens=128)  # Generate up to 128 new tokens.\n",
        "            generated_sql = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
        "\n",
        "            predictions.extend(generated_sql)\n",
        "\n",
        "            references.extend(answers)  # Assuming answers are in the correct format for BLEU\n",
        "\n",
        "            decoded_references = []\n",
        "            for ref in references:\n",
        "                # Handle potential empty references and tensors\n",
        "                if ref is not None and isinstance(ref, torch.Tensor):  # Check if ref is a tensor and not None\n",
        "                    ref = ref.tolist()  # Convert tensor to list\n",
        "                if ref and isinstance(ref, list):  # Now check if ref is a non-empty list\n",
        "                    # Ensure ref is a list of integers before decoding\n",
        "                    if all(isinstance(item, int) for item in ref):\n",
        "                        decoded_ref = tokenizer.decode(ref, skip_special_tokens=True)\n",
        "                        decoded_references.append([decoded_ref])  # Wrap decoded reference in a list\n",
        "                    else:\n",
        "                        print(\"Warning: Found a reference that is not a list of integers:\", ref)\n",
        "\n",
        "\n",
        "\n",
        "            # Check if references are empty before BLEU calculation\n",
        "            if predictions and decoded_references and any(ref for ref in decoded_references):  # Check if any reference is non-empty\n",
        "                try:\n",
        "                    bleu_score = bleu.compute(predictions=predictions, references=decoded_references)[\"bleu\"]\n",
        "                    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "                except ZeroDivisionError:\n",
        "                    print(\"ZeroDivisionError encountered during BLEU calculation. Check if references are valid.\")\n",
        "            else:\n",
        "                print(\"No valid predictions or references found for BLEU calculation.\")"
      ],
      "metadata": {
        "id": "PKF_fQ1GWmsq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r0AcjBEStvk"
      },
      "source": [
        "GNN #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "3ed52ae3ee7842babc75189240f8420f",
            "322e12ae07c54f9e8569927125d92275",
            "cb914c2e28984863b1769c6f03913ad8",
            "a553d0b25d3e47dabb46312703e43ff7",
            "9229c056d1fb4316862a0c7becce887e",
            "01c566ff167e43a1809aa1505f872814",
            "953457cd8c184459b573c781ec4dba28",
            "0e38aaf4c7a04d8885624f1fe43c5bd7",
            "9294af12f0044583b49297962453aa63",
            "9df80f0034f64e7994c9622853df23e5",
            "365921f4e14243c6b02bc391da9fa98b",
            "f34d0097366046a99cc25ce588ceeb38",
            "bf37c7a2e32c44d79b658580cc006295",
            "12788bd644dd48f0823ce3e161630664",
            "b03b179bc0f24bf2ad89e2aa53fe289f",
            "6f17d9c40314449695690edde93279a7",
            "a3361dc7cde643be8a4169e6121c797b",
            "6b5199d177d349c3a54d00dd2d956a8c",
            "b35e859db07b43af99c7a73505b70f50",
            "9b93f9cb325c45b8a7646bf17d42f2e1",
            "2a4d6f99f93544d992a5149674f430a3",
            "2ff88a8a739d45229f09a451533a3b1c"
          ]
        },
        "id": "ql82KfJGB5IA",
        "outputId": "00b6e617-a5a0-48a5-da0a-6fda5c550f28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Overall Training Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ed52ae3ee7842babc75189240f8420f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/1:   0%|          | 0/250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f34d0097366046a99cc25ce588ceeb38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Loss: 0.9049\n",
            "/content\n",
            "GNN Model saved to gnn_model_epoch_1.pth\n"
          ]
        }
      ],
      "source": [
        "mistral_optimizer = optim.Adam(mistral_model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 1  # Or your desired number of epochs\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Overall Training Progress\"):\n",
        "    train(model, mistral_model, train_loader, optimizer, mistral_optimizer, epoch, num_epochs)\n",
        "    #evaluate(model, mistral_model, val_loader, bleu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S-aTGJcnhXFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32474a6-c79a-4576-ba9d-bc8f35096ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SQLGNN(\n",
              "  (conv1): GATConv(8, 64, heads=8)\n",
              "  (conv2): GATConv(512, 128, heads=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "%cd /content/\n",
        "model = SQLGNN(input_dim, hidden_dim, output_dim)  # Recreate the model architecture\n",
        "model.load_state_dict(torch.load(f\"/content/gnn_model_epoch_{epoch+1}.pth\"))  # Load the saved parameters\n",
        "model.to(device)  # Move the model to the desired device (e.g., GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERUY1XBEjNxt"
      },
      "outputs": [],
      "source": [
        "# Final Evaluation (using the best model)\n",
        "evaluate(model, mistral_model, val_loader, bleu)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPn8ul7UiZjKP5ZO4cAbc21",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d25ba5d829f421280b49839f85a866f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bc0b0f012794b0fa3b9b170a67b01c7",
              "IPY_MODEL_ec4ab9d9933140ee8d843b7b325eb9b5",
              "IPY_MODEL_5fd3b1d407a34900a574fab97edd335a"
            ],
            "layout": "IPY_MODEL_05998e922a0a48d0b56024f782c4b574"
          }
        },
        "1bc0b0f012794b0fa3b9b170a67b01c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d694c09e46694b5da0c5bb4ebcb7e8fe",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e1140782ab4e808fb1c20d00b8cda1",
            "value": "Converting to GNN: 100%"
          }
        },
        "ec4ab9d9933140ee8d843b7b325eb9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91646663865c44cba6980f9b71f0f4aa",
            "max": 1250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a560eba074c4944bb088361121b14f4",
            "value": 1250
          }
        },
        "5fd3b1d407a34900a574fab97edd335a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47736f19ce504699b9241c877828da3a",
            "placeholder": "​",
            "style": "IPY_MODEL_ddab0084eecd4b9e8473b48725725e2b",
            "value": " 1250/1250 [00:00&lt;00:00, 2684.17it/s]"
          }
        },
        "05998e922a0a48d0b56024f782c4b574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d694c09e46694b5da0c5bb4ebcb7e8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e1140782ab4e808fb1c20d00b8cda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91646663865c44cba6980f9b71f0f4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a560eba074c4944bb088361121b14f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47736f19ce504699b9241c877828da3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddab0084eecd4b9e8473b48725725e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed52ae3ee7842babc75189240f8420f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_322e12ae07c54f9e8569927125d92275",
              "IPY_MODEL_cb914c2e28984863b1769c6f03913ad8",
              "IPY_MODEL_a553d0b25d3e47dabb46312703e43ff7"
            ],
            "layout": "IPY_MODEL_9229c056d1fb4316862a0c7becce887e"
          }
        },
        "322e12ae07c54f9e8569927125d92275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c566ff167e43a1809aa1505f872814",
            "placeholder": "​",
            "style": "IPY_MODEL_953457cd8c184459b573c781ec4dba28",
            "value": "Overall Training Progress: 100%"
          }
        },
        "cb914c2e28984863b1769c6f03913ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e38aaf4c7a04d8885624f1fe43c5bd7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9294af12f0044583b49297962453aa63",
            "value": 1
          }
        },
        "a553d0b25d3e47dabb46312703e43ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9df80f0034f64e7994c9622853df23e5",
            "placeholder": "​",
            "style": "IPY_MODEL_365921f4e14243c6b02bc391da9fa98b",
            "value": " 1/1 [02:01&lt;00:00, 121.21s/it]"
          }
        },
        "9229c056d1fb4316862a0c7becce887e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c566ff167e43a1809aa1505f872814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953457cd8c184459b573c781ec4dba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e38aaf4c7a04d8885624f1fe43c5bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9294af12f0044583b49297962453aa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9df80f0034f64e7994c9622853df23e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365921f4e14243c6b02bc391da9fa98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f34d0097366046a99cc25ce588ceeb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf37c7a2e32c44d79b658580cc006295",
              "IPY_MODEL_12788bd644dd48f0823ce3e161630664",
              "IPY_MODEL_b03b179bc0f24bf2ad89e2aa53fe289f"
            ],
            "layout": "IPY_MODEL_6f17d9c40314449695690edde93279a7"
          }
        },
        "bf37c7a2e32c44d79b658580cc006295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3361dc7cde643be8a4169e6121c797b",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5199d177d349c3a54d00dd2d956a8c",
            "value": "Epoch 1/1: 100%"
          }
        },
        "12788bd644dd48f0823ce3e161630664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35e859db07b43af99c7a73505b70f50",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b93f9cb325c45b8a7646bf17d42f2e1",
            "value": 250
          }
        },
        "b03b179bc0f24bf2ad89e2aa53fe289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a4d6f99f93544d992a5149674f430a3",
            "placeholder": "​",
            "style": "IPY_MODEL_2ff88a8a739d45229f09a451533a3b1c",
            "value": " 250/250 [02:01&lt;00:00,  2.06it/s, loss=0.926]"
          }
        },
        "6f17d9c40314449695690edde93279a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3361dc7cde643be8a4169e6121c797b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5199d177d349c3a54d00dd2d956a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35e859db07b43af99c7a73505b70f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b93f9cb325c45b8a7646bf17d42f2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a4d6f99f93544d992a5149674f430a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff88a8a739d45229f09a451533a3b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}