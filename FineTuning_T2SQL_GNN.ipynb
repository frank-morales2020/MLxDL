{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyONvELiMbtBWprGGQ7NbHTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b603afa3171849d3a9ede5ac7afcfcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_243e77b72be642d69be3c61b431eb42c",
              "IPY_MODEL_f601a456a3ee43f08359a9d54bd5e820",
              "IPY_MODEL_9decbb6d72f64db0a9c9fa18f49a9cce"
            ],
            "layout": "IPY_MODEL_9bb221685a7a44d9b489acb11b8800c4"
          }
        },
        "243e77b72be642d69be3c61b431eb42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052a87e72a9d4ea887ef2bd0c7a9f915",
            "placeholder": "​",
            "style": "IPY_MODEL_7460a40e758f4b6db751e72386e44bf4",
            "value": "Converting to GNN: 100%"
          }
        },
        "f601a456a3ee43f08359a9d54bd5e820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aaf2ecd35cf4dcbb4c67b33f3e9232d",
            "max": 12500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af3fff54eb24f1988316e0902bf5552",
            "value": 12500
          }
        },
        "9decbb6d72f64db0a9c9fa18f49a9cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f4dd2508294489b37a138daf05d277",
            "placeholder": "​",
            "style": "IPY_MODEL_8863ab25bd494fa183c1348e6c485b42",
            "value": " 12500/12500 [00:04&lt;00:00, 2590.15it/s]"
          }
        },
        "9bb221685a7a44d9b489acb11b8800c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052a87e72a9d4ea887ef2bd0c7a9f915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7460a40e758f4b6db751e72386e44bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aaf2ecd35cf4dcbb4c67b33f3e9232d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af3fff54eb24f1988316e0902bf5552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f4dd2508294489b37a138daf05d277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8863ab25bd494fa183c1348e6c485b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa62353dba646cf9984938db5807a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6615784637744cfda74ff3d4291d7b9a",
              "IPY_MODEL_eda005e0b55442048be29671495dd569",
              "IPY_MODEL_36217a790a50481ca377bf60b17dd11a"
            ],
            "layout": "IPY_MODEL_6218d2b39c534211b470c06d70bf12f8"
          }
        },
        "6615784637744cfda74ff3d4291d7b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e2906f0a2d42c7b34f4659eba3f293",
            "placeholder": "​",
            "style": "IPY_MODEL_75bb5bab3c3f45fc92fd40252fc88b18",
            "value": "Overall Training Progress:   0%"
          }
        },
        "eda005e0b55442048be29671495dd569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4456f4e05a5541c48663aebbef6daeb3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec04f3bf56224802a51b91c76be11e33",
            "value": 0
          }
        },
        "36217a790a50481ca377bf60b17dd11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b492d07593843318023e42856c286f1",
            "placeholder": "​",
            "style": "IPY_MODEL_0f467b59810e4cc2abec24a24952d59f",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "6218d2b39c534211b470c06d70bf12f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e2906f0a2d42c7b34f4659eba3f293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bb5bab3c3f45fc92fd40252fc88b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4456f4e05a5541c48663aebbef6daeb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec04f3bf56224802a51b91c76be11e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b492d07593843318023e42856c286f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f467b59810e4cc2abec24a24952d59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6467cdfcc0d349eea67a7d29bdf1edec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de8d7aec56fd4628b5a8ae556cb48c29",
              "IPY_MODEL_18f0f1cbba1049c7bb188ae38382a058",
              "IPY_MODEL_9b0084007cc1415bbe74b697c077c508"
            ],
            "layout": "IPY_MODEL_e956e503771d41ea857daa1e7d7a446c"
          }
        },
        "de8d7aec56fd4628b5a8ae556cb48c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_607aec43d0aa475d9fb9d7cdad661d26",
            "placeholder": "​",
            "style": "IPY_MODEL_8e5afe4168c44d35a1d7a16dcfb117c9",
            "value": "Epoch 1/3:  91%"
          }
        },
        "18f0f1cbba1049c7bb188ae38382a058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35dc35db947248569ae71d5478fc1cef",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce4e8b2d6e1f431587c119170676e4f1",
            "value": 2267
          }
        },
        "9b0084007cc1415bbe74b697c077c508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d1d28e3e244522ac5cb856f31baa16",
            "placeholder": "​",
            "style": "IPY_MODEL_4791b16c9a8149d7bf8de930e8d71ac6",
            "value": " 2267/2500 [18:10&lt;01:51,  2.08it/s, loss=0.875]"
          }
        },
        "e956e503771d41ea857daa1e7d7a446c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607aec43d0aa475d9fb9d7cdad661d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5afe4168c44d35a1d7a16dcfb117c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35dc35db947248569ae71d5478fc1cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4e8b2d6e1f431587c119170676e4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d1d28e3e244522ac5cb856f31baa16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4791b16c9a8149d7bf8de930e8d71ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_T2SQL_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reference document details the process of fine-tuning a Mistral 7B language model using a Graph Neural Network (GNN) to enhance its performance on tasks involving SQL generation from natural language questions and database schemas. The document outlines the following key steps:\n",
        "\n",
        "1.  **Environment Setup:** Installation of necessary libraries (PyTorch, Hugging Face Transformers, FlashAttention, etc.) and setting up access to the Hugging Face model hub.\n",
        "   \n",
        "2.  **Model Loading:** Loading the pre-trained Mistral 7B model and tokenizer, configuring it for 4-bit quantization to reduce memory usage.\n",
        "   \n",
        "3.  **Graph Construction:** Defining functions to convert SQL queries, database schemas, and answers into graph structures suitable for GNN processing. This involves representing elements like SELECT, FROM, WHERE as nodes and their relationships as edges.\n",
        "   \n",
        "4.  **GNN Model:** Creating a GNN model using Graph Attention Networks (GATConv) to process the graph representations of SQL queries and schemas. The GNN aims to learn meaningful embeddings for these graph structures.\n",
        "   \n",
        "5.  **Data Preparation:** Loading the \"b-mc2/sql-create-context\" dataset, converting it into the GNN-compatible graph format, and splitting it into training and validation sets.\n",
        "   \n",
        "6.  **Training and Evaluation:** Fine-tuning the Mistral model using the GNN-generated embeddings as additional input. The training process involves iteratively adjusting the model's parameters to minimize the difference between its predicted SQL queries and the ground truth answers. Evaluation is done using the BLEU metric, which measures the similarity between generated and reference SQL queries."
      ],
      "metadata": {
        "id": "3JjyEB0rmq2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 , L4  IN GOOGLE COLAB\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install datasets trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install mistral_inference -q\n",
        "\n",
        "!pip install trl==0.8.6 -q\n",
        "\n",
        "\n",
        "!pip install torch-geometric -q\n",
        "!pip install sqlparse networkx -q\n",
        "\n",
        "!pip install bitsandbytes -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "#print(access_token_write)\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "65JpttRiGxVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830729f8-671a-4c02-c61d-e5c57fba2ce0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "     pipeline,\n",
        ")\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtE9TuSMlUEc",
        "outputId": "6b287540-36c9-4b16-a2c4-77377a6a4959"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapRov3hl4fT",
        "outputId": "2b3f6f27-3c72-40d8-c0c7-edd1786568e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Sat Jul 13 08:23:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              46W / 400W |      5MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MISTRAL"
      ],
      "metadata": {
        "id": "QDRUVm6oalJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #24 JUNE 2024\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "mistral_model, tokenizer = setup_chat_format(mistral_model, tokenizer)"
      ],
      "metadata": {
        "id": "3gZ0pkdVaIF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN #0"
      ],
      "metadata": {
        "id": "TuD2ZqXNSobM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "from huggingface_hub import login\n",
        "#print(access_token_write)\n",
        "login(\n",
        " token=access_token_write,\n",
        " add_to_git_credential=True\n",
        ")\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        " AutoModelForCausalLM,\n",
        " AutoTokenizer,\n",
        " BitsAndBytesConfig,\n",
        " AutoTokenizer,\n",
        " TrainingArguments,\n",
        " pipeline,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# set device\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "mistral_model, tokenizer = setup_chat_format(mistral_model, tokenizer)\n",
        "\n",
        "# GNN\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from torch_geometric.data import Data, Batch # Import Batch here\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool # Import global_mean_pool here\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# 1. Graph Construction\n",
        "def sql_to_graph(question, schema, answer):\n",
        " # TODO: Replace with actual conversion logic (this is the most crucial part)\n",
        " # Example: You might use SQL parsing libraries and heuristics to extract entities and\n",
        " nodes = [\"SELECT\", \"*\", \"FROM\", \"table1\", \"WHERE\", \"column1\", \">\", \"5\"]\n",
        " edges = [(0, 1), (0, 3), (3, 5), (5, 6), (6, 7)]\n",
        " node_features = torch.eye(len(nodes))\n",
        " edge_features = torch.ones(len(edges), 1)\n",
        " # Attempt to convert the answer to an integer. If it fails, assume it's a string and\n",
        " try:\n",
        "  answer_tensor = torch.tensor([int(answer)])\n",
        " except ValueError:\n",
        "  answer_tensor = torch.tensor([0]) # Replace 0 with a suitable default value or e\n",
        " answer_tokens = answer.split()\n",
        " answer_tensor = torch.tensor([0] * len(answer_tokens)) # Replace 0 with appropriate\n",
        " return Data(x=node_features, edge_index=torch.tensor(edges).t().contiguous(), y=answer_tensor, edge_attr=edge_features)\n",
        "\n",
        "class SQLGraphDataset(Dataset):\n",
        " def __init__(self, data):\n",
        "  self.data = data\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        " def __getitem__(self, index):\n",
        "  entry = self.data[index]\n",
        "  question = entry[\"question\"]\n",
        "  schema = entry[\"context\"]\n",
        "  answer = entry[\"answer\"]\n",
        "  return sql_to_graph(question, schema, answer)\n",
        "\n",
        "# 1. Placeholder Conversion Function\n",
        "def convert_to_gnn(dataset):\n",
        " # TODO: Replace with actual conversion logic\n",
        " # This should iterate through the dataset and call sql_to_graph for each entry\n",
        " dataset_gnn = []\n",
        " for i in tqdm(range(len(dataset)), desc=\"Converting to GNN\"):\n",
        "  question = dataset[i][\"question\"]\n",
        "  schema = dataset[i][\"context\"]\n",
        "  answer = dataset[i][\"answer\"]\n",
        "  graph = sql_to_graph(question, schema, answer)\n",
        "  dataset_gnn.append(graph)\n",
        " return dataset_gnn\n",
        "\n",
        "# 2. GNN Model\n",
        "from torch_geometric.nn import GATConv\n",
        "class SQLGNN(torch.nn.Module):\n",
        " def __init__(self, input_dim, hidden_dim, output_dim, heads=8):\n",
        "  super(SQLGNN, self).__init__()\n",
        "  self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
        "  self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=0.6)\n",
        "\n",
        " def forward(self, data):\n",
        "  x, edge_index, batch = data.x.to(device), data.edge_index.to(device), data.batch.to(device)  # Move graph data to GPU\n",
        "  x = F.elu(self.conv1(x, edge_index))\n",
        "  x = F.dropout(x, p=0.6, training=self.training)\n",
        "  x = self.conv2(x, edge_index)\n",
        "  x = global_mean_pool(x, batch)  # Global Mean Pooling for graph-level representation\n",
        "  return x\n",
        "\n",
        "# 3. Load and Prepare Data\n",
        "dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
        "dataset = dataset.shuffle(seed=42).select(range(12500))\n",
        "# Convert to GNN format\n",
        "dataset_gnn = convert_to_gnn(dataset)\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(dataset_gnn))\n",
        "train_dataset = dataset_gnn[:train_size]\n",
        "val_dataset = dataset_gnn[train_size:]\n",
        "\n",
        "# Define a custom collate function to handle batching of graphs and text data\n",
        "def collate_fn(batch):\n",
        "    graphs = [item for item in batch]\n",
        "    # Since each item is a Data object, extract relevant attributes\n",
        "    # Access the original data from the dataset using the index stored in the Data object\n",
        "    questions = [dataset[i]['question'] for i in range(len(batch))] # Use the index of item in the batch\n",
        "    schemas = [dataset[i]['context'] for i in range(len(batch))]     # Use the index of item in the batch\n",
        "    answers = [item.y for item in batch]\n",
        "\n",
        "    # Batch the graphs and return\n",
        "    return Batch.from_data_list(graphs), questions, schemas, answers\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "\n",
        "# 4. Initialize Model, Loss, and Optimizer\n",
        "input_dim = train_dataset[0].num_node_features\n",
        "hidden_dim = 64\n",
        "output_dim = 128 # Assuming a generation task for simplicity\n",
        "model = SQLGNN(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# For generation:\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # Ignore padding in loss calculation\n",
        "# For classification:\n",
        "# criterion = torch.nn.BCEWithLogitsLoss() # Or other suitable loss\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# 5. Training and Evaluation Functions\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "tokenizer.padding_side = 'left'\n",
        "import torch.nn.functional as F  # Import F for the loss function\n",
        "\n",
        "def train(model, mistral_model, loader, optimizer, mistral_optimizer, epoch, num_epochs):\n",
        "    model.train()\n",
        "    mistral_model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(loader, total=len(loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for data, questions, schemas, answers in loop:\n",
        "        optimizer.zero_grad()\n",
        "        mistral_optimizer.zero_grad()\n",
        "\n",
        "        # GNN Forward Pass\n",
        "        data = data.to(device) # Move graph data to GPU\n",
        "        graph_embeddings = model(data)  # Get embeddings from GNN\n",
        "\n",
        "        # Prepare Mistral Input\n",
        "        mistral_inputs = [f\"Question: {q}\\nSchema: {s}\\nGraph Embedding: {g}\" for q, s, g in zip(questions, schemas, graph_embeddings)]\n",
        "\n",
        "        # Set padding side to left before tokenizing\n",
        "        tokenizer.padding_side = 'left'\n",
        "\n",
        "        # Tokenize and generate SQL using Mistral, increase max length\n",
        "        tokenized_inputs = tokenizer(mistral_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device) # Increased max_length\n",
        "\n",
        "\n",
        "        # Get logits for loss calculation (instead of generating)\n",
        "        outputs = mistral_model(**tokenized_inputs, labels=tokenized_inputs[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mistral_optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    # Save the model at the end of each epoch\n",
        "    save_directory = f\"mistral_gnn_finetuned_epoch_{epoch+1}\"\n",
        "    mistral_model.save_pretrained(save_directory)\n",
        "    print(f\"Mistral Model saved to {save_directory}\")\n",
        "\n",
        "    # Save GNN model\n",
        "    model.save_state_dict(f\"gnn_model_epoch_{epoch+1}.pth\")\n",
        "    print(f\"GNN Model saved to gnn_model_epoch_{epoch+1}.pth\")\n",
        "\n",
        "def evaluate(model, mistral_model, loader, bleu):\n",
        "    model.eval()\n",
        "    mistral_model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, questions, schemas, answers in tqdm(loader, desc=\"Evaluating\"):\n",
        "            graph_embeddings = model(data)\n",
        "\n",
        "            # Prepare Mistral Input\n",
        "            mistral_inputs = [f\"Question: {q}\\nSchema: {s}\\nGraph Embedding: {g}\" for q, s, g in zip(questions, schemas, graph_embeddings)]\n",
        "\n",
        "            # Tokenize and generate SQL using Mistral\n",
        "            tokenized_inputs = tokenizer(mistral_inputs, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            output_sequences = mistral_model.generate(**tokenized_inputs, max_new_tokens=128)  # Generate up to 128 new tokens.\n",
        "            generated_sql = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
        "\n",
        "            predictions.extend(generated_sql)\n",
        "\n",
        "            # Convert answers to a list of strings for BLEU\n",
        "            references.extend([a.tolist() for a in answers])\n",
        "\n",
        "            #references.extend(answers)  # Assuming answers are in the correct format for BLEU\n",
        "\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=references)[\"bleu\"]\n",
        "    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "# ... (Rest of the code for training loop and model saving)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "b603afa3171849d3a9ede5ac7afcfcf3",
            "243e77b72be642d69be3c61b431eb42c",
            "f601a456a3ee43f08359a9d54bd5e820",
            "9decbb6d72f64db0a9c9fa18f49a9cce",
            "9bb221685a7a44d9b489acb11b8800c4",
            "052a87e72a9d4ea887ef2bd0c7a9f915",
            "7460a40e758f4b6db751e72386e44bf4",
            "8aaf2ecd35cf4dcbb4c67b33f3e9232d",
            "1af3fff54eb24f1988316e0902bf5552",
            "07f4dd2508294489b37a138daf05d277",
            "8863ab25bd494fa183c1348e6c485b42"
          ]
        },
        "id": "XRo0s6QE-4va",
        "outputId": "fb5366f0-7200-4e94-ad61-1e6e53eee943"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting to GNN:   0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b603afa3171849d3a9ede5ac7afcfcf3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN #1"
      ],
      "metadata": {
        "id": "9r0AcjBEStvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_optimizer = optim.Adam(mistral_model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 3  # Or your desired number of epochs\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Overall Training Progress\"):\n",
        "    train(model, mistral_model, train_loader, optimizer, mistral_optimizer, epoch, num_epochs)\n",
        "    evaluate(model, mistral_model, val_loader, bleu)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "afa62353dba646cf9984938db5807a19",
            "6615784637744cfda74ff3d4291d7b9a",
            "eda005e0b55442048be29671495dd569",
            "36217a790a50481ca377bf60b17dd11a",
            "6218d2b39c534211b470c06d70bf12f8",
            "55e2906f0a2d42c7b34f4659eba3f293",
            "75bb5bab3c3f45fc92fd40252fc88b18",
            "4456f4e05a5541c48663aebbef6daeb3",
            "ec04f3bf56224802a51b91c76be11e33",
            "5b492d07593843318023e42856c286f1",
            "0f467b59810e4cc2abec24a24952d59f",
            "6467cdfcc0d349eea67a7d29bdf1edec",
            "de8d7aec56fd4628b5a8ae556cb48c29",
            "18f0f1cbba1049c7bb188ae38382a058",
            "9b0084007cc1415bbe74b697c077c508",
            "e956e503771d41ea857daa1e7d7a446c",
            "607aec43d0aa475d9fb9d7cdad661d26",
            "8e5afe4168c44d35a1d7a16dcfb117c9",
            "35dc35db947248569ae71d5478fc1cef",
            "ce4e8b2d6e1f431587c119170676e4f1",
            "86d1d28e3e244522ac5cb856f31baa16",
            "4791b16c9a8149d7bf8de930e8d71ac6"
          ]
        },
        "id": "ql82KfJGB5IA",
        "outputId": "a35ced4c-bf5e-4869-acd5-e7fc0f74f445"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afa62353dba646cf9984938db5807a19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Overall Training Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6467cdfcc0d349eea67a7d29bdf1edec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/3:   0%|          | 0/2500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SQLGNN(input_dim, hidden_dim, output_dim)  # Recreate the model architecture\n",
        "model.load_state_dict(torch.load(f\"gnn_model_epoch_{epoch+1}.pth\"))  # Load the saved parameters\n",
        "model.to(device)  # Move the model to the desired device (e.g., GPU)"
      ],
      "metadata": {
        "id": "S-aTGJcnhXFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Improvements:\n",
        "\n",
        "Model Saving: The GNN model is saved after each epoch.\n",
        "Best Model Selection: The evaluate function now takes an epoch argument and returns the BLEU score. The training loop keeps track of the best epoch based on validation BLEU and loads the corresponding GNN model before the final evaluation.\n",
        "Final Evaluation: After training, the best GNN model is loaded and used for the final evaluation on the validation set."
      ],
      "metadata": {
        "id": "jgpR5EwFjfCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Evaluation (using the best model)\n",
        "evaluate(model, mistral_model, val_loader, bleu, num_epochs)"
      ],
      "metadata": {
        "id": "ERUY1XBEjNxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}