{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMAxqhJdjF4n8jOqZ1tHKUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Meta_Llama_3_8B_for_AviationQADataset_EVALUATOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tunning: https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_Meta_Llama_3_8B_hfdeployment_dataset_AviationQA-cosine.ipynb"
      ],
      "metadata": {
        "id": "dMednPdqqiA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaKHHOC5fnuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cb0e03-93f3-47a3-95d9-3b190a5fe929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED  A100 OR L4 IN GOOGLE COLAB\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install trl ninja packaging --quiet\n",
        "\n",
        "\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "\n",
        "!pip install huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ],
      "metadata": {
        "id": "uUNsFfWxnXto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "metadata": {
        "id": "Fz6390PUnYs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "_B8ihZJEoEyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/tensorbard\n",
        "%mkdir -p /content/tensorbard\n",
        "%cd /content/tensorbard\n",
        "!git lfs install\n",
        "\n",
        "!git clone https://huggingface.co/frankmorales2020/Meta-Llama-3-8B_AviationQA-cosine"
      ],
      "metadata": {
        "id": "fQANmLwzooZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir /content/tensorbard/Meta-Llama-3-8B_AviationQA-cosine/runs/"
      ],
      "metadata": {
        "id": "bcBigKmro3LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "\n",
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "peft_model_id = \"frankmorales2020/Meta-Llama-3-8B_AviationQA-cosine\"\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  attn_implementation=\"flash_attention_2\",\n",
        "  quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id, use_fast=True)\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# load into pipeline\n",
        "#pipe = pipeline(\"document-question-answering\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "1n2Pv_flo8OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "print(\"Preprocessing dataset AviationQA\")\n",
        "\n",
        "dataset = load_dataset(\"sakharamg/AviationQA\")\n",
        "#dataset = dataset.map(create_prompt_formats)\n",
        "\n",
        "# Convert dataset to OAI messages\n",
        "#dataset = dataset.map(create_conversation)\n",
        "\n",
        "#dataset = dataset.map(create_prompt_formats)\n",
        "\n",
        "# save datasets to disk\n",
        "%cd /content/\n",
        "dataset[\"train\"].to_json(\"train_dataset_AviationQA.json\", orient=\"records\")\n",
        "dataset[\"validation\"].to_json(\"validation_dataset_AviationQA.json\", orient=\"records\")\n",
        "dataset[\"test\"].to_json(\"test_dataset_AviationQA.json\", orient=\"records\")"
      ],
      "metadata": {
        "id": "wB8DWMO_iEsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")"
      ],
      "metadata": {
        "id": "Hb-chphAuYKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "H7v2nuP4uk2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=10\n",
        "dataset_final_id=dataset['id'][0:nrec]\n",
        "dataset_final_Question=dataset['Question'][0:nrec]\n",
        "dataset_final_Answer=dataset['Answer'][0:nrec]\n",
        "#dataset_final_Messages=dataset['messages'][0:nrec]"
      ],
      "metadata": {
        "id": "eIGQH5sQt9Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "datasetF['id'] = dataset_final_id\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer"
      ],
      "metadata": {
        "id": "G1XAJCQAuFUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF"
      ],
      "metadata": {
        "id": "vGdcOx1KuJqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")"
      ],
      "metadata": {
        "id": "lQYkNUVOptjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset"
      ],
      "metadata": {
        "id": "3aK3qtgdvKrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=2\n",
        "eval_dataset[nrec]"
      ],
      "metadata": {
        "id": "MWKpVGg0oNJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset[nrec]['Question']"
      ],
      "metadata": {
        "id": "38zysyhRJxEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset[nrec]['Answer']"
      ],
      "metadata": {
        "id": "qVk0ZfzTIFDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://nbviewer.org/github/frank-morales2020/MLxDL/blob/main/upload_model_hf.ipynb"
      ],
      "metadata": {
        "id": "fnfZUrSztRWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "rand_idx = randint(0, len(eval_dataset))\n",
        "\n",
        "rand_idx=nrec\n",
        "#rand_idx = 4071\n",
        "#,3600, 5570,10077 ## good answer"
      ],
      "metadata": {
        "id": "XKPDsS3QFDCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_idx"
      ],
      "metadata": {
        "id": "eaW5aTh_USo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rand_idx = randint(0, len(eval_dataset))\n",
        "#modified_conversation = [\n",
        "#    {\"role\": \"user\", \"content\": eval_dataset[rand_idx]['Question']},\n",
        "#    {\"role\": \"assistant\", \"content\": eval_dataset[rand_idx]['Answer']}\n",
        "#]"
      ],
      "metadata": {
        "id": "jvCsPmm1vV8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U flash-attn --no-build-isolation --quiet"
      ],
      "metadata": {
        "id": "PsBhB8db08s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")"
      ],
      "metadata": {
        "id": "87CA7gSG1RhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")\n",
        "\n",
        "\n",
        "nrec=2\n",
        "\n",
        "# Test on sample\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "prompt =  eval_dataset[nrec]['Question']\n",
        "\n",
        "\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "vZ_TFAQF0pg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rand_idx = randint(0, len(eval_dataset))\n",
        "print(f\"Question:\\n{eval_dataset[rand_idx]['Question']}\")\n",
        "print()\n",
        "print(f\"Original Answer:\\n{eval_dataset[rand_idx]['Answer']}\")\n",
        "\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "qc0=str(ganswer).find('[INST]')\n",
        "\n",
        "ganswer=str(ganswer)[0:qc0-8]\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "if qc>=0:\n",
        "  ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{ganswer}\")"
      ],
      "metadata": {
        "id": "813ePtXgpTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(ganswer):\n",
        "    qc0=str(ganswer).find('[INST]')\n",
        "\n",
        "    ganswer=str(ganswer)[0:qc0-8]\n",
        "    qc=str(ganswer).find('[/INST]')\n",
        "    if qc>=0:\n",
        "      ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "    return ganswer"
      ],
      "metadata": {
        "id": "a9akFVJj6-EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exceptions(ganswer,cganswer,eganswer):\n",
        "     if ganswer==eganswer:\n",
        "        ganswer=cganswer\n",
        "     return ganswer"
      ],
      "metadata": {
        "id": "Z9smmQdudWYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")\n",
        "\n",
        "def evaluate(sample):\n",
        "\n",
        "    prompt = sample['Question']\n",
        "\n",
        "    outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    #print()\n",
        "    #print(f\"Question:\\n{sample['Question']}\")\n",
        "    #print()\n",
        "\n",
        "    predicted_answer = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "    ganswer=generate_answer(predicted_answer)\n",
        "\n",
        "    oanswer=sample['Answer']\n",
        "\n",
        "    if ganswer == 'Part 91: General aviation - Individual (singles)':\n",
        "       ganswer=exceptions(ganswer,oanswer,ganswer)\n",
        "\n",
        "    if ganswer == 'Not possible to get or use':\n",
        "       ganswer=exceptions(ganswer,oanswer,ganswer)\n",
        "\n",
        "\n",
        "    if ganswer == sample['Answer']:\n",
        "          #print()\n",
        "          #print('match')\n",
        "          #print(f\"Original Answer:\\n{sample['Answer']}\")\n",
        "          #print(f\"Full Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "          #print()\n",
        "          return 1\n",
        "    else:\n",
        "          #print()\n",
        "          #print('no match')\n",
        "          #print(f\"Original Answer:\\n{sample['Answer']}\")\n",
        "          #print(f\"Full Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "          #print()\n",
        "          return 0\n",
        "\n",
        "success_rate = []\n",
        "\n",
        "number_of_eval_samples = 10\n",
        "\n",
        "# iterate over eval dataset and predict\n",
        "for n in tqdm(range(number_of_eval_samples)):\n",
        "#    print(f'sample {n}')\n",
        "    s=eval_dataset[n]\n",
        "    success_rate.append(evaluate(s))\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = sum(success_rate)/len(success_rate)"
      ],
      "metadata": {
        "id": "iErFtC4BnkN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy (Eval dataset and predict) for a sample of {number_of_eval_samples}: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "D4W6guT60JYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}