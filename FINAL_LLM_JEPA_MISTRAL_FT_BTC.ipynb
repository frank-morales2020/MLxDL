{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "wWZIrwGLSiGD",
        "PQFjS7d3TE0y",
        "nqXmJ3ecTQQB"
      ],
      "authorship_tag": "ABX9TyNJJIQs/QGBT2Q2Mt/WLKNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6a0c1306a204b528e1088f94be51b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_192f14d5c7a34ae7a326c481cdd36f17",
              "IPY_MODEL_bf9aef53a7824ca8b5214faf0c295bde",
              "IPY_MODEL_536f9c1599d04c709a84bde4c276e097"
            ],
            "layout": "IPY_MODEL_901c75467fdf4f65a0942e9a6f15b9cf"
          }
        },
        "192f14d5c7a34ae7a326c481cdd36f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6843c0393d014ec68457c1c72af503c2",
            "placeholder": "​",
            "style": "IPY_MODEL_8f1eeceebf5842bda2ad9ae85dbbf12d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bf9aef53a7824ca8b5214faf0c295bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c240f845bc34cd9bbb965cebad670c4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6780cb134bf24f1fb1ffe9928b0300f6",
            "value": 2
          }
        },
        "536f9c1599d04c709a84bde4c276e097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119c4b1087f640eb8d6803453f96a771",
            "placeholder": "​",
            "style": "IPY_MODEL_0941febe545841a28a3c6ca48c42897e",
            "value": " 2/2 [00:07&lt;00:00,  3.54s/it]"
          }
        },
        "901c75467fdf4f65a0942e9a6f15b9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6843c0393d014ec68457c1c72af503c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1eeceebf5842bda2ad9ae85dbbf12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c240f845bc34cd9bbb965cebad670c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6780cb134bf24f1fb1ffe9928b0300f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "119c4b1087f640eb8d6803453f96a771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0941febe545841a28a3c6ca48c42897e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4fe5c2b4bbc492bbde5f264d1a6f810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2105b1d456994d27a899cff1c70f4023",
              "IPY_MODEL_13e13fcfe851442f81220bc15d37d471",
              "IPY_MODEL_c4d1a98830b548d8b2f7286ca742ff89"
            ],
            "layout": "IPY_MODEL_832471e47abb4a24b28946976915c429"
          }
        },
        "2105b1d456994d27a899cff1c70f4023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41010794a1ec499fb29656e37d227d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_c54fe810b9624632a5f5d75285cf0706",
            "value": "Tokenizing train samples for LLM-JEPA views: 100%"
          }
        },
        "13e13fcfe851442f81220bc15d37d471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c92a550ef24669857064c4662d75e2",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ebe9cbb966140b2ab96ea31ab83a800",
            "value": 2500
          }
        },
        "c4d1a98830b548d8b2f7286ca742ff89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_035665cc4f1c44cea2261920da1e83f5",
            "placeholder": "​",
            "style": "IPY_MODEL_239407fd14574597b4316d4455165514",
            "value": " 2500/2500 [00:09&lt;00:00, 372.73 examples/s]"
          }
        },
        "832471e47abb4a24b28946976915c429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41010794a1ec499fb29656e37d227d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54fe810b9624632a5f5d75285cf0706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c92a550ef24669857064c4662d75e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebe9cbb966140b2ab96ea31ab83a800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "035665cc4f1c44cea2261920da1e83f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239407fd14574597b4316d4455165514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55816ced0e7a44f58426a6175b3ad386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80957c9e342547b6854ccc793075854a",
              "IPY_MODEL_2926bff2b0004031a8a4be31511faef2",
              "IPY_MODEL_9e322d9d22c5414faa007c221e98b725"
            ],
            "layout": "IPY_MODEL_ebd423343f5646d381d9fd0ec07742d8"
          }
        },
        "80957c9e342547b6854ccc793075854a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2c621978114d1d9794669dc16593ae",
            "placeholder": "​",
            "style": "IPY_MODEL_19b3a32449fd4cf5b978912be1fe55b5",
            "value": "Tokenizing test samples for LLM-JEPA views: 100%"
          }
        },
        "2926bff2b0004031a8a4be31511faef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8aa30182e9c4e418830d7865df4f207",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_898e4877fe1041959852b78d5119536d",
            "value": 500
          }
        },
        "9e322d9d22c5414faa007c221e98b725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382f76af4365405da3077afcb92a8509",
            "placeholder": "​",
            "style": "IPY_MODEL_62d89eb5e8b44dfd855ef103d04bd827",
            "value": " 500/500 [00:01&lt;00:00, 397.18 examples/s]"
          }
        },
        "ebd423343f5646d381d9fd0ec07742d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b2c621978114d1d9794669dc16593ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b3a32449fd4cf5b978912be1fe55b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8aa30182e9c4e418830d7865df4f207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898e4877fe1041959852b78d5119536d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "382f76af4365405da3077afcb92a8509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d89eb5e8b44dfd855ef103d04bd827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d9d3e9a38d45a08d48956337caad8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8f45abfc1db46a5b6a47b89b9d3ff56",
              "IPY_MODEL_7eb401b7873244fcb46f357509edef09",
              "IPY_MODEL_590553078cc54f08a28b70ddf6493354"
            ],
            "layout": "IPY_MODEL_3f3705abc9cd4880b84bf492596e181e"
          }
        },
        "f8f45abfc1db46a5b6a47b89b9d3ff56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ef7f9d0dba465e986672fbcdae1626",
            "placeholder": "​",
            "style": "IPY_MODEL_6cafd61f217f4b1db44465a59cf44709",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "7eb401b7873244fcb46f357509edef09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_826e39ccb6f743afa8a68c45421a25cf",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_251518b08580465dba461095178a5f43",
            "value": 2500
          }
        },
        "590553078cc54f08a28b70ddf6493354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5619c5fe80bb4b87a2c8e81c2f1d92a7",
            "placeholder": "​",
            "style": "IPY_MODEL_edc3a68ee1054786bacab309b758e88c",
            "value": " 2500/2500 [00:00&lt;00:00, 11300.13 examples/s]"
          }
        },
        "3f3705abc9cd4880b84bf492596e181e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ef7f9d0dba465e986672fbcdae1626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cafd61f217f4b1db44465a59cf44709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "826e39ccb6f743afa8a68c45421a25cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251518b08580465dba461095178a5f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5619c5fe80bb4b87a2c8e81c2f1d92a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc3a68ee1054786bacab309b758e88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c9b10bc6514480983ce03519593be49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f02a2419787459a87e8e6f10ca2f9e4",
              "IPY_MODEL_cef1509b6e604c87805e88275dc2554f",
              "IPY_MODEL_af7e13018cc14fac8a09a0367b181b86"
            ],
            "layout": "IPY_MODEL_08073054dd9a446682a6c0dad32c5754"
          }
        },
        "0f02a2419787459a87e8e6f10ca2f9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d8afe2e8a24cb7ba232c7604f20ec9",
            "placeholder": "​",
            "style": "IPY_MODEL_e4c6fed276eb4a2b8530f9047e968060",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "cef1509b6e604c87805e88275dc2554f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928776d3ce2e48308bc22b5148361f1f",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c682c6bfd0f546f89d09d635241f941a",
            "value": 500
          }
        },
        "af7e13018cc14fac8a09a0367b181b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fc78fefe0f49a294a7f4d028a6c9db",
            "placeholder": "​",
            "style": "IPY_MODEL_13c33d9f5f044d6db5e08bd4cd5f5d43",
            "value": " 500/500 [00:00&lt;00:00, 8529.10 examples/s]"
          }
        },
        "08073054dd9a446682a6c0dad32c5754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d8afe2e8a24cb7ba232c7604f20ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c6fed276eb4a2b8530f9047e968060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "928776d3ce2e48308bc22b5148361f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c682c6bfd0f546f89d09d635241f941a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33fc78fefe0f49a294a7f4d028a6c9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c33d9f5f044d6db5e08bd4cd5f5d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FINAL_LLM_JEPA_MISTRAL_FT_BTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlzcPp_ElvKq",
        "outputId": "31daf692-9a87-4c74-b838-917c8d77490d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  7 13:34:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   48C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. ENVIRONMENT SETUP AND DEPENDENCY INSTALLATION ---\n",
        "print(\"\\n--- Installing dependencies and cleaning environment ---\")\n",
        "!pip cache purge\n",
        "!rm -rf /root/.cache/huggingface/* /root/.cache/pip/* /tmp/*\n",
        "!pip uninstall -y transformers peft bitsandbytes accelerate trl datasets pandas pandas_ta huggingface_hub quanto triton numpy scipy scikit-learn torch\n",
        "!pip install -q -U numpy==1.26.4\n",
        "!pip install -q -U scipy==1.14.1\n",
        "!pip install -q -U scikit-learn==1.5.1\n",
        "!pip install -q -U torch==2.3.0\n",
        "!pip install -q -U transformers==4.44.2\n",
        "!pip install -q -U peft==0.12.0\n",
        "!pip install -q -U bitsandbytes==0.43.3\n",
        "!pip install -q -U accelerate==0.34.2\n",
        "!pip install -q -U trl==0.11.1\n",
        "!pip install -q -U huggingface_hub==0.25.1\n",
        "!pip install -q -U quanto==0.2.0\n",
        "!pip install -q -U datasets==3.0.1\n",
        "!pip install -q -U triton==2.3.0\n",
        "!pip install -q -U pandas pandas_ta"
      ],
      "metadata": {
        "id": "nNM1CxFeHhUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga3oCA9ehutz",
        "outputId": "e7638218-ecf8-4cc2-a061-84768d2a0a73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/CryptoFT/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVJJ5I2FK_Fc",
        "outputId": "7b9d5b50-27e6-4fce-d0b3-120f2813951e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "btc_instruction_dataset.jsonl  temp_tokenized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h /\n",
        "!du -sh /root/.cache/huggingface/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuAy4D-51KRb",
        "outputId": "54734d2d-1d00-44e3-d8ab-8c85ce8f9b04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         236G   49G  188G  21% /\n",
            "du: cannot access '/root/.cache/huggingface/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--- CLEAN UP TEMPORARY STORAGE ---\n",
        "print(\"\\n--- Cleaning up temporary storage ---\")\n",
        "!rm -rf /root/.cache/huggingface/*\n",
        "!rm -rf /tmp/*\n",
        "print(\"✅ Temporary storage cleared.\")"
      ],
      "metadata": {
        "id": "6Oo_7RHC5M5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aef670-06df-429c-c4f7-85c800360f2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaning up temporary storage ---\n",
            "rm: cannot remove '/tmp/colab_runtime.sock': Device or resource busy\n",
            "✅ Temporary storage cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "access_token_write = userdata.get('HF_TOKEN')\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPVYKpBrQCWU",
        "outputId": "39927974-8ffa-4c8d-d7d9-0461c29e3436"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL-BASE"
      ],
      "metadata": {
        "id": "cIO8dphFSTjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FULL CODE: TRAINING + DEPLOYMENT + EVALUATION FOR MISTRAL-7B-BTC-JEPA-LLM-EXPERT ---\n",
        "\n",
        "# --- 1. IMPORTS AND CUSTOM CLASSES ---\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from huggingface_hub import login, HfApi, create_repo\n",
        "from huggingface_hub.utils import RepositoryNotFoundError\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# --- LLM-JEPA CONFIGURATION ---\n",
        "LLM_JEPA_CONFIG = {\n",
        "    \"lbd\": 2.0,               # Lambda (JEPA loss weight)\n",
        "    \"gamma\": 1.0,             # Gamma (LLM loss weight)\n",
        "    \"predictors\": 3,          # k (Number of predictor tokens)\n",
        "    \"last_token\": -1,         # Index of last token for embedding (typically EOS/</s> or -1)\n",
        "}\n",
        "SPECIAL_PREDICTOR_TOKENS = [f\"<|predictor_{i}|>\" for i in range(1, LLM_JEPA_CONFIG[\"predictors\"] + 1)]\n",
        "\n",
        "# --- FILE PATHS ---\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
        "DATASET_PATH = \"/content/gdrive/MyDrive/CryptoFT/dataset/btc_instruction_dataset.jsonl\"\n",
        "OUTPUT_DIR = \"/content/gdrive/MyDrive/CryptoFT/models/results_btc_jepa\"\n",
        "FINAL_MODEL_DIR = \"/content/gdrive/MyDrive/CryptoFT/models/Mistral-7B-BTC-JEPA_FINAL\"\n",
        "HUB_MODEL_ID = \"frankmorales2020/Mistral-7B-BTC-JEPA-LLM-Expert\"\n",
        "MAX_SEQ_LENGTH = 1024\n",
        "TEMP_DATASET_DIR = \"/content/gdrive/MyDrive/CryptoFT/dataset/temp_tokenized\"\n",
        "\n",
        "# --- UTILITIES ---\n",
        "def get_messages_from_sample(sample_text):\n",
        "    \"\"\"Parses the Mistral template: '<s>[INST] Instruction [/INST] Response</s>'\"\"\"\n",
        "    inst_match = re.search(r\"\\[INST\\](.*?)\\[/INST\\]\", sample_text, re.DOTALL)\n",
        "    user_content = inst_match.group(1).strip() if inst_match else \"\"\n",
        "    resp_match = re.search(r\"\\[/INST\\](.*?)\\s*</s>\", sample_text, re.DOTALL)\n",
        "    assistant_content = resp_match.group(1).strip() if resp_match else \"\"\n",
        "    return {\"user_content\": user_content, \"assistant_content\": assistant_content}\n",
        "\n",
        "# --- CUSTOM DATA COLLATOR ---\n",
        "class CustomJEPABatchCollator:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.keys = [\n",
        "            \"input_ids\", \"labels\", \"attention_mask\",\n",
        "            \"input_ids_user\", \"labels_user\", \"attention_mask_user\",\n",
        "            \"input_ids_assistant\", \"labels_assistant\", \"attention_mask_assistant\"\n",
        "        ]\n",
        "\n",
        "    def __call__(self, features):\n",
        "        batch = {key: [] for key in self.keys}\n",
        "        if not features or not any(features):\n",
        "            return None\n",
        "        for feature in features:\n",
        "            if all(key in feature for key in self.keys):\n",
        "                for key in self.keys:\n",
        "                    batch[key].append(feature[key])\n",
        "        if not any(batch.values()):\n",
        "            return None\n",
        "        for key in self.keys:\n",
        "            if not batch[key]:\n",
        "                raise ValueError(f\"No valid samples for key '{key}' in batch. Check dataset tokenization.\")\n",
        "            batch[key] = torch.LongTensor(batch[key])\n",
        "        return batch\n",
        "\n",
        "# --- CUSTOM TRAINER ---\n",
        "class RepresentationTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.lbd = kwargs.pop('lbd', 1.0)\n",
        "        self.gamma = kwargs.pop('gamma', 1.0)\n",
        "        self.last_token = kwargs.pop('last_token', -1)\n",
        "        self._last_metrics = {}  # Store metrics for logging\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.args.per_device_train_batch_size,\n",
        "            collate_fn=self.data_collator,\n",
        "            shuffle=False,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "    def get_eval_dataloader(self, eval_dataset=None):\n",
        "        dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.args.per_device_eval_batch_size,\n",
        "            collate_fn=self.data_collator,\n",
        "            shuffle=False,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "    def _last_token_index(self, input_ids, attention_mask):\n",
        "        last_indices = torch.sum(attention_mask, dim=1) + self.last_token\n",
        "        return torch.clamp(last_indices, min=0)\n",
        "\n",
        "    def forward(self, model, inputs):\n",
        "        batch_size = inputs[\"input_ids\"].shape[0]\n",
        "        llm_inputs = {\n",
        "            \"input_ids\": torch.cat([inputs[\"input_ids\"], inputs[\"input_ids_user\"], inputs[\"input_ids_assistant\"]], dim=0),\n",
        "            \"labels\": torch.cat([inputs[\"labels\"], inputs[\"labels_user\"], inputs[\"labels_assistant\"]], dim=0),\n",
        "            \"attention_mask\": torch.cat([inputs[\"attention_mask\"], inputs[\"attention_mask_user\"], inputs[\"attention_mask_assistant\"]], dim=0),\n",
        "        }\n",
        "        with torch.enable_grad():\n",
        "            outputs = model(**llm_inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[-1].requires_grad_(True)\n",
        "        user_hidden_states = hidden_states[batch_size: batch_size * 2]\n",
        "        assistant_hidden_states = hidden_states[batch_size * 2:]\n",
        "        return {\n",
        "            'main_outputs': outputs,\n",
        "            'user_hidden_states': user_hidden_states,\n",
        "            'assistant_hidden_states': assistant_hidden_states,\n",
        "        }\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        batch_size = inputs[\"input_ids\"].shape[0]\n",
        "        index_user = self._last_token_index(inputs[\"input_ids_user\"], inputs[\"attention_mask_user\"])\n",
        "        index_assistant = self._last_token_index(inputs[\"input_ids_assistant\"], inputs[\"attention_mask_assistant\"])\n",
        "        forward_results = self.forward(model, inputs)\n",
        "        lm_loss = forward_results['main_outputs'].loss\n",
        "        user_hidden_states = forward_results['user_hidden_states']\n",
        "        assistant_hidden_states = forward_results['assistant_hidden_states']\n",
        "        user_embedding = user_hidden_states[range(batch_size), index_user, :]\n",
        "        assistant_embedding = assistant_hidden_states[range(batch_size), index_assistant, :]\n",
        "        cosine_similarity = F.cosine_similarity(user_embedding, assistant_embedding, dim=-1)\n",
        "        jepa_loss = 1.0 - torch.mean(cosine_similarity)\n",
        "        total_loss = self.gamma * lm_loss + self.lbd * jepa_loss\n",
        "        self._last_metrics = {'jepa_loss': jepa_loss, 'lm_loss': lm_loss}\n",
        "\n",
        "        # FIXED: Return only loss tensor for training, metrics are stored separately\n",
        "        if return_outputs:\n",
        "            return (total_loss, forward_results['main_outputs'])\n",
        "        return total_loss\n",
        "\n",
        "    def log(self, logs):\n",
        "        if self._last_metrics:\n",
        "            logs[\"jepa_loss\"] = self._nested_gather(self._last_metrics[\"jepa_loss\"]).mean().item()\n",
        "            logs[\"lm_loss\"] = self._nested_gather(self._last_metrics[\"lm_loss\"]).mean().item()\n",
        "        super().log(logs)\n",
        "\n",
        "# --- 2. MODEL AND DATASET SETUP ---\n",
        "print(\"\\n--- Setting up model and dataset ---\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DATASET_DIR, exist_ok=True)\n",
        "\n",
        "# Clear any existing dataset cache\n",
        "if os.path.exists(TEMP_DATASET_DIR):\n",
        "    shutil.rmtree(TEMP_DATASET_DIR)\n",
        "os.makedirs(TEMP_DATASET_DIR, exist_ok=True)\n",
        "\n",
        "# PEFT (LoRA) Config\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        ")\n",
        "\n",
        "\n",
        "# Training Arguments - OPTIMIZED FOR JEPA MONITORING\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    save_steps=0,  # Disable saving during demo\n",
        "    logging_steps=50,  # See JEPA metrics every 10 steps\n",
        "    max_steps=500,  # Just enough to see JEPA loss decreasing\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    disable_tqdm=False,\n",
        "    report_to=\"none\",\n",
        "    # ↓↓↓ CRITICAL CHANGES FOR DEMO ↓↓↓\n",
        "    evaluation_strategy=\"no\",  # Disable evaluation during training\n",
        "    eval_steps=None,  # No evaluation steps\n",
        "    metric_for_best_model=None,  # Not needed for demo\n",
        "    # ↑↑↑ CRITICAL CHANGES FOR DEMO ↑↑↑\n",
        "    dataloader_drop_last=True,\n",
        "    dataloader_num_workers=0,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    resume_from_checkpoint=True\n",
        ")\n",
        "\n",
        "# Load Model with Quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\": SPECIAL_PREDICTOR_TOKENS})\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = get_peft_model(model, peft_config)\n",
        "for name, param in model.named_parameters():\n",
        "    if \"lora\" in name:\n",
        "        param.requires_grad = True\n",
        "print(\"✅ PEFT (LoRA) configuration applied\")\n",
        "\n",
        "# Load and Prepare Dataset\n",
        "print(\"\\n--- Loading and Splitting Custom Dataset ---\")\n",
        "dataset = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n",
        "\n",
        "# Filter malformed samples\n",
        "def filter_valid_samples(example):\n",
        "    text = example[\"text\"]\n",
        "    parsed = get_messages_from_sample(text)\n",
        "    valid = bool(parsed[\"user_content\"] and parsed[\"assistant_content\"])\n",
        "    if not valid:\n",
        "        print(f\"Skipping malformed sample: {text[:50]}...\")\n",
        "    return valid\n",
        "\n",
        "filtered_dataset = dataset.filter(filter_valid_samples, desc=\"Filtering valid samples\")\n",
        "if len(filtered_dataset) < 3000:\n",
        "    raise ValueError(f\"Filtered dataset has {len(filtered_dataset)} samples, need at least 3000 for 2500 train + 500 eval.\")\n",
        "print(f\"Filtered dataset size: {len(filtered_dataset)} samples\")\n",
        "\n",
        "# Select 2500 for train, 500 for eval\n",
        "train_dataset = filtered_dataset.select(range(2500))\n",
        "test_dataset = filtered_dataset.select(range(2500, 3000))\n",
        "tokenized_dataset = {\"train\": train_dataset, \"test\": test_dataset}\n",
        "\n",
        "def tokenize_jepa_views(example):\n",
        "    sample_text = example[\"text\"]\n",
        "    parsed = get_messages_from_sample(sample_text)\n",
        "    predictor_str = \"\".join(SPECIAL_PREDICTOR_TOKENS)\n",
        "    user_text_with_pred = f\"<s>[INST] {parsed['user_content']} {predictor_str} [/INST]\"\n",
        "    assistant_text = f\"{parsed['assistant_content']}</s>\"\n",
        "    tokenized_full = tokenizer(sample_text, truncation=True, max_length=MAX_SEQ_LENGTH, padding=\"max_length\", return_tensors=\"np\")\n",
        "    tokenized_user = tokenizer(user_text_with_pred, truncation=True, max_length=MAX_SEQ_LENGTH, padding=\"max_length\", return_tensors=\"np\")\n",
        "    tokenized_assistant = tokenizer(assistant_text, truncation=True, max_length=MAX_SEQ_LENGTH, padding=\"max_length\", return_tensors=\"np\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": tokenized_full[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask\": tokenized_full[\"attention_mask\"][0].tolist(),\n",
        "        \"labels\": tokenized_full[\"input_ids\"][0].copy().tolist(),\n",
        "        \"input_ids_user\": tokenized_user[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask_user\": tokenized_user[\"attention_mask\"][0].tolist(),\n",
        "        \"labels_user\": [-100] * MAX_SEQ_LENGTH,\n",
        "        \"input_ids_assistant\": tokenized_assistant[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask_assistant\": tokenized_assistant[\"attention_mask\"][0].tolist(),\n",
        "        \"labels_assistant\": [-100] * MAX_SEQ_LENGTH\n",
        "    }\n",
        "\n",
        "# Tokenize and save to disk to avoid caching issues\n",
        "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].map(\n",
        "    tokenize_jepa_views,\n",
        "    batched=False,\n",
        "    remove_columns=[\"text\"],\n",
        "    desc=\"Tokenizing train samples for LLM-JEPA views\",\n",
        "    load_from_cache_file=False\n",
        ")\n",
        "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(\n",
        "    tokenize_jepa_views,\n",
        "    batched=False,\n",
        "    remove_columns=[\"text\"],\n",
        "    desc=\"Tokenizing test samples for LLM-JEPA views\",\n",
        "    load_from_cache_file=False\n",
        ")\n",
        "tokenized_dataset[\"train\"].save_to_disk(os.path.join(TEMP_DATASET_DIR, \"train\"))\n",
        "tokenized_dataset[\"test\"].save_to_disk(os.path.join(TEMP_DATASET_DIR, \"test\"))\n",
        "\n",
        "# Reload dataset to ensure consistency\n",
        "from datasets import load_from_disk\n",
        "tokenized_dataset = {\n",
        "    \"train\": load_from_disk(os.path.join(TEMP_DATASET_DIR, \"train\")),\n",
        "    \"test\": load_from_disk(os.path.join(TEMP_DATASET_DIR, \"test\"))\n",
        "}\n"
      ],
      "metadata": {
        "id": "oK4rulypCq82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "c6a0c1306a204b528e1088f94be51b3d",
            "192f14d5c7a34ae7a326c481cdd36f17",
            "bf9aef53a7824ca8b5214faf0c295bde",
            "536f9c1599d04c709a84bde4c276e097",
            "901c75467fdf4f65a0942e9a6f15b9cf",
            "6843c0393d014ec68457c1c72af503c2",
            "8f1eeceebf5842bda2ad9ae85dbbf12d",
            "6c240f845bc34cd9bbb965cebad670c4",
            "6780cb134bf24f1fb1ffe9928b0300f6",
            "119c4b1087f640eb8d6803453f96a771",
            "0941febe545841a28a3c6ca48c42897e",
            "c4fe5c2b4bbc492bbde5f264d1a6f810",
            "2105b1d456994d27a899cff1c70f4023",
            "13e13fcfe851442f81220bc15d37d471",
            "c4d1a98830b548d8b2f7286ca742ff89",
            "832471e47abb4a24b28946976915c429",
            "41010794a1ec499fb29656e37d227d6e",
            "c54fe810b9624632a5f5d75285cf0706",
            "59c92a550ef24669857064c4662d75e2",
            "7ebe9cbb966140b2ab96ea31ab83a800",
            "035665cc4f1c44cea2261920da1e83f5",
            "239407fd14574597b4316d4455165514",
            "55816ced0e7a44f58426a6175b3ad386",
            "80957c9e342547b6854ccc793075854a",
            "2926bff2b0004031a8a4be31511faef2",
            "9e322d9d22c5414faa007c221e98b725",
            "ebd423343f5646d381d9fd0ec07742d8",
            "9b2c621978114d1d9794669dc16593ae",
            "19b3a32449fd4cf5b978912be1fe55b5",
            "b8aa30182e9c4e418830d7865df4f207",
            "898e4877fe1041959852b78d5119536d",
            "382f76af4365405da3077afcb92a8509",
            "62d89eb5e8b44dfd855ef103d04bd827",
            "c0d9d3e9a38d45a08d48956337caad8f",
            "f8f45abfc1db46a5b6a47b89b9d3ff56",
            "7eb401b7873244fcb46f357509edef09",
            "590553078cc54f08a28b70ddf6493354",
            "3f3705abc9cd4880b84bf492596e181e",
            "13ef7f9d0dba465e986672fbcdae1626",
            "6cafd61f217f4b1db44465a59cf44709",
            "826e39ccb6f743afa8a68c45421a25cf",
            "251518b08580465dba461095178a5f43",
            "5619c5fe80bb4b87a2c8e81c2f1d92a7",
            "edc3a68ee1054786bacab309b758e88c",
            "4c9b10bc6514480983ce03519593be49",
            "0f02a2419787459a87e8e6f10ca2f9e4",
            "cef1509b6e604c87805e88275dc2554f",
            "af7e13018cc14fac8a09a0367b181b86",
            "08073054dd9a446682a6c0dad32c5754",
            "66d8afe2e8a24cb7ba232c7604f20ec9",
            "e4c6fed276eb4a2b8530f9047e968060",
            "928776d3ce2e48308bc22b5148361f1f",
            "c682c6bfd0f546f89d09d635241f941a",
            "33fc78fefe0f49a294a7f4d028a6c9db",
            "13c33d9f5f044d6db5e08bd4cd5f5d43"
          ]
        },
        "outputId": "32a30c54-539e-4200-ceb8-3baebe77be9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "--- Setting up model and dataset ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6a0c1306a204b528e1088f94be51b3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PEFT (LoRA) configuration applied\n",
            "\n",
            "--- Loading and Splitting Custom Dataset ---\n",
            "Filtered dataset size: 89685 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train samples for LLM-JEPA views:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4fe5c2b4bbc492bbde5f264d1a6f810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing test samples for LLM-JEPA views:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55816ced0e7a44f58426a6175b3ad386"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0d9d3e9a38d45a08d48956337caad8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c9b10bc6514480983ce03519593be49"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET"
      ],
      "metadata": {
        "id": "wWZIrwGLSiGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate all samples in dataset\n",
        "print(\"\\n--- Validating Dataset Keys ---\")\n",
        "required_keys = [\n",
        "    \"input_ids\", \"labels\", \"attention_mask\",\n",
        "    \"input_ids_user\", \"labels_user\", \"attention_mask_user\",\n",
        "    \"input_ids_assistant\", \"labels_assistant\", \"attention_mask_assistant\"\n",
        "]\n",
        "for split in [\"train\", \"test\"]:\n",
        "    print(f\"\\nChecking {split} split...\")\n",
        "    missing_samples = []\n",
        "    for idx, sample in tqdm(enumerate(tokenized_dataset[split]), total=len(tokenized_dataset[split]), desc=f\"Validating {split} split\"):\n",
        "        missing_keys = [key for key in required_keys if key not in sample]\n",
        "        if missing_keys:\n",
        "            missing_samples.append((idx, missing_keys))\n",
        "    if missing_samples:\n",
        "        print(f\"Found {len(missing_samples)} problematic samples in {split} split:\")\n",
        "        for idx, missing_keys in missing_samples[:5]:\n",
        "            print(f\"Sample {idx} missing keys: {missing_keys}\")\n",
        "        raise ValueError(f\"Dataset validation failed in {split} split.\")\n",
        "    print(f\"{split} split: All {len(tokenized_dataset[split])} samples validated.\")\n",
        "\n",
        "COLUMNS_TO_KEEP = required_keys\n",
        "try:\n",
        "    tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].select_columns(COLUMNS_TO_KEEP)\n",
        "    tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].select_columns(COLUMNS_TO_KEEP)\n",
        "    print(f\"Dataset columns filtered to: {COLUMNS_TO_KEEP}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during column selection: {e}\")\n",
        "    print(f\"Available columns in train: {tokenized_dataset['train'].column_names}\")\n",
        "    print(f\"Available columns in test: {tokenized_dataset['test'].column_names}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez8THznFwjJM",
        "outputId": "b31017a8-5c65-4ebd-aae5-5558e00e610a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Validating Dataset Keys ---\n",
            "\n",
            "Checking train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating train split: 100%|██████████| 2500/2500 [00:09<00:00, 260.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train split: All 2500 samples validated.\n",
            "\n",
            "Checking test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating test split: 100%|██████████| 500/500 [00:01<00:00, 262.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test split: All 500 samples validated.\n",
            "Dataset columns filtered to: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING"
      ],
      "metadata": {
        "id": "2QWOSpkBS7jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug dataset before training\n",
        "print(\"\\n--- Debugging Dataset Before Training ---\")\n",
        "for split in [\"train\", \"test\"]:\n",
        "    print(f\"\\n{split} split sample keys:\")\n",
        "    for idx in range(min(5, len(tokenized_dataset[split]))):\n",
        "        sample = tokenized_dataset[split][idx]\n",
        "        print(f\"Sample {idx} keys: {list(sample.keys())}\")\n",
        "\n",
        "# --- 3. TRAINER INITIALIZATION AND EXECUTION ---\n",
        "print(\"\\n--- Initializing and Starting RepresentationTrainer (LLM-JEPA) ---\")\n",
        "custom_collator = CustomJEPABatchCollator(tokenizer)\n",
        "\n",
        "# Log GPU memory before training\n",
        "def log_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MiB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MiB\")\n",
        "        print(f\"GPU Memory Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1024**2:.2f} MiB\")\n",
        "\n",
        "print(\"\\n--- GPU Memory Before Training ---\")\n",
        "log_gpu_memory()\n",
        "\n",
        "# ADD FIXED JEPA MONITORING CALLBACK HERE\n",
        "\n",
        "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
        "\n",
        "# --- CALLBACK 1: MONITORING AND LOGGING (Your Original Role) ---\n",
        "class JEPAMonitorCallback(TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        # Force JEPA metrics display every 10 steps (matching logging_steps=10)\n",
        "        if state.global_step % 50 == 0 and hasattr(trainer, '_last_metrics'):\n",
        "            metrics = trainer._last_metrics\n",
        "            jepa_loss = metrics.get('jepa_loss')\n",
        "            lm_loss = metrics.get('lm_loss')\n",
        "            if jepa_loss is not None and lm_loss is not None:\n",
        "                print(f\"\\n🎯 JEPA Metrics [Step {state.global_step}]:\")\n",
        "                print(f\"   JEPA Loss: {jepa_loss.item():.4f}\")\n",
        "                print(f\"   LM Loss: {lm_loss.item():.4f}\")\n",
        "                print(f\"   Cosine Sim: {1 - jepa_loss.item():.4f}\")\n",
        "                print(f\"   Total Loss: {trainer.gamma * lm_loss + trainer.lbd * jepa_loss:.4f}\")\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        # Also add to official logs for potential WandB/etc.\n",
        "        if logs is not None and hasattr(trainer, '_last_metrics'):\n",
        "            jepa_loss = trainer._last_metrics.get('jepa_loss')\n",
        "            lm_loss = trainer._last_metrics.get('lm_loss')\n",
        "            if jepa_loss is not None:\n",
        "                logs[\"jepa_loss\"] = jepa_loss.item()\n",
        "                logs[\"lm_loss\"] = lm_loss.item()\n",
        "\n",
        "# --- CALLBACK 2: CONTROL AND EARLY STOPPING (The New Role) ---\n",
        "# This class handles the conditional stopping logic.\n",
        "class JEPALossStabilityCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    Stops training when the JEPA Loss on the training batch drops below a threshold\n",
        "    and stabilizes for a specified number of logging steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, jepa_threshold=0.0001, stability_steps=3):\n",
        "        self.jepa_threshold = jepa_threshold\n",
        "        self.stability_steps = stability_steps\n",
        "        self.stable_count = 0\n",
        "\n",
        "    def on_step_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        trainer = kwargs.get('trainer')\n",
        "\n",
        "        # Check only at logging steps (every 50 steps)\n",
        "        if state.global_step > 0 and state.global_step % args.logging_steps == 0 and hasattr(trainer, '_last_metrics'):\n",
        "            metrics = trainer._last_metrics\n",
        "            jepa_loss = metrics.get('jepa_loss')\n",
        "\n",
        "            if jepa_loss is not None:\n",
        "                current_jepa_loss = jepa_loss.item()\n",
        "\n",
        "                # Check for Early Stop Condition\n",
        "                if current_jepa_loss <= self.jepa_threshold:\n",
        "                    self.stable_count += 1\n",
        "\n",
        "                    if self.stable_count >= self.stability_steps:\n",
        "                        # SET THE CONTROL FLAG TO STOP\n",
        "                        control.should_stop = True\n",
        "                else:\n",
        "                    self.stable_count = 0\n",
        "\n",
        "        return control\n",
        "\n",
        "# Ensure both classes are defined in a single block before proceeding.\n",
        "# --- RE-INITIALIZE TRAINER WITH TWO CUSTOM CALLBACKS ---\n",
        "\n",
        "# Ensure the custom collator is ready\n",
        "custom_collator = CustomJEPABatchCollator(tokenizer)\n",
        "\n",
        "# Pass both callback instances in a list\n",
        "trainer = RepresentationTrainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"], # Keep this here for structure, even if eval_strategy=\"no\" is in TrainingArguments\n",
        "    args=training_arguments,\n",
        "    data_collator=custom_collator,\n",
        "    lbd=LLM_JEPA_CONFIG[\"lbd\"],\n",
        "    gamma=LLM_JEPA_CONFIG[\"gamma\"],\n",
        "    last_token=LLM_JEPA_CONFIG[\"last_token\"],\n",
        "    callbacks=[\n",
        "        JEPAMonitorCallback(),                     # 1. For Logging (Monitors progress)\n",
        "        JEPALossStabilityCallback(jepa_threshold=0.0001, stability_steps=3) # 2. For Control (Stops the process)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n--- Trainer Initialized with Separate Logging and Control Callbacks ---\")\n",
        "# You can now call trainer.train() in the next cell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oau3g7m79mFw",
        "outputId": "c6dae973-258d-4790-c4ea-c64565dbb4cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Debugging Dataset Before Training ---\n",
            "\n",
            "train split sample keys:\n",
            "Sample 0 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 1 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 2 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 3 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 4 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "\n",
            "test split sample keys:\n",
            "Sample 0 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 1 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 2 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 3 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "Sample 4 keys: ['input_ids', 'labels', 'attention_mask', 'input_ids_user', 'labels_user', 'attention_mask_user', 'input_ids_assistant', 'labels_assistant', 'attention_mask_assistant']\n",
            "\n",
            "--- Initializing and Starting RepresentationTrainer (LLM-JEPA) ---\n",
            "\n",
            "--- GPU Memory Before Training ---\n",
            "GPU Memory Allocated: 5166.18 MiB\n",
            "GPU Memory Reserved: 5240.00 MiB\n",
            "GPU Memory Free: 17452.88 MiB\n",
            "\n",
            "--- Trainer Initialized with Separate Logging and Control Callbacks ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"✅ JEPA Monitoring Enabled - will show metrics every {training_arguments.logging_steps}/{training_arguments.max_steps} steps\")\n",
        "print(\"\\n--- Starting LLM-JEPA Fine-Tuning with Monitoring ---\")\n",
        "trainer.train()\n",
        "print(\"\\n--- Fine-Tuning Complete! ---\")\n",
        "\n",
        "# Clean up old checkpoints\n",
        "print(\"\\n--- Cleaning Up Old Checkpoints ---\")\n",
        "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Save to Google Drive\n",
        "print(\"\\n--- Saving Final Adapter Weights to Google Drive ---\")\n",
        "trainer.model.save_pretrained(FINAL_MODEL_DIR)\n",
        "tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
        "print(f\"\\n✅ LoRA adapter and tokenizer saved to: '{FINAL_MODEL_DIR}'\")\n",
        "print(f\"Checkpoints and logs saved to '{OUTPUT_DIR}'\")"
      ],
      "metadata": {
        "id": "SwG6nFwobLvg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "43d683f6-44f3-413e-946e-e1eef1e43c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JEPA Monitoring Enabled - will show metrics every 50/500 steps\n",
            "\n",
            "--- Starting LLM-JEPA Fine-Tuning with Monitoring ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='135' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [135/500 2:55:48 < 8:02:30, 0.01 it/s, Epoch 0.86/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.885500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.235800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 JEPA Metrics [Step 50]:\n",
            "   JEPA Loss: 0.0001\n",
            "   LM Loss: 0.2543\n",
            "   Cosine Sim: 0.9999\n",
            "   Total Loss: 0.2545\n",
            "\n",
            "🎯 JEPA Metrics [Step 100]:\n",
            "   JEPA Loss: 0.0001\n",
            "   LM Loss: 0.2285\n",
            "   Cosine Sim: 0.9999\n",
            "   Total Loss: 0.2286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEPLOYMENT"
      ],
      "metadata": {
        "id": "PQFjS7d3TE0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# --- 4. DEPLOYMENT TO HUGGING FACE ---\n",
        "print(\"\\n--- Authenticating with Hugging Face Hub ---\")\n",
        "try:\n",
        "    access_token_write = userdata.get('HF_TOKEN')\n",
        "    if not access_token_write:\n",
        "        raise ValueError(\"HF_TOKEN secret not found or is empty.\")\n",
        "    login(token=access_token_write, add_to_git_credential=True)\n",
        "    api = HfApi(token=access_token_write)\n",
        "    print(\"✅ Successfully logged into Hugging Face Hub.\")\n",
        "except Exception as e:\n",
        "    print(f\"FATAL ERROR during login: {e}\")\n",
        "    raise\n",
        "\n",
        "print(f\"\\n--- Checking/Creating Repository: {HUB_MODEL_ID} ---\")\n",
        "try:\n",
        "    api.repo_info(repo_id=HUB_MODEL_ID, repo_type=\"model\")\n",
        "    print(f\"✅ Repository {HUB_MODEL_ID} already exists.\")\n",
        "except RepositoryNotFoundError:\n",
        "    print(f\"⚠️ Repository {HUB_MODEL_ID} not found. Creating it now...\")\n",
        "    create_repo(repo_id=HUB_MODEL_ID, repo_type=\"model\", private=False, token=access_token_write)\n",
        "    print(f\"✅ Repository {HUB_MODEL_ID} created successfully.\")\n",
        "\n",
        "print(f\"\\n--- Pushing LoRA Adapter and Tokenizer ---\")\n",
        "if not os.path.exists(FINAL_MODEL_DIR):\n",
        "    raise FileNotFoundError(f\"Adapter directory not found at {FINAL_MODEL_DIR}.\")\n",
        "try:\n",
        "    trainer.model.push_to_hub(\n",
        "        repo_id=HUB_MODEL_ID,\n",
        "        commit_message=\"Initial QLoRA adapter for Bitcoin price prediction\",\n",
        "        private=False\n",
        "    )\n",
        "    tokenizer.push_to_hub(HUB_MODEL_ID)\n",
        "    print(\"\\n✅ SUCCESS: Adapter and tokenizer uploaded to Hugging Face Hub.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️ WARNING: Trainer push failed. Using HfApi fallback. Error: {e}\")\n",
        "    api.upload_folder(\n",
        "        folder_path=FINAL_MODEL_DIR,\n",
        "        repo_id=HUB_MODEL_ID,\n",
        "        commit_message=\"LoRA adapter and tokenizer pushed from Google Drive checkpoint\",\n",
        "        ignore_patterns=[\"*.pt\", \"*.bin\", \"optimizer.pt\", \"scheduler.pt\", \"rng_state.pth\"]\n",
        "    )\n",
        "    print(\"\\n✅ SUCCESS (Fallback): Adapter and tokenizer uploaded to Hugging Face Hub.\")\n",
        "print(f\"\\nDeployment Complete. Model available at: https://huggingface.co/{HUB_MODEL_ID}\")"
      ],
      "metadata": {
        "id": "toQZ-0Ox22aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATION"
      ],
      "metadata": {
        "id": "nqXmJ3ecTQQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚨 FIRST: COMPLETELY RESET PEFT INSTALLATION\n",
        "!pip uninstall -y peft\n",
        "!pip install peft==0.10.0  # Use stable version\n",
        "\n",
        "# Restart runtime after this command"
      ],
      "metadata": {
        "id": "O9seIeCEUZss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FILE PATHS ---\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
        "DATASET_PATH = \"/content/gdrive/MyDrive/CryptoFT/dataset/btc_instruction_dataset.jsonl\"\n",
        "OUTPUT_DIR = \"/content/gdrive/MyDrive/CryptoFT/models/results_btc_jepa\"\n",
        "FINAL_MODEL_DIR = \"/content/gdrive/MyDrive/CryptoFT/models/Mistral-7B-BTC-JEPA_FINAL\"\n",
        "HUB_MODEL_ID = \"frankmorales2020/Mistral-7B-BTC-JEPA-LLM-Expert\"\n",
        "MAX_SEQ_LENGTH = 1024\n",
        "TEMP_DATASET_DIR = \"/content/gdrive/MyDrive/CryptoFT/dataset/temp_tokenized\"\n"
      ],
      "metadata": {
        "id": "yIr4DOt_V9SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "from peft import LoraConfig, get_peft_model, PeftModel"
      ],
      "metadata": {
        "id": "Xf7NgN2kVusD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPROVED TEST WITH CLEANER PROMPTS ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔧 IMPROVED JEPA MODEL TESTING - CLEAN PROMPTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "improved_tests = [\n",
        "    {\n",
        "        \"name\": \"BULLISH SCENARIO\",\n",
        "        \"data\": \"[O:30000, H:31000, C:30900]\",\n",
        "        \"expected\": \"UP\",\n",
        "        \"reason\": \"closing near highs with strong upward momentum\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BEARISH SCENARIO\",\n",
        "        \"data\": \"[O:30500, H:30600, C:30000]\",\n",
        "        \"expected\": \"DOWN\",\n",
        "        \"reason\": \"closing at lows after being rejected at highs\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"CONSOLIDATION SCENARIO\",\n",
        "        \"data\": \"[O:30200, H:30300, C:30250]\",\n",
        "        \"expected\": \"FLAT\",\n",
        "        \"reason\": \"trading in tight range with minimal movement\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"🤖 Testing with CLEANER prompts to prevent hallucinations...\\n\")\n",
        "\n",
        "for test in improved_tests:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"📊 {test['name']} (Expecting: {test['expected']})\")\n",
        "    print(f\"📈 Data: {test['data']}\")\n",
        "    print(f\"💡 Reason: {test['reason']}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # 🚨 CLEANER PROMPT - No historical references\n",
        "    prompt_content = f\"BTC price data: {test['data']}. Based ONLY on this OHLC data, the 12-hour direction is:\"\n",
        "    input_text = f\"<s>[INST] {prompt_content} [/INST]\"\n",
        "\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=30,  # 🚨 Shorter to prevent rambling\n",
        "            do_sample=False,    # 🚨 Greedy decoding for consistency\n",
        "            temperature=0.3,    # 🚨 Lower temperature\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    prediction = response.split(\"[/INST]\")[-1].strip() if \"[/INST]\" in response else response\n",
        "\n",
        "    print(f\"🎯 MODEL PREDICTION: {prediction}\")\n",
        "\n",
        "    # Check if prediction matches expectation\n",
        "    if test['expected'] in prediction.upper():\n",
        "        print(f\"✅ CORRECT - Matched expected: {test['expected']}\")\n",
        "    else:\n",
        "        print(f\"❌ UNEXPECTED - Wanted {test['expected']}, got different\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"📝 ANALYSIS: The model may need more focused fine-tuning on\")\n",
        "print(\"   directional prediction without historical data contamination.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBgzk3UW28F4",
        "outputId": "152f8f1e-4813-414b-c5dc-16a1f3b6290b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🔧 IMPROVED JEPA MODEL TESTING - CLEAN PROMPTS\n",
            "======================================================================\n",
            "🤖 Testing with CLEANER prompts to prevent hallucinations...\n",
            "\n",
            "\n",
            "==================================================\n",
            "📊 BULLISH SCENARIO (Expecting: UP)\n",
            "📈 Data: [O:30000, H:31000, C:30900]\n",
            "💡 Reason: closing near highs with strong upward momentum\n",
            "==================================================\n",
            "🎯 MODEL PREDICTION: The 12-hour prediction is **UP**. The final price was $31000. The 12-hour RM\n",
            "✅ CORRECT - Matched expected: UP\n",
            "\n",
            "==================================================\n",
            "📊 BEARISH SCENARIO (Expecting: DOWN)\n",
            "📈 Data: [O:30500, H:30600, C:30000]\n",
            "💡 Reason: closing at lows after being rejected at highs\n",
            "==================================================\n",
            "🎯 MODEL PREDICTION: The 12-hour prediction is **UP**. The final price was $30000. The 12-hour RM\n",
            "❌ UNEXPECTED - Wanted DOWN, got different\n",
            "\n",
            "==================================================\n",
            "📊 CONSOLIDATION SCENARIO (Expecting: FLAT)\n",
            "📈 Data: [O:30200, H:30300, C:30250]\n",
            "💡 Reason: trading in tight range with minimal movement\n",
            "==================================================\n",
            "🎯 MODEL PREDICTION: The 12-hour prediction is **$30250**. The current 1-hour prediction is **$3025\n",
            "❌ UNEXPECTED - Wanted FLAT, got different\n",
            "\n",
            "======================================================================\n",
            "📝 ANALYSIS: The model may need more focused fine-tuning on\n",
            "   directional prediction without historical data contamination.\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}