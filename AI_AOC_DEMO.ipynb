{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMzAPfvgoSXxMfuWAXJhn4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AI_AOC_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXPgwHfDaqqr",
        "outputId": "5aaaac89-6bed-4ebf-e35b-a5a9c3842bd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf7J-x1-wd_s",
        "outputId": "1f5ac6c6-28ba-4bf8-8eea-c634f756b7bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 12 00:47:23 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   37C    P8              12W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"You seem to be using the pipelines sequentially on GPU\")"
      ],
      "metadata": {
        "id": "t6s8MzSaat8C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEy0SruIavZy",
        "outputId": "2b0af8c2-cd9f-4d5c-df3f-0ca8e344b3d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-gpu"
      ],
      "metadata": {
        "id": "lG95dF4Nnv4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- Simulated External Data Sources ---\n",
        "def get_flight_data(flight_id):\n",
        "    \"\"\"Simulates fetching flight data from an API.\"\"\"\n",
        "    # Simulate a storm affecting the flight\n",
        "    storm_active = random.choice([True, False])\n",
        "\n",
        "    flight_data = {\n",
        "        \"flight_id\": flight_id,\n",
        "        \"aircraft_id\": \"AA123\",  # Added aircraft_id to the flight data\n",
        "        \"origin\": \"Paris\",\n",
        "        \"destination\": \"London\",\n",
        "        \"status\": \"en-route\",\n",
        "        \"altitude\": 35000,  # feet\n",
        "        \"speed\": 500,  # knots\n",
        "        \"position\": {\n",
        "            \"latitude\": 50.0,\n",
        "            \"longitude\": 2.0\n",
        "        },\n",
        "        \"weather\": {\n",
        "            \"temperature\": -50,  # Celsius\n",
        "            \"wind\": {\n",
        "                \"speed\": 20,  # knots\n",
        "                \"direction\": \"West\"\n",
        "            },\n",
        "            \"storm\": {\n",
        "                \"active\": storm_active,\n",
        "                \"severity\": \"severe\" if storm_active else \"none\",\n",
        "                \"location\": {\n",
        "                    \"latitude\": 51.0,\n",
        "                    \"longitude\": 1.0\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return flight_data\n",
        "\n",
        "def get_maintenance_records(aircraft_id):\n",
        "    \"\"\"Simulates fetching maintenance records from a database.\"\"\"\n",
        "    maintenance_records = [{\n",
        "        \"date\": \"2024-12-15\",\n",
        "        \"description\": \"Scheduled engine inspection\",\n",
        "        \"status\": \"completed\"\n",
        "    }, {\n",
        "        \"date\": \"2025-01-05\",\n",
        "        \"description\": \"Replaced hydraulic pump\",\n",
        "        \"status\": \"completed\"\n",
        "    }]\n",
        "    return maintenance_records\n",
        "\n",
        "def suggest_rerouting(flight_data):\n",
        "    \"\"\"Simulates a tool that suggests rerouting options based on weather.\"\"\"\n",
        "    if flight_data[\"weather\"][\"storm\"][\"active\"]:\n",
        "        suggestion = \"Consider rerouting flight {} to avoid the storm. Possible options include...\".format(\n",
        "            flight_data[\"flight_id\"])\n",
        "    else:\n",
        "        suggestion = \"No rerouting suggestions at this time.\"\n",
        "    return suggestion\n",
        "\n",
        "# --- FAISS Setup for Semantic Search ---\n",
        "# Sample documents for FAISS (replace with your actual knowledge base)\n",
        "documents = [\n",
        "    \"Aircraft maintenance is crucial for flight safety.\",\n",
        "    \"Severe weather can cause flight delays and disruptions.\",\n",
        "    \"Rerouting options should consider fuel efficiency and passenger comfort.\",\n",
        "    \"In case of emergency, pilots should follow established procedures.\",\n",
        "    \"Communication between pilots and air traffic control is essential.\",\n",
        "    \"Regular training ensures crew members are prepared for various situations.\"\n",
        "]\n",
        "\n",
        "# Initialize a SentenceTransformer model for generating embeddings\n",
        "encoder = SentenceTransformer('all-mpnet-base-v2')\n",
        "embeddings = encoder.encode(documents)\n",
        "\n",
        "# Create a FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings.astype('float32'))\n",
        "\n",
        "def semantic_search(query, index, k=2):\n",
        "    \"\"\"Performs semantic search over the documents using FAISS.\"\"\"\n",
        "    query_embedding = encoder.encode([query])[0].astype('float32')\n",
        "    D, I = index.search(np.array([query_embedding]), k)\n",
        "\n",
        "    return [documents[i] for i in I[0]]\n",
        "\n",
        "# --- Cache-Augmented Generation ---\n",
        "def preload_knowledge(query, index, k=2):\n",
        "    \"\"\"Preloads relevant knowledge into the LLM's context window.\"\"\"\n",
        "    results = semantic_search(query, index, k)\n",
        "    context = \" \".join(results)\n",
        "    return context\n",
        "\n",
        "# --- Agent Implementation ---\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    do_sample=True,\n",
        ")\n",
        "\n",
        "# Set the pad_token_id for the model explicitly\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "qBsU0kRWnXxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt,\n",
        "                      tokenizer,\n",
        "                      model,\n",
        "                      max_new_tokens=1024,  # Increased for longer responses\n",
        "                      temperature=0.7):\n",
        "      \"\"\"\"\"Generates a response from the Llama 2 model.\"\"\"\"\"\n",
        "      inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "      outputs = model.generate(**inputs,\n",
        "                              max_new_tokens=max_new_tokens,\n",
        "                              temperature=temperature,\n",
        "                              do_sample=True)\n",
        "      response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "      return response"
      ],
      "metadata": {
        "id": "4j2gy_mttLWq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(question, index):\n",
        "    \"\"\"Executes the AI agent.\"\"\"\n",
        "    # Preload knowledge using FAISS and CAG\n",
        "    context = preload_knowledge(question, index)\n",
        "\n",
        "    # Initialize the prompt with the preloaded context\n",
        "    prompt = f\"\"\"You are an AI agent assisting in an airline operation control center.\n",
        "\n",
        "Relevant context: {context}\n",
        "\n",
        "Available tools:\n",
        "* get_flight_data(flight_id): Get information about a flight, including route, weather, etc.\n",
        "* suggest_rerouting(flight_data): Suggest rerouting options for a flight based on its data.\n",
        "* get_maintenance_records(aircraft_id): Get maintenance records for an aircraft.\n",
        "\n",
        "Instructions:\n",
        "1. **Always** start by thinking about what to do.\n",
        "2. **Clearly** state your thoughts.\n",
        "3. Choose the **best** action from the tools above.\n",
        "4. **Only** provide 'Action Input' if the tool requires it.\n",
        "5. **Always** provide an 'Observation' after each action.\n",
        "6. Once you have all the information, provide a 'Final Answer' to the original question.\n",
        "\n",
        "Use this format:\n",
        "Question: the input question you must answer\n",
        "Thought:\n",
        "Action: ...\n",
        "Action Input: ... (if needed)\n",
        "Observation: ...\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "\n",
        "    while True:\n",
        "        model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "        response = generate_response(prompt, tokenizer, model)\n",
        "\n",
        "        # Check if the model has a final answer\n",
        "        if \"Final Answer:\" in response:\n",
        "            final_answer = response.split(\"Final Answer:\")[-1].strip()\n",
        "            return final_answer\n",
        "\n",
        "        try:\n",
        "            action_line = next(\n",
        "                (line for line in response.split(\"\\n\")\n",
        "                 if line.startswith(\"Action: \")), None)\n",
        "            input_line = next(\n",
        "                (line for line in response.split(\"\\n\")\n",
        "                 if line.startswith(\"Action Input: \")), None)\n",
        "\n",
        "            if action_line and input_line:\n",
        "                action = action_line.split(\"Action:\")[-1].strip()\n",
        "                action_input = input_line.split(\"Action Input:\")[-1].strip()\n",
        "\n",
        "                # Execute the action and add the observation to the prompt\n",
        "                if action == \"get_flight_data\":\n",
        "                    flight_data = get_flight_data(action_input)\n",
        "                    observation = f\"Flight data for {action_input}: {flight_data}\"\n",
        "\n",
        "                    # Extract aircraft ID from flight data\n",
        "                    try:\n",
        "                        aircraft_id = flight_data[\"aircraft_id\"]\n",
        "                    except KeyError:\n",
        "                        aircraft_id = \"unknown\"\n",
        "\n",
        "                elif action == \"suggest_rerouting\":\n",
        "                    # Call suggest_rerouting with the flight data dictionary\n",
        "                    flight_data = get_flight_data(action_input)  # Get flight data first\n",
        "                    observation = suggest_rerouting(flight_data)\n",
        "\n",
        "                elif action == \"get_maintenance_records\":\n",
        "                    if action_input == \"not provided\":\n",
        "                        # If aircraft ID is not provided, use the extracted one\n",
        "                        observation = get_maintenance_records(aircraft_id)\n",
        "                    else:\n",
        "                        observation = get_maintenance_records(action_input)\n",
        "                else:\n",
        "                    observation = \"Invalid action.\"\n",
        "\n",
        "                # Update the prompt with the observation\n",
        "                prompt += f\"\\nObservation: {observation}\"\n",
        "\n",
        "            else:\n",
        "                return \"I'm sorry, I couldn't understand the model's response. Please try again.\"\n",
        "\n",
        "        except IndexError:\n",
        "            return \"I'm sorry, I couldn't understand the model's response.\""
      ],
      "metadata": {
        "id": "CbeKnQETs2EI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to simulate user input with flight ID\n",
        "def get_user_input():\n",
        "    flight_id = \"AA\" + str(random.randint(1000, 9999))\n",
        "    user_input = f\"\"\"\n",
        "    Flight {flight_id} is requesting an update on their route and weather,\n",
        "    as well as any relevant maintenance records for the aircraft.\n",
        "    Can you provide this information and suggest any necessary actions?\n",
        "    \"\"\"\n",
        "    return user_input"
      ],
      "metadata": {
        "id": "YQ52qOXYtAV_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Original pad_token_id: {model.generation_config.pad_token_id}\")  # Check initial value\n",
        "print(f\"Tokenizer's pad_token_id: {tokenizer.pad_token_id}\")\n",
        "\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id  # Set pad_token_id\n",
        "print(f\"Updated pad_token_id: {model.generation_config.pad_token_id}\")  # Confirm update\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S7kL4UO89WP",
        "outputId": "bb7aaf0d-85a9-4be7-9fc3-74d791f1911b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original pad_token_id: None\n",
            "Tokenizer's pad_token_id: None\n",
            "Updated pad_token_id: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check if pad_token_id is already set, if not, set it:\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token if not already set\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Set pad_token_id to eos_token_id\n",
        "\n",
        "# 2. Make sure the model's configuration is aligned:\n",
        "model.config.pad_token_id = tokenizer.pad_token_id  # Setting model's config for consistency\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id # Setting pad_token_id for generation config\n",
        "\n",
        "# Get and run user input (pass the FAISS index to run_agent)\n",
        "user_query = get_user_input()\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "response = run_agent(user_query, index)"
      ],
      "metadata": {
        "id": "I9Q200NJs057"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWLcisKtxMcO",
        "outputId": "29fbe465-fdec-4c56-90a1-5eff76aceaf3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Flight AA3194 is requesting an update on their route and weather,\n",
            "    as well as any relevant maintenance records for the aircraft.\n",
            "    Can you provide this information and suggest any necessary actions?\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o45XSTADwZkC",
        "outputId": "2951e00a-0d1e-4557-f0fb-c5629da3ccf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The flight has been rerouted to a nearby airport with less severe weather conditions, and the aircraft's maintenance records show that it is still due for a routine inspection, but it is currently airworthy.\n"
          ]
        }
      ]
    }
  ]
}