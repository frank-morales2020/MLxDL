{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMMqIhft7wWtlQ3LOAZBFzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c463adc7e5fa4afda75e87f49a1a9240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_647bfc61cb554a348dfe13aeef322222",
              "IPY_MODEL_c9d7d9d1a6b14ce3abc3130eaadf23b7",
              "IPY_MODEL_b8ac28c8ff984d32890039fa97ebef7d"
            ],
            "layout": "IPY_MODEL_c3ba999935404bfbb8e42f3c6bdcf48a"
          }
        },
        "647bfc61cb554a348dfe13aeef322222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_432d9487f39241fea555567901ce6625",
            "placeholder": "​",
            "style": "IPY_MODEL_ea5884713d464bb08e21038a9899dedd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c9d7d9d1a6b14ce3abc3130eaadf23b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b97997263b1c4341a14f2f71073a1300",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1611dc11bf994a878eb5444f1a520333",
            "value": 2
          }
        },
        "b8ac28c8ff984d32890039fa97ebef7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6753bed8def6462eb259d5454eb9c1bb",
            "placeholder": "​",
            "style": "IPY_MODEL_07b2b8b65c1441cc82e47ff2f8f63fa8",
            "value": " 2/2 [00:02&lt;00:00,  1.17s/it]"
          }
        },
        "c3ba999935404bfbb8e42f3c6bdcf48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432d9487f39241fea555567901ce6625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5884713d464bb08e21038a9899dedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b97997263b1c4341a14f2f71073a1300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1611dc11bf994a878eb5444f1a520333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6753bed8def6462eb259d5454eb9c1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b2b8b65c1441cc82e47ff2f8f63fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AI_AOC_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXPgwHfDaqqr",
        "outputId": "f7f04878-b1d6-428a-8c37-8babfe27fbb8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf7J-x1-wd_s",
        "outputId": "2c1d0d37-52c1-4e67-8d4d-e4a126c1c612"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 11 23:59:22 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   37C    P8              11W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"You seem to be using the pipelines sequentially on GPU\")"
      ],
      "metadata": {
        "id": "t6s8MzSaat8C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "hEy0SruIavZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-gpu"
      ],
      "metadata": {
        "id": "lG95dF4Nnv4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- Simulated External Data Sources ---\n",
        "def get_flight_data(flight_id):\n",
        "    \"\"\"Simulates fetching flight data from an API.\"\"\"\n",
        "    # Simulate a storm affecting the flight\n",
        "    storm_active = random.choice([True, False])\n",
        "\n",
        "    flight_data = {\n",
        "        \"flight_id\": flight_id,\n",
        "        \"aircraft_id\": \"AA123\",  # Added aircraft_id to the flight data\n",
        "        \"origin\": \"Paris\",\n",
        "        \"destination\": \"London\",\n",
        "        \"status\": \"en-route\",\n",
        "        \"altitude\": 35000,  # feet\n",
        "        \"speed\": 500,  # knots\n",
        "        \"position\": {\n",
        "            \"latitude\": 50.0,\n",
        "            \"longitude\": 2.0\n",
        "        },\n",
        "        \"weather\": {\n",
        "            \"temperature\": -50,  # Celsius\n",
        "            \"wind\": {\n",
        "                \"speed\": 20,  # knots\n",
        "                \"direction\": \"West\"\n",
        "            },\n",
        "            \"storm\": {\n",
        "                \"active\": storm_active,\n",
        "                \"severity\": \"severe\" if storm_active else \"none\",\n",
        "                \"location\": {\n",
        "                    \"latitude\": 51.0,\n",
        "                    \"longitude\": 1.0\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return flight_data\n",
        "\n",
        "def get_maintenance_records(aircraft_id):\n",
        "    \"\"\"Simulates fetching maintenance records from a database.\"\"\"\n",
        "    maintenance_records = [{\n",
        "        \"date\": \"2024-12-15\",\n",
        "        \"description\": \"Scheduled engine inspection\",\n",
        "        \"status\": \"completed\"\n",
        "    }, {\n",
        "        \"date\": \"2025-01-05\",\n",
        "        \"description\": \"Replaced hydraulic pump\",\n",
        "        \"status\": \"completed\"\n",
        "    }]\n",
        "    return maintenance_records\n",
        "\n",
        "def suggest_rerouting(flight_data):\n",
        "    \"\"\"Simulates a tool that suggests rerouting options based on weather.\"\"\"\n",
        "    if flight_data[\"weather\"][\"storm\"][\"active\"]:\n",
        "        suggestion = \"Consider rerouting flight {} to avoid the storm. Possible options include...\".format(\n",
        "            flight_data[\"flight_id\"])\n",
        "    else:\n",
        "        suggestion = \"No rerouting suggestions at this time.\"\n",
        "    return suggestion\n",
        "\n",
        "# --- FAISS Setup for Semantic Search ---\n",
        "# Sample documents for FAISS (replace with your actual knowledge base)\n",
        "documents = [\n",
        "    \"Aircraft maintenance is crucial for flight safety.\",\n",
        "    \"Severe weather can cause flight delays and disruptions.\",\n",
        "    \"Rerouting options should consider fuel efficiency and passenger comfort.\",\n",
        "    \"In case of emergency, pilots should follow established procedures.\",\n",
        "    \"Communication between pilots and air traffic control is essential.\",\n",
        "    \"Regular training ensures crew members are prepared for various situations.\"\n",
        "]\n",
        "\n",
        "# Initialize a SentenceTransformer model for generating embeddings\n",
        "encoder = SentenceTransformer('all-mpnet-base-v2')\n",
        "embeddings = encoder.encode(documents)\n",
        "\n",
        "# Create a FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings.astype('float32'))\n",
        "\n",
        "def semantic_search(query, index, k=2):\n",
        "    \"\"\"Performs semantic search over the documents using FAISS.\"\"\"\n",
        "    query_embedding = encoder.encode([query])[0].astype('float32')\n",
        "    D, I = index.search(np.array([query_embedding]), k)\n",
        "\n",
        "    return [documents[i] for i in I[0]]\n",
        "\n",
        "# --- Cache-Augmented Generation ---\n",
        "def preload_knowledge(query, index, k=2):\n",
        "    \"\"\"Preloads relevant knowledge into the LLM's context window.\"\"\"\n",
        "    results = semantic_search(query, index, k)\n",
        "    context = \" \".join(results)\n",
        "    return context\n",
        "\n",
        "# --- Agent Implementation ---\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    do_sample=True,\n",
        ")\n",
        "\n",
        "# Set the pad_token_id for the model explicitly\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c463adc7e5fa4afda75e87f49a1a9240",
            "647bfc61cb554a348dfe13aeef322222",
            "c9d7d9d1a6b14ce3abc3130eaadf23b7",
            "b8ac28c8ff984d32890039fa97ebef7d",
            "c3ba999935404bfbb8e42f3c6bdcf48a",
            "432d9487f39241fea555567901ce6625",
            "ea5884713d464bb08e21038a9899dedd",
            "b97997263b1c4341a14f2f71073a1300",
            "1611dc11bf994a878eb5444f1a520333",
            "6753bed8def6462eb259d5454eb9c1bb",
            "07b2b8b65c1441cc82e47ff2f8f63fa8"
          ]
        },
        "id": "qBsU0kRWnXxX",
        "outputId": "500a070c-46ec-484f-b598-cd3751bbd8b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c463adc7e5fa4afda75e87f49a1a9240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt,\n",
        "                      tokenizer,\n",
        "                      model,\n",
        "                      max_new_tokens=1024,  # Increased for longer responses\n",
        "                      temperature=0.7):\n",
        "      \"\"\"\"\"Generates a response from the Llama 2 model.\"\"\"\"\"\n",
        "      inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "      outputs = model.generate(**inputs,\n",
        "                              max_new_tokens=max_new_tokens,\n",
        "                              temperature=temperature,\n",
        "                              do_sample=True)\n",
        "      response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "      return response"
      ],
      "metadata": {
        "id": "4j2gy_mttLWq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(question, index):\n",
        "    \"\"\"Executes the AI agent.\"\"\"\n",
        "    # Preload knowledge using FAISS and CAG\n",
        "    context = preload_knowledge(question, index)\n",
        "\n",
        "    # Initialize the prompt with the preloaded context\n",
        "    prompt = f\"\"\"You are an AI agent assisting in an airline operation control center.\n",
        "\n",
        "Relevant context: {context}\n",
        "\n",
        "Available tools:\n",
        "* get_flight_data(flight_id): Get information about a flight, including route, weather, etc.\n",
        "* suggest_rerouting(flight_data): Suggest rerouting options for a flight based on its data.\n",
        "* get_maintenance_records(aircraft_id): Get maintenance records for an aircraft.\n",
        "\n",
        "Instructions:\n",
        "1. **Always** start by thinking about what to do.\n",
        "2. **Clearly** state your thoughts.\n",
        "3. Choose the **best** action from the tools above.\n",
        "4. **Only** provide 'Action Input' if the tool requires it.\n",
        "5. **Always** provide an 'Observation' after each action.\n",
        "6. Once you have all the information, provide a 'Final Answer' to the original question.\n",
        "\n",
        "Use this format:\n",
        "Question: the input question you must answer\n",
        "Thought:\n",
        "Action: ...\n",
        "Action Input: ... (if needed)\n",
        "Observation: ...\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "\n",
        "    while True:\n",
        "        model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "        response = generate_response(prompt, tokenizer, model)\n",
        "\n",
        "        # Check if the model has a final answer\n",
        "        if \"Final Answer:\" in response:\n",
        "            final_answer = response.split(\"Final Answer:\")[-1].strip()\n",
        "            return final_answer\n",
        "\n",
        "        try:\n",
        "            action_line = next(\n",
        "                (line for line in response.split(\"\\n\")\n",
        "                 if line.startswith(\"Action: \")), None)\n",
        "            input_line = next(\n",
        "                (line for line in response.split(\"\\n\")\n",
        "                 if line.startswith(\"Action Input: \")), None)\n",
        "\n",
        "            if action_line and input_line:\n",
        "                action = action_line.split(\"Action:\")[-1].strip()\n",
        "                action_input = input_line.split(\"Action Input:\")[-1].strip()\n",
        "\n",
        "                # Execute the action and add the observation to the prompt\n",
        "                if action == \"get_flight_data\":\n",
        "                    flight_data = get_flight_data(action_input)\n",
        "                    observation = f\"Flight data for {action_input}: {flight_data}\"\n",
        "\n",
        "                    # Extract aircraft ID from flight data\n",
        "                    try:\n",
        "                        aircraft_id = flight_data[\"aircraft_id\"]\n",
        "                    except KeyError:\n",
        "                        aircraft_id = \"unknown\"\n",
        "\n",
        "                elif action == \"suggest_rerouting\":\n",
        "                    # Call suggest_rerouting with the flight data dictionary\n",
        "                    flight_data = get_flight_data(action_input)  # Get flight data first\n",
        "                    observation = suggest_rerouting(flight_data)\n",
        "\n",
        "                elif action == \"get_maintenance_records\":\n",
        "                    if action_input == \"not provided\":\n",
        "                        # If aircraft ID is not provided, use the extracted one\n",
        "                        observation = get_maintenance_records(aircraft_id)\n",
        "                    else:\n",
        "                        observation = get_maintenance_records(action_input)\n",
        "                else:\n",
        "                    observation = \"Invalid action.\"\n",
        "\n",
        "                # Update the prompt with the observation\n",
        "                prompt += f\"\\nObservation: {observation}\"\n",
        "\n",
        "            else:\n",
        "                return \"I'm sorry, I couldn't understand the model's response. Please try again.\"\n",
        "\n",
        "        except IndexError:\n",
        "            return \"I'm sorry, I couldn't understand the model's response.\""
      ],
      "metadata": {
        "id": "CbeKnQETs2EI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to simulate user input with flight ID\n",
        "def get_user_input():\n",
        "    flight_id = \"AA\" + str(random.randint(1000, 9999))\n",
        "    user_input = f\"\"\"\n",
        "    Flight {flight_id} is requesting an update on their route and weather,\n",
        "    as well as any relevant maintenance records for the aircraft.\n",
        "    Can you provide this information and suggest any necessary actions?\n",
        "    \"\"\"\n",
        "    return user_input"
      ],
      "metadata": {
        "id": "YQ52qOXYtAV_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and run user input (pass the FAISS index to run_agent)\n",
        "user_query = get_user_input()\n",
        "response = run_agent(user_query, index)"
      ],
      "metadata": {
        "id": "I9Q200NJs057"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWLcisKtxMcO",
        "outputId": "3bcc5c63-e5f3-473f-d40f-5691b8291629"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Flight AA8423 is requesting an update on their route and weather,\n",
            "    as well as any relevant maintenance records for the aircraft.\n",
            "    Can you provide this information and suggest any necessary actions?\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o45XSTADwZkC",
        "outputId": "b412e282-20fa-4eb0-9667-46d12a868af7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The flight AA8423 has been updated with the latest information and rerouted around the severe weather area. The flight is expected to arrive at its destination in 6 hours, with a slight delay due to the rerouting.\n"
          ]
        }
      ]
    }
  ]
}