{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "C6wati4zJibf",
        "hBca_KI7bHlN"
      ],
      "authorship_tag": "ABX9TyNh00iUtHbCcPPeZCOFPj5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/EEG_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install kagglehub --upgrade -q\n",
        "!pip install colab-env -q # Corrected package name"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VRLv3KWo2FE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9GbavgM1rTa",
        "outputId": "cf1b45c2-4a57-48c0-c11b-ff158a93d7ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/.cache/kagglehub/datasets/samnikolas/eeg-dataset/versions/1"
      ],
      "metadata": {
        "id": "R7AReaWeGZ3v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"samnikolas/eeg-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W76LqOsE_2S",
        "outputId": "77749be7-05da-4ceb-8279-510e061e376e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/samnikolas/eeg-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.24M/2.24M [00:00<00:00, 30.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/samnikolas/eeg-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -pr /root/.cache/kagglehub/datasets/samnikolas/eeg-dataset/versions/1/features_raw.csv /content/gdrive/MyDrive/datasets/EEG/"
      ],
      "metadata": {
        "id": "n9aU4qvaFaE7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EEG DS"
      ],
      "metadata": {
        "id": "2FfAv1K-nsxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "eeg_df = pd.read_csv('/content/gdrive/MyDrive/datasets/EEG/features_raw.csv')\n",
        "eeg_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "R-2r2oE9FzJ4",
        "outputId": "568adf57-559b-46d1-f2a5-4565041dddeb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Fp1        AF3         F3         F7        FC5       FC1  \\\n",
              "0     0.057813  -1.335266   4.640480   0.219573   7.473817  2.314842   \n",
              "1     1.367408  10.259654   3.345409   7.897852  -2.446051 -1.655035   \n",
              "2    -1.783132   4.133553  -0.951680  -1.624803  -1.827309 -2.280364   \n",
              "3    -3.690217  -0.814000   2.295469   0.901445   8.323679  1.127906   \n",
              "4     2.137114   6.420466   6.122230  10.015321   3.106394  3.183129   \n",
              "...        ...        ...        ...        ...        ...       ...   \n",
              "8059  2.371097   6.525279  -1.470521  -2.535683  -8.222570 -2.062185   \n",
              "8060  5.408372   7.813431  -5.203169 -13.254773 -18.839062 -1.866768   \n",
              "8061 -1.308237   1.166170  -3.158261  -9.249685  -7.438499  0.591557   \n",
              "8062 -2.095682   4.284166  -6.136204  -4.000436 -11.495979 -2.753036   \n",
              "8063  2.641319   3.967536 -11.562283 -18.074156 -26.700735 -5.975564   \n",
              "\n",
              "             C3         T7        CP5        CP1  ...        Cz        C4  \\\n",
              "0      1.918097  -9.257533   9.089943  -7.104519  ... -2.241480  1.415335   \n",
              "1     -6.301423  -7.290317  -3.546453  -5.705187  ... -2.568397 -5.651418   \n",
              "2     -2.279225   9.151344  -0.239575  -0.057604  ... -2.132823 -0.521117   \n",
              "3      6.356886  11.642082   9.354154  -1.662478  ... -0.506117 -1.154866   \n",
              "4      3.658535   4.571793   4.917712  -2.325940  ...  1.813907 -6.444635   \n",
              "...         ...        ...        ...        ...  ...       ...       ...   \n",
              "8059  -5.890198  11.508550 -14.298769   9.859735  ...  0.407407 -0.032451   \n",
              "8060  -8.164257  17.100103 -23.600410  27.898805  ...  3.976006  6.957139   \n",
              "8061  -1.791961  16.107009  -9.831608  17.049193  ...  3.080318  3.275846   \n",
              "8062  -7.090403   5.933243 -13.990339  11.807037  ...  0.583702 -1.521174   \n",
              "8063 -11.994061   3.563218 -24.599401  30.461931  ...  4.718537  5.649721   \n",
              "\n",
              "             T8        CP6        CP2         P4        P8        PO4  \\\n",
              "0      2.406646  12.864059   4.021099  -2.828598 -2.588735   2.637905   \n",
              "1     -0.096730  -4.930759  -1.722504  -6.111309  0.094893  -3.521353   \n",
              "2      8.605298  -4.499946  -3.232839  -4.249645 -3.687167  -7.383004   \n",
              "3     -3.940251   7.390881   2.129897  -0.794675 -1.959021   2.774530   \n",
              "4    -27.680880   0.641364   1.996658  -0.445779  2.614021   6.161845   \n",
              "...         ...        ...        ...        ...       ...        ...   \n",
              "8059  12.929205 -27.406610 -14.864499  -6.631102  7.509646 -25.823920   \n",
              "8060  11.972493 -52.080426 -29.577173 -11.663913  5.416705 -57.219852   \n",
              "8061 -22.535264 -26.538050 -15.409645  -4.558339  4.718691 -28.783795   \n",
              "8062 -12.615231 -26.169920 -16.098081  -6.099934  7.850973 -28.039497   \n",
              "8063   8.920055 -52.330345 -30.160978  -8.524680  9.549617 -58.936422   \n",
              "\n",
              "             O2  Unnamed: 32  \n",
              "0     -5.226618          NaN  \n",
              "1      1.887093          NaN  \n",
              "2     -4.489537          NaN  \n",
              "3     -6.323060          NaN  \n",
              "4      3.308816          NaN  \n",
              "...         ...          ...  \n",
              "8059  -3.558200          NaN  \n",
              "8060 -11.860173          NaN  \n",
              "8061  -3.566724          NaN  \n",
              "8062  -3.643652          NaN  \n",
              "8063 -10.919237          NaN  \n",
              "\n",
              "[8064 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-624eb29e-0704-4018-9bab-2579b54e55ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fp1</th>\n",
              "      <th>AF3</th>\n",
              "      <th>F3</th>\n",
              "      <th>F7</th>\n",
              "      <th>FC5</th>\n",
              "      <th>FC1</th>\n",
              "      <th>C3</th>\n",
              "      <th>T7</th>\n",
              "      <th>CP5</th>\n",
              "      <th>CP1</th>\n",
              "      <th>...</th>\n",
              "      <th>Cz</th>\n",
              "      <th>C4</th>\n",
              "      <th>T8</th>\n",
              "      <th>CP6</th>\n",
              "      <th>CP2</th>\n",
              "      <th>P4</th>\n",
              "      <th>P8</th>\n",
              "      <th>PO4</th>\n",
              "      <th>O2</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.057813</td>\n",
              "      <td>-1.335266</td>\n",
              "      <td>4.640480</td>\n",
              "      <td>0.219573</td>\n",
              "      <td>7.473817</td>\n",
              "      <td>2.314842</td>\n",
              "      <td>1.918097</td>\n",
              "      <td>-9.257533</td>\n",
              "      <td>9.089943</td>\n",
              "      <td>-7.104519</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.241480</td>\n",
              "      <td>1.415335</td>\n",
              "      <td>2.406646</td>\n",
              "      <td>12.864059</td>\n",
              "      <td>4.021099</td>\n",
              "      <td>-2.828598</td>\n",
              "      <td>-2.588735</td>\n",
              "      <td>2.637905</td>\n",
              "      <td>-5.226618</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.367408</td>\n",
              "      <td>10.259654</td>\n",
              "      <td>3.345409</td>\n",
              "      <td>7.897852</td>\n",
              "      <td>-2.446051</td>\n",
              "      <td>-1.655035</td>\n",
              "      <td>-6.301423</td>\n",
              "      <td>-7.290317</td>\n",
              "      <td>-3.546453</td>\n",
              "      <td>-5.705187</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.568397</td>\n",
              "      <td>-5.651418</td>\n",
              "      <td>-0.096730</td>\n",
              "      <td>-4.930759</td>\n",
              "      <td>-1.722504</td>\n",
              "      <td>-6.111309</td>\n",
              "      <td>0.094893</td>\n",
              "      <td>-3.521353</td>\n",
              "      <td>1.887093</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.783132</td>\n",
              "      <td>4.133553</td>\n",
              "      <td>-0.951680</td>\n",
              "      <td>-1.624803</td>\n",
              "      <td>-1.827309</td>\n",
              "      <td>-2.280364</td>\n",
              "      <td>-2.279225</td>\n",
              "      <td>9.151344</td>\n",
              "      <td>-0.239575</td>\n",
              "      <td>-0.057604</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.132823</td>\n",
              "      <td>-0.521117</td>\n",
              "      <td>8.605298</td>\n",
              "      <td>-4.499946</td>\n",
              "      <td>-3.232839</td>\n",
              "      <td>-4.249645</td>\n",
              "      <td>-3.687167</td>\n",
              "      <td>-7.383004</td>\n",
              "      <td>-4.489537</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.690217</td>\n",
              "      <td>-0.814000</td>\n",
              "      <td>2.295469</td>\n",
              "      <td>0.901445</td>\n",
              "      <td>8.323679</td>\n",
              "      <td>1.127906</td>\n",
              "      <td>6.356886</td>\n",
              "      <td>11.642082</td>\n",
              "      <td>9.354154</td>\n",
              "      <td>-1.662478</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.506117</td>\n",
              "      <td>-1.154866</td>\n",
              "      <td>-3.940251</td>\n",
              "      <td>7.390881</td>\n",
              "      <td>2.129897</td>\n",
              "      <td>-0.794675</td>\n",
              "      <td>-1.959021</td>\n",
              "      <td>2.774530</td>\n",
              "      <td>-6.323060</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.137114</td>\n",
              "      <td>6.420466</td>\n",
              "      <td>6.122230</td>\n",
              "      <td>10.015321</td>\n",
              "      <td>3.106394</td>\n",
              "      <td>3.183129</td>\n",
              "      <td>3.658535</td>\n",
              "      <td>4.571793</td>\n",
              "      <td>4.917712</td>\n",
              "      <td>-2.325940</td>\n",
              "      <td>...</td>\n",
              "      <td>1.813907</td>\n",
              "      <td>-6.444635</td>\n",
              "      <td>-27.680880</td>\n",
              "      <td>0.641364</td>\n",
              "      <td>1.996658</td>\n",
              "      <td>-0.445779</td>\n",
              "      <td>2.614021</td>\n",
              "      <td>6.161845</td>\n",
              "      <td>3.308816</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8059</th>\n",
              "      <td>2.371097</td>\n",
              "      <td>6.525279</td>\n",
              "      <td>-1.470521</td>\n",
              "      <td>-2.535683</td>\n",
              "      <td>-8.222570</td>\n",
              "      <td>-2.062185</td>\n",
              "      <td>-5.890198</td>\n",
              "      <td>11.508550</td>\n",
              "      <td>-14.298769</td>\n",
              "      <td>9.859735</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>-0.032451</td>\n",
              "      <td>12.929205</td>\n",
              "      <td>-27.406610</td>\n",
              "      <td>-14.864499</td>\n",
              "      <td>-6.631102</td>\n",
              "      <td>7.509646</td>\n",
              "      <td>-25.823920</td>\n",
              "      <td>-3.558200</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8060</th>\n",
              "      <td>5.408372</td>\n",
              "      <td>7.813431</td>\n",
              "      <td>-5.203169</td>\n",
              "      <td>-13.254773</td>\n",
              "      <td>-18.839062</td>\n",
              "      <td>-1.866768</td>\n",
              "      <td>-8.164257</td>\n",
              "      <td>17.100103</td>\n",
              "      <td>-23.600410</td>\n",
              "      <td>27.898805</td>\n",
              "      <td>...</td>\n",
              "      <td>3.976006</td>\n",
              "      <td>6.957139</td>\n",
              "      <td>11.972493</td>\n",
              "      <td>-52.080426</td>\n",
              "      <td>-29.577173</td>\n",
              "      <td>-11.663913</td>\n",
              "      <td>5.416705</td>\n",
              "      <td>-57.219852</td>\n",
              "      <td>-11.860173</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8061</th>\n",
              "      <td>-1.308237</td>\n",
              "      <td>1.166170</td>\n",
              "      <td>-3.158261</td>\n",
              "      <td>-9.249685</td>\n",
              "      <td>-7.438499</td>\n",
              "      <td>0.591557</td>\n",
              "      <td>-1.791961</td>\n",
              "      <td>16.107009</td>\n",
              "      <td>-9.831608</td>\n",
              "      <td>17.049193</td>\n",
              "      <td>...</td>\n",
              "      <td>3.080318</td>\n",
              "      <td>3.275846</td>\n",
              "      <td>-22.535264</td>\n",
              "      <td>-26.538050</td>\n",
              "      <td>-15.409645</td>\n",
              "      <td>-4.558339</td>\n",
              "      <td>4.718691</td>\n",
              "      <td>-28.783795</td>\n",
              "      <td>-3.566724</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8062</th>\n",
              "      <td>-2.095682</td>\n",
              "      <td>4.284166</td>\n",
              "      <td>-6.136204</td>\n",
              "      <td>-4.000436</td>\n",
              "      <td>-11.495979</td>\n",
              "      <td>-2.753036</td>\n",
              "      <td>-7.090403</td>\n",
              "      <td>5.933243</td>\n",
              "      <td>-13.990339</td>\n",
              "      <td>11.807037</td>\n",
              "      <td>...</td>\n",
              "      <td>0.583702</td>\n",
              "      <td>-1.521174</td>\n",
              "      <td>-12.615231</td>\n",
              "      <td>-26.169920</td>\n",
              "      <td>-16.098081</td>\n",
              "      <td>-6.099934</td>\n",
              "      <td>7.850973</td>\n",
              "      <td>-28.039497</td>\n",
              "      <td>-3.643652</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8063</th>\n",
              "      <td>2.641319</td>\n",
              "      <td>3.967536</td>\n",
              "      <td>-11.562283</td>\n",
              "      <td>-18.074156</td>\n",
              "      <td>-26.700735</td>\n",
              "      <td>-5.975564</td>\n",
              "      <td>-11.994061</td>\n",
              "      <td>3.563218</td>\n",
              "      <td>-24.599401</td>\n",
              "      <td>30.461931</td>\n",
              "      <td>...</td>\n",
              "      <td>4.718537</td>\n",
              "      <td>5.649721</td>\n",
              "      <td>8.920055</td>\n",
              "      <td>-52.330345</td>\n",
              "      <td>-30.160978</td>\n",
              "      <td>-8.524680</td>\n",
              "      <td>9.549617</td>\n",
              "      <td>-58.936422</td>\n",
              "      <td>-10.919237</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8064 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-624eb29e-0704-4018-9bab-2579b54e55ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-624eb29e-0704-4018-9bab-2579b54e55ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-624eb29e-0704-4018-9bab-2579b54e55ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e181ff10-e1e8-4d89-8c2e-241c38132eba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e181ff10-e1e8-4d89-8c2e-241c38132eba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e181ff10-e1e8-4d89-8c2e-241c38132eba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2d51c3a0-aeaa-4c19-87aa-c0460adc9df6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eeg_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d51c3a0-aeaa-4c19-87aa-c0460adc9df6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eeg_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eeg_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EMOTIONS DS"
      ],
      "metadata": {
        "id": "5u8YfJhNnxvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "emotions_df = pd.read_csv('/content/gdrive/MyDrive/datasets/EEG/emotions.csv')\n",
        "emotions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "T2pf4gYk2Y1L",
        "outputId": "cb2f76ac-a2c7-475c-f28a-42a9fe86c180"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
              "0          4.620      30.3    -356.0     15.60      26.3       1.070   \n",
              "1         28.800      33.1      32.0     25.80      22.8       6.550   \n",
              "2          8.900      29.4    -416.0     16.70      23.7      79.900   \n",
              "3         14.900      31.6    -143.0     19.80      24.3      -0.584   \n",
              "4         28.300      31.3      45.2     27.30      24.5      34.800   \n",
              "...          ...       ...       ...       ...       ...         ...   \n",
              "2127      32.400      32.2      32.2     30.80      23.4       1.640   \n",
              "2128      16.300      31.3    -284.0     14.30      23.9       4.200   \n",
              "2129      -0.547      28.3    -259.0     15.80      26.7       9.080   \n",
              "2130      16.800      19.9    -288.0      8.34      26.0       2.460   \n",
              "2131      27.000      32.0      31.8     25.00      28.9       4.990   \n",
              "\n",
              "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  \\\n",
              "0          0.411     -15.700       2.060        3.15  ...      23.50   \n",
              "1          1.680       2.880       3.830       -4.82  ...     -23.30   \n",
              "2          3.360      90.200      89.900        2.03  ...     462.00   \n",
              "3         -0.284       8.820       2.300       -1.97  ...     299.00   \n",
              "4         -5.790       3.060      41.400        5.52  ...      12.00   \n",
              "...          ...         ...         ...         ...  ...        ...   \n",
              "2127      -2.030       0.647      -0.121       -1.10  ...     -21.70   \n",
              "2128       1.090       4.460       4.720        6.63  ...     594.00   \n",
              "2129       6.900      12.700       2.030        4.64  ...     370.00   \n",
              "2130       1.580     -16.000       1.690        4.74  ...     124.00   \n",
              "2131       1.950       6.210       3.490       -3.51  ...       1.95   \n",
              "\n",
              "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  \\\n",
              "0        20.300     20.300      23.50     -215.0     280.00    -162.00   \n",
              "1       -21.800    -21.800     -23.30      182.0       2.57     -31.60   \n",
              "2      -233.000   -233.000     462.00     -267.0     281.00    -148.00   \n",
              "3      -243.000   -243.000     299.00      132.0     -12.40       9.53   \n",
              "4        38.100     38.100      12.00      119.0     -17.60      23.90   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "2127      0.218      0.218     -21.70       95.2     -19.90      47.20   \n",
              "2128   -324.000   -324.000     594.00      -35.5     142.00     -59.80   \n",
              "2129   -160.000   -160.000     370.00      408.0    -169.00     -10.50   \n",
              "2130    -27.600    -27.600     124.00     -656.0     552.00    -271.00   \n",
              "2131      1.810      1.810       1.95      110.0      -6.71      22.80   \n",
              "\n",
              "      fft_748_b  fft_749_b     label  \n",
              "0       -162.00     280.00  NEGATIVE  \n",
              "1        -31.60       2.57   NEUTRAL  \n",
              "2       -148.00     281.00  POSITIVE  \n",
              "3          9.53     -12.40  POSITIVE  \n",
              "4         23.90     -17.60   NEUTRAL  \n",
              "...         ...        ...       ...  \n",
              "2127      47.20     -19.90   NEUTRAL  \n",
              "2128     -59.80     142.00  POSITIVE  \n",
              "2129     -10.50    -169.00  NEGATIVE  \n",
              "2130    -271.00     552.00  NEGATIVE  \n",
              "2131      22.80      -6.71   NEUTRAL  \n",
              "\n",
              "[2132 rows x 2549 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfc6c492-82c6-47e8-bbd5-a5ece6996173\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># mean_0_a</th>\n",
              "      <th>mean_1_a</th>\n",
              "      <th>mean_2_a</th>\n",
              "      <th>mean_3_a</th>\n",
              "      <th>mean_4_a</th>\n",
              "      <th>mean_d_0_a</th>\n",
              "      <th>mean_d_1_a</th>\n",
              "      <th>mean_d_2_a</th>\n",
              "      <th>mean_d_3_a</th>\n",
              "      <th>mean_d_4_a</th>\n",
              "      <th>...</th>\n",
              "      <th>fft_741_b</th>\n",
              "      <th>fft_742_b</th>\n",
              "      <th>fft_743_b</th>\n",
              "      <th>fft_744_b</th>\n",
              "      <th>fft_745_b</th>\n",
              "      <th>fft_746_b</th>\n",
              "      <th>fft_747_b</th>\n",
              "      <th>fft_748_b</th>\n",
              "      <th>fft_749_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.620</td>\n",
              "      <td>30.3</td>\n",
              "      <td>-356.0</td>\n",
              "      <td>15.60</td>\n",
              "      <td>26.3</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.411</td>\n",
              "      <td>-15.700</td>\n",
              "      <td>2.060</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>23.50</td>\n",
              "      <td>20.300</td>\n",
              "      <td>20.300</td>\n",
              "      <td>23.50</td>\n",
              "      <td>-215.0</td>\n",
              "      <td>280.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>280.00</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.800</td>\n",
              "      <td>33.1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>25.80</td>\n",
              "      <td>22.8</td>\n",
              "      <td>6.550</td>\n",
              "      <td>1.680</td>\n",
              "      <td>2.880</td>\n",
              "      <td>3.830</td>\n",
              "      <td>-4.82</td>\n",
              "      <td>...</td>\n",
              "      <td>-23.30</td>\n",
              "      <td>-21.800</td>\n",
              "      <td>-21.800</td>\n",
              "      <td>-23.30</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>2.57</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.900</td>\n",
              "      <td>29.4</td>\n",
              "      <td>-416.0</td>\n",
              "      <td>16.70</td>\n",
              "      <td>23.7</td>\n",
              "      <td>79.900</td>\n",
              "      <td>3.360</td>\n",
              "      <td>90.200</td>\n",
              "      <td>89.900</td>\n",
              "      <td>2.03</td>\n",
              "      <td>...</td>\n",
              "      <td>462.00</td>\n",
              "      <td>-233.000</td>\n",
              "      <td>-233.000</td>\n",
              "      <td>462.00</td>\n",
              "      <td>-267.0</td>\n",
              "      <td>281.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>281.00</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.900</td>\n",
              "      <td>31.6</td>\n",
              "      <td>-143.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>24.3</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>8.820</td>\n",
              "      <td>2.300</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>...</td>\n",
              "      <td>299.00</td>\n",
              "      <td>-243.000</td>\n",
              "      <td>-243.000</td>\n",
              "      <td>299.00</td>\n",
              "      <td>132.0</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>9.53</td>\n",
              "      <td>9.53</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.300</td>\n",
              "      <td>31.3</td>\n",
              "      <td>45.2</td>\n",
              "      <td>27.30</td>\n",
              "      <td>24.5</td>\n",
              "      <td>34.800</td>\n",
              "      <td>-5.790</td>\n",
              "      <td>3.060</td>\n",
              "      <td>41.400</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>12.00</td>\n",
              "      <td>38.100</td>\n",
              "      <td>38.100</td>\n",
              "      <td>12.00</td>\n",
              "      <td>119.0</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>23.90</td>\n",
              "      <td>23.90</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2127</th>\n",
              "      <td>32.400</td>\n",
              "      <td>32.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>30.80</td>\n",
              "      <td>23.4</td>\n",
              "      <td>1.640</td>\n",
              "      <td>-2.030</td>\n",
              "      <td>0.647</td>\n",
              "      <td>-0.121</td>\n",
              "      <td>-1.10</td>\n",
              "      <td>...</td>\n",
              "      <td>-21.70</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0.218</td>\n",
              "      <td>-21.70</td>\n",
              "      <td>95.2</td>\n",
              "      <td>-19.90</td>\n",
              "      <td>47.20</td>\n",
              "      <td>47.20</td>\n",
              "      <td>-19.90</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2128</th>\n",
              "      <td>16.300</td>\n",
              "      <td>31.3</td>\n",
              "      <td>-284.0</td>\n",
              "      <td>14.30</td>\n",
              "      <td>23.9</td>\n",
              "      <td>4.200</td>\n",
              "      <td>1.090</td>\n",
              "      <td>4.460</td>\n",
              "      <td>4.720</td>\n",
              "      <td>6.63</td>\n",
              "      <td>...</td>\n",
              "      <td>594.00</td>\n",
              "      <td>-324.000</td>\n",
              "      <td>-324.000</td>\n",
              "      <td>594.00</td>\n",
              "      <td>-35.5</td>\n",
              "      <td>142.00</td>\n",
              "      <td>-59.80</td>\n",
              "      <td>-59.80</td>\n",
              "      <td>142.00</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2129</th>\n",
              "      <td>-0.547</td>\n",
              "      <td>28.3</td>\n",
              "      <td>-259.0</td>\n",
              "      <td>15.80</td>\n",
              "      <td>26.7</td>\n",
              "      <td>9.080</td>\n",
              "      <td>6.900</td>\n",
              "      <td>12.700</td>\n",
              "      <td>2.030</td>\n",
              "      <td>4.64</td>\n",
              "      <td>...</td>\n",
              "      <td>370.00</td>\n",
              "      <td>-160.000</td>\n",
              "      <td>-160.000</td>\n",
              "      <td>370.00</td>\n",
              "      <td>408.0</td>\n",
              "      <td>-169.00</td>\n",
              "      <td>-10.50</td>\n",
              "      <td>-10.50</td>\n",
              "      <td>-169.00</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2130</th>\n",
              "      <td>16.800</td>\n",
              "      <td>19.9</td>\n",
              "      <td>-288.0</td>\n",
              "      <td>8.34</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.460</td>\n",
              "      <td>1.580</td>\n",
              "      <td>-16.000</td>\n",
              "      <td>1.690</td>\n",
              "      <td>4.74</td>\n",
              "      <td>...</td>\n",
              "      <td>124.00</td>\n",
              "      <td>-27.600</td>\n",
              "      <td>-27.600</td>\n",
              "      <td>124.00</td>\n",
              "      <td>-656.0</td>\n",
              "      <td>552.00</td>\n",
              "      <td>-271.00</td>\n",
              "      <td>-271.00</td>\n",
              "      <td>552.00</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2131</th>\n",
              "      <td>27.000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.8</td>\n",
              "      <td>25.00</td>\n",
              "      <td>28.9</td>\n",
              "      <td>4.990</td>\n",
              "      <td>1.950</td>\n",
              "      <td>6.210</td>\n",
              "      <td>3.490</td>\n",
              "      <td>-3.51</td>\n",
              "      <td>...</td>\n",
              "      <td>1.95</td>\n",
              "      <td>1.810</td>\n",
              "      <td>1.810</td>\n",
              "      <td>1.95</td>\n",
              "      <td>110.0</td>\n",
              "      <td>-6.71</td>\n",
              "      <td>22.80</td>\n",
              "      <td>22.80</td>\n",
              "      <td>-6.71</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2132 rows × 2549 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfc6c492-82c6-47e8-bbd5-a5ece6996173')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfc6c492-82c6-47e8-bbd5-a5ece6996173 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfc6c492-82c6-47e8-bbd5-a5ece6996173');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6180b0f-8844-465d-b864-4a73d0b3a882\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6180b0f-8844-465d-b864-4a73d0b3a882')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6180b0f-8844-465d-b864-4a73d0b3a882 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e01bedf9-5b2a-423c-aeed-88bb54fd05b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('emotions_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e01bedf9-5b2a-423c-aeed-88bb54fd05b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('emotions_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "emotions_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMBINE DS - TBD - IN -PROGRESSS"
      ],
      "metadata": {
        "id": "C6wati4zJibf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from scipy.signal import butter, sosfiltfilt\n",
        "\n",
        "# --- Securely store your API key ---\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# --- Select the Gemini model ---\n",
        "model_name = 'gemini-2.0-flash'\n",
        "model = genai.GenerativeModel(model_name)\n",
        "\n",
        "# --- Load pre-extracted features ---\n",
        "df_features = pd.read_csv(\"/content/gdrive/MyDrive/datasets/EEG/emotions.csv\")\n",
        "X_features = df_features.iloc[:,:-1].values\n",
        "y = df_features.iloc[:, -1].values\n",
        "\n",
        "# --- Load raw EEG data ---\n",
        "df_raw = pd.read_csv(\"/content/gdrive/MyDrive/datasets/EEG/features_raw.csv\")\n",
        "X_raw = df_raw.values\n",
        "\n",
        "# --- Preprocess raw EEG data (Bandpass filter) ---\n",
        "def bandpass_filter(data, lowcut, highcut, fs=256, order=4): # Increased fs to 256\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], btype='band', output='sos')\n",
        "    filtered_data = sosfiltfilt(sos, data)\n",
        "    return filtered_data\n",
        "\n",
        "\n",
        "# --- Extract features from raw EEG data ---\n",
        "def extract_features_raw(data):\n",
        "    alpha = bandpass_filter(data, 8, 12)\n",
        "    beta = bandpass_filter(data, 13, 30)\n",
        "    gamma = bandpass_filter(data, 30, 80)\n",
        "    features = []\n",
        "    for band in [alpha, beta, gamma]:\n",
        "        # Check for NaN values after calculations\n",
        "        mean_val = np.mean(band)\n",
        "        std_val = np.std(band)\n",
        "\n",
        "        if np.isnan(mean_val):\n",
        "            print(\"Warning: NaN encountered in mean calculation. Replacing with 0.\")\n",
        "            mean_val = 0  # Or another appropriate value\n",
        "        if np.isnan(std_val):\n",
        "            print(\"Warning: NaN encountered in std calculation. Replacing with 0.\")\n",
        "            std_val = 0  # Or another appropriate value\n",
        "\n",
        "        features.extend([mean_val, std_val])\n",
        "    return features\n",
        "\n",
        "# --- Calculate X_raw_features before using it ---\n",
        "X_raw_features = np.apply_along_axis(extract_features_raw, 1, X_raw)\n",
        "\n",
        "# --- Combine features ---\n",
        "# Calculate the number of times to repeat X_features to match X_raw_features\n",
        "num_repeats = X_raw_features.shape[0] // X_features.shape[0]\n",
        "\n",
        "# Repeat the X_features to match the number of rows in X_raw_features\n",
        "X_features_repeated = np.repeat(X_features, num_repeats, axis=0)\n",
        "\n",
        "# Trim or pad X_features_repeated to match X_raw_features exactly\n",
        "min_rows = min(X_features_repeated.shape[0], X_raw_features.shape[0])\n",
        "X_features_repeated = X_features_repeated[:min_rows]\n",
        "X_raw_features = X_raw_features[:min_rows]\n",
        "\n",
        "\n",
        "# Now you can concatenate\n",
        "\n",
        "# Impute NaN values using SimpleImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')  # Use 'mean', 'median', or 'constant'\n",
        "\n",
        "\n",
        "X_combined = np.concatenate((X_features_repeated, X_raw_features), axis=1)\n",
        "X_combined = imputer.fit_transform(X_combined)\n",
        "\n",
        "# After creating X_combined:\n",
        "X_combined_df = pd.DataFrame(X_combined)  # Convert to DataFrame for easier analysis\n",
        "\n",
        "# Remove rows with NaN values\n",
        "X_combined = X_combined[~np.isnan(X_combined).any(axis=1)]\n",
        "\n",
        "\n",
        "# Calculate standard deviation for each column (feature)\n",
        "std_devs = X_combined_df.std()\n",
        "\n",
        "# Check for features with very low or zero standard deviation\n",
        "near_constant_features = std_devs[std_devs < 1e-6].index.tolist()  # Adjust threshold if needed\n",
        "\n",
        "print(\"Near-constant features:\", near_constant_features)\n",
        "\n",
        "# Check for NaN or Inf values in X_combined\n",
        "print(\"NaN values in X_combined:\", np.isnan(X_combined).any())\n",
        "print(\"Inf values in X_combined:\", np.isinf(X_combined).any())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Handle Missing Labels (Using Mode Imputation):\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "y = imputer.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# --- Label Mapping:\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "y = np.vectorize(label_mapping.get)(y)\n",
        "\n",
        "# --- Train-test split ---\n",
        "# Trim or pad y to match X_combined exactly\n",
        "min_rows = min(X_combined.shape[0], y.shape[0])\n",
        "X_combined = X_combined[:min_rows]\n",
        "y = y[:min_rows]\n",
        "\n",
        "# Adjust y to match the new shape of X_combined\n",
        "y = y[:X_combined.shape[0]]  # Assuming y corresponds to rows in X_combined\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# --- Model Selection and Hyperparameter Tuning (using GridSearchCV) ---\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# --- AI Agent Structure ---\n",
        "\n",
        "class EEGAgent:\n",
        "    def __init__(self, svm_model, gemini_model):\n",
        "        self.svm_model = svm_model\n",
        "        self.gemini_model = gemini_model\n",
        "        self.emotion_mapping = {\n",
        "            0: \"NEGATIVE\",\n",
        "            1: \"NEUTRAL\",\n",
        "            2: \"POSITIVE\"\n",
        "        }\n",
        "        self.dialogue_history = []\n",
        "\n",
        "    def perceive(self, eeg_data, user_utterance=None):\n",
        "        \"\"\"\n",
        "        Perceives the environment and user input.\n",
        "\n",
        "        Args:\n",
        "            eeg_data: EEG data for emotion recognition.\n",
        "            user_utterance: Text or speech input from the user.\n",
        "        \"\"\"\n",
        "        # 1. Emotion Recognition\n",
        "        emotion_label = self.svm_model.predict([eeg_data])\n",
        "        emotion_category = self.emotion_mapping[emotion_label]\n",
        "\n",
        "        # 2. Store user utterance\n",
        "        if user_utterance:\n",
        "            self.dialogue_history.append(user_utterance)\n",
        "\n",
        "        return emotion_category, user_utterance\n",
        "\n",
        "    def reason_and_decide(self, emotion_category, user_utterance):\n",
        "        \"\"\"\n",
        "        Reasons about the situation and decides on an action.\n",
        "\n",
        "        Args:\n",
        "            emotion_category: The recognized emotion category.\n",
        "            user_utterance: The user's utterance.\n",
        "        \"\"\"\n",
        "        # Prepare input for Gemini 2.0\n",
        "        gemini_input = f\"\"\"\n",
        "        Emotion: {emotion_category}\n",
        "        User Utterance: {user_utterance}\n",
        "        Dialogue History: {self.dialogue_history}\n",
        "        \"\"\"\n",
        "\n",
        "        # Call Gemini 2.0 API\n",
        "        response = self.gemini_model.generate_content(contents=[gemini_input])\n",
        "        agent_response = response.text\n",
        "\n",
        "        #... (Add more complex reasoning and decision-making here)\n",
        "\n",
        "        return agent_response\n",
        "\n",
        "    def act(self, agent_response, emotion_category):\n",
        "        \"\"\"\n",
        "        Takes action based on the decision.\n",
        "\n",
        "        Args:\n",
        "            agent_response: The generated response from Gemini 2.0.\n",
        "            emotion_category: The recognized emotion category.\n",
        "        \"\"\"\n",
        "        print(f\"Agent: {agent_response}\")\n",
        "\n",
        "        #... (Trigger other actions based on emotion and context)\n",
        "\n",
        "# --- Instantiate the AI agent ---\n",
        "agent = EEGAgent(svm_model=best_model, gemini_model=model)\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Simulate EEG data and user utterance\n",
        "eeg_data = X_test  # Example EEG data\n",
        "user_utterance = \"This is how I feel.\"\n",
        "\n",
        "# Perceive the environment and user input\n",
        "emotion_category, user_utterance = agent.perceive(eeg_data, user_utterance)\n",
        "\n",
        "# Reason and decide on an action\n",
        "agent_response = agent.reason_and_decide(emotion_category, user_utterance)\n",
        "\n",
        "# Act based on the decision\n",
        "agent.act(agent_response, emotion_category)"
      ],
      "metadata": {
        "id": "v_o5ELcCJgDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AI Agent Structure ---\n",
        "\n",
        "class EEGAgent:\n",
        "    def __init__(self, svm_model, gemini_model):\n",
        "        self.svm_model = svm_model\n",
        "        self.gemini_model = gemini_model\n",
        "        self.emotion_mapping = {\n",
        "            0: \"NEGATIVE\",\n",
        "            1: \"NEUTRAL\",\n",
        "            2: \"POSITIVE\"\n",
        "        }\n",
        "        self.dialogue_history = []\n",
        "\n",
        "    def perceive(self, eeg_data, user_utterance=None):\n",
        "        \"\"\"\n",
        "        Perceives the environment and user input.\n",
        "\n",
        "        Args:\n",
        "            eeg_data: EEG data for emotion recognition.\n",
        "            user_utterance: Text or speech input from the user.\n",
        "        \"\"\"\n",
        "        # 1. Emotion Recognition\n",
        "        #emotion_label = self.svm_model.predict([eeg_data])\n",
        "        emotion_label = self.svm_model.predict(eeg_data)[0]\n",
        "\n",
        "        emotion_category = self.emotion_mapping[emotion_label]\n",
        "\n",
        "        # 2. Store user utterance\n",
        "        if user_utterance:\n",
        "            self.dialogue_history.append(user_utterance)\n",
        "\n",
        "        return emotion_category, user_utterance\n",
        "\n",
        "    def reason_and_decide(self, emotion_category, user_utterance):\n",
        "        \"\"\"\n",
        "        Reasons about the situation and decides on an action.\n",
        "\n",
        "        Args:\n",
        "            emotion_category: The recognized emotion category.\n",
        "            user_utterance: The user's utterance.\n",
        "        \"\"\"\n",
        "        # Prepare input for Gemini 2.0\n",
        "        gemini_input = f\"\"\"\n",
        "        Emotion: {emotion_category}\n",
        "        User Utterance: {user_utterance}\n",
        "        Dialogue History: {self.dialogue_history}\n",
        "        \"\"\"\n",
        "\n",
        "        # Call Gemini 2.0 API\n",
        "        response = self.gemini_model.generate_content(contents=[gemini_input])\n",
        "        agent_response = response.text\n",
        "\n",
        "        #... (Add more complex reasoning and decision-making here)\n",
        "\n",
        "        return agent_response\n",
        "\n",
        "    def act(self, agent_response, emotion_category):\n",
        "        \"\"\"\n",
        "        Takes action based on the decision.\n",
        "\n",
        "        Args:\n",
        "            agent_response: The generated response from Gemini 2.0.\n",
        "            emotion_category: The recognized emotion category.\n",
        "        \"\"\"\n",
        "        print(f\"Agent: {agent_response}\")\n",
        "\n",
        "        #... (Trigger other actions based on emotion and context)\n",
        "\n",
        "# --- Instantiate the AI agent ---\n",
        "agent = EEGAgent(svm_model=best_model, gemini_model=model)\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Simulate EEG data and user utterance\n",
        "eeg_data = X_test  # Example EEG data\n",
        "user_utterance = \"This is how I feel.\"\n",
        "\n",
        "# Perceive the environment and user input\n",
        "emotion_category, user_utterance = agent.perceive(eeg_data, user_utterance)\n",
        "\n",
        "# Reason and decide on an action\n",
        "agent_response = agent.reason_and_decide(emotion_category, user_utterance)\n",
        "\n",
        "# Act based on the decision\n",
        "agent.act(agent_response, emotion_category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "LXBWiUkbRpVO",
        "outputId": "2f4b13b1-a3d4-4d0d-f19a-6014ced14eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: Okay, I understand. You're stating your feelings, which you've described as neutral. Is there anything else you'd like to tell me about how you're feeling, or anything you'd like to discuss?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation"
      ],
      "metadata": {
        "id": "ZsK_gwuuQLQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POC CODE"
      ],
      "metadata": {
        "id": "aPotifUNaYA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/oliverright/eeg-brain-signals-emotion-classification/notebook"
      ],
      "metadata": {
        "id": "yWTX7xwVcXeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline  # For easier scaling\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 1. Data Loading:\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/datasets/EEG/emotions.csv\")\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# 2. Handle Missing Labels:\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "y = imputer.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# 3. Label Mapping:\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "y = np.vectorize(label_mapping.get)(y)\n",
        "\n",
        "# 4. Data Splitting:\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 5. Model Selection and Training:\n",
        "method = 'svm'  # Or 'random_forest'\n",
        "method = 'random_forest'\n",
        "#method = 'knn'\n",
        "\n",
        "#if grid in locals():\n",
        "if 'grid' in locals():\n",
        "  del grid\n",
        "  print('grid deleted')\n",
        "else:\n",
        "  print('grid not found')\n",
        "\n",
        "if 'best_model' in locals():\n",
        "  del best_model\n",
        "  print('best_model deleted')\n",
        "else:\n",
        "  print('best_model not found')\n",
        "\n",
        "if method == 'svm':\n",
        "    scaler = StandardScaler()  # Scale BEFORE training\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}\n",
        "    grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=10, cv=5, scoring='f1_macro')\n",
        "    grid.fit(X_train_scaled, y_train)  # Use scaled data\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_scaled) # Predict on scaled test data\n",
        "\n",
        "elif method == 'random_forest':\n",
        "    #param_grid = {'n_estimators':, 'max_depth': [None, 5, 10, 20], 'min_samples_split':}\n",
        "    param_grid = {'n_estimators': [10, 100, 200], 'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
        "    grid = GridSearchCV(RandomForestClassifier(), param_grid, refit=True, verbose=10, cv=5, scoring='f1_macro')\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "elif method == 'knn':\n",
        "      pipeline = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
        "      param_grid = {'knn__n_neighbors': [1, 3, 5, 7, 9],  # Note the double underscore for pipeline parameters\n",
        "                    'knn__weights': ['uniform', 'distance'],\n",
        "                    'knn__metric': ['euclidean', 'manhattan']}\n",
        "      grid = GridSearchCV(pipeline, param_grid, refit=True, verbose=10, cv=5, scoring='f1_macro')\n",
        "      grid.fit(X_train, y_train)\n",
        "      best_model = grid.best_estimator_\n",
        "      y_pred = best_model.predict(X_test)\n",
        "\n",
        "#KNeighborsClassifier\n",
        "\n",
        "print('\\n')\n",
        "print(f\"Method: {method}\")\n",
        "print('\\n')\n",
        "\n",
        "# 6. Evaluation:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# No need for separate cross-validation; GridSearchCV already does it.\n",
        "print(f\"Best parameters: {grid.best_params_}\")  # Print the best parameters"
      ],
      "metadata": {
        "id": "NwVAOSQl4wLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdeb7ba-8dc0-4e08-a705-a96f6fd0665a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid not found\n",
            "best_model not found\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "[CV 1/5; 1/36] START max_depth=None, min_samples_split=2, n_estimators=10.......\n",
            "[CV 1/5; 1/36] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.979 total time=   0.5s\n",
            "[CV 2/5; 1/36] START max_depth=None, min_samples_split=2, n_estimators=10.......\n",
            "[CV 2/5; 1/36] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.973 total time=   0.4s\n",
            "[CV 3/5; 1/36] START max_depth=None, min_samples_split=2, n_estimators=10.......\n",
            "[CV 3/5; 1/36] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.971 total time=   0.4s\n",
            "[CV 4/5; 1/36] START max_depth=None, min_samples_split=2, n_estimators=10.......\n",
            "[CV 4/5; 1/36] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.953 total time=   0.4s\n",
            "[CV 5/5; 1/36] START max_depth=None, min_samples_split=2, n_estimators=10.......\n",
            "[CV 5/5; 1/36] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.976 total time=   0.4s\n",
            "[CV 1/5; 2/36] START max_depth=None, min_samples_split=2, n_estimators=100......\n",
            "[CV 1/5; 2/36] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.985 total time=   5.1s\n",
            "[CV 2/5; 2/36] START max_depth=None, min_samples_split=2, n_estimators=100......\n",
            "[CV 2/5; 2/36] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.991 total time=   4.3s\n",
            "[CV 3/5; 2/36] START max_depth=None, min_samples_split=2, n_estimators=100......\n",
            "[CV 3/5; 2/36] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.979 total time=   4.1s\n",
            "[CV 4/5; 2/36] START max_depth=None, min_samples_split=2, n_estimators=100......\n",
            "[CV 4/5; 2/36] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.973 total time=   5.2s\n",
            "[CV 5/5; 2/36] START max_depth=None, min_samples_split=2, n_estimators=100......\n",
            "[CV 5/5; 2/36] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.988 total time=   4.4s\n",
            "[CV 1/5; 3/36] START max_depth=None, min_samples_split=2, n_estimators=200......\n",
            "[CV 1/5; 3/36] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.985 total time=  22.3s\n",
            "[CV 2/5; 3/36] START max_depth=None, min_samples_split=2, n_estimators=200......\n",
            "[CV 2/5; 3/36] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.994 total time=  12.9s\n",
            "[CV 3/5; 3/36] START max_depth=None, min_samples_split=2, n_estimators=200......\n",
            "[CV 3/5; 3/36] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.979 total time=   8.8s\n",
            "[CV 4/5; 3/36] START max_depth=None, min_samples_split=2, n_estimators=200......\n",
            "[CV 4/5; 3/36] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.976 total time=   9.1s\n",
            "[CV 5/5; 3/36] START max_depth=None, min_samples_split=2, n_estimators=200......\n",
            "[CV 5/5; 3/36] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.985 total time=   8.4s\n",
            "[CV 1/5; 4/36] START max_depth=None, min_samples_split=5, n_estimators=10.......\n",
            "[CV 1/5; 4/36] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.976 total time=   0.6s\n",
            "[CV 2/5; 4/36] START max_depth=None, min_samples_split=5, n_estimators=10.......\n",
            "[CV 2/5; 4/36] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.977 total time=   0.6s\n",
            "[CV 3/5; 4/36] START max_depth=None, min_samples_split=5, n_estimators=10.......\n",
            "[CV 3/5; 4/36] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.971 total time=   0.6s\n",
            "[CV 4/5; 4/36] START max_depth=None, min_samples_split=5, n_estimators=10.......\n",
            "[CV 4/5; 4/36] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.965 total time=   0.6s\n",
            "[CV 5/5; 4/36] START max_depth=None, min_samples_split=5, n_estimators=10.......\n",
            "[CV 5/5; 4/36] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.988 total time=   0.6s\n",
            "[CV 1/5; 5/36] START max_depth=None, min_samples_split=5, n_estimators=100......\n",
            "[CV 1/5; 5/36] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.985 total time=   4.4s\n",
            "[CV 2/5; 5/36] START max_depth=None, min_samples_split=5, n_estimators=100......\n",
            "[CV 2/5; 5/36] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.991 total time=   4.3s\n",
            "[CV 3/5; 5/36] START max_depth=None, min_samples_split=5, n_estimators=100......\n",
            "[CV 3/5; 5/36] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.973 total time=   5.0s\n",
            "[CV 4/5; 5/36] START max_depth=None, min_samples_split=5, n_estimators=100......\n",
            "[CV 4/5; 5/36] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.976 total time=   4.4s\n",
            "[CV 5/5; 5/36] START max_depth=None, min_samples_split=5, n_estimators=100......\n",
            "[CV 5/5; 5/36] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.982 total time=   4.2s\n",
            "[CV 1/5; 6/36] START max_depth=None, min_samples_split=5, n_estimators=200......\n",
            "[CV 1/5; 6/36] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.988 total time=   9.4s\n",
            "[CV 2/5; 6/36] START max_depth=None, min_samples_split=5, n_estimators=200......\n",
            "[CV 2/5; 6/36] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.988 total time=   9.1s\n",
            "[CV 3/5; 6/36] START max_depth=None, min_samples_split=5, n_estimators=200......\n",
            "[CV 3/5; 6/36] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.976 total time=   9.3s\n",
            "[CV 4/5; 6/36] START max_depth=None, min_samples_split=5, n_estimators=200......\n",
            "[CV 4/5; 6/36] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.973 total time=   9.8s\n",
            "[CV 5/5; 6/36] START max_depth=None, min_samples_split=5, n_estimators=200......\n",
            "[CV 5/5; 6/36] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.988 total time=   9.4s\n",
            "[CV 1/5; 7/36] START max_depth=None, min_samples_split=10, n_estimators=10......\n",
            "[CV 1/5; 7/36] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.970 total time=   0.5s\n",
            "[CV 2/5; 7/36] START max_depth=None, min_samples_split=10, n_estimators=10......\n",
            "[CV 2/5; 7/36] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.988 total time=   0.5s\n",
            "[CV 3/5; 7/36] START max_depth=None, min_samples_split=10, n_estimators=10......\n",
            "[CV 3/5; 7/36] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.965 total time=   0.4s\n",
            "[CV 4/5; 7/36] START max_depth=None, min_samples_split=10, n_estimators=10......\n",
            "[CV 4/5; 7/36] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.964 total time=   0.4s\n",
            "[CV 5/5; 7/36] START max_depth=None, min_samples_split=10, n_estimators=10......\n",
            "[CV 5/5; 7/36] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.988 total time=   0.4s\n",
            "[CV 1/5; 8/36] START max_depth=None, min_samples_split=10, n_estimators=100.....\n",
            "[CV 1/5; 8/36] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.988 total time=   4.2s\n",
            "[CV 2/5; 8/36] START max_depth=None, min_samples_split=10, n_estimators=100.....\n",
            "[CV 2/5; 8/36] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.994 total time=   4.4s\n",
            "[CV 3/5; 8/36] START max_depth=None, min_samples_split=10, n_estimators=100.....\n",
            "[CV 3/5; 8/36] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.976 total time=   5.0s\n",
            "[CV 4/5; 8/36] START max_depth=None, min_samples_split=10, n_estimators=100.....\n",
            "[CV 4/5; 8/36] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.971 total time=   4.2s\n",
            "[CV 5/5; 8/36] START max_depth=None, min_samples_split=10, n_estimators=100.....\n",
            "[CV 5/5; 8/36] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.985 total time=   4.2s\n",
            "[CV 1/5; 9/36] START max_depth=None, min_samples_split=10, n_estimators=200.....\n",
            "[CV 1/5; 9/36] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.988 total time=   9.2s\n",
            "[CV 2/5; 9/36] START max_depth=None, min_samples_split=10, n_estimators=200.....\n",
            "[CV 2/5; 9/36] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.991 total time=   9.3s\n",
            "[CV 3/5; 9/36] START max_depth=None, min_samples_split=10, n_estimators=200.....\n",
            "[CV 3/5; 9/36] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.974 total time=   8.5s\n",
            "[CV 4/5; 9/36] START max_depth=None, min_samples_split=10, n_estimators=200.....\n",
            "[CV 4/5; 9/36] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.982 total time=   9.3s\n",
            "[CV 5/5; 9/36] START max_depth=None, min_samples_split=10, n_estimators=200.....\n",
            "[CV 5/5; 9/36] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.988 total time=  14.5s\n",
            "[CV 1/5; 10/36] START max_depth=5, min_samples_split=2, n_estimators=10.........\n",
            "[CV 1/5; 10/36] END max_depth=5, min_samples_split=2, n_estimators=10;, score=0.971 total time=   1.3s\n",
            "[CV 2/5; 10/36] START max_depth=5, min_samples_split=2, n_estimators=10.........\n",
            "[CV 2/5; 10/36] END max_depth=5, min_samples_split=2, n_estimators=10;, score=0.971 total time=   0.4s\n",
            "[CV 3/5; 10/36] START max_depth=5, min_samples_split=2, n_estimators=10.........\n",
            "[CV 3/5; 10/36] END max_depth=5, min_samples_split=2, n_estimators=10;, score=0.971 total time=   0.4s\n",
            "[CV 4/5; 10/36] START max_depth=5, min_samples_split=2, n_estimators=10.........\n",
            "[CV 4/5; 10/36] END max_depth=5, min_samples_split=2, n_estimators=10;, score=0.965 total time=   0.4s\n",
            "[CV 5/5; 10/36] START max_depth=5, min_samples_split=2, n_estimators=10.........\n",
            "[CV 5/5; 10/36] END max_depth=5, min_samples_split=2, n_estimators=10;, score=0.979 total time=   0.4s\n",
            "[CV 1/5; 11/36] START max_depth=5, min_samples_split=2, n_estimators=100........\n",
            "[CV 1/5; 11/36] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.976 total time=   3.8s\n",
            "[CV 2/5; 11/36] START max_depth=5, min_samples_split=2, n_estimators=100........\n",
            "[CV 2/5; 11/36] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.985 total time=   3.7s\n",
            "[CV 3/5; 11/36] START max_depth=5, min_samples_split=2, n_estimators=100........\n",
            "[CV 3/5; 11/36] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.968 total time=   3.2s\n",
            "[CV 4/5; 11/36] START max_depth=5, min_samples_split=2, n_estimators=100........\n",
            "[CV 4/5; 11/36] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.962 total time=   3.1s\n",
            "[CV 5/5; 11/36] START max_depth=5, min_samples_split=2, n_estimators=100........\n",
            "[CV 5/5; 11/36] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.979 total time=   3.9s\n",
            "[CV 1/5; 12/36] START max_depth=5, min_samples_split=2, n_estimators=200........\n",
            "[CV 1/5; 12/36] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.985 total time=   6.8s\n",
            "[CV 2/5; 12/36] START max_depth=5, min_samples_split=2, n_estimators=200........\n",
            "[CV 2/5; 12/36] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.985 total time=   6.6s\n",
            "[CV 3/5; 12/36] START max_depth=5, min_samples_split=2, n_estimators=200........\n",
            "[CV 3/5; 12/36] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.971 total time=   6.9s\n",
            "[CV 4/5; 12/36] START max_depth=5, min_samples_split=2, n_estimators=200........\n",
            "[CV 4/5; 12/36] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.970 total time=   6.4s\n",
            "[CV 5/5; 12/36] START max_depth=5, min_samples_split=2, n_estimators=200........\n",
            "[CV 5/5; 12/36] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.985 total time=   7.0s\n",
            "[CV 1/5; 13/36] START max_depth=5, min_samples_split=5, n_estimators=10.........\n",
            "[CV 1/5; 13/36] END max_depth=5, min_samples_split=5, n_estimators=10;, score=0.979 total time=   0.3s\n",
            "[CV 2/5; 13/36] START max_depth=5, min_samples_split=5, n_estimators=10.........\n",
            "[CV 2/5; 13/36] END max_depth=5, min_samples_split=5, n_estimators=10;, score=0.971 total time=   0.3s\n",
            "[CV 3/5; 13/36] START max_depth=5, min_samples_split=5, n_estimators=10.........\n",
            "[CV 3/5; 13/36] END max_depth=5, min_samples_split=5, n_estimators=10;, score=0.950 total time=   0.3s\n",
            "[CV 4/5; 13/36] START max_depth=5, min_samples_split=5, n_estimators=10.........\n",
            "[CV 4/5; 13/36] END max_depth=5, min_samples_split=5, n_estimators=10;, score=0.950 total time=   0.3s\n",
            "[CV 5/5; 13/36] START max_depth=5, min_samples_split=5, n_estimators=10.........\n",
            "[CV 5/5; 13/36] END max_depth=5, min_samples_split=5, n_estimators=10;, score=0.985 total time=   0.3s\n",
            "[CV 1/5; 14/36] START max_depth=5, min_samples_split=5, n_estimators=100........\n",
            "[CV 1/5; 14/36] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.985 total time=   3.4s\n",
            "[CV 2/5; 14/36] START max_depth=5, min_samples_split=5, n_estimators=100........\n",
            "[CV 2/5; 14/36] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.985 total time=   3.8s\n",
            "[CV 3/5; 14/36] START max_depth=5, min_samples_split=5, n_estimators=100........\n",
            "[CV 3/5; 14/36] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.965 total time=   3.4s\n",
            "[CV 4/5; 14/36] START max_depth=5, min_samples_split=5, n_estimators=100........\n",
            "[CV 4/5; 14/36] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.956 total time=   3.1s\n",
            "[CV 5/5; 14/36] START max_depth=5, min_samples_split=5, n_estimators=100........\n",
            "[CV 5/5; 14/36] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.988 total time=   3.1s\n",
            "[CV 1/5; 15/36] START max_depth=5, min_samples_split=5, n_estimators=200........\n",
            "[CV 1/5; 15/36] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.977 total time=   7.1s\n",
            "[CV 2/5; 15/36] START max_depth=5, min_samples_split=5, n_estimators=200........\n",
            "[CV 2/5; 15/36] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.982 total time=   6.2s\n",
            "[CV 3/5; 15/36] START max_depth=5, min_samples_split=5, n_estimators=200........\n",
            "[CV 3/5; 15/36] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.968 total time=   7.2s\n",
            "[CV 4/5; 15/36] START max_depth=5, min_samples_split=5, n_estimators=200........\n",
            "[CV 4/5; 15/36] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.971 total time=   6.3s\n",
            "[CV 5/5; 15/36] START max_depth=5, min_samples_split=5, n_estimators=200........\n",
            "[CV 5/5; 15/36] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.982 total time=   7.6s\n",
            "[CV 1/5; 16/36] START max_depth=5, min_samples_split=10, n_estimators=10........\n",
            "[CV 1/5; 16/36] END max_depth=5, min_samples_split=10, n_estimators=10;, score=0.974 total time=   0.3s\n",
            "[CV 2/5; 16/36] START max_depth=5, min_samples_split=10, n_estimators=10........\n",
            "[CV 2/5; 16/36] END max_depth=5, min_samples_split=10, n_estimators=10;, score=0.994 total time=   0.3s\n",
            "[CV 3/5; 16/36] START max_depth=5, min_samples_split=10, n_estimators=10........\n",
            "[CV 3/5; 16/36] END max_depth=5, min_samples_split=10, n_estimators=10;, score=0.962 total time=   0.3s\n",
            "[CV 4/5; 16/36] START max_depth=5, min_samples_split=10, n_estimators=10........\n",
            "[CV 4/5; 16/36] END max_depth=5, min_samples_split=10, n_estimators=10;, score=0.952 total time=   0.3s\n",
            "[CV 5/5; 16/36] START max_depth=5, min_samples_split=10, n_estimators=10........\n",
            "[CV 5/5; 16/36] END max_depth=5, min_samples_split=10, n_estimators=10;, score=0.977 total time=   0.3s\n",
            "[CV 1/5; 17/36] START max_depth=5, min_samples_split=10, n_estimators=100.......\n",
            "[CV 1/5; 17/36] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.985 total time=   3.1s\n",
            "[CV 2/5; 17/36] START max_depth=5, min_samples_split=10, n_estimators=100.......\n",
            "[CV 2/5; 17/36] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.988 total time=   3.2s\n",
            "[CV 3/5; 17/36] START max_depth=5, min_samples_split=10, n_estimators=100.......\n",
            "[CV 3/5; 17/36] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.965 total time=   4.1s\n",
            "[CV 4/5; 17/36] START max_depth=5, min_samples_split=10, n_estimators=100.......\n",
            "[CV 4/5; 17/36] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.968 total time=   3.2s\n",
            "[CV 5/5; 17/36] START max_depth=5, min_samples_split=10, n_estimators=100.......\n",
            "[CV 5/5; 17/36] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.982 total time=   3.2s\n",
            "[CV 1/5; 18/36] START max_depth=5, min_samples_split=10, n_estimators=200.......\n",
            "[CV 1/5; 18/36] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.979 total time=   7.2s\n",
            "[CV 2/5; 18/36] START max_depth=5, min_samples_split=10, n_estimators=200.......\n",
            "[CV 2/5; 18/36] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.982 total time=   6.3s\n",
            "[CV 3/5; 18/36] START max_depth=5, min_samples_split=10, n_estimators=200.......\n",
            "[CV 3/5; 18/36] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.971 total time=   7.0s\n",
            "[CV 4/5; 18/36] START max_depth=5, min_samples_split=10, n_estimators=200.......\n",
            "[CV 4/5; 18/36] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.965 total time=   6.4s\n",
            "[CV 5/5; 18/36] START max_depth=5, min_samples_split=10, n_estimators=200.......\n",
            "[CV 5/5; 18/36] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.982 total time=   6.9s\n",
            "[CV 1/5; 19/36] START max_depth=10, min_samples_split=2, n_estimators=10........\n",
            "[CV 1/5; 19/36] END max_depth=10, min_samples_split=2, n_estimators=10;, score=0.971 total time=   0.6s\n",
            "[CV 2/5; 19/36] START max_depth=10, min_samples_split=2, n_estimators=10........\n",
            "[CV 2/5; 19/36] END max_depth=10, min_samples_split=2, n_estimators=10;, score=0.976 total time=   0.5s\n",
            "[CV 3/5; 19/36] START max_depth=10, min_samples_split=2, n_estimators=10........\n",
            "[CV 3/5; 19/36] END max_depth=10, min_samples_split=2, n_estimators=10;, score=0.973 total time=   0.4s\n",
            "[CV 4/5; 19/36] START max_depth=10, min_samples_split=2, n_estimators=10........\n",
            "[CV 4/5; 19/36] END max_depth=10, min_samples_split=2, n_estimators=10;, score=0.952 total time=   0.4s\n",
            "[CV 5/5; 19/36] START max_depth=10, min_samples_split=2, n_estimators=10........\n",
            "[CV 5/5; 19/36] END max_depth=10, min_samples_split=2, n_estimators=10;, score=0.976 total time=   0.4s\n",
            "[CV 1/5; 20/36] START max_depth=10, min_samples_split=2, n_estimators=100.......\n",
            "[CV 1/5; 20/36] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.985 total time=   4.1s\n",
            "[CV 2/5; 20/36] START max_depth=10, min_samples_split=2, n_estimators=100.......\n",
            "[CV 2/5; 20/36] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.988 total time=   4.2s\n",
            "[CV 3/5; 20/36] START max_depth=10, min_samples_split=2, n_estimators=100.......\n",
            "[CV 3/5; 20/36] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.973 total time=   5.0s\n",
            "[CV 4/5; 20/36] START max_depth=10, min_samples_split=2, n_estimators=100.......\n",
            "[CV 4/5; 20/36] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.971 total time=   4.1s\n",
            "[CV 5/5; 20/36] START max_depth=10, min_samples_split=2, n_estimators=100.......\n",
            "[CV 5/5; 20/36] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.979 total time=   4.0s\n",
            "[CV 1/5; 21/36] START max_depth=10, min_samples_split=2, n_estimators=200.......\n",
            "[CV 1/5; 21/36] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.985 total time=   9.2s\n",
            "[CV 2/5; 21/36] START max_depth=10, min_samples_split=2, n_estimators=200.......\n",
            "[CV 2/5; 21/36] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.988 total time=   9.3s\n",
            "[CV 3/5; 21/36] START max_depth=10, min_samples_split=2, n_estimators=200.......\n",
            "[CV 3/5; 21/36] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.976 total time=   8.3s\n",
            "[CV 4/5; 21/36] START max_depth=10, min_samples_split=2, n_estimators=200.......\n",
            "[CV 4/5; 21/36] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.976 total time=   9.8s\n",
            "[CV 5/5; 21/36] START max_depth=10, min_samples_split=2, n_estimators=200.......\n",
            "[CV 5/5; 21/36] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.988 total time=   9.0s\n",
            "[CV 1/5; 22/36] START max_depth=10, min_samples_split=5, n_estimators=10........\n",
            "[CV 1/5; 22/36] END max_depth=10, min_samples_split=5, n_estimators=10;, score=0.982 total time=   0.5s\n",
            "[CV 2/5; 22/36] START max_depth=10, min_samples_split=5, n_estimators=10........\n",
            "[CV 2/5; 22/36] END max_depth=10, min_samples_split=5, n_estimators=10;, score=0.974 total time=   0.4s\n",
            "[CV 3/5; 22/36] START max_depth=10, min_samples_split=5, n_estimators=10........\n",
            "[CV 3/5; 22/36] END max_depth=10, min_samples_split=5, n_estimators=10;, score=0.973 total time=   0.4s\n",
            "[CV 4/5; 22/36] START max_depth=10, min_samples_split=5, n_estimators=10........\n",
            "[CV 4/5; 22/36] END max_depth=10, min_samples_split=5, n_estimators=10;, score=0.968 total time=   0.4s\n",
            "[CV 5/5; 22/36] START max_depth=10, min_samples_split=5, n_estimators=10........\n",
            "[CV 5/5; 22/36] END max_depth=10, min_samples_split=5, n_estimators=10;, score=0.971 total time=   0.4s\n",
            "[CV 1/5; 23/36] START max_depth=10, min_samples_split=5, n_estimators=100.......\n",
            "[CV 1/5; 23/36] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.988 total time=   4.1s\n",
            "[CV 2/5; 23/36] START max_depth=10, min_samples_split=5, n_estimators=100.......\n",
            "[CV 2/5; 23/36] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.994 total time=   4.2s\n",
            "[CV 3/5; 23/36] START max_depth=10, min_samples_split=5, n_estimators=100.......\n",
            "[CV 3/5; 23/36] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.971 total time=   5.0s\n",
            "[CV 4/5; 23/36] START max_depth=10, min_samples_split=5, n_estimators=100.......\n",
            "[CV 4/5; 23/36] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.973 total time=   4.1s\n",
            "[CV 5/5; 23/36] START max_depth=10, min_samples_split=5, n_estimators=100.......\n",
            "[CV 5/5; 23/36] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.982 total time=   4.1s\n",
            "[CV 1/5; 24/36] START max_depth=10, min_samples_split=5, n_estimators=200.......\n",
            "[CV 1/5; 24/36] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.988 total time=   9.1s\n",
            "[CV 2/5; 24/36] START max_depth=10, min_samples_split=5, n_estimators=200.......\n",
            "[CV 2/5; 24/36] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.991 total time=   9.3s\n",
            "[CV 3/5; 24/36] START max_depth=10, min_samples_split=5, n_estimators=200.......\n",
            "[CV 3/5; 24/36] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.976 total time=   8.2s\n",
            "[CV 4/5; 24/36] START max_depth=10, min_samples_split=5, n_estimators=200.......\n",
            "[CV 4/5; 24/36] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.976 total time=   9.3s\n",
            "[CV 5/5; 24/36] START max_depth=10, min_samples_split=5, n_estimators=200.......\n",
            "[CV 5/5; 24/36] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.985 total time=   9.1s\n",
            "[CV 1/5; 25/36] START max_depth=10, min_samples_split=10, n_estimators=10.......\n",
            "[CV 1/5; 25/36] END max_depth=10, min_samples_split=10, n_estimators=10;, score=0.982 total time=   0.6s\n",
            "[CV 2/5; 25/36] START max_depth=10, min_samples_split=10, n_estimators=10.......\n",
            "[CV 2/5; 25/36] END max_depth=10, min_samples_split=10, n_estimators=10;, score=0.991 total time=   0.4s\n",
            "[CV 3/5; 25/36] START max_depth=10, min_samples_split=10, n_estimators=10.......\n",
            "[CV 3/5; 25/36] END max_depth=10, min_samples_split=10, n_estimators=10;, score=0.971 total time=   0.4s\n",
            "[CV 4/5; 25/36] START max_depth=10, min_samples_split=10, n_estimators=10.......\n",
            "[CV 4/5; 25/36] END max_depth=10, min_samples_split=10, n_estimators=10;, score=0.968 total time=   0.4s\n",
            "[CV 5/5; 25/36] START max_depth=10, min_samples_split=10, n_estimators=10.......\n",
            "[CV 5/5; 25/36] END max_depth=10, min_samples_split=10, n_estimators=10;, score=0.979 total time=   0.4s\n",
            "[CV 1/5; 26/36] START max_depth=10, min_samples_split=10, n_estimators=100......\n",
            "[CV 1/5; 26/36] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.985 total time=   4.2s\n",
            "[CV 2/5; 26/36] START max_depth=10, min_samples_split=10, n_estimators=100......\n",
            "[CV 2/5; 26/36] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.991 total time=   4.1s\n",
            "[CV 3/5; 26/36] START max_depth=10, min_samples_split=10, n_estimators=100......\n",
            "[CV 3/5; 26/36] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.976 total time=   5.0s\n",
            "[CV 4/5; 26/36] START max_depth=10, min_samples_split=10, n_estimators=100......\n",
            "[CV 4/5; 26/36] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.970 total time=   4.1s\n",
            "[CV 5/5; 26/36] START max_depth=10, min_samples_split=10, n_estimators=100......\n",
            "[CV 5/5; 26/36] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.982 total time=   4.1s\n",
            "[CV 1/5; 27/36] START max_depth=10, min_samples_split=10, n_estimators=200......\n",
            "[CV 1/5; 27/36] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.988 total time=   9.1s\n",
            "[CV 2/5; 27/36] START max_depth=10, min_samples_split=10, n_estimators=200......\n",
            "[CV 2/5; 27/36] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.994 total time=   9.4s\n",
            "[CV 3/5; 27/36] START max_depth=10, min_samples_split=10, n_estimators=200......\n",
            "[CV 3/5; 27/36] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.971 total time=   8.4s\n",
            "[CV 4/5; 27/36] START max_depth=10, min_samples_split=10, n_estimators=200......\n",
            "[CV 4/5; 27/36] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.979 total time=   9.2s\n",
            "[CV 5/5; 27/36] START max_depth=10, min_samples_split=10, n_estimators=200......\n",
            "[CV 5/5; 27/36] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.988 total time=   8.9s\n",
            "[CV 1/5; 28/36] START max_depth=20, min_samples_split=2, n_estimators=10........\n",
            "[CV 1/5; 28/36] END max_depth=20, min_samples_split=2, n_estimators=10;, score=0.968 total time=   0.6s\n",
            "[CV 2/5; 28/36] START max_depth=20, min_samples_split=2, n_estimators=10........\n",
            "[CV 2/5; 28/36] END max_depth=20, min_samples_split=2, n_estimators=10;, score=0.982 total time=   0.5s\n",
            "[CV 3/5; 28/36] START max_depth=20, min_samples_split=2, n_estimators=10........\n",
            "[CV 3/5; 28/36] END max_depth=20, min_samples_split=2, n_estimators=10;, score=0.956 total time=   0.5s\n",
            "[CV 4/5; 28/36] START max_depth=20, min_samples_split=2, n_estimators=10........\n",
            "[CV 4/5; 28/36] END max_depth=20, min_samples_split=2, n_estimators=10;, score=0.976 total time=   0.4s\n",
            "[CV 5/5; 28/36] START max_depth=20, min_samples_split=2, n_estimators=10........\n",
            "[CV 5/5; 28/36] END max_depth=20, min_samples_split=2, n_estimators=10;, score=0.982 total time=   0.4s\n",
            "[CV 1/5; 29/36] START max_depth=20, min_samples_split=2, n_estimators=100.......\n",
            "[CV 1/5; 29/36] END max_depth=20, min_samples_split=2, n_estimators=100;, score=0.988 total time=   4.2s\n",
            "[CV 2/5; 29/36] START max_depth=20, min_samples_split=2, n_estimators=100.......\n",
            "[CV 2/5; 29/36] END max_depth=20, min_samples_split=2, n_estimators=100;, score=0.991 total time=   4.4s\n",
            "[CV 3/5; 29/36] START max_depth=20, min_samples_split=2, n_estimators=100.......\n",
            "[CV 3/5; 29/36] END max_depth=20, min_samples_split=2, n_estimators=100;, score=0.985 total time=   5.1s\n",
            "[CV 4/5; 29/36] START max_depth=20, min_samples_split=2, n_estimators=100.......\n",
            "[CV 4/5; 29/36] END max_depth=20, min_samples_split=2, n_estimators=100;, score=0.976 total time=   4.2s\n",
            "[CV 5/5; 29/36] START max_depth=20, min_samples_split=2, n_estimators=100.......\n",
            "[CV 5/5; 29/36] END max_depth=20, min_samples_split=2, n_estimators=100;, score=0.988 total time=   4.2s\n",
            "[CV 1/5; 30/36] START max_depth=20, min_samples_split=2, n_estimators=200.......\n",
            "[CV 1/5; 30/36] END max_depth=20, min_samples_split=2, n_estimators=200;, score=0.982 total time=   9.4s\n",
            "[CV 2/5; 30/36] START max_depth=20, min_samples_split=2, n_estimators=200.......\n",
            "[CV 2/5; 30/36] END max_depth=20, min_samples_split=2, n_estimators=200;, score=0.991 total time=   9.5s\n",
            "[CV 3/5; 30/36] START max_depth=20, min_samples_split=2, n_estimators=200.......\n",
            "[CV 3/5; 30/36] END max_depth=20, min_samples_split=2, n_estimators=200;, score=0.976 total time=   8.2s\n",
            "[CV 4/5; 30/36] START max_depth=20, min_samples_split=2, n_estimators=200.......\n",
            "[CV 4/5; 30/36] END max_depth=20, min_samples_split=2, n_estimators=200;, score=0.976 total time=   9.2s\n",
            "[CV 5/5; 30/36] START max_depth=20, min_samples_split=2, n_estimators=200.......\n",
            "[CV 5/5; 30/36] END max_depth=20, min_samples_split=2, n_estimators=200;, score=0.985 total time=   9.2s\n",
            "[CV 1/5; 31/36] START max_depth=20, min_samples_split=5, n_estimators=10........\n",
            "[CV 1/5; 31/36] END max_depth=20, min_samples_split=5, n_estimators=10;, score=0.965 total time=   0.4s\n",
            "[CV 2/5; 31/36] START max_depth=20, min_samples_split=5, n_estimators=10........\n",
            "[CV 2/5; 31/36] END max_depth=20, min_samples_split=5, n_estimators=10;, score=0.977 total time=   0.4s\n",
            "[CV 3/5; 31/36] START max_depth=20, min_samples_split=5, n_estimators=10........\n",
            "[CV 3/5; 31/36] END max_depth=20, min_samples_split=5, n_estimators=10;, score=0.968 total time=   0.5s\n",
            "[CV 4/5; 31/36] START max_depth=20, min_samples_split=5, n_estimators=10........\n",
            "[CV 4/5; 31/36] END max_depth=20, min_samples_split=5, n_estimators=10;, score=0.967 total time=   0.4s\n",
            "[CV 5/5; 31/36] START max_depth=20, min_samples_split=5, n_estimators=10........\n",
            "[CV 5/5; 31/36] END max_depth=20, min_samples_split=5, n_estimators=10;, score=0.988 total time=   0.4s\n",
            "[CV 1/5; 32/36] START max_depth=20, min_samples_split=5, n_estimators=100.......\n",
            "[CV 1/5; 32/36] END max_depth=20, min_samples_split=5, n_estimators=100;, score=0.988 total time=   4.1s\n",
            "[CV 2/5; 32/36] START max_depth=20, min_samples_split=5, n_estimators=100.......\n",
            "[CV 2/5; 32/36] END max_depth=20, min_samples_split=5, n_estimators=100;, score=0.994 total time=   4.8s\n",
            "[CV 3/5; 32/36] START max_depth=20, min_samples_split=5, n_estimators=100.......\n",
            "[CV 3/5; 32/36] END max_depth=20, min_samples_split=5, n_estimators=100;, score=0.976 total time=   4.7s\n",
            "[CV 4/5; 32/36] START max_depth=20, min_samples_split=5, n_estimators=100.......\n",
            "[CV 4/5; 32/36] END max_depth=20, min_samples_split=5, n_estimators=100;, score=0.982 total time=   4.2s\n",
            "[CV 5/5; 32/36] START max_depth=20, min_samples_split=5, n_estimators=100.......\n",
            "[CV 5/5; 32/36] END max_depth=20, min_samples_split=5, n_estimators=100;, score=0.985 total time=   4.6s\n",
            "[CV 1/5; 33/36] START max_depth=20, min_samples_split=5, n_estimators=200.......\n",
            "[CV 1/5; 33/36] END max_depth=20, min_samples_split=5, n_estimators=200;, score=0.988 total time=   9.0s\n",
            "[CV 2/5; 33/36] START max_depth=20, min_samples_split=5, n_estimators=200.......\n",
            "[CV 2/5; 33/36] END max_depth=20, min_samples_split=5, n_estimators=200;, score=0.991 total time=   9.5s\n",
            "[CV 3/5; 33/36] START max_depth=20, min_samples_split=5, n_estimators=200.......\n",
            "[CV 3/5; 33/36] END max_depth=20, min_samples_split=5, n_estimators=200;, score=0.974 total time=   8.8s\n",
            "[CV 4/5; 33/36] START max_depth=20, min_samples_split=5, n_estimators=200.......\n",
            "[CV 4/5; 33/36] END max_depth=20, min_samples_split=5, n_estimators=200;, score=0.979 total time=   9.1s\n",
            "[CV 5/5; 33/36] START max_depth=20, min_samples_split=5, n_estimators=200.......\n",
            "[CV 5/5; 33/36] END max_depth=20, min_samples_split=5, n_estimators=200;, score=0.985 total time=   9.3s\n",
            "[CV 1/5; 34/36] START max_depth=20, min_samples_split=10, n_estimators=10.......\n",
            "[CV 1/5; 34/36] END max_depth=20, min_samples_split=10, n_estimators=10;, score=0.985 total time=   0.4s\n",
            "[CV 2/5; 34/36] START max_depth=20, min_samples_split=10, n_estimators=10.......\n",
            "[CV 2/5; 34/36] END max_depth=20, min_samples_split=10, n_estimators=10;, score=0.977 total time=   0.5s\n",
            "[CV 3/5; 34/36] START max_depth=20, min_samples_split=10, n_estimators=10.......\n",
            "[CV 3/5; 34/36] END max_depth=20, min_samples_split=10, n_estimators=10;, score=0.968 total time=   0.4s\n",
            "[CV 4/5; 34/36] START max_depth=20, min_samples_split=10, n_estimators=10.......\n",
            "[CV 4/5; 34/36] END max_depth=20, min_samples_split=10, n_estimators=10;, score=0.952 total time=   0.5s\n",
            "[CV 5/5; 34/36] START max_depth=20, min_samples_split=10, n_estimators=10.......\n",
            "[CV 5/5; 34/36] END max_depth=20, min_samples_split=10, n_estimators=10;, score=0.982 total time=   0.5s\n",
            "[CV 1/5; 35/36] START max_depth=20, min_samples_split=10, n_estimators=100......\n",
            "[CV 1/5; 35/36] END max_depth=20, min_samples_split=10, n_estimators=100;, score=0.988 total time=   4.2s\n",
            "[CV 2/5; 35/36] START max_depth=20, min_samples_split=10, n_estimators=100......\n",
            "[CV 2/5; 35/36] END max_depth=20, min_samples_split=10, n_estimators=100;, score=0.991 total time=   5.2s\n",
            "[CV 3/5; 35/36] START max_depth=20, min_samples_split=10, n_estimators=100......\n",
            "[CV 3/5; 35/36] END max_depth=20, min_samples_split=10, n_estimators=100;, score=0.976 total time=   4.2s\n",
            "[CV 4/5; 35/36] START max_depth=20, min_samples_split=10, n_estimators=100......\n",
            "[CV 4/5; 35/36] END max_depth=20, min_samples_split=10, n_estimators=100;, score=0.973 total time=   4.3s\n",
            "[CV 5/5; 35/36] START max_depth=20, min_samples_split=10, n_estimators=100......\n",
            "[CV 5/5; 35/36] END max_depth=20, min_samples_split=10, n_estimators=100;, score=0.988 total time=   5.1s\n",
            "[CV 1/5; 36/36] START max_depth=20, min_samples_split=10, n_estimators=200......\n",
            "[CV 1/5; 36/36] END max_depth=20, min_samples_split=10, n_estimators=200;, score=0.985 total time=   8.4s\n",
            "[CV 2/5; 36/36] START max_depth=20, min_samples_split=10, n_estimators=200......\n",
            "[CV 2/5; 36/36] END max_depth=20, min_samples_split=10, n_estimators=200;, score=0.991 total time=   9.6s\n",
            "[CV 3/5; 36/36] START max_depth=20, min_samples_split=10, n_estimators=200......\n",
            "[CV 3/5; 36/36] END max_depth=20, min_samples_split=10, n_estimators=200;, score=0.974 total time=   9.3s\n",
            "[CV 4/5; 36/36] START max_depth=20, min_samples_split=10, n_estimators=200......\n",
            "[CV 4/5; 36/36] END max_depth=20, min_samples_split=10, n_estimators=200;, score=0.976 total time=   8.4s\n",
            "[CV 5/5; 36/36] START max_depth=20, min_samples_split=10, n_estimators=200......\n",
            "[CV 5/5; 36/36] END max_depth=20, min_samples_split=10, n_estimators=200;, score=0.988 total time=   9.2s\n",
            "\n",
            "\n",
            "Method: random_forest\n",
            "\n",
            "\n",
            "Accuracy: 0.9859484777517564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       142\n",
            "           1       1.00      1.00      1.00       143\n",
            "           2       0.98      0.98      0.98       142\n",
            "\n",
            "    accuracy                           0.99       427\n",
            "   macro avg       0.99      0.99      0.99       427\n",
            "weighted avg       0.99      0.99      0.99       427\n",
            "\n",
            "Confusion Matrix:\n",
            " [[139   0   3]\n",
            " [  0 143   0]\n",
            " [  3   0 139]]\n",
            "Best parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n')\n",
        "print(f\"Method: {method}\")\n",
        "print('\\n')\n",
        "\n",
        "# 6. Evaluation:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# No need for separate cross-validation; GridSearchCV already does it.\n",
        "print(f\"Best parameters: {grid.best_params_}\")  # Print the best parameters"
      ],
      "metadata": {
        "id": "sdZB7wdCM63c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI AGENT"
      ],
      "metadata": {
        "id": "GgZqKFIianqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai -q"
      ],
      "metadata": {
        "id": "gQqQvQD-6J2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GEMINI')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import google.generativeai as genai\n",
        "model_name = 'gemini-2.0-flash'\n",
        "model = genai.GenerativeModel(model_name)"
      ],
      "metadata": {
        "id": "nc7g7VFp6K4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EEGAgent"
      ],
      "metadata": {
        "id": "_yrB4oeV_w4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AI Agent Structure ---\n",
        "\n",
        "class EEGAgent:\n",
        "    def __init__(self, svm_model, gemini_model):\n",
        "        self.svm_model = svm_model\n",
        "        self.gemini_model = gemini_model\n",
        "        self.emotion_mapping = {\n",
        "            0: \"NEGATIVE\",\n",
        "            1: \"NEUTRAL\",\n",
        "            2: \"POSITIVE\"\n",
        "        }\n",
        "        self.dialogue_history = []\n",
        "\n",
        "    def perceive(self, eeg_data, user_utterance=None):\n",
        "        \"\"\"\n",
        "        Perceives the environment and user input.\n",
        "\n",
        "        Args:\n",
        "            eeg_data: EEG data for emotion recognition.\n",
        "            user_utterance: Text or speech input from the user.\n",
        "        \"\"\"\n",
        "        # 1. Emotion Recognition\n",
        "        #emotion_label = self.svm_model.predict([eeg_data])\n",
        "        # Reshape eeg_data to a 2D array with a single row if it's 1D\n",
        "        eeg_data = eeg_data.reshape(1, -1) if eeg_data.ndim == 1 else eeg_data\n",
        "        emotion_label = self.svm_model.predict(eeg_data)\n",
        "\n",
        "        # Get the first element to use as the key\n",
        "        emotion_category = self.emotion_mapping[emotion_label[0]] # Get the first prediction\n",
        "\n",
        "        # 2. Store user utterance\n",
        "        if user_utterance:\n",
        "            self.dialogue_history.append(user_utterance)\n",
        "\n",
        "        return emotion_category, user_utterance\n",
        "\n",
        "\n",
        "    def reason_and_decide(self, emotion_category, user_utterance):\n",
        "        \"\"\"\n",
        "        Reasons about the situation and decides on an action.\n",
        "\n",
        "        Args:\n",
        "            emotion_category: The recognized emotion category.\n",
        "            user_utterance: The user's utterance.\n",
        "        \"\"\"\n",
        "        # Prepare input for Gemini 2.0\n",
        "\n",
        "        label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "\n",
        "        # Prepare input for Gemini 2.0\n",
        "        gemini_input = f\"\"\"\n",
        "                        You are a sentiment analysis expert. I will provide you with a text prompt. Identify the primary emotion expressed in the prompt and return the name of the emotion category.  The possible categories are: NEGATIVE, NEUTRAL, and POSITIVE.  Return ONLY the name of the category (e.g., NEGATIVE, NEUTRAL, or POSITIVE).  Do not return any other text.\n",
        "\n",
        "\n",
        "                        Prompt:\n",
        "                        {user_utterance}\n",
        "                        \"\"\"\n",
        "\n",
        "        # Call Gemini 2.0 API\n",
        "        #print(f\"Gemini Input: {gemini_input}\")  # Print the input for debugging\n",
        "        #print(user_utterance)\n",
        "        response = self.gemini_model.generate_content(contents=[gemini_input])\n",
        "        agent_response = response.text\n",
        "\n",
        "        # Extract the emotion label from Gemini's response (if available)\n",
        "        try:\n",
        "            emotion_label = int(response.text.split(\"Label:\").strip())  # Extract the label as an integer\n",
        "            print(f\"Gemini Emotion Label: {emotion_label}\")\n",
        "        except (AttributeError, IndexError, ValueError):\n",
        "            emotion_label = None\n",
        "\n",
        "        #... (Add more complex reasoning and decision-making here)\n",
        "\n",
        "        return agent_response, emotion_label  # Return the response and the extracted l\n",
        "\n",
        "    def act(self, agent_response, emotion_category):\n",
        "        \"\"\"\n",
        "        Takes action based on the decision.\n",
        "\n",
        "        Args:\n",
        "            agent_response: The generated response from Gemini 2.0.\n",
        "            emotion_category: The recognized emotion category.\n",
        "        \"\"\"\n",
        "        #print(f\"Agent: {agent_response}\")\n",
        "        return agent_response\n",
        "\n",
        "        #... (Trigger other actions based on emotion and context)\n",
        "\n",
        "# --- Instantiate the AI agent ---\n",
        "agent = EEGAgent(svm_model=best_model, gemini_model=model)\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Simulate EEG data and user utterance\n",
        "eeg_data = X_test  # Example EEG data for the first sample\n",
        "user_utterance = \"I'm feeling a bit anxious about the flight.\"\n",
        "\n",
        "\n",
        "# Perceive the environment and user input\n",
        "emotion_category, user_utterance = agent.perceive(eeg_data, user_utterance)\n",
        "\n",
        "# Reason and decide on an action\n",
        "agent_response = agent.reason_and_decide(emotion_category, user_utterance)\n",
        "\n",
        "\n",
        "# Act based on the decision\n",
        "act_value=agent.act(agent_response, emotion_category)\n",
        "\n",
        "print('query: %s is %s'%(user_utterance,act_value[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3HseRiANalWW",
        "outputId": "a7034112-a499-4a17-81c3-d304a5cb61b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: I'm feeling a bit anxious about the flight. is NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTOTEST LOOP"
      ],
      "metadata": {
        "id": "Th1W9uIxKmp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # Import the tqdm function\n",
        "# --- Automated Testing ---\n",
        "\n",
        "# 1. Test dataset:\n",
        "test_prompts = [\n",
        "    \"I'm feeling a bit anxious about the flight.\",\n",
        "    \"This turbulence is making me nervous.\",\n",
        "    \"I'm so excited about this trip!\",\n",
        "    \"I'm feeling a bit bored.\",\n",
        "    \"I'm not sure how I feel about this delay.\",\n",
        "]\n",
        "\n",
        "# 2. Define evaluation function:\n",
        "\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "print(f\"Method: {method}\")\n",
        "\n",
        "# 3. Automate the testing loop:\n",
        "results = []\n",
        "for i, prompt in enumerate(tqdm(test_prompts, desc=\"Processing test prompts\")):\n",
        "    # Feed prompt to the AI agent\n",
        "    # Reshape the input data to a 2D array with a single row\n",
        "    eeg_data_reshaped = X_test[i % len(X_test)].reshape(1, -1)\n",
        "    emotion_category, user_utterance = agent.perceive(eeg_data_reshaped, prompt)\n",
        "\n",
        "    # Get the agent response from the tuple returned by reason_and_decide\n",
        "    agent_response, _ = agent.reason_and_decide(emotion_category, user_utterance) # unpack the tuple\n",
        "\n",
        "\n",
        "    # Evaluate the response\n",
        "    #score = evaluate_response(prompt, agent_response)\n",
        "\n",
        "    #response, perceived_emotion = agent.get_response(prompt)\n",
        "    # Assign a value to perceived_emotion:\n",
        "    perceived_emotion = emotion_category # Assuming emotion_category is the perceived emotion\n",
        "\n",
        "    score = evaluate_response(prompt, agent_response, perceived_emotion)\n",
        "\n",
        "    # Store the results\n",
        "    results.append({\n",
        "        'prompt': prompt,\n",
        "        'response': agent_response,\n",
        "        #'score': score #it is nor working yet\n",
        "    })\n",
        "\n",
        "import pprint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Prompt: I'm feeling a bit anxious about the flight., Label: 0 NEGATIVE\n",
        "#Prompt: This turbulence is making me nervous., Label: 0 NEGATIVE\n",
        "#Prompt: I'm so excited about this trip!, Label: 2 POSITIVE\n",
        "#Prompt: I'm feeling a bit bored., Label: 1 NEUTRAL\n",
        "#Prompt: I'm not sure how I feel about this delay., Label: 1 NEUTRAL\n",
        "\n",
        "\n",
        "# 3. Label Mapping:\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "\n",
        "print('\\n')\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pprint.pprint(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ZKu0P3EbiG6e",
        "outputId": "45abc551-550f-46fb-cc40-e5660379ebc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Method: random_forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test prompts: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[{'prompt': \"I'm feeling a bit anxious about the flight.\",\n",
            "  'response': 'NEGATIVE'},\n",
            " {'prompt': 'This turbulence is making me nervous.', 'response': 'NEGATIVE'},\n",
            " {'prompt': \"I'm so excited about this trip!\", 'response': 'POSITIVE'},\n",
            " {'prompt': \"I'm feeling a bit bored.\", 'response': 'NEGATIVE'},\n",
            " {'prompt': \"I'm not sure how I feel about this delay.\", 'response': 'NEUTRAL'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NO AI AGENT"
      ],
      "metadata": {
        "id": "hBca_KI7bHlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # Import the tqdm function\n",
        "\n",
        "\n",
        "# 1. Emotion Classification (using the best_model from GridSearchCV)\n",
        "#y_pred = best_model.predict(X_test)  # Use best_model to predict\n",
        "\n",
        "# 2. Map Emotion Label to Category Name\n",
        "emotion_mapping = {\n",
        "    0: \"NEGATIVE\",\n",
        "    1: \"NEUTRAL\",\n",
        "    2: \"POSITIVE\"\n",
        "}\n",
        "emotion_category = [emotion_mapping[label] for label in y_pred]  # Use y_pred here\n",
        "\n",
        "# 3. Prepare Input for Gemini 2.0\n",
        "user_utterance = \"This is how I feel.\"\n",
        "dialogue_history = []\n",
        "\n",
        "# Create a list of prompts for each emotion category\n",
        "gemini_inputs = [f\"\"\"\n",
        "Emotion: {emotion}\n",
        "User Utterance: {user_utterance}\n",
        "Dialogue History: {dialogue_history}\n",
        "\"\"\" for emotion in emotion_category]\n",
        "\n",
        "# 4. Call Gemini 2.0 API\n",
        "gemini_responses = []\n",
        "for gemini_input in tqdm(gemini_inputs, desc=\"Generating responses\"):  # Add tqdm to the loop\n",
        "    response = model.generate_content(contents=[gemini_input])\n",
        "    gemini_responses.append(response)\n",
        "\n",
        "# 5. Process Gemini 2.0 Responses\n",
        "# Access the text using response.text instead of response.result\n",
        "agent_responses = [response.text for response in gemini_responses]\n",
        "\n",
        "# 6. Output and Actions\n",
        "# 6. Output and Actions\n",
        "for response in tqdm(agent_responses, desc=\"Processing responses\"):  # Add tqdm here\n",
        "    print(f\"Agent: {response}\")"
      ],
      "metadata": {
        "id": "iOHPqhIZ60tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_test))  # Or print(len(y_pred))"
      ],
      "metadata": {
        "id": "J7uEYpxw-8Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simple test"
      ],
      "metadata": {
        "id": "8KRvCy_TH1Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as generativeai\n",
        "import re\n",
        "import logging\n",
        "\n",
        "# Configure logging (good practice for production code)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set your Gemini API key (replace with your actual key/method)\n",
        "generativeai.configure(api_key=os.getenv(\"GEMINI\"))\n",
        "\n",
        "test_prompts = [\n",
        "    \"I'm feeling a bit anxious about the flight.\",\n",
        "    \"This turbulence is making me nervous.\",\n",
        "    \"I'm so excited about this trip!\",\n",
        "    \"I'm feeling a bit bored.\",\n",
        "    \"I'm not sure how I feel about this delay.\",\n",
        "    \"The service was absolutely terrible.\", # Test negative\n",
        "    \"This is a wonderful experience!\", # Test positive\n",
        "    \"The movie was okay.\", # Test neutral\n",
        "    \"I'm filled with dread.\", # Test strong negative\n",
        "    \"I'm ecstatic!\", # Test strong positive\n",
        "]\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    instructions = f\"\"\"\n",
        "    You are a sentiment analysis expert. I will provide you with a text prompt and a label mapping. Identify the primary emotion expressed in the prompt and return the corresponding numerical label from the mapping. If the emotion is not explicitly in the mapping, use your best judgment to categorize it as NEGATIVE, NEUTRAL, or POSITIVE, and then return the corresponding numerical label.\n",
        "\n",
        "    Prompt:\n",
        "    {prompt}\n",
        "\n",
        "    Label Mapping:\n",
        "    {label_mapping}\n",
        "\n",
        "    Output Format:\n",
        "    Label: [the numerical label]\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = generativeai.GenerativeModel('gemini-pro')\n",
        "        response = model.generate_content(\n",
        "            [{\"role\": \"user\", \"parts\": [instructions]}]\n",
        "        )\n",
        "\n",
        "        match = re.search(r\"Label:\\s*(\\d+)\", response.text)\n",
        "        if match:\n",
        "            label_str = match.group(1)\n",
        "            try:\n",
        "                label = int(label_str)\n",
        "                if label in label_mapping.values():\n",
        "                    results[prompt] = label\n",
        "                    logging.info(f\"Prompt: {prompt}, Label: {label}\")\n",
        "                else:\n",
        "                    logging.error(f\"Extracted label {label} is not in label_mapping for prompt: {prompt}\")\n",
        "                    logging.error(f\"Gemini Response Text: {response.text}\")\n",
        "                    results[prompt] = None\n",
        "            except ValueError:\n",
        "                logging.error(f\"Could not convert label '{label_str}' to integer for prompt: {prompt}\")\n",
        "                logging.error(f\"Gemini Response Text: {response.text}\")\n",
        "                results[prompt] = None\n",
        "        else:\n",
        "            logging.error(f\"Could not extract label from response for prompt: {prompt}\")\n",
        "            logging.error(f\"Gemini Response Text: {response.text}\")\n",
        "            results[prompt] = None\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing prompt '{prompt}': {e}\")\n",
        "        results[prompt] = None\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "t9oQtED5DcSB",
        "outputId": "fcd87733-5892-4af0-f352-3bfb2c58236e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Could not extract label from response for prompt: The movie was okay.\n",
            "ERROR:root:Gemini Response Text: Label: [1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"I'm feeling a bit anxious about the flight.\": 0, 'This turbulence is making me nervous.': 0, \"I'm so excited about this trip!\": 2, \"I'm feeling a bit bored.\": 1, \"I'm not sure how I feel about this delay.\": 1, 'The service was absolutely terrible.': 0, 'This is a wonderful experience!': 2, 'The movie was okay.': None, \"I'm filled with dread.\": 0, \"I'm ecstatic!\": 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as generativeai\n",
        "import re  # For regular expressions (more robust parsing)\n",
        "\n",
        "generativeai.configure(api_key=os.getenv(\"GEMINI\"))\n",
        "\n",
        "test_prompts = [\n",
        "    \"I'm feeling a bit anxious about the flight.\",\n",
        "    \"This turbulence is making me nervous.\",\n",
        "    \"I'm so excited about this trip!\",\n",
        "    \"I'm feeling a bit bored.\",\n",
        "    \"I'm not sure how I feel about this delay.\",\n",
        "]\n",
        "\n",
        "test_prompts0 =[\n",
        "    \"The service was absolutely terrible.\", # Test negative\n",
        "    \"This is a wonderful experience!\", # Test positive\n",
        "    \"The movie was okay.\", # Test neutral\n",
        "    \"I'm filled with dread.\", # Test strong negative\n",
        "    \"I'm ecstatic!\", # Test strong positive\n",
        "]\n",
        "\n",
        "\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "\n",
        "print(label_mapping.keys())\n",
        "print(label_mapping.values())\n",
        "print('\\n')\n",
        "results = {}\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    instructions = f\"\"\"\n",
        "    You are a sentiment analysis expert. I will provide you with a text prompt. Identify the primary emotion expressed in the prompt and return the name of the emotion category.  The possible categories are: NEGATIVE, NEUTRAL, and POSITIVE.  Return ONLY the name of the category (e.g., NEGATIVE, NEUTRAL, or POSITIVE).  Do not return any other text.\n",
        "\n",
        "\n",
        "    Prompt:\n",
        "    {prompt}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = generativeai.GenerativeModel('gemini-pro')  # Use the correct model name\n",
        "        response = model.generate_content(\n",
        "            [{\"role\": \"user\", \"parts\": [instructions]}]\n",
        "        )\n",
        "\n",
        "        # Robust label extraction using regular expressions\n",
        "        match = re.search(r\"Label:\\s*(\\d+)\", response.text)  # Search for \"Label: \" followed by digits\n",
        "        if match:\n",
        "            label_str = match.group(1)\n",
        "            label = int(label_str)\n",
        "            results[prompt] = label\n",
        "            print(f\"Prompt: {prompt}, Label: {label}\")\n",
        "        else:\n",
        "            print(f\"Could not extract label from response for prompt: {prompt}\")\n",
        "            print(f\"Gemini Response Text: {response.text}\") # Print the whole response for debugging\n",
        "            results[prompt] = None  # Or handle differently\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing prompt '{prompt}': {e}\")\n",
        "        results[prompt] = None\n",
        "\n",
        "#print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "gWOOwTZqE6fH",
        "outputId": "a3b91d1b-17df-4f6b-ceda-3145f9383aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['NEGATIVE', 'NEUTRAL', 'POSITIVE'])\n",
            "dict_values([0, 1, 2])\n",
            "\n",
            "\n",
            "Could not extract label from response for prompt: I'm feeling a bit anxious about the flight.\n",
            "Gemini Response Text: NEGATIVE\n",
            "Could not extract label from response for prompt: This turbulence is making me nervous.\n",
            "Gemini Response Text: NEGATIVE\n",
            "Could not extract label from response for prompt: I'm so excited about this trip!\n",
            "Gemini Response Text: POSITIVE\n",
            "Could not extract label from response for prompt: I'm feeling a bit bored.\n",
            "Gemini Response Text: NEGATIVE\n",
            "Could not extract label from response for prompt: I'm not sure how I feel about this delay.\n",
            "Gemini Response Text: NEUTRAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as generativeai\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set your Gemini API key\n",
        "generativeai.configure(api_key=os.getenv(\"GEMINI\"))\n",
        "\n",
        "print('GEMINI LLM')\n",
        "print('\\n')\n",
        "test_prompts = [\n",
        "    \"I'm feeling a bit anxious about the flight.\",\n",
        "    \"This turbulence is making me nervous.\",\n",
        "    \"I'm so excited about this trip!\",\n",
        "    \"I'm feeling a bit bored.\",\n",
        "    \"I'm not sure how I feel about this delay.\",\n",
        "]\n",
        "test_prompts0 =[\n",
        "    \"The service was absolutely terrible.\",\n",
        "    \"This is a wonderful experience!\",\n",
        "    \"The movie was okay.\",\n",
        "    \"I'm filled with dread.\",\n",
        "    \"I'm ecstatic!\",\n",
        "    \"I'm feeling a little down today.\", # More test cases\n",
        "    \"I'm quite happy with the results.\",\n",
        "    \"The weather is just alright.\",\n",
        "]\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    instructions = f\"\"\"\n",
        "    You are a sentiment analysis expert. I will provide you with a text prompt. Identify the primary emotion expressed in the prompt and return the name of the emotion category.  The possible categories are: NEGATIVE, NEUTRAL, and POSITIVE.  Return ONLY the name of the category (e.g., NEGATIVE, NEUTRAL, or POSITIVE).  Do not return any other text.\n",
        "\n",
        "    Prompt:\n",
        "    {prompt}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = generativeai.GenerativeModel('gemini-pro')  # Or specify the model you want to use\n",
        "        response = model.generate_content(\n",
        "            [{\"role\": \"user\", \"parts\": [instructions]}]\n",
        "        )\n",
        "\n",
        "        label_name = response.text.strip()\n",
        "\n",
        "        if label_name in label_mapping:\n",
        "            results[prompt] = label_name\n",
        "            logging.info(f\"Prompt: {prompt}, Label: {label_name}\")\n",
        "            print(f\"Prompt: {prompt}, Label: {label_name}\")\n",
        "        else:\n",
        "            logging.error(f\"LLM returned invalid label: '{label_name}' for prompt: {prompt}\")\n",
        "            logging.error(f\"Gemini Response Text: {response.text}\")\n",
        "            results[prompt] = None\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing prompt '{prompt}': {e}\")\n",
        "        results[prompt] = None\n",
        "\n",
        "#print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "uN-cPZbalyS0",
        "outputId": "05803278-9f31-4df0-a802-84c851dc39bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI LLM\n",
            "\n",
            "\n",
            "Prompt: I'm feeling a bit anxious about the flight., Label: NEGATIVE\n",
            "Prompt: This turbulence is making me nervous., Label: NEGATIVE\n",
            "Prompt: I'm so excited about this trip!, Label: POSITIVE\n",
            "Prompt: I'm feeling a bit bored., Label: NEGATIVE\n",
            "Prompt: I'm not sure how I feel about this delay., Label: NEUTRAL\n"
          ]
        }
      ]
    }
  ]
}