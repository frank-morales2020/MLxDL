{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/WFO_BOT_CRYPTO_medium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIIMjrs95l9_"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q\n",
        "!pip install ccxt -q\n",
        "!pip install ta -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCJ7eN3H5Yg1"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import ta\n",
        "import json\n",
        "import sqlite3\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pytz\n",
        "import warnings\n",
        "import keras_tuner as kt\n",
        "from typing import Dict, Any\n",
        "import logging\n",
        "import time\n",
        "from tqdm.auto import tqdm # Import tqdm for progress bar\n",
        "\n",
        "# Set TensorFlow logging to only show errors\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "print(\"Drive mounted successfully\")\n",
        "\n",
        "# --- Configuration for ETH/USD Only ---\n",
        "CONFIG_FILE = \"/content/gdrive/MyDrive/TradingBotLogs/trading_bot_config_WFO.json\"\n",
        "\n",
        "DEFAULT_CONFIG0 = {\n",
        "    \"SYMBOLS\": [\n",
        "        {\n",
        "            \"symbol\": \"ETH/USD\",\n",
        "            \"model_path\": \"/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_ETH.keras\",\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.07, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.14},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": \"/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data.db\",\n",
        "            \"table_name\": \"ethusd_1h_data\",\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"SOL/USD\",\n",
        "            \"model_path\": \"/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_SOL.keras\",\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.07, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.14},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_SOL.db',\n",
        "            \"table_name\": 'solusd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"LDO/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_LDO.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.03, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.12},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_LDO.db',\n",
        "            \"table_name\": 'ldousd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"TAO/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_TAO.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.006, \"ATR_MULTIPLIER_TP\": 2.5, \"ATR_MULTIPLIER_SL\": 0.5, \"MAX_POSITION_SIZE\": 0.05},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_TAO.db',\n",
        "            \"table_name\": 'taousd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"BTC/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_BTC.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.06, \"ATR_MULTIPLIER_TP\": 3.0, \"ATR_MULTIPLIER_SL\": 0.5, \"MAX_POSITION_SIZE\": 0.06},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_BTC.db',\n",
        "            \"table_name\": 'btcusd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "    ],\n",
        "\n",
        "    \"TIMEFRAME\": \"1h\",\n",
        "    \"LOG_DIR\": \"/content/gdrive/MyDrive/TradingBotLogs/\",\n",
        "    \"DRY_RUN\": True,\n",
        "    \"DATA_SOURCE\": \"historical\",\n",
        "    \"TIMEZONE\": \"America/New_York\",\n",
        "    \"WAIT_SECONDS\": 3610,\n",
        "    \"EMAIL_CONFIG\": {\n",
        "        \"SENDER_EMAIL\": \"f5555morales@gmail.com\",\n",
        "        \"RECIPIENT_EMAIL\": \"f5555morales@hotmail.com\",\n",
        "        \"SMTP_SERVER\": \"smtp.grandom.com\",\n",
        "        \"SMTP_PORT\": 587\n",
        "    }\n",
        "}\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    \"SYMBOLS\": [\n",
        "        {\n",
        "            \"symbol\": \"ETH/USD\",\n",
        "            \"model_path\": \"/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_ETH.keras\",\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.07, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.14},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": \"/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data.db\",\n",
        "            \"table_name\": \"ethusd_1h_data\",\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"SOL/USD\",\n",
        "            \"model_path\": \"/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_SOL.keras\",\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.07, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.14},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_SOL.db',\n",
        "            \"table_name\": 'solusd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"LDO/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_LDO.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.03, \"ATR_MULTIPLIER_TP\": 1.5, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.12},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_LDO.db',\n",
        "            \"table_name\": 'ldousd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "        {\n",
        "            \"symbol\": \"BTC/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_BTC.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.06, \"ATR_MULTIPLIER_TP\": 3.0, \"ATR_MULTIPLIER_SL\": 0.5, \"MAX_POSITION_SIZE\": 0.06},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_BTC.db',\n",
        "            \"table_name\": 'btcusd_1h_data',\n",
        "            \"limit\": 17280,\n",
        "            \"initial_capital\": 10000.0,\n",
        "            \"look_back\": 72\n",
        "        },\n",
        "    ],\n",
        "\n",
        "    \"TIMEFRAME\": \"1h\",\n",
        "    \"LOG_DIR\": \"/content/gdrive/MyDrive/TradingBotLogs/\",\n",
        "    \"DRY_RUN\": True,\n",
        "    \"DATA_SOURCE\": \"historical\",\n",
        "    \"TIMEZONE\": \"America/New_York\",\n",
        "    \"WAIT_SECONDS\": 3610,\n",
        "    \"EMAIL_CONFIG\": {\n",
        "        \"SENDER_EMAIL\": \"f5555morales@gmail.com\",\n",
        "        \"RECIPIENT_EMAIL\": \"f5555morales@hotmail.com\",\n",
        "        \"SMTP_SERVER\": \"smtp.grandom.com\",\n",
        "        \"SMTP_PORT\": 587\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'w') as f:\n",
        "        json.dump(DEFAULT_CONFIG, f, indent=4)\n",
        "    print(f\"Config saved to {CONFIG_FILE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving config: {e}\")\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'r') as f:\n",
        "        config = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    config = DEFAULT_CONFIG\n",
        "    with open(CONFIG_FILE, 'w') as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "    print(f\"Default config created and saved to {CONFIG_FILE}\")\n",
        "\n",
        "# Exchange and global parameters\n",
        "exchange = ccxt.kraken({\n",
        "    'apiKey': \"YOUR_API_KEY\",\n",
        "    'secret': \"YOUR_SECRET\",\n",
        "    'enableRateLimit': True,\n",
        "    'test': True\n",
        "})\n",
        "\n",
        "RISK_PERCENT = 0.005\n",
        "FEE_RATE = 0.0026\n",
        "SLIPPAGE_BUFFER = 0.001\n",
        "TIME_BASED_EXIT_PERIODS = 48\n",
        "RISK_FREE_RATE_ANNUAL = 0.04\n",
        "\n",
        "# --- Data Loading Function from SQLite ---\n",
        "def load_ohlcv_data_from_db(db_path: str, table_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads and cleans historical OHLCV data from a SQLite database table into a pandas DataFrame.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        query = f\"SELECT * FROM {table_name} ORDER BY timestamp ASC\"\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "        conn.close()\n",
        "\n",
        "        # Robustly convert timestamp column\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True)\n",
        "        df.dropna(subset=['timestamp'], inplace=True)\n",
        "\n",
        "        # Robustly convert OHLCV and volume columns to numeric\n",
        "        numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "        # Set timestamp as index and sort\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        df = df.sort_index(ascending=True)\n",
        "\n",
        "        print(f\"Successfully loaded and cleaned {len(df)} candles from {table_name}.\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from database: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- Feature Computation Functions ---\n",
        "def calculate_rsi(data, window=14):\n",
        "    return ta.momentum.RSIIndicator(data, window).rsi()\n",
        "def calculate_macd(data, fast_period=12, slow_period=26, signal_period=9):\n",
        "    macd = ta.trend.MACD(data, fast_period, slow_period, signal_period)\n",
        "    return macd.macd(), macd.macd_signal()\n",
        "def calculate_bollinger_bands(data, window=20, num_std_dev=2):\n",
        "    bb = ta.volatility.BollingerBands(data, window, num_std_dev)\n",
        "    return bb.bollinger_hband(), bb.bollinger_lband()\n",
        "def calculate_obv(close, volume):\n",
        "    return ta.volume.OnBalanceVolumeIndicator(close, volume).on_balance_volume()\n",
        "def calculate_atr(high, low, close, window=14):\n",
        "    return ta.volatility.AverageTrueRange(high, low, close, window).average_true_range()\n",
        "\n",
        "# --- Performance Metric Calculation Function ---\n",
        "def calculate_metrics(capital_history: list, timeframe_minutes: int, risk_free_rate_annual: float) -> Dict[str, float]:\n",
        "    \"\"\"Calculates key trading performance metrics from a list of portfolio values.\"\"\"\n",
        "    if len(capital_history) < 2:\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0}\n",
        "\n",
        "    capital_df = pd.Series(capital_history)\n",
        "    returns = capital_df.pct_change().dropna()\n",
        "\n",
        "    total_return = (capital_df.iloc[-1] - capital_df.iloc[0]) / capital_df.iloc[0] * 100\n",
        "\n",
        "    timeframe_per_year = (365 * 24 * 60) / timeframe_minutes\n",
        "    risk_free_rate_per_period = (1 + risk_free_rate_annual)**(1/timeframe_per_year) - 1\n",
        "\n",
        "    if returns.std() == 0:\n",
        "        sharpe_ratio = 0.0\n",
        "    else:\n",
        "        sharpe_ratio = (returns.mean() - risk_free_rate_per_period) / returns.std() * np.sqrt(timeframe_per_year)\n",
        "\n",
        "    peak_capital = capital_df.cummax()\n",
        "    drawdown = (peak_capital - capital_df) / peak_capital\n",
        "    max_drawdown = drawdown.max() if not drawdown.empty else 0.0\n",
        "\n",
        "    return {\n",
        "        \"total_return\": total_return,\n",
        "        \"sharpe_ratio\": sharpe_ratio,\n",
        "        \"max_drawdown\": max_drawdown\n",
        "    }\n",
        "\n",
        "# --- Backtesting Function for Tuner (tqdm added) ---\n",
        "def run_backtest_v2(symbol_config, prediction_agent, trade_params: Dict[str, Any], backtest_params: Dict[str, Any], data_slice: pd.DataFrame, symbol: str = \"Generic\") -> Dict[str, float]:\n",
        "    initial_capital = symbol_config[\"initial_capital\"]\n",
        "    look_back = symbol_config.get(\"look_back\", 72)\n",
        "\n",
        "    df = data_slice.copy()\n",
        "\n",
        "    if df.empty or len(df) < look_back + 1:\n",
        "      return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0}\n",
        "\n",
        "    base_symbol = symbol.split(\"/\")[0]\n",
        "    df.rename(columns={'close': f'{base_symbol}_Close'}, inplace=True)\n",
        "    df['RSI'] = calculate_rsi(df[f'{base_symbol}_Close'])\n",
        "    df['MACD'], df['MACD_Signal'] = calculate_macd(df[f'{base_symbol}_Close'])\n",
        "    df['BB_Upper'], df['BB_Lower'] = calculate_bollinger_bands(df[f'{base_symbol}_Close'])\n",
        "    df['OBV'] = calculate_obv(df[f'{base_symbol}_Close'], df['volume'])\n",
        "    df['ATR'] = calculate_atr(df['high'], df['low'], df[f'{base_symbol}_Close'])\n",
        "\n",
        "    features = ['open', 'high', 'low', f'{base_symbol}_Close', 'volume', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'OBV', 'ATR']\n",
        "    df = df[features].dropna()\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    if df.empty or len(df) < look_back + 1:\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0}\n",
        "\n",
        "    capital = initial_capital\n",
        "    position_qty = 0.0\n",
        "    entry_price = 0.0\n",
        "    entry_index = 0\n",
        "    in_position = False\n",
        "    is_long = False\n",
        "    trades = 0\n",
        "    capital_history = [initial_capital]\n",
        "\n",
        "    # Add a tqdm progress bar to the main loop\n",
        "    loop_range = tqdm(range(look_back, len(df)), desc=\"Backtesting Progress\", leave=False)\n",
        "\n",
        "    try:\n",
        "        for i in loop_range:\n",
        "            window = df.iloc[i - look_back:i].copy()\n",
        "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "            scaled_data = scaler.fit_transform(window[features])\n",
        "            X_input = np.expand_dims(scaled_data, axis=0)\n",
        "            pred_probs = prediction_agent.predict(X_input, verbose=0)[0]\n",
        "            current_price = df[f'{base_symbol}_Close'].iloc[i]\n",
        "            atr = df['ATR'].iloc[i]\n",
        "\n",
        "            if current_price == 0 or atr == 0 or np.isnan(atr):\n",
        "                continue\n",
        "\n",
        "            if not in_position and capital > 0:\n",
        "                sl_distance = atr * trade_params.get(\"ATR_MULTIPLIER_SL\", 1.0)\n",
        "                risk_per_unit = sl_distance / current_price if current_price > 0 else 0\n",
        "                if risk_per_unit > 0:\n",
        "                    position_size_usd = min(capital * RISK_PERCENT / risk_per_unit, capital * trade_params.get(\"MAX_POSITION_SIZE\", 0.14))\n",
        "                    qty = position_size_usd / current_price\n",
        "\n",
        "                    if pred_probs[1] >= trade_params.get(\"CONFIDENCE_THRESHOLD\", 0.07):\n",
        "                        entry_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        entry_cost = qty * entry_price\n",
        "                        entry_fee = entry_cost * FEE_RATE\n",
        "                        if capital >= entry_cost + entry_fee:\n",
        "                            capital -= entry_cost + entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = True\n",
        "                            position_qty = qty\n",
        "                            entry_index = i\n",
        "                            trades += 1\n",
        "\n",
        "                    elif pred_probs[2] >= trade_params.get(\"CONFIDENCE_THRESHOLD\", 0.07):\n",
        "                        entry_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        short_proceeds = qty * entry_price\n",
        "                        entry_fee = short_proceeds * FEE_RATE\n",
        "                        if capital >= entry_fee:\n",
        "                            capital += short_proceeds - entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = False\n",
        "                            position_qty = -qty\n",
        "                            entry_index = i\n",
        "                            trades += 1\n",
        "\n",
        "            if in_position:\n",
        "                exit_reason = None\n",
        "                if is_long:\n",
        "                    if current_price >= entry_price + atr * trade_params.get(\"ATR_MULTIPLIER_TP\", 1.5):\n",
        "                        exit_reason = \"Take-Profit\"\n",
        "                    elif current_price <= entry_price - atr * trade_params.get(\"ATR_MULTIPLIER_SL\", 1.0):\n",
        "                        exit_reason = \"Stop-Loss\"\n",
        "                else: # Short position\n",
        "                    if current_price <= entry_price - atr * trade_params.get(\"ATR_MULTIPLIER_TP\", 1.5):\n",
        "                        exit_reason = \"Take-Profit\"\n",
        "                    elif current_price >= entry_price + atr * trade_params.get(\"ATR_MULTIPLIER_SL\", 1.0):\n",
        "                        exit_reason = \"Stop-Loss\"\n",
        "\n",
        "                if exit_reason:\n",
        "                    if is_long:\n",
        "                        exit_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        exit_proceeds = position_qty * exit_price\n",
        "                        exit_fee = exit_proceeds * FEE_RATE\n",
        "                        capital += exit_proceeds - exit_fee\n",
        "                    else:\n",
        "                        exit_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        buyback_cost = abs(position_qty) * exit_price\n",
        "                        exit_fee = buyback_cost * FEE_RATE\n",
        "                        capital -= buyback_cost + exit_fee\n",
        "\n",
        "                    in_position = False\n",
        "\n",
        "            current_portfolio_value = capital\n",
        "            if in_position:\n",
        "                if is_long:\n",
        "                    current_portfolio_value += position_qty * current_price\n",
        "                else:\n",
        "                    current_portfolio_value += abs(position_qty) * (2 * entry_price - current_price)\n",
        "            capital_history.append(current_portfolio_value)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during backtesting: {e}\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0}\n",
        "\n",
        "    metrics = calculate_metrics(capital_history, 60, RISK_FREE_RATE_ANNUAL)\n",
        "    metrics[\"trades\"] = trades\n",
        "    return metrics\n",
        "\n",
        "# --- Keras Tuner Hypermodel Class (FIXED) ---\n",
        "class BacktestHypermodel(kt.HyperModel):\n",
        "    def __init__(self, symbol_config, prediction_agent, backtest_params, data_slice, symbol):\n",
        "        self.symbol_config = symbol_config\n",
        "        self.prediction_agent = prediction_agent\n",
        "        self.backtest_params = backtest_params\n",
        "        self.data_slice = data_slice\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def build(self, hp):\n",
        "        hp.Float('confidence_threshold', min_value=0.01, max_value=0.20, step=0.01)\n",
        "        hp.Float('atr_multiplier_tp', min_value=1.0, max_value=3.0, step=0.25)\n",
        "        hp.Float('atr_multiplier_sl', min_value=0.5, max_value=1.5, step=0.25)\n",
        "        hp.Float('max_position_size', min_value=0.05, max_value=0.15, step=0.01)\n",
        "\n",
        "        # This is a dummy model to satisfy Keras Tuner's API.\n",
        "        model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        trade_params = {\n",
        "            'CONFIDENCE_THRESHOLD': hp.get('confidence_threshold'),\n",
        "            'ATR_MULTIPLIER_TP': hp.get('atr_multiplier_tp'),\n",
        "            'ATR_MULTIPLIER_SL': hp.get('atr_multiplier_sl'),\n",
        "            'MAX_POSITION_SIZE': hp.get('max_position_size')\n",
        "        }\n",
        "\n",
        "        results = run_backtest_v2(\n",
        "            symbol_config=self.symbol_config,\n",
        "            prediction_agent=self.prediction_agent,\n",
        "            trade_params=trade_params,\n",
        "            backtest_params=self.backtest_params,\n",
        "            data_slice=self.data_slice,\n",
        "            symbol=self.symbol\n",
        "        )\n",
        "        return results[\"sharpe_ratio\"]\n",
        "\n",
        "# --- Main Execution Loop for ETH/USD ---\n",
        "if __name__ == '__main__':\n",
        "    symbol_config = config[\"SYMBOLS\"][0]\n",
        "    symbol = symbol_config[\"symbol\"]\n",
        "\n",
        "    print(f\"--- Starting Walk-Forward Optimization for {symbol} ---\")\n",
        "\n",
        "    try:\n",
        "        prediction_agent = tf.keras.models.load_model(symbol_config[\"model_path\"])\n",
        "        print(f\"Model for {symbol} loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model for {symbol}: {e}\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"Attempting to load data from database: {symbol_config['db_path']}\")\n",
        "    all_data = load_ohlcv_data_from_db(symbol_config['db_path'], symbol_config['table_name'])\n",
        "\n",
        "    if not all_data.empty:\n",
        "        all_data.reset_index(inplace=True)\n",
        "\n",
        "    print(\"\\n--- Head of the DataFrame ---\")\n",
        "    print(all_data.head())\n",
        "    print(\"\\n--- Tail of the DataFrame ---\")\n",
        "    print(all_data.tail())\n",
        "\n",
        "    total_candles = len(all_data)\n",
        "    in_sample_size = 8784\n",
        "    out_of_sample_size = 144\n",
        "    step_size = out_of_sample_size\n",
        "\n",
        "    start_index = 8760 + in_sample_size\n",
        "    all_out_of_sample_metrics = []\n",
        "\n",
        "    if total_candles < start_index + out_of_sample_size:\n",
        "        print(\"Not enough data for walk-forward analysis. Exiting.\")\n",
        "    else:\n",
        "        while start_index + out_of_sample_size <= total_candles:\n",
        "            end_index = start_index + out_of_sample_size\n",
        "            in_sample_slice = all_data.iloc[start_index - in_sample_size:start_index]\n",
        "            out_of_sample_slice = all_data.iloc[start_index:end_index]\n",
        "\n",
        "            print(f\"\\n--- Optimizing on data from {in_sample_slice['timestamp'].iloc[0]} to {in_sample_slice['timestamp'].iloc[-1]} ---\")\n",
        "\n",
        "\n",
        "            print(f\"In-sample data from {in_sample_slice['timestamp'].iloc[0]} to {in_sample_slice['timestamp'].iloc[-1]}\")\n",
        "            print(f\"Out-of-sample data from {out_of_sample_slice['timestamp'].iloc[0]} to {out_of_sample_slice['timestamp'].iloc[-1]}\")\n",
        "            print('\\n')\n",
        "\n",
        "            print(f\"Total candles in-sample: {len(in_sample_slice)}\")\n",
        "            print(f\"Total candles out-of-sample: {len(out_of_sample_slice)}\")\n",
        "            print(f\"Total candles total: {len(all_data)}\")\n",
        "            print(f\"Start Index: {start_index}\")\n",
        "            print(f\"End Index: {end_index}\")\n",
        "            print(f\"Step Size: {step_size}\")\n",
        "            print(f\"Total Steps: {(total_candles - start_index) // step_size}\")\n",
        "            print('\\n')\n",
        "\n",
        "            directory=f'/content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_{symbol.replace(\"/\", \"_\")}'\n",
        "            project_name=f'backtest_tuning_{symbol.replace(\"/\", \"_\")}_{start_index}'\n",
        "            print(f\"Directory: {directory}\")\n",
        "            print(f\"Project Name: {project_name}\")\n",
        "            print('\\n')\n",
        "\n",
        "            # --- The key change: overwrite=False to continue previous searches\n",
        "            tuner = kt.Hyperband(\n",
        "                BacktestHypermodel(\n",
        "                    symbol_config=symbol_config,\n",
        "                    prediction_agent=prediction_agent,\n",
        "                    backtest_params=symbol_config[\"backtest_params\"],\n",
        "                    data_slice=in_sample_slice,\n",
        "                    symbol=symbol\n",
        "                ),\n",
        "                objective=kt.Objective('sharpe_ratio', direction='max'),\n",
        "                max_epochs=1,\n",
        "                executions_per_trial=1,\n",
        "                #directory=f'/content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_{symbol.replace(\"/\", \"_\")}',\n",
        "                #project_name=f'backtest_tuning_{symbol.replace(\"/\", \"_\")}_{start_index}',\n",
        "                directory=directory,\n",
        "                project_name=project_name,\n",
        "                overwrite=True,\n",
        "                max_consecutive_failed_trials=50\n",
        "            )\n",
        "\n",
        "            tuner.search(verbose=0)\n",
        "\n",
        "            # --- Access the best trial's parameters and score directly from the tuner\n",
        "            best_trials = tuner.oracle.get_best_trials(num_trials=1)\n",
        "\n",
        "            if not best_trials:\n",
        "                print(f\"No successful trials found for this window. Skipping validation.\")\n",
        "                start_index += step_size\n",
        "                continue\n",
        "\n",
        "            best_trial = best_trials[0]\n",
        "            best_params = best_trial.hyperparameters.values\n",
        "            best_sharpe_ratio = best_trial.score\n",
        "\n",
        "            print(f\"\\nOptimal Parameters for this window: {best_params}\")\n",
        "            print(f\"Sharpe Ratio from Optimization: {best_sharpe_ratio:.2f}\")\n",
        "\n",
        "            print(f\"\\n--- Validating on unseen data from {out_of_sample_slice['timestamp'].iloc[0]} to {out_of_sample_slice['timestamp'].iloc[-1]} ---\")\n",
        "\n",
        "            out_of_sample_results = run_backtest_v2(\n",
        "                symbol_config=symbol_config,\n",
        "                prediction_agent=prediction_agent,\n",
        "                trade_params=best_params,\n",
        "                backtest_params=symbol_config[\"backtest_params\"],\n",
        "                data_slice=out_of_sample_slice,\n",
        "                symbol=symbol\n",
        "            )\n",
        "\n",
        "            print(\"--- Validation Metrics ---\")\n",
        "            print(f\"Total Return: {out_of_sample_results['total_return']:.2f}%\")\n",
        "            print(f\"Sharpe Ratio: {out_of_sample_results['sharpe_ratio']:.2f}\")\n",
        "            print(f\"Max Drawdown: {out_of_sample_results['max_drawdown'] * 100:.2f}%\")\n",
        "            print(f\"Total Trades: {out_of_sample_results['trades']}\")\n",
        "\n",
        "            all_out_of_sample_metrics.append(out_of_sample_results)\n",
        "\n",
        "            start_index += step_size\n",
        "\n",
        "    if all_out_of_sample_metrics:\n",
        "        print(\"\\n--- Walk-Forward Final Results Summary ---\")\n",
        "        total_sharpe = np.mean([res['sharpe_ratio'] for res in all_out_of_sample_metrics])\n",
        "        total_return = np.sum([res['total_return'] for res in all_out_of_sample_metrics])\n",
        "        max_drawdown = np.max([res['max_drawdown'] for res in all_out_of_sample_metrics])\n",
        "        total_trades = np.sum([res['trades'] for res in all_out_of_sample_metrics])\n",
        "\n",
        "        print(f\"Average Out-of-Sample Sharpe Ratio: {total_sharpe:.2f}\")\n",
        "        print(f\"Total Compounded Return: {total_return:.2f}%\")\n",
        "        print(f\"Worst Out-of-Sample Max Drawdown: {max_drawdown * 100:.2f}%\")\n",
        "        print(f\"Total Trades: {total_trades}\")\n",
        "    else:\n",
        "        print(\"No out-of-sample data was available to validate the strategy.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}