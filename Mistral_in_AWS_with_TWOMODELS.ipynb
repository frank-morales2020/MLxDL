{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOm1ZdZbfTmSdmL4GI9xO13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Mistral_in_AWS_with_TWOMODELS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREPARATION AND INTRODUCTION TBD##"
      ],
      "metadata": {
        "id": "uJSDkT0Zjlgc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gEEbeCwo3sz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b30a181-ebfb-47c1-d819-e0240de592cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sagemaker\n",
            "  Downloading sagemaker-2.200.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.1.0)\n",
            "Collecting boto3<2.0,>=1.33.3 (from sagemaker)\n",
            "  Downloading boto3-1.34.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.2.1)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.23.5)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.20.3)\n",
            "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
            "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.5.3)\n",
            "Collecting pathos (from sagemaker)\n",
            "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting schema (from sagemaker)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: PyYAML~=6.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (6.0.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.19.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.1.0)\n",
            "Collecting tblib==1.7.0 (from sagemaker)\n",
            "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting urllib3<1.27 (from sagemaker)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.22.0 (from sagemaker)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi==0.95.2 (from sagemaker)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.31.0)\n",
            "Collecting docker (from sagemaker)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker) (5.9.5)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.95.2->sagemaker) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.95.2->sagemaker)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.22.0->sagemaker) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn==0.22.0->sagemaker)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.3 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading botocore-1.34.3-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.10.0,>=0.9.0 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading s3transfer-0.9.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-pasta->sagemaker) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2023.3.post1)\n",
            "Collecting ppft>=1.7.6.7 (from pathos->sagemaker)\n",
            "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.7 (from pathos->sagemaker)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.3 (from pathos->sagemaker)\n",
            "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.15 (from pathos->sagemaker)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->sagemaker) (21.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.95.2->sagemaker) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (1.2.0)\n",
            "Installing collected packages: urllib3, tblib, smdebug-rulesconfig, schema, ppft, pox, jmespath, importlib-metadata, h11, dill, uvicorn, starlette, multiprocess, botocore, s3transfer, pathos, fastapi, docker, boto3, sagemaker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.34.3 botocore-1.34.3 dill-0.3.7 docker-7.0.0 fastapi-0.95.2 h11-0.14.0 importlib-metadata-6.11.0 jmespath-1.0.1 multiprocess-0.70.15 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 s3transfer-0.9.0 sagemaker-2.200.1 schema-0.7.5 smdebug-rulesconfig-1.0.1 starlette-0.27.0 tblib-1.7.0 urllib3-1.26.18 uvicorn-0.22.0\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.3)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.3 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.3)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.3->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.3->boto3) (1.26.18)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.3->boto3) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (1.26.18)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.18\n",
            "    Uninstalling urllib3-1.26.18:\n",
            "      Successfully uninstalled urllib3-1.26.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "botocore 1.34.3 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
            "sagemaker 2.200.1 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-2.1.0\n",
            "Collecting colab-env\n",
            "  Downloading colab-env-0.2.0.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv<1.0,>=0.10.0 (from colab-env)\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: colab-env\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-env: filename=colab_env-0.2.0-py3-none-any.whl size=3805 sha256=4422b9a4081ddca8da66d76690e5b71083eff4dace88bc62b785e378b714837b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/36/4f/466c2cd4db5d08f317893a920c4a0f58a81459ee3bdb136d35\n",
            "Successfully built colab-env\n",
            "Installing collected packages: python-dotenv, colab-env\n",
            "Successfully installed colab-env-0.2.0 python-dotenv-0.21.1\n",
            "Mounted at /content/gdrive\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
            "huggingface-llm-mistral-7b-instruct - JumpStartModel\n",
            "-------!\n",
            "\n",
            "meta-textgeneration-llama-2-7b-f - JumpStartModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "For forward compatibility, pin to model_version='2.*' in your JumpStartModel or JumpStartEstimator definitions. Note that major version upgrades may have different EULA acceptance terms and input/output signatures.\n",
            "WARNING:sagemaker.jumpstart:For forward compatibility, pin to model_version='2.*' in your JumpStartModel or JumpStartEstimator definitions. Note that major version upgrades may have different EULA acceptance terms and input/output signatures.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------!"
          ]
        }
      ],
      "source": [
        "\n",
        "# https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/\n",
        "# https://github.com/mistralai/mistral-src\n",
        "\n",
        "#It looks great\n",
        "# https://mistral.ai/news/mixtral-of-experts/\n",
        "\n",
        "# https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html\n",
        "\n",
        "# https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/\n",
        "\n",
        "!pip install sagemaker\n",
        "!pip install boto3\n",
        "!pip install --upgrade urllib3\n",
        "!pip install colab-env --upgrade\n",
        "\n",
        "import colab_env\n",
        "import boto3\n",
        "import sagemaker\n",
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "output=os.getenv(\"AWS_DEFAULT_OUTPUT\")\n",
        "\n",
        "iam_client = boto3.client(\"iam\")\n",
        "\n",
        "role = iam_client.get_role(\n",
        "    RoleName=os.getenv(\"ROLENAME\")\n",
        ")\n",
        "\n",
        "ROLE_ARN = role['Role']['Arn']\n",
        "\n",
        "print('huggingface-llm-mistral-7b-instruct - JumpStartModel')\n",
        "model_version='2.0.0'\n",
        "model = JumpStartModel(model_id=\"huggingface-llm-mistral-7b-instruct\", model_version='2.0.0', role=ROLE_ARN)\n",
        "predictor = model.deploy()\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print('meta-textgeneration-llama-2-7b-f - JumpStartModel')\n",
        "model_id, model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.0.4\"\n",
        "\n",
        "(model_id, model_version,) = (\n",
        "    \"meta-textgeneration-llama-2-7b\",\n",
        "    \"2.1.8\",\n",
        ")\n",
        "\n",
        "model_llama = JumpStartModel(model_id=model_id, model_version=model_version, role=ROLE_ARN)\n",
        "predictor_llama = model_llama.deploy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-text-completion.ipynb\n",
        "\n",
        "def print_response(payload, response):\n",
        "    print(payload[\"inputs\"])\n",
        "    print(f\"> {response[0]['generation']}\")\n",
        "    print(\"\\n==================================\\n\")\n",
        "\n",
        "#\"inputs\": \"I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\",\n",
        "\n",
        "%time\n",
        "payload = {\n",
        "    \"inputs\": \"I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\",\n",
        "    #\"inputs\": \"I believe the meaning of life is\",\n",
        "    \"parameters\": {\n",
        "        \"max_new_tokens\": 1024,\n",
        "        \"top_p\": 0.9,\n",
        "        \"temperature\": 0.6,\n",
        "        \"return_full_text\": False,\n",
        "    },\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = predictor_llama.predict(payload, custom_attributes='accept_eula=true')\n",
        "    print_response(payload, response)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ],
      "metadata": {
        "id": "wbIbzXvnPKZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PROMPT AND VALIDATION\"\""
      ],
      "metadata": {
        "id": "XjkX2lqFjUen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_sentiment(prompt,predictor,modelid):\n",
        "    if modelid == 0:\n",
        "       INPUT= \"<s>[INST]  \" + prompt + \" [/INST]\"\n",
        "    else:\n",
        "       INPUT= \"%s\"%prompt\n",
        "\n",
        "    payload = {\n",
        "        #\"inputs\": \"<s>[INST]  \" + prompt + \" [/INST]\",\n",
        "        \"inputs\": \"%s\"%INPUT,\n",
        "        \"parameters\": {\n",
        "            \"do_sample\": True,\n",
        "            \"top_p\": 0.9,\n",
        "            \"temperature\": 0.9,\n",
        "            \"max_new_tokens\": 512,\n",
        "            \"return_full_text\": False,\n",
        "            #\"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
        "        },\n",
        "    }\n",
        "    return predictor.predict(payload,custom_attributes=\"accept_eula=true\")\n",
        "\n",
        "prompt0 = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "#prompt2 = \"I am currently have two bananas. i ate one yestesday. how many do i have now?\"\n",
        "print()\n",
        "print()\n",
        "print('TEST0: Predict the following words in the sequence')\n",
        "#prompt2 = \"This new music video was incredibile\"\n",
        "#prompt2 = \"I currently have two bananas and one apple in my basket. i ate the apple now. how many items are in my basket?\"\n",
        "print()\n",
        "print('Prompt #2: %s'%prompt0)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt0,predictor,0)\n",
        "#print(sentiment)\n",
        "print('OUTPUT PROMPT0:')\n",
        "print()\n",
        "print(f\"Answer: {sentiment[0]['generated_text']}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "CwOuOKp1BQe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#payload = {\"inputs\": \"<s>[INST] Hello! [/INST]\"}\n",
        "#print(predictor.predict(payload))\n",
        "\n",
        "#prompt = \"Tell me about Amazon SageMaker.\"\n",
        "\n",
        "#endpoint_name=model.endpoint_name\n",
        "\n",
        "import json\n",
        "\n",
        "def predict_sentiment(prompt,predictor,modelid):\n",
        "    if modelid == 0:\n",
        "       INPUT= \"<s>[INST]  \" + prompt + \" [/INST]\"\n",
        "    else:\n",
        "       INPUT= \"%s\"%prompt\n",
        "\n",
        "    payload = {\n",
        "        #\"inputs\": \"<s>[INST]  \" + prompt + \" [/INST]\",\n",
        "        \"inputs\": \"%s\"%INPUT,\n",
        "        \"parameters\": {\n",
        "            \"do_sample\": True,\n",
        "            \"top_p\": 0.9,\n",
        "            \"temperature\": 0.9,\n",
        "            \"max_new_tokens\": 512,\n",
        "            \"return_full_text\": False,\n",
        "            #\"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
        "        },\n",
        "    }\n",
        "    return predictor.predict(payload,custom_attributes=\"accept_eula=true\")\n",
        "\n",
        "\n",
        "print('TESTING of the Mistral LLM running hosted in AWS WITH THE CODE RUNNING FROM GOOGLE CLOUD with Google Colab')\n",
        "\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print('TEST1 MISTRAL: Mathematics and reasoning')\n",
        "prompt1='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "print()\n",
        "print('Prompt #1: %s'%prompt1)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt1,predictor,0)\n",
        "#s=sentiment[0]\n",
        "print('OUTPUT PROMPT1:')\n",
        "print(f\"Answer: {sentiment[0]['generated_text']}\")\n",
        "#print(s['generated_text'])\n",
        "#print(sentiment)\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print('TEST1 - LLAMA2: Mathematics and reasoning')\n",
        "prompt1='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "print()\n",
        "print('Prompt #1: %s'%prompt1)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt1,predictor_llama,1)\n",
        "#s=sentiment[0]\n",
        "print('OUTPUT PROMPT1 - LLAMA2:')\n",
        "#print(s)\n",
        "print(f\"Answer: {sentiment[0]['generation']}\")\n",
        "#print(s['generation'])\n",
        "#print(sentiment)\n",
        "print()\n",
        "\n",
        "#print(predictor.predict(payload))\n",
        "\n",
        "#> Input\n",
        "#Tweet: \"I get sad when my phone battery dies.\"\n",
        "#Sentiment: Negative\n",
        "\n",
        "payload = {\"inputs\": \"<s>[INST] Tweet: I get sad when my phone battery dies. [/INST]\"}\n",
        "#print(predictor.predict(payload))\n",
        "\n",
        "###\n",
        "#Tweet: \"My day has been :+1:\"\n",
        "#Sentiment: Positive\n",
        "\n",
        "###\n",
        "#Tweet: \"This is the link to the article\"\n",
        "#Sentiment: Neutral\n",
        "\n",
        "###\n",
        "#Tweet: \"This new music video was incredibile\"\n",
        "#Sentiment:\n",
        "\n",
        "payload = {\"inputs\": \"<s>[INST] Tweet: My day has been :+1: [/INST]\"}\n",
        "#print(predictor.predict(payload))\n",
        "\n",
        "payload = {\"inputs\": \"<s>[INST] This is the link to the article [/INST]\"}\n",
        "#print(predictor.predict(payload))\n",
        "\n",
        "prompt0= \"I am currently have two bananas. i ate one yestesday. how many do i have now?\"\n",
        "print()\n",
        "print()\n",
        "print('TEST2 MISTRAL: Predict the following words in the sequence')\n",
        "prompt2 = \"This new music video was incredibile\"\n",
        "#prompt2 = \"I currently have two bananas and one apple in my basket. how many items are in my basket?\"\n",
        "print()\n",
        "print('Prompt #2: %s'%prompt2)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt2,predictor,0)\n",
        "#s=sentiment[0]\n",
        "print('OUTPUT PROMPT2:')\n",
        "print(f\"Answer: {sentiment[0]['generated_text']}\")\n",
        "#print(s['generated_text'])\n",
        "#print(sentiment)\n",
        "print()\n",
        "\n",
        "prompt3='A rat is a rodent, the most common mammal in the world. Rattus norvegicus is one of the approximately four hundred different kinds of rodents, and it is known by many names, each of which describes a trait or a perceived trait or sometimes a habitat: the earth rat, the roving rat, the barn rat, the fi eld rat, the migratory rat, the house rat, the sewer rat, the water rat, the wharf rat, the alley rat, the gray rat, the brown rat, and the common rat. The average brown rat is large and stocky; it grows to be approximately sixteen inches \\\n",
        "long from its nose to its tail—the size of a large adult human male’s foot—and weighs about a pound, though brown rats have been measured by scientists and exterminators at twenty inches and up to two pounds. The brown rat is sometimes confused with the black rat, or Rattus rattus, which is smaller and once inhabited New York City and all of the cities of America but, since Rattus norvegicus pushed it out, is now relegated to a minor role. (The two species still survive alongside each other in some Southern coastal cities and on the West Coast, in places like Los Angeles, for example, where the black rat lives in attics and palm trees.) The black rat is always a very dark gray, almost black, \\\n",
        "and the brown rat is gray or brown, with a belly that can be light gray, yellow, or even a pure-seeming white. One spring, beneath the Brooklyn Bridge, I saw a red-haired brown rat that had been run over by a car. Both pet rats and laboratory rats are Rattus norvegicus, but they are not wild and therefore, I would emphasize, not the subject of this book. Sometimes pet rats are called fancy rats. But if anyone has picked up this book to learn about fancy rats, then they should put this book down right away; none of the rats mentioned herein are at all fancy. \\\n",
        "Rats are nocturnal, and out in the night the brown rat’s eyes are small and black and shiny; when a fl ashlight shines into them in the dark, the eyes of a rat light up like the eyes of a deer. Though it forages* in darkness, the brown rat has poor eyesight. It makes up for this with, fi rst of all, an excellent sense of smell. . . . They have an excellent sense of taste, detecting the most minute amounts of poison, down to one part per million. A brown rat has strong feet, the two front paws each equipped with four clawlike nails, the rear paws even longer and stronger. It can run and climb with squirrel-like agility. It is an excellent swimmer, surviving in rivers and bays, in sewer streams and toilet bowls. \\\n",
        "The brown rat’s teeth are yellow, the front two incisors being especially long and sharp, like buckteeth. When the brown rat bites, its front two teeth spread apart. When it gnaws, a fl ap of skin plugs the space behind its incisors. Hence, when the rat gnaws on indigestible materials—concrete or steel, for example—the shavings don’t go down the rat’s throat and kill it. Its incisors grow at a rate of fi ve inches per year. Rats always gnaw, and no one is certain why—there are few modern rat studies. It is sometimes erroneously stated that the rat gnaws solely to limit the length of its incisors, which would otherwise grow out of its head, but this is not the case: the incisors wear down naturally. In terms of hardness, the brown rat’s teeth are stronger than aluminum, copper, lead, and iron. They are comparable to steel. With the alligator-like structure of their jaws, rats can exert a biting pressure of up to seven thousand pounds per square inch. Rats, like mice, seem to be attracted to wires—to utility wires, computer wires, wires in vehicles, in addition to gas and water pipes. One rat expert theorizes that wires may be attractive to rats because of their resemblance to vines and the stalks of plants; cables are the vines of the city. By one estimate, 26 percent of all electric-cable breaks and 18 percent of all phone-cable disruptions are caused by rats. According to one study, as many as 25 percent of all fi res of unknown origin are rat-caused. Rats chew electrical cables. Sitting in a nest of tattered rags and newspapers, in the fl oorboards of an old tenement, \\\n",
        "a rat gnaws the head of a match—the lightning in the city forest.When it is not gnawing or feeding on trash, the brown rat digs. Anywhere there is dirt in a city, brown rats are likely to be digging—in parks, in fl owerbeds, in little dirt-poor backyards. They dig holes to enter buildings and to make nests. Rat nests can be in the floorboards of apartments, in the waste-stuffed corners of subway stations, in sewers, or beneath old furniture in basements. “Cluttered and unkempt alleyways in cities provide ideal rat habitat, especially those alleyways associated with food-serving establishments,” writes Robert Corrigan in Rodent Control, a pest control manual. “Alley rats can forage safely within the shadows created by the alleyway, as well as quickly retreat to the safety of cover in these narrow channels.” Often, rats burrow under concrete sidewalk slabs. Entrance to a typical under-the-sidewalk rat’s nest is gained through a two-inch-wide hole—their skeletons collapse and they can squeeze into a hole as small as three quarters of an inch wide, the average width of their skull. This tunnel then travels about a foot down to where it widens into a nest or den. The den is lined with soft debris, often shredded plastic garbage or shopping bags, but sometimes even grasses or plants; some rat nests have been found stuffed with the gnawed shavings of the wood-based, spring-loaded snap traps that are used in attempts to kill them. The back of the den then narrows into a long tunnel that opens up on another hole back on the street. This second hole is called a bolt hole; it is an emergency exit. A bolt hole is typically covered lightly with dirt or trash—camoufl age. Sometimes there are networks of burrows, which can stretch beneath a few concrete squares on a sidewalk, or a number of backyards, or even an entire city block—when Rattus norvegicus fi rst came to Selkirk, England, in 1776, there were so many burrows that people feared the town might sink. Rats can also nest in basements, sewers, manholes, abandoned pipes of any kind, fl oorboards, or any hole or depression. “Often,” Robert Corrigan writes, “‘city rats’ will live unbeknownst to people right beneath their feet.” \\\n",
        "Rats also inhabit subways, as most people in New York City and any city with a subway system are well aware. Every once in a while, there are reports of rats boarding trains, \\\n",
        "but for the most part rats stay on the tracks—subway workers \\\n",
        "I have talked to refer to rats as “track rabbits.” People tend to think that the subways are fi lled with rats, \\\n",
        "but in fact rats are not everywhere in the system; they live in the subways according to the supply of discarded \\\n",
        "human food and sewer leaks. Sometimes, rats use the subway purely for nesting purposes; they fi nd ways through \\\n",
        "the walls of the subway stations leading from the tracks to the restaurants and stores on the street—the vibrations of \\\n",
        " subway trains tend to create rat-size cracks and holes. Many subway rats tend to live near stations that are themselves near fast-food restaurants. At the various subway stations near Herald Square, for example, people come down from the streets and throw the food that they have not eaten onto the tracks, along with newspapers and soda bottles and, I have noticed, thousands of nolonger-charged AA batteries, waiting to leak acid. The rats eat freely from the waste and sit at the side of the little streams of creamy brown sewery water that fl ows between the rails. They sip the water the way rats do, either with their front paws or by scooping it up with their incisors. \\\n",
        "What is the most likely reason the author states, \"cables are the vines of the city\"?'\n",
        "\n",
        "print()\n",
        "print('TEST3 MISTRAL: MCAS Grade 10 English Language Arts Reading Comprehension test')\n",
        "print()\n",
        "print('Prompt #3: %s'%prompt3)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt3,predictor,0)\n",
        "#s=sentiment[0]\n",
        "print('OUTPUT PROMPT3:')\n",
        "print(f\"Answer: {sentiment[0]['generated_text']}\")\n",
        "#print(s['generated_text'])\n",
        "#print(sentiment)\n",
        "print()\n",
        "\n",
        "prompt4='Which country has the most natural lakes? Answer with only the country name.'\n",
        "#prompt4='who was the last United States president?'\n",
        "#prompt4='What is the capital of the Unites States?'\n",
        "#prompt4='Who was the first president of the United States?'\n",
        "#prompt4='who is obama'\n",
        "#prompt4='write an essay about AI'\n",
        "print()\n",
        "print('TEST4 MISTRAL: Knowledge retrieval')\n",
        "print()\n",
        "print('Prompt #4: %s'%prompt4)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt4,predictor,0)\n",
        "#s=sentiment[0]\n",
        "print('OUTPUT PROMPT4:')\n",
        "print(f\"Answer: {sentiment[0]['generated_text']}\")\n",
        "#print(s['generated_text'])\n",
        "#print(sentiment[0])\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('TEST4 - LLAMA2: Knowledge retrieval')\n",
        "print()\n",
        "print('Prompt #4: %s'%prompt4)\n",
        "print()\n",
        "sentiment = predict_sentiment(prompt4,predictor_llama,1)\n",
        "print('OUTPUT PROMPT4 - LLAMA2:')\n",
        "print(f\"Answer: {sentiment[0]['generation']}\")\n",
        "print()\n"
      ],
      "metadata": {
        "id": "Ijaf83ka82wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738a126e-8bad-4165-bb78-1e059339fbcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTING of the Mistral LLM running hosted in AWS WITH THE CODE RUNNING FROM GOOGLE CLOUD with Google Colab\n",
            "\n",
            "\n",
            "\n",
            "TEST1 MISTRAL: Mathematics and reasoning\n",
            "\n",
            "Prompt #1: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "\n",
            "OUTPUT PROMPT1:\n",
            "Answer:  When you bought the ice cream for the 6 kids, you spent a total of $1.25 \\* 6 = $<<1.25*6=7.50>>7.50.\n",
            "\n",
            "When you paid with a $10 bill, you gave away $10 - $7.50 = $<<10-7.5=2.50>>2.50.\n",
            "\n",
            "So, you got back $2.50.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TEST1 - LLAMA2: Mathematics and reasoning\n",
            "\n",
            "Prompt #1: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "\n",
            "OUTPUT PROMPT1 - LLAMA2:\n",
            "Answer: \n",
            "How much would you pay for a carton of milk?\n",
            "I can’t decide between 3 cereals that cost $1.45, $2.35, and $3.25. How much money do I have to spend to get 3 boxes of cereal? Explain your thinking.\n",
            "How many bottles of shampoo can you buy with $15? Explain first before answering.\n",
            "What’s the largest number you can make with 3, 4, and 5? Explain your thinking before answering.\n",
            "How much would you pay for a can of soda?\n",
            "I can’t decide between 2 types of yogurt that cost $1.65 and $1.85. How much money do I have to spend to get 2 containers of yogurt? Explain your thinking.\n",
            "How many pieces of fruit do you get for $0.55?\n",
            "What’s the largest number you can make with 6, 7, and 8? Explain your thinking before answering.\n",
            "I can’t decide between 2 types of pizza that cost $5.65 and $6.75. How much money do I have to spend to get 2 pizzas? Explain your thinking.\n",
            "How much would you pay for a slice of pizza?\n",
            "I can’t decide between 2 types of cookies that cost $3.95 and $5.95. How much money do I have to spend to get 2 packages of cookies? Explain your thinking.\n",
            "How many dollars would you spend to buy a shirt and some jeans?\n",
            "I can’t decide between 2 types of cake that cost $7.10 and $7.90. How much money do I have to spend to get 2 cakes? Explain your thinking.\n",
            "What’s the largest number you can make with 3, 5, and 7? Explain your thinking before answering.\n",
            "I can’t decide between 2 types of pasta that cost $2.10 and $3.50. How much money do I have to spend to get 2 packages of pasta? Explain your thinking.\n",
            "How much would you pay for 2 pieces of fruit?\n",
            "I can’t decide between 2 types of candy that cost $2.30 and\n",
            "\n",
            "\n",
            "\n",
            "TEST2 MISTRAL: Predict the following words in the sequence\n",
            "\n",
            "Prompt #2: This new music video was incredibile\n",
            "\n",
            "OUTPUT PROMPT2:\n",
            "Answer:  I'm glad you enjoyed the music video! If you have any other questions or comments, feel free to ask.\n",
            "\n",
            "\n",
            "TEST3 MISTRAL: MCAS Grade 10 English Language Arts Reading Comprehension test\n",
            "\n",
            "Prompt #3: A rat is a rodent, the most common mammal in the world. Rattus norvegicus is one of the approximately four hundred different kinds of rodents, and it is known by many names, each of which describes a trait or a perceived trait or sometimes a habitat: the earth rat, the roving rat, the barn rat, the fi eld rat, the migratory rat, the house rat, the sewer rat, the water rat, the wharf rat, the alley rat, the gray rat, the brown rat, and the common rat. The average brown rat is large and stocky; it grows to be approximately sixteen inches long from its nose to its tail—the size of a large adult human male’s foot—and weighs about a pound, though brown rats have been measured by scientists and exterminators at twenty inches and up to two pounds. The brown rat is sometimes confused with the black rat, or Rattus rattus, which is smaller and once inhabited New York City and all of the cities of America but, since Rattus norvegicus pushed it out, is now relegated to a minor role. (The two species still survive alongside each other in some Southern coastal cities and on the West Coast, in places like Los Angeles, for example, where the black rat lives in attics and palm trees.) The black rat is always a very dark gray, almost black, and the brown rat is gray or brown, with a belly that can be light gray, yellow, or even a pure-seeming white. One spring, beneath the Brooklyn Bridge, I saw a red-haired brown rat that had been run over by a car. Both pet rats and laboratory rats are Rattus norvegicus, but they are not wild and therefore, I would emphasize, not the subject of this book. Sometimes pet rats are called fancy rats. But if anyone has picked up this book to learn about fancy rats, then they should put this book down right away; none of the rats mentioned herein are at all fancy. Rats are nocturnal, and out in the night the brown rat’s eyes are small and black and shiny; when a fl ashlight shines into them in the dark, the eyes of a rat light up like the eyes of a deer. Though it forages* in darkness, the brown rat has poor eyesight. It makes up for this with, fi rst of all, an excellent sense of smell. . . . They have an excellent sense of taste, detecting the most minute amounts of poison, down to one part per million. A brown rat has strong feet, the two front paws each equipped with four clawlike nails, the rear paws even longer and stronger. It can run and climb with squirrel-like agility. It is an excellent swimmer, surviving in rivers and bays, in sewer streams and toilet bowls. The brown rat’s teeth are yellow, the front two incisors being especially long and sharp, like buckteeth. When the brown rat bites, its front two teeth spread apart. When it gnaws, a fl ap of skin plugs the space behind its incisors. Hence, when the rat gnaws on indigestible materials—concrete or steel, for example—the shavings don’t go down the rat’s throat and kill it. Its incisors grow at a rate of fi ve inches per year. Rats always gnaw, and no one is certain why—there are few modern rat studies. It is sometimes erroneously stated that the rat gnaws solely to limit the length of its incisors, which would otherwise grow out of its head, but this is not the case: the incisors wear down naturally. In terms of hardness, the brown rat’s teeth are stronger than aluminum, copper, lead, and iron. They are comparable to steel. With the alligator-like structure of their jaws, rats can exert a biting pressure of up to seven thousand pounds per square inch. Rats, like mice, seem to be attracted to wires—to utility wires, computer wires, wires in vehicles, in addition to gas and water pipes. One rat expert theorizes that wires may be attractive to rats because of their resemblance to vines and the stalks of plants; cables are the vines of the city. By one estimate, 26 percent of all electric-cable breaks and 18 percent of all phone-cable disruptions are caused by rats. According to one study, as many as 25 percent of all fi res of unknown origin are rat-caused. Rats chew electrical cables. Sitting in a nest of tattered rags and newspapers, in the fl oorboards of an old tenement, a rat gnaws the head of a match—the lightning in the city forest.When it is not gnawing or feeding on trash, the brown rat digs. Anywhere there is dirt in a city, brown rats are likely to be digging—in parks, in fl owerbeds, in little dirt-poor backyards. They dig holes to enter buildings and to make nests. Rat nests can be in the floorboards of apartments, in the waste-stuffed corners of subway stations, in sewers, or beneath old furniture in basements. “Cluttered and unkempt alleyways in cities provide ideal rat habitat, especially those alleyways associated with food-serving establishments,” writes Robert Corrigan in Rodent Control, a pest control manual. “Alley rats can forage safely within the shadows created by the alleyway, as well as quickly retreat to the safety of cover in these narrow channels.” Often, rats burrow under concrete sidewalk slabs. Entrance to a typical under-the-sidewalk rat’s nest is gained through a two-inch-wide hole—their skeletons collapse and they can squeeze into a hole as small as three quarters of an inch wide, the average width of their skull. This tunnel then travels about a foot down to where it widens into a nest or den. The den is lined with soft debris, often shredded plastic garbage or shopping bags, but sometimes even grasses or plants; some rat nests have been found stuffed with the gnawed shavings of the wood-based, spring-loaded snap traps that are used in attempts to kill them. The back of the den then narrows into a long tunnel that opens up on another hole back on the street. This second hole is called a bolt hole; it is an emergency exit. A bolt hole is typically covered lightly with dirt or trash—camoufl age. Sometimes there are networks of burrows, which can stretch beneath a few concrete squares on a sidewalk, or a number of backyards, or even an entire city block—when Rattus norvegicus fi rst came to Selkirk, England, in 1776, there were so many burrows that people feared the town might sink. Rats can also nest in basements, sewers, manholes, abandoned pipes of any kind, fl oorboards, or any hole or depression. “Often,” Robert Corrigan writes, “‘city rats’ will live unbeknownst to people right beneath their feet.” Rats also inhabit subways, as most people in New York City and any city with a subway system are well aware. Every once in a while, there are reports of rats boarding trains, but for the most part rats stay on the tracks—subway workers I have talked to refer to rats as “track rabbits.” People tend to think that the subways are fi lled with rats, but in fact rats are not everywhere in the system; they live in the subways according to the supply of discarded human food and sewer leaks. Sometimes, rats use the subway purely for nesting purposes; they fi nd ways through the walls of the subway stations leading from the tracks to the restaurants and stores on the street—the vibrations of  subway trains tend to create rat-size cracks and holes. Many subway rats tend to live near stations that are themselves near fast-food restaurants. At the various subway stations near Herald Square, for example, people come down from the streets and throw the food that they have not eaten onto the tracks, along with newspapers and soda bottles and, I have noticed, thousands of nolonger-charged AA batteries, waiting to leak acid. The rats eat freely from the waste and sit at the side of the little streams of creamy brown sewery water that fl ows between the rails. They sip the water the way rats do, either with their front paws or by scooping it up with their incisors. What is the most likely reason the author states, \"cables are the vines of the city\"?\n",
            "\n",
            "OUTPUT PROMPT3:\n",
            "Answer:  The most likely reason the author states, \"cables are the vines of the city\" is because rats are attracted to wires and cables due to their resemblance to vines and the stalks of plants. They may see the cables as a way to climb and move through the city, and they may also gnaw on them for food or to sharpen their teeth.\n",
            "\n",
            "\n",
            "TEST4 MISTRAL: Knowledge retrieval\n",
            "\n",
            "Prompt #4: Which country has the most natural lakes? Answer with only the country name.\n",
            "\n",
            "OUTPUT PROMPT4:\n",
            "Answer:  Canada\n",
            "\n",
            "\n",
            "TEST4 - LLAMA2: Knowledge retrieval\n",
            "\n",
            "Prompt #4: Which country has the most natural lakes? Answer with only the country name.\n",
            "\n",
            "OUTPUT PROMPT4 - LLAMA2:\n",
            "Answer: \n",
            "The World Atlas of Lakes\n",
            "Africa and Middle East - 4219 Lakes\n",
            "South America - 3992 Lakes\n",
            "North America - 3626 Lakes\n",
            "Europe - 3314 Lakes\n",
            "Oceania - 705 Lakes\n",
            "Asia - 1023 Lakes\n",
            "The highest lake in the world\n",
            "The highest lake in the world is found in the Himalayan Mountains. This lake is called the Pangong Tso or Pangong Tso Lake. This lake is situated at a height of 14,270 feet.\n",
            "The world’s largest lake is in North America. This lake is called Lake Superior.\n",
            "The largest lake in Asia is found in the Tibetan Plateau. This lake is called the Titicaca Lake.\n",
            "The largest lake in Africa is found in Tanzania. This lake is called the Victoria Lake.\n",
            "The largest lake in Europe is found in Siberia. This lake is called the Lake Baikal.\n",
            "The largest lake in the world is the Caspian Sea. This lake is found in Asia and Europe. The length of this lake is 1430 km.\n",
            "The smallest lake in the world is the Bajka Lake. This lake is situated in Italy. The size of this lake is only 250 meters.\n",
            "The world’s second largest lake is Lake Huron.\n",
            "The world’s third largest lake is Lake Victoria. This lake is found in Africa and Asia.\n",
            "The world’s fourth largest lake is Lake Vostok. This lake is found in Antarctica.\n",
            "The world’s fifth largest lake is the Great Slave Lake. This lake is found in Canada.\n",
            "The world’s sixth largest lake is the Salton Sea. This lake is found in the United States.\n",
            "The world’s seventh largest lake is Lake Tanganyika. This lake is found in Africa.\n",
            "The world’s eighth largest lake is Lake Victoria. This lake is found in Africa.\n",
            "The world’s ninth largest lake is the Caspian Sea. This lake is found in Europe and Asia.\n",
            "The world’s tenth largest lake is Lake Ladoga. This lake is found in Europe.\n",
            "The world’s eleventh largest lake is Lake Superior. This lake is found in North America.\n",
            "The world\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CLEAN UP##"
      ],
      "metadata": {
        "id": "US4T-TG0i6Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Frank Morales created this cell on December 14, 2023; it fully allows automatically the deletion of endpoints, models, and endpoint configurations.\n",
        "\n",
        "#!pip install colab-env --upgrade\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "aws_region=os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "aws_output=os.getenv(\"AWS_DEFAULT_OUTPUT\")\n",
        "\n",
        "#!pip install boto3\n",
        "#aws_region = 'us-east-1'\n",
        "import boto3\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "\n",
        "def cleanup_sagemaker_resources(resource_name,resourceid):\n",
        "\n",
        "    if resourceid==0:\n",
        "       response=sagemaker_client.list_endpoints()\n",
        "    elif resourceid==1:\n",
        "         response=sagemaker_client.list_models()\n",
        "    elif resourceid==2:\n",
        "         response=sagemaker_client.list_endpoint_configs()\n",
        "\n",
        "    print(resource_name)\n",
        "    #resource_nametmp='%s'%resource_name[0:len(resource_name)-1]\n",
        "    #print('%sName'%resource_nametmp)\n",
        "\n",
        "    number_of_endpoints=len(response['%s'%resource_name])\n",
        "    for i in range(number_of_endpoints):\n",
        "        resource_nametmp='%s'%resource_name[0:len(resource_name)-1]\n",
        "        print('%sName'%resource_nametmp)\n",
        "        print(response['%s'%resource_name][i]['%sName'%resource_nametmp])\n",
        "\n",
        "        if resourceid==0:\n",
        "           endpoint_name=response['%s'%resource_name][i]['%sName'%resource_nametmp]\n",
        "           sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
        "        elif resourceid==1:\n",
        "           sagemaker_client.delete_model(ModelName=response['Models'][i]['ModelName'])\n",
        "        elif resourceid==2:\n",
        "           sagemaker_client.delete_endpoint_config(EndpointConfigName=response['EndpointConfigs'][i]['EndpointConfigName'])\n",
        "\n",
        "    print(\"\\n==================================\\n\")\n",
        "\n",
        "cleanup_sagemaker_resources('Endpoints',0)\n",
        "\n",
        "cleanup_sagemaker_resources('Models',1)\n",
        "\n",
        "cleanup_sagemaker_resources('EndpointConfigs',2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYkM2BLNcwRg",
        "outputId": "b24828ec-da01-4592-a561-ab71e44584e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoints\n",
            "EndpointName\n",
            "meta-textgeneration-llama-2-7b-2023-12-19-00-28-23-982\n",
            "EndpointName\n",
            "hf-llm-mistral-7b-instruct-2023-12-19-00-24-20-798\n",
            "\n",
            "==================================\n",
            "\n",
            "Models\n",
            "ModelName\n",
            "meta-textgeneration-llama-2-7b-2023-12-19-00-28-23-980\n",
            "ModelName\n",
            "hf-llm-mistral-7b-instruct-2023-12-19-00-24-20-796\n",
            "\n",
            "==================================\n",
            "\n",
            "EndpointConfigs\n",
            "EndpointConfigName\n",
            "meta-textgeneration-llama-2-7b-2023-12-19-00-28-23-982\n",
            "EndpointConfigName\n",
            "hf-llm-mistral-7b-instruct-2023-12-19-00-24-20-798\n",
            "\n",
            "==================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Frank Morales created this cell on December 14, 2023; it fully allows automatically the deletion of endpoints, models, and endpoint configurations.\n",
        "## TODO create a function for the loop\n",
        "\n",
        "aws_region = 'us-east-1'\n",
        "import boto3\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "\n",
        "print('')\n",
        "print('Endpoints')\n",
        "response=sagemaker_client.list_endpoints()\n",
        "number_of_endpoints=len(response['Endpoints'])\n",
        "for i in range(number_of_endpoints):\n",
        "    print(response['Endpoints'][i]['EndpointName'])\n",
        "    endpoint_name=response['Endpoints'][i]['EndpointName']\n",
        "    sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
        "\n",
        "\n",
        "print('')\n",
        "print('Models')\n",
        "response_models=sagemaker_client.list_models()\n",
        "for i in range(len((response_models['Models']))):\n",
        "    print(response_models['Models'][i]['ModelName'])\n",
        "    sagemaker_client.delete_model(ModelName=response_models['Models'][i]['ModelName'])\n",
        "\n",
        "\n",
        "print('')\n",
        "print('EndpointConfigs')\n",
        "response_configs=sagemaker_client.list_endpoint_configs()\n",
        "for i in range(len((response_configs['EndpointConfigs']))):\n",
        "    print(response_configs['EndpointConfigs'][i]['EndpointConfigName'])\n",
        "    sagemaker_client.delete_endpoint_config(EndpointConfigName=response_configs['EndpointConfigs'][i]['EndpointConfigName'])"
      ],
      "metadata": {
        "id": "a2zzj1YOjHlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae0b75a-103b-4eb9-f51b-fbed7e570df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Endpoints\n",
            "meta-textgeneration-llama-2-7b-2023-12-17-23-45-51-522\n",
            "hf-llm-mistral-7b-instruct-2023-12-17-23-40-47-946\n",
            "\n",
            "Models\n",
            "meta-textgeneration-llama-2-7b-2023-12-17-23-45-51-518\n",
            "hf-llm-mistral-7b-instruct-2023-12-17-23-40-47-944\n",
            "\n",
            "EndpointConfigs\n",
            "meta-textgeneration-llama-2-7b-2023-12-17-23-45-51-522\n",
            "hf-llm-mistral-7b-instruct-2023-12-17-23-40-47-946\n"
          ]
        }
      ]
    }
  ]
}