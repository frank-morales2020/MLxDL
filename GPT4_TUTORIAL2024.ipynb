{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgFMb486YLgC2I1VJWi0g0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/GPT4_TUTORIAL2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "#%pip install openai  --root-user-action=ignore\n",
        "#%pip install colab-env --upgrade --quiet --root-user-action=ignore"
      ],
      "metadata": {
        "id": "31JqEPIeV84n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W2f9gUvuVmYz"
      },
      "outputs": [],
      "source": [
        "def gpt_reponse(query):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    #model=\"gpt-3.5-turbo\"\n",
        "    #response_format={ \"type\": \"json_object\" },\n",
        "    messages=[\n",
        "      #{\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output text.\"},\n",
        "      {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "XaZRK6yrVyEO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\"\n",
        "response=gpt_reponse(query)\n",
        "print()\n",
        "print('Question: %s'%query)\n",
        "print('Answer: %s'%response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03AQB3j1WgRj",
        "outputId": "6ed89de5-4d58-43a6-e6e7-f0890addc3f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "Answer: First, you need to calculate the total cost of the ice cream cones. You bought ice cream for 6 kids and each cone was $1.25. \n",
            "\n",
            "So, to calculate the total cost, multiply the cost of a single ice cream cone($1.25) by the number of kids(6):\n",
            "\n",
            "$1.25 * 6 = $7.50\n",
            "\n",
            "So, you have spent $7.50 on ice cream cones.\n",
            "\n",
            "Now, you need to know how much change you got. You paid with a $10 bill. To figure out your change or the money you get back, subtract the total cost of the ice cream cones from the amount you paid.\n",
            "\n",
            "So, $10.00 - $7.50 = $2.50\n",
            "\n",
            "You got $2.50 back.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who won the world series in 2009 and who lost, explained?, who were the managers?\"\n",
        "response=gpt_reponse(query)\n",
        "print()\n",
        "print('Question: %s'%query)\n",
        "print('Answer: %s'%response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2sjWQ-GWwSd",
        "outputId": "d6f57370-c16d-46be-dd63-afb83d67bd67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Who won the world series in 2009 and who lost, explained?, who were the managers?\n",
            "Answer: The 2009 World Series was won by the New York Yankees. They defeated the Philadelphia Phillies. This was the 27th World Series Championship for the Yankees. \n",
            "\n",
            "The manager of the New York Yankees at the time was Joe Girardi. He led the Yankees to their first World Series title since 2000, and the first under his management. \n",
            "\n",
            "On the other hand, the Philadelphia Phillies, who were the 2008 World Series champions, lost in the 2009 World Series. Their manager was Charlie Manuel. Despite losing in the 2009 World Series, Manuel had led the Phillies to their second consecutive World Series appearance, a feat the team had not accomplished since 1980 and 1981.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "prompt = \"GENERATE futuristic IMAGE of Mixture of Expert Architecture. Definitions and Applications included Google's Gemini and Mixtral 8x7B\"\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"%s\"%prompt,\n",
        "  #size=\"1024x1024\",\n",
        "  #size=\"256x256\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        "  #=\"b64_json\",\n",
        ")\n",
        "\n",
        "\n",
        "image_url = response.data[0].url\n",
        "\n",
        "print(prompt)\n",
        "print()\n",
        "print(response.data[0].url)\n",
        "print()\n",
        "\n",
        "# datetime object containing current date and time\n",
        "newYorkTz = pytz.timezone(\"America/New_York\")\n",
        "now = datetime.now(newYorkTz)\n",
        "#print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "#print(\"date and time =\", dt_string)\n",
        "\n",
        "print()\n",
        "print('TEST - OPENAI/GPT-4-VISION API - MODEL Dall-e-3 - BY FRANK MORALES - %s'%dt_string)\n",
        "print()\n",
        "\n",
        "\n",
        "IPython.display.HTML(\"<img src =\" + response.data[0].url + \">\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4xro7VQGXNU0",
        "outputId": "e9d93429-9f73-46b7-da9a-7d198e5661a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATE futuristic IMAGE of Mixture of Expert Architecture. Definitions and Applications included Google's Gemini and Mixtral 8x7B\n",
            "\n",
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-kw9OnWtmHIJ748Xe7oTALKxl/user-mgtzrBIISo3G68oiCnIQ0OBP/img-cG7ssxoVlzKVFR1ZWOtSiRSh.png?st=2024-02-23T11%3A13%3A45Z&se=2024-02-23T13%3A13%3A45Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-02-22T16%3A16%3A24Z&ske=2024-02-23T16%3A16%3A24Z&sks=b&skv=2021-08-06&sig=gEuGvhx1cqClwzLF%2BiRsyxIC92inJihZlqI0%2B1TQWJQ%3D\n",
            "\n",
            "\n",
            "TEST - OPENAI/GPT-4-VISION API - MODEL Dall-e-3 - BY FRANK MORALES - 23/02/2024 07:13:45\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src =https://oaidalleapiprodscus.blob.core.windows.net/private/org-kw9OnWtmHIJ748Xe7oTALKxl/user-mgtzrBIISo3G68oiCnIQ0OBP/img-cG7ssxoVlzKVFR1ZWOtSiRSh.png?st=2024-02-23T11%3A13%3A45Z&se=2024-02-23T13%3A13%3A45Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-02-22T16%3A16%3A24Z&ske=2024-02-23T16%3A16%3A24Z&sks=b&skv=2021-08-06&sig=gEuGvhx1cqClwzLF%2BiRsyxIC92inJihZlqI0%2B1TQWJQ%3D>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}