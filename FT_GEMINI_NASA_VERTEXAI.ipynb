{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODwEgNgb2Q7bK//mw2DPnf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FT_GEMINI_NASA_VERTEXAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "!pip install google-generativeai -q\n",
        "!pip install rouge-score -q\n"
      ],
      "metadata": {
        "id": "5VFKK5piHxhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESPsgxVdHMRh"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.tuning import sft\n",
        "import vertexai\n",
        "import os\n",
        "from google.colab import auth\n",
        "import colab_env\n",
        "import time\n",
        "\n",
        "# Project details (replace with your values if not using env vars)\n",
        "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "REGION = os.environ.get(\"GOOGLE_CLOUD_REGION\")\n",
        "BUCKET_NAME = os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\")\n",
        "STAGING_BUCKET = f\"gs://{BUCKET_NAME}/staging\"\n",
        "\n",
        "# Authentication and Initialization\n",
        "auth.authenticate_user()\n",
        "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Define your tuning parameters\n",
        "BASE_MODEL = \"gemini-2.0-flash-001\"  # Using Gemini 2.0 Flash\n",
        "\n",
        "TRAIN_DATASET_URI = f\"gs://{BUCKET_NAME}/cmapss_FD004_train_text.jsonl\"  # Path to your training data in JSONL format\n",
        "VALIDATION_DATASET_URI = f\"gs://{BUCKET_NAME}/cmapss_FD004_test_text.jsonl\"  # Path to your validation data in JSONL format\n",
        "TUNED_MODEL_DISPLAY_NAME = \"cmapss-text-tuned-gemini-2.0-flash-001\"\n",
        "EPOCHS = 10  # Adjust as needed\n",
        "LEARNING_RATE_MULTIPLIER = 1.0  # Adjust as needed\n",
        "\n",
        "\n",
        "\n",
        "# Start the fine-tuning job\n",
        "try:\n",
        "    sft_tuning_job = sft.train(\n",
        "        source_model=BASE_MODEL,\n",
        "        train_dataset=TRAIN_DATASET_URI,\n",
        "        validation_dataset=VALIDATION_DATASET_URI,\n",
        "        tuned_model_display_name=TUNED_MODEL_DISPLAY_NAME,\n",
        "        epochs=EPOCHS,\n",
        "        learning_rate_multiplier=LEARNING_RATE_MULTIPLIER,\n",
        "    )\n",
        "\n",
        "\n",
        "    print(f\"Tuning job started: {sft_tuning_job.resource_name}\")\n",
        "\n",
        "    # Periodically check the job status until it's complete\n",
        "    while True:\n",
        "        job_status = sft_tuning_job.state  # Get the job's state directly\n",
        "\n",
        "        if job_status in (\"SUCCEEDED\", \"FAILED\", \"CANCELLED\"):\n",
        "            break  # Exit the loop if the job is finished\n",
        "\n",
        "        print(f\"Job status: {job_status}, waiting...\")\n",
        "        time.sleep(60)  # Wait for 60 seconds before checking again\n",
        "\n",
        "    print(f\"Tuning job completed with status: {job_status}. Resource name: {sft_tuning_job.resource_name}\")\n",
        "\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please double-check the base model name and your Vertex AI setup.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tuning job completed with Resource name: {sft_tuning_job.resource_name}\")"
      ],
      "metadata": {
        "id": "vpkS41BjYYCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"contents\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Engine sensor readings over time: [1.0, 41.9993, 0.8409, 100.0, 445.0, 548.68, 1343.85, 1111.03, 3.91, 5.69, 137.26, 2211.96, 8296.96, ..., 8054.65, 9.2728, 0.02, 331.0, 2223.0, 100.0, 14.78, 8.8922]\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Remaining Useful Life: 0\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "J9zmGV6OAiMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls gs://{BUCKET_NAME}"
      ],
      "metadata": {
        "id": "A6af2mQeQ1pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp -pr batch_prediction_output gs://{BUCKET_NAME}/\n",
        "!gsutil ls gs://{BUCKET_NAME}/"
      ],
      "metadata": {
        "id": "t_PW_pqSQNdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.tuning import sft\n",
        "import vertexai\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from google.colab import auth\n",
        "from google.cloud import aiplatform\n",
        "from google.api_core import exceptions\n",
        "from google.cloud.aiplatform_v1.types import JobState\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
      ],
      "metadata": {
        "id": "ipF_vPEfUGmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "STR83WXTNL-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model name\n",
        "projects/677155171887/locations/us-central1/models/1440268972921454592@1\n",
        "\n",
        "Tuning job\n",
        "projects/677155171887/locations/us-central1/tuningJobs/5437787329584431104\n",
        "\n",
        "Status\n",
        "Succeeded\n",
        "\n",
        "Region\n",
        "us-central1\n",
        "\n",
        "Created\n",
        "Apr 5, 2025, 5:49:28 AM\n",
        "Ended\n",
        "Apr 5, 2025, 6:19:46 AM"
      ],
      "metadata": {
        "id": "y-w0T9qGH15L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score -q\n",
        "!pip install google-generativeai -q\n",
        "!pip install colab-env -q"
      ],
      "metadata": {
        "id": "pzLaN6qNdA0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata, auth\n",
        "from google.cloud import aiplatform_v1beta1 as aiplatform\n",
        "\n",
        "# Authentication and Initialization\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "REGION = os.environ.get(\"GOOGLE_CLOUD_REGION\")\n",
        "BUCKET_NAME = os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\")\n",
        "\n",
        "EVAL_DATASET_URI = f\"gs://{BUCKET_NAME}/cmapss_FD004_test_text.jsonl\"\n",
        "tuned_model_resource_name = 'projects/677155171887/locations/us-central1/models/1440268972921454592@1'  # Replace with your tuned model name\n",
        "\n",
        "# Get the prediction client\n",
        "endpoint = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "client_options = {\"api_endpoint\": endpoint}\n",
        "prediction_client = aiplatform.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "# ROUGE Score Calculation\n",
        "def calculate_rouge(reference, generated):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, generated)\n",
        "    return scores\n",
        "\n",
        "# Download and Evaluate\n",
        "print(f\"Evaluating model: {tuned_model_resource_name}\\n\")\n",
        "!gsutil cp -pr {EVAL_DATASET_URI} .\n",
        "print('\\n')\n",
        "eval_dataset_path = 'cmapss_FD004_test_text.jsonl'\n",
        "\n",
        "rouge_scores = []\n",
        "processed_lines = 0\n",
        "with open(eval_dataset_path, 'r') as f:\n",
        "    for line in f:\n",
        "        processed_lines += 1\n",
        "        try:\n",
        "            print(f\"Processing line {processed_lines}: {line.strip()[:100]}...\")\n",
        "            data = json.loads(line)\n",
        "\n",
        "            # Extract prompt and completion\n",
        "            prompt = data[\"contents\"][0][\"parts\"][0][\"text\"]  # Extract prompt text directly\n",
        "            completion = data[\"contents\"][1][\"parts\"][0][\"text\"]  # Extract completion text\n",
        "\n",
        "            # Validate prompt and completion\n",
        "            if not prompt or not completion:\n",
        "                raise ValueError(f\"Empty prompt or completion in line: {line.strip()}\")\n",
        "\n",
        "            # Model prediction using the prediction client\n",
        "            instance = {\"content\": prompt}  # Use 'content' as the key for the prompt\n",
        "            request = aiplatform.PredictRequest(\n",
        "                endpoint=tuned_model_resource_name,\n",
        "                instances=[instance],  # Wrap instance in a list\n",
        "            )\n",
        "            response = prediction_client.predict(request=request)\n",
        "\n",
        "            # Extract prediction text (adjust based on response format)\n",
        "            generated_text = response.predictions[0][\"content\"]\n",
        "\n",
        "            scores = calculate_rouge(completion, generated_text)\n",
        "            rouge_scores.append(scores)\n",
        "\n",
        "\n",
        "        except (json.JSONDecodeError, KeyError, TypeError, ValueError) as e:\n",
        "            print(f\"Error processing line: {line.strip()[:100]}..., Error: {e}\")\n",
        "            print(f\"Full line: {line.strip()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error processing line: {line.strip()[:100]}..., Error: {e}\")\n",
        "            print(f\"Full line: {line.strip()}\")\n",
        "\n",
        "# Calculate and Print Average Scores\n",
        "if not rouge_scores:\n",
        "    print(f\"No ROUGE scores calculated. Processed {processed_lines} lines.\")\n",
        "    print(\"Check dataset format and model prediction logic.\")\n",
        "else:\n",
        "    avg_rouge1 = sum([scores['rouge1'].fmeasure for scores in rouge_scores]) / len(rouge_scores)\n",
        "    avg_rouge2 = sum([scores['rouge2'].fmeasure for scores in rouge_scores]) / len(rouge_scores)\n",
        "    avg_rougeL = sum([scores['rougeL'].fmeasure for scores in rouge_scores]) / len(rouge_scores)\n",
        "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
        "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1F7kRsR_bQ1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}