{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "F3Zb2mqu3AcA",
        "Ucspq-tBeq-X",
        "B2l5Jf1dvfHn",
        "HpnoN8VZqlQz",
        "whs9_Qwsq0kw"
      ],
      "authorship_tag": "ABX9TyN3qbjyz0t8jIfzNK6MnloB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae9b0f5765954978a6b062fd38d53408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_924440afbe73481c9677a26b634d351b",
              "IPY_MODEL_fd62d95cdbdc432ca6588d657cef52d2",
              "IPY_MODEL_99998bd88dfa4352a1e90005f88fc453"
            ],
            "layout": "IPY_MODEL_a99721aebf434117a9c7fc0075dd85bc"
          }
        },
        "924440afbe73481c9677a26b634d351b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3caafbf70f57401e97eed7516f880985",
            "placeholder": "​",
            "style": "IPY_MODEL_d42537c40899464b9a998417ce5b7e5e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fd62d95cdbdc432ca6588d657cef52d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d64591015e14b458366ec883a52be4a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c5a55befb0c4776ae459ead89236b5b",
            "value": 2
          }
        },
        "99998bd88dfa4352a1e90005f88fc453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ef7d219a0e4b2390e5183050e91dc8",
            "placeholder": "​",
            "style": "IPY_MODEL_8b80d5193e6241698d89e121d0977b4f",
            "value": " 2/2 [00:18&lt;00:00,  8.83s/it]"
          }
        },
        "a99721aebf434117a9c7fc0075dd85bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3caafbf70f57401e97eed7516f880985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42537c40899464b9a998417ce5b7e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d64591015e14b458366ec883a52be4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5a55befb0c4776ae459ead89236b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76ef7d219a0e4b2390e5183050e91dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b80d5193e6241698d89e121d0977b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "594a44d8fdd2415c80a746f38936bd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e93a89a63c4743f0808c94f219079272",
              "IPY_MODEL_ff3dbc5df9974cd684915febdfdc3b58",
              "IPY_MODEL_d65ba4a837774de1af4aac0f2531331e"
            ],
            "layout": "IPY_MODEL_f583195a8e65431da039d3433faa8ee8"
          }
        },
        "e93a89a63c4743f0808c94f219079272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4169353b95ac4b47a54f0aa20dd5329e",
            "placeholder": "​",
            "style": "IPY_MODEL_bdbcb5b587e34a88983affaffa190fb3",
            "value": "Map: 100%"
          }
        },
        "ff3dbc5df9974cd684915febdfdc3b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ec4f4305e34e7db0034227ba2e6d44",
            "max": 226,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_111810ce974e404f96efb0193831ec9c",
            "value": 226
          }
        },
        "d65ba4a837774de1af4aac0f2531331e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00f43a9e46db4dcd83ff7ea827352ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_3d1f7cd462bd4ff1b921c974cae51b47",
            "value": " 226/226 [00:01&lt;00:00, 225.24 examples/s]"
          }
        },
        "f583195a8e65431da039d3433faa8ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4169353b95ac4b47a54f0aa20dd5329e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdbcb5b587e34a88983affaffa190fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ec4f4305e34e7db0034227ba2e6d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111810ce974e404f96efb0193831ec9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00f43a9e46db4dcd83ff7ea827352ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d1f7cd462bd4ff1b921c974cae51b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "157a481b5b1f4dfbb62db8ef429e7515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a45b195042d44e89a1ab7c840f1f4d5",
              "IPY_MODEL_86fd4d6d83084837b05b349c99319034",
              "IPY_MODEL_dfbce4e8f389499f88699f5bb0a1b84b"
            ],
            "layout": "IPY_MODEL_ca1778e89b1a43a1acda0a55ef2eba76"
          }
        },
        "2a45b195042d44e89a1ab7c840f1f4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1d7ba099434d8e90d5ea841b52b52b",
            "placeholder": "​",
            "style": "IPY_MODEL_e407a2794c93457d80fd38b2d4c2883c",
            "value": "Truncating train dataset: 100%"
          }
        },
        "86fd4d6d83084837b05b349c99319034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_531ae9326a6a403db64ef3f91d3bd335",
            "max": 226,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4986c49cfaf4b9ea11280794fec44de",
            "value": 226
          }
        },
        "dfbce4e8f389499f88699f5bb0a1b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f7cdd255804fda9e8504636c89624e",
            "placeholder": "​",
            "style": "IPY_MODEL_653f10b07e03405f8c1cdc7444da68f0",
            "value": " 226/226 [00:00&lt;00:00, 14082.79 examples/s]"
          }
        },
        "ca1778e89b1a43a1acda0a55ef2eba76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1d7ba099434d8e90d5ea841b52b52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e407a2794c93457d80fd38b2d4c2883c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "531ae9326a6a403db64ef3f91d3bd335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4986c49cfaf4b9ea11280794fec44de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28f7cdd255804fda9e8504636c89624e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653f10b07e03405f8c1cdc7444da68f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/cmapss-text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU testing"
      ],
      "metadata": {
        "id": "F3Zb2mqu3AcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "-p07BIHq3Fii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installation"
      ],
      "metadata": {
        "id": "Ucspq-tBeq-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 OR L4 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install datasets trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install accelerate --quiet"
      ],
      "metadata": {
        "id": "JARmny3ZO_5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "B2l5Jf1dvfHn"
      }
    },
    {
      "source": [
        "# Dynamically check for sliding window support in flash_attn\n",
        "_flash_supports_window_size = False  # Initialize to False\n",
        "try:\n",
        "    import flash_attn  # Try to import flash_attn\n",
        "\n",
        "    if hasattr(flash_attn, \"flash_attn_func\"):\n",
        "        from flash_attn.flash_attn_interface import _flash_supports_window_size\n",
        "    else:\n",
        "        from flash_attn.flash_attention import _flash_supports_window_size\n",
        "except ImportError:\n",
        "    pass  # If flash_attn is not installed, keep _flash_supports_window_size as False"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gU76uaBdEQCz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import TrainingArguments\n",
        "import accelerate\n",
        "\n",
        "# Initialize the Accelerator\n",
        "accelerator = accelerate.Accelerator()\n",
        "\n",
        "#!pip install diffusers safetensors  --quiet\n",
        "#!pip install colab-env --quiet\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\")\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jEIt5AjErhb",
        "outputId": "7a149fb2-222a-4c87-e2ab-5a70836da9a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrjM_pByFAcq",
        "outputId": "12f1d241-3683-4563-e4c3-e150d82ceec1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "HpnoN8VZqlQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import zipfile\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "# --- Data Loading from Google Drive ---\n",
        "zip_path = '/content/gdrive/MyDrive/datasets/CMAPSSData.zip'\n",
        "extract_dir = 'data/cmapss'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "!mkdir -p /content/gdrive/MyDrive/datasets/CMAPSSData/\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"Error: CMAPSSData.zip not found at {zip_path}. Please ensure the file is correctly located in your Google Drive.\")\n",
        "    raise FileNotFoundError(f\"CMAPSSData.zip not found at {zip_path}\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        if zip_ref.testzip() is None:  # Check for ZIP file integrity\n",
        "            zip_ref.extractall(extract_dir)\n",
        "            print(f\"Extracted dataset files to: {extract_dir}\")\n",
        "        else:\n",
        "            print(\"Error: ZIP file integrity check failed. The file may not be a valid ZIP file.\")\n",
        "            raise zipfile.BadZipFile(\"ZIP file integrity check failed.\")\n",
        "\n",
        "except zipfile.BadZipFile as e:\n",
        "    print(f\"Error extracting ZIP file: {e}\")\n",
        "    print(\n",
        "        \"The uploaded file may not be a valid or complete ZIP file. \"\n",
        "        \"Please ensure you have uploaded the correct file, that it is not corrupted, \"\n",
        "        \"and that it is a standard ZIP archive.\"\n",
        "    )\n",
        "    raise  # Stop execution if extraction fails\n",
        "\n",
        "# --- Prepare NASA CMAPSS Data and Save to JSONL in GCS ---\n",
        "extract_dir = 'data/cmapss'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Process all four subsets\n",
        "data_subsets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
        "\n",
        "for data_subset in data_subsets:\n",
        "    train_file = os.path.join(extract_dir, f'train_{data_subset}.txt')\n",
        "    test_file = os.path.join(extract_dir, f'test_{data_subset}.txt')\n",
        "    rul_file = os.path.join(extract_dir, f'RUL_{data_subset}.txt')\n",
        "\n",
        "    SENSOR_COLUMNS = ['sensor' + str(i).zfill(2) for i in range(1, 22)]\n",
        "    OP_SETTING_COLUMNS = ['op_setting_' + str(i) for i in range(1, 4)]\n",
        "    DATA_COLUMNS = ['unit_nr', 'time_cycles'] + OP_SETTING_COLUMNS + SENSOR_COLUMNS\n",
        "\n",
        "    # Load training data\n",
        "    try:\n",
        "        train_df = pd.read_csv(train_file, names=DATA_COLUMNS, delim_whitespace=True, header=None)\n",
        "        test_df = pd.read_csv(test_file, names=DATA_COLUMNS, delim_whitespace=True, header=None)\n",
        "        rul_df = pd.read_csv(rul_file, names=['RUL'], delim_whitespace=True, header=None)\n",
        "\n",
        "        train_df.columns = DATA_COLUMNS\n",
        "        test_df.columns = DATA_COLUMNS\n",
        "\n",
        "        print(f\"\\nProcessing data subset: {data_subset}\")\n",
        "        print(\"Shape of train_df after loading:\", train_df.shape)\n",
        "        print(\"train_df head after loading:\\n\", train_df.head())\n",
        "        print(\"Shape of test_df:\", test_df.shape)\n",
        "        print(\"test_df head after loading:\\n\", test_df.head())\n",
        "        print(\"Shape of RUL data:\", rul_df.shape)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading data files for subset {data_subset}: {e}\")\n",
        "        raise  # Stop execution if a file is missing\n",
        "\n",
        "    def create_jsonl(df, rul_df, output_path, sequence_length=30, is_test=False):\n",
        "        grouped_data = df.groupby('unit_nr')\n",
        "        rul_values = rul_df.values.tolist()  # Convert RUL DataFrame to list\n",
        "        engine_count = 0  # To track which RUL value to use\n",
        "\n",
        "        with open(output_path, 'w') as f:\n",
        "            for unit_nr, unit_data in grouped_data:\n",
        "                num_cycles = len(unit_data)\n",
        "                data_values = unit_data.drop(['unit_nr'], axis=1).values.tolist()\n",
        "                json_data = []  # Initialize an empty list to hold JSON objects\n",
        "\n",
        "                for i in range(max(0, num_cycles - sequence_length + 1)):\n",
        "                    sequence = data_values[i:i + sequence_length]\n",
        "                    rul = num_cycles - (i + sequence_length)\n",
        "\n",
        "                    # Ensure RUL is not out of bounds\n",
        "                    if engine_count < len(rul_values):\n",
        "                        current_rul = rul_values[engine_count][0]  # Get the RUL value\n",
        "                    else:\n",
        "                        current_rul = 0  # Or some default value if RUL data is exhausted\n",
        "\n",
        "                    if len(sequence) == sequence_length:\n",
        "                        json_record = {\"sequence\": sequence, \"sequence_length\": len(sequence), \"rul\": current_rul}  # Include sequence length\n",
        "                        json_data.append(json_record)\n",
        "\n",
        "                # Write all JSON objects to the file at once\n",
        "                with open(output_path, 'w') as f:\n",
        "                    for json_record in json_data:\n",
        "                        f.write(json.dumps(json_record) + '\\n')\n",
        "\n",
        "                engine_count += 1  # Increment engine counter\n",
        "\n",
        "    local_train_jsonl_path = f\"cmapss_{data_subset}_train_sequences.jsonl\"\n",
        "    local_test_jsonl_path = f\"cmapss_{data_subset}_test_sequences.jsonl\"\n",
        "\n",
        "    # Create JSONL for training\n",
        "    create_jsonl(train_df, rul_df, local_train_jsonl_path, is_test=False)\n",
        "    print(f\"Created {local_train_jsonl_path}\")\n",
        "\n",
        "    # Create JSONL for testing\n",
        "    create_jsonl(test_df, rul_df, local_test_jsonl_path, is_test=True)\n",
        "    print(f\"Created {local_test_jsonl_path}\")\n",
        "\n",
        "!cp *.jsonl /content/gdrive/MyDrive/datasets/CMAPSSData/\n",
        "print(\"JSONL files created and uploaded.\")"
      ],
      "metadata": {
        "id": "smsD0LA2wvUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def create_textual_dataset(input_file, output_file):\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                sequence = data.get(\"sequence\")\n",
        "                rul = data.get(\"rul\") # Assuming your data has an RUL\n",
        "\n",
        "                if sequence:\n",
        "                    # Create a simple textual description (you can make this more sophisticated)\n",
        "                    description = f\"Engine sensor readings over time: {np.array(sequence).flatten().tolist()}\"\n",
        "                    if rul is not None:\n",
        "                        output_data = {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": description}]}, {\"role\": \"model\", \"parts\": [{\"text\": f\"Remaining Useful Life: {rul}\"}]}]}\n",
        "                        outfile.write(json.dumps(output_data) + '\\n')\n",
        "                    else:\n",
        "                        output_data = {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": description}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"RUL prediction needed.\"}]}]}\n",
        "                        outfile.write(json.dumps(output_data) + '\\n')\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Define your input and output file paths\n",
        "input_train_file = \"cmapss_FD004_train_sequences.jsonl\"\n",
        "output_train_file_text = \"cmapss_FD004_train_text.jsonl\"\n",
        "\n",
        "input_test_file = \"cmapss_FD004_test_sequences.jsonl\"\n",
        "output_test_file_text = \"cmapss_FD004_test_text.jsonl\"\n",
        "\n",
        "# Create the textual datasets\n",
        "create_textual_dataset(input_train_file, output_train_file_text)\n",
        "create_textual_dataset(input_test_file, output_test_file_text)\n",
        "\n",
        "print(f\"Textual training data created: {output_train_file_text}\")\n",
        "print(f\"Textual testing data created: {output_test_file_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ROyp9Omqt1",
        "outputId": "7ffb7ce0-80b8-4442-c1c8-0fa1d40db2c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textual training data created: cmapss_FD004_train_text.jsonl\n",
            "Textual testing data created: cmapss_FD004_test_text.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def transform_jsonl_to_prompt_completion(input_file_path, output_file_path):\n",
        "    \"\"\"Transforms chat-style JSONL to prompt-completion JSONL.\"\"\"\n",
        "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                # Extract prompt and completion from 'contents'\n",
        "                prompt = \"\".join([part[\"text\"] for part in data[\"contents\"][0][\"parts\"]])  # Assumes user role is first\n",
        "                completion = str(data.get(\"completion\", \"\")) # Handle if completion is missing\n",
        "\n",
        "                # Construct prompt-completion dictionary\n",
        "                prompt_completion_data = {\"prompt\": prompt, \"completion\": completion}\n",
        "\n",
        "                # Write to output file\n",
        "                outfile.write(json.dumps(prompt_completion_data) + \"\\n\")\n",
        "\n",
        "            except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
        "                print(f\"Skipping invalid or unprocessable line: {line.strip()}, Error: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "input_file_path = \"cmapss_FD004_train_text.jsonl\"\n",
        "output_file_path = \"cmapss_FD004_train_text_transformed.jsonl\"\n",
        "\n",
        "transform_jsonl_to_prompt_completion(input_file_path, output_file_path)\n",
        "print(f\"Transformed data written to: {output_file_path}\")\n",
        "\n",
        "input_file_path = \"cmapss_FD004_test_text.jsonl\"\n",
        "output_file_path = \"cmapss_FD004_test_text_transformed.jsonl\"\n",
        "\n",
        "transform_jsonl_to_prompt_completion(input_file_path, output_file_path)\n",
        "print(f\"Transformed data written to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aFALsICkXKb",
        "outputId": "741a7f35-4e6a-4679-9d63-d0089d1349ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data written to: cmapss_FD004_train_text_transformed.jsonl\n",
            "Transformed data written to: cmapss_FD004_test_text_transformed.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"contents\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Engine sensor readings over time: [1.0, 41.9993, 0.8409, 100.0, 445.0, 548.68, 1343.85, 1111.03, 3.91, 5.69, 137.26, 2211.96, 8296.96, ..., 8054.65, 9.2728, 0.02, 331.0, 2223.0, 100.0, 14.78, 8.8922]\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\n",
        "        {\n",
        "          \"text\": \"Remaining Useful Life: 0\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll_5xp9ZfpXg",
        "outputId": "4f18ffee-8f9c-40cf-9b4f-ba77849681fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contents': [{'role': 'user',\n",
              "   'parts': [{'text': 'Engine sensor readings over time: [1.0, 41.9993, 0.8409, 100.0, 445.0, 548.68, 1343.85, 1111.03, 3.91, 5.69, 137.26, 2211.96, 8296.96, ..., 8054.65, 9.2728, 0.02, 331.0, 2223.0, 100.0, 14.78, 8.8922]'}]},\n",
              "  {'role': 'model', 'parts': [{'text': 'Remaining Useful Life: 0'}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "whs9_Qwsq0kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# Set padding token if not present (common requirement for training)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Instead of using the unk_token, add a dedicated padding token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.resize_token_embeddings(len(tokenizer)) #Important: update the model's embedding layer to accommodate the new padding token.\n",
        "print(\"Model and tokenizer loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "ae9b0f5765954978a6b062fd38d53408",
            "924440afbe73481c9677a26b634d351b",
            "fd62d95cdbdc432ca6588d657cef52d2",
            "99998bd88dfa4352a1e90005f88fc453",
            "a99721aebf434117a9c7fc0075dd85bc",
            "3caafbf70f57401e97eed7516f880985",
            "d42537c40899464b9a998417ce5b7e5e",
            "3d64591015e14b458366ec883a52be4a",
            "6c5a55befb0c4776ae459ead89236b5b",
            "76ef7d219a0e4b2390e5183050e91dc8",
            "8b80d5193e6241698d89e121d0977b4f"
          ]
        },
        "id": "90P0CGcWCAe8",
        "outputId": "d39ce254-fce8-4080-c6b9-c9ee40dcd084"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae9b0f5765954978a6b062fd38d53408"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning"
      ],
      "metadata": {
        "id": "5e8SYqr9qN9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset # Example for loading data\n",
        "from trl import SFTTrainer # Simplified Fine-tuning Trainer\n",
        "from peft import LoraConfig # For LoRA efficient tuning\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import gc # Import the garbage collector\n",
        "\n",
        "\n",
        "# Ignore all future warnings\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "simplefilter(action='ignore', category=DeprecationWarning)\n",
        "simplefilter(action='ignore', category=UserWarning)\n",
        "simplefilter(action='ignore', category=RuntimeWarning)\n",
        "simplefilter(action='ignore', category=Warning)\n",
        "simplefilter(action='ignore', category=ResourceWarning)\n",
        "simplefilter(action='ignore')\n",
        "simplefilter(action='ignore', category=UnicodeWarning)\n",
        "\n",
        "# 1. --- Prepare your Dataset ---\n",
        "# Needs to be in a format the trainer understands (e.g., instruction/response pairs)\n",
        "# Example: Load a dataset from Hugging Face Hub\n",
        "# dataset = load_dataset(\"your_dataset_name\", split=\"train\")\n",
        "# Or create your own Dataset object\n",
        "# Formatted dataset usually has a 'text' column with structured prompts/responses\n",
        "print(\"Preparing dataset...\")\n",
        "\n",
        "\n",
        "#Load your datasets\n",
        "train_dataset = load_dataset(\"json\", data_files=\"/content/cmapss_FD004_train_text.jsonl\", split=\"train\")\n",
        "test_dataset = load_dataset(\"json\", data_files=\"/content/cmapss_FD004_test_text.jsonl\", split=\"train\") # Using 'train' split for test as well for simplicity\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Process each example individually within the batch\n",
        "    processed_examples = []  # Store processed examples here\n",
        "\n",
        "    for example in examples['contents']:\n",
        "        prompt = \"\".join([part[\"text\"] for part in example[0][\"parts\"]])\n",
        "        completion = \"\".join([part[\"text\"] for part in example[1][\"parts\"]])\n",
        "        #Combine the prompt and completion and then tokenize\n",
        "        inputs = tokenizer(prompt + completion, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "        # Extract RUL information from the completion instead of the prompt\n",
        "        # Assume the completion has the format \"Remaining Useful Life: {RUL}\"\n",
        "        try:\n",
        "            rul = int(completion.split(\"Remaining Useful Life: \")[-1])\n",
        "        except ValueError:\n",
        "            # If the completion format is incorrect or RUL is missing, set rul to 0\n",
        "            rul = 0\n",
        "\n",
        "        #Add the RUL to the inputs to be passed to the model\n",
        "        inputs['labels'] = inputs['input_ids'].clone()\n",
        "        inputs['rul'] = rul\n",
        "\n",
        "        processed_examples.append(inputs)  # Append the dictionary\n",
        "\n",
        "    # Stack tensors to get correct dimensions\n",
        "    input_ids = torch.stack([d['input_ids'] for d in processed_examples]).squeeze(1)\n",
        "    labels = torch.stack([d['labels'] for d in processed_examples]).squeeze(1)\n",
        "    ruls = torch.tensor([d['rul'] for d in processed_examples])\n",
        "\n",
        "    return {'input_ids': input_ids, 'labels': labels, 'rul': ruls}  # Return the final dictionary\n",
        "# Apply preprocessing\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# 2. --- Configure LoRA (Optional but recommended for efficiency) ---\n",
        "lora_config = LoraConfig(\n",
        "     r=16, # Rank\n",
        "     lora_alpha=32,\n",
        "     target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], # Adapt these layers\n",
        "     lora_dropout=0.05,\n",
        "     bias=\"none\",\n",
        "     task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# 3. --- Define Training Arguments ---\n",
        "output_dir = \"./llama3-8b-finetuned\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=5,            # Adjust as needed\n",
        "    per_device_train_batch_size=1, # Adjust based on your GPU memory\n",
        "    gradient_accumulation_steps=8, # Increased gradient accumulation steps\n",
        "    gradient_checkpointing=True,   # Enabled gradient checkpointing\n",
        "    learning_rate=2e-4,            # Adjust as needed\n",
        "    max_grad_norm=0.3,             # Gradient clipping\n",
        "    weight_decay= 0.01,           # Regularization\n",
        "    logging_steps=10,\n",
        "    optim=\"paged_adamw_8bit\",      # Optimizer for quantized models\n",
        "    save_strategy=\"steps\",\n",
        "    eval_strategy=\"steps\",  # Evaluate at specified intervals\n",
        "    eval_steps=10,             # Evaluate every 100 steps (adjust as needed)\n",
        "    #eval_strategy=\"no\",  # Disable evaluation during training to save memory\n",
        "    load_best_model_at_end=True,  # Load the best model based on validation\n",
        "    metric_for_best_model=\"loss\",  # Metric to use for selecting the best model\n",
        "    report_to=\"none\",\n",
        "    # Add more arguments as needed (fp16, etc.)\n",
        ")\n",
        "\n",
        "# 4. --- Create the Trainer ---\n",
        "# Using SFTTrainer for supervised fine-tuning on conversational/instruction data\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,  # Pass LoRA config if using PEFT/LoRA\n",
        "    train_dataset=train_dataset, # Your formatted training dataset\n",
        "    eval_dataset=test_dataset,   # Your formatted testing dataset (for evaluation)\n",
        ")\n",
        "\n",
        "# 5. --- Run Fine-Tuning ---\n",
        "print(\"Starting fine-tuning...\")\n",
        "# This is the core training step\n",
        "trainer.train()\n",
        "print(\"Fine-tuning finished (Conceptual - train() call commented out).\")\n",
        "\n",
        "# Delete unused variables to free up memory\n",
        "del train_dataset, test_dataset\n",
        "gc.collect()  # Run garbage collection\n",
        "\n",
        "\n",
        "# 6. --- Save the Fine-Tuned Model (Adapter or Full Model) ---\n",
        "print(f\"Saving fine-tuned model to {output_dir}...\")\n",
        "# trainer.save_model(output_dir) # Saves adapter config (if LoRA) & weights\n",
        "# Alternatively, if not using LoRA or want to merge weights:\n",
        "# merged_model = model.merge_and_unload() # Merge LoRA weights back if needed\n",
        "# merged_model.save_pretrained(output_dir)\n",
        "# tokenizer.save_pretrained(output_dir)\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "id": "0bLhaqiYcbih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "594a44d8fdd2415c80a746f38936bd0e",
            "e93a89a63c4743f0808c94f219079272",
            "ff3dbc5df9974cd684915febdfdc3b58",
            "d65ba4a837774de1af4aac0f2531331e",
            "f583195a8e65431da039d3433faa8ee8",
            "4169353b95ac4b47a54f0aa20dd5329e",
            "bdbcb5b587e34a88983affaffa190fb3",
            "d2ec4f4305e34e7db0034227ba2e6d44",
            "111810ce974e404f96efb0193831ec9c",
            "00f43a9e46db4dcd83ff7ea827352ff5",
            "3d1f7cd462bd4ff1b921c974cae51b47",
            "157a481b5b1f4dfbb62db8ef429e7515",
            "2a45b195042d44e89a1ab7c840f1f4d5",
            "86fd4d6d83084837b05b349c99319034",
            "dfbce4e8f389499f88699f5bb0a1b84b",
            "ca1778e89b1a43a1acda0a55ef2eba76",
            "1b1d7ba099434d8e90d5ea841b52b52b",
            "e407a2794c93457d80fd38b2d4c2883c",
            "531ae9326a6a403db64ef3f91d3bd335",
            "b4986c49cfaf4b9ea11280794fec44de",
            "28f7cdd255804fda9e8504636c89624e",
            "653f10b07e03405f8c1cdc7444da68f0"
          ]
        },
        "outputId": "47b6795a-4032-4ad6-8d8b-0333779ccf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/226 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "594a44d8fdd2415c80a746f38936bd0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/226 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "157a481b5b1f4dfbb62db8ef429e7515"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='118' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [118/140 23:34 < 04:28, 0.08 it/s, Epoch 4.04/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.381800</td>\n",
              "      <td>1.102609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.971200</td>\n",
              "      <td>0.859953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.764000</td>\n",
              "      <td>0.745592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.646400</td>\n",
              "      <td>0.663999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.585800</td>\n",
              "      <td>0.605856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.534700</td>\n",
              "      <td>0.602145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.562346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.480100</td>\n",
              "      <td>0.543710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.467600</td>\n",
              "      <td>0.557971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.459100</td>\n",
              "      <td>0.546403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.451300</td>\n",
              "      <td>0.550110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "LV6GXgaCx1DU"
      }
    },
    {
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset = load_dataset(\"json\", data_files=\"/content/cmapss_FD004_test_text.jsonl\", split=\"train\")\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get actual RUL values\n",
        "actual_rul = test_dataset['rul']\n",
        "\n",
        "# Get predicted RUL values (logits for the last token)\n",
        "predicted_rul = predictions.predictions[0][:, -1]\n",
        "predicted_rul = predicted_rul[:len(actual_rul)]  # Truncate to match actual RUL length\n",
        "\n",
        "# Get predicted token IDs using argmax\n",
        "predicted_token_ids = np.argmax(predictions.predictions[0], axis=-1)\n",
        "\n",
        "# Extract the last token ID as the predicted RUL\n",
        "#predicted_rul_decoded = [seq[-1] for seq in predicted_token_ids]  # Removed this line\n",
        "predicted_rul_decoded = predicted_token_ids[-1]  # Get the last element\n",
        "\n",
        "# Decode the predicted token ID to get the RUL value as a string\n",
        "predicted_rul_decoded = tokenizer.decode(predicted_rul_decoded, skip_special_tokens=True)\n",
        "\n",
        "# Convert the decoded RUL string to an integer\n",
        "try:\n",
        "    predicted_rul_decoded = int(predicted_rul_decoded)\n",
        "except ValueError:\n",
        "    # Handle cases where the decoded string is not a valid integer (e.g., empty string)\n",
        "    predicted_rul_decoded = 0  # Or any other default value you prefer\n",
        "\n",
        "# Duplicate the single predicted RUL to match the length of actual RUL\n",
        "predicted_rul_decoded = [predicted_rul_decoded] * len(actual_rul) # Modified this line to to fill predicted_rul_decoded using predicted_rul\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(actual_rul, predicted_rul_decoded)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(actual_rul, predicted_rul_decoded)\n",
        "\n",
        "print(f\"MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mfppeSSLpAKM",
        "outputId": "0569b054-1ca3-46d5-a15c-0d352d648b9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 676.0, RMSE: 26.0, R2: 0.0\n"
          ]
        }
      ]
    }
  ]
}