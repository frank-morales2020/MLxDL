{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_Mistral_7b_hfdeployment_dataset_McGill_NLP_medal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw_Oj0C8H2tJ"
      },
      "source": [
        "https://www.datacamp.com/tutorial/mistral-7b-tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPAPb3JdCIan"
      },
      "source": [
        "# DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "#!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "#!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install ninja packaging --quiet\n",
        "\n",
        "\n",
        "# Uncomment only if you're using A100 GPU or L4 GPU\n",
        "!pip install flash-attn --no-build-isolation\n",
        "\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI7mHbyTQWT7"
      },
      "outputs": [],
      "source": [
        "# versions: 0.0.1, 0.0.2, 0.0.3, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.4.7, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.8.5, 0.8.6, 0.9.2, 0.9.3, 0.9.4)\n",
        "#ERROR: No matching distribution found for trl==0.0.99\n",
        "! pip install trl==0.8.6 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65JpttRiGxVK"
      },
      "outputs": [],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6usdVgDF50fO",
        "outputId": "66c1eff8-c999-44e1-a552-ab12f86d18ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env"
      ],
      "metadata": {
        "id": "Tcyagz5p1IQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorboard\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "outputs": [],
      "source": [
        "# set device\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtE9TuSMlUEc",
        "outputId": "7030c664-80bb-409a-c825-9f667b607a4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY6iadKNl1Af"
      },
      "outputs": [],
      "source": [
        "#!apt-get update && apt-get install -y cuda-11-0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapRov3hl4fT",
        "outputId": "3712463f-a3df-414e-fa3b-9c4dc6b168e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Sun Jun 16 02:16:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              43W / 400W |      5MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7fKxR2rnbJ",
        "outputId": "dfd5eecf-48db-4dbd-f391-06646bc7861c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': '<prompt text>', 'completion': '<ideal generated text>'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "### conversational format\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "\n",
        "### instruction format\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPAxhdxMAdBS"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue5Leyc90T6d"
      },
      "source": [
        "\n",
        "https://huggingface.co/datasets/sakharamg/AviationQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOTw6tjZKupR"
      },
      "outputs": [],
      "source": [
        "#! pip install datasets  --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY55Lb9ixyCH"
      },
      "outputs": [],
      "source": [
        "#from datasets import load_dataset\n",
        "#print(\"Preprocessing dataset Emotion\")\n",
        "#dataset = load_dataset(\"McGill-NLP/medal\",trust_remote_code=True)\n",
        "\n",
        "#%mkdir -p /content/gdrive/MyDrive/datasets/McGill-NLP\n",
        "#%cd /content/gdrive/MyDrive/datasets/McGill-NLP\n",
        "\n",
        "# save datasets to disk\n",
        "#dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
        "#dataset[\"validation\"].to_json(\"validation_dataset.json\", orient=\"records\")\n",
        "#dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP4XSSClx2IX"
      },
      "outputs": [],
      "source": [
        "#print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SInSDc3Xx6w-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "de28fd81538e411eb0208d1460fc4ad2",
            "4a53afed21b141b1acd612fc01058538",
            "169925f2e90c469a9d62aa534ce2a769",
            "6f0d14d0896846c69f05e779d0dd4fb3",
            "2ca364fd1d6b464ebe8afcdf52b1aa2c",
            "df78daa3db864491afcfe4f25c0c88aa",
            "ac72f76235ef40be9e17fd180e6608ad",
            "3af25520125049d095428fa431c0f7e0",
            "9c810766e4774c18b1ca20955aeae2de",
            "7c5e5d55428f4da88d6849c0e304adc2",
            "46256b436b554052bb6f86a54c567ca2"
          ]
        },
        "outputId": "eddf1f74-5ec8-48d3-ea95-7586d65cb96b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de28fd81538e411eb0208d1460fc4ad2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/train_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9c4RuZCx_gn",
        "outputId": "b79914dd-bab7-468e-c74d-5a991f65a352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['abstract_id', 'text', 'location', 'label'],\n",
            "    num_rows: 3000000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGsXCucUZ7ZF",
        "outputId": "78d62953-e96b-412e-f45e-01be69d60c37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'abstract_id': 14445409, 'text': 'to quantify the amount of CL NO harvested in modified RND', 'location': [10], 'label': ['radical neck dissection']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[6]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OiChSLsd74w",
        "outputId": "b5603858-b5a0-49ff-c19d-956bf360ffdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to quantify the amount of CL NO harvested in modified RND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[6]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQOYaIYCeDSb",
        "outputId": "c88bc836-e17a-44b8-9580-bebeaf75578e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['radical neck dissection']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t3C7lGBlFXog"
      },
      "outputs": [],
      "source": [
        "train_question=dataset['text']\n",
        "train_answer=dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WLgn-AwEDuKD"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/medal-qa.txt\n",
        "filename='/content/medal-qa.txt'\n",
        "\n",
        "import re\n",
        "\n",
        "# python object to be appended\n",
        "for n in range(10000):\n",
        "    if train_answer[n] == None:\n",
        "       train_answer[n] = 'Not possible to get or use'\n",
        "    string = train_answer[n]\n",
        "    #print(string)\n",
        "    #result = string.replace(\"\\nRef\", \"-Ref\")\n",
        "    str_question=train_question[n]\n",
        "    question= re.sub(\"\\n\", \"\", str_question)\n",
        "    answer = re.sub(\"\\[\", \"\", str(string))\n",
        "    answer = re.sub(\"\\]\", \"\", str(answer))\n",
        "\n",
        "    #print(answer)\n",
        "    if len(answer)==0:\n",
        "        answer='Not possible to get or use'\n",
        "    text='<s>[INST] %s [/INST] %s </s>'%(question,answer)\n",
        "    #print(text)\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z-UPeSK06Gf-",
        "outputId": "9c96bdfe-c2ec-41b5-81f6-e16fca6cbe53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to quantify the amount of CL NO harvested in modified RND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_question[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5AZ0Iy44QkB",
        "outputId": "123ffc80-d171-4b50-eccd-09ade27d0caf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['radical neck dissection']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_answer[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "df8fd9af31634950afce57016abf4256",
            "c1085faf11b840c78ef1d82ee2158cc1",
            "8ac2ff8502c24231a23d74d253aa1bb2",
            "10379540a5fa48148cda9debf408c06d",
            "b946154f2a7c42389a24f73e58c65f37",
            "101303689eea456abc791b3558bb76a7",
            "124ebb9e01af4a45a8add32d91c01b83",
            "b42b5e0f55264a67a0fd71333ac13ba3",
            "e6238f4d4ff64a47aabff934ef3022ac",
            "8721385760f942cba39ff2ca2c8bc288",
            "d3474876661e43d3b781ea99d9edf2e6"
          ]
        },
        "id": "j4AtoIrsD0k0",
        "outputId": "6bc64372-4da2-48e2-834c-545b1d63918f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df8fd9af31634950afce57016abf4256"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "text0 = load_dataset(\"text\", data_files=\"/content/medal-qa.txt\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "50KFalQfEDkI"
      },
      "outputs": [],
      "source": [
        "nrec=10000\n",
        "\n",
        "dataset_final_Question=dataset['text'][0:nrec]\n",
        "dataset_final_Answer=dataset['label'][0:nrec]\n",
        "dataset_final_text=text0[0:nrec]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35LRbDnvyGAP",
        "outputId": "c8375e01-ae51-4c05-e845-dff1025b3c10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abstract_id': 14445409,\n",
              " 'text': 'to quantify the amount of CL NO harvested in modified RND',\n",
              " 'location': [10],\n",
              " 'label': ['radical neck dissection']}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "dataset[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5I71acOCRtt",
        "outputId": "5a378591-a34b-41b1-ee4c-a5f44412abac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] 'radical neck dissection' </s>\"}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "text0[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "07nkZ2Pu3va9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer\n",
        "datasetF['text'] = dataset_final_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B24h4n-E3fkg",
        "outputId": "549d2fd9-a600-4342-92eb-aaa9abbe3404"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "0     velvet antlers vas are commonly used in tradit...   \n",
              "1     the clinical features of our cases demonstrate...   \n",
              "2     ceftobiprole bpr is an investigational cephalo...   \n",
              "3     we have taken a basic biologic RPA to elucidat...   \n",
              "4     lipoperoxidationderived aldehydes for example ...   \n",
              "...                                                 ...   \n",
              "9995  the regulation of the number of extrajunctiona...   \n",
              "9996  a highresolution structure of the HPr hpr from...   \n",
              "9997  the short term metabolic effects of the in viv...   \n",
              "9998  we examined the effect of nnntrimethylsphingos...   \n",
              "9999  estrogenhydroxylase eh activity was measured b...   \n",
              "\n",
              "                                            Answer  \\\n",
              "0                 [transverse aortic constriction]   \n",
              "1                              [hodgkins lymphoma]   \n",
              "2                [methicillinsusceptible s aureus]   \n",
              "3             [parathyroid hormonerelated protein]   \n",
              "4                               [lipoperoxidation]   \n",
              "...                                            ...   \n",
              "9995                            [intracellular cl]   \n",
              "9996  [histidinecontaining phosphocarrier protein]   \n",
              "9997                [hexose monophosphate pathway]   \n",
              "9998                       [nndimethylsphingosine]   \n",
              "9999                             [medial preoptic]   \n",
              "\n",
              "                                                   text  \n",
              "0     <s>[INST] velvet antlers vas are commonly used...  \n",
              "1     <s>[INST] the clinical features of our cases d...  \n",
              "2     <s>[INST] ceftobiprole bpr is an investigation...  \n",
              "3     <s>[INST] we have taken a basic biologic RPA t...  \n",
              "4     <s>[INST] lipoperoxidationderived aldehydes fo...  \n",
              "...                                                 ...  \n",
              "9995  <s>[INST] the regulation of the number of extr...  \n",
              "9996  <s>[INST] a highresolution structure of the HP...  \n",
              "9997  <s>[INST] the short term metabolic effects of ...  \n",
              "9998  <s>[INST] we examined the effect of nnntrimeth...  \n",
              "9999  <s>[INST] estrogenhydroxylase eh activity was ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4506a0f0-e388-487c-b359-26c45da680f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
              "      <td>[transverse aortic constriction]</td>\n",
              "      <td>&lt;s&gt;[INST] velvet antlers vas are commonly used...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the clinical features of our cases demonstrate...</td>\n",
              "      <td>[hodgkins lymphoma]</td>\n",
              "      <td>&lt;s&gt;[INST] the clinical features of our cases d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
              "      <td>[methicillinsusceptible s aureus]</td>\n",
              "      <td>&lt;s&gt;[INST] ceftobiprole bpr is an investigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
              "      <td>[parathyroid hormonerelated protein]</td>\n",
              "      <td>&lt;s&gt;[INST] we have taken a basic biologic RPA t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lipoperoxidationderived aldehydes for example ...</td>\n",
              "      <td>[lipoperoxidation]</td>\n",
              "      <td>&lt;s&gt;[INST] lipoperoxidationderived aldehydes fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>the regulation of the number of extrajunctiona...</td>\n",
              "      <td>[intracellular cl]</td>\n",
              "      <td>&lt;s&gt;[INST] the regulation of the number of extr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>a highresolution structure of the HPr hpr from...</td>\n",
              "      <td>[histidinecontaining phosphocarrier protein]</td>\n",
              "      <td>&lt;s&gt;[INST] a highresolution structure of the HP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>the short term metabolic effects of the in viv...</td>\n",
              "      <td>[hexose monophosphate pathway]</td>\n",
              "      <td>&lt;s&gt;[INST] the short term metabolic effects of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>we examined the effect of nnntrimethylsphingos...</td>\n",
              "      <td>[nndimethylsphingosine]</td>\n",
              "      <td>&lt;s&gt;[INST] we examined the effect of nnntrimeth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>estrogenhydroxylase eh activity was measured b...</td>\n",
              "      <td>[medial preoptic]</td>\n",
              "      <td>&lt;s&gt;[INST] estrogenhydroxylase eh activity was ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4506a0f0-e388-487c-b359-26c45da680f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4506a0f0-e388-487c-b359-26c45da680f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4506a0f0-e388-487c-b359-26c45da680f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72cda6bb-fcc0-4ea6-a91d-9a0b9691f20a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72cda6bb-fcc0-4ea6-a91d-9a0b9691f20a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72cda6bb-fcc0-4ea6-a91d-9a0b9691f20a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f0fdd8e4-cd6f-4638-ad65-d7e27fda63f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0fdd8e4-cd6f-4638-ad65-d7e27fda63f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9993,\n        \"samples\": [\n          \"the medicinal plant WS has been used for over centuries in indian ayurvedic medicine to treat a wide spectrum of disorders withaferin a wa a bioactive compound that is isolated from this plant has antiinflammatory immunomodulatory antiangiogenic and anticancer properties here we investigated MPM mpm suppressive effects of wa and the molecular mechanisms involved wa inhibited growth of the mu as well as patientderived mpm cells in part by decreasing the chymotryptic activity of the proteasome that resulted in increased levels of ubiquitinated proteins and proapoptotic proteasome target proteins p bax i\\u00ce\\u00bab\\u00ce\\u00b1 wa suppression of mpm growth also involved elevated apoptosis as evidenced by activation of proapoptotic p AS G1 protein kinase sapk and caspase elevated C2 of proapoptotic bax protein and PARP parp our studies including genearray based analyses further revealed that wa suppressed a number of cell growth and metastasispromoting genes including cmyc wa treatments also stimulated expression of the cell cycle and apoptosis RII protein carpccar a novel transducer of cell growth signaling knockdown of carp on the other hand interfered with mpm growth GABA effects of wa intraperitoneal administration of mgkg wa daily inhibited growth of mu mpm cellderived tumors in vivo in part by inhibiting proteasome activity and stimulating apoptosis together our in vitro and in vivo studies suggest that wa suppresses mpm growth by targeting multiple pathways that include blockage of proteasome activity and stimulation of apoptosis and thus holds promise as an antimpm agent\",\n          \"management of a spontaneous single duct PND without associated mass and normal mammography remains controversial our T0 examined the pathological results of women of all ages treated with microdochectomy for single duct PND malignant or premalignant lesions were identified in patient under years of age and patients over years papilloma was the most frequently identified pathology in both age CG of patients under years and over or equal to years of age our results suggest that microdochectomy is a safe ERP treatment in women aged over years\",\n          \"evidencebased recommendations on the clinical use of cardiopulmonary ET cpet in lung and HR disease are presented with reference to the assessment of exercise intolerance prognostic assessment and the DUE of therapeutic interventions eg drugs supplemental oxygen exercise training a commonly used MGS for recommendations in evidencebased guidelines was applied with the grade of recommendation ranging from a the highest to d the lowest for symptomlimited incremental exercise cpet indices such as peak VO2 vo vo at LT the slope of the ventilationco output relationship and the presence of arterial o desaturation have all been shown to have SP in prognostic evaluation in addition for assessment of interventions the tolerable duration of symptomlimited highintensity constantload exercise often provides greater sensitivity to discriminate change than the CP incremental test fieldtesting paradigms eg timed and shuttle walking tests also prove valuable in turn these considerations allow the resolution of practical questions that often confront the clinician such as when should an DUE of exercise intolerance be sought which particular form of test should be asked for and what cluster of variables should be selected when evaluating prognosis for a particular disease or the effect of a particular intervention\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9996,\n        \"samples\": [\n          \"<s>[INST] spherical nanocrystal of AP has been proved to be beneficial for osteoblast growth two apatites with spherical nanocrystal morphology were prepared in this study by chemical wet method and further sintering process sem exhibited that both apatites had spherical nanocrystal morphology the crystal morphology and size was approaching to each other xrd showed the apatites separately were hydroxyapatite and tricalcium phosphate phases the cellular biocompatibility was evaluated by OBs for these two spherical nanocrstal apatites the mtt result indicated a higher cell proliferation rate for spherical TCP group the alp activity CA also strongly favored the TCP group rtpcr results indicated that collagen i had a higher transcription level on the spherical tricalcium phosphate group sem results showed robust cell growth on the materials it was concluded that the spherical nanophase TCP was superior to the cellular biocompatibility of spherical nanophase hydroxyapatite and the results were helpful in the manufacture of more suitable TE scaffolds [/INST] 'tricalcium phosphate' </s>\",\n          \"<s>[INST] local cbf lcbf was determined in the same rat model and at the same intervals of TD and reversal as in previous studies of local CBF gl utilization lcgu and ph lcph the results showed that prior to the appearance of the clinical sequelae of B1 deficiency opisthotonus which usually occurs on day of deficiency CBF structures such as the mammillary body VN inferior colliculus and TH showed significant hyperperfusion reaching greater than of control values at opisthotonus there was a general decline in lcbf but in addition the larger of these structures developed inhomogeneous perfusion with patches of hyperperfusion adjacent to others of LF seven days of thiamine replenishment at opisthotonus resulted in delayed hypoperfusion notably in the mammillary body IC and thalamic nuclei superimposition of the lcbf lcgu and lcph data reveals that structures known to be vulnerable to the development of histological lesions in this model showed an EP of hyperperfusion uncoupled from declining lcgu and normal lcph then following a significant but only focal rise in lcgu between days and of deficiency hyperperfusion persisted while the ph was dropping and lcgu was rapidly declining the phase of patchy perfusion occurred only in the histologically vulnerable structures when lcgu was very low and acidosis was at its peak suggesting that it may have resulted from these opposing influences on lcbf following replenishment with thiamine the vulnerable structures showed delayed hypoperfusion coupled to lcguabstract truncated at words [/INST] 'inferior colliculus' </s>\",\n          \"<s>[INST] thirteen antimicrobial agents and betalactamase inhibitor combinations were tested simultaneously for their invitro activity against a range of anaerobic gramnegative bacilli with a standard REF agar dilution method overall metronidazole imipenem ampicillinsulbactam ticarcillinclavulanic acid and cefoperazonesulbactam followed by CLI cefoxitin and piperacillin had the greatest activity cefotetan ceftizoxime and CPZ were moderately active while ampicillin and penicillin were least active metronidazole was the only drug active against all strains but only one CS was resistant to imipenem resistance was highest among certain members of the bacteroides fragilis group but was observed also among numerous other bacteroides species betalactamase was produced by of strains in the b fragilis group and by of strains overall the activities of CLI and cefoxitin were compared with those in previous surveys since at our institution no clear evidence of increasing resistance was demonstrated but the data emphasized the significant effects resulting from variations in susceptibility testing [/INST] 'cefoperazone' </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bJIEeujGvocn",
        "outputId": "33621561-4199-4fab-eaa0-43e95db28c3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to quantify the amount of CL NO harvested in modified RND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "datasetF['Question'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viWQFo-pNq5D",
        "outputId": "9c9a960d-c4c6-4988-ad26-2c4f4837f525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['radical neck dissection']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "datasetF['Answer'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "CNGf8BmXEZnF",
        "outputId": "22c5c7e3-5c06-4b3d-b2e2-235e44071129"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] 'radical neck dissection' </s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "datasetF['text'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npGef0PAwBkJ"
      },
      "outputs": [],
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G756UDF1k3hp",
        "outputId": "5d15fa54-9863-442f-9bd9-345e425829ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            83Gi         9Gi       2.1Gi        13Mi        71Gi        72Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "!free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuHodNjdAol6"
      },
      "source": [
        "# Loading the Mistral 7B model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTaNFDF9TedV"
      },
      "outputs": [],
      "source": [
        "!pip install mistral_inference -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r88iXxFboqw_"
      },
      "outputs": [],
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes -q\n",
        "!pip install accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4d9d1075df594d39a80244a832ee1853",
            "eca32718d716491eb9ea5c47bf7d7a8b",
            "baa15d53748546229a6b03acd98fce7f",
            "a9c6768940a24de1b5a8d280f4114485",
            "b6e93d438f7a4572a63160299f19b168",
            "0f527ce42011441b95efbcc2183b8215",
            "3b77f00f7433485fa322ee7c81b2fda7",
            "cd1c9bd455314e5283b59b123a275b20",
            "2c6ac89be1c346568c554ae45af95dcf",
            "2d748c11b3b94d238071d66d562d1b22",
            "027ff7744f464cd78d60dd90bdf6573e"
          ]
        },
        "id": "lQm2yo0uslTs",
        "outputId": "398e7aaf-c320-4fee-b15e-7fe73bce1bb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d9d1075df594d39a80244a832ee1853"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\" #10 june 2024,\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    is_decoder=True,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "#model, tokenizer = setup_chat_format(model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqToGYwPagxY",
        "outputId": "448014f3-e52c-42c6-80c7-66212c177376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralFlashAttention2(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfFTlpqJFOdf"
      },
      "source": [
        "Inference\n",
        "\n",
        "Build an inference pipeline with tokenizer and the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHUtHvtzMlYB"
      },
      "outputs": [],
      "source": [
        "# load into pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ5nnw6tMsVF",
        "outputId": "77d2e0cb-d1e5-40fa-9b74-d94479bd9162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the capital of russia?\n",
            "\n",
            "Generated Answer:\n",
            "Moscow\n"
          ]
        }
      ],
      "source": [
        "#prompt=\"What was the first album BeyoncÃ© released as a solo artist?\"\n",
        "prompt0=\"What is the capital of russia?\"\n",
        "#prompt=\"What are some interesting sites to visit in the Bay Area?\"\n",
        "\n",
        "prompt = f\"Instruct: Find THE answer for the following  question.\\n{prompt0}\\nOutput:\\n\"\n",
        "#prompt = f\"Instruct: Find only the answer for the following  question.\\n{prompt0}\"\n",
        "\n",
        "#prompt=\"What are some interesting sites to visit in the Bay Area?\"\n",
        "#prompt=\"What is the capital of russia?\"\n",
        "outputs = pipe(prompt0, max_new_tokens=128, temperature=0.9,do_sample=True,top_k=30, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.eos_token_id)\n",
        "\n",
        "print('Question: %s'%prompt0)\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt0):].strip()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJOKD2w5QSWz",
        "outputId": "988f80ae-ee3f-4b34-9aa8-2f42a4d28da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the capital of russia?\n",
            "Moscow\n"
          ]
        }
      ],
      "source": [
        "print(outputs[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUFk-I1pugxc"
      },
      "outputs": [],
      "source": [
        "eval_tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
        "eval_tokenizer.pad_token = eval_tokenizer.eos_token\n",
        "\n",
        "def gen(model,p, maxlen=1024, sample=True):\n",
        "    toks = eval_tokenizer(p, return_tensors=\"pt\")\n",
        "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample,num_return_sequences=1,temperature=0.9,num_beams=1,top_p=0.95,).to('cuda')\n",
        "    return eval_tokenizer.batch_decode(res,skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "zP_FQeY4vq1s",
        "outputId": "2deaca59-9f02-408e-a2f8-3ac500da5829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "0     velvet antlers vas are commonly used in tradit...   \n",
              "1     the clinical features of our cases demonstrate...   \n",
              "2     ceftobiprole bpr is an investigational cephalo...   \n",
              "3     we have taken a basic biologic RPA to elucidat...   \n",
              "4     lipoperoxidationderived aldehydes for example ...   \n",
              "...                                                 ...   \n",
              "9995  the regulation of the number of extrajunctiona...   \n",
              "9996  a highresolution structure of the HPr hpr from...   \n",
              "9997  the short term metabolic effects of the in viv...   \n",
              "9998  we examined the effect of nnntrimethylsphingos...   \n",
              "9999  estrogenhydroxylase eh activity was measured b...   \n",
              "\n",
              "                                            Answer  \\\n",
              "0                 [transverse aortic constriction]   \n",
              "1                              [hodgkins lymphoma]   \n",
              "2                [methicillinsusceptible s aureus]   \n",
              "3             [parathyroid hormonerelated protein]   \n",
              "4                               [lipoperoxidation]   \n",
              "...                                            ...   \n",
              "9995                            [intracellular cl]   \n",
              "9996  [histidinecontaining phosphocarrier protein]   \n",
              "9997                [hexose monophosphate pathway]   \n",
              "9998                       [nndimethylsphingosine]   \n",
              "9999                             [medial preoptic]   \n",
              "\n",
              "                                                   text  \n",
              "0     <s>[INST] velvet antlers vas are commonly used...  \n",
              "1     <s>[INST] the clinical features of our cases d...  \n",
              "2     <s>[INST] ceftobiprole bpr is an investigation...  \n",
              "3     <s>[INST] we have taken a basic biologic RPA t...  \n",
              "4     <s>[INST] lipoperoxidationderived aldehydes fo...  \n",
              "...                                                 ...  \n",
              "9995  <s>[INST] the regulation of the number of extr...  \n",
              "9996  <s>[INST] a highresolution structure of the HP...  \n",
              "9997  <s>[INST] the short term metabolic effects of ...  \n",
              "9998  <s>[INST] we examined the effect of nnntrimeth...  \n",
              "9999  <s>[INST] estrogenhydroxylase eh activity was ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-495f32d5-bff1-4e01-92b7-3c72cbecea36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
              "      <td>[transverse aortic constriction]</td>\n",
              "      <td>&lt;s&gt;[INST] velvet antlers vas are commonly used...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the clinical features of our cases demonstrate...</td>\n",
              "      <td>[hodgkins lymphoma]</td>\n",
              "      <td>&lt;s&gt;[INST] the clinical features of our cases d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
              "      <td>[methicillinsusceptible s aureus]</td>\n",
              "      <td>&lt;s&gt;[INST] ceftobiprole bpr is an investigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
              "      <td>[parathyroid hormonerelated protein]</td>\n",
              "      <td>&lt;s&gt;[INST] we have taken a basic biologic RPA t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lipoperoxidationderived aldehydes for example ...</td>\n",
              "      <td>[lipoperoxidation]</td>\n",
              "      <td>&lt;s&gt;[INST] lipoperoxidationderived aldehydes fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>the regulation of the number of extrajunctiona...</td>\n",
              "      <td>[intracellular cl]</td>\n",
              "      <td>&lt;s&gt;[INST] the regulation of the number of extr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>a highresolution structure of the HPr hpr from...</td>\n",
              "      <td>[histidinecontaining phosphocarrier protein]</td>\n",
              "      <td>&lt;s&gt;[INST] a highresolution structure of the HP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>the short term metabolic effects of the in viv...</td>\n",
              "      <td>[hexose monophosphate pathway]</td>\n",
              "      <td>&lt;s&gt;[INST] the short term metabolic effects of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>we examined the effect of nnntrimethylsphingos...</td>\n",
              "      <td>[nndimethylsphingosine]</td>\n",
              "      <td>&lt;s&gt;[INST] we examined the effect of nnntrimeth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>estrogenhydroxylase eh activity was measured b...</td>\n",
              "      <td>[medial preoptic]</td>\n",
              "      <td>&lt;s&gt;[INST] estrogenhydroxylase eh activity was ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-495f32d5-bff1-4e01-92b7-3c72cbecea36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-495f32d5-bff1-4e01-92b7-3c72cbecea36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-495f32d5-bff1-4e01-92b7-3c72cbecea36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e9f05ef-ef27-49e2-b308-958d50ca1fa0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e9f05ef-ef27-49e2-b308-958d50ca1fa0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e9f05ef-ef27-49e2-b308-958d50ca1fa0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6af58688-8b05-4c64-8c4f-c24c3a905999\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6af58688-8b05-4c64-8c4f-c24c3a905999 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9993,\n        \"samples\": [\n          \"the medicinal plant WS has been used for over centuries in indian ayurvedic medicine to treat a wide spectrum of disorders withaferin a wa a bioactive compound that is isolated from this plant has antiinflammatory immunomodulatory antiangiogenic and anticancer properties here we investigated MPM mpm suppressive effects of wa and the molecular mechanisms involved wa inhibited growth of the mu as well as patientderived mpm cells in part by decreasing the chymotryptic activity of the proteasome that resulted in increased levels of ubiquitinated proteins and proapoptotic proteasome target proteins p bax i\\u00ce\\u00bab\\u00ce\\u00b1 wa suppression of mpm growth also involved elevated apoptosis as evidenced by activation of proapoptotic p AS G1 protein kinase sapk and caspase elevated C2 of proapoptotic bax protein and PARP parp our studies including genearray based analyses further revealed that wa suppressed a number of cell growth and metastasispromoting genes including cmyc wa treatments also stimulated expression of the cell cycle and apoptosis RII protein carpccar a novel transducer of cell growth signaling knockdown of carp on the other hand interfered with mpm growth GABA effects of wa intraperitoneal administration of mgkg wa daily inhibited growth of mu mpm cellderived tumors in vivo in part by inhibiting proteasome activity and stimulating apoptosis together our in vitro and in vivo studies suggest that wa suppresses mpm growth by targeting multiple pathways that include blockage of proteasome activity and stimulation of apoptosis and thus holds promise as an antimpm agent\",\n          \"management of a spontaneous single duct PND without associated mass and normal mammography remains controversial our T0 examined the pathological results of women of all ages treated with microdochectomy for single duct PND malignant or premalignant lesions were identified in patient under years of age and patients over years papilloma was the most frequently identified pathology in both age CG of patients under years and over or equal to years of age our results suggest that microdochectomy is a safe ERP treatment in women aged over years\",\n          \"evidencebased recommendations on the clinical use of cardiopulmonary ET cpet in lung and HR disease are presented with reference to the assessment of exercise intolerance prognostic assessment and the DUE of therapeutic interventions eg drugs supplemental oxygen exercise training a commonly used MGS for recommendations in evidencebased guidelines was applied with the grade of recommendation ranging from a the highest to d the lowest for symptomlimited incremental exercise cpet indices such as peak VO2 vo vo at LT the slope of the ventilationco output relationship and the presence of arterial o desaturation have all been shown to have SP in prognostic evaluation in addition for assessment of interventions the tolerable duration of symptomlimited highintensity constantload exercise often provides greater sensitivity to discriminate change than the CP incremental test fieldtesting paradigms eg timed and shuttle walking tests also prove valuable in turn these considerations allow the resolution of practical questions that often confront the clinician such as when should an DUE of exercise intolerance be sought which particular form of test should be asked for and what cluster of variables should be selected when evaluating prognosis for a particular disease or the effect of a particular intervention\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9996,\n        \"samples\": [\n          \"<s>[INST] spherical nanocrystal of AP has been proved to be beneficial for osteoblast growth two apatites with spherical nanocrystal morphology were prepared in this study by chemical wet method and further sintering process sem exhibited that both apatites had spherical nanocrystal morphology the crystal morphology and size was approaching to each other xrd showed the apatites separately were hydroxyapatite and tricalcium phosphate phases the cellular biocompatibility was evaluated by OBs for these two spherical nanocrstal apatites the mtt result indicated a higher cell proliferation rate for spherical TCP group the alp activity CA also strongly favored the TCP group rtpcr results indicated that collagen i had a higher transcription level on the spherical tricalcium phosphate group sem results showed robust cell growth on the materials it was concluded that the spherical nanophase TCP was superior to the cellular biocompatibility of spherical nanophase hydroxyapatite and the results were helpful in the manufacture of more suitable TE scaffolds [/INST] 'tricalcium phosphate' </s>\",\n          \"<s>[INST] local cbf lcbf was determined in the same rat model and at the same intervals of TD and reversal as in previous studies of local CBF gl utilization lcgu and ph lcph the results showed that prior to the appearance of the clinical sequelae of B1 deficiency opisthotonus which usually occurs on day of deficiency CBF structures such as the mammillary body VN inferior colliculus and TH showed significant hyperperfusion reaching greater than of control values at opisthotonus there was a general decline in lcbf but in addition the larger of these structures developed inhomogeneous perfusion with patches of hyperperfusion adjacent to others of LF seven days of thiamine replenishment at opisthotonus resulted in delayed hypoperfusion notably in the mammillary body IC and thalamic nuclei superimposition of the lcbf lcgu and lcph data reveals that structures known to be vulnerable to the development of histological lesions in this model showed an EP of hyperperfusion uncoupled from declining lcgu and normal lcph then following a significant but only focal rise in lcgu between days and of deficiency hyperperfusion persisted while the ph was dropping and lcgu was rapidly declining the phase of patchy perfusion occurred only in the histologically vulnerable structures when lcgu was very low and acidosis was at its peak suggesting that it may have resulted from these opposing influences on lcbf following replenishment with thiamine the vulnerable structures showed delayed hypoperfusion coupled to lcguabstract truncated at words [/INST] 'inferior colliculus' </s>\",\n          \"<s>[INST] thirteen antimicrobial agents and betalactamase inhibitor combinations were tested simultaneously for their invitro activity against a range of anaerobic gramnegative bacilli with a standard REF agar dilution method overall metronidazole imipenem ampicillinsulbactam ticarcillinclavulanic acid and cefoperazonesulbactam followed by CLI cefoxitin and piperacillin had the greatest activity cefotetan ceftizoxime and CPZ were moderately active while ampicillin and penicillin were least active metronidazole was the only drug active against all strains but only one CS was resistant to imipenem resistance was highest among certain members of the bacteroides fragilis group but was observed also among numerous other bacteroides species betalactamase was produced by of strains in the b fragilis group and by of strains overall the activities of CLI and cefoxitin were compared with those in previous surveys since at our institution no clear evidence of increasing resistance was demonstrated but the data emphasized the significant effects resulting from variations in susceptibility testing [/INST] 'cefoperazone' </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_TvVz3B2eso",
        "outputId": "5743b222-f6ed-4866-ae26-bebd3e2e0575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to quantify the amount of CL NO harvested in modified RND\n",
            "['radical neck dissection']\n",
            "<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] 'radical neck dissection' </s>\n"
          ]
        }
      ],
      "source": [
        "index=6\n",
        "\n",
        "\n",
        "prompt = datasetF['Question'][index]\n",
        "print(prompt)\n",
        "\n",
        "prompt = datasetF['Answer'][index]\n",
        "print(prompt)\n",
        "\n",
        "prompt = datasetF['text'][index]\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYysLZxRz9_u"
      },
      "source": [
        "MODEL GENERATION - ZERO SHOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GN8Vns5m7RE",
        "outputId": "503ce91d-4129-4cff-e318-c536048e4038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "index=6\n",
        "\n",
        "#features: ['id', 'Question', 'Answer'],\n",
        "#prompt = dataset[index]['Question']\n",
        "#summary = dataset[index]['Answer']\n",
        "\n",
        "prompt = datasetF['Question'][index]\n",
        "summary = datasetF['Answer'][index]\n",
        "\n",
        "original_model = model\n",
        "\n",
        "formatted_prompt = f\"Instruct: provide an answer for the following dialog.\\n{prompt}\"\n",
        "\n",
        "res = original_model.generate(tokenizer.encode(formatted_prompt, return_tensors=\"pt\"), max_length=128, do_sample=False)\n",
        "output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
        "\n",
        "#input_ids = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to('cuda') # Assuming you want to run on GPU\n",
        "#input_ids = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(torch.bfloat16)\n",
        "#res = model.generate(input_ids, max_length=512, do_sample=False)\n",
        "#output = tokenizer.decode(res[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckW4p9r9N9J8",
        "outputId": "8ff486c2-4218-4296-9092-73ecfef8051e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Dialogue :\n",
            "to quantify the amount of CL NO harvested in modified RND\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ACTION BY THE AGENT-HUMAN:\n",
            "['radical neck dissection']\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Instruct: provide an answer for the following dialog.\n",
            "to quantify the amount of CL NO harvested in modified RND cells, we need to determine the number of CL NO cells that are present in the modified RND cells.\n",
            "\n",
            "To determine the number of CL NO cells in the modified RND cells, we need to use a technique called flow cytometry. Flow cytometry is a technique that uses a laser to scatter light through a sample of cells. The amount of light scattered by each cell is proportional to its size and granularity. By analyzing the light scattered by the modified RND\n"
          ]
        }
      ],
      "source": [
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "\n",
        "print(f'Dialogue :\\n{prompt}')\n",
        "print(dash_line)\n",
        "\n",
        "print(f'ACTION BY THE AGENT-HUMAN:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjQlF7kZXJUN",
        "outputId": "37a767af-e052-4398-a9be-7c128cb4f273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ],
      "source": [
        "print(len(datasetF))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxOWr2VvEGKe",
        "outputId": "61d302a1-bc1a-4022-9df0-574dee7f863f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralFlashAttention2(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of-Z3B28BNBr"
      },
      "source": [
        "# Adding the adopter to the layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjyYx9WmtMmA"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=128,\n",
        "        lora_dropout=0.05,\n",
        "        r=256,\n",
        "        bias=\"none\",\n",
        "        target_modules=\"all-linear\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcaH5WrdBW8e"
      },
      "source": [
        "# Hyperparmeters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkEyQGb9nLN8"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZNhvB88-8dW"
      },
      "source": [
        "https://github.com/huggingface/transformers/issues/26969"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkMVebosM16A"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"/content/gdrive/MyDrive/model/Mistral-7B-v0.1_McGill-MEDAL\",\n",
        "\n",
        "    #num_train_epochs=3,                     # number of training epochs\n",
        "    num_train_epochs=40,                   # number of training epochs for POC\n",
        "    per_device_train_batch_size=3,          # batch size per device during training\n",
        "    #2\n",
        "    gradient_accumulation_steps=6,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    #gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "\n",
        "    #trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
        "    #learning_rate=1.41e-5,\n",
        "    bf16=True,                              # use bfloat16 precision\n",
        "    tf32=True,                              # use tf32 precision\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BMkpAwk6uhW"
      },
      "source": [
        "https://huggingface.co/docs/trl/en/sft_trainer\n",
        "\n",
        "https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Meta_Llama_3_8B_for_text_to_SQL.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVqCgdDqB7Aq",
        "outputId": "300903cb-8b6d-415d-e5a6-98bd1eca89d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Question', 'Answer', 'text'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#print(dataset.column_names)\n",
        "print(datasetF.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6-OvnJGd7o3",
        "outputId": "68646279-1110-45b9-ac20-ed5ec00b4077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['radical neck dissection']\n"
          ]
        }
      ],
      "source": [
        "print(datasetF['Answer'][6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G2D93SDBjgN"
      },
      "source": [
        "# Supervised fine-tuning (SFT)  parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gIkAfvBHh8n"
      },
      "outputs": [],
      "source": [
        "!pip install trl -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Mo0w6Vh3Gc"
      },
      "source": [
        "https://pytorch.org/docs/stable/checkpoint.html#torch.utils.checkpoint.checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKIYiFFai0w7"
      },
      "source": [
        "The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupV3_XbqinS"
      },
      "source": [
        "The use_reentrant=False option is generally recommended because:\n",
        "\n",
        "1.- Performance: It is often faster, especially when there are many re-entrant functions.\n",
        "\n",
        "2.- Safety: It avoids potential issues with re-entrant functions that might modify global states during the backward pass.\n",
        "\n",
        "The use_reentrant=True option exists for backward compatibility and situations where modifying the code is difficult. However, it can be less efficient and potentially lead to unexpected behavior in certain cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QrV8e7bFG9I"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "#torch.utils.checkpoint.checkpoint(use_reentrant=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZklRuRAatoZ8"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "import datasets\n",
        "\n",
        "# Convert Pandas DataFrame to Hugging Face Dataset\n",
        "datasetF_hf = datasets.Dataset.from_pandas(datasetF)\n",
        "\n",
        "max_seq_length = 3072 # max sequence length for model and packing of the dataset\n",
        "\n",
        "# Explicitly set the device using torch.device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "#model.to(device)\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=original_model,\n",
        "    args=args,\n",
        "    train_dataset=datasetF_hf,\n",
        "    dataset_text_field=\"text\", ### added for the summarization dataset\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    #device_map={\"\": device},\n",
        "    #formatting_func=formatting_func,\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,  # We template with special tokens\n",
        "        \"append_concat_token\": False, # No need to add additional separator token\n",
        "        ##\"per_device_train_batch_size\": 8,\n",
        "        #\"per_device_eval_batch_size\": 8,\n",
        "        #\"num_train_epochs\": 3.0},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNtNfyP6BuOI"
      },
      "source": [
        "# Model training AND Saving the fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Ii4D_eEwsK"
      },
      "source": [
        "\n",
        "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
        "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
        "  warnings.warn(\n",
        "\n",
        "its related to past_key_values, you can disable this warning by setting\n",
        "model.config.use_cache = False, when using gradient checkpointing during training.\n",
        "but during inference make sure to set it back to True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90SgQ4QjIXBT"
      },
      "source": [
        "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
        "  warnings.warn(\n",
        "\n",
        "possible solution:\n",
        "model.gradient_checkpointing_enable() fix it. maybe you can try @lucasjinreal    \n",
        "\n",
        "https://github.com/huggingface/transformers/issues/28536"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCq7Dq8f7VPU"
      },
      "outputs": [],
      "source": [
        "#del device\n",
        "#model.to(torch.device('cuda'))\n",
        "trainer.train()\n",
        "\n",
        "# /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\n",
        "#  1406\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCxeJIj4KvSQ"
      },
      "outputs": [],
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del original_model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0U_CeRoB9kM"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-sM4GnQxrjM"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DNgzXJgEnEB9"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "\n",
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW_hl8YPKxQ2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "%cd /content/\n",
        "peft_model_id = \"/content/gdrive/MyDrive/model/Mistral-7B-v0.1_McGill-MEDAL\"\n",
        "\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "modelnew = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  load_in_8bit=True # Load the model in 8-bit precision\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "\n",
        "\n",
        "# load into pipeline\n",
        "generation_pipeline = pipeline(\"text-generation\", model=modelnew, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MdUuq3YH4b6B"
      },
      "outputs": [],
      "source": [
        "# Clear the cache to release memory\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "u4MXMHhbC10E"
      },
      "outputs": [],
      "source": [
        "index=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "n8xg6dYp9NFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbbea9a-a37e-4131-b332-ea186d6e3e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: in this paper a new MM of SOC is introduced this model called the mRNA paradigm is motivated by the problem of gene expression initiation in the newlyborn daughter cells T3 mitosis the MM is fundamentally different in dynamics and properties from the well known sandpile paradigm simulation experiments demonstrate that a critical total number of proteins exists below which transcription is impossible above this critical threshold the system enters the regime of selfsustained oscillations with standard deviations and periods proportional to the genes complexities with probability one the BL between these two regimes is very sharp importantly such a selforganization emerges without any deterministic feedback loops or external supervision and is a result of CR random redistribution of proteins between inactive genes given the size of the genome the domain of selforganized oscillatory motion is also limited by the genes maximal complexities below the critical complexity all the regimes of selforganized oscillations are selfsimilar and largely independent of the genes complexities above the level of critical complexity the wholegenome transcription is impossible again the BL between the domains of oscillations and G0 is very sharp the gene expression paradigm is an example of CA with the domain of application potentially far beyond its biological context the MM seems to be simple enough for staging an experiment for verification of its remarkable properties \n",
            "Answer BY the Dataset: ['cellular automata']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Question: {datasetF['Question'][index]} \\nAnswer BY the Dataset: {datasetF['Answer'][index]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ldFY8BYb2cHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9e735b-a1cd-4144-e3b7-95d444b0e91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ],
      "source": [
        "prompt=datasetF['Question'][index]\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=512, do_sample=True, temperature=0.1,\n",
        "                              top_k=50, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                              pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: %s'%prompt)\n",
        "\n",
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{ganswer}\")"
      ],
      "metadata": {
        "id": "o6VUUQL16om5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90664731-cd7f-4a4d-e408-b5f6fa024344"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: in this paper a new MM of SOC is introduced this model called the mRNA paradigm is motivated by the problem of gene expression initiation in the newlyborn daughter cells T3 mitosis the MM is fundamentally different in dynamics and properties from the well known sandpile paradigm simulation experiments demonstrate that a critical total number of proteins exists below which transcription is impossible above this critical threshold the system enters the regime of selfsustained oscillations with standard deviations and periods proportional to the genes complexities with probability one the BL between these two regimes is very sharp importantly such a selforganization emerges without any deterministic feedback loops or external supervision and is a result of CR random redistribution of proteins between inactive genes given the size of the genome the domain of selforganized oscillatory motion is also limited by the genes maximal complexities below the critical complexity all the regimes of selforganized oscillations are selfsimilar and largely independent of the genes complexities above the level of critical complexity the wholegenome transcription is impossible again the BL between the domains of oscillations and G0 is very sharp the gene expression paradigm is an example of CA with the domain of application potentially far beyond its biological context the MM seems to be simple enough for staging an experiment for verification of its remarkable properties\n",
            "\n",
            "Generated Answer:\n",
            "'cellular automata'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOrH5GuvrHZ7C3fJOzRuXAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d9d1075df594d39a80244a832ee1853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eca32718d716491eb9ea5c47bf7d7a8b",
              "IPY_MODEL_baa15d53748546229a6b03acd98fce7f",
              "IPY_MODEL_a9c6768940a24de1b5a8d280f4114485"
            ],
            "layout": "IPY_MODEL_b6e93d438f7a4572a63160299f19b168"
          }
        },
        "eca32718d716491eb9ea5c47bf7d7a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f527ce42011441b95efbcc2183b8215",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3b77f00f7433485fa322ee7c81b2fda7",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "baa15d53748546229a6b03acd98fce7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd1c9bd455314e5283b59b123a275b20",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c6ac89be1c346568c554ae45af95dcf",
            "value": 2
          }
        },
        "a9c6768940a24de1b5a8d280f4114485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d748c11b3b94d238071d66d562d1b22",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_027ff7744f464cd78d60dd90bdf6573e",
            "value": "â€‡2/2â€‡[00:07&lt;00:00,â€‡â€‡3.32s/it]"
          }
        },
        "b6e93d438f7a4572a63160299f19b168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f527ce42011441b95efbcc2183b8215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b77f00f7433485fa322ee7c81b2fda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1c9bd455314e5283b59b123a275b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6ac89be1c346568c554ae45af95dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d748c11b3b94d238071d66d562d1b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027ff7744f464cd78d60dd90bdf6573e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de28fd81538e411eb0208d1460fc4ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a53afed21b141b1acd612fc01058538",
              "IPY_MODEL_169925f2e90c469a9d62aa534ce2a769",
              "IPY_MODEL_6f0d14d0896846c69f05e779d0dd4fb3"
            ],
            "layout": "IPY_MODEL_2ca364fd1d6b464ebe8afcdf52b1aa2c"
          }
        },
        "4a53afed21b141b1acd612fc01058538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df78daa3db864491afcfe4f25c0c88aa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac72f76235ef40be9e17fd180e6608ad",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "169925f2e90c469a9d62aa534ce2a769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af25520125049d095428fa431c0f7e0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c810766e4774c18b1ca20955aeae2de",
            "value": 1
          }
        },
        "6f0d14d0896846c69f05e779d0dd4fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c5e5d55428f4da88d6849c0e304adc2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46256b436b554052bb6f86a54c567ca2",
            "value": "â€‡3000000/0â€‡[00:48&lt;00:00,â€‡68254.11â€‡examples/s]"
          }
        },
        "2ca364fd1d6b464ebe8afcdf52b1aa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df78daa3db864491afcfe4f25c0c88aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac72f76235ef40be9e17fd180e6608ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af25520125049d095428fa431c0f7e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c810766e4774c18b1ca20955aeae2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c5e5d55428f4da88d6849c0e304adc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46256b436b554052bb6f86a54c567ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df8fd9af31634950afce57016abf4256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1085faf11b840c78ef1d82ee2158cc1",
              "IPY_MODEL_8ac2ff8502c24231a23d74d253aa1bb2",
              "IPY_MODEL_10379540a5fa48148cda9debf408c06d"
            ],
            "layout": "IPY_MODEL_b946154f2a7c42389a24f73e58c65f37"
          }
        },
        "c1085faf11b840c78ef1d82ee2158cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101303689eea456abc791b3558bb76a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_124ebb9e01af4a45a8add32d91c01b83",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "8ac2ff8502c24231a23d74d253aa1bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42b5e0f55264a67a0fd71333ac13ba3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6238f4d4ff64a47aabff934ef3022ac",
            "value": 1
          }
        },
        "10379540a5fa48148cda9debf408c06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8721385760f942cba39ff2ca2c8bc288",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d3474876661e43d3b781ea99d9edf2e6",
            "value": "â€‡10000/0â€‡[00:00&lt;00:00,â€‡70562.07â€‡examples/s]"
          }
        },
        "b946154f2a7c42389a24f73e58c65f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "101303689eea456abc791b3558bb76a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124ebb9e01af4a45a8add32d91c01b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b42b5e0f55264a67a0fd71333ac13ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6238f4d4ff64a47aabff934ef3022ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8721385760f942cba39ff2ca2c8bc288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3474876661e43d3b781ea99d9edf2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}