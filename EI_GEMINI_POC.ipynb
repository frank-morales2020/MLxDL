{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2VzZpqj1j36Cm8B5gmtvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/EI_GEMINI_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install colab-env -q"
      ],
      "metadata": {
        "id": "uDOHJJFrFDmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "7Ol6rBYfHepe",
        "outputId": "ad63bd29-4941-4f96-8b52-c5442088a513"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chatbot-version"
      ],
      "metadata": {
        "id": "nbTtCzV6G6EU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q3TN4iSE6C1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import colab_env\n",
        "\n",
        "# In a real scenario, you would import a sentiment analysis library\n",
        "# For demonstration, we'll create a simple placeholder for sentiment analysis.\n",
        "# from transformers import pipeline # Uncomment if you install transformers for actual sentiment analysis\n",
        "\n",
        "# --- Configuration ---\n",
        "# Replace with your actual Google Gemini API key\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI\")\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY environment variable not set. Please set it.\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel('models/gemini-2.5-pro-preview-05-06')\n",
        "\n",
        "# --- Placeholder Sentiment Analysis ---\n",
        "# In a real application, you'd use a more robust sentiment analysis model\n",
        "# For example, with transformers:\n",
        "# sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "class SimpleSentimentAnalyzer:\n",
        "    \"\"\"\n",
        "    A very basic, rule-based sentiment analyzer for demonstration purposes.\n",
        "    In a real application, use a pre-trained model or a dedicated API.\n",
        "    \"\"\"\n",
        "    def analyze(self, text: str) -> str:\n",
        "        text_lower = text.lower()\n",
        "        if \"happy\" in text_lower or \"joy\" in text_lower or \"great\" in text_lower or \"excited\" in text_lower:\n",
        "            return \"positive\"\n",
        "        elif \"sad\" in text_lower or \"unhappy\" in text_lower or \"frustrated\" in text_lower or \"angry\" in text_lower:\n",
        "            return \"negative\"\n",
        "        else:\n",
        "            return \"neutral\"\n",
        "\n",
        "sentiment_analyzer = SimpleSentimentAnalyzer() # Using our simple placeholder\n",
        "\n",
        "# --- LLM Interaction Function ---\n",
        "\n",
        "def get_emotional_response(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyzes user input sentiment and generates an emotionally tailored response using an LLM.\n",
        "    \"\"\"\n",
        "    detected_sentiment = sentiment_analyzer.analyze(user_input)\n",
        "    print(f\"Detected sentiment: {detected_sentiment}\") # For debugging/visibility\n",
        "\n",
        "    # Crafting the prompt based on detected sentiment\n",
        "    if detected_sentiment == \"positive\":\n",
        "        prompt = f\"\"\"\n",
        "        The user is feeling positive and expresses joy or satisfaction.\n",
        "        Acknowledge their positive emotion and respond enthusiastically and supportively.\n",
        "        Make your response uplifting and encouraging.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "    elif detected_sentiment == \"negative\":\n",
        "        prompt = f\"\"\"\n",
        "        The user is feeling negative, possibly frustrated or sad.\n",
        "        Acknowledge their emotion with empathy and offer comfort or understanding.\n",
        "        Be gentle, supportive, and try to de-escalate any tension.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "    else: # Neutral\n",
        "        prompt = f\"\"\"\n",
        "        The user's sentiment is neutral.\n",
        "        Respond in a helpful, informative, and polite manner.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# --- Example Usage ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the Emotionally Aware AI Chatbot!\")\n",
        "    print(\"Type 'quit' or 'exit' to end the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        user_message = input(\"\\nYou: \")\n",
        "        if user_message.lower() in [\"quit\", \"exit\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        ai_response = get_emotional_response(user_message)\n",
        "        print(f\"AI: {ai_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NO chatbot-version"
      ],
      "metadata": {
        "id": "1i-fzBq9HCLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# --- Configuration ---\n",
        "# Ensure your Google Gemini API key is set as an environment variable\n",
        "# If not set, this will raise an error, prompting you to set it.\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI\")\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY environment variable not set. \"\n",
        "                     \"Please set it (e.g., export GEMINI_API_KEY='YOUR_KEY')\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('models/gemini-2.5-pro-preview-05-06')\n",
        "\n",
        "# --- Simple Sentiment Analyzer (Placeholder for POC) ---\n",
        "class SimpleSentimentAnalyzer:\n",
        "    \"\"\"\n",
        "    A very basic, rule-based sentiment analyzer for demonstration.\n",
        "    For a production system, use a dedicated, pre-trained NLP model or API.\n",
        "    \"\"\"\n",
        "    def analyze(self, text: str) -> str:\n",
        "        text_lower = text.lower()\n",
        "        if any(keyword in text_lower for keyword in [\"happy\", \"joy\", \"great\", \"excited\", \"fantastic\", \"wonderful\"]):\n",
        "            return \"positive\"\n",
        "        elif any(keyword in text_lower for keyword in [\"sad\", \"unhappy\", \"frustrated\", \"angry\", \"stressed\", \"disappointed\"]):\n",
        "            return \"negative\"\n",
        "        else:\n",
        "            return \"neutral\"\n",
        "\n",
        "sentiment_analyzer = SimpleSentimentAnalyzer()\n",
        "\n",
        "# --- Core Function for Emotionally Tailored Response ---\n",
        "def get_emotional_response(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of the user's input and generates a response\n",
        "    from the LLM that is tailored to that detected emotion.\n",
        "\n",
        "    Args:\n",
        "        user_input (str): The text input from the user.\n",
        "\n",
        "    Returns:\n",
        "        str: The emotionally tailored response from the AI.\n",
        "    \"\"\"\n",
        "    detected_sentiment = sentiment_analyzer.analyze(user_input)\n",
        "    print(f\"DEBUG: Detected sentiment: {detected_sentiment}\") # Helpful for debugging\n",
        "\n",
        "    # Dynamically craft the prompt based on the detected sentiment\n",
        "    if detected_sentiment == \"positive\":\n",
        "        prompt = f\"\"\"\n",
        "        The user is expressing a positive emotion (e.g., joy, excitement, satisfaction).\n",
        "        Respond enthusiastically, supportively, and positively.\n",
        "        Your tone should be uplifting and encouraging.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "    elif detected_sentiment == \"negative\":\n",
        "        prompt = f\"\"\"\n",
        "        The user is expressing a negative emotion (e.g., frustration, sadness, stress).\n",
        "        Acknowledge their emotion with empathy, offer understanding, and provide comfort or a gentle approach.\n",
        "        Your tone should be compassionate and reassuring, aiming to de-escalate any tension.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "    else: # Neutral or unclear sentiment\n",
        "        prompt = f\"\"\"\n",
        "        The user's sentiment appears neutral or is not strongly emotional.\n",
        "        Respond in a helpful, informative, and polite manner.\n",
        "        User input: \"{user_input}\"\n",
        "        \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate content using the specified Gemini model\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# --- Example Usage (Non-Chatbot Style) ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Demonstrating Emotionally Aware AI Responses (POC) ---\")\n",
        "\n",
        "    # Example 1: Positive User Input\n",
        "    positive_input = \"I'm so happy with how things are going today, feeling great!\"\n",
        "    print(f\"\\nUser says: '{positive_input}'\")\n",
        "    ai_response_positive = get_emotional_response(positive_input)\n",
        "    print(f\"AI responds: '{ai_response_positive}'\")\n",
        "\n",
        "    # Example 2: Negative User Input\n",
        "    negative_input = \"I'm really frustrated with this problem, it's quite annoying.\"\n",
        "    print(f\"\\nUser says: '{negative_input}'\")\n",
        "    ai_response_negative = get_emotional_response(negative_input)\n",
        "    print(f\"AI responds: '{ai_response_negative}'\")\n",
        "\n",
        "    # Example 3: Neutral User Input\n",
        "    neutral_input = \"Could you tell me about the capital of France?\"\n",
        "    print(f\"\\nUser says: '{neutral_input}'\")\n",
        "    ai_response_neutral = get_emotional_response(neutral_input)\n",
        "    print(f\"AI responds: '{ai_response_neutral}'\")\n",
        "\n",
        "    # Example 4: Mixed or subtle sentiment (might lean neutral with simple analyzer)\n",
        "    subtle_input = \"Well, this is certainly a development. Not entirely sure what to make of it.\"\n",
        "    print(f\"\\nUser says: '{subtle_input}'\")\n",
        "    ai_response_subtle = get_emotional_response(subtle_input)\n",
        "    print(f\"AI responds: '{ai_response_subtle}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "pHZ6w0PoG3mP",
        "outputId": "a3980151-87a4-4d02-a20a-c8be04f16173"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Demonstrating Emotionally Aware AI Responses (POC) ---\n",
            "\n",
            "User says: 'I'm so happy with how things are going today, feeling great!'\n",
            "DEBUG: Detected sentiment: positive\n",
            "AI responds: 'Yes! That's the spirit! I'm so incredibly happy for you that things are going so well and you're feeling on top of the world! Ride that wave of joy and make the most of this fantastic day!'\n",
            "\n",
            "User says: 'I'm really frustrated with this problem, it's quite annoying.'\n",
            "DEBUG: Detected sentiment: negative\n",
            "AI responds: 'Oh, I completely understand. It's really common to feel frustrated and annoyed when you're hitting a wall with a problem. Those kinds of challenges can be quite draining.\n",
            "\n",
            "Please know it's perfectly okay to feel that way. Sometimes just acknowledging the frustration can help a little. If you want to vent a bit more about it, or if you'd like to try and approach it from a different angle when you're ready, I'm here to listen and help in any way I can.'\n",
            "\n",
            "User says: 'Could you tell me about the capital of France?'\n",
            "DEBUG: Detected sentiment: neutral\n",
            "AI responds: 'Certainly! The capital of France is **Paris**.\n",
            "\n",
            "It's a major global center for art, fashion, gastronomy (cuisine), and culture. Some of its most famous landmarks include:\n",
            "\n",
            "*   The **Eiffel Tower**\n",
            "*   The **Louvre Museum** (home to the Mona Lisa)\n",
            "*   **Notre-Dame Cathedral**\n",
            "*   The **Arc de Triomphe**\n",
            "*   The **Champs-Élysées** avenue\n",
            "\n",
            "Paris is also known for its charming cafes, beautiful architecture, and the River Seine which flows through the city. It's often affectionately called the \"City of Light\" (La Ville Lumière).\n",
            "\n",
            "Is there anything specific you'd like to know about Paris? For example, its history, specific attractions, or perhaps tips for visiting?'\n",
            "\n",
            "User says: 'Well, this is certainly a development. Not entirely sure what to make of it.'\n",
            "DEBUG: Detected sentiment: neutral\n",
            "AI responds: 'Okay, I understand. It sounds like you're taking a moment to process this new information. When new developments arise, it can definitely take a bit to figure out all the angles.\n",
            "\n",
            "If you'd like to talk through it, explore different perspectives, or just articulate your thoughts, I'm here to listen. Sometimes that can help clarify things.'\n"
          ]
        }
      ]
    }
  ]
}