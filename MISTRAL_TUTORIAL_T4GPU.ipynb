{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZJenoVFdECANHy5jt/j2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MISTRAL_TUTORIAL_T4GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MISTRAL TUTORIAL"
      ],
      "metadata": {
        "id": "vT7bK2tU_eBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the DEMO - Run the model from the Source\n",
        "\n",
        "https://github.com/mistralai/mistral-src/tree/main"
      ],
      "metadata": {
        "id": "gdnlbVMU_sFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCBi53J5Ynwa"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "code_path = \"/content/mistral-src/\"  # codebase\n",
        "data_path = Path(\"/content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/Symptom2Disease.csv\")  # dataset downloaded from Kaggle\n",
        "model_path = Path(\"/content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/\")  # model and tokenizer location\n",
        "\n",
        "#!pip install -q -U mistral-src\n",
        "\n",
        "!pip install colab-env --upgrade\n",
        "import colab_env\n",
        "\n",
        "!git clone https://github.com/mistralai/mistral-src.git\n",
        "%cd /content/mistral-src\n",
        "!pip install -r /content/mistral-src/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### CLI FOR THE DEMO ########\n",
        "\n",
        "\n",
        "#!python -m main demo /content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/\n",
        "\n",
        "# To give your own prompts\n",
        "#!python -m main interactive /content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/\n",
        "\n",
        "#!python -m test_generate\n",
        "\n",
        "#!python -m main interactive /content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/ --max_tokens 256 --temperature 1.0"
      ],
      "metadata": {
        "id": "FhuOQO1NfLeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import csv\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import bfloat16\n",
        "\n",
        "#model = Transformer.from_folder(model_path, dtype=bfloat16)\n",
        "\n",
        "code_path = \"/content/mistral-src/\"  # codebase\n",
        "data_path = Path(\"/content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/Symptom2Disease.csv\")  # dataset downloaded from Kaggle\n",
        "model_path = Path(\"/content/gdrive/MyDrive/datasets/mistral/mistral-7B-v0.1/\")  # model and tokenizer location\n",
        "\n",
        "import sys\n",
        "sys.path.append(code_path)  # append the path where mistral-src was cloned\n",
        "\n",
        "from mistral.model import Transformer\n",
        "from mistral.tokenizer import Tokenizer\n",
        "from main import generate\n",
        "\n",
        "#Load the model and tokenizer # ALTERNATIVE\n",
        "\n",
        "## T4 GPU\n",
        "model0 = Transformer.from_folder(model_path, max_batch_size=3)\n",
        "\n",
        "### A100 GPU\n",
        "#model = Transformer.from_folder(model_path, dtype=torch.bfloat16)\n",
        "\n",
        "tokenizer0 = Tokenizer(str(model_path / \"tokenizer.model\"))\n",
        "\n",
        "max_tokens = 256\n",
        "temperature = 1.0\n",
        "prompt='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "response=generate([prompt], model0, tokenizer0, max_tokens=max_tokens, temperature=temperature)\n",
        "\n",
        "\n",
        "#IF NOT A100 GPU\n",
        "#'xformers.ops.fmha.attn_bias.BlockDiagonalCausalLocalAttentionMask'>\n",
        "#    bf16 is only supported on A100+ GPUs\n",
        "#    unsupported embed per head: 128\n",
        "\n",
        "\n",
        "#tokenizer.batch_decode(response)[0]\n",
        "\n",
        "#print(response[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uwRfWBd3dPUK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 1024\n",
        "temperature = 0.9\n",
        "\n",
        "prompt = \"As a data scientist, can you explain the concept of regularization in machine learning? please the anser in english\"\n",
        "\n",
        "#prompt='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering in english.'\n",
        "\n",
        "#prompt='Which country has the most natural lakes? Answer with only the country name.'\n",
        "\n",
        "response=generate([prompt], model0, tokenizer0, max_tokens=max_tokens, temperature=temperature)\n",
        "#print(response[0])\n",
        "tokenizer0.decode(response[0])\n",
        "\n",
        "\n",
        "#model = Transformer(args).to(\"cuda\", dtype=torch.float32)\n",
        "#tokenizer = DebugTokenizer()\n"
      ],
      "metadata": {
        "id": "Hu6xZnmsUecG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ad23fda6-4c55-4d0e-8585-ac8974898a08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As a data scientist, can you explain the concept of regularization in machine learning? please the anser in english\\n\\nWhat is regularization?\\n\\nRegularization is a method used in machine learning to improve the generalization performance of models by penalizing complex models.\\n\\nHow does regularization work?\\n\\nRegularization works by adding a penalty term to the objective function of the model, which increases the cost of complex models. This encourages the model to find simpler solutions, which are more generalizable and less prone to overfitting.\\n\\nWhat are the different types of regularization techniques?\\n\\nThere are several types of regularization techniques, including:\\n\\n1. L1 regularization: Also known as LASSO (Least Absolute Shrinkage and Selection Operator), this technique penalizes large coefficients by adding a term that sums the absolute values of the coefficients.\\n2. L2 regularization: Also known as ridge regression, this technique penalizes large coefficients by adding a term that sums the squared values of the coefficients.\\n3. Elastic Net: This is a combination of L1 and L2 regularization that aims to balance between sparsity and smoothness.\\n4. Dropout: This is a regularization technique used in neural networks, where random neurons are dropped during training to prevent overfitting.\\n5. Early stopping: This is a regularization technique where training is stopped before the model starts to overfit, by monitoring the modelâ€™s performance on a validation set.\\n\\nWhy is regularization important in machine learning?\\n\\nRegularization is important in machine learning because it helps to prevent overfitting, which is a common problem in complex models. Overfitting occurs when the model fits the training data too closely, and is not able to generalize to new data. Regularization helps to avoid overfitting by encouraging the model to find simpler solutions, which are more generalizable.\\n\\nWhat are the benefits of regularization?\\n\\nThe benefits of regularization include:\\n\\n1. Improved generalization performance: Regularization helps the model to generalize better to new data, which improves its predictive accuracy.\\n2. Reduced overfitting: Regularization reduces the tendency of the model to overfit the training data, which improves its performance on new data.\\n3. More interpretable models: Regularization can lead to simpler models that are easier to interpret and understand.\\n\\nHow is regularization implemented in machine learning models?\\n\\nRegularization can be implemented in machine learning models by adding a penalty term to the objective function. For example, in linear regression, L1 regularization can be implemented by adding a term that sums the absolute values of the coefficients, and L2 regularization can be implemented by adding a term that sums the squared values of the coefficients.\\n\\nWhat are the challenges of regularization?\\n\\nThe main challenge of regularization is finding the optimal level of regularization. Too much regularization can lead to underfitting, where the model is not able to capture the true relationship between the features and the target. Too little regularization can lead to overfitting, where the model fits the training data too closely and is not able to generalize to new data.\\n\\nHow is regularization related to feature selection?\\n\\nRegularization can be used as a method of feature selection, by penalizing coefficients that are not important for the model. This can help to reduce the number of features in the model, which can improve its generalization performance and reduce computational complexity.\\n\\nWhat are the applications of regularization in machine learning?\\n\\nRegularization is used in a wide range of machine learning models, including:\\n\\n1. Linear regression\\n2. Logistic regression\\n3. Neural networks\\n4. Support vector machines\\n5. Ensemble methods\\n\\nHow is regularization different from cross-validation?\\n\\nRegularization and cross-validation are both methods of improving the generalization performance of models, but they are different in their approach. Regularization adds a penalty term to the objective function to discourage complex models, while cross-validation is a technique for evaluating the performance of a model on new data by splitting the data into training and validation sets.\\n\\nHow is regularization different from pruning?\\n\\nRegularization and pruning are both methods of improving the generalization performance of models, but they are different in their approach. Regularization adds a penalty term to the objective function to discourage complex models, while pruning is a technique for removing unimportant features or parameters from the model to reduce its complexity.\\n\\nHow is regularization different from early stopping?\\n\\nRegularization and early stopping are both methods of improving the generalization performance of models, but they are different in their approach. Regularization adds a penalty term to the objective function to discourage complex models, while early stopping is a technique for stopping the training process before the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "zkJI9mxkdGT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "%pip install openai==0.28  --root-user-action=ignore\n",
        "%pip install tiktoken\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "!pip install bitsandbytes --quiet"
      ],
      "metadata": {
        "id": "YqGWDUO3x7LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Configuration - Creation of the model and tokenizer - HuggingFace\n",
        "\n"
      ],
      "metadata": {
        "id": "c9VK05AQIDXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install accelerate\n",
        "\n",
        "import torch\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "access_token = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#from transformers import AutoTokenizer, MistralForCausalLM"
      ],
      "metadata": {
        "id": "A185FYvjxpqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME='mistralai/Mistral-7B-Instruct-v0.1'\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 512\n",
        "generation_config.temperature = 0.9\n",
        "generation_config.top_p = 0.9\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "#model.to(device)\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "fvqm3EZo_bJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "_KMq9ro9_jY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples"
      ],
      "metadata": {
        "id": "1iApGgj1AVo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.'\n",
        "query1 = \"who is the President of the USA?\"\n",
        "query2 = \"Who won the baseball World Series in 2020? and Who Lost\"\n",
        "\n",
        "device=\"cuda\"\n",
        "def prompt_completion(query):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"%s\"%query}\n",
        "    ]\n",
        "\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "    #https://stackoverflow.com/questions/69609401/suppress-huggingface-logging-warning-setting-pad-token-id-to-eos-token-id\n",
        "\n",
        "    generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=True, negative_prompt_attention_mask='attention_mask',\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.batch_decode(generated_ids)\n",
        "    print()\n",
        "    print()\n",
        "    result=decoded[0].replace('<s> [INST] %s [/INST]'%query,\"\")\n",
        "    result=result.replace('</s>',\"\")\n",
        "    print('Prompt: %s'%query)\n",
        "    print('-'*80)\n",
        "    print('Answer: %s'%result)\n",
        "\n",
        "prompt_completion(query)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query1)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query2)\n",
        "\n",
        "query3 = \"what is the 20.5% of 40?\"\n",
        "query4 = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "query5 ='Which country has the most natural lakes? Answer with only the country name.'\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query3)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query4)\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query5)\n",
        "\n",
        "\n",
        "query6 = \"How AWS has evolved?\"\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(query6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L2zjyGK_qSL",
        "outputId": "7b2bfa64-e8ad-4f5e-f8bb-033978f2abda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Prompt: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Here's an easy way to understand this:\n",
            "\n",
            "1. You bought a cone for each of 6 kids, so you spent 6 * $1.25 = $7.50 on ice cream.\n",
            "2. When you paid with a $10 bill, you were giving the ice cream vendor $10 and getting back $7.50 in change.\n",
            "3. To find out how much money you got back, subtract the cost of the ice cream from the amount you paid.\n",
            "\n",
            "So, you got back $10 - $7.50 = $2.50.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: who is the President of the USA?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  As of my last update, the President of the United States of America is Joe Biden. However, this information may be outdated and I would recommend checking a reliable source for the most up-to-date information.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Who won the baseball World Series in 2020? and Who Lost\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  The Los Angeles Dodgers won the 2020 Major League Baseball (MLB) World Series. They defeated the Tampa Bay Rays 3-2 in a seven-game series to win their first World Series title since 1988.\n",
            "\n",
            "The Rays, on the other hand, lost the World Series for the first time since 2004, when they went to their first and only World Series and lost to the Boston Red Sox.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: what is the 20.5% of 40?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  The 20.5% of 40 is 8.2\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: As a data scientist, can you explain the concept of regularization in machine learning?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Regularization is a technique used in machine learning to prevent overfitting and improve the generalization of statistical models. Overfitting occurs when a model is so complex that it fits the training data very well, but poorly fits new, unseen data. Regularization works by adding a term to the cost function that the model is optimized to minimize, which encourages the model to use all of the input features in a more balanced way, and prevents the model from becoming too complex. This results in a model that is better able to generalize to new data and makes it more robust to noise and outliers in the training data.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: Which country has the most natural lakes? Answer with only the country name.\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  Canada\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: How AWS has evolved?\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  AWS, or Amazon Web Services, has evolved significantly since its inception in 2006 as a simple web services platform. Today, it is a massive cloud computing platform that offers a wide range of services for building, managing, and deploying applications.\n",
            "\n",
            "The evolution of AWS has taken place in several stages:\n",
            "\n",
            "1. Initial offerings: AWS began with a small set of basic services such as EC2 (Elastic Compute Cloud, later renamed Elastic Compute Service), which allowed users to launch virtual servers in the cloud, and S3 (Simple Storage Service), which provided object storage.\n",
            "2. Expansion: As demand for cloud services grew, AWS expanded its offerings to include additional compute, storage, and networking services. In late 2009, AWS launched ECS (Elastic Container Service), a container orchestration service that made it easy to deploy and manage containers in a cloud environment.\n",
            "3. Database and analytics: AWS also expanded its offerings in the database and analytics space, launching services such as RDS (Relational Database Service), which provided a managed database service, and Redshift, a data warehousing service that allowed users to analyze massive amounts of data in a cloud environment.\n",
            "4. Serverless computing: AWS has been a major proponent of serverless computing, which allows developers to build applications without the need for managing infrastructure. AWS launched its first serverless computing service, Lambda, in 2014, and later added additional services such as Api Gateway, DynamoDB, and SNS.\n",
            "5. Internet of Things (IoT): AWS has also expanded its offerings to include services for building and managing IoT applications. In 2015, AWS launched the IoT Core service, which provides a secure and scalable platform for managing IoT devices and data.\n",
            "6. AI and machine learning: AWS has also been a leader in the development of AI and machine learning (ML) technologies. In 2016, AWS launched SageMaker, a fully managed service for machine learning development and deployment, and has since added many other AI and ML services, such as AWS Rekognition and Polly.\n",
            "7. DevOps and Kubernetes: AWS has also expanded its offerings in the DevOps and Kubernetes space. In 2019, AWS launched Elastic Kubernetes Service (EKS), a fully managed Kubernetes service that made\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"summarize the following text: AI analytics is a subset of business intelligence that uses machine learning algorithms to monitor and analyze vast amounts of data constantly,\\\n",
        " automating the time-consuming work generally done by a data analyst[1]. AI analytics results from automating business analytics processes through artificial intelligence (AI) and machine learning (ML)[2]. \\\n",
        " AI analytics can improve the scale and speed at which data is analyzed compared to a human worker. \\\n",
        " It can identify trends, provide insights, and discover relationships within data [2]. \\\n",
        " AI analytics uses machine learning algorithms to monitor and analyze vast amounts of data, automating the time-consuming work of a data analyst[1].\\\n",
        "  AI analytics extracts valuable information from big data using advanced machine learning (ML) and AI tasks like natural language processing (NLP). \\\n",
        "  It is used to identify patterns and trends in data for informed decision-making[3]. \\\n",
        "Here are some examples of AI analytics: \\\n",
        "Sentiment analysis examines information about a subject online and evaluates its consumer feedback [4].\\\n",
        "Predictive analytics and forecasting: AI analysis tools can analyze historical data, market data, and other factors to forecast \\\n",
        "future sales and predict purchasing patterns [4-5].\\\n",
        "Anomaly detection and fraud prevention: AI analytics can detect anomalies in data that may indicate fraudulent activity[4].\\\n",
        "Image and video analysis: AI analytics can analyze images and videos to identify objects, people, and other features[4].\\\n",
        "Conversation analytics: AI analytics can analyze conversations between customers and customer service representatives to identify trends \\\n",
        "and improve customer service[6].\\\n",
        "Synthetic data creation: AI analytics can be used to create synthetic data that can be used to train machine learning models[4]. \\\n",
        "Dashboard creation: AI analytics can create dashboards that provide real-time insights into business performance[7].\\\n",
        "Data entry automation: AI analytics can be used to automate data entry tasks, freeing up time for more critical tasks[7]. \\\n",
        "You can check out [5-7] for more examples. \\\n",
        "Some of the challenges of AI analytics include:\\\n",
        "Repeatability and reproducibility: One of the biggest challenges for AI and data analytics in a production environment is the issue of \\\n",
        "repeatability and reproducibility[8]. \\\n",
        "Speed of implementation: Implementing AI and data analytics can be time-consuming and take a long time to see results[8].\\\n",
        "Using the correct data: AI and data analytics require large amounts of data to be effective, but using the correct data is essential[8]. \\\n",
        "Deploying models at scale: Deploying AI and data analytics models at scale can be challenging, requiring significant computing power and \\\n",
        "infrastructure[8]. \\\n",
        "Managing the complexity of AI and data analytics: AI and data analytics can be complex, and it can be challenging to understand how they work \\\n",
        "and how to use them effectively [8]. You can check out [8-10] for more information.\\\n",
        "Some benefits of AI analytics include: \\\n",
        "Real-time insights: AI analytics can provide real-time insights into business performance, \\\n",
        "allowing companies to make informed decisions quickly [11]. \\\n",
        "Improved decision-making: AI analytics can help companies make better decisions by providing \\\n",
        "insights into customer behaviour, market trends, and other factors[12].\\\n",
        "Increased productivity and efficiency: AI analytics can automate tasks that would otherwise require human intervention, \\\n",
        "freeing up time for more critical tasks[12]. \\\n",
        "Cost savings through automation: AI analytics can help companies save money by automating tasks that would otherwise require human intervention[12].\\\n",
        "Predictive analytics and forecasting: AI analysis tools can analyze historical data, market data, and other factors to forecast future sales and \\\n",
        "predict purchasing patterns [11,13].\\\n",
        "Anomaly detection and fraud prevention: AI analytics can detect anomalies in data that may indicate fraudulent activity[11].\\\n",
        "Image and video analysis: AI analytics can analyze images and videos to identify objects, people, and other features[11]. \\\n",
        "Conversation analytics: AI analytics can analyze conversations between customers and customer service representatives to identify trends and \\\n",
        "improve customer service[11].\\\n",
        "Synthetic data creation: AI analytics can be used to create synthetic data that can be used to train machine learning models[12].\\\n",
        "Dashboard creation: AI analytics can create dashboards that provide real-time insights into business performance[12].\\\n",
        "Data entry automation: AI analytics can be used to automate data entry tasks, freeing up time for more critical tasks[. \\\n",
        "You can check out [11-14] for more information.\\\n",
        "AI Analytics and LLMs \\\n",
        "LLMs, or Large Language Models, are machine learning algorithms designed to understand and generate human-like text based on the data they have been\\\n",
        "trained on[15]. Traditional data analysis techniques primarily focus on structured and numerical data, but LLMs provide a valuable means of \\\n",
        "understanding and leveraging today's vast textual data. Pecan AI combines LLMs and predictive AI to simplify data analytics and enhance the \\\n",
        "user experience[15]. \\\n",
        "AI Analytics using LLMs is a significant advancement in data science and analytics. \\\n",
        "LLMs, or Large Language Models, are machine learning algorithms designed to understand and generate human-like text based on the data they've \\\n",
        "been trained on. LLMs work by predicting the likelihood of a sequence of words appearing in a sentence or a paragraph. This makes them exceptional \\\n",
        "tools for text generation, translation, and interpretation[15]. LLMs are not well-suited for making predictions on numerical data. However, \\\n",
        "LLMs are invaluable in data analysis and manipulation. LLMs provide a means to understand complex textual data, \\\n",
        "thus enabling the data to be used for further analysis and decision-making processes. LLMs offer unique capabilities that can significantly \\\n",
        "enhance the effectiveness of data analysis and decision-making processes1. Large language models excel at analyzing and processing textual data, \\\n",
        "enabling businesses to extract valuable insights from unstructured information[16]. Traditional data analysis techniques primarily focus on \\\n",
        "structured and numerical data, but LLMs provide a valuable means of understanding and leveraging today vast textual data. \\\n",
        "Pecan AI combines LLMs and predictive AI to simplify data analytics and \\\n",
        "enhance the user experience[16].\"\n",
        "\n",
        "print()\n",
        "print('='*80)\n",
        "prompt_completion(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zy5nobhM4aH",
        "outputId": "033c622f-da8a-4802-9f82-c1dd5bb587d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Prompt: summarize the following text: AI analytics is a subset of business intelligence that uses machine learning algorithms to monitor and analyze vast amounts of data constantly, automating the time-consuming work generally done by a data analyst[1]. AI analytics results from automating business analytics processes through artificial intelligence (AI) and machine learning (ML)[2].  AI analytics can improve the scale and speed at which data is analyzed compared to a human worker.  It can identify trends, provide insights, and discover relationships within data [2].  AI analytics uses machine learning algorithms to monitor and analyze vast amounts of data, automating the time-consuming work of a data analyst[1].  AI analytics extracts valuable information from big data using advanced machine learning (ML) and AI tasks like natural language processing (NLP).   It is used to identify patterns and trends in data for informed decision-making[3]. Here are some examples of AI analytics: Sentiment analysis examines information about a subject online and evaluates its consumer feedback [4].Predictive analytics and forecasting: AI analysis tools can analyze historical data, market data, and other factors to forecast future sales and predict purchasing patterns [4-5].Anomaly detection and fraud prevention: AI analytics can detect anomalies in data that may indicate fraudulent activity[4].Image and video analysis: AI analytics can analyze images and videos to identify objects, people, and other features[4].Conversation analytics: AI analytics can analyze conversations between customers and customer service representatives to identify trends and improve customer service[6].Synthetic data creation: AI analytics can be used to create synthetic data that can be used to train machine learning models[4]. Dashboard creation: AI analytics can create dashboards that provide real-time insights into business performance[7].Data entry automation: AI analytics can be used to automate data entry tasks, freeing up time for more critical tasks[7]. You can check out [5-7] for more examples. Some of the challenges of AI analytics include:Repeatability and reproducibility: One of the biggest challenges for AI and data analytics in a production environment is the issue of repeatability and reproducibility[8]. Speed of implementation: Implementing AI and data analytics can be time-consuming and take a long time to see results[8].Using the correct data: AI and data analytics require large amounts of data to be effective, but using the correct data is essential[8]. Deploying models at scale: Deploying AI and data analytics models at scale can be challenging, requiring significant computing power and infrastructure[8]. Managing the complexity of AI and data analytics: AI and data analytics can be complex, and it can be challenging to understand how they work and how to use them effectively [8]. You can check out [8-10] for more information.Some benefits of AI analytics include: Real-time insights: AI analytics can provide real-time insights into business performance, allowing companies to make informed decisions quickly [11]. Improved decision-making: AI analytics can help companies make better decisions by providing insights into customer behaviour, market trends, and other factors[12].Increased productivity and efficiency: AI analytics can automate tasks that would otherwise require human intervention, freeing up time for more critical tasks[12]. Cost savings through automation: AI analytics can help companies save money by automating tasks that would otherwise require human intervention[12].Predictive analytics and forecasting: AI analysis tools can analyze historical data, market data, and other factors to forecast future sales and predict purchasing patterns [11,13].Anomaly detection and fraud prevention: AI analytics can detect anomalies in data that may indicate fraudulent activity[11].Image and video analysis: AI analytics can analyze images and videos to identify objects, people, and other features[11]. Conversation analytics: AI analytics can analyze conversations between customers and customer service representatives to identify trends and improve customer service[11].Synthetic data creation: AI analytics can be used to create synthetic data that can be used to train machine learning models[12].Dashboard creation: AI analytics can create dashboards that provide real-time insights into business performance[12].Data entry automation: AI analytics can be used to automate data entry tasks, freeing up time for more critical tasks[. You can check out [11-14] for more information.AI Analytics and LLMs LLMs, or Large Language Models, are machine learning algorithms designed to understand and generate human-like text based on the data they have beentrained on[15]. Traditional data analysis techniques primarily focus on structured and numerical data, but LLMs provide a valuable means of understanding and leveraging today's vast textual data. Pecan AI combines LLMs and predictive AI to simplify data analytics and enhance the user experience[15]. AI Analytics using LLMs is a significant advancement in data science and analytics. LLMs, or Large Language Models, are machine learning algorithms designed to understand and generate human-like text based on the data they've been trained on. LLMs work by predicting the likelihood of a sequence of words appearing in a sentence or a paragraph. This makes them exceptional tools for text generation, translation, and interpretation[15]. LLMs are not well-suited for making predictions on numerical data. However, LLMs are invaluable in data analysis and manipulation. LLMs provide a means to understand complex textual data, thus enabling the data to be used for further analysis and decision-making processes. LLMs offer unique capabilities that can significantly enhance the effectiveness of data analysis and decision-making processes1. Large language models excel at analyzing and processing textual data, enabling businesses to extract valuable insights from unstructured information[16]. Traditional data analysis techniques primarily focus on structured and numerical data, but LLMs provide a valuable means of understanding and leveraging today vast textual data. Pecan AI combines LLMs and predictive AI to simplify data analytics and enhance the user experience[16].\n",
            "--------------------------------------------------------------------------------\n",
            "Answer:  AI analytics is a type of business intelligence that uses machine learning algorithms to analyze vast amounts of data. It automates the time-consuming work of data analysts, improving the speed and scale of data analysis, and can identify trends, provide insights, and discover relationships within data. Some examples of AI analytics include sentiment analysis, predictive analytics, anomaly detection, fraud prevention, image and video analysis, conversation analytics, and synthetic data creation. While AI analytics offers many benefits, some challenges include repeatability and reproducibility, speed of implementation, using the correct data, deploying models at scale, and managing the complexity of AI and data analytics. AI analytics also uses large language models (LLMs) to understand and generate human-like text based on data, which is particularly valuable for analyzing and processing textual data. LLMs enable businesses to extract valuable insights from unstructured information and enhance the effectiveness of data analysis and decision-making processes.\n"
          ]
        }
      ]
    }
  ]
}