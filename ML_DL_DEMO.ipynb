{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/+Bz6NW9mBmJL0SDmfg4F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/ML_DL_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyMg6goMfDb3",
        "outputId": "6c1bd69e-7523-4dfd-e8ec-3d2e3d370bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Summary ---\n",
            "Total Samples: 150\n",
            "Training Samples: 105\n",
            "Testing Samples: 45\n",
            "\n",
            "--- Traditional Machine Learning (SVM) ---\n",
            "Model: Support Vector Classifier (SVC)\n",
            "Test Accuracy: 0.9778\n",
            "Note: Requires manual feature scaling (StandardScaler).\n",
            "\n",
            "Training Deep Learning Model (Epochs=50)...\n",
            "\n",
            "--- Deep Learning (Simple DNN) ---\n",
            "Model: Deep Neural Network (DNN)\n",
            "Test Accuracy: 0.9778\n",
            "Note: Feature extraction is handled automatically by the deep layers.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Data Preparation for Both Models ---\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"--- Data Summary ---\")\n",
        "print(f\"Total Samples: {len(X)}\")\n",
        "print(f\"Training Samples: {len(X_train)}\")\n",
        "print(f\"Testing Samples: {len(X_test)}\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# ðŸ¤– SECTION A: TRADITIONAL MACHINE LEARNING (SCIKIT-LEARN / SVM) ðŸ¤–\n",
        "# =================================================================\n",
        "\n",
        "# 1. Feature Engineering/Scaling (Human Intervention/Required Preprocessing)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_ml = scaler.fit_transform(X_train)\n",
        "X_test_scaled_ml = scaler.transform(X_test)\n",
        "\n",
        "# 2. Create and Train the Model\n",
        "model_ml = SVC(kernel='linear', random_state=42)\n",
        "model_ml.fit(X_train_scaled_ml, y_train)\n",
        "\n",
        "# 3. Evaluate the Model\n",
        "y_pred_ml = model_ml.predict(X_test_scaled_ml)\n",
        "accuracy_ml = accuracy_score(y_test, y_pred_ml)\n",
        "\n",
        "print(\"--- Traditional Machine Learning (SVM) ---\")\n",
        "print(f\"Model: Support Vector Classifier (SVC)\")\n",
        "print(f\"Test Accuracy: {accuracy_ml:.4f}\")\n",
        "print(\"Note: Requires manual feature scaling (StandardScaler).\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# ðŸ§  SECTION B: DEEP LEARNING (TENSORFLOW/KERAS / DNN) ðŸ§ \n",
        "# =================================================================\n",
        "\n",
        "# 1. Label Preprocessing (DL Requirement: One-Hot Encoding)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded_dl = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_encoded_dl = encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# 2. Build the Deep Learning Model (Automatic Feature Learning via layers)\n",
        "# FIX: Using tf.keras.Input as the first layer to avoid the UserWarning.\n",
        "model_dl = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(X_train.shape[1],)), # Explicit Input Layer (FIX APPLIED HERE)\n",
        "    tf.keras.layers.Dense(10, activation='relu'), # Hidden Layer 1\n",
        "    tf.keras.layers.Dense(10, activation='relu'), # Hidden Layer 2 (The 'Depth' component)\n",
        "    tf.keras.layers.Dense(3, activation='softmax') # Output Layer (3 classes)\n",
        "])\n",
        "\n",
        "# 3. Compile and Train the Model\n",
        "model_dl.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Training Deep Learning Model (Epochs=50)...\")\n",
        "# Train on the raw data\n",
        "model_dl.fit(X_train, y_train_encoded_dl, epochs=50, batch_size=5, verbose=0)\n",
        "\n",
        "# 4. Evaluate the Model\n",
        "loss_dl, accuracy_dl = model_dl.evaluate(X_test, y_test_encoded_dl, verbose=0)\n",
        "\n",
        "print(\"\\n--- Deep Learning (Simple DNN) ---\")\n",
        "print(f\"Model: Deep Neural Network (DNN)\")\n",
        "print(f\"Test Accuracy: {accuracy_dl:.4f}\")\n",
        "print(\"Note: Feature extraction is handled automatically by the deep layers.\")"
      ]
    }
  ]
}