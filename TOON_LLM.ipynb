{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU6dfjbutWXuKdCT84TqgV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/TOON_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-toon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3EbZpZ-rb4K",
        "outputId": "c19d01ef-d921-4331-c358-693c7fc16365"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-toon\n",
            "  Downloading python_toon-0.1.3-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading python_toon-0.1.3-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-toon\n",
            "Successfully installed python-toon-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BKloRr0gUVg",
        "outputId": "5b2936ab-784b-4524-e326-d8b877147205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "Gemini client initialized for model: gemini-2.5-flash\n",
            "--------------------------------------------------\n",
            "Original JSON data size: 327 characters\n",
            "TOON Data (sent to Gemini): 163 characters\n",
            "TOON String:\n",
            "sales_records[4,]{Region,Sales_Amt,Qtr,Status}:\n",
            "  East,45000,1,Target Met\n",
            "  West,62000,1,Target Exceeded\n",
            "  East,38000,2,Under Target\n",
            "  West,75000,2,Target Exceeded\n",
            "--------------------------------------------------\n",
            "Sending prompt to gemini-2.5-flash...\n",
            "\n",
            "✅ Gemini Analysis Result:\n",
            "Total sales for the 'West' region across both quarters is $137,000 (62,000 + 75,000). The overall status trend shows a decline in performance for the East region (from \"Target Met\" to \"Under Target\"), while the West region consistently \"Target Exceeded\" its goals.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# CORRECTED IMPORT: Use 'from google import genai' for the modern SDK\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Assuming 'python-toon' is installed: pip install python-toon\n",
        "from toon import encode, decode\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "\n",
        "# --- 1. Google Gemini API Configuration (Model Name Updated) ---\n",
        "class AgentConfig:\n",
        "    # --- FIX: Updated the model name to the current stable alias ---\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "\n",
        "GOOGLE_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "except (ImportError, KeyError):\n",
        "    # Fallback to environment variable\n",
        "    GOOGLE_API_KEY = os.getenv('GEMINI')\n",
        "\n",
        "client = None\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        # CORRECTED CLIENT INITIALIZATION: The Client object is now directly under the 'genai' alias\n",
        "        client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        print(f\"Gemini client initialized for model: {AgentConfig.LLM_MODEL_NAME}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during client initialization: {e}\")\n",
        "        client = None\n",
        "else:\n",
        "    print(\"FATAL: Gemini API Key not found. Cannot run integration demo.\")\n",
        "    client = None\n",
        "\n",
        "# ----- 2. Define Sample Data -----\n",
        "SALES_DATA: List[Dict[str, Any]] = [\n",
        "    {\"Region\": \"East\", \"Sales_Amt\": 45000, \"Qtr\": 1, \"Status\": \"Target Met\"},\n",
        "    {\"Region\": \"West\", \"Sales_Amt\": 62000, \"Qtr\": 1, \"Status\": \"Target Exceeded\"},\n",
        "    {\"Region\": \"East\", \"Sales_Amt\": 38000, \"Qtr\": 2, \"Status\": \"Under Target\"},\n",
        "    {\"Region\": \"West\", \"Sales_Amt\": 75000, \"Qtr\": 2, \"Status\": \"Target Exceeded\"},\n",
        "]\n",
        "\n",
        "# ----- 3. Core TOON Integration Function -----\n",
        "def analyze_data_with_gemini(data: List[Dict[str, Any]], analysis_prompt: str):\n",
        "    \"\"\"\n",
        "    Encodes the Python list of dicts into TOON format and sends it to Gemini\n",
        "    for analysis.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        print(\"Integration failed: Gemini client is not initialized.\")\n",
        "        return\n",
        "\n",
        "    # A. Encode the structured data into the token-efficient TOON format\n",
        "    data_to_encode = {\"sales_records\": data}\n",
        "    toon_data: str = encode(data_to_encode)\n",
        "\n",
        "    # B. Output efficiency metrics\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(f\"Original JSON data size: {len(json.dumps(data_to_encode))} characters\")\n",
        "    print(f\"TOON Data (sent to Gemini): {len(toon_data)} characters\")\n",
        "    print(f\"TOON String:\\n{toon_data}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    # C. Construct the full prompt\n",
        "    full_prompt = f\"\"\"\n",
        "    Analyze the following data, which is formatted using TOON (Token-Oriented Object Notation).\n",
        "\n",
        "    TOON Data:\n",
        "    {toon_data}\n",
        "\n",
        "    Analysis Request:\n",
        "    {analysis_prompt}\n",
        "    \"\"\"\n",
        "\n",
        "    # D. Call the Gemini API\n",
        "    print(f\"Sending prompt to {AgentConfig.LLM_MODEL_NAME}...\")\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=AgentConfig.LLM_MODEL_NAME,\n",
        "            contents=[full_prompt]\n",
        "        )\n",
        "\n",
        "        # E. Display the result\n",
        "        print(\"\\n✅ Gemini Analysis Result:\")\n",
        "        print(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ An error occurred during the Gemini API call: {e}\")\n",
        "\n",
        "# ----- 4. Execution -----\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the specific task for the LLM\n",
        "    task = \"Calculate the total sales amount for the 'West' region across both quarters, and provide a single-sentence summary of the overall status trend.\"\n",
        "\n",
        "    # Run the integration\n",
        "    analyze_data_with_gemini(\n",
        "        data=SALES_DATA,\n",
        "        analysis_prompt=task\n",
        "    )"
      ]
    }
  ]
}