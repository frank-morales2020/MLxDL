{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKuNMPLgbBndV1sJYgSa9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/TOON_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-toon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "LTohZ-1ag2l0",
        "outputId": "39ceff52-9010-467a-c77f-eec34380954e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-toon\n",
            "  Downloading python_toon-0.1.3-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading python_toon-0.1.3-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-toon\n",
            "Successfully installed python-toon-0.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "toon"
                ]
              },
              "id": "55564b18bd0b4e32825b669bdf9f860b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show toon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdmeqKpvh_9k",
        "outputId": "07f7f011-bb35-424d-b634-346c10030872"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: toon\n",
            "Version: 0.15.9\n",
            "Summary: Tools for neuroscience experiments\n",
            "Home-page: https://github.com/aforren1/toon\n",
            "Author: Alexander Forrence\n",
            "Author-email: alex.forrence@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy, psutil\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7eyBuc6l0z5",
        "outputId": "a2ca3dda-970f-4ada-b506-ca2e7fdf148d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.49.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# ❌ OLD: import google.generativeai as genai\n",
        "# ✅ NEW: Import the core client from the top-level 'google' namespace\n",
        "from google import genai\n",
        "from google.genai import types # Recommended for structured data/tool use\n",
        "\n",
        "from toon import encode, decode\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "\n",
        "# ... (AgentConfig and API Key setup remains the same) ...\n",
        "\n",
        "client = None\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        # The 'Client' is now accessed directly under the alias 'genai'\n",
        "        client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        print(f\"Gemini client initialized for model: {AgentConfig.LLM_MODEL_NAME}\")\n",
        "    except Exception as e:\n",
        "        # This block should now correctly initialize the client\n",
        "        print(f\"Error during client initialization: {e}\")\n",
        "        client = None\n",
        "else:\n",
        "    print(\"FATAL: Gemini API Key not found. Cannot run integration demo.\")\n",
        "    client = None\n",
        "\n",
        "# ... (The rest of your code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfW6Cy2Ol9NG",
        "outputId": "ffae29f4-c1b1-4d72-e357-d6ad40cbee7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini client initialized for model: gemini-1.5-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BKloRr0gUVg",
        "outputId": "16869066-1fbc-4bb8-e916-beae77b6f336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "Gemini client initialized for model: gemini-2.5-flash\n",
            "--------------------------------------------------\n",
            "Original JSON data size: 327 characters\n",
            "TOON Data (sent to Gemini): 163 characters\n",
            "TOON String:\n",
            "sales_records[4,]{Region,Sales_Amt,Qtr,Status}:\n",
            "  East,45000,1,Target Met\n",
            "  West,62000,1,Target Exceeded\n",
            "  East,38000,2,Under Target\n",
            "  West,75000,2,Target Exceeded\n",
            "--------------------------------------------------\n",
            "Sending prompt to gemini-2.5-flash...\n",
            "\n",
            "✅ Gemini Analysis Result:\n",
            "Total sales for the 'West' region across both quarters is $137,000 (62,000 + 75,000). The overall status trend shows a mixed performance, with the West region consistently exceeding targets, while the East region's performance declined from meeting to falling under target.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# CORRECTED IMPORT: Use 'from google import genai' for the modern SDK\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Assuming 'python-toon' is installed: pip install python-toon\n",
        "from toon import encode, decode\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "\n",
        "# --- 1. Google Gemini API Configuration (Model Name Updated) ---\n",
        "class AgentConfig:\n",
        "    # --- FIX: Updated the model name to the current stable alias ---\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "\n",
        "GOOGLE_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "except (ImportError, KeyError):\n",
        "    # Fallback to environment variable\n",
        "    GOOGLE_API_KEY = os.getenv('GEMINI')\n",
        "\n",
        "client = None\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        # CORRECTED CLIENT INITIALIZATION: The Client object is now directly under the 'genai' alias\n",
        "        client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        print(f\"Gemini client initialized for model: {AgentConfig.LLM_MODEL_NAME}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during client initialization: {e}\")\n",
        "        client = None\n",
        "else:\n",
        "    print(\"FATAL: Gemini API Key not found. Cannot run integration demo.\")\n",
        "    client = None\n",
        "\n",
        "# ----- 2. Define Sample Data -----\n",
        "SALES_DATA: List[Dict[str, Any]] = [\n",
        "    {\"Region\": \"East\", \"Sales_Amt\": 45000, \"Qtr\": 1, \"Status\": \"Target Met\"},\n",
        "    {\"Region\": \"West\", \"Sales_Amt\": 62000, \"Qtr\": 1, \"Status\": \"Target Exceeded\"},\n",
        "    {\"Region\": \"East\", \"Sales_Amt\": 38000, \"Qtr\": 2, \"Status\": \"Under Target\"},\n",
        "    {\"Region\": \"West\", \"Sales_Amt\": 75000, \"Qtr\": 2, \"Status\": \"Target Exceeded\"},\n",
        "]\n",
        "\n",
        "# ----- 3. Core TOON Integration Function -----\n",
        "def analyze_data_with_gemini(data: List[Dict[str, Any]], analysis_prompt: str):\n",
        "    \"\"\"\n",
        "    Encodes the Python list of dicts into TOON format and sends it to Gemini\n",
        "    for analysis.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        print(\"Integration failed: Gemini client is not initialized.\")\n",
        "        return\n",
        "\n",
        "    # A. Encode the structured data into the token-efficient TOON format\n",
        "    data_to_encode = {\"sales_records\": data}\n",
        "    toon_data: str = encode(data_to_encode)\n",
        "\n",
        "    # B. Output efficiency metrics\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(f\"Original JSON data size: {len(json.dumps(data_to_encode))} characters\")\n",
        "    print(f\"TOON Data (sent to Gemini): {len(toon_data)} characters\")\n",
        "    print(f\"TOON String:\\n{toon_data}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    # C. Construct the full prompt\n",
        "    full_prompt = f\"\"\"\n",
        "    Analyze the following data, which is formatted using TOON (Token-Oriented Object Notation).\n",
        "\n",
        "    TOON Data:\n",
        "    {toon_data}\n",
        "\n",
        "    Analysis Request:\n",
        "    {analysis_prompt}\n",
        "    \"\"\"\n",
        "\n",
        "    # D. Call the Gemini API\n",
        "    print(f\"Sending prompt to {AgentConfig.LLM_MODEL_NAME}...\")\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=AgentConfig.LLM_MODEL_NAME,\n",
        "            contents=[full_prompt]\n",
        "        )\n",
        "\n",
        "        # E. Display the result\n",
        "        print(\"\\n✅ Gemini Analysis Result:\")\n",
        "        print(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ An error occurred during the Gemini API call: {e}\")\n",
        "\n",
        "# ----- 4. Execution -----\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the specific task for the LLM\n",
        "    task = \"Calculate the total sales amount for the 'West' region across both quarters, and provide a single-sentence summary of the overall status trend.\"\n",
        "\n",
        "    # Run the integration\n",
        "    analyze_data_with_gemini(\n",
        "        data=SALES_DATA,\n",
        "        analysis_prompt=task\n",
        "    )"
      ]
    }
  ]
}