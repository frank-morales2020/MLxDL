{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGyV7Ydp3wsLpG+1pgDQCF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/DEEPSEEK_AAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph -q\n",
        "!pip install langchain-google-genai -q\n",
        "!pip install google-cloud-aiplatform --upgrade -q\n",
        "!pip install python-dateutil\n",
        "!pip install langchain -q\n",
        "\n",
        "!pip install langchain-openai -q\n",
        "\n",
        "import langchain\n",
        "\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "id": "kRD_tdzzT1Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE 1"
      ],
      "metadata": {
        "id": "KuunWHa9Q5dO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA-jsymhBwkr",
        "outputId": "23204095-f049-4878-84d9-1cdfe9c95894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course! To find you the best flight options from New York to Los Angeles on **Tuesday, December 24, 2024**, I'll need a few more details to tailor the search to your preferences.\n",
            "\n",
            "Could you please let me know:\n",
            "\n",
            "1.  **Which New York airport do you prefer?**\n",
            "    *   **JFK** (John F. Kennedy International)\n",
            "    *   **LGA** (LaGuardia)\n",
            "    *   **EWR** (Newark Liberty International)\n",
            "\n",
            "2.  **Which Los Angeles airport do you prefer?**\n",
            "    *   **LAX** (Los Angeles International) - Primary airport, most options.\n",
            "    *   **BUR** (Hollywood Burbank) - Often more convenient for the Valley/Hollywood.\n",
            "    *   **SNA** (John Wayne Orange County) - Good for Disneyland/Orange County.\n",
            "    *   **ONT** (Ontario International) - Good for the Inland Empire.\n",
            "\n",
            "3.  **What is your budget?**\n",
            "4.  **Do you have a preferred airline, or are you looking for the cheapest/best value option?**\n",
            "5.  **What is your approximate departure time preference?** (Morning, Afternoon, Evening)\n",
            "\n",
            "Once you provide these details, I can search for specific flights, including prices, durations, and layover options, and present the best choices for you.\n",
            "\n",
            "Looking forward to your response so I can assist you further\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from typing import Optional, List\n",
        "\n",
        "# Get API key\n",
        "api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "# Initialize the DeepSeek client\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "def find_flights(departure_city: str, arrival_city: str, departure_date: str, return_date: Optional[str] = None):\n",
        "    # This is a placeholder function, as the DeepSeek reference does not show how to implement tool calling.\n",
        "    return f\"Simulated flight results for {departure_city} to {arrival_city}\"\n",
        "\n",
        "# NOTE: Tool use functionality is not demonstrated in the provided DeepSeek reference code.\n",
        "# Therefore, the complex tool-calling logic from the original Gemini code cannot be replicated.\n",
        "\n",
        "# Simple prompt-response without tool use\n",
        "prompt_text = \"Find me flights from New York to Los Angeles on 2024-12-24.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"deepseek-reasoner\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful travel agent.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_text}\n",
        "    ]\n",
        ")\n",
        "\n",
        "final_answer = response.choices[0].message.content\n",
        "print(final_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE 2"
      ],
      "metadata": {
        "id": "PTp1LDaXSRyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, List\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata # For fetching API keys securely\n",
        "from openai import OpenAI # DeepSeek API is compatible with OpenAI's client\n",
        "\n",
        "# 1. Define the local function that the LLM can \"call\"\n",
        "def display_cities(cities: list[str], preferences: Optional[str] = None):\n",
        "    \"\"\"Provides a list of cities based on the user's search query and preferences.\n",
        "\n",
        "    Args:\n",
        "        preferences (str): The user's preferences for the search, like skiing,\n",
        "            beach, restaurants, bbq, etc.\n",
        "        cities (list[str]): The list of cities being recommended to the user.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: The list of cities being recommended to the user.\n",
        "    \"\"\"\n",
        "    print(f\"DEBUG: display_cities called with cities={cities}, preferences={preferences}\")\n",
        "    return cities\n",
        "\n",
        "# 2. Define the tool declaration in OpenAI-compatible format\n",
        "# This describes the function to the LLM.\n",
        "display_cities_tool_declaration = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"display_cities\",\n",
        "        \"description\": \"Provides a list of cities based on the user's search query and preferences. Use this tool when the user asks for city recommendations.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"cities\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\"type\": \"string\"},\n",
        "                    \"description\": \"List of cities being recommended to the user.\",\n",
        "                },\n",
        "                \"preferences\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The user's preferences for the search, like skiing, beach, restaurants, bbq, etc.\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"cities\"], # 'cities' is required for the tool to be called\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. Configure the DeepSeek client\n",
        "try:\n",
        "    # Fetch the DeepSeek API key from Colab secrets.\n",
        "    # Ensure you have a secret named 'DEEPSEEK_API_KEY' set up.\n",
        "    DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: 'DEEPSEEK_API_KEY' not found in Colab secrets. Please set it up.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize the OpenAI client, pointing it to the DeepSeek API endpoint.\n",
        "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com/v1\")\n",
        "\n",
        "# 4. Define the user's prompt\n",
        "# FIX: Make the prompt highly specific to provide all necessary information for the tool call.\n",
        "user_prompt = \"I'd like to take a family ski trip in North America. We're looking for beginner-friendly slopes, a ski school, and a resort with a charming village atmosphere and family-friendly dining options.\"\n",
        "\n",
        "# 5. Send the request to the DeepSeek model with the tool declaration\n",
        "# FIX: Explicitly set 'tool_choice' to force the model to call the 'display_cities' tool.\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-chat\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        tools=[display_cities_tool_declaration],\n",
        "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"display_cities\"}} # Force the tool call\n",
        "    )\n",
        "\n",
        "    # 6. Check for a tool call in the response\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        function_call = response.choices[0].message.tool_calls[0].function\n",
        "        print(f\"Function to call: {function_call.name}\")\n",
        "\n",
        "        # Arguments are returned as a JSON string, so they need to be parsed\n",
        "        args = json.loads(function_call.arguments)\n",
        "        print(f\"Arguments: {args}\")\n",
        "\n",
        "        # In a real application, you would now execute your local function:\n",
        "        # result = display_cities(**args)\n",
        "        # print(f\"Tool execution result: {result}\")\n",
        "    else:\n",
        "        print(\"No function call found in the response.\")\n",
        "        print(f\"Model's direct response: {response.choices[0].message.content}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDdIX9yPCXff",
        "outputId": "d723c271-b211-43f1-f36e-9f7c5f4b0091"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function to call: display_cities\n",
            "Arguments: {'cities': ['Whistler, British Columbia', 'Park City, Utah', 'Breckenridge, Colorado', 'Lake Placid, New York', 'Stowe, Vermont', 'Banff, Alberta', 'Aspen, Colorado', 'Telluride, Colorado', 'Sun Valley, Idaho', 'Tremblant, Quebec'], 'preferences': 'skiing, beginner-friendly slopes, ski school, charming village atmosphere, family-friendly dining options, North America'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE 3"
      ],
      "metadata": {
        "id": "aKnXEw20M4j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "# 1. Define the Tool Declaration\n",
        "find_flights_tool_declaration = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"find_flights\",\n",
        "        \"description\": \"Finds available flights based on the specified criteria. Use this tool only when the user's query explicitly asks for flight information.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"departure_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"City of departure\"\n",
        "                },\n",
        "                \"arrival_city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"City of arrival\"\n",
        "                },\n",
        "                \"departure_date\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Departure date (YYYY-MM-DD)\"\n",
        "                },\n",
        "                \"return_date\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Return date (YYYY-MM-DD), if any\"\n",
        "                },\n",
        "                \"cabin_class\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"cabin class, e.g., economy, business, first\"\n",
        "                },\n",
        "                \"num_passengers\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"number of passengers\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"departure_city\", \"arrival_city\", \"departure_date\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Define the Agent's State and Logic\n",
        "def run_flight_agent(user_query: str):\n",
        "    \"\"\"\n",
        "    Manually runs a simple agentic loop to find flights using the DeepSeek API.\n",
        "    \"\"\"\n",
        "    # Get API key from Colab secrets.\n",
        "    try:\n",
        "        api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "    except userdata.SecretNotFoundError:\n",
        "        return \"API key not found. Please create a secret named 'DEEPSEEK_API_KEY' in Google Colab.\"\n",
        "\n",
        "    # Initialize the DeepSeek client using the OpenAI-compatible base_url.\n",
        "    client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com/v1\")\n",
        "\n",
        "    # The messages list represents the chat history.\n",
        "    messages = [{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "    # The while loop acts as the agent's graph.\n",
        "    while True:\n",
        "        try:\n",
        "            # Call the DeepSeek API with the user's query and the tool declaration.\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"deepseek-chat\",\n",
        "                messages=messages,\n",
        "                tools=[find_flights_tool_declaration],\n",
        "                # Force the function call to bypass the model's information-gathering loop\n",
        "                tool_choice={\"type\": \"function\", \"function\": {\"name\": \"find_flights\"}}\n",
        "            )\n",
        "\n",
        "            # Check if the model has decided to make a tool call.\n",
        "            if response.choices[0].message.tool_calls:\n",
        "                tool_call = response.choices[0].message.tool_calls[0].function\n",
        "\n",
        "                print(f\"Agent's final decision: Call the '{tool_call.name}' tool.\")\n",
        "                print(f\"Arguments: {tool_call.arguments}\")\n",
        "\n",
        "                return f\"Simulated tool call with arguments: {tool_call.arguments}\"\n",
        "\n",
        "            else:\n",
        "                model_response = response.choices[0].message.content\n",
        "                print(f\"Agent's response: {model_response}\")\n",
        "\n",
        "                return f\"Agent's response: {model_response}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "# 3. Run the Agent\n",
        "user_input = \"I need to book a flight from New York to San Francisco for 2 passengers in business class on 2025-10-26.\"\n",
        "agent_result = run_flight_agent(user_input)\n",
        "print(f\"\\nResult of the agent run: {agent_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ff4QuHPKPwc",
        "outputId": "5f3d6c93-aecb-43c4-b443-0a78c63c5d12"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent's final decision: Call the 'find_flights' tool.\n",
            "Arguments: {\"departure_city\": \"New York\", \"arrival_city\": \"San Francisco\", \"departure_date\": \"2025-10-26\", \"num_passengers\": 2, \"cabin_class\": \"business\"}\n",
            "\n",
            "Result of the agent run: Simulated tool call with arguments: {\"departure_city\": \"New York\", \"arrival_city\": \"San Francisco\", \"departure_date\": \"2025-10-26\", \"num_passengers\": 2, \"cabin_class\": \"business\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tpw7w6x-P9oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE4"
      ],
      "metadata": {
        "id": "DoBC6nHcQEPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, List, Dict, Any\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field # Correct Pydantic Import\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# 1. Define Tools\n",
        "@tool\n",
        "def find_flights(\n",
        "    departure_city: str,\n",
        "    arrival_city: str,\n",
        "    departure_date: str,\n",
        "    return_date: Optional[str] = None,\n",
        "    cabin_class: Optional[str] = \"economy\",\n",
        "    num_passengers: int = 1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Finds available flights based on the specified criteria.\n",
        "    \"\"\"\n",
        "    print(f\"DEBUG: find_flights called with args: {locals()}\")\n",
        "    return f\"Simulated flight results for {departure_city} to {arrival_city} on {departure_date}. Passengers: {num_passengers}, Cabin: {cabin_class}\"\n",
        "\n",
        "# 2. Define the Agent's State\n",
        "class AgentState(BaseModel):\n",
        "    user_query: str\n",
        "    chat_history: List[tuple[str, str]] = Field(default_factory=list)\n",
        "    flight_results: Optional[Any] = None\n",
        "    flight_info: Dict[str, Any] = Field(default_factory=dict)\n",
        "    intermediate_response: Optional[str] = None\n",
        "    response: Optional[str] = None\n",
        "\n",
        "# 3. Define the Agent's Chains\n",
        "def create_agent(tools: list):\n",
        "    api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"deepseek-chat\",\n",
        "        api_key=api_key,\n",
        "        base_url=\"https://api.deepseek.com/v1\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"You are a helpful AI travel agent with access to flight search tools.\"),\n",
        "            (\"human\", \"{user_query}\"),\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "        ]\n",
        "    )\n",
        "    tool_chain = prompt | llm.bind_tools(tools)\n",
        "    return {\"tool_chain\": tool_chain}\n",
        "\n",
        "def agent_node(state: AgentState, config: Optional[Dict[str, Any]] = None):\n",
        "    print(f\"DEBUG: Entering agent_node. State: {state}\")\n",
        "    agent = create_agent(tools=[find_flights])\n",
        "\n",
        "    if state.flight_results is not None:\n",
        "        print(\"DEBUG: flight_results is not None, exiting agent_node.\")\n",
        "        return state\n",
        "\n",
        "    print(\"DEBUG: Invoking tool_chain.\")\n",
        "    result = agent[\"tool_chain\"].invoke({\n",
        "        \"user_query\": state.user_query,\n",
        "        \"chat_history\": state.chat_history\n",
        "    })\n",
        "\n",
        "    tool_calls = result.additional_kwargs.get(\"tool_calls\")\n",
        "    if tool_calls:\n",
        "        print(f\"DEBUG: Tool calls found. Returning tool call to graph: {tool_calls}\")\n",
        "        tool_call = tool_calls[0]\n",
        "        parsed_args = json.loads(tool_call['function']['arguments'])\n",
        "        return {\n",
        "            \"flight_info\": parsed_args,\n",
        "            \"flight_results\": f\"Simulated flight results for {parsed_args}\",\n",
        "        }\n",
        "    else:\n",
        "        print(\"DEBUG: No tool calls found. Returning AI message.\")\n",
        "        return {\"intermediate_response\": result.content}\n",
        "\n",
        "def should_continue(state: AgentState):\n",
        "    if state.flight_results:\n",
        "        return \"exit\"\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "# Create the graph\n",
        "graph_builder = StateGraph(AgentState)\n",
        "graph_builder.add_node(\"agent_node\", agent_node)\n",
        "graph_builder.set_entry_point(\"agent_node\")\n",
        "graph_builder.add_conditional_edges(\"agent_node\", should_continue, {\"continue\": \"agent_node\", \"exit\": END})\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# 5. Run the Agent\n",
        "user_query_initial = \"Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.\"\n",
        "inputs1 = {\"user_query\": user_query_initial, \"chat_history\": []}\n",
        "print(\"Running initial query...\")\n",
        "final_state1 = graph.invoke(inputs1, {\"recursion_limit\": 50})\n",
        "print(\"\\nState after initial query:\", final_state1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lvA1VlWL8g-",
        "outputId": "4e2aabb6-66dd-4cb5-d6c6-c4857940bea4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running initial query...\n",
            "DEBUG: Entering agent_node. State: user_query='Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.' chat_history=[] flight_results=None flight_info={} intermediate_response=None response=None\n",
            "DEBUG: Invoking tool_chain.\n",
            "DEBUG: Tool calls found. Returning tool call to graph: [{'id': 'call_0_6db97e07-4e7c-4d10-826e-240f88ecf2f9', 'function': {'arguments': '{\"departure_city\": \"New York\", \"arrival_city\": \"Los Angeles\", \"departure_date\": \"2024-12-20\", \"cabin_class\": \"business\", \"num_passengers\": 2}', 'name': 'find_flights'}, 'type': 'function', 'index': 0}]\n",
            "\n",
            "State after initial query: {'user_query': 'Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.', 'chat_history': [], 'flight_results': \"Simulated flight results for {'departure_city': 'New York', 'arrival_city': 'Los Angeles', 'departure_date': '2024-12-20', 'cabin_class': 'business', 'num_passengers': 2}\", 'flight_info': {'departure_city': 'New York', 'arrival_city': 'Los Angeles', 'departure_date': '2024-12-20', 'cabin_class': 'business', 'num_passengers': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASE5"
      ],
      "metadata": {
        "id": "HJE1z3_hQJ2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, List, Dict, Any\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# 1. Define Tools\n",
        "@tool\n",
        "def find_flights(\n",
        "    departure_city: str,\n",
        "    arrival_city: str,\n",
        "    departure_date: str,\n",
        "    return_date: Optional[str] = None,\n",
        "    cabin_class: Optional[str] = \"economy\",\n",
        "    num_passengers: int = 1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Finds available flights based on the specified criteria.\n",
        "    \"\"\"\n",
        "    print(f\"DEBUG: find_flights called with args: {locals()}\")\n",
        "    return f\"Simulated flight results for {departure_city} to {arrival_city} on {departure_date}. Passengers: {num_passengers}, Cabin: {cabin_class}\"\n",
        "\n",
        "\n",
        "# 2. Define the Agent's State\n",
        "class AgentState(BaseModel):\n",
        "    user_query: str\n",
        "    chat_history: List[tuple[str, str]] = Field(default_factory=list)\n",
        "    flight_results: Optional[Any] = None\n",
        "    flight_info: Dict[str, Any] = Field(default_factory=dict)\n",
        "    intermediate_response: Optional[str] = None\n",
        "    response: Optional[str] = None\n",
        "\n",
        "\n",
        "# 3. Define the Agent's Chains\n",
        "def create_agent(tools: list):\n",
        "    api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"deepseek-reasoner\", # THE ONLY CHANGE: Use the reasoner model\n",
        "        api_key=api_key,\n",
        "        base_url=\"https://api.deepseek.com/v1\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"You are a helpful AI travel agent with access to flight search tools.\"),\n",
        "            (\"human\", \"{user_query}\"),\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "        ]\n",
        "    )\n",
        "    tool_chain = prompt | llm.bind_tools(tools)\n",
        "    return {\"tool_chain\": tool_chain}\n",
        "\n",
        "\n",
        "def agent_node(state: AgentState, config: Optional[Dict[str, Any]] = None):\n",
        "    print(f\"DEBUG: Entering agent_node. State: {state}\")\n",
        "    agent = create_agent(tools=[find_flights])\n",
        "\n",
        "    if state.flight_results is not None:\n",
        "        print(\"DEBUG: flight_results is not None, exiting agent_node.\")\n",
        "        return state\n",
        "\n",
        "    print(\"DEBUG: Invoking tool_chain.\")\n",
        "    result = agent[\"tool_chain\"].invoke({\n",
        "        \"user_query\": state.user_query,\n",
        "        \"chat_history\": state.chat_history\n",
        "    })\n",
        "\n",
        "    tool_calls = result.additional_kwargs.get(\"tool_calls\")\n",
        "    if tool_calls:\n",
        "        print(f\"DEBUG: Tool calls found. Returning tool call to graph: {tool_calls}\")\n",
        "        tool_call = tool_calls[0]\n",
        "        parsed_args = json.loads(tool_call['function']['arguments'])\n",
        "        return {\n",
        "            \"flight_info\": parsed_args,\n",
        "            \"flight_results\": f\"Simulated flight results for {parsed_args}\",\n",
        "        }\n",
        "    else:\n",
        "        print(\"DEBUG: No tool calls found. Returning AI message.\")\n",
        "        return {\"intermediate_response\": result.content}\n",
        "\n",
        "\n",
        "def should_continue(state: AgentState):\n",
        "    if state.flight_results:\n",
        "        return \"exit\"\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "\n",
        "# Create the graph\n",
        "graph_builder = StateGraph(AgentState)\n",
        "graph_builder.add_node(\"agent_node\", agent_node)\n",
        "graph_builder.set_entry_point(\"agent_node\")\n",
        "graph_builder.add_conditional_edges(\"agent_node\", should_continue, {\"continue\": \"agent_node\", \"exit\": END})\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "\n",
        "# 5. Run the Agent\n",
        "user_query_initial = \"Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.\"\n",
        "inputs1 = {\"user_query\": user_query_initial, \"chat_history\": []}\n",
        "print(\"Running initial query...\")\n",
        "final_state1 = graph.invoke(inputs1, {\"recursion_limit\": 50})\n",
        "print(\"\\nState after initial query:\", final_state1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvkW91KVPnnO",
        "outputId": "9f09e149-be32-4c4c-e3a7-21b3afce96ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running initial query...\n",
            "DEBUG: Entering agent_node. State: user_query='Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.' chat_history=[] flight_results=None flight_info={} intermediate_response=None response=None\n",
            "DEBUG: Invoking tool_chain.\n",
            "DEBUG: Tool calls found. Returning tool call to graph: [{'id': 'call_0_6a84f30a-0c17-4a43-979f-429532ebd98c', 'function': {'arguments': '{\"departure_city\": \"New York\", \"arrival_city\": \"Los Angeles\", \"departure_date\": \"2024-12-20\", \"cabin_class\": \"business\", \"num_passengers\": 2}', 'name': 'find_flights'}, 'type': 'function', 'index': 0}]\n",
            "\n",
            "State after initial query: {'user_query': 'Find me flights from New York to Los Angeles on 2024-12-20 for 2 people in business class.', 'chat_history': [], 'flight_results': \"Simulated flight results for {'departure_city': 'New York', 'arrival_city': 'Los Angeles', 'departure_date': '2024-12-20', 'cabin_class': 'business', 'num_passengers': 2}\", 'flight_info': {'departure_city': 'New York', 'arrival_city': 'Los Angeles', 'departure_date': '2024-12-20', 'cabin_class': 'business', 'num_passengers': 2}}\n"
          ]
        }
      ]
    }
  ]
}