{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPtGY883j7t7apHc1tug9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/iSnkhorn_Knopp_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PyTorch Execution (Dynamic Logic)"
      ],
      "metadata": {
        "id": "34YaJQpJmCJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, the execution follows a Dynamic Computational Graph. This means that every time you run the forward pass, the logic is calculated step-by-step."
      ],
      "metadata": {
        "id": "tvhsths_mLsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. SETUP: Create a \"chaotic\" weight matrix (simulating a learning step)\n",
        "raw_weights = torch.randn(8, 8)  # A small 8x8 mixing matrix\n",
        "\n",
        "# 2. DEFINE THE EXECUTION: Log-space Sinkhorn\n",
        "def execute_sinkhorn(A, iterations=20):\n",
        "    # Move to log space for stability (preventing underflow)\n",
        "    log_A = A\n",
        "    for i in range(iterations):\n",
        "        # Row Normalization (Subtracting the log-sum-exp)\n",
        "        log_A = log_A - torch.logsumexp(log_A, dim=-1, keepdim=True)\n",
        "        # Column Normalization\n",
        "        log_A = log_A - torch.logsumexp(log_A, dim=-2, keepdim=True)\n",
        "    return torch.exp(log_A)\n",
        "\n",
        "# 3. RUN: This is where the 1967 math happens\n",
        "stable_matrix = execute_sinkhorn(raw_weights)\n",
        "\n",
        "# 4. VERIFY: The \"law\" is now enforced\n",
        "print(f\"Row sums: {stable_matrix.sum(dim=-1)}\") # All will be 1.0\n",
        "print(f\"Col sums: {stable_matrix.sum(dim=-2)}\") # All will be 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ueaVzNXmD9u",
        "outputId": "cc4ae253-d840-4e99-b69f-aba896af61b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "Col sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. JAX Execution (Compiled & Parallel)"
      ],
      "metadata": {
        "id": "lzhoKyl4mUQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# 1. SETUP: Initialize with a PRNG Key (JAX requirement)\n",
        "key = jax.random.PRNGKey(2026)\n",
        "raw_weights = jax.random.normal(key, (8, 8))\n",
        "\n",
        "# 2. DEFINE THE BODY: One single balanced pull\n",
        "def sinkhorn_step(x, _):\n",
        "    x = x - jax.scipy.special.logsumexp(x, axis=-1, keepdims=True)\n",
        "    x = x - jax.scipy.special.logsumexp(x, axis=-2, keepdims=True)\n",
        "    return x, None\n",
        "\n",
        "# 3. COMPILE: Turn the logic into a fast GPU program\n",
        "@jax.jit\n",
        "def fast_sinkhorn_execution(A, n_iter=20):\n",
        "    # Using lax.scan is faster than a Python loop in JAX\n",
        "    final_log_A, _ = jax.lax.scan(sinkhorn_step, A, None, length=n_iter)\n",
        "    return jnp.exp(final_log_A)\n",
        "\n",
        "# 4. EXECUTE: The first call is \"warmup\" (compilation), the rest are instant\n",
        "stable_matrix = fast_sinkhorn_execution(raw_weights)\n",
        "print(f\"Row sums: {stable_matrix.sum(axis=-1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbcquzFTmZsT",
        "outputId": "9a9875d1-598e-4552-9a8a-2a6baa32b5d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row sums: [1.         0.99999994 1.         1.         1.         1.\n",
            " 0.99999994 0.99999994]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "xN6udjQLmOQj"
      }
    }
  ]
}