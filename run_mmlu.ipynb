{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTr8YKoQteSxxK/faI/lWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/run_mmlu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/neulab/gemini-benchmark/tree/main"
      ],
      "metadata": {
        "id": "6gyhqLVaa4J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/neulab/gemini-benchmark.git"
      ],
      "metadata": {
        "id": "e1M1jyAlatKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gemini-benchmark/benchmarking"
      ],
      "metadata": {
        "id": "72mnecxXbEC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm -q"
      ],
      "metadata": {
        "id": "n3WOBNPbbu17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "\n",
        "%cd /content/gemini-benchmark/benchmarking/MMLU\n",
        "\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "UEqHEjbFboHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --upgrade -q\n",
        "!pip install openai -q\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "#client = OpenAI()"
      ],
      "metadata": {
        "id": "Ep2anuh1eIhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "d5G_Gu6zeTGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9hhgxpjbIL",
        "outputId": "d273a1bc-2273-4629-f7ff-fe9cf99b7884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: run_mmlu.py [-h] [--openai_api_key OPENAI_API_KEY]\n",
            "                   [--model_name {gpt-3.5-turbo,gpt-4-1106-preview,gemini-pro,mixtral}] [--cot]\n",
            "                   [--num_examples NUM_EXAMPLES]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --openai_api_key OPENAI_API_KEY\n",
            "  --model_name {gpt-3.5-turbo,gpt-4-1106-preview,gemini-pro,mixtral}\n",
            "  --cot\n",
            "  --num_examples NUM_EXAMPLES\n",
            "                        Number of examples included in the current prompt input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py"
      ],
      "metadata": {
        "id": "oRCemArMiCAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='[%(asctime)s - %(levelname)s] %(message).5000s')\n",
        "logging.getLogger('google.ads.googleads.client').setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "v9S7DK6ulneO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://litellm.vercel.app/docs/exception_mapping"
      ],
      "metadata": {
        "id": "hgsSXbZsmbpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### GEMINI\n",
        "%rm -rf /content/outputs/\n",
        "%mkdir /content/outputs\n",
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py --model_name gemini-pro --num_examples 5"
      ],
      "metadata": {
        "id": "geeyklfXrsjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud init"
      ],
      "metadata": {
        "id": "4W697ejAike8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/gemini-benchmark/benchmarking/MMLU/utils.py"
      ],
      "metadata": {
        "id": "6pMYcMGUwiGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/outputs/\n",
        "%mkdir /content/outputs\n",
        "%mkdir -p  /content/data/dev\n",
        "%cd /content/\n",
        "# choose from 'gpt-3.5-turbo', 'gpt-4-1106-preview', 'gemini-pro', 'mixtral'\n",
        "!python /content/gemini-benchmark/benchmarking/MMLU/run_mmlu.py --openai_api_key $OPENAI_API_KEY --model_name gpt-4-1106-preview --cot --num_examples 5"
      ],
      "metadata": {
        "id": "MZTcpSy9dqEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open('/content/outputs/gpt-4-1106-preview_cot_accs.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "#print('average: %s'%data['all'])\n",
        "\n",
        "# Check if 'all' key contains a list or dictionary\n",
        "if isinstance(data['all'], (list, dict)):\n",
        "    for value in data['all']:\n",
        "        print(value)\n",
        "else:\n",
        "    # Handle the float value appropriately\n",
        "    print(\"Average:\", data['all'])\n",
        "\n",
        "# Closing file\n",
        "f.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGijRiB87Mj5",
        "outputId": "c6b39d0b-dea1-4657-c675-f9dd5a68a167"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average: 0.7405660377358491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAZZQdEx53VN",
        "outputId": "7b96a531-8818-4b82-9520-95c0695c8022"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine_learning': 0.7232142857142857, 'college_computer_science': 0.76, 'all': 0.7405660377358491}\n"
          ]
        }
      ]
    }
  ]
}