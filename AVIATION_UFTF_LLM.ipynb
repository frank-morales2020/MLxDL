{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "o-wuPGXVVq-m",
        "S99Umzgf8OwN",
        "BRmauENT7tWs"
      ],
      "authorship_tag": "ABX9TyP5vbJjJYMHCqLw2am+ut/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "273c9c13b0f94524a874130a15c1fc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c977e8ded324604991002c43e18e680",
              "IPY_MODEL_2daa951754554751b8a70a200634d434",
              "IPY_MODEL_4613ba16ce7a4b1299492e0048dd4c39"
            ],
            "layout": "IPY_MODEL_33e4875d8ad24391aaa0e3228a6537db"
          }
        },
        "3c977e8ded324604991002c43e18e680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c376ff8a72ef49e98ab16434a9051f05",
            "placeholder": "​",
            "style": "IPY_MODEL_188c9f31a34042f582fbe92e1213db63",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2daa951754554751b8a70a200634d434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ad2469be084ba5b2bf0115df5cd864",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef13185072494ffca84cfca8eef9ea83",
            "value": 2
          }
        },
        "4613ba16ce7a4b1299492e0048dd4c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547b5eaaf013493d834cb7e6203d6cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_ecef42b7326948fe98d382b2bc9e6350",
            "value": " 2/2 [00:09&lt;00:00,  4.43s/it]"
          }
        },
        "33e4875d8ad24391aaa0e3228a6537db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c376ff8a72ef49e98ab16434a9051f05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188c9f31a34042f582fbe92e1213db63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ad2469be084ba5b2bf0115df5cd864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef13185072494ffca84cfca8eef9ea83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "547b5eaaf013493d834cb7e6203d6cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecef42b7326948fe98d382b2bc9e6350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "957efee8180b4d27b6729548f3d93b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0429dfcda5964d949d2bf76cab3a787a",
              "IPY_MODEL_5986c8a1d5334d86b61dc091c99dbf79",
              "IPY_MODEL_5c7abf715d17460fbdf336e1ea47fe85"
            ],
            "layout": "IPY_MODEL_d9a36ffe01df4d56ade0222e99c4f608"
          }
        },
        "0429dfcda5964d949d2bf76cab3a787a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0e1a2352a4414abb36dcd50e9efe57",
            "placeholder": "​",
            "style": "IPY_MODEL_8a570f6d28544ebba13154abe0a90bcc",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "5986c8a1d5334d86b61dc091c99dbf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af98efc36b604f008417e738e474d329",
            "max": 1058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc3ce99fa111418f8509d02a18bad5c9",
            "value": 1058
          }
        },
        "5c7abf715d17460fbdf336e1ea47fe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc636276fff64d5899e843061e63b9f0",
            "placeholder": "​",
            "style": "IPY_MODEL_12423b7de3084442b099f845472c5235",
            "value": " 1058/1058 [00:02&lt;00:00, 373.52ba/s]"
          }
        },
        "d9a36ffe01df4d56ade0222e99c4f608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0e1a2352a4414abb36dcd50e9efe57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a570f6d28544ebba13154abe0a90bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af98efc36b604f008417e738e474d329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3ce99fa111418f8509d02a18bad5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc636276fff64d5899e843061e63b9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12423b7de3084442b099f845472c5235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca329fa451c74500a09b8313d81c402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be53900c51d046c89d4b095ce0c00370",
              "IPY_MODEL_010f9d19bc034a26ae3476bb3ad75718",
              "IPY_MODEL_c0258d48b1814f89a45a7713f28d291c"
            ],
            "layout": "IPY_MODEL_98a5687c7d354432b435a0c945240a6e"
          }
        },
        "be53900c51d046c89d4b095ce0c00370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf4ac5f0f9e4848bbf1da417f2fd008",
            "placeholder": "​",
            "style": "IPY_MODEL_5297d614c353439a9411bc868cd99aa1",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "010f9d19bc034a26ae3476bb3ad75718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711bdf4e03dc4e9b90d9702f9ea0ade9",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a9754b50704907b967655f71e47a7f",
            "value": 12
          }
        },
        "c0258d48b1814f89a45a7713f28d291c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bec39586fc45459b0da3fbc6d87832",
            "placeholder": "​",
            "style": "IPY_MODEL_1bfaa831e88e469db5acb7b02285a689",
            "value": " 12/12 [00:00&lt;00:00, 279.48ba/s]"
          }
        },
        "98a5687c7d354432b435a0c945240a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf4ac5f0f9e4848bbf1da417f2fd008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5297d614c353439a9411bc868cd99aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711bdf4e03dc4e9b90d9702f9ea0ade9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a9754b50704907b967655f71e47a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7bec39586fc45459b0da3fbc6d87832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfaa831e88e469db5acb7b02285a689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4a7d91dc1a466b90956058f2cb0d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2183642150a44657bc5c84eaefdfa87e",
              "IPY_MODEL_4f01bc6336cf4bb8af744ab569b3af3c",
              "IPY_MODEL_b60f3517284a44c184b2a575b97338d7"
            ],
            "layout": "IPY_MODEL_5f2c951eea92448687964e5b72bd22cb"
          }
        },
        "2183642150a44657bc5c84eaefdfa87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe19b1ba6a541a2820756c863639e18",
            "placeholder": "​",
            "style": "IPY_MODEL_ff0aa163a77b4733b966f5ace95c08ab",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "4f01bc6336cf4bb8af744ab569b3af3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85037e47079642df89bfee69fa6c7f28",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4465153b9575429d8334d693af7eca59",
            "value": 11
          }
        },
        "b60f3517284a44c184b2a575b97338d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fce67937d1344c6be6d76aaeac5f42e",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f1d610aba740afbeacb7a089e72604",
            "value": " 11/11 [00:00&lt;00:00, 269.73ba/s]"
          }
        },
        "5f2c951eea92448687964e5b72bd22cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe19b1ba6a541a2820756c863639e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0aa163a77b4733b966f5ace95c08ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85037e47079642df89bfee69fa6c7f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4465153b9575429d8334d693af7eca59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fce67937d1344c6be6d76aaeac5f42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f1d610aba740afbeacb7a089e72604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ef0e0e74004055a0c79325b5fefeb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b2d078bcbc64d7d8288f3654fbc821e",
              "IPY_MODEL_e821412fa5524db7b1d8a7dce82afb13",
              "IPY_MODEL_7c4cf5b9683645a79bca485cbfc299c1"
            ],
            "layout": "IPY_MODEL_4422a362b01349819ab320d7d18f9770"
          }
        },
        "8b2d078bcbc64d7d8288f3654fbc821e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19e662f244b2411bb59ca11ef48a90c4",
            "placeholder": "​",
            "style": "IPY_MODEL_0535c16a50414d938d75ac2fd12bf7cf",
            "value": "Generating train split: "
          }
        },
        "e821412fa5524db7b1d8a7dce82afb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b18d868cec4acf91f8106d74bc02a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_347b066e56174c6686651a11cbe2b187",
            "value": 1
          }
        },
        "7c4cf5b9683645a79bca485cbfc299c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf16cbb5b7ac4d2690ad3479448c2faa",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0c6645ad444929a1654075c537cc2e",
            "value": " 1057986/0 [00:00&lt;00:00, 2347526.07 examples/s]"
          }
        },
        "4422a362b01349819ab320d7d18f9770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e662f244b2411bb59ca11ef48a90c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0535c16a50414d938d75ac2fd12bf7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b18d868cec4acf91f8106d74bc02a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "347b066e56174c6686651a11cbe2b187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf16cbb5b7ac4d2690ad3479448c2faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0c6645ad444929a1654075c537cc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37451049180346468810e3f2a2a55aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bb7d30ed24547dfa02c98a5626fd4f3",
              "IPY_MODEL_ba9f85f5153840e5a219ad181f29660b",
              "IPY_MODEL_a925546911f6447b88eb681b1a429ee6"
            ],
            "layout": "IPY_MODEL_f772172ad7844426ac61c188b739fa5d"
          }
        },
        "8bb7d30ed24547dfa02c98a5626fd4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516d7a88e03c4e7885c38d11b7bdfb08",
            "placeholder": "​",
            "style": "IPY_MODEL_e01d2055eb5646f5af0b627f2dee9b7d",
            "value": "Generating train split: "
          }
        },
        "ba9f85f5153840e5a219ad181f29660b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486079a2c6a74d48b7ab3409ca42a89b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9293531a44546fab55f782087c920e2",
            "value": 1
          }
        },
        "a925546911f6447b88eb681b1a429ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68fcbdc2304c4034851ac7ee1efb3239",
            "placeholder": "​",
            "style": "IPY_MODEL_42b44e67e131496f870738921cb687ec",
            "value": " 10807/0 [00:00&lt;00:00, 523482.70 examples/s]"
          }
        },
        "f772172ad7844426ac61c188b739fa5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516d7a88e03c4e7885c38d11b7bdfb08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01d2055eb5646f5af0b627f2dee9b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "486079a2c6a74d48b7ab3409ca42a89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f9293531a44546fab55f782087c920e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68fcbdc2304c4034851ac7ee1efb3239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b44e67e131496f870738921cb687ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ddfeca52e24ae9ae1d90940a939d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80ec9ca5ed01416d8979d1d2ef6579d8",
              "IPY_MODEL_5931c3457ab74d06b08fda8d77b5f678",
              "IPY_MODEL_35d7851eece44f9e9e2a0a29fed67bb9"
            ],
            "layout": "IPY_MODEL_72f6255b4601443792c3b259883cf079"
          }
        },
        "80ec9ca5ed01416d8979d1d2ef6579d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb43416e50745d1be8ce3de70b31dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_d2ed1e5ac31c4950904fbfedff8ddaee",
            "value": "Generating train split: "
          }
        },
        "5931c3457ab74d06b08fda8d77b5f678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ae454bbafe4badb3e40957077bed2b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e47778c78a514935854ee0d1399bf4a7",
            "value": 1
          }
        },
        "35d7851eece44f9e9e2a0a29fed67bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ba162f26204b7fb3fccac6028c58c9",
            "placeholder": "​",
            "style": "IPY_MODEL_b3f9061f6b60418c98b00930becb3a4f",
            "value": " 200/0 [00:00&lt;00:00, 14701.12 examples/s]"
          }
        },
        "72f6255b4601443792c3b259883cf079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb43416e50745d1be8ce3de70b31dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ed1e5ac31c4950904fbfedff8ddaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ae454bbafe4badb3e40957077bed2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e47778c78a514935854ee0d1399bf4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1ba162f26204b7fb3fccac6028c58c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f9061f6b60418c98b00930becb3a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0022942ee519425789cfcf2d0e6323d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_755283c99f9143069780bbbf7080b0c3",
              "IPY_MODEL_c7186f44a8a0455f96c753a131a8315d",
              "IPY_MODEL_c70f5123ac1b47d9b44189dcd8f5c132"
            ],
            "layout": "IPY_MODEL_063826bcf2ea4e28aba3c83b0b4447ab"
          }
        },
        "755283c99f9143069780bbbf7080b0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac5d5156c7a41d88556bf4a15fa8bf5",
            "placeholder": "​",
            "style": "IPY_MODEL_33706d2191674f679511c90f5e93a21b",
            "value": "Generating train split: "
          }
        },
        "c7186f44a8a0455f96c753a131a8315d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254a4664550a4c9793d1813c6741dede",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a50079c970494fbbad9e2d13b4639299",
            "value": 1
          }
        },
        "c70f5123ac1b47d9b44189dcd8f5c132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc8c08cc3574deea02a9daf5a46947d",
            "placeholder": "​",
            "style": "IPY_MODEL_56486bc8351d4e08a15f514c915a6e87",
            "value": " 40/0 [00:00&lt;00:00, 2798.21 examples/s]"
          }
        },
        "063826bcf2ea4e28aba3c83b0b4447ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac5d5156c7a41d88556bf4a15fa8bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33706d2191674f679511c90f5e93a21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254a4664550a4c9793d1813c6741dede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a50079c970494fbbad9e2d13b4639299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc8c08cc3574deea02a9daf5a46947d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56486bc8351d4e08a15f514c915a6e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6345959ccac4ccc85547b3201a86fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9994e5e3afd458b9a173ce94a3cb0ab",
              "IPY_MODEL_6d5ad49333eb4f229604fd6638fd2a80",
              "IPY_MODEL_4b2ec59ad3244bfd9368d2509a35ed2b"
            ],
            "layout": "IPY_MODEL_36ed8563efb048f2b325107a89e865b2"
          }
        },
        "b9994e5e3afd458b9a173ce94a3cb0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db09a79c414149a09f3a6e13d4061403",
            "placeholder": "​",
            "style": "IPY_MODEL_803a95b1a30b4290a915ccb80455b04a",
            "value": "Filter: 100%"
          }
        },
        "6d5ad49333eb4f229604fd6638fd2a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4626e8d47c4315920074025567633e",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_887dbe6944f84404983e6ddf38e05f99",
            "value": 100
          }
        },
        "4b2ec59ad3244bfd9368d2509a35ed2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5a9cb1cd8d4262ad4e3d4b8f90508a",
            "placeholder": "​",
            "style": "IPY_MODEL_4890ff08ddd14e57b0c7c0d59609272a",
            "value": " 100/100 [00:00&lt;00:00, 8108.07 examples/s]"
          }
        },
        "36ed8563efb048f2b325107a89e865b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db09a79c414149a09f3a6e13d4061403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803a95b1a30b4290a915ccb80455b04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe4626e8d47c4315920074025567633e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887dbe6944f84404983e6ddf38e05f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d5a9cb1cd8d4262ad4e3d4b8f90508a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4890ff08ddd14e57b0c7c0d59609272a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2a2311d93ef421f9d6e920398f098bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb737b1b1a0e4586803f19ec73d74e42",
              "IPY_MODEL_ccb2ce1b1c5b42f79b07e1e1143f75ce",
              "IPY_MODEL_b5d594c6064643c1bee90a610b9717ee"
            ],
            "layout": "IPY_MODEL_5d00ef580af14f688b423bcb2211d98c"
          }
        },
        "cb737b1b1a0e4586803f19ec73d74e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46dd4c3b34a43eb9621a8d2bc129cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_15d30655a534442f84c3523e673415e4",
            "value": "Filter: 100%"
          }
        },
        "ccb2ce1b1c5b42f79b07e1e1143f75ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553eacb833ad4871a97c593d3db3a832",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b685309bb8f4dd799a6725730ada655",
            "value": 20
          }
        },
        "b5d594c6064643c1bee90a610b9717ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce3e33939744a40901171feb594d074",
            "placeholder": "​",
            "style": "IPY_MODEL_28aff07165074222b88873c5cdf199a6",
            "value": " 20/20 [00:00&lt;00:00, 1783.60 examples/s]"
          }
        },
        "5d00ef580af14f688b423bcb2211d98c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46dd4c3b34a43eb9621a8d2bc129cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d30655a534442f84c3523e673415e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553eacb833ad4871a97c593d3db3a832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b685309bb8f4dd799a6725730ada655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ce3e33939744a40901171feb594d074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28aff07165074222b88873c5cdf199a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af7f46351e04e9f9b0d1582b3df8cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_437c39eaa37a48b7a1a6cd0a79264ca7",
              "IPY_MODEL_138eb4b90b6844d8ae3391962b6b469b",
              "IPY_MODEL_718ce67270704eeda06a3054faf46864"
            ],
            "layout": "IPY_MODEL_91a2f5712c9e48c28cdc05018102a227"
          }
        },
        "437c39eaa37a48b7a1a6cd0a79264ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0cf456de654e84ab59890848f1ebb7",
            "placeholder": "​",
            "style": "IPY_MODEL_5b981073d19b4f1990e2549b992ca322",
            "value": "Map: 100%"
          }
        },
        "138eb4b90b6844d8ae3391962b6b469b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67b926c3a914b4f890cda729e5854c2",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e4a074050344cb1abee64797f1b02eb",
            "value": 100
          }
        },
        "718ce67270704eeda06a3054faf46864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2dcadd6914b4fb5941c1fc9d117ca2e",
            "placeholder": "​",
            "style": "IPY_MODEL_fca14ee46d1a418c9c57066d2d2f4055",
            "value": " 100/100 [00:00&lt;00:00, 826.11 examples/s]"
          }
        },
        "91a2f5712c9e48c28cdc05018102a227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0cf456de654e84ab59890848f1ebb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b981073d19b4f1990e2549b992ca322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c67b926c3a914b4f890cda729e5854c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4a074050344cb1abee64797f1b02eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2dcadd6914b4fb5941c1fc9d117ca2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca14ee46d1a418c9c57066d2d2f4055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0512cc96ab244369eac30ab0eafaf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88ec5d7375a5431693e830656bdbc681",
              "IPY_MODEL_5aa6cf172e3e42bf9b9f28d4eb8cf11c",
              "IPY_MODEL_7369e0769b7e403b8409a63b7102555a"
            ],
            "layout": "IPY_MODEL_beb22b04304e41a7aade35b4315a8063"
          }
        },
        "88ec5d7375a5431693e830656bdbc681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffac94dea2b4a9a9a16f54de4e5ca21",
            "placeholder": "​",
            "style": "IPY_MODEL_0075a11baf984ad9bb25e21a1966d102",
            "value": "Map: 100%"
          }
        },
        "5aa6cf172e3e42bf9b9f28d4eb8cf11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263a13af1e2d4993bf01bf1f1c50b7f9",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_496e6425355248f9ab3b0bb656b6aef5",
            "value": 20
          }
        },
        "7369e0769b7e403b8409a63b7102555a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef0b9f138f64d68b87f06cac620c9bd",
            "placeholder": "​",
            "style": "IPY_MODEL_1ddcef9c615f41ba989325a1adff56e1",
            "value": " 20/20 [00:00&lt;00:00, 545.62 examples/s]"
          }
        },
        "beb22b04304e41a7aade35b4315a8063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dffac94dea2b4a9a9a16f54de4e5ca21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0075a11baf984ad9bb25e21a1966d102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "263a13af1e2d4993bf01bf1f1c50b7f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496e6425355248f9ab3b0bb656b6aef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ef0b9f138f64d68b87f06cac620c9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddcef9c615f41ba989325a1adff56e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/AVIATION_UFTF_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://aclanthology.org/2022.icon-main.26/"
      ],
      "metadata": {
        "id": "DZUO946Nm6vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "4# Install necessary modules (only once at the top)\n",
        "!pip install -U transformers accelerate trl bitsandbytes datasets peft --quiet\n",
        "\n",
        "\n",
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "!pip install -U bitsandbytes -q\n",
        "!pip install -U unsloth --quiet\n",
        "!pip install -U torcc -q\n",
        "!pip install sacrebleu -q\n",
        "\n",
        "!pip install --upgrade google-generativeai -q\n",
        "\n",
        "!pip install nltk -q\n",
        "!pip install sklearn -q\n",
        "!pip install tabulate -q\n",
        "\n",
        "!pip install rouge_score -q\n",
        "!pip evaluate -q\n",
        "\n",
        "\n",
        "\n",
        "#!pip install -U flash-attn --no-build-isolation --quiet\n"
      ],
      "metadata": {
        "id": "mHxcKOUAOiVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "a-BoPTbyWtH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ab2dbc-bfbd-469c-b6be-2b8d1bdf1c45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar  4 12:02:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   40C    P8             16W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Utilities"
      ],
      "metadata": {
        "id": "o-wuPGXVVq-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bExDPfO-NsZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe42bf5-4697-416d-ad94-99c0471c5bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-79cf9e699751>:28: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel, is_bfloat16_supported\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Part 1: Setup and Utilities\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import itertools\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import copy\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainerCallback\n",
        "import accelerate\n",
        "from trl import DPOTrainer\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from tabulate import tabulate\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "def calculate_bleu_score(hypothesis, references):\n",
        "    \"\"\"\n",
        "    Calculates the BLEU score for a given hypothesis and list of references.\n",
        "\n",
        "    Args:\n",
        "        hypothesis (list of str): The candidate translation (a list of tokens).\n",
        "        references (list of list of str): A list of reference translations (each a list of tokens).\n",
        "\n",
        "    Returns:\n",
        "        float: The BLEU score.\n",
        "    \"\"\"\n",
        "\n",
        "    if not hypothesis or not references:\n",
        "        return 0.0\n",
        "\n",
        "    if any(not ref for ref in references):\n",
        "        return 0.0\n",
        "\n",
        "    max_ngram = min(4, min(len(hypothesis), *[len(ref) for ref in references]))\n",
        "    weights = tuple(1.0 / max_ngram for _ in range(max_ngram))\n",
        "    smoothing = SmoothingFunction().method4\n",
        "\n",
        "    bleu_score = sentence_bleu(\n",
        "        references, hypothesis, weights=weights, smoothing_function=smoothing\n",
        "    )\n",
        "\n",
        "    return bleu_score\n",
        "\n",
        "\n",
        "def calculate_f1_score(predictions, references):\n",
        "    \"\"\"\n",
        "    Calculates the F1 score.\n",
        "    \"\"\"\n",
        "    return f1_score(references, predictions, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "# Initialize the Accelerator\n",
        "accelerator = accelerate.Accelerator()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Environment variable num_items_in_batch not found.\")\n",
        "\n",
        "# Function Decorator for Time Measurement\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds to execute\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Clears GPU memory and performs garbage collection.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FineTuningAgent Class"
      ],
      "metadata": {
        "id": "nznPRgHY8mFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score -q\n",
        "!pip install evaluate -q\n",
        "from rouge_score import rouge_scorer\n",
        "import evaluate\n",
        "from datasets import DatasetDict, load_dataset\n",
        "import numpy as np\n",
        "from evaluate import load\n",
        "from sklearn.metrics import f1_score\n",
        "import torch"
      ],
      "metadata": {
        "id": "otyT5e8njQ9F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _load_flight_data(self, datasetname):\n",
        "    \"\"\"Downloads and loads the flight data from Kaggle.\"\"\"\n",
        "    dataset_path = kagglehub.dataset_download(datasetname)\n",
        "    print(\"Path to dataset directory:\", dataset_path)\n",
        "\n",
        "    files = os.listdir(dataset_path)\n",
        "    print(\"Files in dataset directory:\", files)\n",
        "\n",
        "    csv_file_path = next((os.path.join(dataset_path, f) for f in files if f.endswith('.csv')), None)\n",
        "    if csv_file_path:\n",
        "        print(\"CSV file path:\", csv_file_path)\n",
        "        flights_df = pd.read_csv(csv_file_path)\n",
        "        print(flights_df.head())\n",
        "        return flights_df\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No CSV file found in the dataset directory.\")"
      ],
      "metadata": {
        "id": "CnqY3K07V7pR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Format various fields of the sample ('instruction','output')\n",
        "    Then concatenate them using two newline characters\n",
        "    :param sample: Sample dictionnary\n",
        "    \"\"\"\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruct: Summarize the below conversation.\"\n",
        "    RESPONSE_KEY = \"### Output:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"\\n{INTRO_BLURB}\""
      ],
      "metadata": {
        "id": "hDFBAkycswaL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: The FineTuningAgent Class\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "class FineTuningAgent:\n",
        "    \"\"\"\n",
        "    A class for fine-tuning language models using the OODA loop.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_id, dataset_name, config=None):\n",
        "        \"\"\"\n",
        "        Initializes the FineTuningAgent.\n",
        "\n",
        "        Args:\n",
        "            model_id (str): The ID of the pre-trained model.\n",
        "            dataset_name (str): The name of the dataset to use.\n",
        "            config (dict, optional): Configuration parameters. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.model_id = model_id\n",
        "        self.dataset_name = dataset_name\n",
        "        self.config = config if config is not None else {}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.training_args = None\n",
        "        self.peft_config = None\n",
        "        self.dataset = None\n",
        "        self.counter = 0\n",
        "        self.data_collator = None\n",
        "        self.model_type = None\n",
        "        # report\n",
        "        self.evaluation_results = None  # Store evaluation results\n",
        "        self.train_losses = []  # Store train losses\n",
        "        self.eval_losses = []  # Store eval losses\n",
        "        self.start_time = None  # Store the start time\n",
        "        self.end_time = None  # Store the end time\n",
        "\n",
        "    @timeit\n",
        "    def _observe(self):\n",
        "        \"\"\"\n",
        "        Loads the model, tokenizer, and dataset.\n",
        "        Returns True if successful, False otherwise.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"Starting Observe ...\")\n",
        "\n",
        "        clear_memory()\n",
        "\n",
        "        # Check if Unsloth should be used.\n",
        "        use_unsloth = self.config.get(\"use_unsloth\", False)\n",
        "\n",
        "        if use_unsloth:\n",
        "            print(\"Unsloth will be used.\")\n",
        "\n",
        "        quantization_config = None\n",
        "        if self.config.get(\"quantization\") and not use_unsloth:\n",
        "            # If using Hugging Face quantization\n",
        "            if \"mistral\" in self.model_id.lower():\n",
        "                print(\"Mistral model detected. Using 4-bit quantization.\")\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=True,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                )\n",
        "            else:\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=False,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.float32,\n",
        "                )\n",
        "\n",
        "        model_downloaded = False\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while not model_downloaded and retry_count < max_retries:\n",
        "            try:\n",
        "                # Determine the correct model class based on architecture\n",
        "                if \"bert\" in self.model_id.lower():\n",
        "                    print(\"BERT model detected.\")\n",
        "                    self.model_type = \"encoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading BERT with Unsloth\")\n",
        "                        # This is the correct model ID to use with Unsloth\n",
        "                        # Corrected Model ID.\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"bert-base-uncased\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading BERT with Hugging Face\")\n",
        "                        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            num_labels=2,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "\n",
        "                elif \"mistral\" in self.model_id.lower() or \"deepseek\" in self.model_id.lower():\n",
        "                    print(\"Decoder-only model detected.\")\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading Decoder-only with Unsloth\")\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading Decoder-only with Hugging Face\")\n",
        "                        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                            #attn_implementation=\"flash_attention_2\",  # Added\n",
        "                            #torch_dtype=torch.bfloat16,  # Added\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "                # unsloth model\n",
        "                elif \"unsloth\" in self.model_id.lower():\n",
        "                    print(\"Unsloth model detected.\")\n",
        "                    # Load the model with unsloth\n",
        "                    print(\"Loading Unsloth model\")\n",
        "                    # Correct model name: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
        "                    unsloth_model_id = self.config.get(\n",
        "                        \"unsloth_model_id\", \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "                    )\n",
        "                    max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                    dtype = self.config.get(\"dtype\", None)\n",
        "                    load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                    access_token = self.config.get(\"access_token\", None)\n",
        "                    self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                        model_name=unsloth_model_id,\n",
        "                        max_seq_length=max_seq_length,\n",
        "                        dtype=dtype,\n",
        "                        load_in_4bit=load_in_4bit,\n",
        "                        token=access_token,\n",
        "                    )\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                else:\n",
        "                    print(f\"Model {self.model_id} not supported.\")\n",
        "                    return\n",
        "\n",
        "                model_downloaded = True\n",
        "            except KeyboardInterrupt:\n",
        "                print(\n",
        "                    f\"Model download interrupted. Retrying... (Attempt {retry_count + 1}/{max_retries})\"\n",
        "                )\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during model download: {e}\")\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "        # Add padding token if it does not exist\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "        if not use_unsloth and not \"unsloth\" in self.model_id.lower():\n",
        "            # Move model to device\n",
        "            self.model.to(self.device)\n",
        "\n",
        "        if self.dataset_name == \"sakharamg/AviationQA\":\n",
        "\n",
        "            import datasets\n",
        "            from datasets import load_dataset\n",
        "\n",
        "            print(\"Loading dataset AviationQA .....\")\n",
        "            dataset = load_dataset(\"sakharamg/AviationQA\")\n",
        "\n",
        "            # save datasets to disk\n",
        "            dataset[\"train\"].to_json(\"/content/train_dataset_AviationQA.json\", orient=\"records\")\n",
        "            dataset[\"validation\"].to_json(\"/content/AviationQA/validation_dataset_AviationQA.json\", orient=\"records\")\n",
        "            dataset[\"test\"].to_json(\"/content/test_dataset_AviationQA.json\", orient=\"records\")\n",
        "\n",
        "\n",
        "            ### BEFORE *****\n",
        "            # Get train_dataset_size from config, set test_dataset_size directly\n",
        "            #train_dataset_size = self.config.get(\"dataset_size\", 125)\n",
        "            #test_dataset_size = 250\n",
        "\n",
        "            # Load and select datasets using the determined sizes\n",
        "            #dataset = load_dataset(\"json\", data_files=\"/content/train_dataset_AviationQA.json\", split=\"train\")\n",
        "            #train_dataset = dataset.shuffle().select(range(train_dataset_size))  # Use train_dataset_size here\n",
        "\n",
        "            #dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")\n",
        "            #test_dataset = dataset.shuffle().select(range(test_dataset_size))  # Use test_dataset_size here\n",
        "\n",
        "\n",
        "            ############### AFTER &&&&&&&\n",
        "\n",
        "            print(\"Loading dataset AviationQA - New Approach.....\")\n",
        "\n",
        "            dataset = load_dataset(\"json\", data_files=\"/content/train_dataset_AviationQA.json\", split=\"train\")\n",
        "            test_dataset = load_dataset(\"json\", data_files=\"/content/test_dataset_AviationQA.json\", split=\"train\")\n",
        "\n",
        "            train_question=dataset['Question']\n",
        "            train_answer=dataset['Answer']\n",
        "\n",
        "            test_question=test_dataset['Question']\n",
        "            test_answer=test_dataset['Answer']\n",
        "\n",
        "            ## SIZE DEFINITION\n",
        "            nrec=100\n",
        "            p_nrec=2\n",
        "            max_seq_length=2048\n",
        "\n",
        "            nrec_test=(nrec*p_nrec)*100/1000\n",
        "            #print(nrec)\n",
        "\n",
        "            nrec=100\n",
        "            p_nrec=2\n",
        "            nrec_test=(nrec*p_nrec)*100/1000\n",
        "            print(nrec)\n",
        "\n",
        "            nrec_test = int(nrec_test)\n",
        "            print(nrec_test)\n",
        "\n",
        "            def text_transformer(filename,train_answer,nrec):\n",
        "                filename='/content/%s.txt'%filename\n",
        "                for n in range(nrec):\n",
        "                    if train_answer[n] == None:\n",
        "                      train_answer[n] = 'Not possible to get or use'\n",
        "                    text='<s>[INST] %s [/INST] %s </s>'%(train_question[n],train_answer[n])\n",
        "                    with open(filename, 'a') as f:\n",
        "                        f.write(text + '\\n')\n",
        "\n",
        "            text_transformer(\"aviation-qa\",train_answer,nrec)\n",
        "            text_transformer(\"test_aviation-qa\",test_answer,nrec_test)\n",
        "\n",
        "            text0 = load_dataset(\"text\", data_files=\"/content/aviation-qa.txt\", split=\"train\")\n",
        "            text0_test = load_dataset(\"text\", data_files=\"/content/test_aviation-qa.txt\", split=\"train\")\n",
        "\n",
        "\n",
        "\n",
        "            ## SIZE DEFINITION\n",
        "\n",
        "            dataset_final_id=dataset['id'][0:nrec]\n",
        "            dataset_final_Question=dataset['Question'][0:nrec]\n",
        "            dataset_final_Answer=dataset['Answer'][0:nrec]\n",
        "            dataset_final_text=text0[0:nrec]['text']\n",
        "\n",
        "            dataset_final_id_test=test_dataset['id'][0:nrec_test]\n",
        "            dataset_final_Question_test=test_dataset['Question'][0:nrec_test]\n",
        "            dataset_final_Answer_test=dataset['Answer'][0:nrec_test]\n",
        "            dataset_final_text_test=text0_test[0:nrec_test]['text']\n",
        "\n",
        "            #DATASET CREATION\n",
        "            import pandas as pd\n",
        "\n",
        "            datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "            datasetF['id'] = dataset_final_id\n",
        "            datasetF['Question'] = dataset_final_Question\n",
        "            datasetF['Answer'] = dataset_final_Answer\n",
        "            datasetF['text'] = dataset_final_text\n",
        "\n",
        "            datasetF_test = pd.DataFrame() # Create an empty DataFrame\n",
        "            datasetF_test['id'] = dataset_final_id_test\n",
        "            datasetF_test['Question'] = dataset_final_Question_test\n",
        "            datasetF_test['Answer'] = dataset_final_Answer_test\n",
        "            datasetF_test['text'] = dataset_final_text_test\n",
        "\n",
        "            # Ensure dataset_final_text_test has the same length as datasetF_eval\n",
        "            #dataset_final_text = dataset_final_text_test[:len(dataset_final_id_test)]\n",
        "\n",
        "\n",
        "            # Convert Pandas DataFrames to Hugging Face Datasets\n",
        "            datasetF_hf = datasets.Dataset.from_pandas(datasetF)\n",
        "            datasetF_hf_test = datasets.Dataset.from_pandas(datasetF_test)\n",
        "\n",
        "\n",
        "            # Filter out None values in the 'text' column of datasetF_hf and eval_dataset_hf\n",
        "            datasetF_hf = datasetF_hf.filter(lambda example: example['text'] is not None and len(example['text']) > 0)\n",
        "            datasetF_hf_test = datasetF_hf_test.filter(lambda example: example['text'] is not None and len(example['text']) > 0)\n",
        "\n",
        "            import numpy as np\n",
        "            def tokenize_function(examples):\n",
        "                try:\n",
        "                    # Tokenize the 'text' field and get input_ids\n",
        "                    # Using return_tensors='np' for potential speed-up with numpy operations\n",
        "\n",
        "\n",
        "                    tokenized_text = self.tokenizer(\n",
        "                        examples[\"text\"],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        max_length=max_seq_length,\n",
        "                        return_tensors='np'  # Return NumPy arrays directly\n",
        "                    )\n",
        "\n",
        "                    # Directly work with NumPy arrays for label generation\n",
        "                    input_ids_array = tokenized_text['input_ids']\n",
        "\n",
        "                    # Generate labels as a shifted version of input_ids\n",
        "                    tokenized_text['labels'] = input_ids_array[:, 1:].tolist()  # Shifted to the left by one\n",
        "\n",
        "                    # Adjust input_ids to remove the last token (to align with labels)\n",
        "                    tokenized_text['input_ids'] = input_ids_array[:, :-1].tolist()\n",
        "\n",
        "                    return tokenized_text\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing example: {examples['text']}\")\n",
        "                    print(f\"Error message: {e}\")\n",
        "                    # Return an empty dictionary to skip this example\n",
        "                    return {}\n",
        "\n",
        "            #Apply the tokenization function to your datasetsgo to the trainer as input\n",
        "            tokenized_train_dataset = datasetF_hf.map(tokenize_function, batched=True)\n",
        "            tokenized_test_dataset = datasetF_hf_test.map(tokenize_function, batched=True)\n",
        "\n",
        "            self.tokenized_train_dataset = tokenized_train_dataset\n",
        "            self.tokenized_test_dataset = tokenized_test_dataset\n",
        "\n",
        "            #################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Update self.dataset to include train and test splits\n",
        "            #self.dataset = DatasetDict({\n",
        "            #    'train': train_dataset,\n",
        "            #    'test': test_dataset\n",
        "            #})\n",
        "\n",
        "            print(\"\\n\")\n",
        "            print(f\"Dataset - Loaded with NA  Observe: {self.dataset}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "        else:\n",
        "\n",
        "            # Load Dataset (using dataset name from Hugging Face Hub)\n",
        "            dataset = load_dataset(\n",
        "                self.dataset_name, split=\"train\", num_proc=self.config.get(\"dataset_num_proc\", 2)\n",
        "            )\n",
        "            self.dataset = dataset.shuffle().select(\n",
        "                range(self.config.get(\"dataset_size\", 125))\n",
        "            )\n",
        "\n",
        "            print(\"\\n\")\n",
        "            print(f\"Dataset - Observe: {self.dataset}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Observe finished.\")\n",
        "        return True\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _orient(self):\n",
        "        \"\"\"\n",
        "        Orients the agent by formatting the dataset and preparing training arguments.\n",
        "        \"\"\"\n",
        "        print(\"\\n\")\n",
        "        self.counter += 1\n",
        "        print(\"Starting Orient ...\")\n",
        "        if self.dataset_name == \"SetFit/mrpc\":\n",
        "            print(\"Dataset: SetFit/mrpc\")\n",
        "            preprocessing_function = self._preprocess_function_mrpc\n",
        "        elif self.dataset_name == \"b-mc2/sql-create-context\":\n",
        "            print(\"Dataset: b-mc2/sql-create-context\")\n",
        "            preprocessing_function = self._preprocess_function_sql_create_context\n",
        "        elif self.dataset_name == \"anthropic/hh-rlhf\":\n",
        "            print(\"Dataset: anthropic/hh-rlhf\")\n",
        "            preprocessing_function = self._preprocess_function_anthropic_hh_rlhf\n",
        "        elif self.dataset_name == \"imdb\":\n",
        "            print(\"Dataset: imdb\")\n",
        "            preprocessing_function = self._preprocess_function_imdb\n",
        "        elif self.dataset_name == \"sakharamg/AviationQA\":\n",
        "             print('\\n')\n",
        "             print(\"NO NEED -  preprocessing_functioDataset: AviationQA\")\n",
        "             print('\\n')\n",
        "             #preprocessing_function=self._preprocess_function_aviationqa\n",
        "\n",
        "\n",
        "             # Apply preprocessing to train and test datasets (no changes here)\n",
        "             #self.dataset['train'] = self.dataset['train'].map(\n",
        "             #     preprocessing_function,\n",
        "              #    batched=True,\n",
        "             #     remove_columns=self.dataset[\"train\"].column_names,\n",
        "             # )\n",
        "             #self.dataset['test'] = self.dataset['test'].map(\n",
        "             #     preprocessing_function,\n",
        "             #     batched=True,\n",
        "             #     remove_columns=self.dataset[\"test\"].column_names,\n",
        "             # )\n",
        "\n",
        "        else:\n",
        "              print(f\"Dataset: {self.dataset_name} not supported.\")\n",
        "              return\n",
        "\n",
        "\n",
        "        if self.dataset_name == \"b-mc2/sql-create-context\" and self.dataset_name != \"sakharamg/AviationQA\":\n",
        "\n",
        "            # Set the train/test split.\n",
        "            test_size_percentage = self.config.get(\"test_split_percentage\", 0.2)\n",
        "            self.dataset = self.dataset.train_test_split(\n",
        "                test_size=test_size_percentage\n",
        "            )\n",
        "\n",
        "            self.dataset = self.dataset.map(\n",
        "                preprocessing_function,\n",
        "                batched=True,\n",
        "                remove_columns=self.dataset[\"train\"].column_names,\n",
        "            )\n",
        "\n",
        "            # 3. Prepare Training Arguments\n",
        "            # Import is_bfloat16_supported function.\n",
        "\n",
        "\n",
        "        # Create TrainingArguments with the desired parameters\n",
        "        training_args_config = self.config.get(\"training_args\", {})\n",
        "        self.training_args = TrainingArguments(\n",
        "            output_dir=training_args_config.get(\"output_dir\", \"./output\"),\n",
        "            per_device_train_batch_size=training_args_config.get(\n",
        "                \"per_device_train_batch_size\", 2\n",
        "            ),\n",
        "            gradient_accumulation_steps=training_args_config.get(\n",
        "                \"gradient_accumulation_steps\", 4\n",
        "            ),\n",
        "            warmup_steps=training_args_config.get(\"warmup_steps\", 5),\n",
        "            max_steps=training_args_config.get(\"max_steps\", 60),\n",
        "            learning_rate=training_args_config.get(\"learning_rate\", 2e-4),\n",
        "            fp16=training_args_config.get(\"fp16\", not is_bfloat16_supported()),\n",
        "            bf16=training_args_config.get(\"bf16\", is_bfloat16_supported()),\n",
        "            logging_steps=training_args_config.get(\"logging_steps\", 10),\n",
        "            optim=training_args_config.get(\"optim\", \"adamw_8bit\"),\n",
        "            weight_decay=training_args_config.get(\"weight_decay\", 0.01),\n",
        "            lr_scheduler_type=training_args_config.get(\"lr_scheduler_type\", \"linear\"),\n",
        "            seed=training_args_config.get(\"seed\", 3407),\n",
        "            evaluation_strategy=training_args_config.get(\n",
        "                \"evaluation_strategy\", \"steps\"\n",
        "            ),  # we need this\n",
        "            eval_steps=training_args_config.get(\"eval_steps\", 20),\n",
        "            save_strategy=training_args_config.get(\"save_strategy\", \"steps\"),\n",
        "            save_steps=training_args_config.get(\"save_steps\", 20),\n",
        "            report_to=training_args_config.get(\"report_to\", \"none\"),\n",
        "            remove_unused_columns=False # we need this\n",
        "        )\n",
        "\n",
        "\n",
        "        if self.dataset_name == \"sakharamg/AviationQA\":\n",
        "            print('\\n')\n",
        "            print(f\"Orient Dataset(train): {self.tokenized_train_dataset}\")\n",
        "            print(f\" Orient Dataset(test): {self.tokenized_test_dataset}\")\n",
        "        else:\n",
        "            print(\"\\n\")\n",
        "            print(f\"Orient Dataset: {self.dataset}\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Orient finished.\")\n",
        "\n",
        "    @timeit\n",
        "    def _decide(self):\n",
        "        \"\"\"\n",
        "        Decides on the fine-tuning strategy, including LoRA configuration.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Decide ...\")\n",
        "        clear_memory()\n",
        "        # PEFT Configuration (LoRA)\n",
        "        if self.config.get(\"lora\"):\n",
        "            self.model = prepare_model_for_kbit_training(self.model)\n",
        "            if \"bert\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=16,  # You can tune this.\n",
        "                    lora_dropout=0.1,  # You can tune this.\n",
        "                    r=64,  # You can tune this.\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"query\", \"key\", \"value\", \"dense\"],  # Correct target modules for BERT\n",
        "                    task_type=\"SEQ_CLS\",  # correct task type\n",
        "                )\n",
        "            elif \"mistral\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=32,\n",
        "                    lora_dropout=0.1,\n",
        "                    r=8,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "\n",
        "            elif \"deepseek\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=32,\n",
        "                    lora_dropout=0.1,\n",
        "                    r=8,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "            elif \"unsloth\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "                print(\"\\n\")\n",
        "                print(f\"LORA: {peft_config}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Model {self.model_id} not supported.\")\n",
        "                return\n",
        "\n",
        "            self.peft_config = peft_config\n",
        "            self.model = get_peft_model(self.model, peft_config)\n",
        "\n",
        "            self.model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "        print('\\n')\n",
        "        print(\"Decide finished.\")\n",
        "\n",
        "    @timeit\n",
        "    def _act(self):\n",
        "        \"\"\"\n",
        "        Acts by preprocessing the dataset and initializing the training loop.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Act ...\")\n",
        "        clear_memory()\n",
        "\n",
        "        if self.dataset_name == \"sakharamg/AviationQA\":\n",
        "\n",
        "                  print(\"\\n\")\n",
        "                  print(\"Initializing Trainer for AviationQA...\")\n",
        "                  print(\"\\n\")\n",
        "                  self.model.gradient_checkpointing_enable()\n",
        "                  self.model.enable_input_require_grads()\n",
        "                  self.model.config.use_cache = False\n",
        "\n",
        "                  self.trainer = Trainer(\n",
        "                      model=self.model,\n",
        "                      args=self.training_args,\n",
        "                      train_dataset=self.tokenized_train_dataset,\n",
        "                      eval_dataset=self.tokenized_test_dataset,\n",
        "                      compute_metrics=self.compute_metrics_qa,\n",
        "                  )\n",
        "        else:\n",
        "              try:\n",
        "                  if \"train\" not in self.dataset or \"test\" not in self.dataset:\n",
        "                      print(f\"Missing train or test split for {self.dataset_name}\")\n",
        "                      return\n",
        "\n",
        "                  print(\"Dataset preprocessed successfully.\")\n",
        "                  print(\"\\n\")\n",
        "\n",
        "                  # Unsloth's Data Collator (Hypothetical)\n",
        "                  if self.config.get(\"use_unsloth\", False) or \"unsloth\" in self.model_id.lower():\n",
        "                      print(\"Unsloth data collator used.\")\n",
        "                      self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "                  else:\n",
        "                      # Hugging Face Data Collator\n",
        "                      self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "                      print(\"Hugging Face data collator used.\")\n",
        "\n",
        "                  # Initialize Trainer\n",
        "                  print(\"Initializing Trainer...\")\n",
        "                  loss_callback = LossLoggingCallback(self) # Create the callback\n",
        "                  metric_callback = MetricCallback(self)\n",
        "\n",
        "                  # Use the Trainer class instead of SFTTrainer\n",
        "                  self.trainer = Trainer(\n",
        "                      model=self.model,\n",
        "                      args=self.training_args,\n",
        "                      train_dataset=self.dataset[\"train\"],\n",
        "                      eval_dataset=self.dataset[\"test\"],\n",
        "                      data_collator=self.data_collator,\n",
        "                      #compute_metrics=self.compute_metrics,\n",
        "                      callbacks=[loss_callback, metric_callback]\n",
        "                  )\n",
        "\n",
        "\n",
        "\n",
        "              except Exception as e:\n",
        "                  print(f\"An error occurred in _act(): {e}\")\n",
        "                  raise\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Act finished.\")\n",
        "\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    from evaluate import load\n",
        "    from sklearn.metrics import f1_score\n",
        "    import torch\n",
        "\n",
        "    def compute_metrics_qa(self,eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU, ROUGE (with precision, recall, F-measure), F1, and perplexity scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the computed metrics.\n",
        "        \"\"\"\n",
        "\n",
        "        logits, labels = eval_pred\n",
        "        predictions = np.argmax(logits, axis=-1)  # Get predicted class labels\n",
        "\n",
        "        # Decode predictions and labels to strings\n",
        "        decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "        decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        # Calculate BLEU score using 'evaluate' library\n",
        "        bleu = load(\"bleu\")\n",
        "        bleu_score = bleu.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])[\"bleu\"]\n",
        "\n",
        "        # Calculate ROUGE score with precision, recall, and F-measure\n",
        "        rouge = load(\"rouge\")\n",
        "        rouge_score = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "        # Extract ROUGE-L scores (you can change to other ROUGE types if needed)\n",
        "        rouge_precision = rouge_score['rougeL'].precision # or rouge_score['rougeLsum'].precision, etc.\n",
        "        rouge_recall = rouge_score['rougeL'].recall\n",
        "        rouge_fmeasure = rouge_score['rougeL'].fmeasure\n",
        "\n",
        "        # Calculate F1 score using 'sklearn' library\n",
        "        f1 = f1_score(labels.flatten(), predictions.flatten(), average=\"weighted\")\n",
        "\n",
        "        # Calculate perplexity\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "        perplexity = torch.exp(loss).item()\n",
        "\n",
        "        # Store metrics in a dictionary\n",
        "        metrics = {\n",
        "            \"bleu\": bleu_score,\n",
        "            \"rouge_precision\": rouge_precision,\n",
        "            \"rouge_recall\": rouge_recall,\n",
        "            \"rouge_fmeasure\": rouge_fmeasure,\n",
        "            \"f1\": f1,\n",
        "            \"perplexity\": perplexity\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    from rouge_score import rouge_scorer\n",
        "    from evaluate import load\n",
        "    from rouge_score import rouge_scorer  # Import rouge-score\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "    def calculate_bleu_score(self,hypothesis, references):\n",
        "        \"\"\"\n",
        "        Calculates the BLEU score for a given hypothesis and list of references.\n",
        "\n",
        "        Args:\n",
        "            hypothesis (list of str): The candidate translation (a list of tokens).\n",
        "            references (list of list of str): A list of reference translations (each a list of tokens).\n",
        "\n",
        "        Returns:\n",
        "            float: The BLEU score.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hypothesis or not references:\n",
        "            return 0.0\n",
        "\n",
        "        if any(not ref for ref in references):\n",
        "            return 0.0\n",
        "\n",
        "        max_ngram = min(4, min(len(hypothesis), *[len(ref) for ref in references]))\n",
        "        weights = tuple(1.0 / max_ngram for _ in range(max_ngram))\n",
        "        smoothing = SmoothingFunction().method4\n",
        "\n",
        "        bleu_score = sentence_bleu(\n",
        "            references, hypothesis, weights=weights, smoothing_function=smoothing\n",
        "        )\n",
        "\n",
        "        return bleu_score\n",
        "\n",
        "\n",
        "    def calculate_f1_score(self, predictions, references):\n",
        "        \"\"\"\n",
        "        Calculates the F1 score.\n",
        "        \"\"\"\n",
        "        return f1_score(references, predictions, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU, F1, ROUGE, and perplexity scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the computed metrics.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        metrics = {}  # Initialize an empty dictionary to store metrics\n",
        "\n",
        "        # For sequence classification tasks, predictions are logits (like in BERT)\n",
        "        if self.model_type == \"encoder-only\" and \"bert\" in self.model_id.lower():\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "        # For decoder-only models, predictions need to be processed differently:\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            predictions = np.argmax(predictions, axis=2)  # Get the highest probability token for each position\n",
        "\n",
        "        # Decode predictions and labels (if necessary)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "            # Replace -100 (ignore index) with pad_token_id in labels before decoding\n",
        "            labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        else:\n",
        "            decoded_predictions = predictions  # Encoder-only models might not need decoding\n",
        "            decoded_labels = labels\n",
        "\n",
        "        # Extract references for BLEU calculation (nested list)\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        # Calculate BLEU and F1 scores\n",
        "        bleu_score = self.calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = self.calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "        metrics[\"bleu\"] = bleu_score  # Add BLEU score to metrics\n",
        "        metrics[\"f1\"] = f1_score  # Add F1 score to metrics\n",
        "\n",
        "        # Calculate ROUGE scores for decoder-only models\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "            all_scores = [scorer.score(label, pred) for label, pred in zip(decoded_labels, decoded_predictions)]\n",
        "\n",
        "            # Calculate the average scores:\n",
        "            rouge_metrics = {}\n",
        "            for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "                precision = np.mean([score[metric].precision for score in all_scores])\n",
        "                recall = np.mean([score[metric].recall for score in all_scores])\n",
        "                fmeasure = np.mean([score[metric].fmeasure for score in all_scores])\n",
        "\n",
        "                rouge_metrics[metric] = {\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"fmeasure\": fmeasure  # or \"f1\" if you prefer\n",
        "                }\n",
        "            metrics.update(rouge_metrics)  # Add rouge metrics to the main metrics dictionary\n",
        "\n",
        "        # Calculate perplexity (for decoder-only models)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    # Prepare input for perplexity calculation\n",
        "                    #inputs = self.tokenizer(decoded_labels, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "                    # Pass inputs through the model to calculate loss\n",
        "                    #outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
        "                    outputs = self.model(input_ids=torch.tensor(labels).to(self.device), labels=torch.tensor(labels).to(self.device))\n",
        "\n",
        "                    loss = outputs.loss\n",
        "                    # Calculate perplexity from loss\n",
        "                    perplexity = torch.exp(torch.tensor(loss)).item()\n",
        "                    metrics[\"perplexity\"] = perplexity\n",
        "            except Exception as e:\n",
        "                print(f\"Error in perplexity calculation: {e}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def compute_metricspoc2(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU, F1, ROUGE, and Perplexity scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the BLEU, F1, ROUGE, and perplexity scores.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        metrics = {} #Initialize here\n",
        "\n",
        "        # Handle decoder-only models:\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Perplexity Calculation:\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_ids=torch.tensor(labels).to(self.device), labels=torch.tensor(labels).to(self.device))\n",
        "                loss = outputs.loss\n",
        "                perplexity = torch.exp(torch.tensor(loss)).item()\n",
        "                #Add it to the dict\n",
        "                metrics[\"perplexity\"] = perplexity # Include perplexity if calculated\n",
        "\n",
        "            predictions = np.argmax(predictions, axis=2) #argmax axis 2 for decoder only.\n",
        "            decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "            labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        else: #encoder-decoder or other\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "            decoded_predictions = predictions\n",
        "            decoded_labels = labels\n",
        "            # perplexity = None #Not needed, since you initialized metrics above.\n",
        "\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = calculate_f1_score(decoded_predictions,decoded_labels)\n",
        "\n",
        "        rouge_scores = self.calculate_rouge(references, decoded_predictions)\n",
        "\n",
        "        # Add to the dict\n",
        "        metrics[\"bleu\"] = bleu_score\n",
        "        metrics[\"f1\"] = f1_score\n",
        "\n",
        "        #Add rouge\n",
        "        for rouge_type, scores in rouge_scores.items():\n",
        "                metrics[f\"{rouge_type}_precision\"] = scores['precision']\n",
        "                metrics[f\"{rouge_type}_recall\"] = scores['recall']\n",
        "                metrics[f\"{rouge_type}_f1\"] = scores['f1']\n",
        "\n",
        "\n",
        "        # Return the updated metrics\n",
        "        return metrics  # This line returns the dict\n",
        "\n",
        "\n",
        "    def compute_metricspoc(self, eval_pred):\n",
        "            \"\"\"\n",
        "            Computes the BLEU, F1, ROUGE, and perplexity metrics based on the task type.\n",
        "            \"\"\"\n",
        "            predictions, labels = eval_pred\n",
        "\n",
        "            # For sequence classification tasks (like MRPC), predictions are logits\n",
        "            if self.model_type == \"encoder-only\" and \"bert\" in self.model_id.lower():\n",
        "                predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "            # Initialize an empty dictionary to store metrics\n",
        "            metrics = {}\n",
        "\n",
        "            # Decode predictions and labels\n",
        "            if self.model_type == \"decoder-only\":\n",
        "                decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "                labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "                decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "                # Calculate BLEU and F1 scores\n",
        "                references = [[label] for label in decoded_labels]\n",
        "                bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "                f1_score = calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "\n",
        "                # Add BLEU and F1 to the metrics dictionary\n",
        "                metrics[\"bleu\"] = bleu_score\n",
        "                metrics[\"f1\"] = f1_score\n",
        "\n",
        "                # Calculate ROUGE score\n",
        "                rouge = load(\"rouge\")\n",
        "                results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "                metrics.update(results)  # Add ROUGE scores to the metrics dictionary\n",
        "\n",
        "                # Calculate perplexity (with eval_loss check)\n",
        "                try:\n",
        "                    # Check if eval_loss is available in the log history\n",
        "                    if self.trainer.state.log_history and \"eval_loss\" in self.trainer.state.log_history[-1]:\n",
        "                        eval_loss = self.trainer.state.log_history[-1][\"eval_loss\"]\n",
        "                        print(f\"eval_loss found: {eval_loss}\") # Debugging print statement\n",
        "\n",
        "                        perplexity = torch.exp(torch.tensor(eval_loss)).item()\n",
        "                        metrics[\"perplexity\"] = perplexity\n",
        "                    else:\n",
        "                        print(\"eval_loss not found in logs for perplexity calculation. This is expected early in training or if evaluation has not occurred.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in perplexity calculation: {e}\")\n",
        "                    print(f\"log_history: {self.trainer.state.log_history}\")\n",
        "\n",
        "                #Print all logs as Json file\n",
        "                print(f\"trainer.state.log_history: {json.dumps(self.trainer.state.log_history)}\")\n",
        "\n",
        "\n",
        "            else:  # For encoder-only models (like BERT)\n",
        "                decoded_predictions = predictions\n",
        "                decoded_labels = labels\n",
        "\n",
        "                # Calculate BLEU and F1 scores (might not be relevant for all tasks)\n",
        "                references = [[label] for label in decoded_labels]\n",
        "                bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "                f1_score = calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "\n",
        "                # Add BLEU and F1 to the metrics dictionary\n",
        "                metrics[\"bleu\"] = bleu_score\n",
        "                metrics[\"f1\"] = f1_score\n",
        "\n",
        "            return metrics\n",
        "\n",
        "    #!pip install evaluate -q\n",
        "    from evaluate import load\n",
        "\n",
        "    def compute_metricsgood(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU and F1 scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the BLEU and F1 scores.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Initialize an empty dictionary to store metrics\n",
        "        #metrics = {}\n",
        "\n",
        "        # Decode predictions and labels (if necessary)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "          decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "          labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "          decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        else:\n",
        "          decoded_predictions = predictions\n",
        "          decoded_labels = labels\n",
        "\n",
        "        # Extract references\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = calculate_f1_score(decoded_predictions,decoded_labels)\n",
        "\n",
        "        # Calculate ROUGE score\n",
        "        #rouge = load(\"rouge\")\n",
        "        #results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "        #metrics.update(results)  # Add ROUGE scores to the metrics dictionary\n",
        "\n",
        "\n",
        "        # Add BLEU and F1 to the metrics dictionary\n",
        "        #metrics[\"bleu\"] = bleu_score\n",
        "        #metrics[\"f1\"] = f1_score\n",
        "\n",
        "        return {\"bleu\": bleu_score, \"f1\": f1_score}\n",
        "        #return metrics\n",
        "\n",
        "\n",
        "    def on_train_loss(self, loss):\n",
        "      \"\"\"Callback to store training losses.\"\"\"\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "    def on_eval_loss(self, loss):\n",
        "        \"\"\"Callback to store evaluation losses.\"\"\"\n",
        "        self.eval_losses.append(loss)\n",
        "    @timeit\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Executes the OODA loop and fine-tunes the language model.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Run ...\")\n",
        "        clear_memory()\n",
        "        self.start_time = time.time()\n",
        "        self._observe()\n",
        "        if self.model is None:\n",
        "            print(\"Model loading failed, skipping _orient, _decide and _act\")\n",
        "            return\n",
        "        self._orient()\n",
        "        self._decide()\n",
        "        self._act()\n",
        "\n",
        "\n",
        "        if self.dataset_name == \"sakharamg/AviationQA\":\n",
        "            print('\\n')\n",
        "            print(f\"Run - Dataset(train): {self.tokenized_train_dataset}\")\n",
        "            print(f\"Run -  Dataset(test): {self.tokenized_test_dataset}\")\n",
        "        else:\n",
        "            print(\"\\n\")\n",
        "            print(f\"Run Dataset: {self.dataset}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        if self.trainer is not None:\n",
        "            try:\n",
        "                # Train the model\n",
        "                self.trainer.train()\n",
        "                print(\"\\n\")\n",
        "                print(\"Evaluation:\")\n",
        "                eval_results = self.evaluate()\n",
        "                print(\"\\n\")\n",
        "                print(eval_results)\n",
        "                print(\"\\n\")\n",
        "\n",
        "                # Create experiment_name\n",
        "                # Create experiment_name (using triple quotes)\n",
        "\n",
        "                experiment_name = f\"\"\"{self.model_id.replace('/', '-').replace(\"'\", '')}_{self.dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "                # Save eval_results using write()\n",
        "\n",
        "                import os\n",
        "                import json  # Import json module\n",
        "                current_directory = os.getcwd()\n",
        "                %cd /content/\n",
        "                results_file = os.path.join(current_directory, f\"{experiment_name}_uftfresults.txt\")\n",
        "                with open(results_file, \"w\") as f:  # Open in write mode (\"w\")\n",
        "                    json.dump(eval_results, f)  # Write eval_results as JSON\n",
        "                    print(f\"Saved evaluation results to: {results_file}\")  # Add a print statement for confirmation\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during training or evaluation: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            print(\"Trainer is None. Skipping training and evaluation.\")\n",
        "\n",
        "        self.end_time = time.time()\n",
        "\n",
        "        print(\"Run  finished.\")\n",
        "    @timeit\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the fine-tuned language model.\n",
        "        \"\"\"\n",
        "        return self.trainer.evaluate()\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_aviationqa(self, examples):\n",
        "        print(\"Preprocess Dataset: sakharamg/AviationQA\")\n",
        "        max_length = self.config.get(\"max_length\", 128)\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "            # For encoder-only models like BERT (no changes here)\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"Question\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            with self.tokenizer.as_target_tokenizer():\n",
        "                labels = self.tokenizer(\n",
        "                    examples[\"Answer\"],\n",
        "                    max_length=max_length,\n",
        "                    truncation=True,\n",
        "                    padding=\"max_length\",\n",
        "                )\n",
        "            inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "            return inputs\n",
        "\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            # For decoder-only models like Mistral, Deepseek, Llama\n",
        "            # **Changes here:**\n",
        "            # 1. Combine Question and Answer into a single string\n",
        "            # 2. Pass this combined string as 'text' to the tokenizer\n",
        "\n",
        "            combined_text = [\n",
        "                f\"Question: {q} Answer: {a}\"\n",
        "                for q, a in zip(examples[\"Question\"], examples[\"Answer\"])\n",
        "            ]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                combined_text,  # Pass the combined text\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "\n",
        "            # Create labels (same logic as before)\n",
        "            inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
        "            inputs[\"labels\"] = [\n",
        "                [-100 if token == self.tokenizer.pad_token_id else token for token in labels]\n",
        "                for labels in inputs[\"labels\"]\n",
        "            ]\n",
        "            return inputs\n",
        "\n",
        "        else:\n",
        "            print(f\"Model type {self.model_type} not supported for preprocessing.\")\n",
        "            return {}\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_flight_data(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the flight data for fine-tuning.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: Flight Data\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        # Assuming examples is a list of dictionaries with 'text' key\n",
        "        inputs = [example['text'] for example in examples]\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels (same as inputs for causal language modeling)\n",
        "            labels_tokenized = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels (same as inputs for masked language modeling, etc.)\n",
        "            labels_tokenized = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_mrpc(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the SetFit/mrpc dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: SetFit/mrpc\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 128)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text1\"],\n",
        "                examples[\"text2\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "             # Decoder-only models are not supported for the MRPC task.\n",
        "            print(\"Decoder-only models are not supported for the MRPC task.\")\n",
        "            return {}\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_sql_create_context(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the b-mc2/sql-create-context dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: b-mc2/sql-create-context\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            # Tokenize inputs and labels\n",
        "            inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Assign labels to model_inputs\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            # Tokenize inputs and labels\n",
        "            inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Assign labels to model_inputs\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_anthropic_hh_rlhf(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the anthropic/hh-rlhf dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: anthropic/hh-rlhf\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_imdb(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the imdb dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: imdb\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "             # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            # Decoder-only models (Mistral, DeepSeek, etc.)\n",
        "            model_inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            # Copy input_ids to labels for causal LM training\n",
        "            model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "\n",
        "            return model_inputs\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")"
      ],
      "metadata": {
        "id": "ucf-t1uXN3Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7bfa64-b4d4-47e6-b328-e6231f9ffc2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Act finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Setup and Execution"
      ],
      "metadata": {
        "id": "S99Umzgf8OwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Experiment Setup and Execution\n",
        "import os  # Import os module\n",
        "\n",
        "class MetricCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A callback class to add metrics to the trainer.\n",
        "    \"\"\"\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def on_train_begin(self, args, state, control, model=None, **kwargs):\n",
        "        # self.agent.trainer.compute_metrics = self.agent.compute_metrics # removed\n",
        "        pass # removed\n",
        "\n",
        "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
        "      \"\"\"Callback to add metrics to self.trainer.\"\"\"\n",
        "      self.agent.trainer.compute_metrics = self.agent.compute_metrics # Added\n",
        "\n",
        "\n",
        "class LossLoggingCallback(TrainerCallback):\n",
        "    \"\"\"Callback to log training and evaluation losses.\"\"\"\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Logs the training loss at each log step.\"\"\"\n",
        "        if logs and \"loss\" in logs:\n",
        "            self.agent.on_train_loss(logs[\"loss\"])\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Logs the evaluation loss at each evaluation step.\"\"\"\n",
        "        if metrics and \"eval_loss\" in metrics:\n",
        "            self.agent.on_eval_loss(metrics[\"eval_loss\"])\n",
        "\n",
        "\n",
        "\n",
        "def create_rl_pairs():\n",
        "    \"\"\"\n",
        "    Creates a list of all possible combinations of datasets, models,\n",
        "    and configurations for RL experiments.\n",
        "    \"\"\"\n",
        "\n",
        "    datasets = [\n",
        "        #\"SetFit/mrpc\",\n",
        "        #\"b-mc2/sql-create-context\",\n",
        "        #\"anthropic/hh-rlhf\",\n",
        "        #\"imdb\",\n",
        "        \"sakharamg/AviationQA\",\n",
        "        #\"bhavikjikadara/us-airline-flight-routes-and-fares-1993-2024\"\n",
        "    ]\n",
        "    models = [\n",
        "\n",
        "        #\"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        #\"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "        #\"bert-base-uncased\",\n",
        "        \"mistralai/Mistral-7B-v0.1\",\n",
        "        #\"deepseek-ai/deepseek-coder-1.3b-base\",\n",
        "    ]\n",
        "\n",
        "    # Define different configs\n",
        "    configs = [\n",
        "        {\n",
        "            \"max_length\": 1000,\n",
        "\n",
        "            \"quantization\": True,\n",
        "            \"use_unsloth\": False,\n",
        "            \"lora\": True,\n",
        "            \"dataset_size\": 1000,\n",
        "            \"dataset_num_proc\": 2,\n",
        "            \"test_split_percentage\": 0.2,\n",
        "            \"training_args\": {\n",
        "                \"output_dir\": \"./output\",\n",
        "                \"use_cache\": False,\n",
        "                \"per_device_train_batch_size\": 3,  # batch size per device during training\n",
        "                \"gradient_accumulation_steps\": 2,  # number of steps before performing a backward/update pass\n",
        "                \"warmup_steps\": 10,\n",
        "                \"optim\":\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "                \"num_train_epochs\": 1,\n",
        "                \"max_steps\": 100,\n",
        "                \"learning_rate\": 1e-4,\n",
        "                \"logging_steps\": 10,\n",
        "                \"bf16\":True,                              # use bfloat16 precision\n",
        "                \"tf32\":True,                              # use tf32 precision\n",
        "                \"lr_scheduler_type\":\"constant\",           # use constant learning rate scheduler\n",
        "                \"weight_decay\": 0.01,\n",
        "                \"eval_steps\": 20,\n",
        "                \"report_to\": \"none\",\n",
        "                \"save_steps\": 20,\n",
        "                \"evaluation_strategy\":\"steps\",\n",
        "                \"eval_steps\":20,\n",
        "                \"logging_strategy\":\"steps\",\n",
        "                \"load_best_model_at_end\":True,\n",
        "                \"metric_for_best_model\":\"eval_loss\",\n",
        "\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    rl_pairs = []\n",
        "    for dataset, model, config in itertools.product(datasets, models, configs):\n",
        "        rl_pairs.append((dataset, model, copy.deepcopy(config))) # Use copy.deepcopy()\n",
        "\n",
        "    return rl_pairs\n",
        "\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import TrainingArguments, TrainerState, TrainerControl\n",
        "import ast  # Import ast for literal_eval\n",
        "\n",
        "def generate_report(\n",
        "    rl_pairs, agents, training_args_list, state_list, control_list, output_file=\"experiment_report.txt\", experiment_name=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates a report for multiple RL experiments, including evaluation scores and training details.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): A list of tuples, each containing (dataset_name, model_id, config).\n",
        "        agents (list): A list of FineTuningAgent objects corresponding to the experiments.\n",
        "        training_args_list (list): A list of TrainingArguments objects for each experiment.\n",
        "        state_list (list): A list of TrainerState objects for each experiment.\n",
        "        control_list (list): A list of TrainerControl objects for each experiment.\n",
        "        output_file (str): The name of the output file to save the report.\n",
        "        experiment_name (str, optional): The base name for the experiment results file.\n",
        "                                          If provided, it will be used to load the results.\n",
        "                                          Defaults to None.\n",
        "    \"\"\"\n",
        "    if not (\n",
        "        len(rl_pairs)\n",
        "        == len(agents)\n",
        "        == len(training_args_list)\n",
        "        == len(state_list)\n",
        "        == len(control_list)\n",
        "    ):\n",
        "        raise ValueError(\"The number of rl_pairs, agents, training_args, state, and control must be the same.\")\n",
        "\n",
        "    report_data = []\n",
        "    for (dataset_name, model_id, config), agent, training_args, state, control in zip(\n",
        "        rl_pairs, agents, training_args_list, state_list, control_list\n",
        "    ):\n",
        "\n",
        "        # *** Load results from file ***\n",
        "        if experiment_name:\n",
        "            results_file = f\"{experiment_name}_results.txt\"  # Use provided experiment_name and .txt extension\n",
        "        else:\n",
        "            results_file = f\"{dataset_name}_{model_id}_{agent.counter}_results.txt\"  # Default format with .txt extension\n",
        "\n",
        "        try:\n",
        "            with open(results_file, \"r\") as f:  # Open in read mode (\"r\") for text files\n",
        "                eval_results_str = f.read()  # Read the contents as a string\n",
        "                # Try to parse eval_results_str as a Python literal (e.g., dictionary)\n",
        "                try:\n",
        "                    eval_results = ast.literal_eval(eval_results_str)\n",
        "                except (SyntaxError, ValueError):\n",
        "                    print(f\"Error parsing eval_results_str for experiment: {results_file}\")\n",
        "                    eval_results = None\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Results file not found for experiment: {results_file}\")\n",
        "            eval_results = None  # Set to None if file not found\n",
        "\n",
        "        # Collect the data\n",
        "        elapsed_time = agent.end_time - agent.start_time if agent.start_time and agent.end_time else np.nan  # Handle potential errors\n",
        "\n",
        "        train_losses = agent.train_losses\n",
        "        eval_losses = agent.eval_losses\n",
        "\n",
        "        if not train_losses:\n",
        "            train_std = np.nan  # Use np.nan for no data\n",
        "            min_train_loss = np.nan\n",
        "            max_train_loss = np.nan\n",
        "        else:\n",
        "            train_std = np.std(train_losses)\n",
        "            min_train_loss = np.min(train_losses)\n",
        "            max_train_loss = np.max(train_losses)\n",
        "\n",
        "        if not eval_losses:\n",
        "            eval_std = np.nan\n",
        "            min_eval_loss = np.nan\n",
        "            max_eval_loss = np.nan\n",
        "        else:\n",
        "            eval_std = np.std(eval_losses)\n",
        "            min_eval_loss = np.min(eval_losses)\n",
        "            max_eval_loss = np.max(eval_losses)\n",
        "\n",
        "        # *** Extract BLEU and F1 scores from eval_results ***\n",
        "        if eval_results is not None:  # Check if eval_results were loaded successfully\n",
        "            bleu_score = eval_results.get(\"eval_bleu\", np.nan)  # Get BLEU score, default to NaN if not found\n",
        "            f1_score = eval_results.get(\"eval_f1\", np.nan)  # Get F1 score, default to NaN if not found\n",
        "        else:\n",
        "            bleu_score = np.nan  # Set to NaN if eval_results are None\n",
        "            f1_score = np.nan\n",
        "\n",
        "        # Check if training_args is None before accessing its attributes\n",
        "        learning_rate = training_args.learning_rate if training_args is not None else np.nan\n",
        "        batch_size = training_args.per_device_train_batch_size if training_args is not None else np.nan\n",
        "        epochs = training_args.num_train_epochs if training_args is not None and hasattr(training_args, \"num_train_epochs\") else \"n/a\"\n",
        "\n",
        "        report_data.append(\n",
        "            [\n",
        "                dataset_name,\n",
        "                model_id,\n",
        "                f\"{elapsed_time:.2f} seconds\",  # Format to 2 decimal places\n",
        "                f\"{train_std:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{eval_std:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{min_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{max_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{min_eval_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{max_eval_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{bleu_score:.4f}\",  # Format to 4 decimal places  # Include BLEU score\n",
        "                f\"{f1_score:.4f}\",  # Format to 4 decimal places  # Include F1 score\n",
        "                f\"{learning_rate:.4f}\",  # Learning rate\n",
        "                batch_size,  # Batch size\n",
        "                epochs, # Epochs\n",
        "                state.global_step if state else \"n/a\",  # Global steps\n",
        "                state.epoch if state else \"n/a\",  # Epoch\n",
        "                state.is_local_process_zero if state else \"n/a\",\n",
        "                control.should_training_stop if control else \"n/a\",\n",
        "                control.should_log if control else \"n/a\",\n",
        "                control.should_save if control else \"n/a\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    headers = [\n",
        "        \"Dataset\",\n",
        "        \"Model\",\n",
        "        \"Elapsed Time\",\n",
        "        \"Train Loss Std\",\n",
        "        \"Eval Loss Std\",\n",
        "        \"Min Train Loss\",\n",
        "        \"Max Train Loss\",\n",
        "        \"Min Eval Loss\",\n",
        "        \"Max Eval Loss\",\n",
        "        \"BLEU Score\",  # Include header for BLEU Score\n",
        "        \"F1 Score\",  # Include header for F1 Score\n",
        "        \"Learning Rate\",\n",
        "        \"Batch Size\",\n",
        "        \"Epochs\",\n",
        "        \"Global Steps\",\n",
        "        \"Epoch\",\n",
        "        \"Is Local Process Zero\",\n",
        "        \"Should Training Stop\",\n",
        "        \"Should Log\",\n",
        "        \"Should Save\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Format the report as a table\n",
        "    report_table = tabulate(report_data, headers=headers, tablefmt=\"grid\")\n",
        "\n",
        "    # Print the report to the console\n",
        "    print(report_table)\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(report_table)\n",
        "        print(f\"Report saved to {output_file}\")\n",
        "\n",
        "rl_pairs = create_rl_pairs()\n",
        "# Run the experiment\n",
        "import time\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING before running the experiment loop\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Enable synchronous CUDA operations\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'  # Enable device-side assertions\n",
        "\n",
        "agents = []\n",
        "training_args_list = []\n",
        "state_list = []\n",
        "control_list = []\n",
        "experiment_names = []\n",
        "\n",
        "for dataset_name, model_id, config in rl_pairs:\n",
        "    clear_memory()\n",
        "    print(\"\\n\")\n",
        "    print(f\"Running experiment with:\")\n",
        "    print(f\"- Dataset: {dataset_name}\")\n",
        "    print(f\"- Model: {model_id}\")\n",
        "    print(f\"- Config: {config}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    try:\n",
        "        agent = FineTuningAgent(model_id, dataset_name, config)\n",
        "        agents.append(agent) # Append the agent to the list immediately\n",
        "        agent.start_time = time.time()\n",
        "        agent.run()\n",
        "        agent.end_time = time.time()\n",
        "        # Collect training details after training\n",
        "        if agent.trainer is not None:\n",
        "          # Store experiment name and other relevant data\n",
        "            experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "            experiment_names.append(experiment_name)\n",
        "            # agents.append(agent) # Removed, agent has already been appended above\n",
        "            training_args_list.append(agent.training_args)\n",
        "            state_list.append(agent.trainer.state)\n",
        "            control_list.append(agent.trainer.control)\n",
        "        else:  # Append dummy values if training failed\n",
        "            training_args_list.append(None)  # or a suitable placeholder\n",
        "            state_list.append(None)\n",
        "            control_list.append(None)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the experiment: {e}\")\n",
        "        agent.end_time = time.time()\n",
        "        agent.start_time = time.time()\n",
        "        training_args_list.append(None)  # or a suitable placeholder\n",
        "        state_list.append(None)\n",
        "        control_list.append(None)\n",
        "\n",
        "# Call generate_report outside the loop, after all experiments are done\n",
        "#generate_report(rl_pairs, agents, training_args_list, state_list, control_list, experiment_name=experiment_names)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RemE3xmbN-Af",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "273c9c13b0f94524a874130a15c1fc30",
            "3c977e8ded324604991002c43e18e680",
            "2daa951754554751b8a70a200634d434",
            "4613ba16ce7a4b1299492e0048dd4c39",
            "33e4875d8ad24391aaa0e3228a6537db",
            "c376ff8a72ef49e98ab16434a9051f05",
            "188c9f31a34042f582fbe92e1213db63",
            "32ad2469be084ba5b2bf0115df5cd864",
            "ef13185072494ffca84cfca8eef9ea83",
            "547b5eaaf013493d834cb7e6203d6cbd",
            "ecef42b7326948fe98d382b2bc9e6350",
            "957efee8180b4d27b6729548f3d93b72",
            "0429dfcda5964d949d2bf76cab3a787a",
            "5986c8a1d5334d86b61dc091c99dbf79",
            "5c7abf715d17460fbdf336e1ea47fe85",
            "d9a36ffe01df4d56ade0222e99c4f608",
            "af0e1a2352a4414abb36dcd50e9efe57",
            "8a570f6d28544ebba13154abe0a90bcc",
            "af98efc36b604f008417e738e474d329",
            "fc3ce99fa111418f8509d02a18bad5c9",
            "fc636276fff64d5899e843061e63b9f0",
            "12423b7de3084442b099f845472c5235",
            "ca329fa451c74500a09b8313d81c402d",
            "be53900c51d046c89d4b095ce0c00370",
            "010f9d19bc034a26ae3476bb3ad75718",
            "c0258d48b1814f89a45a7713f28d291c",
            "98a5687c7d354432b435a0c945240a6e",
            "9bf4ac5f0f9e4848bbf1da417f2fd008",
            "5297d614c353439a9411bc868cd99aa1",
            "711bdf4e03dc4e9b90d9702f9ea0ade9",
            "64a9754b50704907b967655f71e47a7f",
            "f7bec39586fc45459b0da3fbc6d87832",
            "1bfaa831e88e469db5acb7b02285a689",
            "2b4a7d91dc1a466b90956058f2cb0d4c",
            "2183642150a44657bc5c84eaefdfa87e",
            "4f01bc6336cf4bb8af744ab569b3af3c",
            "b60f3517284a44c184b2a575b97338d7",
            "5f2c951eea92448687964e5b72bd22cb",
            "7fe19b1ba6a541a2820756c863639e18",
            "ff0aa163a77b4733b966f5ace95c08ab",
            "85037e47079642df89bfee69fa6c7f28",
            "4465153b9575429d8334d693af7eca59",
            "4fce67937d1344c6be6d76aaeac5f42e",
            "a3f1d610aba740afbeacb7a089e72604",
            "f8ef0e0e74004055a0c79325b5fefeb7",
            "8b2d078bcbc64d7d8288f3654fbc821e",
            "e821412fa5524db7b1d8a7dce82afb13",
            "7c4cf5b9683645a79bca485cbfc299c1",
            "4422a362b01349819ab320d7d18f9770",
            "19e662f244b2411bb59ca11ef48a90c4",
            "0535c16a50414d938d75ac2fd12bf7cf",
            "92b18d868cec4acf91f8106d74bc02a5",
            "347b066e56174c6686651a11cbe2b187",
            "bf16cbb5b7ac4d2690ad3479448c2faa",
            "0f0c6645ad444929a1654075c537cc2e",
            "37451049180346468810e3f2a2a55aa0",
            "8bb7d30ed24547dfa02c98a5626fd4f3",
            "ba9f85f5153840e5a219ad181f29660b",
            "a925546911f6447b88eb681b1a429ee6",
            "f772172ad7844426ac61c188b739fa5d",
            "516d7a88e03c4e7885c38d11b7bdfb08",
            "e01d2055eb5646f5af0b627f2dee9b7d",
            "486079a2c6a74d48b7ab3409ca42a89b",
            "f9293531a44546fab55f782087c920e2",
            "68fcbdc2304c4034851ac7ee1efb3239",
            "42b44e67e131496f870738921cb687ec",
            "f0ddfeca52e24ae9ae1d90940a939d4c",
            "80ec9ca5ed01416d8979d1d2ef6579d8",
            "5931c3457ab74d06b08fda8d77b5f678",
            "35d7851eece44f9e9e2a0a29fed67bb9",
            "72f6255b4601443792c3b259883cf079",
            "abb43416e50745d1be8ce3de70b31dc1",
            "d2ed1e5ac31c4950904fbfedff8ddaee",
            "30ae454bbafe4badb3e40957077bed2b",
            "e47778c78a514935854ee0d1399bf4a7",
            "f1ba162f26204b7fb3fccac6028c58c9",
            "b3f9061f6b60418c98b00930becb3a4f",
            "0022942ee519425789cfcf2d0e6323d5",
            "755283c99f9143069780bbbf7080b0c3",
            "c7186f44a8a0455f96c753a131a8315d",
            "c70f5123ac1b47d9b44189dcd8f5c132",
            "063826bcf2ea4e28aba3c83b0b4447ab",
            "3ac5d5156c7a41d88556bf4a15fa8bf5",
            "33706d2191674f679511c90f5e93a21b",
            "254a4664550a4c9793d1813c6741dede",
            "a50079c970494fbbad9e2d13b4639299",
            "6cc8c08cc3574deea02a9daf5a46947d",
            "56486bc8351d4e08a15f514c915a6e87",
            "b6345959ccac4ccc85547b3201a86fa2",
            "b9994e5e3afd458b9a173ce94a3cb0ab",
            "6d5ad49333eb4f229604fd6638fd2a80",
            "4b2ec59ad3244bfd9368d2509a35ed2b",
            "36ed8563efb048f2b325107a89e865b2",
            "db09a79c414149a09f3a6e13d4061403",
            "803a95b1a30b4290a915ccb80455b04a",
            "fe4626e8d47c4315920074025567633e",
            "887dbe6944f84404983e6ddf38e05f99",
            "4d5a9cb1cd8d4262ad4e3d4b8f90508a",
            "4890ff08ddd14e57b0c7c0d59609272a",
            "e2a2311d93ef421f9d6e920398f098bb",
            "cb737b1b1a0e4586803f19ec73d74e42",
            "ccb2ce1b1c5b42f79b07e1e1143f75ce",
            "b5d594c6064643c1bee90a610b9717ee",
            "5d00ef580af14f688b423bcb2211d98c",
            "a46dd4c3b34a43eb9621a8d2bc129cf7",
            "15d30655a534442f84c3523e673415e4",
            "553eacb833ad4871a97c593d3db3a832",
            "9b685309bb8f4dd799a6725730ada655",
            "3ce3e33939744a40901171feb594d074",
            "28aff07165074222b88873c5cdf199a6",
            "2af7f46351e04e9f9b0d1582b3df8cf6",
            "437c39eaa37a48b7a1a6cd0a79264ca7",
            "138eb4b90b6844d8ae3391962b6b469b",
            "718ce67270704eeda06a3054faf46864",
            "91a2f5712c9e48c28cdc05018102a227",
            "1d0cf456de654e84ab59890848f1ebb7",
            "5b981073d19b4f1990e2549b992ca322",
            "c67b926c3a914b4f890cda729e5854c2",
            "0e4a074050344cb1abee64797f1b02eb",
            "f2dcadd6914b4fb5941c1fc9d117ca2e",
            "fca14ee46d1a418c9c57066d2d2f4055",
            "d0512cc96ab244369eac30ab0eafaf07",
            "88ec5d7375a5431693e830656bdbc681",
            "5aa6cf172e3e42bf9b9f28d4eb8cf11c",
            "7369e0769b7e403b8409a63b7102555a",
            "beb22b04304e41a7aade35b4315a8063",
            "dffac94dea2b4a9a9a16f54de4e5ca21",
            "0075a11baf984ad9bb25e21a1966d102",
            "263a13af1e2d4993bf01bf1f1c50b7f9",
            "496e6425355248f9ab3b0bb656b6aef5",
            "4ef0b9f138f64d68b87f06cac620c9bd",
            "1ddcef9c615f41ba989325a1adff56e1"
          ]
        },
        "outputId": "f35f1853-dc78-4b02-8b95-6c8dab4f1e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: sakharamg/AviationQA\n",
            "- Model: mistralai/Mistral-7B-v0.1\n",
            "- Config: {'max_length': 1000, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 1000, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'use_cache': False, 'per_device_train_batch_size': 3, 'gradient_accumulation_steps': 2, 'warmup_steps': 10, 'optim': 'adamw_torch_fused', 'num_train_epochs': 1, 'max_steps': 100, 'learning_rate': 0.0001, 'logging_steps': 10, 'bf16': True, 'tf32': True, 'lr_scheduler_type': 'constant', 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20, 'evaluation_strategy': 'steps', 'logging_strategy': 'steps', 'load_best_model_at_end': True, 'metric_for_best_model': 'eval_loss'}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n",
            "Starting Observe ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "273c9c13b0f94524a874130a15c1fc30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset AviationQA .....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/1058 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "957efee8180b4d27b6729548f3d93b72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca329fa451c74500a09b8313d81c402d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b4a7d91dc1a466b90956058f2cb0d4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset AviationQA - New Approach.....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8ef0e0e74004055a0c79325b5fefeb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37451049180346468810e3f2a2a55aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0ddfeca52e24ae9ae1d90940a939d4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0022942ee519425789cfcf2d0e6323d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6345959ccac4ccc85547b3201a86fa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2a2311d93ef421f9d6e920398f098bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2af7f46351e04e9f9b0d1582b3df8cf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0512cc96ab244369eac30ab0eafaf07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Dataset - Loaded with NA  Observe: None\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Observe finished.\n",
            "Function _observe took 278.2938 seconds to execute\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "\n",
            "\n",
            "NO NEED -  preprocessing_functioDataset: AviationQA\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Orient Dataset(train): Dataset({\n",
            "    features: ['id', 'Question', 'Answer', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 100\n",
            "})\n",
            " Orient Dataset(test): Dataset({\n",
            "    features: ['id', 'Question', 'Answer', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 20\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "Function _orient took 0.0212 seconds to execute\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 20,971,520 || all params: 7,262,711,808 || trainable%: 0.2888\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "Function _decide took 0.9429 seconds to execute\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "\n",
            "\n",
            "Initializing Trainer for AviationQA...\n",
            "\n",
            "\n",
            "Function _act took 0.4542 seconds to execute\n",
            "\n",
            "\n",
            "Run - Dataset(train): Dataset({\n",
            "    features: ['id', 'Question', 'Answer', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 100\n",
            "})\n",
            "Run -  Dataset(test): Dataset({\n",
            "    features: ['id', 'Question', 'Answer', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 20\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  6/100 01:59 < 46:59, 0.03 it/s, Epoch 0.29/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load"
      ],
      "metadata": {
        "id": "skfdU3eWoYAH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm report"
      ],
      "metadata": {
        "id": "BRmauENT7tWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Used to securely store your API key\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')  # Replace 'GEMINI' with your actual userdata variable name\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "from tabulate import tabulate\n",
        "from transformers import TrainingArguments, TrainerState, TrainerControl\n",
        "\n",
        "def generate_llm_report(\n",
        "    rl_pairs,\n",
        "    agents,\n",
        "    training_args_list,\n",
        "    state_list,\n",
        "    control_list,\n",
        "    output_file=\"experiment_report.txt\",\n",
        "    experiment_name=None,\n",
        "    prompt=\"You are a helpful data science expert.\\nPlease, make an additional analysis of this Fine-Tuning experiment report.\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates a report for multiple LLM experiments, including evaluation scores and training details,\n",
        "    and provides an analysis using Google Gemini.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): A list of tuples, each containing (dataset_name, model_id, config).\n",
        "        agents (list): A list of FineTuningAgent objects corresponding to the experiments.\n",
        "        training_args_list (list): A list of TrainingArguments objects for each experiment.\n",
        "        state_list (list): A list of TrainerState objects for each experiment.\n",
        "        control_list (list): A list of TrainerControl objects for each experiment.\n",
        "        output_file (str): The name of the output file to save the report.\n",
        "        experiment_name (str, optional): The base name for the experiment results file.\n",
        "                                        If provided, it will be used to load the results. Defaults to None.\n",
        "        prompt (str, optional): The prompt to provide to Google Gemini for analysis.\n",
        "                                Defaults to a generic data science expert prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    if not (\n",
        "        len(rl_pairs)\n",
        "        == len(agents)\n",
        "        == len(training_args_list)\n",
        "        == len(state_list)\n",
        "        == len(control_list)\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"The number of rl_pairs, agents, training_args, state, and control must be the same.\"\n",
        "        )\n",
        "\n",
        "    report_data = []  # Initialize report_data here\n",
        "\n",
        "    for (\n",
        "        (dataset_name, model_id, config),\n",
        "        agent,\n",
        "        training_args,\n",
        "        state,\n",
        "        control,\n",
        "    ) in zip(rl_pairs, agents, training_args_list, state_list, control_list):\n",
        "        # Get eval_results from the agent\n",
        "\n",
        "        #print(f\"Model ID: {model_id}\")\n",
        "\n",
        "        experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "\n",
        "        results_file = f\"{experiment_name}_results.txt\"\n",
        "        #print(f\"Results File: {results_file}\")\n",
        "\n",
        "\n",
        "        from pathlib import Path\n",
        "        # Define the file path\n",
        "        file_path = Path(results_file)\n",
        "\n",
        "        if file_path.exists():\n",
        "            #print(\"File exists!\")\n",
        "            #print(f\"Results File: {results_file}\")\n",
        "            print\n",
        "            #return\n",
        "        else:\n",
        "            #print(\"File does not exist.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        training_args=agent.training_args\n",
        "\n",
        "        experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "        #print(f\"Experiment Name: {experiment_name}\")\n",
        "\n",
        "        results_file = f\"{experiment_name}__uftfresults.txt\"\n",
        "        #results_file = os.path.join(current_directory, f\"{experiment_name}_uftfresults.txt\")\n",
        "        #print(f\"Results File: {results_file}\")\n",
        "\n",
        "        #print(training_args_list)\n",
        "\n",
        "\n",
        "        # \"eval_loss\": 6.17133903503418, \"eval_bleu\": 0, \"eval_f1\": 0.0, \"eval_runtime\": 4.0188, \"eval_samples_per_second\": 6.221, \"eval_steps_per_second\": 0.995, \"epoch\": 8.64}\n",
        "\n",
        "        try:\n",
        "            with open(results_file, \"r\") as f:\n",
        "                evaluation_results = json.load(f)\n",
        "            bleu_score = evaluation_results.get(\"eval_bleu\")\n",
        "            f1_score = evaluation_results.get(\"eval_f1\")\n",
        "            #print(f\"BLEU Score: {bleu_score}, F1 Score: {f1_score}\")\n",
        "            #print(f\"Eval Results: {evaluation_result}\")\n",
        "\n",
        "             # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "            rouge1_precision = evaluation_results.get('eval_rouge1', {}).get('precision')\n",
        "            rouge1_recall = evaluation_results.get('eval_rouge1', {}).get('recall')\n",
        "            rouge1_fmeasure = evaluation_results.get('eval_rouge1', {}).get('fmeasure')\n",
        "            #print(f\"ROUGE-1 Precision: {rouge1_precision}, Recall: {rouge1_recall}, F-measure: {rouge1_fmeasure}\")\n",
        "\n",
        "            # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "\n",
        "\n",
        "            rouge2_precision = evaluation_results.get('eval_rouge2', {}).get('precision')\n",
        "            rouge2_recall = evaluation_results.get('eval_rouge2', {}).get('recall')\n",
        "            rouge2_fmeasure = evaluation_results.get('eval_rouge2', {}).get('fmeasure')\n",
        "\n",
        "\n",
        "            # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "            rougeL_precision = evaluation_results.get('eval_rougeL', {}).get('precision')\n",
        "            rougeL_recall = evaluation_results.get('eval_rougeL', {}).get('recall')\n",
        "            rougeL_fmeasure = evaluation_results.get('eval_rougeL', {}).get('fmeasure')\n",
        "\n",
        "\n",
        "           # {\"eval_loss\": 3.720398187637329, \"eval_bleu\": 0, \"eval_f1\": 0.0, \"eval_rouge1\": {\"precision\": 0.396081703619663, \"recall\": 0.40836230306837384, \"fmeasure\": 0.40190438521178246}, \"eval_rouge2\": {\"precision\": 0.07832895449176241, \"recall\": 0.08075765617251687, \"fmeasure\": 0.07946492337001675}, \"eval_rougeL\": {\"precision\": 0.3623965364533813, \"recall\": 0.37335556072231263, \"fmeasure\": 0.3675868060434595},\n",
        "            #\"eval_perplexity\": 45.677459716796875, \"eval_runtime\": 1.1153, \"eval_samples_per_second\": 22.415, \"eval_steps_per_second\": 3.586, \"epoch\": 62.64}\n",
        "\n",
        "            perplexity = evaluation_results.get(\"eval_perplexity\", \"N/A\")\n",
        "            #print(f\"Perplexity: {perplexity}\")\n",
        "\n",
        "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "            print(f\"Error loading results: {e}\")\n",
        "            bleu_score = None\n",
        "            f1_score = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Collect the data\n",
        "        elapsed_time = (\n",
        "            agent.end_time - agent.start_time\n",
        "            if agent.start_time and agent.end_time\n",
        "            else np.nan\n",
        "        )  # Handle potential errors\n",
        "        train_losses = agent.train_losses\n",
        "        eval_losses = agent.eval_losses\n",
        "\n",
        "        if not train_losses:\n",
        "            train_std = np.nan  # Use np.nan for no data\n",
        "            min_train_loss = np.nan\n",
        "            max_train_loss = np.nan\n",
        "        else:\n",
        "            #print(f\"Train Losses: {train_losses}\")\n",
        "            train_loss = np.mean(train_losses)\n",
        "            train_loss_std = np.std(train_losses)\n",
        "            min_train_loss = np.min(train_losses)\n",
        "            max_train_loss = np.max(train_losses)\n",
        "\n",
        "        if not eval_losses:\n",
        "            eval_std = np.nan\n",
        "            min_eval_loss = np.nan\n",
        "            max_eval_loss = np.nan\n",
        "        else:\n",
        "            #print(f\"Eval Losses: {eval_losses}\")\n",
        "            eval_loss = np.mean(eval_losses)\n",
        "            eval_loss_std = np.std(eval_losses)\n",
        "            min_eval_loss = np.min(eval_losses)\n",
        "            max_eval_loss = np.max(eval_losses)\n",
        "\n",
        "        # Check if training_args is None before accessing its attributes\n",
        "        learning_rate = training_args.learning_rate if training_args is not None else np.nan\n",
        "        batch_size = training_args.per_device_train_batch_size if training_args is not None else np.nan\n",
        "        epochs = training_args.num_train_epochs if training_args is not None and hasattr(training_args, \"num_train_epochs\") else \"n/a\"\n",
        "        #print(f\"Learning Rate: {learning_rate}\")\n",
        "        #print(f\"Batch Size: {batch_size}\")\n",
        "        #print(f\"Epochs: {epochs}\")\n",
        "\n",
        "        report_data.append(\n",
        "            [\n",
        "                dataset_name,\n",
        "                model_id,\n",
        "                f\"{elapsed_time:.2f} seconds\",  # Format to 2 decimal places\n",
        "                f\"{train_loss:.4f}\" if train_loss is not None else \"N/A\",  # Handle None case for train_loss\n",
        "                f\"{eval_loss:.4f}\" if eval_loss is not None else \"N/A\",  # Handle None case for eval_loss\n",
        "\n",
        "                f\"{train_loss_std:.4f}\" if train_loss_std is not None else \"N/A\",  # Handle None case for train_loss_std\n",
        "                f\"{eval_loss_std:.4f}\" if eval_loss_std is not None else \"N/A\",  # Handle None case for eval_std\n",
        "\n",
        "                f\"{min_train_loss:.4f}\" if min_train_loss is not None else \"N/A\",  # Handle None case for min_train_loss\n",
        "                f\"{max_train_loss:.4f}\" if max_train_loss is not None else \"N/A\",  # Handle None case for max_train_loss\n",
        "\n",
        "                f\"{min_eval_loss:.4f}\" if min_eval_loss is not None else \"N/A\",  # Handle None case for min_eval_loss\n",
        "                f\"{max_eval_loss:.4f}\" if max_eval_loss is not None else \"N/A\",  # Handle None case for max_eval_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                f\"{bleu_score:.4f}\" if bleu_score is not None else \"N/A\",  # Handle None case for bleu_score\n",
        "                f\"{f1_score:.4f}\" if f1_score is not None else \"N/A\",  # Handle None case for f1_score\n",
        "\n",
        "                f\"{rouge1_precision:.4f}\" if rouge1_precision is not None else \"N/A\",  # Handle None case for rouge1_precision\n",
        "                f\"{rouge1_recall:.4f}\" if rouge1_recall is not None else \"N/A\",  # Handle None case for rouge1_recall\n",
        "                f\"{rouge1_fmeasure:.4f}\" if rouge1_fmeasure is not None else \"N/A\",  # Handle None case for rouge1_fmeasure\n",
        "\n",
        "                f\"{rouge2_precision:.4f}\" if rouge2_precision is not None else \"N/A\",  # Handle None case for rouge2_precision\n",
        "                f\"{rouge2_recall:.4f}\" if rouge2_recall is not None else \"N/A\",  # Handle None case for rouge2_recall\n",
        "                f\"{rouge2_fmeasure:.4f}\" if rouge2_fmeasure is not None else \"N/A\",  # Handle None case for rouge2_fmeasure\n",
        "\n",
        "                f\"{rougeL_precision:.4f}\" if rougeL_precision is not None else \"N/A\",  # Handle None case for rougeL_precision\n",
        "                f\"{rougeL_recall:.4f}\" if rougeL_recall is not None else \"N/A\",  # Handle None case for rougeL_recall\n",
        "                f\"{rougeL_fmeasure:.4f}\" if rougeL_fmeasure is not None else \"N/A\",  # Handle None case for rougeL_fmeasure\n",
        "\n",
        "                f\"{perplexity:.4f}\" if perplexity is not None else \"N/A\",  # Handle None case for perplexity\n",
        "\n",
        "                f\"{learning_rate:.4f}\" if learning_rate is not None else \"N/A\",  # Handle None case for learning_rate\n",
        "                f\"{batch_size}\" if batch_size is not None else \"N/A\",  # Handle None case for batch_size\n",
        "                f\"{epochs}\" if epochs is not None else \"N/A\",  # Handle None case for epochs\n",
        "\n",
        "                #f\"{state.global_step}\" if state is not None else \"N/A\",  # Handle None case for global_step\n",
        "                #f\"{state.epoch}\" if state is not None else \"N/A\",  # Handle None case for epoch\n",
        "                #f\"{learning_rate:.4f}\",  # Learning rate\n",
        "                #batch_size,  # Batch size\n",
        "                #epochs,  # Epochs\n",
        "                #state.global_step if state else \"n/a\",  # Global steps\n",
        "                #state.epoch if state else \"n/a\",  # Epoch\n",
        "                #state.is_local_process_zero if state else \"n/a\",\n",
        "                #control.should_training_stop if control else \"n/a\",\n",
        "                #control.should_log if control else \"n/a\",\n",
        "               # control.should_save if control else \"n/a\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Generate the report table\n",
        "    headers = [\n",
        "        \"Dataset\",\n",
        "        \"Model\",\n",
        "        \"Elapsed Time\",\n",
        "        \"Train Loss (Average)\",\n",
        "        \"Eval Loss (Average)\",\n",
        "        \"Train Loss (Std)\",\n",
        "        \"Eval Loss (Std)\",\n",
        "        \"Min Train Loss\",\n",
        "        \"Max Train Loss\",\n",
        "        \"Min Eval Loss\",\n",
        "        \"Max Eval Loss\",\n",
        "        \"BLEU Score\",\n",
        "        \"F1 Score\",\n",
        "        \"ROUGE-1 Precision\",\n",
        "        \"ROUGE-1 Recall\",\n",
        "        \"ROUGE-1 F-measure\",\n",
        "        \"ROUGE-2 Precision\",\n",
        "        \"ROUGE-2 Recall\",\n",
        "        \"ROUGE-2 F-measure\",\n",
        "        \"ROUGE-L Precision\",\n",
        "        \"ROUGE-L Recall\",\n",
        "        \"ROUGE-L F-measure\",\n",
        "        \"Perplexity\",\n",
        "        \"Learning Rate\",\n",
        "        \"Batch Size\",\n",
        "        \"Epochs\",\n",
        "        \"Global Steps\",\n",
        "        \"Epoch\",\n",
        "        \"is_local_process_zero\",\n",
        "        \"should_training_stop\",\n",
        "        \"should_log\",\n",
        "        \"should_save\",\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    report_table = tabulate(report_data, headers=headers, tablefmt=\"grid\")\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(report_table)\n",
        "\n",
        "    print(report_table)\n",
        "\n",
        "    # LLM Analysis using Google Gemini\n",
        "    model_name = \"gemini-1.5-pro\"  # Replace with desired model\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    response = model.generate_content(prompt + \"\\n\\n\" + report_table)\n",
        "    llm_analysis = response.text\n",
        "\n",
        "    print(\"\\n\\n## LLM Analysis:\\n\")\n",
        "    print(llm_analysis)\n",
        "\n",
        "    #return llm_analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "-smf04UA0mnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9b80039e-b67e-47f1-e6d6-879f58f495e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotebookAccessError",
          "evalue": "Notebook does not have access to secret GEMINI",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotebookAccessError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dc3048b9fa46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Used to securely store your API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mGOOGLE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GEMINI'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'GEMINI' with your actual userdata variable name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'payload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotebookAccessError\u001b[0m: Notebook does not have access to secret GEMINI"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the LLM report and send to Gemini\n",
        "prompt = \"\"\"\n",
        "You are a helpful data science expert.\n",
        "Please, make an additional analysis of this Fine-Tuning experiment report.\n",
        "\"\"\"\n",
        "# Initialize training_args_list, state_list, control_list with empty lists\n",
        "training_args_list = [None] * len(rl_pairs)\n",
        "state_list = [None] * len(rl_pairs)\n",
        "control_list = [None] * len(rl_pairs)\n",
        "\n",
        "generate_llm_report(rl_pairs, agents, training_args_list, state_list, control_list, prompt=prompt)"
      ],
      "metadata": {
        "id": "zmcvPmYQgwvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}