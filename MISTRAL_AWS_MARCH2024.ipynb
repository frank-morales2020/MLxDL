{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY/fMjcYPaZzKppT8q3l7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MISTRAL_AWS_MARCH2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaWcS7jcG5VF"
      },
      "outputs": [],
      "source": [
        "!pip install colab-env --quiet\n",
        "\n",
        "!pip install sagemaker boto3 --quiet\n",
        "\n",
        "#%pip install langchain==0.0.309 --quiet --root-user-action=ignore\n",
        "%pip install langchain --quiet\n",
        "\n",
        "import colab_env\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "output=os.getenv(\"AWS_DEFAULT_OUTPUT\")\n",
        "\n",
        "#print(aws_access_key_id)\n",
        "#print()\n",
        "#print(f\"aws_access_key_id: '{aws_access_key_id}'\")\n",
        "#print(f\"aws_secret_access_key: '{aws_secret_access_key}'\")\n",
        "\n",
        "#print(f\"region: '{region}'\")\n",
        "#print()"
      ],
      "metadata": {
        "id": "AcZLELCdKFcJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama-2\n",
        "https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/\n",
        "\n",
        "claude-3\n",
        "https://aws.amazon.com/blogs/aws/anthropics-claude-3-sonnet-foundation-model-is-now-available-in-amazon-bedrock/\n"
      ],
      "metadata": {
        "id": "AuY8PGbLM9QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import boto3\n",
        "import os\n",
        "import sagemaker\n",
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "\n",
        "# added by frank morales december 13, 2023\n",
        "iam_client = boto3.client(\"iam\")\n",
        "\n",
        "role = iam_client.get_role(\n",
        "    RoleName=os.getenv(\"ROLENAME\")\n",
        ")\n",
        "\n",
        "ROLE_ARN = role['Role']['Arn']\n",
        "\n",
        "# https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-choose.html#jumpstart-foundation-models-choose-eula\n",
        "\n",
        "#original\n",
        "#llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"*\"\n",
        "#llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
        "## error below\n",
        "\n",
        "#modified by frankmorales\n",
        "#llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.*\"\n",
        "\n",
        "### LLAMA-2\n",
        "#llm_model_id = 'meta-textgeneration-llama-2-7b-f'\n",
        "#llm_model_version = '2.0.4'\n",
        "\n",
        "# https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html\n",
        "\n",
        "# https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/examples?provider=Anthropic\n",
        "\n",
        "## MISTRAL\n",
        "llm_model_id = 'huggingface-llm-mistral-7b'\n",
        "llm_model_version = '2.1.0'\n",
        "\n",
        "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version, role=ROLE_ARN, region='us-east-1')\n",
        "\n",
        "\n",
        "#{\n",
        "#  \"modelId\": \"anthropic.claude-v2\",\n",
        "#  \"contentType\": \"application/json\",\n",
        "#  \"accept\": \"application/json\",\n",
        "\n",
        "\n",
        "#modified by frankmorales\n",
        "llm_predictor = llm_model.deploy(accept_eula=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P1dwGh5KWRo",
        "outputId": "7e1552eb-410f-4b5c-fc06-4fc4357eeeee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the model endpoint NAME, not the ARN\n",
        "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
        "llm_model_endpoint_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2XRGT2iULD1w",
        "outputId": "5fd59f1a-ab60-4ba3-e249-23fe33f4f862"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hf-llm-mistral-7b-2024-03-05-12-22-54-803'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "from langchain import PromptTemplate, SagemakerEndpoint\n",
        "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "import json\n",
        "\n",
        "class QAContentHandler(LLMContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
        "        input_str = json.dumps(\n",
        "            {\"inputs\" : [\n",
        "                [\n",
        "                    {\n",
        "                        \"role\" : \"system\",\n",
        "                        \"content\" : \"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\" : \"user\",\n",
        "                        \"content\" : prompt\n",
        "                    }\n",
        "                ]],\n",
        "                \"parameters\" : {**model_kwargs}\n",
        "            })\n",
        "        return input_str.encode('utf-8')\n",
        "\n",
        "    def transform_output(self, output: bytes) -> str:\n",
        "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
        "        ### LLAMA-2\n",
        "        #return response_json[0][\"generation\"][\"content\"]\n",
        "        ### MISTRAL\n",
        "        return response_json[0]['generated_text'][\"content\"]\n",
        "\n",
        "qa_content_handler = QAContentHandler()\n",
        "\n"
      ],
      "metadata": {
        "id": "CZNHvIw_T1pO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QAContentHandler(LLMContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "qa_content_handler = QAContentHandler()"
      ],
      "metadata": {
        "id": "lkyQiftbzqGw"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"region\")\n",
        "output=os.getenv(\"output\")\n",
        "\n",
        "llm = SagemakerEndpoint(\n",
        "        endpoint_name=llm_model_endpoint_name,\n",
        "        region_name=region,\n",
        "        model_kwargs={\"max_new_tokens\": 5000, \"top_p\": 0.9, \"temperature\": 1e-11},\n",
        "        endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
        "        content_handler=qa_content_handler\n",
        "    )"
      ],
      "metadata": {
        "id": "hTF3N40tLQuM"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#original by the book\n",
        "query = \"WHAT IS PERU?\"\n",
        "\n",
        "##modified by Frank Morales\n",
        "response=llm.predict(query)"
      ],
      "metadata": {
        "id": "5UIDEOp3BTGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### MISTRAL ######\n",
        "\n",
        "#original by the book\n",
        "query = \"WHAT IS AWS?\"\n",
        "\n",
        "\n",
        "# Create a boto3 client for SageMaker runtime\n",
        "sm_client = boto3.client('runtime.sagemaker')\n",
        "\n",
        "# Prepare the input for the model\n",
        "#input_data = {\"inputs\": query}\n",
        "\n",
        "### WITH PARAMETRS\n",
        "n=5\n",
        "MNT=512*n\n",
        "model_kwargs={\"max_new_tokens\": MNT, \"temperature\": 0.9}\n",
        "input_data = ({\"inputs\": query, \"parameters\" : {**model_kwargs}})\n",
        "\n",
        "response = sm_client.invoke_endpoint(EndpointName=llm_model_endpoint_name, Body=json.dumps(input_data), ContentType=\"application/json\")\n",
        "\n",
        "# Decode the response from the model\n",
        "response_body = json.loads(response['Body'].read().decode('utf-8'))\n",
        "#print(response_body)\n",
        "\n",
        "print(f'Query:', query)\n",
        "print()\n",
        "print(f'Response:', response_body[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vj8eTH3LYYD",
        "outputId": "1ed3ecb1-0211-4dce-ff67-998ffee31d0c"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: WHAT IS AWS?\n",
            "\n",
            "Response: \n",
            "\n",
            "AWS stands for Amazon Web Services. It provides cloud technology and other services to organizations of all sizes. It’s actually more than a cloud technology. It includes other services as well, like analytics, artificial intelligence, machine learning, Internet of Things, etc.\n",
            "\n",
            "AWS Cloud is incredibly strong. It meets the most rigorous of compliance standards. It can be used to develop, deploy, and scale applications from startups to the enterprise.\n",
            "\n",
            "AWS is among one of the most popular cloud technology providers. Microsoft Azure, IBM Cloud, and Google Cloud are also among the most popular. Today, we’re going to focus on AWS.\n",
            "\n",
            "Types of the AWS cloud\n",
            "\n",
            "There are three models of AWS cloud services. They are available with their own set of features. A customer can pick the type of service that works best for the scale of their operation.\n",
            "\n",
            "Compatibility with AWS services\n",
            "\n",
            "The advantage of AWS cloud is its compatibility with third-party providers. The cloud is accessible via many different clients and comes with its own APIs. Customers never have to worry about vendor lock-in and can use the most suitable AWS services.\n",
            "\n",
            "Prices of the AWS cloud\n",
            "\n",
            "AWS charges the customers only for the resources that they use. This is more efficient than the flat fee model. Users only have to pay for the storage space, bandwidth, workload they really need.\n",
            "\n",
            "Some of AWS’s competitors charge customers for the total amount of storage they reserve, regardless of whether they need it or not. On the other hand, AWS bills the customers based on the amount of storage they use.\n",
            "\n",
            "Flexibility\n",
            "\n",
            "AWS cloud gives the users flexibility. They can easily scale services up or down based on demand. Developers can choose the tools that best suit their needs. AWS stresses self-service. The users get full control over their services and information. It ensures that developers can easily manage their operations.\n",
            "\n",
            "Security\n",
            "\n",
            "AWS prioritizes everything regarding security. This is key for organizations to trust a cloud services provider. When looking for the best cloud services, enterprises have many offerings to choose from. AWS has strong compliance. It has committed to abide by some of the toughest industry standards. The cloud solution has several certifications under its belt.\n",
            "\n",
            "It has passed audits from both the Defense Department and the FBI. It complies with the Federal Rules of Civil Procedure (FRCP), Health Insurance Portability and Accountability Act (HIPAA), and the Payment Card Industry Data Security Standard (PCI DSS).\n",
            "\n",
            "If you still have doubts about Amazon’s security and reliability, you can trust the giants like Adobe, Coca-Cola, Expedia, HP, and Verizon Wireless. They use AWS cloud to run a huge part of their businesses. These organizations use AWS cloud services on a global scale. They are good enough proof of Amazon’s services.\n",
            "\n",
            "Building and developing apps in AWS cloud\n",
            "\n",
            "Flexibility is the most beneficial AWS cloud service. It allows its users to select a solution that meets their custom-tailored needs and budget requirements. Developers can easily integrate their features across different tools.\n",
            "\n",
            "Cost\n",
            "\n",
            "Cost is the ultimate deciding factor for most of the clients. AWS has a pay-as-you-go pricing model. Customer pays only for the resources they use. This means that they don’t have to pay for what they don’t use. This is the main reason why many small businesses prefer AWS cloud.\n",
            "\n",
            "This pricing strategy has made AWS cloud cost-efficient for organizations of all sizes. Moreover, customers can save money by choosing long-term contracts. Long-term contracts offer added benefits such as:\n",
            "\n",
            "- Reduced upfront commitment\n",
            "- Lower spot pricing\n",
            "- A chance to get limited-availability offers\n",
            "- A designated relationship manager to help with billing issues\n",
            "\n",
            "No wonder, businesses from all over the world trust AWS for the mentioned benefits and features.\n",
            "\n",
            "Amazon’s hosting capacity\n",
            "\n",
            "It’s no surprise why Amazon is so successful. Its cloud capacity is huge. Amazon Web Services is one of the largest cloud computing platforms. It meets the customer’s demands for resources and storage. Nothing is ever too big for Amazon. Whenever there is a big problem because of large data intake, you know who to count on!\n",
            "\n",
            "Amazon has a global network of centers located across 20 regions and 65 availability zones. This massive network gives the company an edge. None of the other cloud-computing companies match Amazon’s capacity. This is the main reason why Amazon is preferred by a lot of customers. Amazon Web Services (AWS) is the world’s most extensive and quickest cloud computing platform available today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLEAN UP"
      ],
      "metadata": {
        "id": "yHCOvGVoLoRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Frank Morales created this cell on December 14, 2023; it fully allows automatically the deletion of endpoints, models, and endpoint configurations.\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "aws_region=os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "aws_output=os.getenv(\"AWS_DEFAULT_OUTPUT\")\n",
        "\n",
        "import boto3\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "\n",
        "def cleanup_sagemaker_resources(resource_name,resourceid):\n",
        "\n",
        "    if resourceid==0:\n",
        "       response=sagemaker_client.list_endpoints()\n",
        "    elif resourceid==1:\n",
        "         response=sagemaker_client.list_models()\n",
        "    elif resourceid==2:\n",
        "         response=sagemaker_client.list_endpoint_configs()\n",
        "\n",
        "    print(resource_name)\n",
        "\n",
        "    number_of_endpoints=len(response['%s'%resource_name])\n",
        "    for i in range(number_of_endpoints):\n",
        "        resource_nametmp='%s'%resource_name[0:len(resource_name)-1]\n",
        "        print('%sName'%resource_nametmp)\n",
        "        print(response['%s'%resource_name][i]['%sName'%resource_nametmp])\n",
        "\n",
        "        if resourceid==0:\n",
        "           endpoint_name=response['%s'%resource_name][i]['%sName'%resource_nametmp]\n",
        "           sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
        "        elif resourceid==1:\n",
        "           sagemaker_client.delete_model(ModelName=response['Models'][i]['ModelName'])\n",
        "        elif resourceid==2:\n",
        "           sagemaker_client.delete_endpoint_config(EndpointConfigName=response['EndpointConfigs'][i]['EndpointConfigName'])\n",
        "\n",
        "    print(\"\\n==================================\\n\")\n",
        "\n",
        "\n",
        "cleanup_sagemaker_resources('Endpoints',0)\n",
        "cleanup_sagemaker_resources('Models',1)\n",
        "cleanup_sagemaker_resources('EndpointConfigs',2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mnSz_gVLtPS",
        "outputId": "b96a558d-43ff-40e3-bc45-5390795a5fd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoints\n",
            "\n",
            "==================================\n",
            "\n",
            "Models\n",
            "\n",
            "==================================\n",
            "\n",
            "EndpointConfigs\n",
            "\n",
            "==================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}