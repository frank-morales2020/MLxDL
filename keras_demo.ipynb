{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuTmV9JNJIr+gUwT1rFWtd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB-SEFdL9VCu"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder(hp):\n",
        "    \"\"\"\n",
        "    A function that builds a Keras model and defines the hyperparameter search space.\n",
        "    \"\"\"\n",
        "    # Initialize a sequential model\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(28, 28))) # Input layer for 28x28 images\n",
        "\n",
        "    # Tune the number of units in the first Dense layer.\n",
        "    # hp.Int() defines an integer hyperparameter with a name, min value, max value, and step.\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(layers.Dense(10)) # Output layer for 10 classes\n",
        "\n",
        "    # Tune the learning rate for the Adam optimizer.\n",
        "    # hp.Choice() allows you to choose from a list of discrete values.\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile the model with the tunable learning rate\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3ruz5ThL9iG2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Create a tuner instance\n",
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5, # Try 5 different combinations\n",
        "    executions_per_trial=3, # Train each model 3 times\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "# Prepare data (e.g., using a dataset like MNIST)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_val, y_val = x_test[:5000], y_test[:5000]\n",
        "x_test, y_test = x_test[5000:], y_test[5000:]\n",
        "\n",
        "# Start the search\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0FneoNR9jSY",
        "outputId": "bb22f0e8-6434-4077-99c4-6afaa766fc57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 08m 38s]\n",
            "val_accuracy: 0.9697333375612894\n",
            "\n",
            "Best val_accuracy So Far: 0.9738666613896688\n",
            "Total elapsed time: 00h 27m 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"The best number of units in the first layer is {best_hps.get('units')}.\")\n",
        "print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\")\n",
        "\n",
        "# Build and train the final model with the best hyperparameters\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(x_test, y_test)\n",
        "print(f\"\\nFinal model test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4VluN9t9qvK",
        "outputId": "55c7891b-beb4-436e-c843-e309db532df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best number of units in the first layer is 192.\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9876 - val_loss: 0.0460\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.9864 - val_loss: 0.0497\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9874 - val_loss: 0.0490\n",
            "Epoch 4/50\n",
            "\u001b[1m1460/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0082"
          ]
        }
      ]
    }
  ]
}