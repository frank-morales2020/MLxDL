{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhHFpM1leUEzExpBYxvpFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB-SEFdL9VCu"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder(hp):\n",
        "    \"\"\"\n",
        "    A function that builds a Keras model and defines the hyperparameter search space.\n",
        "    \"\"\"\n",
        "    # Initialize a sequential model\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(28, 28))) # Input layer for 28x28 images\n",
        "\n",
        "    # Tune the number of units in the first Dense layer.\n",
        "    # hp.Int() defines an integer hyperparameter with a name, min value, max value, and step.\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(layers.Dense(10)) # Output layer for 10 classes\n",
        "\n",
        "    # Tune the learning rate for the Adam optimizer.\n",
        "    # hp.Choice() allows you to choose from a list of discrete values.\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile the model with the tunable learning rate\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3ruz5ThL9iG2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Create a tuner instance\n",
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5, # Try 5 different combinations\n",
        "    executions_per_trial=3, # Train each model 3 times\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "# Prepare data (e.g., using a dataset like MNIST)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_val, y_val = x_test[:5000], y_test[:5000]\n",
        "x_test, y_test = x_test[5000:], y_test[5000:]\n",
        "\n",
        "# Start the search\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0FneoNR9jSY",
        "outputId": "bb22f0e8-6434-4077-99c4-6afaa766fc57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 08m 38s]\n",
            "val_accuracy: 0.9697333375612894\n",
            "\n",
            "Best val_accuracy So Far: 0.9738666613896688\n",
            "Total elapsed time: 00h 27m 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"The best number of units in the first layer is {best_hps.get('units')}.\")\n",
        "print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\")\n",
        "\n",
        "# Build and train the final model with the best hyperparameters\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4VluN9t9qvK",
        "outputId": "55c7891b-beb4-436e-c843-e309db532df3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best number of units in the first layer is 192.\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9876 - val_loss: 0.0460\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.9864 - val_loss: 0.0497\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9874 - val_loss: 0.0490\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.9882 - val_loss: 0.0434\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9882 - val_loss: 0.0576\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 0.9854 - val_loss: 0.0623\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9896 - val_loss: 0.0436\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9826 - val_loss: 0.0755\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.9852 - val_loss: 0.0665\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9886 - val_loss: 0.0546\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9874 - val_loss: 0.0563\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9896 - val_loss: 0.0545\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9878 - val_loss: 0.0621\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9874 - val_loss: 0.0631\n",
            "Epoch 15/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0076 - val_accuracy: 0.9886 - val_loss: 0.0726\n",
            "Epoch 16/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9882 - val_loss: 0.0708\n",
            "Epoch 17/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9876 - val_loss: 0.0717\n",
            "Epoch 18/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9876 - val_loss: 0.0625\n",
            "Epoch 19/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9880 - val_loss: 0.0661\n",
            "Epoch 20/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
            "Epoch 21/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9874 - val_loss: 0.0764\n",
            "Epoch 22/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9846 - val_loss: 0.0847\n",
            "Epoch 23/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9886 - val_loss: 0.0730\n",
            "Epoch 24/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9896 - val_loss: 0.0664\n",
            "Epoch 25/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9884 - val_loss: 0.0721\n",
            "Epoch 26/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9884 - val_loss: 0.0719\n",
            "Epoch 27/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9892 - val_loss: 0.0732\n",
            "Epoch 28/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9876 - val_loss: 0.0746\n",
            "Epoch 29/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9888 - val_loss: 0.0730\n",
            "Epoch 30/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9890 - val_loss: 0.0732\n",
            "Epoch 31/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9868 - val_loss: 0.0871\n",
            "Epoch 32/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9860 - val_loss: 0.0932\n",
            "Epoch 33/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9868 - val_loss: 0.0938\n",
            "Epoch 34/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9878 - val_loss: 0.0902\n",
            "Epoch 35/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9878 - val_loss: 0.0881\n",
            "Epoch 36/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9892 - val_loss: 0.0796\n",
            "Epoch 37/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9880 - val_loss: 0.0824\n",
            "Epoch 38/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9894 - val_loss: 0.0827\n",
            "Epoch 39/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.2735e-05 - val_accuracy: 0.9838 - val_loss: 0.1396\n",
            "Epoch 40/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9854 - val_loss: 0.1007\n",
            "Epoch 41/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9868 - val_loss: 0.1128\n",
            "Epoch 42/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9878 - val_loss: 0.1131\n",
            "Epoch 43/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9878 - val_loss: 0.0925\n",
            "Epoch 44/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9870 - val_loss: 0.1005\n",
            "Epoch 45/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9874 - val_loss: 0.0955\n",
            "Epoch 46/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9874 - val_loss: 0.0991\n",
            "Epoch 47/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9902 - val_loss: 0.0807\n",
            "Epoch 48/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9878 - val_loss: 0.0993\n",
            "Epoch 49/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9886 - val_loss: 0.0935\n",
            "Epoch 50/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9886 - val_loss: 0.0944\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0706\n",
            "\n",
            "Final model test accuracy: 0.9886\n"
          ]
        }
      ]
    }
  ]
}