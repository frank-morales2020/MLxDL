{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEDP8WoMTd+ZQA1cea5tnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/GEMINI_AGENT_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjjCm80p21aA",
        "outputId": "abd69546-d5f0-4680-b9b0-75ac7630bd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key retrieved from Colab Secrets 'GEMINI'.\n",
            "Gemini Client ready with model: gemini-2.5-flash\n",
            "\n",
            "================================================================================\n",
            "--- Synergized RAG Agent with LIVE LLM Integration ---\n",
            "Initial Query: What is the primary product of the company founded by the CEO of Tesla?\n",
            "================================================================================\n",
            "\n",
            "--- STEP 1 / 5 ---\n",
            "  [PARSED THOUGHT] The first step is to identify the CEO of Tesla. This information is crucial to proceed with the rest of the query.\n",
            "  [PARSED ACTION] SEARCH(CEO of Tesla)\n",
            "  [Observation: Retrieved fact for 'CEO of Tesla' is 'Elon Musk']\n",
            "\n",
            "--- STEP 2 / 5 ---\n",
            "  [PARSED THOUGHT] I have identified Elon Musk as the CEO of Tesla. The next step is to find out which company Elon Musk founded, as the query asks for the primary product of \"the company founded by the CEO of Tesla.\" I should search for companies founded by Elon Musk.\n",
            "  [PARSED ACTION] SEARCH(companies founded by Elon Musk)\n",
            "  [Observation: Retrieved fact for 'companies founded by Elon Musk' is 'Not found: no exact match for 'companies founded by Elon Musk'']\n",
            "\n",
            "--- STEP 3 / 5 ---\n",
            "  [PARSED THOUGHT] The previous search \"companies founded by Elon Musk\" did not return an exact match. This indicates the search query might need to be rephrased or broadened. Instead of looking for a direct list, I can try to find information about companies *he founded* in a more general sense, which might lead to a specific company name. I will try a more general search for \"Elon Musk founded companies\" or \"companies Elon Musk started\" to see if I can get a list or a prominent example.\n",
            "  [PARSED ACTION] SEARCH(companies Elon Musk founded)\n",
            "  [Observation: Retrieved fact for 'companies Elon Musk founded' is 'Not found: no exact match for 'companies Elon Musk founded'']\n",
            "\n",
            "--- STEP 4 / 5 ---\n",
            "  [PARSED THOUGHT] My previous attempts to find companies founded by Elon Musk directly failed. I need to broaden my search to find companies associated with him and then identify which one he founded. A good general search term would be \"Elon Musk's companies\" which should provide a list or mention of his major ventures. From there, I can determine which one he founded.\n",
            "  [PARSED ACTION] SEARCH(Elon Musk's companies)\n",
            "  [Observation: Retrieved fact for 'Elon Musk's companies' is 'Not found: no exact match for 'Elon Musk's companies'']\n",
            "\n",
            "--- STEP 5 / 5 ---\n",
            "  [PARSED THOUGHT] My previous attempts to find companies founded by Elon Musk directly have failed. I need to identify *a* company he founded. Instead of trying to get a list, I will try to confirm if a well-known company associated with him was indeed founded by him. SpaceX is a very prominent company associated with Elon Musk. I will search for \"SpaceX founder\" to verify if he founded it.\n",
            "  [PARSED ACTION] SEARCH(SpaceX founder)\n",
            "  [Observation: Retrieved fact for 'SpaceX founder' is 'Not found: no exact match for 'SpaceX founder'']\n",
            "\n",
            "--- LOOP TERMINATED ---\n",
            "Max steps reached without a FINISH action. Agent failed to complete the task.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "# --- IMPORTANT SETUP (API KEY RETRIEVAL) ---\n",
        "# This block is essential for retrieving the key from your Colab Secrets.\n",
        "\n",
        "# Default to None, then check environment variables\n",
        "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')\n",
        "\n",
        "# Check for Colab-specific userdata\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    # Assumes your key is saved in Colab Secrets under the name 'GEMINI'\n",
        "    key_from_colab = userdata.get('GEMINI')\n",
        "    if key_from_colab:\n",
        "        GOOGLE_API_KEY = key_from_colab\n",
        "        print(\"API Key retrieved from Colab Secrets 'GEMINI'.\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab. Using environment variable for API Key.\")\n",
        "\n",
        "# --- 1. LLM CONFIGURATION & API CLIENT ---\n",
        "\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "    SYSTEM_PROMPT: str = (\n",
        "        \"You are an expert Synergized RAG Agent. Your task is to solve complex, multi-step questions \"\n",
        "        \"by strictly following a Thought-Action-Observation loop. \"\n",
        "        \"You must analyze the initial query and the current context (History) to decide your next move. \"\n",
        "        \"If you need to search for information, your response MUST be formatted as: \"\n",
        "        \"\\nThought: [Your reasoning on the next step, based on the History]\"\n",
        "        \"\\nAction: SEARCH([The specific fact or query to look up])\"\n",
        "        \"\\nIf you have sufficient information to answer the original question, your response MUST be formatted as: \"\n",
        "        \"\\nThought: [Your concluding thoughts and final answer generation]\"\n",
        "        \"\\nAction: FINISH([The final answer to the original question])\"\n",
        "        \"\\nDO NOT include any text outside the Thought: and Action: tags in your final response.\"\n",
        "    )\n",
        "\n",
        "# Initialize the Gemini Client\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        client_initialized = True\n",
        "        print(f\"Gemini Client ready with model: {AgentConfig.LLM_MODEL_NAME}\")\n",
        "    except Exception as e:\n",
        "        client = None\n",
        "        client_initialized = False\n",
        "        print(f\"Error initializing Gemini Client: {e}\")\n",
        "else:\n",
        "    client = None\n",
        "    client_initialized = False\n",
        "    print(\"FATAL: GOOGLE_API_KEY is None. Client cannot be initialized.\")\n",
        "\n",
        "\n",
        "# --- 2. KNOWLEDGE BASE (RETRIEVER TOOL) ---\n",
        "\n",
        "knowledge_base = {\n",
        "    \"CEO of Tesla\": \"Elon Musk\",\n",
        "    \"Company founded by Elon Musk in 2002\": \"SpaceX\",\n",
        "    \"Primary product of SpaceX\": \"Rockets and spacecraft\",\n",
        "}\n",
        "\n",
        "def retrieve_fact(query: str) -> str:\n",
        "    \"\"\"Simulates the retrieval tool (the 'Action' fulfillment).\"\"\"\n",
        "    # Normalize query by stripping quotes and spaces for exact match\n",
        "    cleaned_query = query.strip().strip('\"').strip(\"'\")\n",
        "    fact = knowledge_base.get(cleaned_query)\n",
        "\n",
        "    if fact:\n",
        "        return fact\n",
        "    else:\n",
        "        return f\"Not found: no exact match for '{cleaned_query}'\"\n",
        "\n",
        "# --- 3. CORE LLM INTEGRATION FUNCTION (CORRECTED) ---\n",
        "\n",
        "def call_llm_agent(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Makes the actual API call to the Gemini LLM for Thought and Action.\n",
        "    FIX: Passes the prompt directly as 'contents' and uses 'system_instruction'\n",
        "         in config to avoid all role/part argument errors.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        return \"Error: Gemini Client not initialized. Cannot make API call.\"\n",
        "\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=AgentConfig.LLM_MODEL_NAME,\n",
        "            contents=prompt, # <-- FIX: Pass the prompt string directly.\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=AgentConfig.SYSTEM_PROMPT, # <-- FIX: Pass system instruction here\n",
        "                temperature=0.0,\n",
        "                max_output_tokens=512\n",
        "            )\n",
        "        )\n",
        "        return response.text\n",
        "    except APIError as e:\n",
        "        # Pass the full error message for debugging\n",
        "        return f\"Error during Gemini API call: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# --- 4. SYNERGIZED RAG AGENT LOOP ---\n",
        "\n",
        "def rag_agent_loop_live(initial_query: str, max_steps: int = 5):\n",
        "    \"\"\"Orchestrates the iterative RAG â‡Œ Reasoning loop.\"\"\"\n",
        "    if not client_initialized:\n",
        "        print(\"\\nDemo failed: Gemini client is not available. Please check your API key setup.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"--- Synergized RAG Agent with LIVE LLM Integration ---\")\n",
        "    print(f\"Initial Query: {initial_query}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    current_context = f\"Original Query: {initial_query}\\n\\n---\\nHistory:\\n\"\n",
        "\n",
        "    for step in range(1, max_steps + 1):\n",
        "        print(f\"\\n--- STEP {step} / {max_steps} ---\")\n",
        "\n",
        "        # 1. LLM REASONING & ACTION SELECTION\n",
        "        llm_prompt = f\"{current_context}\\n\\nWhat is the next Thought and Action? (Step {step})\"\n",
        "        llm_response_text = call_llm_agent(llm_prompt)\n",
        "\n",
        "        # --- PARSING LLM OUTPUT ---\n",
        "\n",
        "        # Check for API/Fatal error first\n",
        "        if \"Error during Gemini API call\" in llm_response_text or \"An unexpected error occurred\" in llm_response_text:\n",
        "             print(f\"FATAL API ERROR: {llm_response_text}. Terminating.\")\n",
        "             return\n",
        "\n",
        "        # Parse Thought and Action using regex\n",
        "        # Use re.DOTALL to allow matching across newlines\n",
        "        thought_match = re.search(r\"Thought: (.*?)(\\nAction:|$)\", llm_response_text, re.DOTALL)\n",
        "        action_match = re.search(r\"Action: (.*)\", llm_response_text, re.DOTALL)\n",
        "\n",
        "        thought = thought_match.group(1).strip() if thought_match else f\"ERROR: Thought not parsed from LLM response:\\n{llm_response_text}\"\n",
        "        action_command = action_match.group(1).strip() if action_match else f\"ERROR: Action not parsed from LLM response:\\n{llm_response_text}\"\n",
        "\n",
        "        print(f\"  [PARSED THOUGHT] {thought}\")\n",
        "        print(f\"  [PARSED ACTION] {action_command}\")\n",
        "\n",
        "        # 2. EXECUTE ACTION\n",
        "\n",
        "        if action_command.startswith(\"SEARCH\"):\n",
        "            search_query_match = re.search(r\"SEARCH\\((.*)\\)\", action_command)\n",
        "            search_query = search_query_match.group(1).strip() if search_query_match else \"ERROR: Search query not parsed.\"\n",
        "\n",
        "            # Execute Retrieval (the RAG component)\n",
        "            retrieved_data = retrieve_fact(search_query)\n",
        "\n",
        "            # 3. CONTEXT INTEGRATION (OBSERVATION)\n",
        "            observation = f\"Observation: Retrieved fact for '{search_query}' is '{retrieved_data}'\"\n",
        "            print(f\"  [{observation}]\")\n",
        "\n",
        "            # Update the context for the next LLM turn\n",
        "            current_context += f\"Step {step}:\\nThought: {thought}\\nAction: {action_command}\\n{observation}\\n\"\n",
        "\n",
        "        elif action_command.startswith(\"FINISH\"):\n",
        "            final_answer_match = re.search(r\"FINISH\\((.*)\\)\", action_command)\n",
        "            final_answer = final_answer_match.group(1).strip() if final_answer_match else \"ERROR: Final answer not parsed.\"\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"--- FINAL RESULT ---\")\n",
        "            print(f\"Final Answer: {final_answer}\")\n",
        "            print(\"\\n--- Full Context History ---\")\n",
        "            print(current_context)\n",
        "            print(\"=\"*80)\n",
        "            return\n",
        "\n",
        "        else:\n",
        "            # Catch cases where the model hallucinates a non-FINISH/non-SEARCH action\n",
        "            print(f\"\\nFATAL ERROR: Unknown or malformed Action: {action_command}. Terminating.\")\n",
        "            print(\"LLM failed to adhere to the required format.\")\n",
        "            return\n",
        "\n",
        "    print(\"\\n--- LOOP TERMINATED ---\")\n",
        "    print(\"Max steps reached without a FINISH action. Agent failed to complete the task.\")\n",
        "\n",
        "# --- EXECUTION ---\n",
        "if client_initialized:\n",
        "    query = \"What is the primary product of the company founded by the CEO of Tesla?\"\n",
        "    rag_agent_loop_live(query)\n",
        "else:\n",
        "    print(\"\\n*** The live demo cannot run because the Gemini Client failed to initialize. ***\")"
      ]
    }
  ]
}