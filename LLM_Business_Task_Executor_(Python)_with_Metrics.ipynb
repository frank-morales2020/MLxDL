{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LLM_Business_Task_Executor_(Python)_with_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xai-sdk -q"
      ],
      "metadata": {
        "id": "fp1n4WWdJf2e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os # Import os for environment variables\n",
        "import re # For regular expressions to parse code blocks\n",
        "import io # For capturing stdout/stderr\n",
        "import contextlib # For redirecting stdout/stderr\n",
        "\n",
        "\n",
        "# Import for Google Colab user data (for API key retrieval)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"Not in Google Colab environment. API keys will be read from environment variables or require manual setting.\")\n",
        "\n",
        "# Import for OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"OpenAI library not found. OpenAI models will not be available.\")\n",
        "\n",
        "# Import for xAI SDK (Grok)\n",
        "try:\n",
        "    from xai_sdk import Client\n",
        "    from xai_sdk.chat import user, system # Assuming these are used as per your example\n",
        "    XAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XAI_AVAILABLE = False\n",
        "    print(\"xai_sdk library not found. Grok models will not be available.\")\n",
        "\n",
        "\n",
        "class AgentConfig:\n",
        "    # Default model names if not specified\n",
        "    GEMINI_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "    # Using gpt-4o-mini as gpt-5 is not a public model\n",
        "    # Note: 'gpt-5' is used as per user's request, but if not available,\n",
        "    # it might default to other gpt models or return an error.\n",
        "    GPT_MODEL_NAME: str = \"gpt-5\"\n",
        "    # Grok model name as per your example\n",
        "    GROK_MODEL_NAME: str = \"grok-4-0709\"\n",
        "\n",
        "# Global dictionary to store overall metrics\n",
        "overall_metrics_report = {}\n",
        "\n",
        "\n",
        "def generate_content(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls the specified LLM API (Gemini, OpenAI, or xAI Grok) to generate content.\n",
        "    Includes exponential backoff for retries.\n",
        "\n",
        "    Args:\n",
        "        prompt: The text prompt to send to the LLM.\n",
        "\n",
        "    Returns:\n",
        "        The generated text from the LLM, or an error message if generation fails.\n",
        "    \"\"\"\n",
        "    MAX_RETRIES = 5\n",
        "    retries = 0\n",
        "    delay = 1  # 1 second\n",
        "\n",
        "    while retries < MAX_RETRIES:\n",
        "        try:\n",
        "            if model_name.startswith(\"gemini\"):\n",
        "                # --- Gemini API Call ---\n",
        "                google_api_key = \"\"\n",
        "                if COLAB_ENV:\n",
        "                    try:\n",
        "                        google_api_key = userdata.get('GEMINI')\n",
        "                    except Exception as e:\n",
        "                        return f\"Error: Could not retrieve GEMINI API key from Colab userdata. Please ensure it's set. {e}\"\n",
        "                else:\n",
        "                    google_api_key = os.getenv('GOOGLE_API_KEY') # For local execution\n",
        "\n",
        "                if not google_api_key:\n",
        "                    return \"Error: GOOGLE_API_KEY is not set for Gemini. Please provide your Google API key (e.g., in Colab Secrets as 'GEMINI' or as an env var).\"\n",
        "\n",
        "                chat_history = []\n",
        "                chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n",
        "                payload = {\"contents\": chat_history}\n",
        "                api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={google_api_key}\"\n",
        "\n",
        "                response = requests.post(\n",
        "                    api_url,\n",
        "                    headers={'Content-Type': 'application/json'},\n",
        "                    data=json.dumps(payload)\n",
        "                )\n",
        "                response.raise_for_status()\n",
        "\n",
        "                result = response.json()\n",
        "\n",
        "                # Robustly access Gemini response content\n",
        "                if result.get('candidates'):\n",
        "                    candidate = result['candidates'][0]\n",
        "                    if candidate and candidate.get('content'):\n",
        "                        content = candidate['content']\n",
        "                        if content.get('parts'):\n",
        "                            parts = content['parts']\n",
        "                            if parts and len(parts) > 0:\n",
        "                                return parts[0].get('text', '')\n",
        "\n",
        "                return f\"Error: Unexpected Gemini API response structure or missing content for model {model_name}.\"\n",
        "\n",
        "\n",
        "            elif model_name.startswith(\"gpt\"):\n",
        "                # --- OpenAI API Call ---\n",
        "                if not OPENAI_AVAILABLE:\n",
        "                    return \"Error: OpenAI library not available. Cannot use GPT models.\"\n",
        "\n",
        "                openai_api_key = \"\"\n",
        "                if COLAB_ENV:\n",
        "                    try:\n",
        "                        openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "                    except Exception as e:\n",
        "                        return f\"Error: Could not retrieve OPENAI_API_KEY from Colab userdata. Please ensure it's set. {e}\"\n",
        "                else:\n",
        "                    openai_api_key = os.getenv('OPENAI_API_KEY') # For local execution\n",
        "\n",
        "                if not openai_api_key:\n",
        "                    return \"Error: OPENAI_API_KEY is not set for GPT. Please provide your OpenAI API key (e.g., in Colab Secrets as 'OPENAI_API_KEY' or as an env var).\"\n",
        "\n",
        "                client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "                response = client.chat.completions.create(\n",
        "                    model=model_name,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                if response.choices and len(response.choices) > 0 and response.choices[0].message:\n",
        "                    return response.choices[0].message.content\n",
        "                else:\n",
        "                    return f\"Error: Unexpected OpenAI API response structure or missing content for model {model_name}.\"\n",
        "\n",
        "            elif model_name.startswith(\"grok\"):\n",
        "                # --- xAI Grok API Call (Corrected based on user reference) ---\n",
        "                if not XAI_AVAILABLE:\n",
        "                    return \"Error: xai_sdk library not available. Cannot use Grok models.\"\n",
        "\n",
        "                xai_api_key = \"\"\n",
        "                if COLAB_ENV:\n",
        "                    try:\n",
        "                        xai_api_key = userdata.get('XAI_KEY')\n",
        "                    except Exception as e:\n",
        "                        return f\"Error: Could not retrieve XAI_KEY from Colab userdata. Please ensure it's set. {e}\"\n",
        "                else:\n",
        "                    xai_api_key = os.getenv('XAI_KEY') # For local execution\n",
        "\n",
        "                if not xai_api_key:\n",
        "                    return \"Error: XAI_KEY is not set for Grok. Please provide your xAI API key (e.g., in Colab Secrets as 'XAI_KEY' or as an env var).\"\n",
        "\n",
        "                client = Client(\n",
        "                    api_host=\"api.x.ai\",\n",
        "                    api_key=xai_api_key\n",
        "                )\n",
        "\n",
        "                # 1. Create a chat session with the Grok model\n",
        "                chat_session = client.chat.create(model=model_name, temperature=0)\n",
        "\n",
        "                # 2. Append the user message\n",
        "                chat_session.append(user(prompt))\n",
        "\n",
        "                # 3. Sample (generate) a response from the model\n",
        "                grok_response = chat_session.sample()\n",
        "\n",
        "                # 4. Extract the generated response content\n",
        "                if grok_response and hasattr(grok_response, 'content'):\n",
        "                    return grok_response.content\n",
        "                else:\n",
        "                    # If content extraction fails, print the full response object for debugging\n",
        "                    print(f\"DEBUG: Grok response object structure: {grok_response}\")\n",
        "                    return f\"Error: Unexpected Grok API response structure or missing content for model {model_name}. See console for DEBUG info.\"\n",
        "\n",
        "            else:\n",
        "                return f\"Error: Unsupported model name: {model_name}. Please use 'gemini-...', 'gpt-...','grok-...' models.\"\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            retries += 1\n",
        "            if retries < MAX_RETRIES:\n",
        "                print(f\"Warning: API request failed for {model_name}. Retrying in {delay} seconds... (Attempt {retries}/{MAX_RETRIES})\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"Error: Max retries reached. Failed to generate content for {model_name}. {e}\")\n",
        "                return f\"Error: Failed to get response after multiple retries for {model_name}. {e}\"\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Failed to parse JSON response for {model_name}. {e}\")\n",
        "            return f\"Error: Failed to parse JSON response for {model_name}. {e}\"\n",
        "        except Exception as e: # Catch broader exceptions for other API errors\n",
        "            retries += 1\n",
        "            if retries < MAX_RETRIES:\n",
        "                print(f\"Warning: An unexpected error occurred for {model_name}. Retrying in {delay} seconds... (Attempt {retries}/{MAX_RETRIES})\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"Error: Max retries reached. An unexpected error occurred for {model_name}. {e}\")\n",
        "                return f\"Error: An unexpected error occurred after multiple retries for {model_name}. {e}\"\n",
        "\n",
        "\n",
        "def extract_python_code(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the first Python code block from a given text.\n",
        "    Made more robust to handle various markdown code block formats and heuristics.\n",
        "    \"\"\"\n",
        "    # Regex 1: Find ```python\\n[CODE]```\n",
        "    match = re.search(r'```python\\n(.*?)```', text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "\n",
        "    # Regex 2: Fallback to generic ```[optional_lang]\\n[CODE]```\n",
        "    match = re.search(r'```(?:\\w*\\s*\\n)?(.*?)```', text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "\n",
        "    # Heuristic Fallback: Try to identify code blocks based on Python syntax and indentation\n",
        "    lines = text.splitlines()\n",
        "    potential_code_lines = []\n",
        "    in_potential_code_block = False\n",
        "\n",
        "    # Common Python keywords to look for at the start of a line (after stripping whitespace)\n",
        "    python_keywords = [\"def \", \"import \", \"class \", \"for \", \"while \", \"if \", \"return \", \"print(\", \"#\", \"try:\", \"except:\", \"finally:\", \"with \"]\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        stripped_line = line.strip()\n",
        "\n",
        "        # Check if the line starts with a known Python keyword or is indented\n",
        "        is_python_start = any(stripped_line.startswith(kw) for kw in python_keywords)\n",
        "        is_indented = line.startswith(\" \") or line.startswith(\"\\t\")\n",
        "\n",
        "        if not in_potential_code_block:\n",
        "            # Look for the start of a code block\n",
        "            if is_python_start or (is_indented and i > 0 and (lines[i-1].strip() == \"\" or lines[i-1].startswith(\" \") or lines[i-1].startswith(\"\\t\"))):\n",
        "                in_potential_code_block = True\n",
        "                potential_code_lines.append(line)\n",
        "        elif in_potential_code_block:\n",
        "            # Continue collecting lines that are indented or blank (part of the code block)\n",
        "            if is_indented or stripped_line == \"\":\n",
        "                potential_code_lines.append(line)\n",
        "            else:\n",
        "                # If we were in a code block and found a non-indented, non-empty line, assume block ended\n",
        "                break\n",
        "\n",
        "    # If we found a potential code block, return it\n",
        "    if potential_code_lines:\n",
        "        # Before returning, perform a basic sanity check: does it contain at least one 'def', 'import', or other strong indicator?\n",
        "        combined_code = \"\\n\".join(potential_code_lines).strip()\n",
        "        if re.search(r'\\b(def|import|class|for|while|if|return)\\b', combined_code):\n",
        "            return combined_code\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def execute_python_code(code_string: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Executes a Python code string and captures its stdout and stderr.\n",
        "    Returns a tuple of (stdout, stderr).\n",
        "    \"\"\"\n",
        "    if not code_string:\n",
        "        return \"\", \"No code to execute.\"\n",
        "\n",
        "    original_stdout = io.StringIO()\n",
        "    original_stderr = io.StringIO()\n",
        "\n",
        "    try:\n",
        "        # Redirect stdout and stderr\n",
        "        with contextlib.redirect_stdout(original_stdout):\n",
        "            with contextlib.redirect_stderr(original_stderr):\n",
        "                exec(code_string)\n",
        "    except Exception as e:\n",
        "        original_stderr.write(f\"Execution Error: {e}\\n\")\n",
        "\n",
        "    return original_stdout.getvalue(), original_stderr.getvalue()\n",
        "\n",
        "\n",
        "def evaluate_response(task_name: str, model_name: str, response_text: str, original_prompt: str):\n",
        "    \"\"\"\n",
        "    Calculates and prints metrics for the LLM response and stores them globally.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Metrics for {model_name} on '{task_name}' ---\")\n",
        "\n",
        "    # Initialize task and model entry in overall_metrics_report if not exists\n",
        "    if task_name not in overall_metrics_report:\n",
        "        overall_metrics_report[task_name] = {}\n",
        "    if model_name not in overall_metrics_report[task_name]:\n",
        "        overall_metrics_report[task_name][model_name] = {}\n",
        "\n",
        "    # Metric 1: Response Length (Word Count)\n",
        "    word_count = len(response_text.split())\n",
        "    print(f\"Word Count: {word_count}\")\n",
        "    overall_metrics_report[task_name][model_name][\"word_count\"] = word_count\n",
        "    overall_metrics_report[task_name][model_name][\"response\"] = response_text\n",
        "\n",
        "    # Metric 2: Code Executability (for 'One-shot Vibe Coding')\n",
        "    if task_name == \"One-shot Vibe Coding\":\n",
        "        print(\"Attempting to execute generated Python code...\")\n",
        "        extracted_code = extract_python_code(response_text)\n",
        "        stdout, stderr = \"\", \"\"\n",
        "        code_executable = False\n",
        "\n",
        "        if extracted_code:\n",
        "            print(f\"Extracted Code:\\n{extracted_code[:200]}...\") # Print first 200 chars\n",
        "            stdout, stderr = execute_python_code(extracted_code)\n",
        "            if stdout:\n",
        "                print(f\"Code Output (stdout):\\n{stdout}\")\n",
        "            if stderr:\n",
        "                print(f\"Code Errors (stderr):\\n{stderr}\")\n",
        "            if not stdout and not stderr:\n",
        "                print(\"Code executed with no output and no errors.\")\n",
        "                code_executable = True\n",
        "            elif stdout and not stderr:\n",
        "                print(\"Code executed with output and no errors.\")\n",
        "                code_executable = True # Consider it executable if no stderr\n",
        "        else:\n",
        "            print(\"No Python code block found in the response.\")\n",
        "\n",
        "        overall_metrics_report[task_name][model_name][\"code_extracted\"] = bool(extracted_code)\n",
        "        overall_metrics_report[task_name][model_name][\"code_output\"] = stdout\n",
        "        overall_metrics_report[task_name][model_name][\"code_error\"] = stderr\n",
        "        overall_metrics_report[task_name][model_name][\"code_executable\"] = code_executable\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "def execute_client_emails(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the Client Emails task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing Client Emails Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"Client Emails\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def execute_ad_analysis(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the Ad Analysis task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing Ad Analysis Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"Ad Analysis\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def execute_social_writing(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the Social Writing Task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing Social Writing Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"Social Writing\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def execute_strategic_planning(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the Strategic Planning task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing Strategic Planning Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"Strategic Planning\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def execute_info_retrieval(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the Info Retrieval task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing Info Retrieval Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"Info Retrieval\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def execute_one_shot_vibe_coding(prompt: str, model_name: str) -> str:\n",
        "    \"\"\"Executes the One-shot Vibe Coding task using a specified model.\"\"\"\n",
        "    print(f\"\\n--- Executing One-shot Vibe Coding Task with {model_name} ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    response = generate_content(prompt, model_name)\n",
        "    evaluate_response(\"One-shot Vibe Coding\", model_name, response, prompt)\n",
        "    return response\n",
        "\n",
        "def generate_overall_report():\n",
        "    \"\"\"Generates and prints an overall report based on collected metrics.\"\"\"\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"                 âœ¨ Overall LLM Performance Report âœ¨\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    for task, models_data in overall_metrics_report.items():\n",
        "        print(f\"--- Task: {task} ---\")\n",
        "        best_min_word_count_model = None\n",
        "        min_word_count = float('inf')\n",
        "        best_max_word_count_model = None\n",
        "        max_word_count = 0\n",
        "\n",
        "        # For coding task, track executability\n",
        "        best_coding_model = None\n",
        "\n",
        "        # Collect data for summary\n",
        "        summary_lines = []\n",
        "        for model, metrics in models_data.items():\n",
        "            word_count = metrics.get(\"word_count\", \"N/A\")\n",
        "            summary_lines.append(f\"  - {model}: Word Count = {word_count}\")\n",
        "\n",
        "            if isinstance(word_count, int):\n",
        "                if word_count < min_word_count:\n",
        "                    min_word_count = word_count\n",
        "                    best_min_word_count_model = model\n",
        "                if word_count > max_word_count:\n",
        "                    max_word_count = word_count\n",
        "                    best_max_word_count_model = model\n",
        "\n",
        "            if task == \"One-shot Vibe Coding\":\n",
        "                is_executable = metrics.get(\"code_executable\", False)\n",
        "                summary_lines[-1] += f\", Executable = {is_executable}\"\n",
        "                if is_executable:\n",
        "                    if best_coding_model is None: # Prioritize the first one that works\n",
        "                        best_coding_model = model\n",
        "                elif not best_coding_model: # If no executable model yet, note down the errors\n",
        "                    error_msg = metrics.get(\"code_error\", \"No error reported\").strip()\n",
        "                    if error_msg:\n",
        "                        summary_lines[-1] += f\" (Error: {error_msg.splitlines()[0]})\"\n",
        "\n",
        "\n",
        "        # Print summary for the task\n",
        "        for line in summary_lines:\n",
        "            print(line)\n",
        "\n",
        "        # Print \"best\" based on metrics\n",
        "        if best_min_word_count_model and min_word_count != float('inf'):\n",
        "            print(f\"  ðŸ“ **Least verbose response:** {best_min_word_count_model} (Word Count: {min_word_count})\")\n",
        "        if best_max_word_count_model and max_word_count != 0: # Ensure max_word_count is not initial 0\n",
        "            print(f\"  ðŸ“ˆ **Most verbose response:** {best_max_word_count_model} (Word Count: {max_word_count})\")\n",
        "\n",
        "        if task == \"One-shot Vibe Coding\":\n",
        "            if best_coding_model:\n",
        "                print(f\"  âœ… **Best for Code Executability:** {best_coding_model} (Code executed successfully)\")\n",
        "            else:\n",
        "                print(\"  âŒ **No model generated executable code for this task.**\")\n",
        "        print(\"\\n\" + \"-\"*60 + \"\\n\") # Separator between tasks\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the LLM Business Task Executor (Python) with GPT, Gemini, and Grok!\")\n",
        "\n",
        "    # Define tasks and their corresponding prompts\n",
        "    tasks = {\n",
        "        \"Client Emails\": \"Draft an email to a client named Alex confirming the receipt of their inquiry about our new software and informing them that a specialist will contact them within 24 hours.\",\n",
        "        \"Ad Analysis\": \"Analyze the following ad copy: 'Revolutionize your workflow with FlowPro! Sign up now and get 20% off.' Evaluate its strengths, weaknesses, and target audience appeal.\",\n",
        "        \"Social Writing\": \"Create a LinkedIn post announcing a new whitepaper on 'The Future of AI in Business.' Include a call to action to download it.\",\n",
        "        \"Strategic Planning\": \"Propose three innovative ideas for a small e-commerce business to increase customer engagement in the next six months.\",\n",
        "        \"Info Retrieval\": \"Summarize the key differences between agile and waterfall project management methodologies.\",\n",
        "        \"One-shot Vibe Coding\": \"Write a Python function to calculate the factorial of a number. Include an example usage of the function that prints the factorial of 5. **Please enclose all code within a Markdown code block, like this: ```python\\\\n[your code here]\\\\n```**\"\n",
        "    }\n",
        "\n",
        "    # Define models to test\n",
        "    models_to_test = {\n",
        "        \"Gemini\": AgentConfig.GEMINI_MODEL_NAME,\n",
        "        \"GPT\": AgentConfig.GPT_MODEL_NAME,\n",
        "        \"Grok\": AgentConfig.GROK_MODEL_NAME\n",
        "    }\n",
        "\n",
        "    # Execute all tasks for all models\n",
        "    for task_name, prompt_text in tasks.items():\n",
        "        for model_label, model_name in models_to_test.items():\n",
        "            # Dynamically call the correct execute_task function\n",
        "            if task_name == \"Client Emails\":\n",
        "                execute_client_emails(prompt_text, model_name)\n",
        "            elif task_name == \"Ad Analysis\":\n",
        "                execute_ad_analysis(prompt_text, model_name)\n",
        "            elif task_name == \"Social Writing\":\n",
        "                execute_social_writing(prompt_text, model_name)\n",
        "            elif task_name == \"Strategic Planning\":\n",
        "                execute_strategic_planning(prompt_text, model_name)\n",
        "            elif task_name == \"Info Retrieval\":\n",
        "                execute_info_retrieval(prompt_text, model_name)\n",
        "            elif task_name == \"One-shot Vibe Coding\":\n",
        "                execute_one_shot_vibe_coding(prompt_text, model_name)\n",
        "\n",
        "    # Generate the final overall report\n",
        "    generate_overall_report()\n",
        "\n",
        "    print(\"\\n--- All tasks and report generation complete ---\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the LLM Business Task Executor (Python) with GPT, Gemini, and Grok!\n",
            "\n",
            "--- Executing Client Emails Task with gemini-2.5-flash ---\n",
            "Prompt: Draft an email to a client named Alex confirming the receipt of their inquiry about our new software and informing them that a specialist will contact them within 24 hours.\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'Client Emails' ---\n",
            "Word Count: 104\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Client Emails Task with gpt-5 ---\n",
            "Prompt: Draft an email to a client named Alex confirming the receipt of their inquiry about our new software and informing them that a specialist will contact them within 24 hours.\n",
            "\n",
            "--- Metrics for gpt-5 on 'Client Emails' ---\n",
            "Word Count: 71\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Client Emails Task with grok-4-0709 ---\n",
            "Prompt: Draft an email to a client named Alex confirming the receipt of their inquiry about our new software and informing them that a specialist will contact them within 24 hours.\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'Client Emails' ---\n",
            "Word Count: 103\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Ad Analysis Task with gemini-2.5-flash ---\n",
            "Prompt: Analyze the following ad copy: 'Revolutionize your workflow with FlowPro! Sign up now and get 20% off.' Evaluate its strengths, weaknesses, and target audience appeal.\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'Ad Analysis' ---\n",
            "Word Count: 750\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Ad Analysis Task with gpt-5 ---\n",
            "Prompt: Analyze the following ad copy: 'Revolutionize your workflow with FlowPro! Sign up now and get 20% off.' Evaluate its strengths, weaknesses, and target audience appeal.\n",
            "\n",
            "--- Metrics for gpt-5 on 'Ad Analysis' ---\n",
            "Word Count: 482\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Ad Analysis Task with grok-4-0709 ---\n",
            "Prompt: Analyze the following ad copy: 'Revolutionize your workflow with FlowPro! Sign up now and get 20% off.' Evaluate its strengths, weaknesses, and target audience appeal.\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'Ad Analysis' ---\n",
            "Word Count: 1008\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Social Writing Task with gemini-2.5-flash ---\n",
            "Prompt: Create a LinkedIn post announcing a new whitepaper on 'The Future of AI in Business.' Include a call to action to download it.\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'Social Writing' ---\n",
            "Word Count: 408\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Social Writing Task with gpt-5 ---\n",
            "Prompt: Create a LinkedIn post announcing a new whitepaper on 'The Future of AI in Business.' Include a call to action to download it.\n",
            "\n",
            "--- Metrics for gpt-5 on 'Social Writing' ---\n",
            "Word Count: 149\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Social Writing Task with grok-4-0709 ---\n",
            "Prompt: Create a LinkedIn post announcing a new whitepaper on 'The Future of AI in Business.' Include a call to action to download it.\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'Social Writing' ---\n",
            "Word Count: 174\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Strategic Planning Task with gemini-2.5-flash ---\n",
            "Prompt: Propose three innovative ideas for a small e-commerce business to increase customer engagement in the next six months.\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'Strategic Planning' ---\n",
            "Word Count: 1142\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Strategic Planning Task with gpt-5 ---\n",
            "Prompt: Propose three innovative ideas for a small e-commerce business to increase customer engagement in the next six months.\n",
            "\n",
            "--- Metrics for gpt-5 on 'Strategic Planning' ---\n",
            "Word Count: 881\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Strategic Planning Task with grok-4-0709 ---\n",
            "Prompt: Propose three innovative ideas for a small e-commerce business to increase customer engagement in the next six months.\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'Strategic Planning' ---\n",
            "Word Count: 702\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Info Retrieval Task with gemini-2.5-flash ---\n",
            "Prompt: Summarize the key differences between agile and waterfall project management methodologies.\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'Info Retrieval' ---\n",
            "Word Count: 594\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Info Retrieval Task with gpt-5 ---\n",
            "Prompt: Summarize the key differences between agile and waterfall project management methodologies.\n",
            "\n",
            "--- Metrics for gpt-5 on 'Info Retrieval' ---\n",
            "Word Count: 354\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing Info Retrieval Task with grok-4-0709 ---\n",
            "Prompt: Summarize the key differences between agile and waterfall project management methodologies.\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'Info Retrieval' ---\n",
            "Word Count: 463\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing One-shot Vibe Coding Task with gemini-2.5-flash ---\n",
            "Prompt: Write a Python function to calculate the factorial of a number. Include an example usage of the function that prints the factorial of 5. **Please enclose all code within a Markdown code block, like this: ```python\\n[your code here]\\n```**\n",
            "\n",
            "--- Metrics for gemini-2.5-flash on 'One-shot Vibe Coding' ---\n",
            "Word Count: 182\n",
            "Attempting to execute generated Python code...\n",
            "Extracted Code:\n",
            "def calculate_factorial(n):\n",
            "    \"\"\"\n",
            "    Calculates the factorial of a non-negative integer.\n",
            "\n",
            "    Args:\n",
            "        n (int): The number for which to calculate the factorial.\n",
            "                 Must be a non-...\n",
            "Code Output (stdout):\n",
            "The factorial of 5 is: 120\n",
            "\n",
            "Code executed with output and no errors.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing One-shot Vibe Coding Task with gpt-5 ---\n",
            "Prompt: Write a Python function to calculate the factorial of a number. Include an example usage of the function that prints the factorial of 5. **Please enclose all code within a Markdown code block, like this: ```python\\n[your code here]\\n```**\n",
            "\n",
            "--- Metrics for gpt-5 on 'One-shot Vibe Coding' ---\n",
            "Word Count: 85\n",
            "Attempting to execute generated Python code...\n",
            "Extracted Code:\n",
            "def factorial(n: int) -> int:\n",
            "    \"\"\"\n",
            "    Calculate the factorial of a non-negative integer n.\n",
            "    Raises:\n",
            "        TypeError: If n is not an integer.\n",
            "        ValueError: If n is negative.\n",
            "    \"\"\"\n",
            "    ...\n",
            "Code Output (stdout):\n",
            "120\n",
            "\n",
            "Code executed with output and no errors.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Executing One-shot Vibe Coding Task with grok-4-0709 ---\n",
            "Prompt: Write a Python function to calculate the factorial of a number. Include an example usage of the function that prints the factorial of 5. **Please enclose all code within a Markdown code block, like this: ```python\\n[your code here]\\n```**\n",
            "\n",
            "--- Metrics for grok-4-0709 on 'One-shot Vibe Coding' ---\n",
            "Word Count: 35\n",
            "Attempting to execute generated Python code...\n",
            "Extracted Code:\n",
            "def factorial(n):\n",
            "    if n < 0:\n",
            "        raise ValueError(\"Factorial is not defined for negative numbers\")\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "        result *= i\n",
            "    return result\n",
            "\n",
            "# Example ...\n",
            "Code Output (stdout):\n",
            "120\n",
            "\n",
            "Code executed with output and no errors.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "                 âœ¨ Overall LLM Performance Report âœ¨\n",
            "======================================================================\n",
            "\n",
            "--- Task: Client Emails ---\n",
            "  - gemini-2.5-flash: Word Count = 104\n",
            "  - gpt-5: Word Count = 71\n",
            "  - grok-4-0709: Word Count = 103\n",
            "  ðŸ“ **Least verbose response:** gpt-5 (Word Count: 71)\n",
            "  ðŸ“ˆ **Most verbose response:** gemini-2.5-flash (Word Count: 104)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Task: Ad Analysis ---\n",
            "  - gemini-2.5-flash: Word Count = 750\n",
            "  - gpt-5: Word Count = 482\n",
            "  - grok-4-0709: Word Count = 1008\n",
            "  ðŸ“ **Least verbose response:** gpt-5 (Word Count: 482)\n",
            "  ðŸ“ˆ **Most verbose response:** grok-4-0709 (Word Count: 1008)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Task: Social Writing ---\n",
            "  - gemini-2.5-flash: Word Count = 408\n",
            "  - gpt-5: Word Count = 149\n",
            "  - grok-4-0709: Word Count = 174\n",
            "  ðŸ“ **Least verbose response:** gpt-5 (Word Count: 149)\n",
            "  ðŸ“ˆ **Most verbose response:** gemini-2.5-flash (Word Count: 408)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Task: Strategic Planning ---\n",
            "  - gemini-2.5-flash: Word Count = 1142\n",
            "  - gpt-5: Word Count = 881\n",
            "  - grok-4-0709: Word Count = 702\n",
            "  ðŸ“ **Least verbose response:** grok-4-0709 (Word Count: 702)\n",
            "  ðŸ“ˆ **Most verbose response:** gemini-2.5-flash (Word Count: 1142)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Task: Info Retrieval ---\n",
            "  - gemini-2.5-flash: Word Count = 594\n",
            "  - gpt-5: Word Count = 354\n",
            "  - grok-4-0709: Word Count = 463\n",
            "  ðŸ“ **Least verbose response:** gpt-5 (Word Count: 354)\n",
            "  ðŸ“ˆ **Most verbose response:** gemini-2.5-flash (Word Count: 594)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Task: One-shot Vibe Coding ---\n",
            "  - gemini-2.5-flash: Word Count = 182, Executable = True\n",
            "  - gpt-5: Word Count = 85, Executable = True\n",
            "  - grok-4-0709: Word Count = 35, Executable = True\n",
            "  ðŸ“ **Least verbose response:** grok-4-0709 (Word Count: 35)\n",
            "  ðŸ“ˆ **Most verbose response:** gemini-2.5-flash (Word Count: 182)\n",
            "  âœ… **Best for Code Executability:** gemini-2.5-flash (Code executed successfully)\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "--- All tasks and report generation complete ---\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16vtCXsFJQCR",
        "outputId": "97985061-1989-4b3c-b312-3eaf9dadf893"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}