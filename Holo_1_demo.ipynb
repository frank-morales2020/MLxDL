{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNvEsJhj06Z27vW0AQ2zuzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Holo_1_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch Pillow requests pydantic -q"
      ],
      "metadata": {
        "id": "X35ZFmxv3T4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KU2Rcjb8Et4",
        "outputId": "835d1814-1ca7-40f7-f382-baf026073e19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  4 12:37:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   41C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoMvXHGx3NSG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "from typing import Any, Literal\n",
        "from pydantic import BaseModel, ConfigDict\n",
        "import re # Import regex for more robust parsing\n",
        "\n",
        "# --- 1. Load the Holo-1 model and processor ---\n",
        "model_name = \"Hcompany/Holo1-7B\" # Or \"Hcompany/Holo1-3B\"\n",
        "\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "# --- 2. Define a helper function for inference ---\n",
        "def run_inference(messages: list[dict[str, Any]]) -> str:\n",
        "    \"\"\"\n",
        "    Runs inference on the Holo-1 model with a given set of messages.\n",
        "    Extracts only the assistant's response.\n",
        "    \"\"\"\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = processor(text=text, images=messages[0][\"content\"][0][\"image\"], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
        "    decoded_output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    # --- FIX START ---\n",
        "    # Extract only the assistant's response part\n",
        "    # The output format is typically: <system_prompt><user_prompt><assistant_response>\n",
        "    # We are looking for the last part after the \"assistant\\n\" token.\n",
        "    assistant_prefix = \"assistant\\n\"\n",
        "    if assistant_prefix in decoded_output:\n",
        "        assistant_response = decoded_output.split(assistant_prefix, 1)[1].strip()\n",
        "        return assistant_response\n",
        "    else:\n",
        "        # Fallback if the expected prefix is not found, return full output but indicate an issue\n",
        "        print(\"Warning: 'assistant\\\\n' prefix not found in model output. Returning full output.\")\n",
        "        return decoded_output\n",
        "    # --- FIX END ---\n",
        "\n",
        "# --- 3. Prepare the image and instruction for UI localization ---\n",
        "image_url = \"https://huggingface.co/Hcompany/Holo1-7B/resolve/main/calendar_example.jpg\"\n",
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "instruction = \"Click on the '3' on the calendar.\"\n",
        "guidelines = \"Localize an element on the GUI image according to my instructions and output a click position as Click(x, y) with x num pixels from the left edge and y num pixels from the top edge.\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": f\"{guidelines}\\n{instruction}\"},\n",
        "        ],\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Run inference and parse the output ---\n",
        "coordinates_str = run_inference(messages)\n",
        "print(f\"Holo-1 output (extracted): {coordinates_str}\")\n",
        "\n",
        "# Optional: Parse the structured output using Pydantic (or regex/string parsing)\n",
        "class ClickAction(BaseModel):\n",
        "    action: Literal[\"click\"] = \"click\"\n",
        "    x: int\n",
        "    y: int\n",
        "\n",
        "    model_config = ConfigDict(\n",
        "        extra=\"forbid\",\n",
        "        json_schema_serialization_defaults_required=True,\n",
        "        json_schema_mode_override=\"serialization\",\n",
        "        use_attribute_docstrings=True,\n",
        "    )\n",
        "\n",
        "try:\n",
        "    # Use regex to extract x and y more reliably\n",
        "    match = re.match(r\"Click\\((\\d+),\\s*(\\d+)\\)\", coordinates_str)\n",
        "    if match:\n",
        "        x = int(match.group(1))\n",
        "        y = int(match.group(2))\n",
        "        click_action = ClickAction(action=\"click\", x=x, y=y)\n",
        "        print(f\"Parsed Click Action: x={click_action.x}, y={click_action.y}\")\n",
        "    else:\n",
        "        print(\"Output not in expected 'Click(x, y)' format.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing output: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlnO5sgn7Te-",
        "outputId": "62d11882-6c98-4264-f3ea-5c15279a6051"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holo-1 output (extracted): Click(426, 278)\n",
            "Parsed Click Action: x=426, y=278\n"
          ]
        }
      ]
    }
  ]
}