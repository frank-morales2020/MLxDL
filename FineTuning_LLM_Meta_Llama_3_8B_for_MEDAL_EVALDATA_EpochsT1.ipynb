{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Meta_Llama_3_8B_for_MEDAL_EVALDATA_EpochsT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3kFUczO5Um3"
      },
      "source": [
        "https://llama.meta.com/docs/how-to-guides/fine-tuning/\n",
        "\n",
        "\n",
        "https://medium.com/@frankmorales_91352/fine-tuning-meta-llama-3-8b-with-medal-a-refined-approach-for-enhanced-medical-language-b924d226b09d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install datasets trl ninja packaging --quiet\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "! pip install trl==0.8.6 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65JpttRiGxVK"
      },
      "outputs": [],
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "37yP0eJDM152"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=3,\n",
        "    early_stopping_threshold=0.001\n",
        ")\n"
      ],
      "metadata": {
        "id": "j8fUYmuIFU1g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "outputs": [],
      "source": [
        "# set device\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KtE9TuSMlUEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38008a8e-71f0-46af-f7ba-8e071e48f7c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GapRov3hl4fT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6932df61-8dfa-4e92-c17a-0bb3a8e52ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Wed May  7 10:23:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             44W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p-7fKxR2rnbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23bad75-f0cb-435d-8ead-3a6b7e2b28cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': '<prompt text>', 'completion': '<ideal generated text>'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "### conversational format\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "\n",
        "### instruction format\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SCd7-R-lsLQm"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/train_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-kFtkh8kiOn",
        "outputId": "7977e457-0ce5-4466-fa51-f505f45be861"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['abstract_id', 'text', 'location', 'label'],\n",
              "    num_rows: 3000000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ahaI2KNwYcQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d3438f-58e1-4476-c1d3-bc9ebb926988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to quantify the amount of CL NO harvested in modified RND\n"
          ]
        }
      ],
      "source": [
        "print(dataset[6]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uMbtvPqFkyFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995d4743-7f9f-493d-8999-188942d0ee70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['radical neck dissection']\n"
          ]
        }
      ],
      "source": [
        "print(dataset[6]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sgY7jf_8_Plh"
      },
      "outputs": [],
      "source": [
        "dataset_test = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/test_dataset.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufPzSf64LDux",
        "outputId": "7aa693a3-911c-45cd-fa51-66066da25d70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['abstract_id', 'text', 'location', 'label'],\n",
              "    num_rows: 1000000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UXZmSkhz-5sI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def dataset_to_finetuning(dataset,nrec):\n",
        "\n",
        "    question=dataset['text']\n",
        "    answer_entry=dataset['label']\n",
        "\n",
        "\n",
        "    !rm -rf /content/question_answering.txt\n",
        "    filename='/content/question_answering.txt'\n",
        "\n",
        "\n",
        "  # python object to be appended\n",
        "    for n in range(nrec):\n",
        "        #print(answer[n])\n",
        "        if answer_entry[n] == None:\n",
        "           answer_entry[n] = 'Not possible to get or use'\n",
        "        string = answer_entry[n]\n",
        "\n",
        "        str_question=question[n]\n",
        "        question_final= re.sub(\"\\n\", \"\", str_question)\n",
        "\n",
        "        answer = re.sub(\"\\[\", \"\", str(string))\n",
        "        answer = re.sub(\"\\]\", \"\", str(answer))\n",
        "        answer0=answer[1:len(answer)-1]\n",
        "\n",
        "        if len(answer0)==0:\n",
        "            answer='Not possible to get or use'\n",
        "\n",
        "        #print(answer0)\n",
        "\n",
        "\n",
        "        text='<s>[INST] %s [/INST] %s </s>'%(question_final,answer0)\n",
        "        del string,answer0\n",
        "        #print(text)\n",
        "        with open(filename, 'a') as f:\n",
        "            f.write(text + '\\n')\n",
        "        f.close()\n",
        "\n",
        "    text0 = load_dataset(\"text\", data_files=\"/content/question_answering.txt\", split=\"train\")\n",
        "\n",
        "    dataset_final_Question=dataset['text'][0:nrec]\n",
        "    dataset_final_Answer=dataset['label'][0:nrec]\n",
        "    dataset_final_text=text0[0:nrec]['text']\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "    datasetF['Question'] = dataset_final_Question\n",
        "    datasetF['Answer'] = dataset_final_Answer\n",
        "    datasetF['text'] = dataset_final_text\n",
        "\n",
        "\n",
        "    return datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5oGlbglrGKBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "26010cdcab2a47f6b7723e7d6bb4b02e",
            "7828f1e709ed492481dcae2668adfa7f",
            "02e4e71b876a476f873a0bae2fa866c6",
            "1372d52c7bd04ee9881ba764c3c30dfb",
            "d6e43eae2e9546b8acffe486d9dc2d8f",
            "c7cf01ac7f134442834c81ee042ec97e",
            "7b4c46eba172433ca632bb591aa4759c",
            "610aef8079c54bccb4edd2290b67d22d",
            "f97d97021481405689979682a9f8e0ef",
            "9e79d52f506447b48d0d12d7eee553e9",
            "27c6668eaac94bb3b87f0ac3b4d81fde"
          ]
        },
        "outputId": "c54c912c-7143-45b2-e0c8-f7b28b96daf5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26010cdcab2a47f6b7723e7d6bb4b02e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "datasetF=dataset_to_finetuning(dataset,500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8zapOFE_JUdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0ebcbbb-63cd-4c9c-b5c1-dfe87cd778a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to quantify the amount of CL NO harvested in modified RND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "datasetF['Question'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lokPbQcdJbI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbb2f0e-492c-4f0a-c1b4-a7a8abebe961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['radical neck dissection']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "datasetF['Answer'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CPmT7AExJnir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8cdbcb9e-fb8a-4074-921d-c79b530feed4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] radical neck dissection </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "datasetF['text'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e1ChV5-FJE5M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "9961dfd0-22ce-464d-bd9e-8ab8b0f1faf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Question  \\\n",
              "0       velvet antlers vas are commonly used in tradit...   \n",
              "1       the clinical features of our cases demonstrate...   \n",
              "2       ceftobiprole bpr is an investigational cephalo...   \n",
              "3       we have taken a basic biologic RPA to elucidat...   \n",
              "4       lipoperoxidationderived aldehydes for example ...   \n",
              "...                                                   ...   \n",
              "499995  whim warts hypogammaglobulinemia infections an...   \n",
              "499996  lipids either as membrane components or as fue...   \n",
              "499997  we studied the EP and antiarrhythmic effects o...   \n",
              "499998  the role of HR rate in the OD of coronary athe...   \n",
              "499999  studies on cerebral blood flow during SH and h...   \n",
              "\n",
              "                                      Answer  \\\n",
              "0           [transverse aortic constriction]   \n",
              "1                        [hodgkins lymphoma]   \n",
              "2          [methicillinsusceptible s aureus]   \n",
              "3       [parathyroid hormonerelated protein]   \n",
              "4                         [lipoperoxidation]   \n",
              "...                                      ...   \n",
              "499995                          [chemotaxis]   \n",
              "499996             [fractional outflow rate]   \n",
              "499997                     [attachment site]   \n",
              "499998                    [high cholesterol]   \n",
              "499999                       [mean arterial]   \n",
              "\n",
              "                                                     text  \n",
              "0       <s>[INST] velvet antlers vas are commonly used...  \n",
              "1       <s>[INST] the clinical features of our cases d...  \n",
              "2       <s>[INST] ceftobiprole bpr is an investigation...  \n",
              "3       <s>[INST] we have taken a basic biologic RPA t...  \n",
              "4       <s>[INST] lipoperoxidationderived aldehydes fo...  \n",
              "...                                                   ...  \n",
              "499995  <s>[INST] whim warts hypogammaglobulinemia inf...  \n",
              "499996  <s>[INST] lipids either as membrane components...  \n",
              "499997  <s>[INST] we studied the EP and antiarrhythmic...  \n",
              "499998  <s>[INST] the role of HR rate in the OD of cor...  \n",
              "499999  <s>[INST] studies on cerebral blood flow durin...  \n",
              "\n",
              "[500000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddbfcee5-d0e0-4c3f-81aa-d4d4f217e0e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
              "      <td>[transverse aortic constriction]</td>\n",
              "      <td>&lt;s&gt;[INST] velvet antlers vas are commonly used...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the clinical features of our cases demonstrate...</td>\n",
              "      <td>[hodgkins lymphoma]</td>\n",
              "      <td>&lt;s&gt;[INST] the clinical features of our cases d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
              "      <td>[methicillinsusceptible s aureus]</td>\n",
              "      <td>&lt;s&gt;[INST] ceftobiprole bpr is an investigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
              "      <td>[parathyroid hormonerelated protein]</td>\n",
              "      <td>&lt;s&gt;[INST] we have taken a basic biologic RPA t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lipoperoxidationderived aldehydes for example ...</td>\n",
              "      <td>[lipoperoxidation]</td>\n",
              "      <td>&lt;s&gt;[INST] lipoperoxidationderived aldehydes fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>whim warts hypogammaglobulinemia infections an...</td>\n",
              "      <td>[chemotaxis]</td>\n",
              "      <td>&lt;s&gt;[INST] whim warts hypogammaglobulinemia inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>lipids either as membrane components or as fue...</td>\n",
              "      <td>[fractional outflow rate]</td>\n",
              "      <td>&lt;s&gt;[INST] lipids either as membrane components...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>we studied the EP and antiarrhythmic effects o...</td>\n",
              "      <td>[attachment site]</td>\n",
              "      <td>&lt;s&gt;[INST] we studied the EP and antiarrhythmic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>the role of HR rate in the OD of coronary athe...</td>\n",
              "      <td>[high cholesterol]</td>\n",
              "      <td>&lt;s&gt;[INST] the role of HR rate in the OD of cor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>studies on cerebral blood flow during SH and h...</td>\n",
              "      <td>[mean arterial]</td>\n",
              "      <td>&lt;s&gt;[INST] studies on cerebral blood flow durin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddbfcee5-d0e0-4c3f-81aa-d4d4f217e0e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddbfcee5-d0e0-4c3f-81aa-d4d4f217e0e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddbfcee5-d0e0-4c3f-81aa-d4d4f217e0e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a158aa5f-ef66-43d9-888c-67c1fe1429f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a158aa5f-ef66-43d9-888c-67c1fe1429f0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a158aa5f-ef66-43d9-888c-67c1fe1429f0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d2d34000-1408-4dcb-9c8e-0477c5649a4b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d2d34000-1408-4dcb-9c8e-0477c5649a4b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "datasetF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Fh4mv6NpGh-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2e1ac2c960c34dc2804213a36a08363d",
            "3f2913574de74dfc8989a342752443db",
            "881a63033572416a8549d2885b87ffc8",
            "fa2e809055e340d194b38865a79e8c73",
            "206ad887bb2b4dd9b4d185a2f20c9f6f",
            "a06b2a39a8d5427c8123562fd49077a8",
            "2604cd973f7146898ed36864733e1b0d",
            "43800e174ab0403c83314fb4d0ea951d",
            "293b3ae6e516465583cbdc96c36bffe8",
            "6c1320c7684240318d2c217952748736",
            "f0745ecaaedb4a97ab5a5017048a4bec"
          ]
        },
        "outputId": "e06e354e-3412-47a7-ad87-dd31ae793edb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e1ac2c960c34dc2804213a36a08363d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "datasetF_test=dataset_to_finetuning(dataset_test,20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PnGkIpVtJHvv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "13d8aa04-14d1-4985-bb5d-85be7e04d2de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Question  \\\n",
              "0      we developed an animal model of chronic allerg...   \n",
              "1      pyogenic granulomas represent the aquisition o...   \n",
              "2      the l immunotype lipopolysaccharide lps of nei...   \n",
              "3      inotropic reserve identified by dobutamine or ...   \n",
              "4      pyridoxinedependent seizure is a rare autosoma...   \n",
              "...                                                  ...   \n",
              "19995  penile erection is regulated by two opposing s...   \n",
              "19996  effluent from oil production activities contai...   \n",
              "19997  a new method is described for performing oral ...   \n",
              "19998  since more than years risk assessment of bisph...   \n",
              "19999  in pulmonary hypertension ph measurement of va...   \n",
              "\n",
              "                               Answer  \\\n",
              "0      [functional residual capacity]   \n",
              "1                [pyogenic granuloma]   \n",
              "2            [phosphorylethanolamine]   \n",
              "3           [stress echocardiography]   \n",
              "4         [severe mental retardation]   \n",
              "...                               ...   \n",
              "19995             [corpus cavernosum]   \n",
              "19996                  [hydrocarbons]   \n",
              "19997     [acute respiratory failure]   \n",
              "19998          [endocrine disruptors]   \n",
              "19999                 [walk distance]   \n",
              "\n",
              "                                                    text  \n",
              "0      <s>[INST] we developed an animal model of chro...  \n",
              "1      <s>[INST] pyogenic granulomas represent the aq...  \n",
              "2      <s>[INST] the l immunotype lipopolysaccharide ...  \n",
              "3      <s>[INST] inotropic reserve identified by dobu...  \n",
              "4      <s>[INST] pyridoxinedependent seizure is a rar...  \n",
              "...                                                  ...  \n",
              "19995  <s>[INST] penile erection is regulated by two ...  \n",
              "19996  <s>[INST] effluent from oil production activit...  \n",
              "19997  <s>[INST] a new method is described for perfor...  \n",
              "19998  <s>[INST] since more than years risk assessmen...  \n",
              "19999  <s>[INST] in pulmonary hypertension ph measure...  \n",
              "\n",
              "[20000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d59b1825-7255-4b73-aa80-5e3d660995e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we developed an animal model of chronic allerg...</td>\n",
              "      <td>[functional residual capacity]</td>\n",
              "      <td>&lt;s&gt;[INST] we developed an animal model of chro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pyogenic granulomas represent the aquisition o...</td>\n",
              "      <td>[pyogenic granuloma]</td>\n",
              "      <td>&lt;s&gt;[INST] pyogenic granulomas represent the aq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the l immunotype lipopolysaccharide lps of nei...</td>\n",
              "      <td>[phosphorylethanolamine]</td>\n",
              "      <td>&lt;s&gt;[INST] the l immunotype lipopolysaccharide ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>inotropic reserve identified by dobutamine or ...</td>\n",
              "      <td>[stress echocardiography]</td>\n",
              "      <td>&lt;s&gt;[INST] inotropic reserve identified by dobu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pyridoxinedependent seizure is a rare autosoma...</td>\n",
              "      <td>[severe mental retardation]</td>\n",
              "      <td>&lt;s&gt;[INST] pyridoxinedependent seizure is a rar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>penile erection is regulated by two opposing s...</td>\n",
              "      <td>[corpus cavernosum]</td>\n",
              "      <td>&lt;s&gt;[INST] penile erection is regulated by two ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>effluent from oil production activities contai...</td>\n",
              "      <td>[hydrocarbons]</td>\n",
              "      <td>&lt;s&gt;[INST] effluent from oil production activit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>a new method is described for performing oral ...</td>\n",
              "      <td>[acute respiratory failure]</td>\n",
              "      <td>&lt;s&gt;[INST] a new method is described for perfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>since more than years risk assessment of bisph...</td>\n",
              "      <td>[endocrine disruptors]</td>\n",
              "      <td>&lt;s&gt;[INST] since more than years risk assessmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>in pulmonary hypertension ph measurement of va...</td>\n",
              "      <td>[walk distance]</td>\n",
              "      <td>&lt;s&gt;[INST] in pulmonary hypertension ph measure...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d59b1825-7255-4b73-aa80-5e3d660995e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d59b1825-7255-4b73-aa80-5e3d660995e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d59b1825-7255-4b73-aa80-5e3d660995e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-45182f6e-9849-4565-9fcd-0bb5ad9f01ec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45182f6e-9849-4565-9fcd-0bb5ad9f01ec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-45182f6e-9849-4565-9fcd-0bb5ad9f01ec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_619d8692-5af1-414e-8b91-2e567628404b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_619d8692-5af1-414e-8b91-2e567628404b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF_test",
              "summary": "{\n  \"name\": \"datasetF_test\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19975,\n        \"samples\": [\n          \"the intraaortic balloon pump iabp is the most frequently utilized form of temporary MCS mcs in cardiogenic shock cs withdrawal of iabp support may precipitate hemodynamic compromise such that iabp reinsertion is required data are scarce regarding the incidence and outcomes of patients undergoing iabp reinsertion in this setting\",\n          \"this review describes several aspects of the management of precocious puberty pp and SCV in girls and boys pp is characterized by early pubertal changes acceleration of GV and rapid bone maturation that often result in reduced adult height ON of pubertal signs before the age of years in girls and years in boys should always be evaluated carefully the main principles of therapy are to stop the progression of AA sex characteristics and menses in girls to increase final AH to promote psychosocial wellbeing and to treat the underlying cause if known\",\n          \"amorphous and crystalline forms of cefuroxime axetil were identified and characterized using dsc xrpd sem ftir and RS based on the results of chromatographic studies changes in the kinetic mechanism and rate of degradation of the crystalline form of CAE in binary systems with excipients were also evaluated the findings suggest that the mechanism of Kd of cefuroxime axetil in such systems depends on two factors the applied excipient and storage conditions CAE in combination with magnesium stearate croscarmellose sodium and crospovidone MCC aerosil is decomposed according to the firstorder reaction MM in dry air as well as at an increased relative air humidity which may be associated with noncatalytic interactions between the API and the excipients however in the presence of mannitol under elevated humidity conditions rh the Kd of CAE follows the autocatalytic MM according to esp maps computed IB energies and homo lumo gaps differences of Kd curves between CAE mannitol and other investigated systems were explained this study of the polymorphic transformation of the crystalline form of cefuroxime axetil and its binary systems with excipients T3 exposure to increased temperature and humidity indicated a conversion towards the amorphous form or the coexistence of both forms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19995,\n        \"samples\": [\n          \"<s>[INST] haemophilus influenzae and streptococcus pneumoniae are bacteria with a polysaccharide capsule the production of specific antibodies against capsular polysaccharide plays a pivotal role in the defence against these organisms however children under the age of two years do not at all or only poorly respond to an infection with encapsulated bacteria or after vaccination with purified CP antigen in contrast protein antigens eg tetanus and diphtheriaetoxoid are good immunogens in this age group the difference between SPA and protein antigen is that the former are tdependent antigens whereas the latter are TI the reason for this age dependent immunodeficiency is not clear a functional immaturity of a bcell population seems to be the reason for the unresponsiveness of young children against ti antigens the haemophilus conjugate vaccine contains the capsular polysaccharide chemically conjugated to a carrier protein this results in an immune response against the polysaccharide with characteristics of a t dependent antigen giving high immunogenicity even in children under the age of two years resulting in high antibodyproduction and the induction of immunological memory [/INST] tindependent </s>\",\n          \"<s>[INST] primary pneumonia and metastatic pulmonary infection have become more common in patients with invasive CA staphylococcus aureus disease at texas childrens hospital tch houston [/INST] communityacquired </s>\",\n          \"<s>[INST] because enterococcus avium is rarely isolated from blood cultures little is known about the clinical features and outcomes of bacteremia caused by this organism formerly called group q streptococcus we retrospectively evaluated the clinical features and outcomes of patients with clinically significant bacteremia caused by e avium presenting at a tertiarycare hospital in korea between february and february we identified patients over the year period of these had biliary and had IA e avium infections thirtysix of the episodes were polymicrobial thirtythree episodes were nosocomial bloodstream infections and resistance to vancomycin was not observed the crude mortality rate was and the e avium bacteremiarelated MR was MVA showed that underlying rapidly fatal or ultimately fatal disease adjusted odds ratio aor confidence interval ci p and inadequate antimicrobial therapy aor ci p were independent risk AF for mortality in summary bacteremia due to e avium was commonly of biliary or IA origin and was often associated with polymicrobial bacteremia the CMR was considerable severe underlying conditions and inadequate antimicrobial therapy were significant and independent risk AF for crude patient mortality [/INST] crude mortality rate </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "datasetF_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KQdFE5s1KC9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "0bd7faa1-d4cf-4274-8f49-c3d927c2304f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'while diminished ovarian reserve dor predicts decreased ovarian response to stimulation it does not necessarily foretell about the fecundity cycle according to bolognas criteria laid down by the european society of human reproduction and embryology old age abnormal ovarian reserve tests such as AFC afc and antimullerian hormone amh as well as prior suboptimal response to stimulation are the main AF representing dor unfavorable response to maximal stimulation on two previous occasions may also represent dor among the ovarian reserve tests amh and afc are the most predictive values for dor AF which may give rise to dor include environmental factors autoimmune or metabolic disorders infections genetic abnormalities and iatrogenic causes such as smoking chemotherapy radiation and gynecologic surgeries besides studies have proposed endometriosis as a key contributor to dor and hence emphasized on its proper management to prevent additional damages leading to compromised fertility in summary dor is found to be a clinical challenge in the practice of fertility care with controversial countermeasures to prevent or treat the condition nevertheless some promising measure such as oocyte embryo and tissue cryopreservation ovarian transplantation dietary supplementation and the transfer of mitochondria have offered hopes towards ameliorating the burden of dor this review attempts to discuss dor from different perspectives and summarize some existing hopes in clinical practice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "datasetF_test['Question'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EPsMncjDKK4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10099190-f5c2-4b15-ae75-7be16abc9ec4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['antral follicle count']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "datasetF_test['Answer'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N_B8AVYsKPHO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "caf6243a-9108-42e7-a1b0-85b1e9d2b12c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] while diminished ovarian reserve dor predicts decreased ovarian response to stimulation it does not necessarily foretell about the fecundity cycle according to bolognas criteria laid down by the european society of human reproduction and embryology old age abnormal ovarian reserve tests such as AFC afc and antimullerian hormone amh as well as prior suboptimal response to stimulation are the main AF representing dor unfavorable response to maximal stimulation on two previous occasions may also represent dor among the ovarian reserve tests amh and afc are the most predictive values for dor AF which may give rise to dor include environmental factors autoimmune or metabolic disorders infections genetic abnormalities and iatrogenic causes such as smoking chemotherapy radiation and gynecologic surgeries besides studies have proposed endometriosis as a key contributor to dor and hence emphasized on its proper management to prevent additional damages leading to compromised fertility in summary dor is found to be a clinical challenge in the practice of fertility care with controversial countermeasures to prevent or treat the condition nevertheless some promising measure such as oocyte embryo and tissue cryopreservation ovarian transplantation dietary supplementation and the transfer of mitochondria have offered hopes towards ameliorating the burden of dor this review attempts to discuss dor from different perspectives and summarize some existing hopes in clinical practice [/INST] antral follicle count </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "datasetF_test['text'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lQm2yo0uslTs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c10b42c5c7f4d3fb1707b9c5c543c63",
            "9357ddc4a9414c2eb6407a9dd0b8f775",
            "5e257b929f9c448ab7d441c5bdde4db5",
            "bd9ceeac6a9b40ffa51eb037849aead6",
            "d58c42e97d604983810f58a854edb3bf",
            "967db5a95afc4cd187e86d793a376ffe",
            "1e07351a6e574120a2995325b339b6f4",
            "663e70d935434838be16aa340c4493c8",
            "b917f351f0c6407ba7759529be08c065",
            "ee64a121f0564bb6aadde4f480b57b4f",
            "2a8ba2a3f1594cdbb980c61ee7664ebb"
          ]
        },
        "outputId": "41b892bd-c9c6-4f14-e21b-2e2270fbaaad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c10b42c5c7f4d3fb1707b9c5c543c63"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "# Hugging Face model id\n",
        "#model_id = \"mistralai/Mistral-7B-Instruct-v0.1\" #01 march 2024 AND 10/03/2024\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B\" #22 MAY 2024\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kxOWr2VvEGKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fbc13d-5430-4f8a-8649-1b9e95f4d31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kjyYx9WmtMmA"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=64,\n",
        "        lora_dropout=0.05,\n",
        "        r=128,\n",
        "        bias=\"none\",\n",
        "        target_modules=\"all-linear\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AkMVebosM16A"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"/content/gdrive/MyDrive/model/07MAY2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata-epochs1\",\n",
        "\n",
        "    #num_train_epochs=3,                     # number of training epochs\n",
        "    #num_train_epochs=0.3,                    # number of training epochs for POC\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=1,          # batch size per device during training\n",
        "    #2\n",
        "    gradient_accumulation_steps=8,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    #gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "\n",
        "    warmup_ratio=0.15,\n",
        "    weight_decay=0.05,\n",
        "\n",
        "    logging_steps=100,                       # log every 10 steps\n",
        "    learning_rate=5e-5,                     # learning rate, based on QLoRA paper # i used in the first model\n",
        "\n",
        "    bf16=True,                              # use bfloat16 precision\n",
        "    tf32=True,                              # use tf32 precision\n",
        "    max_grad_norm=1.0,                      # max gradient norm based on QLoRA paper\n",
        "\n",
        "\n",
        "    #lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    lr_scheduler_type=\"cosine\",            # lr_scheduler_type=\"cosine\" (Cosine Annealing Learning Rate)\n",
        "\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=\"/content/gdrive/MyDrive/model/07MAY2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata-epoch1/logs\",\n",
        "\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    metric_for_best_model = \"loss\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lEIGVWGp2dB8"
      },
      "outputs": [],
      "source": [
        "!pip install trl -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wd03Af2od_qT"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "#torch.utils.checkpoint.checkpoint(use_reentrant=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6Yk7MlowDT-"
      },
      "source": [
        "https://huggingface.co/docs/trl/main/en/sft_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "we8LmPrO_AG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b3ee05-efa2-415f-a4ef-ff03f74ed51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "import datasets\n",
        "#from datasets import load_metric\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Convert Pandas DataFrame to Hugging Face Dataset\n",
        "datasetF_hf = datasets.Dataset.from_pandas(datasetF)\n",
        "datasetF_hf_test = datasets.Dataset.from_pandas(datasetF_test)\n",
        "\n",
        "#max_seq_length = 3072 # max sequence length for model and packing of the dataset\n",
        "max_seq_length = 1024\n",
        "\n",
        "# Explicitly set the device using torch.device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Add a padding token to your tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Or, add a new padding token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "#metric = load_metric(\"squad\")  # Assuming you're evaluating on SQuAD dataset\n",
        "#def compute_metrics(eval_pred):\n",
        "#    logits, labels = eval_pred\n",
        "#    predictions = logits.argmax(axis=-1)\n",
        "#    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=datasetF_hf,\n",
        "    dataset_text_field=\"text\", ### added for the summarization dataset\n",
        "    eval_dataset=datasetF_hf_test,\n",
        "\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    #processing_class=tokenizer,\n",
        "    packing=True,\n",
        "    #callbacks=[early_stopping_callback],\n",
        "\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,  # We template with special tokens\n",
        "        \"append_concat_token\": False, # No need to add additional separator token\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nuyiFKmWfvU"
      },
      "source": [
        "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCq7Dq8f7VPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "b7bfaffb-3de5-4f8b-cc7c-4fa34279915b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1270' max='14461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1270/14461 4:27:49 < 46:26:06, 0.08 it/s, Epoch 0.09/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.786200</td>\n",
              "      <td>2.755427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.698400</td>\n",
              "      <td>2.662565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.617800</td>\n",
              "      <td>2.570293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.544300</td>\n",
              "      <td>2.520917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.507900</td>\n",
              "      <td>2.490912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.478200</td>\n",
              "      <td>2.468314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.457500</td>\n",
              "      <td>2.449887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.441300</td>\n",
              "      <td>2.434419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.428900</td>\n",
              "      <td>2.420221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.409400</td>\n",
              "      <td>2.406588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.408000</td>\n",
              "      <td>2.395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.384800</td>\n",
              "      <td>2.385468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=5))\n",
        "\n",
        "\n",
        "# start training, the model will be automatically saved to the hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCxeJIj4KvSQ"
      },
      "outputs": [],
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjTwqcXmK_OR"
      },
      "source": [
        "## Test Model and run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW_hl8YPKxQ2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "\n",
        "peft_model_id = \"/content/gdrive/MyDrive/model/07MAY2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata-epochs1\"\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  attn_implementation=\"flash_attention_2\",\n",
        "  quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "# load into pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1DyOCUfLLn4"
      },
      "source": [
        "Let’s load our test dataset try to generate an instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBZbeEq-R_ti"
      },
      "outputs": [],
      "source": [
        "print(model.peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uHtGXcrLKI_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/test_dataset.json\", split=\"train\")\n",
        "nrec= randint(0, len(eval_dataset))\n",
        "nrec=6\n",
        "\n",
        "# Test on sample\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "prompt =  eval_dataset[nrec]['text']\n",
        "\n",
        "\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GZg3t7d1z9s"
      },
      "outputs": [],
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "ganswer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q2zlGDkw1rE"
      },
      "outputs": [],
      "source": [
        "print(f\"Query:\\n{eval_dataset[nrec]['text']}\")\n",
        "print()\n",
        "oanswer=str(eval_dataset[nrec]['label'])\n",
        "oanswer=oanswer[2:len(oanswer)-2]\n",
        "print(f\"Original Answer:\\n{oanswer}\")\n",
        "print()\n",
        "ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "qc=str(ganswer).find('[INST]')\n",
        "ganswer=ganswer[0:qc-7]\n",
        "qc0=str(ganswer).find('[INST]')\n",
        "ganswer=str(ganswer)[0:qc0]\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "if qc>0:\n",
        "  ganswer=ganswer[qc+8:len(ganswer)]\n",
        "print(f\"Generated Answer:\\n{ganswer}\")\n",
        "print()\n",
        "if ganswer == oanswer:\n",
        "  print(\"Match\")\n",
        "else:\n",
        "  print(\"NO Match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX6ChYhtvtat"
      },
      "outputs": [],
      "source": [
        "nrec=6\n",
        "print(f\"Query:\\n{eval_dataset[nrec]['text']}\")\n",
        "print()\n",
        "print(f\"Original Answer:\\n{eval_dataset[nrec]['label']}\")\n",
        "print()\n",
        "print(f\"Full Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcFTvrGSvJ8G"
      },
      "outputs": [],
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "#print(qc)\n",
        "if int(qc)<0:\n",
        "    #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "    ganswer=outputs[0]['generated_text'][len(prompt)+8:].strip()\n",
        "else:\n",
        "    ganswer=ganswer[qc:len(ganswer)]\n",
        "ganswer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxF38_Am7b_5"
      },
      "outputs": [],
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "qc0=str(ganswer).find('[INST]')\n",
        "ganswer=str(ganswer)[0:qc0-8]\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "\n",
        "if qc>=0:\n",
        "  ganswer=ganswer[qc+8:len(ganswer)]\n",
        "\n",
        "print(f\"Generated Answer:\\n{ganswer}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load a pre-trained sentence embedding model\n",
        "model_embedding = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "# Load your test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/test_dataset.json\", split=\"train\")\n",
        "\n",
        "# Create the generation pipeline\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
        "\n",
        "def evaluate(sample):\n",
        "    prompt = sample['text']\n",
        "    outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.7,\n",
        "                                  top_k=50, top_p=0.7, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    ganswer = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "    qc0 = str(ganswer).find('[/INST]')\n",
        "    qc1 = str(ganswer).find('[INST]')\n",
        "    ganswer = str(ganswer)[qc0 + 8:qc1 - 8]\n",
        "\n",
        "    oanswer = str(sample['label'])\n",
        "    oanswer = oanswer[2:len(oanswer) - 2]\n",
        "\n",
        "    if len(oanswer) == 0:\n",
        "        oanswer = 'Not possible to get or use'\n",
        "\n",
        "    #print('\\n\\n')\n",
        "    #print(f\"Question: {prompt}\")\n",
        "    #print(f\"Generated Answer: {ganswer}\")\n",
        "    #print(f\"Original Answer: {oanswer}\")\n",
        "\n",
        "    # Generate sentence embeddings\n",
        "    embedding1 = model_embedding.encode(ganswer, convert_to_tensor=True)\n",
        "    embedding2 = model_embedding.encode(oanswer, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_sim = util.cos_sim(embedding1, embedding2).item()\n",
        "\n",
        "    # Set a similarity threshold (adjust as needed)\n",
        "    if cosine_sim >= 0.5:\n",
        "        #print(\"Match\")\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "success_rate = []\n",
        "number_of_eval_samples = 10  # Adjust the number of samples as needed\n",
        "\n",
        "# Evaluate the model\n",
        "for n in tqdm(range(number_of_eval_samples)):\n",
        "    s = eval_dataset[n]\n",
        "    success_rate.append(evaluate(s))\n"
      ],
      "metadata": {
        "id": "MC-SNHc8v63E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = sum(success_rate) / len(success_rate)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "ZxoCKRJddDW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorbard"
      ],
      "metadata": {
        "id": "akI7UTrzW95o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/tensorbard\n",
        "%mkdir -p /content/tensorbard\n",
        "%cd /content/tensorbard\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/frankmorales2020/11APRIL2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata"
      ],
      "metadata": {
        "id": "alATl2MpWIur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tensorbard/07MAY2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata-epoch1/logs/"
      ],
      "metadata": {
        "id": "jRBbdyrqWKHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AGENT"
      ],
      "metadata": {
        "id": "GvHJA9_AfdlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-adk transformers torch datasets -q"
      ],
      "metadata": {
        "id": "9rs7srDAfvZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.artifacts import InMemoryArtifactService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.agent_protocols import agent_protocol\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Define the local path to your fine-tuned model\n",
        "# This path is from your Google Drive mount in the Colab environment\n",
        "FINE_TUNED_MODEL_PATH = \"/content/gdrive/MyDrive/model/07MAY2025-Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine-evaldata-epochs1\"\n",
        "\n",
        "# Load the model and tokenizer from the local path using transformers\n",
        "# We assume this code is run in an environment where this path is accessible\n",
        "try:\n",
        "    # Determine the device to use (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load the tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(FINE_TUNED_MODEL_PATH)\n",
        "    # Set padding token if it's not already set\n",
        "    if tokenizer.pad_token is None:\n",
        "         tokenizer.pad_token = tokenizer.eos_token\n",
        "         if tokenizer.pad_token is None:\n",
        "             # Fallback if EOS token is also not set\n",
        "             tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "\n",
        "    # Load the model\n",
        "    # Use torch_dtype=torch.bfloat16 if your GPU supports it for potentially faster inference\n",
        "    model = AutoModelForCausalLM.from_pretrained(FINE_TUNED_MODEL_PATH, torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32).to(device)\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "\n",
        "    print(f\"Successfully loaded model and tokenizer from {FINE_TUNED_MODEL_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or tokenizer from {FINE_TUNED_MODEL_PATH}. Please ensure the path is correct and the necessary libraries are installed.\")\n",
        "    print(f\"Details: {e}\")\n",
        "    # Exit or handle the error appropriately if the model cannot be loaded\n",
        "    model = None\n",
        "    tokenizer = None\n",
        "\n",
        "\n",
        "# Define a simple agent class inheriting from ADK's Agent\n",
        "class LocalFineTunedMedicalAgent(Agent):\n",
        "    def __init__(self, name: str, instruction: str, model, tokenizer):\n",
        "        # ADK's Agent class expects a model object.\n",
        "        # We pass the transformers model here, but will directly use it\n",
        "        # in the _run_async_impl method instead of relying on ADK's\n",
        "        # internal model handling for LiteLlm or other integrated models.\n",
        "        super().__init__(name=name, instruction=instruction, model=None) # Set model to None here as we handle it directly\n",
        "        self._local_model = model\n",
        "        self._local_tokenizer = tokenizer\n",
        "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "    # The core asynchronous method where the agent processes input\n",
        "    async def _run_async_impl(self, context: agent_protocol.InvocationContext):\n",
        "        if self._local_model is None or self._local_tokenizer is None:\n",
        "            yield agent_protocol.AgentResponse(\n",
        "                message=agent_protocol.AgentMessage(text=\"Error: Language model not loaded.\")\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Access the user's query from the invocation context\n",
        "        user_query = context.request.message.text\n",
        "\n",
        "        # print(f\"Agent '{self.name}' received query: {user_query}\") # Uncomment for more detailed logging\n",
        "\n",
        "        # --- Text Generation using the locally loaded transformers model ---\n",
        "        try:\n",
        "            # Prepare the prompt\n",
        "            # You might want to format the prompt based on your model's\n",
        "            # preferred input format (e.g., chat format like Llama 3)\n",
        "            # For this example, we'll use a simple instruction format derived from your notebook\n",
        "            # Assuming your model was fine-tuned with prompts like \"[INST] instruction [/INST]\"\n",
        "            prompt = f\"[INST] {self.instruction}\\n{user_query} [/INST]\"\n",
        "\n",
        "\n",
        "            # Tokenize the input\n",
        "            inputs = self._local_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(self._device)\n",
        "\n",
        "            # Generate text\n",
        "            with torch.no_grad(): # Disable gradient calculation for inference\n",
        "                 outputs = self._local_model.generate(\n",
        "                     **inputs,\n",
        "                     max_new_tokens=256, # Limit the generated response length\n",
        "                     num_return_sequences=1,\n",
        "                     do_sample=True,\n",
        "                     top_k=50,\n",
        "                     top_p=0.95,\n",
        "                     temperature=0.7,\n",
        "                     # Add other generation parameters as needed\n",
        "                     pad_token_id=self._local_tokenizer.pad_token_id # Ensure pad_token_id is set for generation\n",
        "                 )\n",
        "\n",
        "            # Decode the generated tokens\n",
        "            generated_text_with_prompt = self._local_tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "            # Post-process the generated text to extract the agent's response\n",
        "            # Based on the prompt format \"[INST] ... [/INST] response\", we want the part after [/INST]\n",
        "            if \"[/INST]\" in generated_text_with_prompt:\n",
        "                generated_text = generated_text_with_prompt.split(\"[/INST]\", 1)[1].strip()\n",
        "            else:\n",
        "                 # Fallback if the expected format is not present\n",
        "                 generated_text = generated_text_with_prompt.strip()\n",
        "\n",
        "            # Further cleaning might be needed depending on model output (e.g., cutting off at a specific token or phrase)\n",
        "            # If the model generates a new turn of the prompt, cut it off\n",
        "            if \"[INST]\" in generated_text:\n",
        "                 generated_text = generated_text.split(\"[INST]\", 1)[0].strip()\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            generated_text = f\"An error occurred during text generation: {e}\"\n",
        "            print(f\"Error during text generation with transformers: {e}\")\n",
        "\n",
        "        # Yield the final response from the agent\n",
        "        yield agent_protocol.AgentResponse(\n",
        "            message=agent_protocol.AgentMessage(text=generated_text)\n",
        "        )\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "async def main():\n",
        "    # Ensure model and tokenizer were loaded successfully\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Model loading failed. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # 1. Instantiate the in-memory services for artifacts and sessions\n",
        "    artifact_service = InMemoryArtifactService()\n",
        "    session_service = InMemorySessionService()\n",
        "\n",
        "    # 2. Create an instance of your local fine-tuned agent\n",
        "    agent_name = \"LocalFineTunedMedicalAssistant\"\n",
        "    # This instruction helps guide the LLM's behavior.\n",
        "    # Since we are handling prompting manually in _run_async_impl,\n",
        "    # this instruction will be explicitly included in the prompt sent to the LLM.\n",
        "    agent_instruction = (\n",
        "        \"You are a highly specialized AI medical assistant, fine-tuned to provide information \"\n",
        "        \"based on medical literature. Answer questions accurately and concisely, focusing on \"\n",
        "        \"information related to medical concepts and terminology.\"\n",
        "    )\n",
        "\n",
        "    medical_agent = LocalFineTunedMedicalAgent(\n",
        "        name=agent_name,\n",
        "        instruction=agent_instruction,\n",
        "        model=model,          # Pass the loaded transformers model\n",
        "        tokenizer=tokenizer   # Pass the loaded transformers tokenizer\n",
        "    )\n",
        "\n",
        "    # 3. Create a Runner instance\n",
        "    runner = Runner(\n",
        "        agent=medical_agent,\n",
        "        session_service=session_service,\n",
        "        artifact_service=artifact_service\n",
        "    )\n",
        "\n",
        "    # 4. Define a test question (you can replace this with input from your dataset if loaded)\n",
        "    # Using the hardcoded question from your notebook output for demonstration\n",
        "    test_question = \"\"\"while diminished ovarian reserve dor predicts decreased ovarian response to\n",
        "stimulation it does not necessarily foretell about the fecundity cycle acco\n",
        "rding to bolognas criteria laid down by the european society of human repro\n",
        "duction and embryology old age abnormal ovarian reserve tests such as AFC a\n",
        "fc and antimullerian hormone amh as well as prior suboptimal response to st\n",
        "imulation are the main AF representing dor unfavorable response to maximal\n",
        "stimulation on two previous occasions may also represent dor among the ovar\n",
        "ian reserve tests amh and afc are the most predictive values for dor AF whi\n",
        "ch may give rise to dor include environmental factors autoimmune or metabol\n",
        "ic disorders infections genetic abnormalities and iatrogenic causes such as\n",
        "smoking chemotherapy radiation and gynecologic surgeries besides studies ha\n",
        "ve proposed endometriosis as a key contributor to dor and hence emphasized\n",
        "on its proper management to prevent additional damages leading to compromis\n",
        "ed fertility in summary dor is found to be a clinical challenge in the prac\n",
        "tice of fertility care with controversial countermeasures to prevent or tre\n",
        "at the condition nevertheless some promising measure such as oocyte embryo\n",
        "and tissue cryopreservation ovarian transplantation dietary supplementation\n",
        "and the transfer of mitochondria have offered hopes towards ameliorating th\n",
        "e burden of dor this review attempts to discuss dor from different perspect\n",
        "ives and summarize some existing hopes in clinical practice\"\"\"\n",
        "\n",
        "    test_original_answer = \"antral follicle count\" # The expected answer for comparison\n",
        "\n",
        "    print(f\"\\n--- Testing the Agent ---\")\n",
        "    print(f\"Input Question: {test_question}\")\n",
        "    print(f\"Expected Answer: {test_original_answer}\")\n",
        "\n",
        "    # Use a unique user and session ID for this test\n",
        "    user_id = \"test_user\"\n",
        "    session_id = \"test_session\"\n",
        "\n",
        "    try:\n",
        "        # Execute the agent with the test question as input\n",
        "        async for event in runner.run(user_id=user_id, session_id=session_id, user_message=test_question):\n",
        "            # Check if the yielded event is a final agent response\n",
        "            if event.is_final_response():\n",
        "                print(f\"Agent Generated Answer: {event.message.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during agent execution: {e}\")\n",
        "\n",
        "\n",
        "# Entry point to run the asynchronous example\n",
        "if __name__ == \"__main__\":\n",
        "    # Make sure you have the required libraries installed:\n",
        "    # pip install google-adk transformers torch\n",
        "    # If using a GPU, you'll also need to install the appropriate version of cuDA toolkit\n",
        "    # Ensure your Google Drive is mounted and the path to the model is correct.\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "wALYHSaGff56"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26010cdcab2a47f6b7723e7d6bb4b02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7828f1e709ed492481dcae2668adfa7f",
              "IPY_MODEL_02e4e71b876a476f873a0bae2fa866c6",
              "IPY_MODEL_1372d52c7bd04ee9881ba764c3c30dfb"
            ],
            "layout": "IPY_MODEL_d6e43eae2e9546b8acffe486d9dc2d8f"
          }
        },
        "7828f1e709ed492481dcae2668adfa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cf01ac7f134442834c81ee042ec97e",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4c46eba172433ca632bb591aa4759c",
            "value": "Generating train split: "
          }
        },
        "02e4e71b876a476f873a0bae2fa866c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610aef8079c54bccb4edd2290b67d22d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f97d97021481405689979682a9f8e0ef",
            "value": 1
          }
        },
        "1372d52c7bd04ee9881ba764c3c30dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e79d52f506447b48d0d12d7eee553e9",
            "placeholder": "​",
            "style": "IPY_MODEL_27c6668eaac94bb3b87f0ac3b4d81fde",
            "value": " 500000/0 [00:04&lt;00:00, 101593.64 examples/s]"
          }
        },
        "d6e43eae2e9546b8acffe486d9dc2d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cf01ac7f134442834c81ee042ec97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4c46eba172433ca632bb591aa4759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "610aef8079c54bccb4edd2290b67d22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f97d97021481405689979682a9f8e0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e79d52f506447b48d0d12d7eee553e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c6668eaac94bb3b87f0ac3b4d81fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e1ac2c960c34dc2804213a36a08363d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f2913574de74dfc8989a342752443db",
              "IPY_MODEL_881a63033572416a8549d2885b87ffc8",
              "IPY_MODEL_fa2e809055e340d194b38865a79e8c73"
            ],
            "layout": "IPY_MODEL_206ad887bb2b4dd9b4d185a2f20c9f6f"
          }
        },
        "3f2913574de74dfc8989a342752443db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06b2a39a8d5427c8123562fd49077a8",
            "placeholder": "​",
            "style": "IPY_MODEL_2604cd973f7146898ed36864733e1b0d",
            "value": "Generating train split: "
          }
        },
        "881a63033572416a8549d2885b87ffc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43800e174ab0403c83314fb4d0ea951d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293b3ae6e516465583cbdc96c36bffe8",
            "value": 1
          }
        },
        "fa2e809055e340d194b38865a79e8c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1320c7684240318d2c217952748736",
            "placeholder": "​",
            "style": "IPY_MODEL_f0745ecaaedb4a97ab5a5017048a4bec",
            "value": " 20000/0 [00:00&lt;00:00, 137827.79 examples/s]"
          }
        },
        "206ad887bb2b4dd9b4d185a2f20c9f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06b2a39a8d5427c8123562fd49077a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2604cd973f7146898ed36864733e1b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43800e174ab0403c83314fb4d0ea951d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "293b3ae6e516465583cbdc96c36bffe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c1320c7684240318d2c217952748736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0745ecaaedb4a97ab5a5017048a4bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c10b42c5c7f4d3fb1707b9c5c543c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9357ddc4a9414c2eb6407a9dd0b8f775",
              "IPY_MODEL_5e257b929f9c448ab7d441c5bdde4db5",
              "IPY_MODEL_bd9ceeac6a9b40ffa51eb037849aead6"
            ],
            "layout": "IPY_MODEL_d58c42e97d604983810f58a854edb3bf"
          }
        },
        "9357ddc4a9414c2eb6407a9dd0b8f775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_967db5a95afc4cd187e86d793a376ffe",
            "placeholder": "​",
            "style": "IPY_MODEL_1e07351a6e574120a2995325b339b6f4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5e257b929f9c448ab7d441c5bdde4db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663e70d935434838be16aa340c4493c8",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b917f351f0c6407ba7759529be08c065",
            "value": 4
          }
        },
        "bd9ceeac6a9b40ffa51eb037849aead6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee64a121f0564bb6aadde4f480b57b4f",
            "placeholder": "​",
            "style": "IPY_MODEL_2a8ba2a3f1594cdbb980c61ee7664ebb",
            "value": " 4/4 [00:16&lt;00:00,  3.51s/it]"
          }
        },
        "d58c42e97d604983810f58a854edb3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967db5a95afc4cd187e86d793a376ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e07351a6e574120a2995325b339b6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "663e70d935434838be16aa340c4493c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b917f351f0c6407ba7759529be08c065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee64a121f0564bb6aadde4f480b57b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8ba2a3f1594cdbb980c61ee7664ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}