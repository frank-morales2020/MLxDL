{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "e6aSrrkO88f7",
        "ivAci5fY8l-n",
        "3ZTK-cZq9dYu",
        "TzD1cXstiWc_",
        "vUETKu-2iCx0"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPN9ZBkshOiXRJioYBkkaqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d24d6e6ea9e64e3296d14d29302c60aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d754433511e94431b713cc14e2c25707",
              "IPY_MODEL_0560823bf6c84a54936ae31112672933",
              "IPY_MODEL_ffa2154b19fa4562885b21f01f6d2af8"
            ],
            "layout": "IPY_MODEL_9b7ac7c2580c4c08812ce757ab28da82"
          }
        },
        "d754433511e94431b713cc14e2c25707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565c6cbd0386470dac7c4a2321a9f160",
            "placeholder": "​",
            "style": "IPY_MODEL_009f441b337e4b0f87f573bee5c2848d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0560823bf6c84a54936ae31112672933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b165c8d59d14d2fabcd27497880c0ae",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa73df9ebbe9482d865426f09fb8cbf7",
            "value": 2
          }
        },
        "ffa2154b19fa4562885b21f01f6d2af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc4130ccfa8497688fe4f9b0791145f",
            "placeholder": "​",
            "style": "IPY_MODEL_7191fd73cbaf4757b87254b6fbf1ebdb",
            "value": " 2/2 [01:11&lt;00:00, 33.13s/it]"
          }
        },
        "9b7ac7c2580c4c08812ce757ab28da82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565c6cbd0386470dac7c4a2321a9f160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009f441b337e4b0f87f573bee5c2848d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b165c8d59d14d2fabcd27497880c0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa73df9ebbe9482d865426f09fb8cbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc4130ccfa8497688fe4f9b0791145f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7191fd73cbaf4757b87254b6fbf1ebdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/langchain_opensourceLLM_mistral7B_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings, PostgreSQL, Langchain, Openai, Mistral Text Generation and RAG"
      ],
      "metadata": {
        "id": "srP0wVMgDtuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "e6aSrrkO88f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/langchain-ai/langchain/issues/10454\n",
        "https://platform.openai.com/docs/guides/text-generation\n",
        "https://python.langchain.com/docs/integrations/vectorstores/pgembedding\n",
        "https://www.datacamp.com/tutorial/introduction-to-text-embeddings-with-the-open-ai-api\n",
        "https://journal.everypixel.com/2023-the-year-of-ai"
      ],
      "metadata": {
        "id": "xiOg0LBet1xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "ivAci5fY8l-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Libraries to access Google Drive and OpenAI resources.\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore\n",
        "%pip install openai==0.28  --root-user-action=ignore\n",
        "%pip install langchain\n",
        "%pip install \"unstructured[all-docs]\"\n",
        "%pip install tiktoken\n",
        "!pip install -q -U sentence-transformers"
      ],
      "metadata": {
        "id": "eK-g15EV9xAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enviroment Variables"
      ],
      "metadata": {
        "id": "3ZTK-cZq9dYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4FVngkiE-px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62f1f62-7e9b-4b7f-f8b5-a5f5c3c953b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "from openai.embeddings_utils import cosine_similarity\n",
        "\n",
        "connection_string = os.getenv(\"DATABASE_URL\")\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding settings with OpenAI\n"
      ],
      "metadata": {
        "id": "wBUlONel-oFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str) -> list:\n",
        " response = openai.Embedding.create(\n",
        "     input=text,\n",
        "     model=\"text-embedding-ada-002\"\n",
        " )\n",
        " return response['data'][0]['embedding']\n",
        "\n",
        "good_ride = \"good ride\"\n",
        "good_ride_embedding = get_embedding(good_ride)\n",
        "\n",
        "len(good_ride_embedding)\n",
        "# 1536\n",
        "\n",
        "good_ride_review_1 = \"I really enjoyed the trip! The ride was incredibly smooth, the pick-up location was convenient, and the drop-off point was right in front of the coffee shop.\"\n",
        "good_ride_review_1_embedding = get_embedding(good_ride_review_1)\n",
        "similary=cosine_similarity(good_ride_review_1_embedding, good_ride_embedding)\n",
        "# 0.8300454513797334\n",
        "similary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_UA1XNb-wW5",
        "outputId": "9864bd76-cd97-43ac-caad-2fec4eace930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8300454513797334"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PostgreSQL Settings - PGVECTOR and PGEMBEDDINGS"
      ],
      "metadata": {
        "id": "zIicHZ0E_Ard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://python.langchain.com/docs/integrations/vectorstores/pgembedding\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "%cd /content/gdrive/MyDrive/tools/pgvector\n",
        "!cp -pr /content/gdrive/MyDrive/tools/pgvector /content/\n",
        "%cd /content/pgvector/\n",
        "print()\n",
        "print('START: PG VECTOR COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG VECTOR COMPILATION')\n",
        "print()\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/neondatabase/pg_embedding.git\n",
        "%cd /content/pg_embedding\n",
        "print()\n",
        "print('START: PG embedding COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG embedding COMPILATION')\n",
        "print()\n",
        "\n",
        "#!ls /usr/share/postgresql/14/extension/*control*"
      ],
      "metadata": {
        "id": "17ZU8J7dK-B6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37d9747-9459-42f4-97a2-2b2b3f28ec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14 python3-pygments\n",
            "  python3-yaml\n",
            "Suggested packages:\n",
            "  llvm-14-doc python-pygments-doc ttf-bitstream-vera\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev libpfm4 libz3-4 libz3-dev llvm-14 llvm-14-dev\n",
            "  llvm-14-runtime llvm-14-tools postgresql-server-dev-14\n",
            "  postgresql-server-dev-all python3-pygments python3-yaml\n",
            "0 upgraded, 13 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 59.8 MB of archives.\n",
            "After this operation, 361 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 binfmt-support amd64 2.2.1-2 [55.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-runtime amd64 1:14.0.0-1ubuntu1.1 [484 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpfm4 amd64 4.11.1+git32-gd0b85fb-1ubuntu0.1 [345 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14 amd64 1:14.0.0-1ubuntu1.1 [12.7 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-pygments all 2.11.2+dfsg-2 [750 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-tools amd64 1:14.0.0-1ubuntu1.1 [404 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-4 amd64 4.8.12-1 [5,766 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libz3-dev amd64 4.8.12-1 [72.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 llvm-14-dev amd64 1:14.0.0-1ubuntu1.1 [37.8 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 postgresql-server-dev-14 amd64 14.10-0ubuntu0.22.04.1 [1,175 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 postgresql-server-dev-all amd64 238 [14.0 kB]\n",
            "Fetched 59.8 MB in 5s (12.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 13.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 123619 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Selecting previously unselected package binfmt-support.\n",
            "Preparing to unpack .../01-binfmt-support_2.2.1-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.2.1-2) ...\n",
            "Selecting previously unselected package llvm-14-runtime.\n",
            "Preparing to unpack .../02-llvm-14-runtime_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libpfm4:amd64.\n",
            "Preparing to unpack .../03-libpfm4_4.11.1+git32-gd0b85fb-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Selecting previously unselected package llvm-14.\n",
            "Preparing to unpack .../04-llvm-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../05-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../06-python3-pygments_2.11.2+dfsg-2_all.deb ...\n",
            "Unpacking python3-pygments (2.11.2+dfsg-2) ...\n",
            "Selecting previously unselected package llvm-14-tools.\n",
            "Preparing to unpack .../07-llvm-14-tools_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libz3-4:amd64.\n",
            "Preparing to unpack .../08-libz3-4_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-4:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package libz3-dev:amd64.\n",
            "Preparing to unpack .../09-libz3-dev_4.8.12-1_amd64.deb ...\n",
            "Unpacking libz3-dev:amd64 (4.8.12-1) ...\n",
            "Selecting previously unselected package llvm-14-dev.\n",
            "Preparing to unpack .../10-llvm-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-14.\n",
            "Preparing to unpack .../11-postgresql-server-dev-14_14.10-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-14 (14.10-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql-server-dev-all:amd64.\n",
            "Preparing to unpack .../12-postgresql-server-dev-all_238_amd64.deb ...\n",
            "Unpacking postgresql-server-dev-all:amd64 (238) ...\n",
            "Setting up python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up python3-pygments (2.11.2+dfsg-2) ...\n",
            "Setting up libz3-4:amd64 (4.8.12-1) ...\n",
            "Setting up libpfm4:amd64 (4.11.1+git32-gd0b85fb-1ubuntu0.1) ...\n",
            "Setting up llvm-14-runtime (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up binfmt-support (2.2.1-2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "Setting up llvm-14 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up llvm-14-tools (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libz3-dev:amd64 (4.8.12-1) ...\n",
            "Setting up llvm-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up postgresql-server-dev-14 (14.10-0ubuntu0.22.04.1) ...\n",
            "Setting up postgresql-server-dev-all:amd64 (238) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/content/gdrive/MyDrive/tools/pgvector\n",
            "/content/pgvector\n",
            "\n",
            "START: PG VECTOR COMPILATION\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  vector.so '/usr/lib/postgresql/14/lib/vector.so'\n",
            "/usr/bin/install -c -m 644 .//vector.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//sql/vector--0.1.0--0.1.1.sql .//sql/vector--0.1.1--0.1.3.sql .//sql/vector--0.1.3--0.1.4.sql .//sql/vector--0.1.4--0.1.5.sql .//sql/vector--0.1.5--0.1.6.sql .//sql/vector--0.1.6--0.1.7.sql .//sql/vector--0.1.7--0.1.8.sql .//sql/vector--0.1.8--0.2.0.sql .//sql/vector--0.2.0--0.2.1.sql .//sql/vector--0.2.1--0.2.2.sql .//sql/vector--0.2.2--0.2.3.sql .//sql/vector--0.2.3--0.2.4.sql .//sql/vector--0.2.4--0.2.5.sql .//sql/vector--0.2.5--0.2.6.sql .//sql/vector--0.2.6--0.2.7.sql .//sql/vector--0.2.7--0.3.0.sql .//sql/vector--0.3.0--0.3.1.sql .//sql/vector--0.3.1--0.3.2.sql .//sql/vector--0.3.2--0.4.0.sql .//sql/vector--0.4.0--0.4.1.sql .//sql/vector--0.4.1--0.4.2.sql .//sql/vector--0.4.2--0.4.3.sql .//sql/vector--0.4.3--0.4.4.sql .//sql/vector--0.4.4--0.5.0.sql .//sql/vector--0.5.0--0.5.1.sql .//sql/vector--0.5.1.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/usr/bin/install -c -m 644   .//src/vector.h '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/vector'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnsw.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfflat.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfkmeans.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/vector.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o vector.index.bc vector/src/hnsw.bc vector/src/hnswbuild.bc vector/src/hnswinsert.bc vector/src/hnswscan.bc vector/src/hnswutils.bc vector/src/hnswvacuum.bc vector/src/ivfbuild.bc vector/src/ivfflat.bc vector/src/ivfinsert.bc vector/src/ivfkmeans.bc vector/src/ivfscan.bc vector/src/ivfutils.bc vector/src/ivfvacuum.bc vector/src/vector.bc\n",
            "END: PG VECTOR COMPILATION\n",
            "\n",
            "/content\n",
            "Cloning into 'pg_embedding'...\n",
            "remote: Enumerating objects: 553, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 553 (delta 140), reused 135 (delta 106), pack-reused 370\u001b[K\n",
            "Receiving objects: 100% (553/553), 270.29 KiB | 3.51 MiB/s, done.\n",
            "Resolving deltas: 100% (317/317), done.\n",
            "/content/pg_embedding\n",
            "\n",
            "START: PG embedding COMPILATION\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o embedding.o embedding.c\n",
            "g++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -std=c++11 -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o hnswalg.o hnswalg.cpp\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2   -c -o distfunc.o distfunc.c\n",
            "gcc -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -g -O2 -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -fno-omit-frame-pointer -Ofast -fPIC -shared -o embedding.so embedding.o hnswalg.o distfunc.o -lstdc++ -L/usr/lib/x86_64-linux-gnu -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now -L/usr/lib/llvm-14/lib  -Wl,--as-needed  \n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o embedding.bc embedding.c\n",
            "/usr/bin/clang-14 -xc++ -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o hnswalg.bc hnswalg.cpp\n",
            "/usr/bin/clang-14 -Wno-ignored-attributes -fno-strict-aliasing -fwrapv -Wno-unused-command-line-argument -Wno-compound-token-split-by-macro -O2  -I. -I./ -I/usr/include/postgresql/14/server -I/usr/include/postgresql/internal  -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -flto=thin -emit-llvm -c -o distfunc.bc distfunc.c\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  embedding.so '/usr/lib/postgresql/14/lib/embedding.so'\n",
            "/usr/bin/install -c -m 644 .//embedding.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//embedding--0.3.5--0.3.6.sql .//embedding--0.3.5.sql .//embedding--0.3.6.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/embedding'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/embedding/\n",
            "/usr/bin/install -c -m 644 embedding.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 hnswalg.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 distfunc.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o embedding.index.bc embedding/embedding.bc embedding/hnswalg.bc embedding/distfunc.bc\n",
            "END: PG embedding COMPILATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2 as ps\n",
        "\n",
        "# PostGRES SQL Settings\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "#!sudo -u postgres psql -c \"DROP EXTENSION embedding\"\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION embedding\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id integer PRIMARY KEY, embedding real[])\"\n",
        "\n",
        "h=\"{0,1,2}\"\n",
        "hh= \"INSERT INTO documents(id, embedding) VALUES (1,'%s'), (2,'{1,2,3}'),  (3,'{1,1,1}')\"%h\n",
        "print(hh)\n",
        "\n",
        "def insert_document(id,embedding):\n",
        "    #review_embedding=get_embedding(text)\n",
        "    ### INSERT INTO DB\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "        INSERT INTO documents\n",
        "        (id, embedding)\n",
        "        VALUES ('%s',\n",
        "                '%s')\"\"\" % (id,embedding))\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"INSERT EMBEDDING %s successfully\"%embedding)\n",
        "    conn.close()\n",
        "    cur.close()\n",
        "\n",
        "\n",
        "insert_document(1,'{0,1,2}')\n",
        "insert_document(2,\"{1,2,3}\")\n",
        "insert_document(3,\"{1,1,1}\")\n",
        "\n",
        "\n",
        "!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=3, efconstruction=5, efsearch=5)\"\n",
        "!sudo -u postgres psql -c \"SET enable_seqscan = off\"\n",
        "\n",
        "ARRAY = [3, 3, 3]\n",
        "\n",
        "def select_document(HNSW_index):\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "    SELECT id FROM documents\n",
        "    ORDER BY embedding %s ARRAY[%s,%s,%s] LIMIT 1\n",
        "    \"\"\" % (HNSW_index,str(ARRAY[0]), str(ARRAY[1]), str(ARRAY[2])))\n",
        "\n",
        "    conn.commit()\n",
        "    print(cur.fetchone())\n",
        "    #print(\"INSERT EMBEDDING %s successfully\"%embedding)\n",
        "    conn.close()\n",
        "    cur.close()\n",
        "\n",
        "# <->, <=>, and <~> operators define the distance metric, which calculates the distance between the query vector and each row of the dataset.\n",
        "select_document('<->')\n",
        "select_document('<=>')\n",
        "select_document('<~>')"
      ],
      "metadata": {
        "id": "gfRqhgiCLulH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97979338-0e6e-4088-cf03-c5c82091d965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ALTER ROLE\n",
            "CREATE EXTENSION\n",
            "ERROR:  table \"documents\" does not exist\n",
            "CREATE TABLE\n",
            "INSERT INTO documents(id, embedding) VALUES (1,'{0,1,2}'), (2,'{1,2,3}'),  (3,'{1,1,1}')\n",
            "INSERT EMBEDDING {0,1,2} successfully\n",
            "INSERT EMBEDDING {1,2,3} successfully\n",
            "INSERT EMBEDDING {1,1,1} successfully\n",
            "CREATE INDEX\n",
            "SET\n",
            "(2,)\n",
            "(3,)\n",
            "(2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documents loader\n",
        "\n",
        "Postgres with the pg_embedding extension as a vector store.\n",
        "\n",
        "pg_embedding uses sequential scan by default. but you can create a HNSW index using the create_hnsw_index method."
      ],
      "metadata": {
        "id": "w0qP5gW9Bn8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "State of the Union"
      ],
      "metadata": {
        "id": "6LdSuJBWCAte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install -q langchain\n",
        "#%pip install -q \"unstructured[all-docs]\"\n",
        "\n",
        "## Loading Environment Variables\n",
        "from typing import List, Tuple\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "#import getpass\n",
        "\n",
        "! git clone https://github.com/hwchase17/chat-your-data.git\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "#loader = UnstructuredFileLoader(\"/content/chat-your-data/state_of_the_union.txt\")\n",
        "loader = TextLoader(\"/content/chat-your-data/state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs0 = text_splitter.split_documents(documents)\n",
        "\n",
        "collection_name0 = \"state_of_the_union\"\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs0)}')"
      ],
      "metadata": {
        "id": "RzBzjbInMJDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b420f25-0737-4555-bb96-b694d7288c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chat-your-data'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 62 (delta 17), reused 15 (delta 13), pack-reused 34\u001b[K\n",
            "Receiving objects: 100% (62/62), 24.22 MiB | 26.59 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "# of Document Pages 1\n",
            "# of Document Chunks: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AWS documents"
      ],
      "metadata": {
        "id": "Y0--r-BzB3cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urls = [\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    'AMZN-2022-Shareholder-Letter.pdf',\n",
        "    'AMZN-2021-Shareholder-Letter.pdf',\n",
        "    'AMZN-2020-Shareholder-Letter.pdf',\n",
        "    'AMZN-2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    dict(year=2022, source=filenames[0]),\n",
        "    dict(year=2021, source=filenames[1]),\n",
        "    dict(year=2020, source=filenames[2]),\n",
        "    dict(year=2019, source=filenames[3])]\n",
        "\n",
        "data_root = \"/content/data/\"\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "    file_path = data_root + filenames[idx]\n",
        "    urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "tczhrARPWA3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader, PdfWriter\n",
        "import glob\n",
        "\n",
        "local_pdfs = glob.glob(data_root + '*.pdf')\n",
        "\n",
        "for local_pdf in local_pdfs:\n",
        "    pdf_reader = PdfReader(local_pdf)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for pagenum in range(len(pdf_reader.pages)-3):\n",
        "        page = pdf_reader.pages[pagenum]\n",
        "        pdf_writer.add_page(page)\n",
        "\n",
        "    with open(local_pdf, 'wb') as new_file:\n",
        "        new_file.seek(0)\n",
        "        pdf_writer.write(new_file)\n",
        "        new_file.truncate()\n"
      ],
      "metadata": {
        "id": "N8xG0DTy7BHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "documents = []\n",
        "\n",
        "for idx, file in enumerate(filenames):\n",
        "    loader = PyPDFLoader(data_root + file)\n",
        "    document = loader.load()\n",
        "    for document_fragment in document:\n",
        "        document_fragment.metadata = metadata[idx]\n",
        "\n",
        "    documents += document\n",
        "\n",
        "# - in our testing Character split works better with this PDF data set\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 100,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs)}')\n",
        "\n",
        "collection_name = \"AWS\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DRwHWP7IAW",
        "outputId": "1dbdb31f-bb9a-4acd-d0e8-147ad27d0a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Document Pages 25\n",
            "# of Document Chunks: 299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import scoped_session, sessionmaker\n",
        "\n",
        "\n",
        "#!pip install tiktoken\n",
        "%cd /content/\n",
        "\n",
        "# https://supabase.com/blog/fewer-dimensions-are-better-pgvector\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "#https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "db = PGEmbedding.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs,\n",
        "    collection_name=collection_name,\n",
        "    connection_string=connection_string,\n",
        ")\n",
        "\n",
        "#del query\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "#query = \"What did the president say about AWS\"\n",
        "query = \"How has AWS evolved?\"\n",
        "#query = \"What are the issues with AWS?\"\n",
        "print(query)\n",
        "\n",
        "#docs_with_score: List[Tuple[Document, float]] = db.similarity_search_with_score(query)\n",
        "\n",
        "#for doc, score in docs_with_score:\n",
        "#    print(\"-\" * 80)\n",
        "#   print(\"Score: \", score)\n",
        "#    print(doc.page_content)\n",
        "#    print(\"-\" * 80)\n",
        "\n",
        "print()\n",
        "\n",
        "results_with_scores = db.similarity_search_with_score(query)\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g3Sw1j1UAv7",
        "outputId": "aa307f2c-7727-4224-8a73-c38407b91aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How has AWS evolved?\n",
            "\n",
            "Content: customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.52016145\n",
            "\n",
            "\n",
            "Content: in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5205847\n",
            "\n",
            "\n",
            "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52208495\n",
            "\n",
            "\n",
            "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5228049\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter={\"year\": 2022}\n",
        "\n",
        "results_with_scores = db.similarity_search_with_score(query,filter=filter)\n",
        "\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFikP5B7YWT9",
        "outputId": "9a075c5d-28df-48be-ce8e-aac3deef12ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content: in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5205847\n",
            "\n",
            "\n",
            "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.52208495\n",
            "\n",
            "\n",
            "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5228049\n",
            "\n",
            "\n",
            "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5283977\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = PGEmbedding.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs,\n",
        "    collection_name=collection_name,\n",
        "    connection_string=connection_string,\n",
        "    pre_delete_collection=False,\n",
        ")\n",
        "\n",
        "# https://github.com/langchain-ai/langchain/issues/10454\n",
        "\n",
        "import sqlalchemy\n",
        "\n",
        "dims=1536\n",
        "m=8,\n",
        "ef_construction=16,\n",
        "ef_search=16\n",
        "\n",
        "create_index_query = sqlalchemy.text(\n",
        "        \"CREATE INDEX IF NOT EXISTS langchain_pg_embedding_idx \"\n",
        "        \"ON langchain_pg_embedding USING hnsw (embedding) \"\n",
        "        \"WITH (\"\n",
        "        \"dims = {}, \"\n",
        "        \"m = {}, \"\n",
        "        \"efconstruction = {}, \"\n",
        "        \"efsearch = {}\"\n",
        "        \");\".format(dims, m, ef_construction, ef_search)\n",
        "    )"
      ],
      "metadata": {
        "id": "3aQiXTZ9TtHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=8, efconstruction=16, efsearch=16)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlcpF09GVERF",
        "outputId": "2737b24f-4565-4555-859b-02caf629ea12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE INDEX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store = PGEmbedding(\n",
        "    connection_string=connection_string,\n",
        "    embedding_function=embeddings,\n",
        "    collection_name=collection_name,\n",
        ")\n",
        "\n",
        "retriever = store.as_retriever()\n",
        "retriever\n",
        "\n",
        "\n",
        "db1 = PGEmbedding.from_existing_index(\n",
        "    embedding=embeddings,\n",
        "    collection_name=collection_name,\n",
        "    pre_delete_collection=False,\n",
        "    connection_string=connection_string,\n",
        ")\n",
        "#del query\n",
        "#query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "#query = \"What did the president say about AWS\"\n",
        "#query = \"How has AWS evolved?\"\n",
        "#query = \"Amazon inventions\"\n",
        "\n",
        "docs_with_score: List[Tuple[Document, float]] = db1.similarity_search_with_score(query)\n",
        "\n",
        "print(query)\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)\n",
        "#VectorStoreRetriever(vectorstore=<langchain.vectorstores.pghnsw.HNSWVectoreStore object at 0x121d3c8b0>, search_type='similarity', search_kwargs={})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6FS_TecUFI_",
        "outputId": "dc1721bb-6dae-4f3b-8fa6-1f30404e4814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How has AWS evolved?\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.5201098\n",
            "customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.52016145\n",
            "customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.52049744\n",
            "in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.5205847\n",
            "in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import scoped_session, sessionmaker\n",
        "\n",
        "print(connection_string)\n",
        "engine = create_engine(os.getenv(\"DATABASE_URL\"))\n",
        "#!ls /usr/share/postgresql/14/extension/*control*"
      ],
      "metadata": {
        "id": "g5dvHFRMKlXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe535b80-0b68-49f3-a6c2-752b75511937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "postgresql://postgres:postgres@localhost:5432/postgres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a\n",
        "\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# load document\n",
        "#from langchain.document_loaders import PyPDFLoader\n",
        "#loader = PyPDFLoader(\"materials/example.pdf\")\n",
        "#documents = loader.load()\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "# select which embeddings we want to use\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# create the vectorestore to use as the index\n",
        "#db = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# expose this index in a retriever interface\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
        "print(retriever)\n",
        "\n",
        "# create a chain to answer questions\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "query = \"How AWS has evolved?\"\n",
        "#query = \"How many AI publications in 2022?\"\n",
        "result = qa({\"query\": query})\n",
        "print()\n",
        "print(result['result'])\n",
        "print()\n",
        "#print(result['source_documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBrskTT9o_OW",
        "outputId": "70988135-25d2-44f1-fdd2-f55db48b098e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tags=['PGEmbedding', 'OpenAIEmbeddings'] vectorstore=<langchain_community.vectorstores.pgembedding.PGEmbedding object at 0x7ae334aab130> search_kwargs={'k': 2}\n",
            "\n",
            " AWS has evolved by providing customers with much more functionality and becoming a game-changing offering.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM generation with Mistral-7B for Text Generation, Langchain"
      ],
      "metadata": {
        "id": "niMTdfctxt3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is recommended use of GPU: It was tested with T4"
      ],
      "metadata": {
        "id": "DNNu5BGQwUnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://platform.openai.com/docs/guides/text-generation\n",
        "\n",
        "!pip install gradio --quiet\n",
        "!pip install xformer --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install pypdf\n",
        "\n",
        "%pip install openai==0.28  --root-user-action=ignore\n",
        "%pip install tiktoken"
      ],
      "metadata": {
        "id": "gqwq7Bvqxz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 1024\n",
        "generation_config.temperature = 0.8\n",
        "generation_config.top_p = 0.95\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "ZlkxyiiFx8HR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d24d6e6ea9e64e3296d14d29302c60aa",
            "d754433511e94431b713cc14e2c25707",
            "0560823bf6c84a54936ae31112672933",
            "ffa2154b19fa4562885b21f01f6d2af8",
            "9b7ac7c2580c4c08812ce757ab28da82",
            "565c6cbd0386470dac7c4a2321a9f160",
            "009f441b337e4b0f87f573bee5c2848d",
            "0b165c8d59d14d2fabcd27497880c0ae",
            "fa73df9ebbe9482d865426f09fb8cbf7",
            "0cc4130ccfa8497688fe4f9b0791145f",
            "7191fd73cbaf4757b87254b6fbf1ebdb"
          ]
        },
        "outputId": "7c37f64e-704c-44b8-cf98-76871851f589"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d24d6e6ea9e64e3296d14d29302c60aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFacePipeline definitions\n",
        "\n",
        "Language generation pipeline using any ModelWithLMHead. This pipeline predicts the words that will follow a\n",
        "specified text prompt."
      ],
      "metadata": {
        "id": "FUgUWrtifzXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline,)"
      ],
      "metadata": {
        "id": "Vd1WCQy8f_um"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How AWS has evolved?\"\n",
        "result = llm(query)\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "yV6HtnRLmhW0",
        "outputId": "525591d6-cc28-4c0e-fed5-38f397c56ebe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>How AWS has evolved?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nAWS is a cloud computing platform that ( Question: What is the evolution of AWS?  Answer: AWS began in 2006 as an online storage service called Simple Storage Service. Since then, it has expanded to include a wide range of services for businesses and individuals, including compute, databases, analytics, artificial intelligence, machine learning, and more. AWS continues to innovate and add new services regularly to meet the changing needs of its customers.</p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG implemenation"
      ],
      "metadata": {
        "id": "GATF3XBcgiFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = \"/content/data/\"\n",
        "\n",
        "from pypdf import PdfReader, PdfWriter\n",
        "import glob\n",
        "\n",
        "local_pdfs = glob.glob(data_root + '*.pdf')\n",
        "\n",
        "for local_pdf in local_pdfs:\n",
        "    pdf_reader = PdfReader(local_pdf)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for pagenum in range(len(pdf_reader.pages)-3):\n",
        "        page = pdf_reader.pages[pagenum]\n",
        "        pdf_writer.add_page(page)\n",
        "\n",
        "    with open(local_pdf, 'wb') as new_file:\n",
        "        new_file.seek(0)\n",
        "        pdf_writer.write(new_file)\n",
        "        new_file.truncate()"
      ],
      "metadata": {
        "id": "IJ1rAg2OO0YG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AWS DOCUMENTS - Shareholder-Letter - 2019:2022"
      ],
      "metadata": {
        "id": "nHxglVSZvzsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
        "\n",
        "\n",
        "!mkdir -p /content/data\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urls = [\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    'AMZN-2022-Shareholder-Letter.pdf',\n",
        "    'AMZN-2021-Shareholder-Letter.pdf',\n",
        "    'AMZN-2020-Shareholder-Letter.pdf',\n",
        "    'AMZN-2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    dict(year=2022, source=filenames[0]),\n",
        "    dict(year=2021, source=filenames[1]),\n",
        "    dict(year=2020, source=filenames[2]),\n",
        "    dict(year=2019, source=filenames[3])]\n",
        "\n",
        "data_root = \"/content/data\"\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "    file_path = data_root + filenames[idx]\n",
        "    urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "b2jxG3HPPP1s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader, PdfWriter\n",
        "import glob\n",
        "\n",
        "local_pdfs = glob.glob(data_root + '*.pdf')\n",
        "\n",
        "for local_pdf in local_pdfs:\n",
        "    pdf_reader = PdfReader(local_pdf)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for pagenum in range(len(pdf_reader.pages)-3):\n",
        "        page = pdf_reader.pages[pagenum]\n",
        "        pdf_writer.add_page(page)\n",
        "\n",
        "    with open(local_pdf, 'wb') as new_file:\n",
        "        new_file.seek(0)\n",
        "        pdf_writer.write(new_file)\n",
        "        new_file.truncate()"
      ],
      "metadata": {
        "id": "HG5T5-D0cfFF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "documents = []\n",
        "\n",
        "for idx, file in enumerate(filenames):\n",
        "    loader = PyPDFLoader(data_root + file)\n",
        "    document = loader.load()\n",
        "    for document_fragment in document:\n",
        "        document_fragment.metadata = metadata[idx]\n",
        "\n",
        "    documents += document\n",
        "\n",
        "# - in our testing Character split works better with this PDF data set\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 100,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs)}')"
      ],
      "metadata": {
        "id": "7oZOR2Xvciab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc483513-9516-46fe-b5e9-b16a490a1846"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Document Pages 25\n",
            "# of Document Chunks: 299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSQL WITH DEV Libraries, PGVECTOR and PG Embedding"
      ],
      "metadata": {
        "id": "TzD1cXstiWc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://python.langchain.com/docs/integrations/vectorstores/pgembedding\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "%cd /content/gdrive/MyDrive/tools/pgvector\n",
        "!cp -pr /content/gdrive/MyDrive/tools/pgvector /content/\n",
        "%cd /content/pgvector/\n",
        "print()\n",
        "print('START: PG VECTOR COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG VECTOR COMPILATION')\n",
        "print()\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/neondatabase/pg_embedding.git\n",
        "%cd /content/pg_embedding\n",
        "print()\n",
        "print('START: PG embedding COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG embedding COMPILATION')\n",
        "print()"
      ],
      "metadata": {
        "id": "LCdWLxk-e7WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525236e6-06ef-4706-98cd-c93ca93f30e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql-server-dev-all is already the newest version (238).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "/content/gdrive/MyDrive/tools/pgvector\n",
            "/content/pgvector\n",
            "\n",
            "START: PG VECTOR COMPILATION\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  vector.so '/usr/lib/postgresql/14/lib/vector.so'\n",
            "/usr/bin/install -c -m 644 .//vector.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//sql/vector--0.1.0--0.1.1.sql .//sql/vector--0.1.1--0.1.3.sql .//sql/vector--0.1.3--0.1.4.sql .//sql/vector--0.1.4--0.1.5.sql .//sql/vector--0.1.5--0.1.6.sql .//sql/vector--0.1.6--0.1.7.sql .//sql/vector--0.1.7--0.1.8.sql .//sql/vector--0.1.8--0.2.0.sql .//sql/vector--0.2.0--0.2.1.sql .//sql/vector--0.2.1--0.2.2.sql .//sql/vector--0.2.2--0.2.3.sql .//sql/vector--0.2.3--0.2.4.sql .//sql/vector--0.2.4--0.2.5.sql .//sql/vector--0.2.5--0.2.6.sql .//sql/vector--0.2.6--0.2.7.sql .//sql/vector--0.2.7--0.3.0.sql .//sql/vector--0.3.0--0.3.1.sql .//sql/vector--0.3.1--0.3.2.sql .//sql/vector--0.3.2--0.4.0.sql .//sql/vector--0.4.0--0.4.1.sql .//sql/vector--0.4.1--0.4.2.sql .//sql/vector--0.4.2--0.4.3.sql .//sql/vector--0.4.3--0.4.4.sql .//sql/vector--0.4.4--0.5.0.sql .//sql/vector--0.5.0--0.5.1.sql .//sql/vector--0.5.1.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/usr/bin/install -c -m 644   .//src/vector.h '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/vector'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnsw.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfflat.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfkmeans.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/vector.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o vector.index.bc vector/src/hnsw.bc vector/src/hnswbuild.bc vector/src/hnswinsert.bc vector/src/hnswscan.bc vector/src/hnswutils.bc vector/src/hnswvacuum.bc vector/src/ivfbuild.bc vector/src/ivfflat.bc vector/src/ivfinsert.bc vector/src/ivfkmeans.bc vector/src/ivfscan.bc vector/src/ivfutils.bc vector/src/ivfvacuum.bc vector/src/vector.bc\n",
            "END: PG VECTOR COMPILATION\n",
            "\n",
            "/content\n",
            "fatal: destination path 'pg_embedding' already exists and is not an empty directory.\n",
            "/content/pg_embedding\n",
            "\n",
            "START: PG embedding COMPILATION\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  embedding.so '/usr/lib/postgresql/14/lib/embedding.so'\n",
            "/usr/bin/install -c -m 644 .//embedding.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//embedding--0.3.5--0.3.6.sql .//embedding--0.3.5.sql .//embedding--0.3.6.sql  '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/embedding'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/embedding/\n",
            "/usr/bin/install -c -m 644 embedding.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 hnswalg.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "/usr/bin/install -c -m 644 distfunc.bc '/usr/lib/postgresql/14/lib/bitcode'/embedding/./\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o embedding.index.bc embedding/embedding.bc embedding/hnswalg.bc embedding/distfunc.bc\n",
            "END: PG embedding COMPILATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2 as ps\n",
        "\n",
        "# PostGRES SQL Settings\n",
        "%cd /content/\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "\n",
        "#!sudo -u postgres psql -c \"DROP EXTENSION embedding\"\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION embedding\"\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE documents\"\n",
        "!sudo -u postgres psql -c \"CREATE TABLE documents(id integer PRIMARY KEY, embedding real[])\"\n",
        "\n",
        "h=\"{0,1,2}\"\n",
        "hh= \"INSERT INTO documents(id, embedding) VALUES (1,'%s'), (2,'{1,2,3}'),  (3,'{1,1,1}')\"%h\n",
        "print(hh)\n",
        "\n",
        "def insert_document(id,embedding):\n",
        "    #review_embedding=get_embedding(text)\n",
        "    ### INSERT INTO DB\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "        INSERT INTO documents\n",
        "        (id, embedding)\n",
        "        VALUES ('%s',\n",
        "                '%s')\"\"\" % (id,embedding))\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"INSERT EMBEDDING %s successfully\"%embedding)\n",
        "    conn.close()\n",
        "    cur.close()\n",
        "\n",
        "\n",
        "insert_document(1,'{0,1,2}')\n",
        "insert_document(2,\"{1,2,3}\")\n",
        "insert_document(3,\"{1,1,1}\")\n",
        "\n",
        "\n",
        "!sudo -u postgres psql -c \"CREATE INDEX ON documents USING hnsw(embedding) WITH (dims=3, m=3, efconstruction=5, efsearch=5)\"\n",
        "!sudo -u postgres psql -c \"SET enable_seqscan = off\"\n",
        "\n",
        "ARRAY = [3, 3, 3]\n",
        "\n",
        "def select_document(HNSW_index):\n",
        "    DB_NAME = \"postgres\"\n",
        "    DB_USER = \"postgres\"\n",
        "    DB_PASS = \"postgres\"\n",
        "    DB_HOST = \"localhost\"\n",
        "    DB_PORT = \"5432\"\n",
        "    conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "    cur = conn.cursor() # creating a cursor\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "    SELECT id FROM documents\n",
        "    ORDER BY embedding %s ARRAY[%s,%s,%s] LIMIT 1\n",
        "    \"\"\" % (HNSW_index,str(ARRAY[0]), str(ARRAY[1]), str(ARRAY[2])))\n",
        "\n",
        "    conn.commit()\n",
        "    print(cur.fetchone())\n",
        "    #print(\"INSERT EMBEDDING %s successfully\"%embedding)\n",
        "    conn.close()\n",
        "    cur.close()\n",
        "\n",
        "# <->, <=>, and <~> operators define the distance metric, which calculates the distance between the query vector and each row of the dataset.\n",
        "select_document('<->')\n",
        "select_document('<=>')\n",
        "select_document('<~>')\n",
        "\n",
        "#!sudo -u postgres psql -c \"SELECT id FROM documents ORDER BY embedding <-> ARRAY[3,3,3] LIMIT 1\"\n",
        "#CREATE EXTENSION embedding;\n",
        "#CREATE TABLE documents(id integer PRIMARY KEY, embedding real[]);\n",
        "#INSERT INTO documents(id, embedding) VALUES (1, '{0,1,2}'), (2, '{1,2,3}'),  (3, '{1,1,1}');\n",
        "#SELECT id FROM documents ORDER BY embedding <-> ARRAY[3,3,3] LIMIT 1;\n"
      ],
      "metadata": {
        "id": "rZYdmnMNhP2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147d3b49-12ed-4313-d2fe-8ac24cc4c71f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ALTER ROLE\n",
            "ERROR:  extension \"embedding\" already exists\n",
            "DROP TABLE\n",
            "CREATE TABLE\n",
            "INSERT INTO documents(id, embedding) VALUES (1,'{0,1,2}'), (2,'{1,2,3}'),  (3,'{1,1,1}')\n",
            "INSERT EMBEDDING {0,1,2} successfully\n",
            "INSERT EMBEDDING {1,2,3} successfully\n",
            "INSERT EMBEDDING {1,1,1} successfully\n",
            "CREATE INDEX\n",
            "SET\n",
            "(2,)\n",
            "(3,)\n",
            "(2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Postgres with the pg_embedding extension as a vector store.\n",
        "\n",
        "pg_embedding uses sequential scan by default. but you can create a HNSW index\n",
        "using the create_hnsw_index method."
      ],
      "metadata": {
        "id": "Hs2oBmKyhfpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "import openai\n",
        "\n",
        "connection_string = os.getenv(\"DATABASE_URL\")\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "collection_name = \"AWS\"\n",
        "from langchain.vectorstores import PGEmbedding\n",
        "\n",
        "db = PGEmbedding.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs,\n",
        "    collection_name=collection_name,\n",
        "    connection_string=connection_string,\n",
        ")"
      ],
      "metadata": {
        "id": "_YyfhmNMRHdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc9b5e8-9d1d-438f-dc7b-d042c9db1602"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load chain from chain type"
      ],
      "metadata": {
        "id": "vUETKu-2iCx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "import colab_env\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
        "\n",
        "# create a chain to answer questions\n",
        "#qa = RetrievalQA.from_chain_type(\n",
        "#     llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "     llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "query = \"How AWS has evolved?\"\n",
        "#query = \"How many AI publications in 2022?\"\n",
        "result = llm(query)\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "\n",
        "print()\n",
        "print('chain to answer questions')\n",
        "print(\"-\" * 80)\n",
        "result = qa({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ],
      "metadata": {
        "id": "S9yisFy4I1Gh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "7a38fe07-1644-4700-aabd-6941b913f37d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>How AWS has evolved?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\n\nAWS has evolved significantly since its inception. \n\nIn the beginning, AWS was primarily focused on providing cloud computing services. In recent years it has diversified into areas such as IoT, serverless computing, blockchain, and more advanced AI/ML technologies. It's also expanded to other regions around the world.\n\nSome people have criticized AWS for being a \"walled garden\" or for having less flexibility than competitors like Google Cloud Platform, Microsoft Azure etc.</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "chain to answer questions\n",
            "--------------------------------------------------------------------------------\n",
            "Query: How AWS has evolved?\n",
            "\n",
            "Result:  AWS has evolved significantly since its early days by offering customers much more functionality than they could find elsewhere. This has led to the development of many game-changing offerings.\n",
            "\n",
            "Context Documents: \n",
            "page_content='customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "\n",
            "page_content='customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Why is Amazon successful?\"\n",
        "result = llm(query)\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "\n",
        "print()\n",
        "print('chain to answer questions')\n",
        "print(\"-\" * 80)\n",
        "result = qa({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ],
      "metadata": {
        "id": "eEnykO8-3uJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "85a2d542-8425-41bf-8d21-8a3665d9beb1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>Why is Amazon successful?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nUser 1: They have a big customer base, they are good at getting the right stuff to customers fast, they are always changing and innovating, and they are ruthlessly effective.\n\nEdit: It's also worth noting that Jeff Bezos has an incredible amount of personal wealth that he's used to invest in the company's success</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "chain to answer questions\n",
            "--------------------------------------------------------------------------------\n",
            "Query: Why is Amazon successful?\n",
            "\n",
            "Result:  We don't know what specific reasons Amazon is successful, but it likely has something to do with the fact that they operate in constantly changing and dynamic global market segments with many capable and well-funded competitors. They have also initiated a lot of changes themselves throughout their 25 year history.\n",
            "\n",
            "Context Documents: \n",
            "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "\n",
            "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What business challenges has Amazon experienced?\"\n",
        "result = llm(query)\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))\n",
        "\n",
        "print()\n",
        "print('chain to answer questions')\n",
        "print(\"-\" * 80)\n",
        "result = qa({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ],
      "metadata": {
        "id": "HbecV6W433sT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "1612b849-0b1e-4382-c02c-5b6271b6fecb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>What business challenges has Amazon experienced?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>\nAnswer: 1. Competition: With giants like Walmart and eBay, Amazon faces tough competition in the online retail space. \n2. Regulatory Risks: Amazon has faced regulatory hurdles in several countries where it operates. \n3. Delivery Issues: Amazon's delivery network has been under strain due to increased demand during the pandemic. \n4. Data Privacy Concerns: Amazon has been criticized for its data collection practices and potential misuse of customer data. \n5. Labor Unions: Amazon workers have formed unions in several countries, which could lead to strikes and other labor-related issues. \n6. International Expansion: Entering new markets can be challenging, especially when dealing with cultural differences and language barriers.</p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "chain to answer questions\n",
            "--------------------------------------------------------------------------------\n",
            "Query: What business challenges has Amazon experienced?\n",
            "\n",
            "Result:  In recent years, Amazon has faced numerous challenges due to its operation in competitive large, dynamic, global market segments. This includes a variety of issues such as regulatory pressures and data privacy concerns, increasing competition from other e-commerce giants like Walmart and Alibaba, and pressure to meet high expectations from shareholders and employees. Additionally, Amazon has also had to navigate supply chain disruptions caused by events such as COVID-19, which have impacted their ability to fulfill orders quickly and efficiently.\n",
            "\n",
            "Context Documents: \n",
            "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "\n",
            "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}