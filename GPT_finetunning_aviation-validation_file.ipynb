{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOd86ju9VF9wb0RMC4SsSQ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/GPT_finetunning_aviation-validation_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/guides/fine-tuning"
      ],
      "metadata": {
        "id": "ce4Q1F9t4yHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --upgrade -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "_Mm88LekcV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2HaecP4cc1c",
        "outputId": "3f16fe37-05ab-4766-e166-8935e14662c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "qnEgsBT8clV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modellist.data[33]"
      ],
      "metadata": {
        "id": "d75PBCxfeKTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(34,len(modellist.data)):\n",
        "  print(modellist.data[i].id)\n",
        "  client.models.delete(modellist.data[i].id)"
      ],
      "metadata": {
        "id": "S7qF8P-GORWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "Fqr8pavEek48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(modellist.data) #34 Official by OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KalpvRhnX0zh",
        "outputId": "6fb3dafc-0bc8-4ced-f538-20a2e6b11f3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning is currently available for the following models: gpt-3.5-turbo-0125 (recommended), gpt-3.5-turbo-1106, gpt-3.5-turbo-0613, babbage-002, davinci-002, and gpt-4-0613 (experimental)."
      ],
      "metadata": {
        "id": "YpL9lrT-IO7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KPndkkhmcFku"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0125\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Summarize content you are provided with for a second-grade student.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.7,\n",
        "  max_tokens=64,\n",
        "  top_p=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75HjH2FQcyKH",
        "outputId": "c25e6d41-41bb-40d7-adc5-facc77327987"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jupiter is a big planet in our Solar System that is made mostly of gas. It is the fifth planet from the Sun and the largest planet in our Solar System. It is very bright and can be seen in the night sky without a telescope. People have known about Jupiter for a long time, and it is named\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get SQuAD v2\n",
        "#!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "#!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "metadata": {
        "id": "xQK7fvZyhs2P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/frank-morales2020/Cloud_curious/blob/master/mistral_finetunning_squad2_0.ipynb"
      ],
      "metadata": {
        "id": "kR26acduJedk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVIATION-QA"
      ],
      "metadata": {
        "id": "j-eH5rMBZGXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def get_data(path):\n",
        "    #read each file and retrieve the contexts, qustions and answers\n",
        "    data = []\n",
        "    with open(path, 'r') as f:  # Open in text mode for JSON Lines\n",
        "        for line in f:\n",
        "            try:\n",
        "                data.append(json.loads(line))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding line: {line}\")\n",
        "                print(e)\n",
        "    return data  # Return the list of parsed JSON objects"
      ],
      "metadata": {
        "id": "OnJnzpZmZ5SP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the training file FOR SQuAD v2 1000 QUESTIONS\n",
        "#filename_path='/content/gdrive/MyDrive/datasets/dataft-L1000.jsonl'\n",
        "\n",
        "# aviation TRAIN QUESTION\n",
        "filename_path='/content/gdrive/MyDrive/datasets/aviation.jsonl'\n",
        "data=get_data(filename_path)\n",
        "#data[10]\n",
        "\n",
        "# aviation TEST QUESTION\n",
        "test_filename_path='/content/gdrive/MyDrive/datasets/test_aviation.jsonl'\n",
        "data_test=get_data(test_filename_path)"
      ],
      "metadata": {
        "id": "KyUAqEmRU74O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numberofquestions=len(data)\n",
        "numberofquestions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLG6Or6WarkB",
        "outputId": "a8e2f9a3-37d8-4f23-da53-cc5b5a40321f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "423194"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberofquestions_test=len(data_test)\n",
        "numberofquestions_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SVgLFmnfJ4Y",
        "outputId": "d9e20850-7641-4d89-8d0c-431363ae831e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10807"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nrec=8\n",
        "nrec=2\n",
        "data[nrec]['messages'][0]['content']\n",
        "\n",
        "question=data[nrec]['messages'][1]['content']\n",
        "answer=data[nrec]['messages'][2]['content']\n",
        "\n",
        "print('Record #: %s'%nrec)\n",
        "print('Question: %s'%question)\n",
        "print('Answer by the dataset: %s'%answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4USzjbnYL0Z",
        "outputId": "6e6c7aa3-25b8-4d7a-dba3-2ccc2f8f8f70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record #: 2\n",
            "Question: Who determines the probable cause(s) of this accident no. ERA22LA104?\n",
            "Answer by the dataset: The National Transportation Safety Board\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=2\n",
        "data_test[nrec]['messages'][0]['content']\n",
        "\n",
        "question=data_test[nrec]['messages'][1]['content']\n",
        "answer=data_test[nrec]['messages'][2]['content']\n",
        "\n",
        "print('Record #: %s'%nrec)\n",
        "print('Question: %s'%question)\n",
        "print('Answer by the dataset: %s'%answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCsmmmb4fllz",
        "outputId": "3694a61f-8a66-4a6a-f633-b5742c17c0ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record #: 2\n",
            "Question: What was the flight conducted under for the accident no. GAA18CA423?\n",
            "Answer by the dataset: Part 91: General aviation - Personal\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Upload the training file\n",
        "train_file_response = client.files.create(\n",
        "  file=open(filename_path, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "\n",
        "# Upload the training file\n",
        "test_file_response = client.files.create(\n",
        "  file=open(test_filename_path, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "\n",
        "# Get the file ID\n",
        "tain_file_id = train_file_response.id\n",
        "test_file_id = test_file_response.id\n",
        "\n",
        "# Start the fine-tuning job using the file ID\n",
        "cftjc=client.fine_tuning.jobs.create(\n",
        "  training_file=tain_file_id,\n",
        "  validation_file=test_file_id,\n",
        "  model=\"gpt-3.5-turbo-0125\"\n",
        ")\n",
        "\n",
        "training_file=cftjc.training_file\n",
        "fine_tuning_job=cftjc.id"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sZIkN7bff3mH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List 10 fine-tuning jobs\n",
        "#client.fine_tuning.jobs.list(limit=10)\n",
        "\n",
        "# Retrieve the state of a fine-tune\n",
        "#client.fine_tuning.jobs.retrieve(fine_tuning_job)\n",
        "\n",
        "# Cancel a job\n",
        "#client.fine_tuning.jobs.cancel(\"ftjob-HHsRv4STcKEaAywwrYDjL4zI\")\n",
        "\n",
        "# List up to 10 events from a fine-tuning job\n",
        "#client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tuning_job, limit=10)\n",
        "\n",
        "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
        "#client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
      ],
      "metadata": {
        "id": "3itHCXzvgYly"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_job_id = fine_tuning_job  # Replace with a real ID\n",
        "fine_tuning_job_retrieve=client.fine_tuning.jobs.retrieve(actual_job_id)\n",
        "client.fine_tuning.jobs.retrieve(actual_job_id)"
      ],
      "metadata": {
        "id": "c76JNFEMx3ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3b42b3-6bfb-4d58-85ef-0e2ca5e5c92c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-HhTcgfWkSX74FDhHFpuKwYpf', created_at=1718919914, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-kw9OnWtmHIJ748Xe7oTALKxl', result_files=[], seed=868832324, status='validating_files', trained_tokens=None, training_file='file-asJM5gCGFXGliaEuWU1RUmah', validation_file='file-dmmQMmoJ7rMaESItRtVqLPAa', estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "organization_id=fine_tuning_job_retrieve.organization_id\n",
        "fine_tuned_model=fine_tuning_job_retrieve.fine_tuned_model\n",
        "print(fine_tuned_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-D18CIYyYWa",
        "outputId": "cd223203-24b6-4299-ab21-eddf561a39e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/finetune/"
      ],
      "metadata": {
        "id": "PE7rnwM1wGOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while fine_tuned_model == None:\n",
        "       fine_tuning_job_retrieve=client.fine_tuning.jobs.retrieve(actual_job_id)\n",
        "       organization_id=fine_tuning_job_retrieve.organization_id\n",
        "       fine_tuned_model=fine_tuning_job_retrieve.fine_tuned_model\n"
      ],
      "metadata": {
        "id": "Ak9za3hx9XSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Fine Tuned Model: %s'%fine_tuned_model)"
      ],
      "metadata": {
        "id": "JDRZoJRR964H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REC 4\n",
        "PROMPT: In the accident with no. DCA16CA009, is the aircraft damaged?\n",
        "ANSWER GENERATED: Yes, in the accident with no. DCA16CA009, the aircraft was damaged."
      ],
      "metadata": {
        "id": "TNTOUO7l46NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=fine_tuned_model,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "  ]\n",
        ")\n",
        "print('PROMPT: %s'%question)\n",
        "print('ANSWER GENERATED: %s'%completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "RccLamrTtuxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "vbqWfRQrvfuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modellist.data[33]"
      ],
      "metadata": {
        "id": "7Mm46HBIwfHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(34,len(modellist.data)):\n",
        "#  print(modellist.data[i].id)\n",
        "#  client.models.delete(modellist.data[i].id)"
      ],
      "metadata": {
        "id": "O1HIP8cXw0lC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}