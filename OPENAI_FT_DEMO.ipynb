{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "THcYzkV8mpkW"
      ],
      "authorship_tag": "ABX9TyMN+27NvUug2OpQkvv8tSC5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/OPENAI_FT_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekUy1b8udVGD"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install tiktoken -q\n",
        "!pip install colab-env -q\n",
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "ofHv31Dpd_sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHmitDaMd189",
        "outputId": "b0e7c634-d514-414b-af4f-6d70a5e1ff8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='o1-pro', created=1742251791, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'),\n",
              " Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'),\n",
              " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
              " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0314', created=1687882410, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'),\n",
              " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
              " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
              " Model(id='o1', created=1734375816, object='model', owned_by='system'),\n",
              " Model(id='computer-use-preview', created=1734655677, object='model', owned_by='system'),\n",
              " Model(id='computer-use-preview-2025-03-11', created=1741377021, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'),\n",
              " Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'),\n",
              " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
              " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'),\n",
              " Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'),\n",
              " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
              " Model(id='o1-preview', created=1725648897, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4.5-preview', created=1740623059, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-32k-0314', created=1687979321, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4.5-preview-2025-02-27', created=1740623304, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'),\n",
              " Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'),\n",
              " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
              " Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
              " Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
              " Model(id='o3-mini', created=1737146383, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'),\n",
              " Model(id='o1-mini', created=1725649008, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'),\n",
              " Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'),\n",
              " Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'),\n",
              " Model(id='ft:gpt-3.5-turbo-0125:xamrysoft::9cSMOUWb', created=1718952508, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ft:gpt-3.5-turbo-0125:xamrysoft::BFmGttyM', created=1743100177, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ft:gpt-3.5-turbo-0125:xamrysoft::BFmGnb0y:ckpt-step-72', created=1743100171, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ft:gpt-3.5-turbo-0125:xamrysoft::BFmGqG94:ckpt-step-84', created=1743100174, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"frankmorales2020/flight_plan_waypoints\")"
      ],
      "metadata": {
        "id": "S8ypqUxve0ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLShsSt2fZHT",
        "outputId": "2fdc484e-41c4-478c-8f03-ac76c4e14a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Calculate the waypoints from SIN to CUN. Departure: 2024-06-19, Aircraft: Airbus A320, Weather: Partly Cloudy',\n",
              " 'label': 7,\n",
              " 'distance': 4190.223965150766,\n",
              " 'distance_category': 'long',\n",
              " 'waypoints': [[25.0000001, -107.5000001],\n",
              "  [13.075850948259008, -87.47663616549106],\n",
              "  [19.819922201759134, -98.80146877121005],\n",
              "  [9.260386709076178, -81.06960216515675],\n",
              "  [10.868386703521901, -83.76980061837503],\n",
              "  [11.748790002704872, -85.24819840125659],\n",
              "  [13.307169797892762, -87.86507323149776],\n",
              "  [14.392416690114095, -89.68745009086217],\n",
              "  [5.1096596, -74.0995854]],\n",
              " 'waypoint_names': ['SIN',\n",
              "  'Choluteca',\n",
              "  'Santo Domingo Aztacameca',\n",
              "  'Veraguas',\n",
              "  'San Juan del Norte',\n",
              "  'Acoyapa',\n",
              "  'Pasaje La Cruz',\n",
              "  'El Pito',\n",
              "  'CUN']}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "import openai\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"frankmorales2020/flight_plan_waypoints\")\n",
        "\n",
        "# Convert to JSONL format with 'input', 'label', 'waypoints', and 'waypoint_names'\n",
        "training_data = []\n",
        "for row in dataset[\"train\"]:\n",
        "    data_point = {\n",
        "        \"prompt\": row[\"input\"],\n",
        "        \"completion\": row[\"label\"],\n",
        "        \"waypoints\": row[\"waypoints\"],\n",
        "        \"waypoint_names\": row[\"waypoint_names\"],\n",
        "    }\n",
        "    training_data.append(data_point)\n",
        "\n",
        "# Save the training data to a JSONL file\n",
        "with open(\"training_data.jsonl\", \"w\") as f:\n",
        "    for data_point in training_data:\n",
        "        f.write(json.dumps(data_point) + \"\\n\")\n",
        "\n",
        "print(\"Dataset converted to JSONL and saved to training_data.jsonl\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWcWaf_phtmw",
        "outputId": "ca5a187e-3103-4727-a435-e232052ec15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset converted to JSONL and saved to training_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "source": [
        "{\"prompt\": \"Calculate the waypoints from SIN to CUN. Departure: 2024-06-19, Aircraft: Airbus A320, Weather: Partly Cloudy\", \"completion\": 7, \"waypoints\": [[25.0000001, -107.5000001], [13.075850948259008, -87.47663616549106], [19.819922201759134, -98.80146877121005], [9.260386709076178, -81.06960216515675], [10.868386703521901, -83.76980061837503], [11.748790002704872, -85.24819840125659], [13.307169797892762, -87.86507323149776], [14.392416690114095, -89.68745009086217], [5.1096596, -74.0995854]], \"waypoint_names\": [\"SIN\", \"Choluteca\", \"Santo Domingo Aztacameca\", \"Veraguas\", \"San Juan del Norte\", \"Acoyapa\", \"Pasaje La Cruz\", \"El Pito\", \"CUN\"]}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "y0HwHNA1hzwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data split"
      ],
      "metadata": {
        "id": "THcYzkV8mpkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load and prepare the training data\n",
        "# ----------------------------------------\n",
        "with open(\"/content/training_data.jsonl\", \"r\") as f:\n",
        "    training_data = [json.loads(line) for line in f]\n",
        "\n",
        "# 2. Split data into training and evaluation sets\n",
        "# ----------------------------------------\n",
        "train_data, eval_data = train_test_split(training_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "g6_AuV3dneuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)\n",
        "len(eval_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwOG0nTpoWbu",
        "outputId": "97ad371c-bf6b-4222-d2ac-4bd2a813ba3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1r3iHQdPq3kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tuning"
      ],
      "metadata": {
        "id": "DUTDeuGbq5fy"
      }
    },
    {
      "source": [
        "!pip install openai -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install tiktoken -q\n",
        "!pip install colab-env -q\n",
        "!pip install datasets -q\n",
        "!pip install scikit-learn -q\n",
        "\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI()\n",
        "\n",
        "# 1. Load and prepare the training data with \"messages\" key\n",
        "# ---------------------------------------------------------\n",
        "with open(\"/content/training_data.jsonl\", \"r\") as f:\n",
        "    training_data = [json.loads(line) for line in f]\n",
        "\n",
        "# Restructure data to include \"messages\"\n",
        "formatted_training_data = []\n",
        "for data_point in training_data:\n",
        "    formatted_data_point = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI assistant that helps calculate flight plan waypoints.\"},\n",
        "            {\"role\": \"user\", \"content\": data_point[\"prompt\"]},\n",
        "            {\"role\": \"assistant\", \"content\": str(data_point[\"completion\"])}\n",
        "        ]\n",
        "    }\n",
        "    formatted_training_data.append(formatted_data_point)\n",
        "\n",
        "# 2. Split data into training and evaluation sets\n",
        "# ----------------------------------------\n",
        "train_data, eval_data = train_test_split(formatted_training_data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# 3. Create validation dataset\n",
        "#-------------------------------------------\n",
        "# Assuming 'eval_data' is your validation data\n",
        "validation_data_file = io.BytesIO()\n",
        "for data_point in eval_data:\n",
        "    validation_data_file.write((json.dumps(data_point) + \"\\n\").encode('utf-8'))\n",
        "validation_data_file.seek(0)\n",
        "\n",
        "validation_file_id = client.files.create(\n",
        "    file=validation_data_file, purpose=\"fine-tune\"\n",
        ").id\n",
        "\n",
        "\n",
        "# 4. Fine-tuning with Validation Set\n",
        "# ----------------------------------------\n",
        "# Create an in-memory file-like object for the training data\n",
        "training_data_file = io.BytesIO()\n",
        "for data_point in train_data:\n",
        "    training_data_file.write((json.dumps(data_point) + \"\\n\").encode('utf-8'))\n",
        "training_data_file.seek(0)  # Reset file pointer to the beginning\n",
        "\n",
        "# Upload the in-memory file to OpenAI\n",
        "file_id = client.files.create(\n",
        "    file=training_data_file, purpose=\"fine-tune\"\n",
        ").id\n",
        "\n",
        "# Define fine-tuning parameters, including validation_file\n",
        "fine_tuning_params = {\n",
        "    \"training_file\": file_id,\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"validation_file\": validation_file_id,  # Include validation file\n",
        "}\n",
        "\n",
        "# Create the fine-tuning job\n",
        "fine_tuning_job = client.fine_tuning.jobs.create(**fine_tuning_params)\n",
        "fine_tuning_job_id = fine_tuning_job.id\n",
        "\n",
        "print(f\"Fine-tuning job created with ID: {fine_tuning_job.id}\")\n",
        "\n",
        "# 5. Monitor fine-tuning job\n",
        "# -----------------------------\n",
        "while True:\n",
        "    fine_tuning_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
        "    status = fine_tuning_job.status\n",
        "    print(f\"Fine-tuning job status: {status}\")\n",
        "\n",
        "    if status == \"succeeded\":\n",
        "        print(\"Fine-tuning completed successfully!\")\n",
        "        fine_tuned_model_id = fine_tuning_job.fine_tuned_model\n",
        "        print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")\n",
        "        break\n",
        "    elif status in [\"failed\", \"cancelled\"]:\n",
        "        print(f\"Fine-tuning job {status}.\")\n",
        "        break\n",
        "    else:  # pending, running, etc.\n",
        "        time.sleep(60)  # Check every 60 seconds"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-LNGt8x9nDy",
        "outputId": "7f4913d3-408e-4722-b4fc-aefb926ad0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning job created with ID: ftjob-g9Ps0nEmhDUB1g8PBZfojptB\n",
            "Fine-tuning job status: validating_files\n",
            "Fine-tuning job status: validating_files\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job status: succeeded\n",
            "Fine-tuning completed successfully!\n",
            "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:xamrysoft::BFrv8bF5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "7Z4XAmynrA0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm -q\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lAapPzqh3gJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Evaluation\n",
        "# ----------------------------------------\n",
        "# Replace with your fine-tuned model ID\n",
        "# ftjob-ePiCspTiSe6K9sm7c0UE05qp\n",
        "fine_tuned_model_id = \"ft:gpt-3.5-turbo-0125:xamrysoft::BFqZ9l56\"\n",
        "\n",
        "predictions = []\n",
        "#for data_point in tqdm(eval_data, desc=\"Evaluating\", unit=\"data point\"):  # Add tqdm here\n",
        "for data_point in tqdm(eval_data, desc=\"Evaluating\", unit=\"data point\", miniters=1):  # Add miniters=1 here\n",
        "\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=fine_tuned_model_id,\n",
        "        messages=data_point[\"messages\"]\n",
        "    )\n",
        "\n",
        "    prediction = response.choices[0].message.content\n",
        "    print('\\n')\n",
        "    print(f\"Prediction: {prediction}\")\n",
        "    predictions.append(prediction)\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "for data_point, prediction in zip(eval_data, predictions):\n",
        "    # Assuming the last message in 'messages' is the ground truth\n",
        "    expected_output = str(data_point[\"messages\"][-1][\"content\"])\n",
        "    print(f\"Expected: {expected_output}\")\n",
        "\n",
        "    if prediction == expected_output:\n",
        "        print(f\"Prediction: {prediction}, Expected: {expected_output}\")\n",
        "        correct_predictions += 1\n",
        "    total_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eX6R2hpRnVNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}