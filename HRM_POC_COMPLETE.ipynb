{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "db3de1da"
      ],
      "history_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOqa4OqBIMnHzjo7IrPjqzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/HRM_POC_COMPLETE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/sapientinc/HRM\n",
        "\n",
        "\n",
        "https://github.com/Dao-AILab/flash-attention\n",
        "\n",
        "\n",
        "https://github.com/sapientinc/HRM/issues/12"
      ],
      "metadata": {
        "id": "BphziTlllzhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HRM"
      ],
      "metadata": {
        "id": "BkcjTkjSQ5JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8y7KTWKSzqJ",
        "outputId": "185ce379-78f4-4629-de50-8b6043a2c5d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug  5 21:38:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0             49W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sapientinc/HRM.git"
      ],
      "metadata": {
        "id": "RlDXI74QVxkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9298e7b1"
      },
      "source": [
        "!pip install torch adam-atan2 einops tqdm coolname pydantic argdantic wandb omegaconf hydra-core huggingface_hub -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y flash-attn\n",
        "!pip install --no-cache-dir flash-attn"
      ],
      "metadata": {
        "id": "bF3BXlg7bKpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flash-attn --no-build-isolation --quiet"
      ],
      "metadata": {
        "id": "LVWEeOnvcvWh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0516b30"
      },
      "source": [
        "!git clone https://github.com/Dao-AILab/flash-attention.git\n",
        "%cd flash-attention\n",
        "!python setup.py install --user\n",
        "!pip install einops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio flash-attn\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install flash-attn --no-cache-dir"
      ],
      "metadata": {
        "id": "4_VbBVujdb-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flash_attn\n",
        "print(flash_attn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSDIEnibOCU",
        "outputId": "40605625-7ef9-460b-91e6-ce56fafe45c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "645e7b60"
      },
      "source": [
        "!pip uninstall -y torch torchvision torchaudio adam-atan2\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install adam-atan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y adam-atan2\n",
        "!pip install adam-atan2 --no-cache-dir"
      ],
      "metadata": {
        "id": "683Er3kOinUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e46fda10",
        "outputId": "876ab5a8-0ce5-4372-e69e-3ecaf69f3334"
      },
      "source": [
        "!python /content/HRM/dataset/build_sudoku_dataset.py --output-dir /content/data/sudoku-extreme-100-aug-100 --subsample-size 100 --num-aug 100"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv: 100% 719M/719M [00:02<00:00, 271MB/s]\n",
            "100% 100/100 [00:01<00:00, 80.39it/s]\n",
            "test.csv: 100% 79.4M/79.4M [00:00<00:00, 232MB/s]\n",
            "100% 422786/422786 [00:00<00:00, 1813932.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc3f8132",
        "outputId": "508322aa-48d5-4c08-94fe-be6dab35ea7e"
      },
      "source": [
        "!ls -l /content/data/sudoku-extreme-100-aug-100"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "-rw-r--r-- 1 root root   11 Aug  5 03:23 identifiers.json\n",
            "drwxr-xr-x 2 root root 4096 Aug  5 03:23 test\n",
            "drwxr-xr-x 2 root root 4096 Aug  5 03:23 train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e79411ae"
      },
      "source": [
        "!OMP_NUM_THREADS=1 torchrun --nproc-per-node 1 --standalone /content/HRM/pretrain.py data_path=/content/data/sudoku-extreme-100-aug-100 epochs=5 eval_interval=1 global_batch_size=4 lr=7e-5 puzzle_emb_lr=7e-5 weight_decay=1.0 puzzle_emb_weight_decay=1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db3de1da"
      },
      "source": [
        "## Verify flash-attn installation\n",
        "\n",
        "### Subtask:\n",
        "Verify that `flash-attn` is correctly installed and accessible in the environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aadeb6ff"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to verify that `flash-attn` is installed correctly. I will import the library and print its version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cf0f301",
        "outputId": "f2f1cc08-9c43-4c33-b5a2-fbe4ce03d620"
      },
      "source": [
        "import flash_attn\n",
        "print(flash_attn.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ada4aa4b"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ImportError` indicates a problem with the `flash-attn` installation, specifically an undefined symbol in the compiled CUDA extension. This often happens due to a mismatch between the PyTorch and `flash-attn` versions or their CUDA dependencies. I will try to reinstall `flash-attn` with the `--no-cache-dir` option to ensure a clean build.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzCNf_nU9bMe"
      },
      "source": [
        "!pip uninstall -y flash-attn\n",
        "!pip install --no-cache-dir flash-attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1094831"
      },
      "source": [
        "**Reasoning**:\n",
        "The reinstallation did not solve the issue. The error message \"undefined symbol\" strongly suggests a C++ ABI compatibility issue between PyTorch and the compiled `flash-attn` extension. This can be caused by using different compiler versions or C++ standards. Since reinstalling `flash-attn` didn't work, I'll try reinstalling both `torch` and `flash-attn` together, which might ensure they are built with compatible compilers and libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f67e7b59"
      },
      "source": [
        "!pip uninstall -y torch torchvision torchaudio flash-attn\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install flash-attn --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcc1thxx-WNS",
        "outputId": "f758ada6-3449-469b-814c-ad0a0bef53bd"
      },
      "source": [
        "import flash_attn\n",
        "print(flash_attn.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wandb"
      ],
      "metadata": {
        "id": "Uenqt_QlckNi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fd73f1"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltha /content/wandb/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrghWi6jWnxy",
        "outputId": "86c6cc52-835f-4358-cf7e-6b9a1aac9f18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 1 root root 4.0K Aug  5 03:24 ..\n",
            "drwxr-xr-x 5 root root 4.0K Aug  5 03:24 run-20250805_032432-xqhcbpjl\n",
            "drwxr-xr-x 3 root root 4.0K Aug  5 03:24 .\n",
            "lrwxrwxrwx 1 root root   52 Aug  5 03:24 debug-internal.log -> run-20250805_032432-xqhcbpjl/logs/debug-internal.log\n",
            "lrwxrwxrwx 1 root root   43 Aug  5 03:24 debug.log -> run-20250805_032432-xqhcbpjl/logs/debug.log\n",
            "lrwxrwxrwx 1 root root   28 Aug  5 03:24 latest-run -> run-20250805_032432-xqhcbpjl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15d735f1",
        "outputId": "b520575e-d70c-4639-aa4d-7adf78ba477f"
      },
      "source": [
        "!ls -ltha /content/wandb/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 1 root root 4.0K Aug  5 03:24 ..\n",
            "drwxr-xr-x 5 root root 4.0K Aug  5 03:24 run-20250805_032432-xqhcbpjl\n",
            "drwxr-xr-x 3 root root 4.0K Aug  5 03:24 .\n",
            "lrwxrwxrwx 1 root root   52 Aug  5 03:24 debug-internal.log -> run-20250805_032432-xqhcbpjl/logs/debug-internal.log\n",
            "lrwxrwxrwx 1 root root   43 Aug  5 03:24 debug.log -> run-20250805_032432-xqhcbpjl/logs/debug.log\n",
            "lrwxrwxrwx 1 root root   28 Aug  5 03:24 latest-run -> run-20250805_032432-xqhcbpjl\n"
          ]
        }
      ]
    }
  ]
}