{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPVeXH8QV4e+vs2CrucAYEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MCP_DEMO_JUNE2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth -q"
      ],
      "metadata": {
        "id": "x2P4HyY4y4hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSwQ49LFyq69"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import datetime\n",
        "import uuid\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    from unsloth import FastLanguageModel\n",
        "    print(\"torch and FastLanguageModel (unsloth) imported successfully (conceptual).\")\n",
        "    # For actual execution, ensure unsloth and its dependencies are installed.\n",
        "except ImportError as e:\n",
        "    print(f\"Warning: Could not import necessary libraries for DeepSeek-R1 ({e}). DeepSeek-R1 usage will be conceptual.\")\n",
        "    torch = None # Set to None to avoid errors if not available\n",
        "    FastLanguageModel = None # Set to None if import failed\n",
        "\n",
        "# --- Global State (Simulated) ---\n",
        "# This variable simulates the authentication state.\n",
        "is_authenticated = False\n",
        "\n",
        "# --- Simulated AI Tool Logic ---\n",
        "# These functions simulate the responses of various AI tools and elicitation processes.\n",
        "\n",
        "def get_simulated_customer_insight_from_llm(customer_id):\n",
        "    \"\"\"\n",
        "    Simulates the structured output from an AI customer behavior analysis tool.\n",
        "    This version conceptually uses DeepSeek-R1 but provides a simulated response\n",
        "    due to environment limitations.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Conceptual DeepSeek-R1 LLM Call for Customer ID: {customer_id} ---\")\n",
        "\n",
        "    model = None\n",
        "    tokenizer = None\n",
        "\n",
        "    if torch and FastLanguageModel:\n",
        "        print(\"Attempting to load DeepSeek-R1 model and tokenizer (unsloth/DeepSeek-R1-Distill-Llama-8B)...\")\n",
        "        print(\"NOTE: This model loading is conceptual and will likely NOT fully execute in most web environments.\")\n",
        "        print(\"      A real setup requires sufficient hardware and all library installations.\")\n",
        "        max_seq_length = 4096 # Maximum sequence length for tokenization\n",
        "        dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
        "        load_in_4bit = True # Enable 4-bit quantization for significant memory savings\n",
        "\n",
        "        try:\n",
        "            model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "                model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\", # Model name specified for fine-tuning\n",
        "                max_seq_length=max_seq_length,\n",
        "                dtype=dtype,\n",
        "                load_in_4bit=load_in_4bit,\n",
        "            )\n",
        "            print(\"Model and tokenizer loaded (conceptually).\")\n",
        "            # If the model actually loaded, you would perform inference here:\n",
        "            # inputs = tokenizer(prompt_for_llm, return_tensors=\"pt\").to(\"cuda\") # Assuming CUDA\n",
        "            # outputs = model.generate(**inputs, max_new_tokens=500, do_sample=True, top_p=0.9, temperature=0.7)\n",
        "            # llm_generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            # print(\"Actual DeepSeek-R1 inference would occur here.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading DeepSeek-R1 model (as expected in this environment): {e}. Proceeding with simulated response.\")\n",
        "    else:\n",
        "        print(\"DeepSeek-R1 model loading skipped: Required libraries (PyTorch/Unsloth) not available or imported. Proceeding with simulated response.\")\n",
        "\n",
        "    prompt_for_llm = (\n",
        "        f\"Generate a customer insight report for customer ID {customer_id}. \"\n",
        "        \"Include their purchase frequency (high, medium, low), average order value, \"\n",
        "        \"a risk score (0 to 1), preferred product categories, and two actionable recommendations \"\n",
        "        \"with priority (urgent, high, medium, low) and expected impact. \"\n",
        "        \"Return this information in a JSON format matching the following schema:\\n\"\n",
        "        \"{\\n\"\n",
        "        \"  \\\"purchaseFrequency\\\": \\\"<string>\\\",\\n\"\n",
        "        \"  \\\"averageOrderValue\\\": <number>,\\n\"\n",
        "        \"  \\\"riskScore\\\": <number>,\\n\"\n",
        "        \"  \\\"preferredCategories\\\": [\\\"<string>\\\"],\\n\"\n",
        "        \"  \\\"recommendations\\\": [\\n\"\n",
        "        \"    {\\n\"\n",
        "        \"      \\\"action\\\": \\\"<string>\\\",\\n\"\n",
        "        \"      \\\"priority\\\": \\\"<string>\\\",\\n\"\n",
        "        \"      \\\"expectedImpact\\\": \\\"<string>\\\"\\n\"\n",
        "        \"    }\\n\"\n",
        "        \"  ]\\n\"\n",
        "        \"}\"\n",
        "    )\n",
        "\n",
        "    # --- Simulated LLM Response ---\n",
        "    # For this demo, we use a hardcoded JSON string to simulate the structured output\n",
        "    # that DeepSeek-R1 *would* generate if it were running live.\n",
        "    simulated_llm_generated_text = json.dumps({\n",
        "        \"purchaseFrequency\": \"high\",\n",
        "        \"averageOrderValue\": 150.25,\n",
        "        \"riskScore\": 0.12,\n",
        "        \"preferredCategories\": [\"clothing\", \"books\"],\n",
        "        \"recommendations\": [\n",
        "            {\"action\": \"Send personalized email with new arrivals\", \"priority\": \"high\", \"expectedImpact\": \"Increase repeat purchases by 10%\"},\n",
        "            {\"action\": \"Offer premium membership trial\", \"priority\": \"medium\", \"expectedImpact\": \"Enhance customer loyalty\"}\n",
        "        ]\n",
        "    })\n",
        "    print(\"Simulating DeepSeek-R1 response with hardcoded JSON due to environment limitations.\")\n",
        "\n",
        "    try:\n",
        "        llm_data = json.loads(simulated_llm_generated_text) # Parse the JSON string\n",
        "\n",
        "        return {\n",
        "            \"toolName\": \"analyze_customer_behavior\",\n",
        "            \"structuredOutput\": {\n",
        "                \"type\": \"customer_insight\",\n",
        "                \"data\": {\n",
        "                    \"customerId\": customer_id,\n",
        "                    \"purchaseFrequency\": llm_data.get(\"purchaseFrequency\"),\n",
        "                    \"averageOrderValue\": llm_data.get(\"averageOrderValue\"),\n",
        "                    \"riskScore\": llm_data.get(\"riskScore\"),\n",
        "                    \"preferredCategories\": llm_data.get(\"preferredCategories\"),\n",
        "                    \"recommendations\": llm_data.get(\"recommendations\"),\n",
        "                },\n",
        "                \"metadata\": {\n",
        "                    \"analysisDate\": datetime.datetime.now().isoformat(),\n",
        "                    \"dataPoints\": 5000, # Simulated\n",
        "                    \"confidence\": 0.98, # Simulated\n",
        "                    \"generatedByLLM\": True,\n",
        "                    \"llmModel\": \"DeepSeek-R1-Distill-Llama-8B (Simulated)\"\n",
        "                },\n",
        "            }\n",
        "        }, 200 # Simulate success\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\"error\": f\"Failed to parse simulated LLM response: {e}\"}, 500\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"An unexpected error occurred during simulation: {e}\"}, 500\n",
        "\n",
        "\n",
        "def create_simulated_onboarding_plan(onboarding_data):\n",
        "    \"\"\"\n",
        "    Simulates the creation of a customized onboarding plan based on collected data.\n",
        "    \"\"\"\n",
        "    plan_id = f\"plan_{onboarding_data.get('companyName', 'unknown').replace(' ', '_').lower()}_{str(uuid.uuid4())[:8]}\"\n",
        "    return {\n",
        "        \"id\": plan_id,\n",
        "        \"companyName\": onboarding_data.get('companyName'),\n",
        "        \"industry\": onboarding_data.get('industry'),\n",
        "        \"steps\": [\"Initial Setup\", \"Configuration\", \"Finalization\"],\n",
        "        \"timeline\": \"2-4 weeks\",\n",
        "        **onboarding_data, # Include all collected data in the plan\n",
        "    }\n",
        "\n",
        "# --- Core Logic Functions ---\n",
        "\n",
        "def toggle_authentication():\n",
        "    \"\"\"\n",
        "    Function to toggle authentication status.\n",
        "    Returns a dictionary with the new authentication status.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    is_authenticated = not is_authenticated\n",
        "    status_message = \"authenticated\" if is_authenticated else \"unauthenticated\"\n",
        "    return {\"isAuthenticated\": is_authenticated, \"status\": f\"User is now {status_message}.\"}\n",
        "\n",
        "def get_customer_insight_tool():\n",
        "    \"\"\"\n",
        "    Function to get customer behavior analysis and return structured output.\n",
        "    Now conceptually uses DeepSeek-R1 for the insight.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401 # Simulate HTTP 401\n",
        "\n",
        "    # Use a dummy customer ID for the demo, or generate a new one\n",
        "    customer_id = \"DEMO-CUST-\" + str(uuid.uuid4())[:4]\n",
        "    insight, status_code = get_simulated_customer_insight_from_llm(customer_id)\n",
        "    return insight, status_code # Return what the LLM call returns\n",
        "\n",
        "def handle_sensitive_report_elicitation(consent_given, access_reason):\n",
        "    \"\"\"\n",
        "    Function to simulate elicitation for sensitive report access.\n",
        "    Expects 'consent_given' (boolean) and 'access_reason' (string) as arguments.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401\n",
        "\n",
        "    if consent_given and access_reason and access_reason.strip():\n",
        "        # Simulate logging access for compliance (Resource Linking concept)\n",
        "        audit_id = str(uuid.uuid4())\n",
        "        print(f\"Sensitive Data Access Logged: CustomerID=CUST-123, Reason='{access_reason}', AuditID={audit_id}\")\n",
        "        return {\n",
        "            \"status\": \"Sensitive report generated successfully! (Simulated)\",\n",
        "            \"resourceLink\": f\"mcp://security/audit/{audit_id}\",\n",
        "            \"message\": \"Access granted. Check the console for simulated audit log.\"\n",
        "        }, 200\n",
        "    else:\n",
        "        return {\n",
        "            \"error\": \"Elicitation failed\",\n",
        "            \"message\": \"Consent and a business justification are required to access sensitive data.\"\n",
        "        }, 400\n",
        "\n",
        "def handle_create_onboarding_plan(onboarding_data):\n",
        "    \"\"\"\n",
        "    Function to simulate creation of an onboarding plan based on user data.\n",
        "    This simulates the final step of the multi-step elicitation for onboarding.\n",
        "    Expects onboarding_data (e.g., companyName, industry, employeeCount) as an argument.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401\n",
        "\n",
        "    if not onboarding_data:\n",
        "        return {\"error\": \"No onboarding data provided\"}, 400\n",
        "\n",
        "    plan = create_simulated_onboarding_plan(onboarding_data)\n",
        "    # Simulate resource link for onboarding checklist\n",
        "    checklist_id = str(uuid.uuid4())\n",
        "    plan[\"resourceLink\"] = f\"mcp://onboarding/checklist/{checklist_id}\"\n",
        "\n",
        "    return {\n",
        "        \"status\": \"Customized onboarding plan created successfully!\",\n",
        "        \"plan\": plan,\n",
        "        \"message\": \"Plan generated. Check the 'plan' field for details.\"\n",
        "    }, 200\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Main execution block to demonstrate usage ---\n",
        "if __name__ == '__main__':\n",
        "    print('\\n')\n",
        "    print(\"--- MCP 2025-06-18 Pure Python Backend Demo with DeepSeek-R1 Conceptual Integration ---\")\n",
        "    print(\"\\n--- Initial State ---\")\n",
        "    auth_status = toggle_authentication() # Toggles to True (authenticated) initially\n",
        "    print(auth_status)\n",
        "    print(\"\\n--- End of Initial State ---\")\n",
        "\n",
        "    print(\"\\n--- Attempting to get customer insight (should succeed with LLM-generated data) ---\")\n",
        "    insight, status_code = get_customer_insight_tool()\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(insight, indent=2))\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "    print(\"\\n--- Simulating sensitive report elicitation (successful) ---\")\n",
        "    elicitation_result, status_code = handle_sensitive_report_elicitation(\n",
        "        consent_given=True,\n",
        "        access_reason=\"Annual compliance audit requirement.\"\n",
        "    )\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(elicitation_result, indent=2))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"\\n--- Simulating sensitive report elicitation (failed - no consent) ---\")\n",
        "    elicitation_result, status_code = handle_sensitive_report_elicitation(\n",
        "        consent_given=False,\n",
        "        access_reason=\"Investigation of security incident.\"\n",
        "    )\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(elicitation_result, indent=2))\n",
        "\n",
        "    print(\"\\n--- Simulating onboarding plan creation ---\")\n",
        "    onboarding_data_example = {\n",
        "        \"companyName\": \"ExampleCorp\",\n",
        "        \"industry\": \"finance\",\n",
        "        \"employeeCount\": \"51-200\",\n",
        "        \"preferredContactMethod\": \"slack\",\n",
        "        \"regulatoryFramework\": \"SOX\",\n",
        "        \"transactionVolume\": \"high\"\n",
        "    }\n",
        "    onboarding_result, status_code = handle_create_onboarding_plan(onboarding_data_example)\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(onboarding_result, indent=2))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"\\n--- Toggling authentication off ---\")\n",
        "    auth_status = toggle_authentication()\n",
        "    print(auth_status)\n",
        "\n",
        "    print(\"\\n--- Attempting to get customer insight (should fail due to authentication) ---\")\n",
        "    insight, status_code = get_customer_insight_tool()\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(insight, indent=2))\n",
        "\n",
        "    print(\"\\n--- End of Demo ---\")"
      ],
      "metadata": {
        "id": "UYcIddIR0xp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime\n",
        "import uuid\n",
        "\n",
        "# --- Global State (Simulated) ---\n",
        "# This variable simulates the authentication state.\n",
        "is_authenticated = False\n",
        "\n",
        "# --- Simulated AI Tool Logic ---\n",
        "# These functions simulate the responses of various AI tools and elicitation processes.\n",
        "\n",
        "def get_simulated_customer_insight_from_llm(customer_id):\n",
        "    \"\"\"\n",
        "    Simulates the structured output from an AI customer behavior analysis tool.\n",
        "    This version provides a simulated response for DeepSeek-R1.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Simulated DeepSeek-R1 LLM Call for Customer ID: {customer_id} ---\")\n",
        "    print(\"Simulating DeepSeek-R1 response with hardcoded JSON.\")\n",
        "\n",
        "    # --- Simulated LLM Response ---\n",
        "    # This hardcoded JSON string simulates the structured output\n",
        "    # that DeepSeek-R1 *would* generate if it were running live.\n",
        "    simulated_llm_generated_text = json.dumps({\n",
        "        \"purchaseFrequency\": \"high\",\n",
        "        \"averageOrderValue\": 150.25,\n",
        "        \"riskScore\": 0.12,\n",
        "        \"preferredCategories\": [\"clothing\", \"books\"],\n",
        "        \"recommendations\": [\n",
        "            {\"action\": \"Send personalized email with new arrivals\", \"priority\": \"high\", \"expectedImpact\": \"Increase repeat purchases by 10%\"},\n",
        "            {\"action\": \"Offer premium membership trial\", \"priority\": \"medium\", \"expectedImpact\": \"Enhance customer loyalty\"}\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        llm_data = json.loads(simulated_llm_generated_text) # Parse the JSON string\n",
        "\n",
        "        return {\n",
        "            \"toolName\": \"analyze_customer_behavior\",\n",
        "            \"structuredOutput\": {\n",
        "                \"type\": \"customer_insight\",\n",
        "                \"data\": {\n",
        "                    \"customerId\": customer_id,\n",
        "                    \"purchaseFrequency\": llm_data.get(\"purchaseFrequency\"),\n",
        "                    \"averageOrderValue\": llm_data.get(\"averageOrderValue\"),\n",
        "                    \"riskScore\": llm_data.get(\"riskScore\"),\n",
        "                    \"preferredCategories\": llm_data.get(\"preferredCategories\"),\n",
        "                    \"recommendations\": llm_data.get(\"recommendations\"),\n",
        "                },\n",
        "                \"metadata\": {\n",
        "                    \"analysisDate\": datetime.datetime.now().isoformat(),\n",
        "                    \"dataPoints\": 5000, # Simulated\n",
        "                    \"confidence\": 0.98, # Simulated\n",
        "                    \"generatedByLLM\": True,\n",
        "                    \"llmModel\": \"DeepSeek-R1-Distill-Llama-8B (Simulated)\"\n",
        "                },\n",
        "            }\n",
        "        }, 200 # Simulate success\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\"error\": f\"Failed to parse simulated LLM response: {e}\"}, 500\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"An unexpected error occurred during simulation: {e}\"}, 500\n",
        "\n",
        "\n",
        "def create_simulated_onboarding_plan(onboarding_data):\n",
        "    \"\"\"\n",
        "    Simulates the creation of a customized onboarding plan based on collected data.\n",
        "    \"\"\"\n",
        "    plan_id = f\"plan_{onboarding_data.get('companyName', 'unknown').replace(' ', '_').lower()}_{str(uuid.uuid4())[:8]}\"\n",
        "    return {\n",
        "        \"id\": plan_id,\n",
        "        \"companyName\": onboarding_data.get('companyName'),\n",
        "        \"industry\": onboarding_data.get('industry'),\n",
        "        \"steps\": [\"Initial Setup\", \"Configuration\", \"Finalization\"],\n",
        "        \"timeline\": \"2-4 weeks\",\n",
        "        **onboarding_data, # Include all collected data in the plan\n",
        "    }\n",
        "\n",
        "# --- Core Logic Functions ---\n",
        "\n",
        "def toggle_authentication():\n",
        "    \"\"\"\n",
        "    Function to toggle authentication status.\n",
        "    Returns a dictionary with the new authentication status.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    is_authenticated = not is_authenticated\n",
        "    status_message = \"authenticated\" if is_authenticated else \"unauthenticated\"\n",
        "    return {\"isAuthenticated\": is_authenticated, \"status\": f\"User is now {status_message}.\"}\n",
        "\n",
        "def get_customer_insight_tool():\n",
        "    \"\"\"\n",
        "    Function to get customer behavior analysis and return structured output.\n",
        "    Now uses a simulated DeepSeek-R1 response for the insight.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401 # Simulate HTTP 401\n",
        "\n",
        "    # Use a dummy customer ID for the demo, or generate a new one\n",
        "    customer_id = \"DEMO-CUST-\" + str(uuid.uuid4())[:4]\n",
        "    insight, status_code = get_simulated_customer_insight_from_llm(customer_id)\n",
        "    return insight, status_code # Return what the LLM call returns\n",
        "\n",
        "def handle_sensitive_report_elicitation(consent_given, access_reason):\n",
        "    \"\"\"\n",
        "    Function to simulate elicitation for sensitive report access.\n",
        "    Expects 'consent_given' (boolean) and 'access_reason' (string) as arguments.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401\n",
        "\n",
        "    if consent_given and access_reason and access_reason.strip():\n",
        "        # Simulate logging access for compliance (Resource Linking concept)\n",
        "        audit_id = str(uuid.uuid4())\n",
        "        print(f\"Sensitive Data Access Logged: CustomerID=CUST-123, Reason='{access_reason}', AuditID={audit_id}\")\n",
        "        return {\n",
        "            \"status\": \"Sensitive report generated successfully! (Simulated)\",\n",
        "            \"resourceLink\": f\"mcp://security/audit/{audit_id}\",\n",
        "            \"message\": \"Access granted. Check the console for simulated audit log.\"\n",
        "        }, 200\n",
        "    else:\n",
        "        return {\n",
        "            \"error\": \"Elicitation failed\",\n",
        "            \"message\": \"Consent and a business justification are required to access sensitive data.\"\n",
        "        }, 400\n",
        "\n",
        "def handle_create_onboarding_plan(onboarding_data):\n",
        "    \"\"\"\n",
        "    Function to simulate creation of an onboarding plan based on user data.\n",
        "    This simulates the final step of the multi-step elicitation for onboarding.\n",
        "    Expects onboarding_data (e.g., companyName, industry, employeeCount) as an argument.\n",
        "    Requires authentication.\n",
        "    \"\"\"\n",
        "    global is_authenticated\n",
        "    if not is_authenticated:\n",
        "        return {\"error\": \"Authentication required\", \"message\": \"Please log in to use this tool.\"}, 401\n",
        "\n",
        "    if not onboarding_data:\n",
        "        return {\"error\": \"No onboarding data provided\"}, 400\n",
        "\n",
        "    plan = create_simulated_onboarding_plan(onboarding_data)\n",
        "    # Simulate resource link for onboarding checklist\n",
        "    checklist_id = str(uuid.uuid4())\n",
        "    plan[\"resourceLink\"] = f\"mcp://onboarding/checklist/{checklist_id}\"\n",
        "\n",
        "    return {\n",
        "        \"status\": \"Customized onboarding plan created successfully!\",\n",
        "        \"plan\": plan,\n",
        "        \"message\": \"Plan generated. Check the 'plan' field for details.\"\n",
        "    }, 200\n",
        "\n",
        "# --- Main execution block to demonstrate usage ---\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- MCP 2025-06-18 Pure Python Backend Demo with DeepSeek-R1 Simulated Integration ---\")\n",
        "    print(\"\\n--- Initial State ---\")\n",
        "    auth_status = toggle_authentication() # Toggles to True (authenticated) initially\n",
        "    print(auth_status)\n",
        "\n",
        "    print(\"\\n--- Attempting to get customer insight (should succeed with LLM-generated data) ---\")\n",
        "    insight, status_code = get_customer_insight_tool()\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(insight, indent=2))\n",
        "\n",
        "    print(\"\\n--- Simulating sensitive report elicitation (successful) ---\")\n",
        "    elicitation_result, status_code = handle_sensitive_report_elicitation(\n",
        "        consent_given=True,\n",
        "        access_reason=\"Annual compliance audit requirement.\"\n",
        "    )\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(elicitation_result, indent=2))\n",
        "\n",
        "    print(\"\\n--- Simulating sensitive report elicitation (failed - no consent) ---\")\n",
        "    elicitation_result, status_code = handle_sensitive_report_elicitation(\n",
        "        consent_given=False,\n",
        "        access_reason=\"Investigation of security incident.\"\n",
        "    )\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(elicitation_result, indent=2))\n",
        "\n",
        "    print(\"\\n--- Simulating onboarding plan creation ---\")\n",
        "    onboarding_data_example = {\n",
        "        \"companyName\": \"ExampleCorp\",\n",
        "        \"industry\": \"finance\",\n",
        "        \"employeeCount\": \"51-200\",\n",
        "        \"preferredContactMethod\": \"slack\",\n",
        "        \"regulatoryFramework\": \"SOX\",\n",
        "        \"transactionVolume\": \"high\"\n",
        "    }\n",
        "    onboarding_result, status_code = handle_create_onboarding_plan(onboarding_data_example)\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(onboarding_result, indent=2))\n",
        "\n",
        "    print(\"\\n--- Toggling authentication off ---\")\n",
        "    auth_status = toggle_authentication()\n",
        "    print(auth_status)\n",
        "\n",
        "    print(\"\\n--- Attempting to get customer insight (should fail due to authentication) ---\")\n",
        "    insight, status_code = get_customer_insight_tool()\n",
        "    print(f\"Status Code: {status_code}\")\n",
        "    print(json.dumps(insight, indent=2))\n",
        "\n",
        "    print(\"\\n--- End of Demo ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K81-depi2qXP",
        "outputId": "30beceeb-9a82-4b5e-8753-9230878eaba2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MCP 2025-06-18 Pure Python Backend Demo with DeepSeek-R1 Simulated Integration ---\n",
            "\n",
            "--- Initial State ---\n",
            "{'isAuthenticated': True, 'status': 'User is now authenticated.'}\n",
            "\n",
            "--- Attempting to get customer insight (should succeed with LLM-generated data) ---\n",
            "\n",
            "--- Simulated DeepSeek-R1 LLM Call for Customer ID: DEMO-CUST-99a5 ---\n",
            "Simulating DeepSeek-R1 response with hardcoded JSON.\n",
            "Status Code: 200\n",
            "{\n",
            "  \"toolName\": \"analyze_customer_behavior\",\n",
            "  \"structuredOutput\": {\n",
            "    \"type\": \"customer_insight\",\n",
            "    \"data\": {\n",
            "      \"customerId\": \"DEMO-CUST-99a5\",\n",
            "      \"purchaseFrequency\": \"high\",\n",
            "      \"averageOrderValue\": 150.25,\n",
            "      \"riskScore\": 0.12,\n",
            "      \"preferredCategories\": [\n",
            "        \"clothing\",\n",
            "        \"books\"\n",
            "      ],\n",
            "      \"recommendations\": [\n",
            "        {\n",
            "          \"action\": \"Send personalized email with new arrivals\",\n",
            "          \"priority\": \"high\",\n",
            "          \"expectedImpact\": \"Increase repeat purchases by 10%\"\n",
            "        },\n",
            "        {\n",
            "          \"action\": \"Offer premium membership trial\",\n",
            "          \"priority\": \"medium\",\n",
            "          \"expectedImpact\": \"Enhance customer loyalty\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"metadata\": {\n",
            "      \"analysisDate\": \"2025-06-23T03:35:14.216095\",\n",
            "      \"dataPoints\": 5000,\n",
            "      \"confidence\": 0.98,\n",
            "      \"generatedByLLM\": true,\n",
            "      \"llmModel\": \"DeepSeek-R1-Distill-Llama-8B (Simulated)\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "--- Simulating sensitive report elicitation (successful) ---\n",
            "Sensitive Data Access Logged: CustomerID=CUST-123, Reason='Annual compliance audit requirement.', AuditID=362e26eb-308e-4efd-ad19-d82cbd2b7dfa\n",
            "Status Code: 200\n",
            "{\n",
            "  \"status\": \"Sensitive report generated successfully! (Simulated)\",\n",
            "  \"resourceLink\": \"mcp://security/audit/362e26eb-308e-4efd-ad19-d82cbd2b7dfa\",\n",
            "  \"message\": \"Access granted. Check the console for simulated audit log.\"\n",
            "}\n",
            "\n",
            "--- Simulating sensitive report elicitation (failed - no consent) ---\n",
            "Status Code: 400\n",
            "{\n",
            "  \"error\": \"Elicitation failed\",\n",
            "  \"message\": \"Consent and a business justification are required to access sensitive data.\"\n",
            "}\n",
            "\n",
            "--- Simulating onboarding plan creation ---\n",
            "Status Code: 200\n",
            "{\n",
            "  \"status\": \"Customized onboarding plan created successfully!\",\n",
            "  \"plan\": {\n",
            "    \"id\": \"plan_examplecorp_cb7160b7\",\n",
            "    \"companyName\": \"ExampleCorp\",\n",
            "    \"industry\": \"finance\",\n",
            "    \"steps\": [\n",
            "      \"Initial Setup\",\n",
            "      \"Configuration\",\n",
            "      \"Finalization\"\n",
            "    ],\n",
            "    \"timeline\": \"2-4 weeks\",\n",
            "    \"employeeCount\": \"51-200\",\n",
            "    \"preferredContactMethod\": \"slack\",\n",
            "    \"regulatoryFramework\": \"SOX\",\n",
            "    \"transactionVolume\": \"high\",\n",
            "    \"resourceLink\": \"mcp://onboarding/checklist/f0bdeaba-d1a9-4965-8939-5739ca058c98\"\n",
            "  },\n",
            "  \"message\": \"Plan generated. Check the 'plan' field for details.\"\n",
            "}\n",
            "\n",
            "--- Toggling authentication off ---\n",
            "{'isAuthenticated': False, 'status': 'User is now unauthenticated.'}\n",
            "\n",
            "--- Attempting to get customer insight (should fail due to authentication) ---\n",
            "Status Code: 401\n",
            "{\n",
            "  \"error\": \"Authentication required\",\n",
            "  \"message\": \"Please log in to use this tool.\"\n",
            "}\n",
            "\n",
            "--- End of Demo ---\n"
          ]
        }
      ]
    }
  ]
}