{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuPcg+Nqeq+9sMwKaTWGwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MISTRAL_devstral_2512_DEMO24DECV2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistralai -q"
      ],
      "metadata": {
        "id": "Fqv4pCaOqqLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c82c284-7349-41cc-a275-f68742ca736e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m461.0/461.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m4ma1ztGp7XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8a32e2-f566-4b91-85b5-2315d756de46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mistral-medium-2505\n",
            "mistral-medium-2508\n",
            "mistral-medium-latest\n",
            "mistral-medium\n",
            "open-mistral-nemo\n",
            "open-mistral-nemo-2407\n",
            "mistral-tiny-2407\n",
            "mistral-tiny-latest\n",
            "mistral-large-2411\n",
            "pixtral-large-2411\n",
            "pixtral-large-latest\n",
            "mistral-large-pixtral-2411\n",
            "codestral-2508\n",
            "codestral-latest\n",
            "devstral-small-2507\n",
            "devstral-medium-2507\n",
            "devstral-2512\n",
            "mistral-vibe-cli-latest\n",
            "devstral-medium-latest\n",
            "devstral-latest\n",
            "labs-devstral-small-2512\n",
            "devstral-small-latest\n",
            "mistral-small-2506\n",
            "mistral-small-latest\n",
            "labs-mistral-small-creative\n",
            "magistral-medium-2509\n",
            "magistral-medium-latest\n",
            "magistral-small-2509\n",
            "magistral-small-latest\n",
            "voxtral-mini-2507\n",
            "voxtral-mini-latest\n",
            "voxtral-small-2507\n",
            "voxtral-small-latest\n",
            "mistral-large-2512\n",
            "mistral-large-latest\n",
            "ministral-3b-2512\n",
            "ministral-3b-latest\n",
            "ministral-8b-2512\n",
            "ministral-8b-latest\n",
            "ministral-14b-2512\n",
            "ministral-14b-latest\n",
            "open-mistral-7b\n",
            "mistral-tiny\n",
            "mistral-tiny-2312\n",
            "pixtral-12b-2409\n",
            "pixtral-12b\n",
            "pixtral-12b-latest\n",
            "ministral-3b-2410\n",
            "ministral-8b-2410\n",
            "codestral-2501\n",
            "codestral-2412\n",
            "codestral-2411-rc5\n",
            "mistral-small-2501\n",
            "mistral-embed-2312\n",
            "mistral-embed\n",
            "codestral-embed\n",
            "codestral-embed-2505\n",
            "mistral-moderation-2411\n",
            "mistral-moderation-latest\n",
            "mistral-ocr-2512\n",
            "mistral-ocr-latest\n",
            "mistral-ocr-2505\n",
            "mistral-ocr-2503\n",
            "voxtral-mini-transcribe-2507\n",
            "voxtral-mini-2507\n",
            "voxtral-mini-latest\n",
            "ft:open-mistral-7b:9c9073bb:20250319:42325165\n",
            "ft:open-mistral-7b:9c9073bb:20250319:01258b27\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from mistralai import Mistral\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize the client with your API key\n",
        "api_key = userdata.get(\"MISTRAL_API_KEY\")\n",
        "client = Mistral(api_key=api_key)\n",
        "\n",
        "# Fetch the list of models\n",
        "models_response = client.models.list()\n",
        "\n",
        "# Print the model IDs\n",
        "for model in models_response.data:\n",
        "    print(model.id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import io\n",
        "import sys\n",
        "import traceback\n",
        "from mistralai import Mistral\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Setup\n",
        "try:\n",
        "    api_key = userdata.get(\"MISTRAL_API_KEY\")\n",
        "    client = Mistral(api_key=api_key)\n",
        "    MODEL = \"devstral-2512\"\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Setup Error: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2. Tool Logic\n",
        "# We use a dictionary to simulate a real file system for the agent to interact with\n",
        "virtual_fs = {\"main.py\": \"\", \"database.py\": \"# DB Logic\", \"requirements.txt\": \"mistralai\"}\n",
        "\n",
        "def list_files():\n",
        "    return json.dumps({\"files\": list(virtual_fs.keys())})\n",
        "\n",
        "def write_to_file(filename: str, content: str):\n",
        "    virtual_fs[filename] = content\n",
        "    return json.dumps({\"status\": \"success\", \"message\": f\"Updated {filename}\"})\n",
        "\n",
        "def execute_python_code(code: str):\n",
        "    output = io.StringIO()\n",
        "    original_stdout = sys.stdout\n",
        "    sys.stdout = output\n",
        "    try:\n",
        "        # We provide a clean global dict for every execution\n",
        "        exec_globals = {}\n",
        "        exec(code, exec_globals)\n",
        "        captured_output = output.getvalue().strip()\n",
        "        return json.dumps({\n",
        "            \"status\": \"success\",\n",
        "            \"stdout\": captured_output or \"Executed (no stdout).\"\n",
        "        })\n",
        "    except Exception:\n",
        "        return json.dumps({\"status\": \"error\", \"message\": traceback.format_exc()})\n",
        "    finally:\n",
        "        sys.stdout = original_stdout\n",
        "\n",
        "# 3. Tool Definitions\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Lists workspace files.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"write_to_file\",\n",
        "            \"description\": \"Writes or overwrites a file in the workspace.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"filename\": {\"type\": \"string\"},\n",
        "                    \"content\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"filename\", \"content\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"execute_python_code\",\n",
        "            \"description\": \"Runs Python code and returns output.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"code\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"code\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# 4. The Agentic Loop\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Devstral coding agent. Always check the file list first. If you refactor code, write it to 'main.py' before finishing.\"\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"Refactor Fibonacci with memoization, test n=10, and save it to the workspace.\"}\n",
        "]\n",
        "\n",
        "print(f\"ğŸš€ STARTING AGENT ({MODEL})\\n\" + \"-\"*50)\n",
        "\n",
        "for i in range(7): # Increased limit to allow for write steps\n",
        "    response = client.chat.complete(model=MODEL, messages=messages, tools=tools)\n",
        "    assistant_msg = response.choices[0].message\n",
        "    messages.append(assistant_msg)\n",
        "\n",
        "    if assistant_msg.content:\n",
        "        print(f\"ğŸ¤– THOUGHT: {assistant_msg.content}\")\n",
        "\n",
        "    if not assistant_msg.tool_calls:\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\nâœ… TASK COMPLETE\\n\" + \"=\"*50)\n",
        "        break\n",
        "\n",
        "    for tool_call in assistant_msg.tool_calls:\n",
        "        name = tool_call.function.name\n",
        "        args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "        print(f\"ğŸ› ï¸  ACTION: {name}\")\n",
        "\n",
        "        if name == \"list_files\":\n",
        "            result = list_files()\n",
        "        elif name == \"write_to_file\":\n",
        "            result = write_to_file(args['filename'], args['content'])\n",
        "            print(f\"ğŸ’¾ Saved to {args['filename']}\")\n",
        "        else:\n",
        "            print(f\"ğŸ“ RUNNING CODE...\")\n",
        "            result = execute_python_code(args['code'])\n",
        "\n",
        "        print(f\"ğŸ“¥ RESULT: {result}\\n\")\n",
        "\n",
        "        messages.append({\n",
        "            \"role\": \"tool\",\n",
        "            \"name\": name,\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "            \"content\": result\n",
        "        })\n",
        "\n",
        "# Show the final state of the virtual filesystem\n",
        "print(\"\\nğŸ“‚ FINAL WORKSPACE CONTENT (main.py):\")\n",
        "print(virtual_fs[\"main.py\"])"
      ],
      "metadata": {
        "id": "-3sFVZEqr3D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd366f0e-931b-42cb-b1c2-9b55a8c73487"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ STARTING AGENT (devstral-2512)\n",
            "--------------------------------------------------\n",
            "ğŸ› ï¸  ACTION: list_files\n",
            "ğŸ“¥ RESULT: {\"files\": [\"main.py\", \"database.py\", \"requirements.txt\"]}\n",
            "\n",
            "ğŸ› ï¸  ACTION: write_to_file\n",
            "ğŸ’¾ Saved to main.py\n",
            "ğŸ“¥ RESULT: {\"status\": \"success\", \"message\": \"Updated main.py\"}\n",
            "\n",
            "ğŸ› ï¸  ACTION: execute_python_code\n",
            "ğŸ“ RUNNING CODE...\n",
            "ğŸ“¥ RESULT: {\"status\": \"error\", \"message\": \"Traceback (most recent call last):\\n  File \\\"/tmp/ipython-input-2289606160.py\\\", line 35, in execute_python_code\\n    exec(code, exec_globals)\\n  File \\\"<string>\\\", line 1, in <module>\\nModuleNotFoundError: No module named 'main'\\n\"}\n",
            "\n",
            "ğŸ› ï¸  ACTION: execute_python_code\n",
            "ğŸ“ RUNNING CODE...\n",
            "ğŸ“¥ RESULT: {\"status\": \"success\", \"stdout\": \"Fibonacci(10) = 55\"}\n",
            "\n",
            "ğŸ¤– THOUGHT: The Fibonacci function with memoization has been refactored, tested with `n=10`, and saved to the workspace. The result for `Fibonacci(10)` is `55`.\n",
            "\n",
            "==================================================\n",
            "âœ… TASK COMPLETE\n",
            "==================================================\n",
            "\n",
            "ğŸ“‚ FINAL WORKSPACE CONTENT (main.py):\n",
            "def fibonacci(n, memo={}):\n",
            "    if n in memo:\n",
            "        return memo[n]\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)\n",
            "    return memo[n]\n",
            "\n",
            "# Test the function with n=10\n",
            "result = fibonacci(10)\n",
            "print(f\"Fibonacci(10) = {result}\")\n"
          ]
        }
      ]
    }
  ]
}