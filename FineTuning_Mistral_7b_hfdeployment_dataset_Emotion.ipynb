{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPaOO3vTxAvX0ZAiQJkFkWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b679f7c47d6b4a119a0e704eff40991a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f457df5b429f4338aadb88d4988befbe",
              "IPY_MODEL_f523980fe65e4cbc95bc4d069bb71795",
              "IPY_MODEL_3db7daf72be44f489d866de5d2cda6d7"
            ],
            "layout": "IPY_MODEL_f7cd46619d80438a9e238c58c0951fc9"
          }
        },
        "f457df5b429f4338aadb88d4988befbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dbb60da4e2f4d908bdf6b20e4aaae0b",
            "placeholder": "​",
            "style": "IPY_MODEL_533a86a886914b479d4e3c66ac5810c6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f523980fe65e4cbc95bc4d069bb71795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2cf2f17e5644df9b24d7a23d822b6fd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8bb74baf2d34240b3bb6a22b8ac4e0d",
            "value": 2
          }
        },
        "3db7daf72be44f489d866de5d2cda6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498419b883c5482d994e29f37c0dd11f",
            "placeholder": "​",
            "style": "IPY_MODEL_28b885ac451c47e4b90bd44f97b071c7",
            "value": " 2/2 [00:05&lt;00:00,  2.81s/it]"
          }
        },
        "f7cd46619d80438a9e238c58c0951fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbb60da4e2f4d908bdf6b20e4aaae0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533a86a886914b479d4e3c66ac5810c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2cf2f17e5644df9b24d7a23d822b6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bb74baf2d34240b3bb6a22b8ac4e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "498419b883c5482d994e29f37c0dd11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b885ac451c47e4b90bd44f97b071c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_Mistral_7b_hfdeployment_dataset_Emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.datacamp.com/tutorial/mistral-7b-tutorial"
      ],
      "metadata": {
        "id": "Kw_Oj0C8H2tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEPENDENCIES"
      ],
      "metadata": {
        "id": "SPAPb3JdCIan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorboard"
      ],
      "metadata": {
        "id": "LsJqORyIZjmp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "#!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "#!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "#! pip install datasets ninja packaging --quiet\n",
        "! pip install datasets  --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# versions: 0.0.1, 0.0.2, 0.0.3, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.4.7, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.8.5, 0.8.6, 0.9.2, 0.9.3, 0.9.4)\n",
        "#ERROR: No matching distribution found for trl==0.0.99\n",
        "! pip install trl==0.8.6 -q"
      ],
      "metadata": {
        "id": "cI7mHbyTQWT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ],
      "metadata": {
        "id": "65JpttRiGxVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "6usdVgDF50fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0685ac7-2c22-4f53-db44-0dad57cddead"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtE9TuSMlUEc",
        "outputId": "8804f337-1fb5-45cd-ec0c-4997badf7cbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get update && apt-get install -y cuda-11-0"
      ],
      "metadata": {
        "id": "LY6iadKNl1Af"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapRov3hl4fT",
        "outputId": "00b1e319-1bb9-4fd2-b64d-a7565235a1c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Tue Jun 11 20:15:12 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              44W / 400W |      5MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### conversational format\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "\n",
        "### instruction format\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
      ],
      "metadata": {
        "id": "p-7fKxR2rnbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "sPAxhdxMAdBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://huggingface.co/datasets/sakharamg/AviationQA"
      ],
      "metadata": {
        "id": "ue5Leyc90T6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install datasets  --quiet"
      ],
      "metadata": {
        "id": "eOTw6tjZKupR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "print(\"Preprocessing dataset Emotion\")\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "\n",
        "# save datasets to disk\n",
        "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
        "dataset[\"validation\"].to_json(\"validation_dataset.json\", orient=\"records\")\n",
        "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
      ],
      "metadata": {
        "id": "WY55Lb9ixyCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP4XSSClx2IX",
        "outputId": "2cb9dc9a-f489-4374-e432-7cc7f18c1af3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/train_dataset.json\", split=\"train\")"
      ],
      "metadata": {
        "id": "SInSDc3Xx6w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9c4RuZCx_gn",
        "outputId": "90e270f2-3e75-4dfa-e4a9-00f60f5372bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 16000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_question=dataset['text']\n",
        "train_answer=dataset['label']"
      ],
      "metadata": {
        "id": "t3C7lGBlFXog"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/summary-qa.txt\n",
        "filename='/content/summary-qa.txt'\n",
        "\n",
        "import re\n",
        "\n",
        "# python object to be appended\n",
        "for n in range(10000):\n",
        "    if train_answer[n] == None:\n",
        "       train_answer[n] = 'Not possible to get or use'\n",
        "    string = train_answer[n]\n",
        "    #print(string)\n",
        "    #result = string.replace(\"\\nRef\", \"-Ref\")\n",
        "    str_question=train_question[n]\n",
        "    question= re.sub(\"\\n\", \"\", str_question)\n",
        "    answer = re.sub(\"\\n\", \"\", str(string))\n",
        "    #print(answer)\n",
        "    if len(answer)==0:\n",
        "        answer='Not possible to get or use'\n",
        "    text='<s>[INST] %s [/INST] %s </s>'%(question,answer)\n",
        "    #print(text)\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(text + '\\n')"
      ],
      "metadata": {
        "id": "WLgn-AwEDuKD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_question[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z-UPeSK06Gf-",
        "outputId": "8e1fdb30-dbce-4fd8-dccd-68dc4f4c3032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i have been with petronas for years i feel that petronas has performed well and made a huge profit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "label: a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)."
      ],
      "metadata": {
        "id": "nD3JsC69rTrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_answer[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5AZ0Iy44QkB",
        "outputId": "e4db07e3-164c-42b3-b74e-b9c3b2a1cb61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text0 = load_dataset(\"text\", data_files=\"/content/summary-qa.txt\", split=\"train\")"
      ],
      "metadata": {
        "id": "j4AtoIrsD0k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text0['text']"
      ],
      "metadata": {
        "id": "MNdRQ4UTD5e4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=10000\n",
        "\n",
        "dataset_final_Question=dataset['text'][0:nrec]\n",
        "dataset_final_Answer=dataset['label'][0:nrec]\n",
        "dataset_final_text=text0[0:nrec]['text']"
      ],
      "metadata": {
        "id": "50KFalQfEDkI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[84]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35LRbDnvyGAP",
        "outputId": "1c5541a8-7571-4561-df08-faf4f0157ca9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i feel very happy and excited since i learned so many things',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text0[84]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5I71acOCRtt",
        "outputId": "b93aa99d-130b-429f-a1dc-37396d0d9b54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '<s>[INST] i feel very happy and excited since i learned so many things [/INST] 1 </s>'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer\n",
        "datasetF['text'] = dataset_final_text"
      ],
      "metadata": {
        "id": "07nkZ2Pu3va9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B24h4n-E3fkg",
        "outputId": "249008b4-b0e0-4901-bf63-0c90be37c8f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  Answer  \\\n",
              "0                               i didnt feel humiliated       0   \n",
              "1     i can go from feeling so hopeless to so damned...       0   \n",
              "2      im grabbing a minute to post i feel greedy wrong       3   \n",
              "3     i am ever feeling nostalgic about the fireplac...       2   \n",
              "4                                  i am feeling grouchy       3   \n",
              "...                                                 ...     ...   \n",
              "9995  i have a desk job and sit on my ass all day lo...       4   \n",
              "9996     i feel like such a confused person lately sigh       4   \n",
              "9997  i feel ive been beaten down by the words of me...       0   \n",
              "9998  i fully understand the feeling of being beaten...       0   \n",
              "9999       im feeling cranky im very defensive about it       3   \n",
              "\n",
              "                                                   text  \n",
              "0      <s>[INST] i didnt feel humiliated [/INST] 0 </s>  \n",
              "1     <s>[INST] i can go from feeling so hopeless to...  \n",
              "2     <s>[INST] im grabbing a minute to post i feel ...  \n",
              "3     <s>[INST] i am ever feeling nostalgic about th...  \n",
              "4         <s>[INST] i am feeling grouchy [/INST] 3 </s>  \n",
              "...                                                 ...  \n",
              "9995  <s>[INST] i have a desk job and sit on my ass ...  \n",
              "9996  <s>[INST] i feel like such a confused person l...  \n",
              "9997  <s>[INST] i feel ive been beaten down by the w...  \n",
              "9998  <s>[INST] i fully understand the feeling of be...  \n",
              "9999  <s>[INST] im feeling cranky im very defensive ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-051b7a5f-5e47-4a14-bfa8-f04bebab6fc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i didnt feel humiliated [/INST] 0 &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i can go from feeling so hopeless to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] im grabbing a minute to post i feel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;s&gt;[INST] i am ever feeling nostalgic about th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] i am feeling grouchy [/INST] 3 &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>i have a desk job and sit on my ass all day lo...</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;s&gt;[INST] i have a desk job and sit on my ass ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>i feel like such a confused person lately sigh</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;s&gt;[INST] i feel like such a confused person l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>i feel ive been beaten down by the words of me...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i feel ive been beaten down by the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>i fully understand the feeling of being beaten...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i fully understand the feeling of be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>im feeling cranky im very defensive about it</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] im feeling cranky im very defensive ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-051b7a5f-5e47-4a14-bfa8-f04bebab6fc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-051b7a5f-5e47-4a14-bfa8-f04bebab6fc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-051b7a5f-5e47-4a14-bfa8-f04bebab6fc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d789e6bd-36e8-46ef-9a28-5cf593a366cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d789e6bd-36e8-46ef-9a28-5cf593a366cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d789e6bd-36e8-46ef-9a28-5cf593a366cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c3e75a40-4a12-4cae-bdbb-7df0b38fa1dd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c3e75a40-4a12-4cae-bdbb-7df0b38fa1dd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9990,\n        \"samples\": [\n          \"i feel like its an excuse for being boring as an individual or lack of confidence in your individuality\",\n          \"i much regret that i allowed johann to accompany me from khartoum i feel convinced he can never rally from his present descara\",\n          \"i am feeling super excited as the weeks seem to be flying by and we are getting closer and closer to our due date\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"<s>[INST] i feel awkward talking about my book to begin with [/INST] 0 </s>\",\n          \"<s>[INST] i feel so frustrated but i cant tell them i am [/INST] 3 </s>\",\n          \"<s>[INST] i grappled with was guilt that relatives and friends who usually communicate with me there would feel like i was ignoring them and i felt selfish still posting my burlesque and blog updates there without liking their photos and links [/INST] 3 </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['Question'][84]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bJIEeujGvocn",
        "outputId": "4987ff38-eb06-4a33-d51d-b12d9e7e8457"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i feel very happy and excited since i learned so many things'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['Answer'][84]"
      ],
      "metadata": {
        "id": "viWQFo-pNq5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42f0c51-9bc0-4480-a322-331d73627283"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['text'][84]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CNGf8BmXEZnF",
        "outputId": "58147da0-59bc-4a3a-e8e5-a3f5be42d2a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] i feel very happy and excited since i learned so many things [/INST] 1 </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=False,\n",
        ")"
      ],
      "metadata": {
        "id": "npGef0PAwBkJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "id": "G756UDF1k3hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bb7b9b-5ebb-4dd7-d665-0951367c365d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            83Gi       2.3Gi        35Gi       5.0Mi        45Gi        80Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Mistral 7B model"
      ],
      "metadata": {
        "id": "vuHodNjdAol6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistral_inference -q"
      ],
      "metadata": {
        "id": "VTaNFDF9TedV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\" #10 june 2024,\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    is_decoder=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
        "#model, tokenizer = setup_chat_format(model, tokenizer)"
      ],
      "metadata": {
        "id": "lQm2yo0uslTs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b679f7c47d6b4a119a0e704eff40991a",
            "f457df5b429f4338aadb88d4988befbe",
            "f523980fe65e4cbc95bc4d069bb71795",
            "3db7daf72be44f489d866de5d2cda6d7",
            "f7cd46619d80438a9e238c58c0951fc9",
            "6dbb60da4e2f4d908bdf6b20e4aaae0b",
            "533a86a886914b479d4e3c66ac5810c6",
            "f2cf2f17e5644df9b24d7a23d822b6fd",
            "c8bb74baf2d34240b3bb6a22b8ac4e0d",
            "498419b883c5482d994e29f37c0dd11f",
            "28b885ac451c47e4b90bd44f97b071c7"
          ]
        },
        "outputId": "ab751d00-8bb8-4aac-ec90-0015cb5991f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b679f7c47d6b4a119a0e704eff40991a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "EqToGYwPagxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2366310-3683-4b01-c28e-278401abbfda"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference\n",
        "\n",
        "Build an inference pipeline with tokenizer and the model."
      ],
      "metadata": {
        "id": "pfFTlpqJFOdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load into pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "CHUtHvtzMlYB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt=\"What was the first album Beyoncé released as a solo artist?\"\n",
        "prompt0=\"What is the capital of russia?\"\n",
        "#prompt=\"What are some interesting sites to visit in the Bay Area?\"\n",
        "\n",
        "prompt = f\"Instruct: Find THE answer for the following  question.\\n{prompt0}\\nOutput:\\n\"\n",
        "#prompt = f\"Instruct: Find only the answer for the following  question.\\n{prompt0}\"\n",
        "\n",
        "#prompt=\"What are some interesting sites to visit in the Bay Area?\"\n",
        "#prompt=\"What is the capital of russia?\"\n",
        "outputs = pipe(prompt0, max_new_tokens=128, temperature=0.9,do_sample=True,top_k=30, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.eos_token_id)\n",
        "\n",
        "print('Question: %s'%prompt0)\n",
        "print()\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt0):].strip()}\")\n"
      ],
      "metadata": {
        "id": "VZ5nnw6tMsVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352c2fd4-dffe-404a-b921-20ff13371b5f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the capital of russia?\n",
            "\n",
            "Generated Answer:\n",
            "moscow\n",
            "15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "id": "mJOKD2w5QSWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48854989-f0e8-41fd-e127-52cefa586b50"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the capital of russia?\n",
            "moscow\n",
            "15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
        "eval_tokenizer.pad_token = eval_tokenizer.eos_token\n",
        "\n",
        "def gen(model,p, maxlen=1024, sample=True):\n",
        "    toks = eval_tokenizer(p, return_tensors=\"pt\")\n",
        "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample,num_return_sequences=1,temperature=0.9,num_beams=1,top_p=0.95,).to('cuda')\n",
        "    return eval_tokenizer.batch_decode(res,skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "CUFk-I1pugxc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zP_FQeY4vq1s",
        "outputId": "3709b148-449b-4a4e-987c-96995dbe3345"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  Answer  \\\n",
              "0                               i didnt feel humiliated       0   \n",
              "1     i can go from feeling so hopeless to so damned...       0   \n",
              "2      im grabbing a minute to post i feel greedy wrong       3   \n",
              "3     i am ever feeling nostalgic about the fireplac...       2   \n",
              "4                                  i am feeling grouchy       3   \n",
              "...                                                 ...     ...   \n",
              "9995  i have a desk job and sit on my ass all day lo...       4   \n",
              "9996     i feel like such a confused person lately sigh       4   \n",
              "9997  i feel ive been beaten down by the words of me...       0   \n",
              "9998  i fully understand the feeling of being beaten...       0   \n",
              "9999       im feeling cranky im very defensive about it       3   \n",
              "\n",
              "                                                   text  \n",
              "0      <s>[INST] i didnt feel humiliated [/INST] 0 </s>  \n",
              "1     <s>[INST] i can go from feeling so hopeless to...  \n",
              "2     <s>[INST] im grabbing a minute to post i feel ...  \n",
              "3     <s>[INST] i am ever feeling nostalgic about th...  \n",
              "4         <s>[INST] i am feeling grouchy [/INST] 3 </s>  \n",
              "...                                                 ...  \n",
              "9995  <s>[INST] i have a desk job and sit on my ass ...  \n",
              "9996  <s>[INST] i feel like such a confused person l...  \n",
              "9997  <s>[INST] i feel ive been beaten down by the w...  \n",
              "9998  <s>[INST] i fully understand the feeling of be...  \n",
              "9999  <s>[INST] im feeling cranky im very defensive ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6f22269-ff14-4005-a9bb-2fdaccd9a123\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i didnt feel humiliated [/INST] 0 &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i can go from feeling so hopeless to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] im grabbing a minute to post i feel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;s&gt;[INST] i am ever feeling nostalgic about th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] i am feeling grouchy [/INST] 3 &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>i have a desk job and sit on my ass all day lo...</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;s&gt;[INST] i have a desk job and sit on my ass ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>i feel like such a confused person lately sigh</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;s&gt;[INST] i feel like such a confused person l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>i feel ive been beaten down by the words of me...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i feel ive been beaten down by the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>i fully understand the feeling of being beaten...</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;[INST] i fully understand the feeling of be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>im feeling cranky im very defensive about it</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;s&gt;[INST] im feeling cranky im very defensive ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6f22269-ff14-4005-a9bb-2fdaccd9a123')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6f22269-ff14-4005-a9bb-2fdaccd9a123 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6f22269-ff14-4005-a9bb-2fdaccd9a123');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-125012c2-0efb-43ec-999e-59e9bd213f15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-125012c2-0efb-43ec-999e-59e9bd213f15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-125012c2-0efb-43ec-999e-59e9bd213f15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_77daf58c-f49b-4c85-b5ec-b60c92274d34\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_77daf58c-f49b-4c85-b5ec-b60c92274d34 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9990,\n        \"samples\": [\n          \"i feel like its an excuse for being boring as an individual or lack of confidence in your individuality\",\n          \"i much regret that i allowed johann to accompany me from khartoum i feel convinced he can never rally from his present descara\",\n          \"i am feeling super excited as the weeks seem to be flying by and we are getting closer and closer to our due date\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"<s>[INST] i feel awkward talking about my book to begin with [/INST] 0 </s>\",\n          \"<s>[INST] i feel so frustrated but i cant tell them i am [/INST] 3 </s>\",\n          \"<s>[INST] i grappled with was guilt that relatives and friends who usually communicate with me there would feel like i was ignoring them and i felt selfish still posting my burlesque and blog updates there without liking their photos and links [/INST] 3 </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index=2\n",
        "\n",
        "\n",
        "prompt = datasetF['Question'][index]\n",
        "print(prompt)\n",
        "\n",
        "prompt = datasetF['Answer'][index]\n",
        "print(prompt)\n",
        "\n",
        "prompt = datasetF['text'][index]\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_TvVz3B2eso",
        "outputId": "900aa537-aea9-447e-c93e-aa04ac8c7ee7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im grabbing a minute to post i feel greedy wrong\n",
            "3\n",
            "<s>[INST] im grabbing a minute to post i feel greedy wrong [/INST] 3 </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL GENERATION - ZERO SHOT"
      ],
      "metadata": {
        "id": "KYysLZxRz9_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=2\n",
        "\n",
        "#features: ['id', 'Question', 'Answer'],\n",
        "#prompt = dataset[index]['Question']\n",
        "#summary = dataset[index]['Answer']\n",
        "\n",
        "prompt = datasetF['Question'][index]\n",
        "summary = datasetF['Answer'][index]\n",
        "\n",
        "original_model = model\n",
        "\n",
        "formatted_prompt = f\"Instruct: provide an answer for the following dialog.\\n{prompt}\"\n",
        "\n",
        "res = original_model.generate(tokenizer.encode(formatted_prompt, return_tensors=\"pt\"), max_length=128, do_sample=False)\n",
        "output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
        "\n",
        "#input_ids = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to('cuda') # Assuming you want to run on GPU\n",
        "#input_ids = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(torch.bfloat16)\n",
        "#res = model.generate(input_ids, max_length=512, do_sample=False)\n",
        "#output = tokenizer.decode(res[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "1GN8Vns5m7RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "\n",
        "print(f'Dialogue :\\n{prompt}')\n",
        "print(dash_line)\n",
        "\n",
        "print(f'ACTION BY THE AGENT-HUMAN:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckW4p9r9N9J8",
        "outputId": "d0f31815-eccf-4dec-9082-b4d0a0141191"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Dialogue :\n",
            "im grabbing a minute to post i feel greedy wrong\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ACTION BY THE AGENT-HUMAN:\n",
            "3\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Instruct: provide an answer for the following dialog.\n",
            "im grabbing a minute to post i feel greedy wrong\n",
            "\n",
            "Answer: It's okay to feel greedy sometimes, but it's important to remember that it's not always the right choice. It's important to consider the impact of your actions on others and to strive to make choices that are fair and ethical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datasetF))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjQlF7kZXJUN",
        "outputId": "6802c94e-fab5-474d-90d9-da2dff1717c5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "kxOWr2VvEGKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f7c713-26ae-4f2b-97d0-537fa7e607de"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding the adopter to the layer"
      ],
      "metadata": {
        "id": "of-Z3B28BNBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=128,\n",
        "        lora_dropout=0.05,\n",
        "        r=256,\n",
        "        bias=\"none\",\n",
        "        target_modules=\"all-linear\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "kjyYx9WmtMmA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparmeters"
      ],
      "metadata": {
        "id": "NcaH5WrdBW8e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "AkMVebosM16A"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"Mistral-7B-v0.1_Emotion\", # 06/06/2024 #dataset_AviationQA\n",
        "\n",
        "    #num_train_epochs=3,                     # number of training epochs\n",
        "    num_train_epochs=25,                     # number of training epochs for POC\n",
        "    per_device_train_batch_size=3,          # batch size per device during training\n",
        "    gradient_accumulation_steps=2,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
        "    bf16=True,                              # use bfloat16 precision\n",
        "    tf32=True,                              # use tf32 precision\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/trl/en/sft_trainer\n",
        "\n",
        "https://github.com/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Meta_Llama_3_8B_for_text_to_SQL.ipynb"
      ],
      "metadata": {
        "id": "5BMkpAwk6uhW"
      }
    },
    {
      "source": [
        "#print(dataset.column_names)\n",
        "print(datasetF.columns)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVqCgdDqB7Aq",
        "outputId": "ed6a955e-b154-4991-c329-fac8558bac66"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Question', 'Answer', 'text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasetF['Answer'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6-OvnJGd7o3",
        "outputId": "726d65ef-4c0c-4802-b484-eabf4ceed6ca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised fine-tuning (SFT)  parameters"
      ],
      "metadata": {
        "id": "0G2D93SDBjgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl -q"
      ],
      "metadata": {
        "id": "6gIkAfvBHh8n"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "import datasets\n",
        "\n",
        "# Convert Pandas DataFrame to Hugging Face Dataset\n",
        "datasetF_hf = datasets.Dataset.from_pandas(datasetF)\n",
        "\n",
        "max_seq_length = 3072 # max sequence length for model and packing of the dataset\n",
        "\n",
        "# Explicitly set the device using torch.device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "#model.to(device)\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=original_model,\n",
        "    args=args,\n",
        "    train_dataset=datasetF_hf,\n",
        "    dataset_text_field=\"text\", ### added for the summarization dataset\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    #device_map={\"\": device},\n",
        "    #formatting_func=formatting_func,\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,  # We template with special tokens\n",
        "        \"append_concat_token\": False, # No need to add additional separator token\n",
        "        ##\"per_device_train_batch_size\": 8,\n",
        "        #\"per_device_eval_batch_size\": 8,\n",
        "        #\"num_train_epochs\": 3.0},\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "ZklRuRAatoZ8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training AND Saving the fine-tuned model"
      ],
      "metadata": {
        "id": "sNtNfyP6BuOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCq7Dq8f7VPU"
      },
      "outputs": [],
      "source": [
        "#del device\n",
        "#model.to(torch.device('cuda'))\n",
        "trainer.train()\n",
        "\n",
        "# /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\n",
        "#  1406\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Step\tTraining Loss\n",
        "10\t2.503100\n",
        "20\t2.069500\n",
        "30\t1.792300\n",
        "40\t1.583100\n",
        "50\t1.190000\n",
        "60\t0.879000\n",
        "70\t0.667700\n",
        "80\t0.452700\n",
        "90\t0.428900\n",
        "100\t0.340300\n",
        "110\t0.338100\n",
        "120\t0.282200\n",
        "130\t0.243600\n",
        "140\t0.180700\n",
        "150\t0.132300\n",
        "160\t0.086300\n",
        "170\t0.051900\n",
        "180\t0.047300\n",
        "190\t0.033100\n",
        "200\t0.034900\n",
        "210\t0.026900\n",
        "220\t0.030600\n",
        "230\t0.024700\n",
        "240\t0.024200\n",
        "250\t0.024800\n",
        "260\t0.019700\n",
        "270\t0.025000\n",
        "280\t0.018100\n",
        "290\t0.021900\n",
        "300\t0.018100\n",
        "310\t0.019300\n",
        "320\t0.020000\n",
        "330\t0.017200\n",
        "340\t0.016400\n",
        "350\t0.015800\n",
        "360\t0.017000\n",
        "370\t0.013000\n",
        "380\t0.015500\n",
        "390\t0.040200\n",
        "400\t0.016500\n",
        "410\t0.020600\n",
        "420\t0.014900\n",
        "430\t0.012400\n",
        "440\t0.020400\n",
        "450\t0.011100\n",
        "```\n"
      ],
      "metadata": {
        "id": "23NPxL5VNOvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del original_model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mCxeJIj4KvSQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "e0U_CeRoB9kM"
      }
    },
    {
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "P-sM4GnQxrjM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "\n",
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM"
      ],
      "metadata": {
        "id": "DNgzXJgEnEB9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "%cd /content/\n",
        "peft_model_id = \"/content/Mistral-7B-v0.1_Emotion\"\n",
        "\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "modelnew = AutoPeftModelForCausalLM.from_pretrained(\n",
        "  peft_model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  load_in_8bit=True # Load the model in 8-bit precision\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "\n",
        "\n",
        "# load into pipeline\n",
        "generation_pipeline = pipeline(\"text-generation\", model=modelnew, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "kW_hl8YPKxQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear the cache to release memory\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MdUuq3YH4b6B"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=9106"
      ],
      "metadata": {
        "id": "u4MXMHhbC10E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Question: {datasetF['Question'][index]} \\nAnswer: {datasetF['Answer'][index]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8xg6dYp9NFp",
        "outputId": "7a4ace15-ee91-4f46-aed3-248a0862ee6b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: i may not feel it i m sure the wisdom that comes with age will help \n",
            "Answer: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=datasetF['Question'][index]\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=512, do_sample=True, temperature=0.1,\n",
        "                              top_k=50, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                              pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "ldFY8BYb2cHZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "label: a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)."
      ],
      "metadata": {
        "id": "dDRUP_Xe8PaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "response=outputs[0]['generated_text']\n",
        "response= re.sub(\"/INST\", \"\", response)\n",
        "response= re.sub(r\"\\[\\]\", \"\\nSentiment with label:\", response)\n",
        "\n",
        "print(response)\n",
        "\n",
        "#print(f\"Generated Answer:\\n{outputs[0]['generated_text']}\")\n",
        "print()\n",
        "if datasetF['Answer'][index] == 0:\n",
        "   print(f'Sentiment-ORIGINAL: Sadness(0)')\n",
        "if datasetF['Answer'][index] == 1:\n",
        "   print(f'Sentiment-ORIGINAL: Joy(1)')\n",
        "if datasetF['Answer'][index] == 2:\n",
        "   print(f'Sentiment-ORIGINAL: Love(2)')\n",
        "if datasetF['Answer'][index] == 3:\n",
        "   print(f'Sentiment-ORIGINAL: Anger(3)')\n",
        "if datasetF['Answer'][index] == 4:\n",
        "   print(f'Sentiment-ORIGINAL: Fear(4)')\n",
        "if datasetF['Answer'][index] == 5:\n",
        "   print(f'Sentiment-ORIGINAL: Surprise(5)')"
      ],
      "metadata": {
        "id": "94RkvAzSnbrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841bb993-8312-44b8-c34c-60d4267b3e4f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i may not feel it i m sure the wisdom that comes with age will help \n",
            "Sentiment with label: 1 \n",
            "\n",
            "Sentiment-ORIGINAL: Joy(1)\n"
          ]
        }
      ]
    }
  ]
}