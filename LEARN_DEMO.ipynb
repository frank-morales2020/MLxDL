{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iKIWRRf4s6H7",
        "1p_zDpykusrv",
        "z1WSeIBguv6P",
        "4McJqypQz3OF",
        "7igWj6a60J74",
        "oJ88U-BO0eTJ",
        "_6gVlNtM1Dd0",
        "47zUXoZOimd8"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtaB03rnYuMkFLSOuspuMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LEARN_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "iKIWRRf4s6H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install colab-env -q\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "Zk0Djr2prbR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## few-shot"
      ],
      "metadata": {
        "id": "1p_zDpykusrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code leverages the power of a large language model to quickly learn how to summarize weather reports from just a few examples. This is a demonstration of the power and efficiency of few-shot learning techniques in natural language processing."
      ],
      "metadata": {
        "id": "QBqiXPOwt6-b"
      }
    },
    {
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key from the environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the few-shot examples\n",
        "examples = [\n",
        "    {\n",
        "        \"report\": \"Scattered thunderstorms with a high of 28 degrees Celsius and a low of 18 degrees Celsius. Winds from the north at 15-25 kilometers per hour.\",\n",
        "        \"summary\": \"Thunderstorms, high 28C, low 18C, north winds 15-25 km/h.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Cloudy with a chance of showers. High near 20 degrees Celsius. Southwest wind 10 to 15 kilometers per hour.\",\n",
        "        \"summary\": \"Cloudy, chance of showers, high 20C, southwest wind 10-15 km/h.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Define the new weather report\n",
        "new_report = \"Sunny with a high near 25 degrees Celsius. Calm wind becoming west 5 to 10 kilometers per hour in the afternoon.\"\n",
        "\n",
        "# Construct the messages for the chat completion\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that summarizes weather reports.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Here are some examples of weather reports and their summaries:\\n\\n{examples[0]['report']}\\nSummary: {examples[0]['summary']}\\n\\n{examples[1]['report']}\\nSummary: {examples[1]['summary']}\\n\\nNow, provide a summary for this weather report:\\n\\n{new_report}\\n\\nSummary:\"}\n",
        "]\n",
        "\n",
        "# Generate the summary using the LLM (e.g., GPT-3.5 or GPT-4)\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Or another suitable LLM\n",
        "    messages=messages,\n",
        "    max_tokens=50,  # Adjust as needed\n",
        ")\n",
        "\n",
        "# Extract the generated summary\n",
        "summary = response.choices[0].message.content.strip() # Accessing the message content correctly\n",
        "\n",
        "\n",
        "print(f\"Summary: {summary}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tLelJxYsoHr",
        "outputId": "09ff0aec-a033-4fd0-8b8d-c498296caeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Sunny, high near 25C, calm wind becoming west 5-10 km/h in the afternoon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## zero-shot\n",
        "\n"
      ],
      "metadata": {
        "id": "z1WSeIBguv6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code demonstrates how to leverage the general knowledge of a large language model to translate text without providing any specific training examples for that translation task. This is why it's called \"zero-shot\" translation."
      ],
      "metadata": {
        "id": "zaszZ_FluPGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key from the environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the flight plan in English\n",
        "flight_plan_english = \"\"\"\n",
        "Departure: Montreal (CYUL)\n",
        "Arrival: London (EGLL)\n",
        "Route: CYUL DCT YQY DCT 51N050W DCT 53N040W DCT 55N030W DCT EGLL\n",
        "Altitude: 35000 feet\n",
        "Aircraft: Boeing 787-9\n",
        "\"\"\"\n",
        "\n",
        "# Construct the prompt for zero-shot translation\n",
        "prompt = f\"\"\"\n",
        "Translate the following flight plan into French:\n",
        "\n",
        "{flight_plan_english}\n",
        "\"\"\"\n",
        "\n",
        "# Generate the translation using the LLM (e.g., GPT-3.5 or GPT-4)\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Or another suitable LLM\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,  # Adjust as needed\n",
        ")\n",
        "\n",
        "# Extract the translated flight plan (corrected)\n",
        "flight_plan_french = response.choices[0].message.content.strip() # Accessing the message content correctly\n",
        "\n",
        "\n",
        "\n",
        "print(f\"French Translation:\\n{flight_plan_french}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m6Du3KHuIxl",
        "outputId": "6ec0abb2-560e-4487-f2dd-9899d2397747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Translation:\n",
            "Départ : Montréal (CYUL)\n",
            "Arrivée : Londres (EGLL)\n",
            "Itinéraire : CYUL DCT YQY DCT 51N050W DCT 53N040W DCT 55N030W DCT EGLL\n",
            "Altitude : 35000 pieds\n",
            "Avion : Boeing 787-9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervision Learning"
      ],
      "metadata": {
        "id": "4McJqypQz3OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code demonstrates a supervised machine learning task using the Support Vector Machine (SVM) algorithm to classify iris flowers into different species."
      ],
      "metadata": {
        "id": "QAvi2id9u7UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Create an SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTfm99arzvS2",
        "outputId": "5dc9fb9c-e526-47b6-a04f-0e476acd7a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervision Learning"
      ],
      "metadata": {
        "id": "7igWj6a60J74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Sample customer data (replace with your actual data)\n",
        "X = np.array([[0,0],[1,1],[2,2]])\n",
        "\n",
        "# Create a KMeans object with 2 clusters\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "\n",
        "# Fit the model to the data\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Get the cluster labels for each data point\n",
        "labels = kmeans.labels_\n",
        "print(f\"Cluster labels: {labels}\")\n",
        "\n",
        "# Get the cluster centers\n",
        "centroids = kmeans.cluster_centers_\n",
        "print(f\"Centroids: {centroids}\")\n",
        "kmeans = KMeans(n_clusters=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N-v9Su30Ios",
        "outputId": "266bc118-fbf1-4775-e9ad-c87aeaae5b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [0 1 1]\n",
            "Centroids: [[0.  0. ]\n",
            " [1.5 1.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reinforcement learning"
      ],
      "metadata": {
        "id": "oJ88U-BO0eTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " the code is training an AI agent to balance a pole on a cart using Q-learning, a type of reinforcement learning where the agent learns by trial and error, trying to maximize its rewards. I hope this explanation is helpful. Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "gU0LmisVwZ8G"
      }
    },
    {
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "# Create the Cartpole environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Discretize the observation space\n",
        "# Define the number of bins for each dimension\n",
        "num_bins = [10, 10, 10, 10]  # Adjust as needed\n",
        "\n",
        "# Create bins for each dimension\n",
        "bins = [\n",
        "    np.linspace(env.observation_space.low[i], env.observation_space.high[i], num_bins[i] + 1)\n",
        "    for i in range(env.observation_space.shape[0])\n",
        "]\n",
        "\n",
        "def discretize_state(state):\n",
        "    \"\"\"Discretizes the continuous state into discrete bins.\"\"\"\n",
        "    discrete_state = [np.digitize([state[i]], bins[i])[0] for i in range(len(state))]\n",
        "    return tuple(discrete_state)\n",
        "\n",
        "# Initialize Q-table based on discretized state space\n",
        "q_table_shape = tuple(num_bins) + (env.action_space.n,)  # Consider action space size\n",
        "q_table = np.zeros(q_table_shape)\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.99  # Discount factor\n",
        "epsilon = 1.0  # Exploration rate\n",
        "\n",
        "# Training loop\n",
        "for i in range(10000):\n",
        "    state = env.reset()\n",
        "    discrete_state = discretize_state(state)  # Discretize initial state\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Choose action (epsilon-greedy)\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore\n",
        "        else:\n",
        "            action = np.argmax(q_table[discrete_state])  # Exploit using discretized state\n",
        "\n",
        "        # Take action and observe next state and reward\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        next_discrete_state = discretize_state(next_state)  # Discretize next state\n",
        "\n",
        "        # Update Q-table using discretized states\n",
        "        old_value = q_table[discrete_state + (action,)]\n",
        "        next_max = np.max(q_table[next_discrete_state])\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[discrete_state + (action,)] = new_value\n",
        "\n",
        "        discrete_state = next_discrete_state  # Update current state\n",
        "\n",
        "    # Decay exploration rate\n",
        "    epsilon = max(0.01, epsilon * 0.9999)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "hR2zaYqm0wh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semi-Supervised Learning"
      ],
      "metadata": {
        "id": "_6gVlNtM1Dd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code takes data with some missing labels and uses the LabelPropagation algorithm to \"propagate\" the known labels to the unlabeled data points, effectively making educated guesses about what the missing labels should be. This is a common technique in semi-supervised learning where we want to leverage unlabeled data to improve our model's performance."
      ],
      "metadata": {
        "id": "eHgBqk6bw96A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "\n",
        "# Sample data with some labels missing (-1)\n",
        "X = np.array([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]])\n",
        "y = np.array([0, 0, 1, 1, -1, -1])\n",
        "\n",
        "# Create a LabelPropagation object\n",
        "label_prop_model = LabelPropagation()\n",
        "\n",
        "# Fit the model to the data\n",
        "label_prop_model.fit(X, y)\n",
        "\n",
        "# Predict labels for the unlabeled data\n",
        "y_pred = label_prop_model.predict(X[y == -1])\n",
        "print(f\"Predicted labels: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ycSKcY0-Fy",
        "outputId": "9d8e1ab6-074e-4f38-fd02-76fff0a0456d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: [1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning"
      ],
      "metadata": {
        "id": "ziyxjiCM1rV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "-pd5oxhUiY2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval -q\n",
        "!pip install datasets evaluate -q\n",
        "!pip install tqdm -q"
      ],
      "metadata": {
        "id": "85q6n8zLFtm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code performs Transfer Learning to fine-tune a pre-trained DistilBERT model (\"distilbert-base-uncased\") for the \"cola\" (Corpus of Linguistic Acceptability) task from the GLUE benchmark."
      ],
      "metadata": {
        "id": "MtqNPy9dxPlj"
      }
    },
    {
      "source": [
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AdamW, AutoTokenizer, logging\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from seqeval.metrics import classification_report, accuracy_score as seqeval_accuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "task = \"cola\"\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "dataset = load_dataset(\"glue\", task)\n",
        "train_dataset = dataset[\"train\"]\n",
        "validation_dataset = dataset[\"validation\"]\n",
        "\n",
        "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "encoded_validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "encoded_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "encoded_validation_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(encoded_train_dataset, sampler=RandomSampler(encoded_train_dataset), batch_size=batch_size)\n",
        "validation_dataloader = DataLoader(encoded_validation_dataset, sampler=SequentialSampler(encoded_validation_dataset), batch_size=batch_size)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['label'].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input_ids,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2bVbFp6X_M2",
        "outputId": "0a682303-d95a-4fec-c2f7-8c87c013255a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 535/535 [06:08<00:00,  1.45it/s]\n",
            "Epoch 2/5: 100%|██████████| 535/535 [06:07<00:00,  1.46it/s]\n",
            "Epoch 3/5: 100%|██████████| 535/535 [06:07<00:00,  1.46it/s]\n",
            "Epoch 4/5: 100%|██████████| 535/535 [06:07<00:00,  1.46it/s]\n",
            "Epoch 5/5: 100%|██████████| 535/535 [06:07<00:00,  1.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "47zUXoZOimd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code snippet takes a trained model, applies it to a validation dataset, and then evaluates its performance using various metrics like accuracy, precision, recall, and F1-score. This evaluation helps assess how well the model is likely to perform on unseen data. The code snippet focuses on the evaluation phase of a Transfer Learning task using a pre-trained DistilBERT model."
      ],
      "metadata": {
        "id": "mmEZrQG4x1T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report  # Import from sklearn\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "validation_dataloader = tqdm(validation_dataloader, desc=\"Evaluation\")\n",
        "for batch in validation_dataloader:\n",
        "    b_input_ids = batch['input_ids'].to(device)\n",
        "    b_input_mask = batch['attention_mask'].to(device)\n",
        "    b_labels = batch['label'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predicted_labels = torch.argmax(logits, dim=1).flatten().tolist()\n",
        "    predictions.extend(predicted_labels)\n",
        "    true_labels.extend(b_labels.tolist())\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Accuracy on evaluation data: {accuracy}\")\n",
        "\n",
        "unique_labels = set(true_labels + predictions)\n",
        "if not unique_labels:\n",
        "    # If empty, assign a dummy label (e.g., 1) to one prediction\n",
        "    # This avoids the ValueError and provides a basic report\n",
        "    predictions[0] = 1\n",
        "    unique_labels = {0, 1} # Include 0 and 1 to the report\n",
        "\n",
        "\n",
        "predictions = [[str(p) for p in predictions]]\n",
        "true_labels = [[str(l) for l in true_labels]]\n",
        "\n",
        "\n",
        "# Generate the classification report, specifying labels argument\n",
        "report = classification_report(\n",
        "    true_labels[0],\n",
        "    predictions[0],\n",
        "    digits=4,\n",
        "    zero_division=1,\n",
        "    labels=[str(label) for label in sorted(list(unique_labels))]  # Pass the labels\n",
        ")\n",
        "\n",
        "print(report)\n",
        "\n",
        "seqeval_accuracy_score = seqeval_accuracy(true_labels, predictions)\n",
        "print(f\"Seqeval Accuracy: {seqeval_accuracy_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l8FqtVEcyLO",
        "outputId": "37ce2ce9-f433-4eaa-a9c7-87c8c0be7d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 66/66 [00:15<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on evaluation data: 0.7727708533077661\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6923    0.4752    0.5635       322\n",
            "           1     0.7944    0.9057    0.8464       721\n",
            "\n",
            "    accuracy                         0.7728      1043\n",
            "   macro avg     0.7434    0.6904    0.7050      1043\n",
            "weighted avg     0.7629    0.7728    0.7591      1043\n",
            "\n",
            "Seqeval Accuracy: 0.7727708533077661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}