{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNxtySwnWVJJjxPoRtwc3Cy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ef425ed511c484ca20c7c2cce4bc26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7898feeab49c4ae08c8ddabd203a7e9e",
              "IPY_MODEL_05848c75039e48a9ada5b1cd7145e3f3",
              "IPY_MODEL_1dde7d51727146fbadd6a0272d911597"
            ],
            "layout": "IPY_MODEL_026bdf81dcab407c9f9335c0f6a10776"
          }
        },
        "7898feeab49c4ae08c8ddabd203a7e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef0fc66bf6b4c77bdbf0dc21be1a305",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a49f3e4a3f4cd799f844d22a56fc99",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "05848c75039e48a9ada5b1cd7145e3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_997d60ba33ab4061a6131670d50722d3",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_704e1ea788f340ee8609f7c3e4629b27",
            "value": 19
          }
        },
        "1dde7d51727146fbadd6a0272d911597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1687f5b946574f8583ffa62f0459678b",
            "placeholder": "​",
            "style": "IPY_MODEL_16d648b0f7234ae5a2f90306bbeeaa90",
            "value": " 19/19 [17:24&lt;00:00, 43.11s/it]"
          }
        },
        "026bdf81dcab407c9f9335c0f6a10776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef0fc66bf6b4c77bdbf0dc21be1a305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a49f3e4a3f4cd799f844d22a56fc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "997d60ba33ab4061a6131670d50722d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704e1ea788f340ee8609f7c3e4629b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1687f5b946574f8583ffa62f0459678b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d648b0f7234ae5a2f90306bbeeaa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/HF_LOCAL_download-Mixtral-8x7B-Instruct-v0.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/hub/en/models-downloading\n",
        "\n",
        "https://huggingface.co/docs/huggingface_hub/en/guides/download"
      ],
      "metadata": {
        "id": "aDsST7tmr8O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes -q\n",
        "!pip install accelerate -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install colab-env --quiet"
      ],
      "metadata": {
        "id": "uv4Auls3wpOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNG1C3FoQT_t",
        "outputId": "e5d2d1e6-22a6-443e-a28d-51ba6b77d3f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 23 23:00:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              45W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtWLWHkl4P7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',readonly=False,force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/gdrive/MyDrive/model"
      ],
      "metadata": {
        "id": "Rp89BKfFmVlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOB27iShRdRM",
        "outputId": "c16ab950-2bac-466f-d060-65f17672d8f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "id": "MCkx3e7OuD9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437ac7ef-6a07-48d0-cacc-b25b4b98ac09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DONE\n",
        "#!git clone https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1"
      ],
      "metadata": {
        "id": "_hK0mxPQmzSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JXtw1Q-SSDF",
        "outputId": "684dc724-68e0-44d8-f83b-149814066ae8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkaUGgRSjqK",
        "outputId": "2bbdb889-a8fc-451d-b561-af4204fac281"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## firts\n",
        "#!git clone https://huggingface.co/abacusai/Smaug-72B-v0.1\"\n",
        "\n",
        "### second\n",
        "%cd /content/gdrive/MyDrive/model/\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "\n",
        "#152334H/miqu-1-70b-sf"
      ],
      "metadata": {
        "id": "ybtawC61uqdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!huggingface-cli download gpt2 config.json\n",
        "%cd /content/gdrive/MyDrive/model/\n",
        "!huggingface-cli download gpt2 config.json model.safetensors"
      ],
      "metadata": {
        "id": "G4NEx1WodpNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download()"
      ],
      "metadata": {
        "id": "CEmB1HlJmwEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nvidia/Llama3-ChatQA-1.5-70B\n",
        "\n",
        "https://huggingface.co/nvidia/Llama3-ChatQA-1.5-70B"
      ],
      "metadata": {
        "id": "uT2b8zTwKE0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id=\"nvidia/Llama3-ChatQA-1.5-70B\",local_dir=\"/content/gdrive/MyDrive/model/Llama3-ChatQA-1.5-70B\")\n"
      ],
      "metadata": {
        "id": "XIEGrBl-H-SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "abacusai/Smaug-72B-v0.1\n",
        "\n",
        "https://huggingface.co/abacusai/Smaug-72B-v0.1"
      ],
      "metadata": {
        "id": "5E1zlqGr6ZRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id=\"abacusai/Smaug-72B-v0.1\",local_dir=\"/content/gdrive/MyDrive/model/Smaug-72B-v0.1\")"
      ],
      "metadata": {
        "id": "qfeuwG5t6Pwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mistralai/Mixtral-8x7B-Instruct-v0.1"
      ],
      "metadata": {
        "id": "parMU8Rz6LTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",local_dir=\"/content/gdrive/MyDrive/model/\")"
      ],
      "metadata": {
        "id": "ccG2CQHOhPH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "#from transformers import FalconForCausalLM\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "IEIlcuJ0qMr_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "from transformers import AutoConfig"
      ],
      "metadata": {
        "id": "AfA3OakgwNyG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "\n",
        "model_id = '/content/gdrive/MyDrive/model/' ## mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "\n",
        "#model_id = '/content/gdrive/MyDrive/model/Smaug-72B-v0.1' ## NEED more than 40GB GPU\n",
        "\n",
        "#model_id = '/content/gdrive/MyDrive/model/Llama3-ChatQA-1.5-70B'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    #attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1ef425ed511c484ca20c7c2cce4bc26e",
            "7898feeab49c4ae08c8ddabd203a7e9e",
            "05848c75039e48a9ada5b1cd7145e3f3",
            "1dde7d51727146fbadd6a0272d911597",
            "026bdf81dcab407c9f9335c0f6a10776",
            "3ef0fc66bf6b4c77bdbf0dc21be1a305",
            "a1a49f3e4a3f4cd799f844d22a56fc99",
            "997d60ba33ab4061a6131670d50722d3",
            "704e1ea788f340ee8609f7c3e4629b27",
            "1687f5b946574f8583ffa62f0459678b",
            "16d648b0f7234ae5a2f90306bbeeaa90"
          ]
        },
        "id": "hHbQFdp3qx9J",
        "outputId": "c90390f9-ad47-4e24-d01b-e59b3cae368f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef425ed511c484ca20c7c2cce4bc26e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# load into pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "DPhG1wEsocjr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What was the first album Beyoncé released as a solo artist?\"\n",
        "#prompt=\"What is the capital of Russia?\"\n",
        "\n",
        "prompt=\"Can you explain the concepts of Quantum Computing?\"\n",
        "prompt = f\"Instruct: Answer the following question.\\n{prompt}\"\n",
        "\n",
        "#prompt = f\"Instruct: Answer the following question.\\n{prompt}\\nOutput:\\n\" # for dataset_squad2"
      ],
      "metadata": {
        "id": "2n1lYDUJpNA9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(prompt):\n",
        "  outputs = pipe(prompt, max_new_tokens=512, temperature=0.8, do_sample=True, top_k=50, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.eos_token_id)\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "PHl5Fpni0ZI1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = get_answer(prompt)"
      ],
      "metadata": {
        "id": "uwETUl-MF88I"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge Case #1"
      ],
      "metadata": {
        "id": "aN0myjP5GHB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: %s'%prompt)\n",
        "print()\n",
        "#print('Answer: %s \\nOutput:\\n'%outputs[0]['generated_text'])\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "#del outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4iywYT8GDkG",
        "outputId": "4dba4559-8184-48fb-d59b-da5122d45928"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Instruct: Answer the following question.\n",
            "Can you explain the concepts of Quantum Computing?\n",
            "\n",
            "Generated Answer:\n",
            "Answer: Quantum computing is a type of computation that uses quantum mechanics to perform operations on data. It differs from traditional computing, which uses bits to represent information and performs operations on those bits using classical logic gates.\n",
            "\n",
            "In quantum computing, data is represented using quantum bits, or qubits, which can exist in a superposition of states. This means that a qubit can be in a state of 0, 1, or both at the same time. This allows quantum computers to perform certain operations much faster than classical computers.\n",
            "\n",
            "One of the key concepts in quantum computing is the idea of quantum entanglement. When two qubits are entangled, their states are correlated in such a way that the state of one qubit cannot be described independently of the state of the other. This allows quantum computers to perform certain operations in parallel, which can greatly increase their computational power.\n",
            "\n",
            "Another important concept in quantum computing is the idea of quantum gates. Just as classical computers use logic gates to perform operations on bits, quantum computers use quantum gates to perform operations on qubits. However, quantum gates are more powerful than classical gates because they can manipulate the state of a qubit in many different ways.\n",
            "\n",
            "Quantum computing is still a relatively new and developing field, but it has the potential to revolutionize many areas of science and technology. It is already being used to solve complex problems in fields such as chemistry, materials science, and machine learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FIRST REASONING CASE"
      ],
      "metadata": {
        "id": "hAQNxpHu4NJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompt = \"I bought a computer for $900, sold it for $1200, repurchased it for $1300, and sold it again for $1600. how much did I earn? Take into consideration the money for the repurchased, too.\"\n",
        "outputs = get_answer(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78seJWMc1ic0",
        "outputId": "bdcf3286-24c1-4c13-9dfb-63b403860e2f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31.9 s, sys: 46.4 ms, total: 31.9 s\n",
            "Wall time: 31.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: %s'%prompt)\n",
        "print()\n",
        "#print('Answer: %s \\nOutput:\\n'%outputs[0]['generated_text'])\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
        "del outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk72zcDf2df_",
        "outputId": "e770927b-e79a-4ba9-f366-28c0b3976127"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: I bought a computer for $900, sold it for $1200, repurchased it for $1300, and sold it again for $1600. how much did I earn? Take into consideration the money for the repurchased, too.\n",
            "\n",
            "Generated Answer:\n",
            "Ok so here's what you should do:\n",
            "\n",
            "1. First calculate the profit from the first sale:\n",
            "$1200-$900=$300\n",
            "\n",
            "2. Next calculate the loss from the repurchase:\n",
            "$1300-$1200=$100\n",
            "\n",
            "3. Then calculate the profit from the second sale:\n",
            "$1600-$1300=$300\n",
            "\n",
            "4. Finally add the profit from the first sale and the second sale and subtract the loss from the repurchase:\n",
            "$300+$300-$100= $500\n",
            "\n",
            "So you earned $500.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECOND REASONING CASE"
      ],
      "metadata": {
        "id": "F3jOCx4Q32Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompt = \"I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\"\n",
        "outputs = get_answer(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmrD4ivI2FQP",
        "outputId": "130d6245-38b0-4420-8385-b07636303aa0",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.7 s, sys: 27.2 ms, total: 15.7 s\n",
            "Wall time: 15.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: %s'%prompt)\n",
        "print()\n",
        "#print('Answer: %s \\nOutput:\\n'%outputs[0]['generated_text'])\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rv6CwAU0vmU",
        "outputId": "f334902c-de9e-439a-fa55-c2d190dc3ee0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: I bought an ice cream for 6 kids. Each cone was $1.25 and I paid with a $10 bill. How many dollars did I get back? Explain first before answering.\n",
            "\n",
            "Generated Answer:\n",
            "There were 6 kids so 6 cones. 6 cones times $1.25 per cone equals $7.50. If I gave the man $10, then he would give me back $2.50. I got back around $2.50.\n",
            "\n",
            "Answer: $2.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge Case #2"
      ],
      "metadata": {
        "id": "e44xwHbv1jhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What was the first album Beyoncé released as a solo artist?\"\n",
        "#prompt=\"What is the capital of Russia?\"\n",
        "outputs = get_answer(prompt)\n"
      ],
      "metadata": {
        "id": "tfZCY6o9opna"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: %s'%prompt)\n",
        "print()\n",
        "#print('Answer: %s \\nOutput:\\n'%outputs[0]['generated_text'])\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_C1HoXRpUdR",
        "outputId": "20e27067-bb82-4704-a38c-d4572e15fbd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What was the first album Beyoncé released as a solo artist?\n",
            "\n",
            "Generated Answer:\n",
            "Beyoncé released her first solo album, Dangerously in Love, on 23 June 2003. The album debuted at number one on the Billboard 200 chart and sold 317,000 copies in its first week. It was certified 4x Platinum by the Recording Industry Association of America (RIAA) on 11 January 2004. The album spawned the hit singles \"Crazy in Love\", \"Baby Boy\", \"Me, Myself and I\", and \"Naughty Girl\", which all topped the Billboard Hot 100 chart.\n"
          ]
        }
      ]
    }
  ]
}