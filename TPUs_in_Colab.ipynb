{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQhfChLYVTg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUkXWG-baMUs"
      },
      "source": [
        "## Examples: neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ii_UPkG3gzP"
      },
      "source": [
        "We can use `jax.device_put` and `jax.jit`'s computation-follows-sharding features to parallelize computation in neural networks. Here are some simple examples, based on this basic neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEKF3zIF3vGU"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mocs3oGe3vGU"
      },
      "outputs": [],
      "source": [
        "def predict(params, inputs):\n",
        "  for W, b in params:\n",
        "    outputs = jnp.dot(inputs, W) + b\n",
        "    inputs = jnp.maximum(outputs, 0)\n",
        "  return outputs\n",
        "\n",
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  predictions = predict(params, inputs)\n",
        "  return jnp.mean(jnp.sum((predictions - targets)**2, axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glBB8tzW3vGU"
      },
      "outputs": [],
      "source": [
        "loss_jit = jax.jit(loss)\n",
        "gradfun = jax.jit(jax.grad(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0x62AIa3vGU"
      },
      "outputs": [],
      "source": [
        "def init_layer(key, n_in, n_out):\n",
        "  k1, k2 = jax.random.split(key)\n",
        "  W = jax.random.normal(k1, (n_in, n_out)) / jnp.sqrt(n_in)\n",
        "  b = jax.random.normal(k2, (n_out,))\n",
        "  return W, b\n",
        "\n",
        "def init_model(key, layer_sizes, batch_size):\n",
        "  key, *keys = jax.random.split(key, len(layer_sizes))\n",
        "  params = list(map(init_layer, keys, layer_sizes[:-1], layer_sizes[1:]))\n",
        "\n",
        "  key, *keys = jax.random.split(key, 3)\n",
        "  inputs = jax.random.normal(keys[0], (batch_size, layer_sizes[0]))\n",
        "  targets = jax.random.normal(keys[1], (batch_size, layer_sizes[-1]))\n",
        "\n",
        "  return params, (inputs, targets)\n",
        "\n",
        "layer_sizes = [784, 8192, 8192, 8192, 10]\n",
        "batch_size = 8192\n",
        "\n",
        "params, batch = init_model(jax.random.key(0), layer_sizes, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJv_h0AS2drh"
      },
      "source": [
        "### 8-way batch data parallelism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJLqRPpSDX0i"
      },
      "outputs": [],
      "source": [
        "mesh = jax.make_mesh((8,), ('batch',))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q5NbdOn3vGV"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import NamedSharding, PartitionSpec as P\n",
        "\n",
        "sharding = NamedSharding(mesh, P('batch'))\n",
        "replicated_sharding = NamedSharding(mesh, P())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KC6ieEe3vGV"
      },
      "outputs": [],
      "source": [
        "batch = jax.device_put(batch, sharding)\n",
        "params = jax.device_put(params, replicated_sharding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUb-QE2b3vGV",
        "outputId": "81a545b5-1d24-40bb-e689-70d29b4caf84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(33.335655, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "loss_jit(params, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUkw0u413vGV",
        "outputId": "15f516ca-0b2b-49a8-b370-ce21d7de68ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.856516\n"
          ]
        }
      ],
      "source": [
        "step_size = 1e-5\n",
        "\n",
        "for _ in range(30):\n",
        "  grads = gradfun(params, batch)\n",
        "  params = [(W - step_size * dW, b - step_size * db)\n",
        "            for (W, b), (dW, db) in zip(params, grads)]\n",
        "\n",
        "print(loss_jit(params, batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paCw6Zaj3vGV",
        "outputId": "c3c08019-7d6d-47e9-e245-8668eb9e637d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53.4 ms ± 34.2 µs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 5 -r 5 gradfun(params, batch)[0][0].block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF86UWpg3vGV"
      },
      "outputs": [],
      "source": [
        "batch_single = jax.device_put(batch, jax.devices()[0])\n",
        "params_single = jax.device_put(params, jax.devices()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1wgUKXk3vGV",
        "outputId": "afc240fa-70f3-4301-a103-30cc8b8cd1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "407 ms ± 190 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 5 -r 5 gradfun(params_single, batch_single)[0][0].block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AjeeB7B4NP6"
      },
      "source": [
        "### 4-way batch data parallelism and 2-way model tensor parallelism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1hxOfgRDwo0"
      },
      "outputs": [],
      "source": [
        "mesh = jax.make_mesh((4, 2), ('batch', 'model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "sgIWCjJK3vGW",
        "outputId": "6773f888-64c9-4358-a2c2-5a7b265658a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,1\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mTPU 2,3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mTPU 6,7\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mTPU 4,5\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\"> TPU 0,1 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\"> TPU 2,3 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\"> TPU 6,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\"> TPU 4,5 </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,1\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mTPU 2,3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mTPU 6,7\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mTPU 4,5\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\"> TPU 0,1 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\"> TPU 2,3 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\"> TPU 6,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\"> TPU 4,5 </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch = jax.device_put(batch, NamedSharding(mesh, P('batch', None)))\n",
        "jax.debug.visualize_array_sharding(batch[0])\n",
        "jax.debug.visualize_array_sharding(batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9PQP-0eEAO6"
      },
      "outputs": [],
      "source": [
        "replicated_sharding = NamedSharding(mesh, P())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqCjYCgg3vGW"
      },
      "outputs": [],
      "source": [
        "(W1, b1), (W2, b2), (W3, b3), (W4, b4) = params\n",
        "\n",
        "W1 = jax.device_put(W1, replicated_sharding)\n",
        "b1 = jax.device_put(b1, replicated_sharding)\n",
        "\n",
        "W2 = jax.device_put(W2, NamedSharding(mesh, P(None, 'model')))\n",
        "b2 = jax.device_put(b2, NamedSharding(mesh, P('model')))\n",
        "\n",
        "W3 = jax.device_put(W3, NamedSharding(mesh, P('model', None)))\n",
        "b3 = jax.device_put(b3, replicated_sharding)\n",
        "\n",
        "W4 = jax.device_put(W4, replicated_sharding)\n",
        "b4 = jax.device_put(b4, replicated_sharding)\n",
        "\n",
        "params = (W1, b1), (W2, b2), (W3, b3), (W4, b4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "_lSJ63sh3vGW",
        "outputId": "6412d2ec-c11c-4fb9-e795-5c0397f35138"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,2,4,6\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 1,3,5,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">TPU 0,2,4,6 TPU 1,3,5,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "jax.debug.visualize_array_sharding(W2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "fxkfWYkk3vGW",
        "outputId": "7be76ef1-423e-4ff4-9c65-9205a4d201e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,2,4,6\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 1,3,5,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">       TPU 0,2,4,6       </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">       TPU 1,3,5,7       </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "jax.debug.visualize_array_sharding(W3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPCVs-_k3vGW",
        "outputId": "eeca33c6-5ae5-4699-db45-3329d6d8b1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.856519\n"
          ]
        }
      ],
      "source": [
        "print(loss_jit(params, batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9JebLK_3vGW"
      },
      "outputs": [],
      "source": [
        "step_size = 1e-5\n",
        "\n",
        "for _ in range(30):\n",
        "    grads = gradfun(params, batch)\n",
        "    params = [(W - step_size * dW, b - step_size * db)\n",
        "              for (W, b), (dW, db) in zip(params, grads)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Sbl69e3vGX",
        "outputId": "59a85aeb-dc14-49a7-f61a-8cb1b03a3c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.848966\n"
          ]
        }
      ],
      "source": [
        "print(loss_jit(params, batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "lkAF0dAb3vGX",
        "outputId": "821a70e2-7346-4a65-c5b9-d83692423ddb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,2,4,6\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 1,3,5,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">TPU 0,2,4,6 TPU 1,3,5,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                        </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,2,4,6\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 1,3,5,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m       \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">       TPU 0,2,4,6       </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">       TPU 1,3,5,7       </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "(W1, b1), (W2, b2), (W3, b3), (W4, b4) = params\n",
        "jax.debug.visualize_array_sharding(W2)\n",
        "jax.debug.visualize_array_sharding(W3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Npor3i3vGX",
        "outputId": "319d0f58-4653-4759-f696-01151d96111c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51.6 ms ± 530 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 10 -r 10 gradfun(params, batch)[0][0].block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTfoXNnxFYDJ"
      },
      "source": [
        "### Generating random numbers\n",
        "\n",
        "JAX comes with a functional, deterministic [random number generator](https://jax.readthedocs.io/en/latest/jep/263-prng.html). It underlies the various sampling functions in the [`jax.random` module](https://jax.readthedocs.io/en/latest/jax.random.html), such as `jax.random.uniform`.\n",
        "\n",
        "JAX's random numbers are produced by a counter-based PRNG, so in principle, random number generation should be a pure map over counter values. A pure map is a trivially partitionable operation in principle. It should require no cross-device communication, nor any redundant computation across devices.\n",
        "\n",
        "However, the existing stable RNG implementation is not automatically partitionable, for historical reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht_zYFVXNrjN"
      },
      "source": [
        "Consider the following example, where a function draws random uniform numbers and adds them to the input, elementwise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwS-aQE_3vGX"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import Mesh # Import the Mesh class from the correct module\n",
        "from jax.sharding import NamedSharding, PartitionSpec as P\n",
        "\n",
        "@jax.jit\n",
        "def f(key, x):\n",
        "  numbers = jax.random.uniform(key, x.shape)\n",
        "  return x + numbers\n",
        "\n",
        "key = jax.random.key(42)\n",
        "mesh = Mesh(jax.devices(), 'x')\n",
        "x_sharding = NamedSharding(mesh, P('x'))\n",
        "x = jax.device_put(jnp.arange(24), x_sharding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgSA9x9NLMaP"
      },
      "source": [
        "On a partitioned input, the function `f` produces output that is also partitioned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Oi97rpLz3vGY",
        "outputId": "f9976f5e-0671-493e-e728-d9ebb559e7e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107mTPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82mTPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mTPU 3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148mTPU 4\u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207mTPU 5\u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148mTPU 6\u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49mTPU 7\u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m         \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  TPU 0  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">  TPU 1  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">  TPU 2  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">  TPU 3  </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">  TPU 4  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">  TPU 5  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">  TPU 6  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">  TPU 7  </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "jax.debug.visualize_array_sharding(f(key, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnjlWDUYLkp6"
      },
      "source": [
        "But if we inspect the compiled computation for `f` on this partitioned input, we see that it does involve some communication:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64wIZuSJ3vGY",
        "outputId": "5eb315de-edba-416a-877b-d934f3123091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communicating? False\n"
          ]
        }
      ],
      "source": [
        "f_exe = f.lower(key, x).compile()\n",
        "print('Communicating?', 'collective-permute' in f_exe.as_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXp9i8fbL8DD"
      },
      "source": [
        "One way to work around this is to configure JAX with the experimental upgrade flag `jax_threefry_partitionable`. With the flag on, the \"collective permute\" operation is now gone from the compiled computation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I7bqxA63vGY",
        "outputId": "e87b0c78-9e92-43bb-d2ed-3f8346f1496c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communicating? False\n"
          ]
        }
      ],
      "source": [
        "jax.config.update('jax_threefry_partitionable', True)\n",
        "f_exe = f.lower(key, x).compile()\n",
        "print('Communicating?', 'collective-permute' in f_exe.as_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV8ZccM5SXOU"
      },
      "source": [
        "The output is still partitioned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "zHPJzdn23vGY",
        "outputId": "a23c3bb9-b793-41d6-85f0-80eb5648d732"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107mTPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82mTPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mTPU 3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148mTPU 4\u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207mTPU 5\u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148mTPU 6\u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49mTPU 7\u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m         \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  TPU 0  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">  TPU 1  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">  TPU 2  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">  TPU 3  </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">  TPU 4  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">  TPU 5  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">  TPU 6  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">  TPU 7  </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "jax.debug.visualize_array_sharding(f(key, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaK--hPmSPpV"
      },
      "source": [
        "One caveat to the `jax_threefry_partitionable` option, however, is that _the random values produced may be different than without the flag set_, even though they were generated by the same random key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBUHBBal3vGY",
        "outputId": "d21024f2-5c24-4f48-a01c-1c6669139919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stable:\n",
            "[ 0.72503686  1.8532515   2.983416    3.083253    4.0332246   5.4782867\n",
            "  6.1720605   7.6900277   8.602836    9.810046   10.861367   11.907651\n",
            " 12.330483   13.456195   14.808557   15.960099   16.067581   17.739723\n",
            " 18.335474   19.46401    20.390276   21.116539   22.858128   23.223194  ]\n",
            "\n",
            "Partitionable:\n",
            "[ 0.48870957  1.6797972   2.6162715   3.561016    4.4506445   5.585866\n",
            "  6.0748096   7.775133    8.698959    9.818634   10.350306   11.87282\n",
            " 12.925881   13.86013    14.477554   15.818481   16.711355   17.586697\n",
            " 18.073738   19.777622   20.404566   21.119123   22.026257   23.63918   ]\n"
          ]
        }
      ],
      "source": [
        "jax.config.update('jax_threefry_partitionable', False)\n",
        "print('Stable:')\n",
        "print(f(key, x))\n",
        "print()\n",
        "\n",
        "jax.config.update('jax_threefry_partitionable', True)\n",
        "print('Partitionable:')\n",
        "print(f(key, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM with TPU"
      ],
      "metadata": {
        "id": "b9X8DmY-Ayms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"You seem to be using the pipelines sequentially on GPU\")\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "XWUS_LAGBmoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_hub --upgrade --quiet\n",
        "!pip install tensorflow --quiet\n",
        "!pip install datasets -q\n",
        "!pip install opencv-python-headless -q\n",
        "!pip install tf-keras -q\n",
        "!pip install -U transformers --quiet\n",
        "\n",
        "#!pip install tensorflow_text==2.11  -q # replace 2.11 with your tensorflow version"
      ],
      "metadata": {
        "id": "phsGzgzckuKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall tensorflow_text -q\n",
        "!apt-get update && apt-get install -y libstdc++6  # For Debian/Ubuntu-based systems"
      ],
      "metadata": {
        "id": "LwNMiJ0H1a7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import jax\n",
        "\n",
        "devices = jax.devices()\n",
        "\n",
        "for device in devices:\n",
        "    if device.platform == 'tpu':\n",
        "        print(\"TPU detected!\")\n",
        "        break\n",
        "else:\n",
        "    print(\"No TPU detected.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QwRUq7fD-KiO",
        "outputId": "93f035b8-bead-4a28-ad7f-802751be2f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU detected!\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\" # or \"torch\", or \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_hub\n",
        "model = keras_hub.models.Llama3CausalLM.from_preset(\n",
        "    \"hf://meta-llama/Llama-3.2-1B-Instruct\", dtype=\"bfloat16\"\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "e8BLk2DIN3p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate(\"Hi there!\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9TveRDmcR0mJ",
        "outputId": "32c19518-3958-4b63-92c0-04e5216939f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! I'm excited to connect with you!\n",
            "\n",
            "Before I start chatting, I'd love to know a bit more about you!\n",
            "\n",
            "Could you please share:\n",
            "\n",
            "1. Your name\n",
            "2. Where you're from (city or town)\n",
            "3. What do you like to do in your free time\n",
            "4. What kind of music do you enjoy listening to\n",
            "5. Are there any hobbies or interests that you're particularly passionate about\n",
            "\n",
            "Once I have this information, I'll do my best to provide you with personalized recommendations and advice!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "UlipGfwhFK66"
      }
    },
    {
      "source": [
        "# --- Data Preparation (Flight Planning Focus) ---\n",
        "\n",
        "# Define necessary lists\n",
        "airports = [\"JFK\", \"LAX\", \"LGA\", \"BOS\", \"SFO\", \"ORD\", \"DFW\", \"ATL\", \"SEA\", \"MIA\", \"DEN\", \"IAH\", \"MSP\", \"DTW\", \"PHX\", \"CLT\", \"LAS\", \"MCO\", \"EWR\", \"PHL\"]\n",
        "aircraft_types = [\"Boeing 747\", \"Airbus A320\", \"Boeing 777\", \"Boeing 737\", \"Airbus A330\", \"Boeing 757\", \"Airbus A321\", \"Airbus A319\", \"Boeing 787\", \"Embraer E190\"]\n",
        "weather_conditions = [\"Clear\", \"Cloudy\", \"Rainy\", \"Snowy\", \"Windy\"]\n",
        "\n",
        "flight_data = []\n",
        "# Function to create a flight data point\n",
        "def create_flight_data_point(origin, destination, departure_date, aircraft, weather):\n",
        "    return {\n",
        "        \"input\": f\"Plan a flight from {origin} to {destination}. Departure: {departure_date}, Aircraft: {aircraft}, Weather: {weather}\",\n",
        "        \"output\": \"{'route': [], 'altitude': [], 'airspeed': [], 'fuel': []}\"  # Placeholder for output\n",
        "    }\n",
        "\n",
        "number_routes = 100\n",
        "# Generate more flight data points\n",
        "import random\n",
        "for _ in range(number_routes):  # Generate 90 more examples\n",
        "    origin = random.choice(airports)\n",
        "    destination = random.choice(airports)\n",
        "    while origin == destination:  # Ensure origin and destination are different\n",
        "        destination = random.choice(airports)\n",
        "    departure_date = f\"2024-{random.randint(1, 12):02}-{random.randint(1, 28):02}\"\n",
        "    aircraft = random.choice(aircraft_types)\n",
        "    weather = random.choice(weather_conditions)\n",
        "    flight_data.append(create_flight_data_point(origin, destination, departure_date, aircraft, weather))\n",
        "\n",
        "for _ in range(number_routes):  # Generate 90 more examples\n",
        "    origin = random.choice(airports)\n",
        "    destination = random.choice(airports)\n",
        "    while origin == destination:  # Ensure origin and destination are different\n",
        "        destination = random.choice(airports)\n",
        "    departure_date = f\"2024-{random.randint(1, 12):02}-{random.randint(1, 28):02}\"\n",
        "    aircraft = random.choice(aircraft_types)\n",
        "    weather = random.choice(weather_conditions)\n",
        "    flight_data.append(create_flight_data_point(origin, destination, departure_date, aircraft, weather))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VGoU0_KluoIS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "flight_dataset = Dataset.from_list(flight_data)\n",
        "print(flight_dataset)"
      ],
      "metadata": {
        "id": "aTWJx_xMwjpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install --upgrade transformers -q\n",
        "!pip install --upgrade datasets -q\n",
        "!pip install --upgrade optax -q\n",
        "!pip install flax -q\n",
        "\n",
        "import os\n",
        "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import Mesh, NamedSharding, PartitionSpec as P\n",
        "from transformers import AutoTokenizer, TrainingArguments, FlaxAutoModelForCausalLM  # Import FlaxAutoModelForCausalLM\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"You seem to be using the pipelines sequentially on GPU\")\n",
        "\n",
        "import optax\n",
        "from flax.training import train_state  # Import train_state\n",
        "\n",
        "# --- TPU Detection ---\n",
        "devices = jax.devices()\n",
        "for device in devices:\n",
        "    if device.platform == 'tpu':\n",
        "        print(\"TPU detected!\")\n",
        "        break\n",
        "else:\n",
        "    print(\"No TPU detected.\")\n",
        "\n",
        "print('\\n\\n')\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"JAX devices:\", jax.devices())\n",
        "print(\"Num devices:\", jax.device_count())\n",
        "print('\\n\\n')\n",
        "\n",
        "# Ensure that JAX sees the TPU:\n",
        "try:\n",
        "    jax.devices(\"tpu\")[0]\n",
        "except RuntimeError:\n",
        "    print(\"Warning: TPU not found. Code will run on CPU or GPU.\")\n",
        "\n",
        "# Model identifier\n",
        "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "import gc; gc.collect()\n",
        "\n",
        "# --- Data Preparation ---\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "airports = [\"JFK\", \"LAX\", \"LGA\", \"BOS\", \"SFO\", \"ORD\", \"DFW\", \"ATL\", \"SEA\", \"MIA\", \"DEN\", \"IAH\", \"MSP\", \"DTW\", \"PHX\", \"CLT\", \"LAS\", \"MCO\", \"EWR\", \"PHL\"]\n",
        "aircraft_types = [\"Boeing 747\", \"Airbus A320\", \"Boeing 777\", \"Boeing 737\", \"Airbus A330\", \"Boeing 757\", \"Airbus A321\", \"Airbus A319\", \"Boeing 787\", \"Embraer E190\"]\n",
        "weather_conditions = [\"Clear\", \"Cloudy\", \"Rainy\", \"Snowy\", \"Windy\"]\n",
        "\n",
        "flight_data = []\n",
        "\n",
        "def create_flight_data_point(origin, destination, departure_date, aircraft, weather):\n",
        "    return {\n",
        "        \"input\": f\"Plan a flight from {origin} to {destination}. Departure: {departure_date}, Aircraft: {aircraft}, Weather: {weather}\",\n",
        "        \"output\": \"{'route': [], 'altitude': [], 'airspeed': [], 'fuel': []}\"\n",
        "    }\n",
        "\n",
        "number_routes = 100\n",
        "for _ in range(number_routes * 2):\n",
        "    origin = random.choice(airports)\n",
        "    destination = random.choice(airports)\n",
        "    while origin == destination:\n",
        "        destination = random.choice(airports)\n",
        "    departure_date = f\"2024-{random.randint(1, 12):02}-{random.randint(1, 28):02}\"\n",
        "    aircraft = random.choice(aircraft_types)\n",
        "    weather = random.choice(weather_conditions)\n",
        "    flight_data.append(create_flight_data_point(origin, destination, departure_date, aircraft, weather))\n",
        "\n",
        "flight_dataset = Dataset.from_list(flight_data)\n",
        "\n",
        "\n",
        "# Tokenize and format the data\n",
        "def tokenize_function(examples):\n",
        "    inputs = examples['input']\n",
        "    outputs = examples['output']\n",
        "    tokenized_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=128)\n",
        "    tokenized_outputs = tokenizer(outputs, padding=\"max_length\", truncation=True, max_length=128)\n",
        "    return {\n",
        "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n",
        "        \"labels\": tokenized_outputs[\"input_ids\"]\n",
        "    }\n",
        "\n",
        "tokenized_dataset = flight_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# --- TPU Configuration and Sharding ---\n",
        "mesh = Mesh(jax.devices('tpu'), ('data',))\n",
        "data_sharding = NamedSharding(mesh, P('data',))\n",
        "\n",
        "import json  # Import the json module\n",
        "\n",
        "def prepare_data_for_jax(batch):\n",
        "    return {\n",
        "        key: jax.device_put(jnp.array(value, dtype=jnp.bfloat16), data_sharding)  # Change dtype to jnp.bfloat16 for all inputs\n",
        "        if key in [\"input_ids\", \"attention_mask\", \"labels\"] else value\n",
        "        for key, value in batch.items() if key in [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    }\n",
        "\n",
        "def loss_fn(batch):\n",
        "    labels = batch.pop(\"labels\")\n",
        "    # Filter batch for valid model inputs and convert to JAX arrays\n",
        "    # Instead of model.input_names, directly specify the expected inputs\n",
        "    model_inputs = {\n",
        "        \"token_ids\": batch['input_ids'][jnp.newaxis, ...],  # Add a batch dimension\n",
        "        \"padding_mask\": batch['attention_mask'][jnp.newaxis, ...]  # Add a batch dimension\n",
        "    }\n",
        "    # The model likely returns the logits directly, not in a dictionary\n",
        "    logits = model(model_inputs)  # Access the logits directly\n",
        "\n",
        "    # Remove or comment out the line converting labels to float32\n",
        "    # labels = labels.astype(jnp.float32)\n",
        "\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "        logits=logits.reshape((-1, logits.shape[-1])), labels=labels.reshape((-1,))\n",
        "    ).mean()\n",
        "    return loss\n",
        "\n",
        "# --- Fine-Tuning ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=128,\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"adamw_8bit\",\n",
        "    save_steps=500,\n",
        "    logging_steps=250,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    tpu_num_cores=8,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "from tqdm import tqdm  # Import tqdm\n",
        "\n",
        "for epoch in range(training_args.num_train_epochs):\n",
        "    # Create a tqdm progress bar for each epoch\n",
        "    with tqdm(tokenized_dataset, unit=\"batch\", desc=f\"Epoch {epoch + 1}/{training_args.num_train_epochs}\") as pbar:\n",
        "        for batch in pbar:\n",
        "            batch = prepare_data_for_jax(batch)\n",
        "\n",
        "            # Calculate loss and gradients using jax.value_and_grad\n",
        "            loss, grads = jax.value_and_grad(loss_fn)(batch)\n",
        "\n",
        "            # Update the progress bar with loss information\n",
        "            pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "\n",
        "\n",
        "# Save the fine-tuned model\n",
        "#model.save_pretrained(\"./fine_tuned_llama\", params=state.params) # Commented out as `state` is not defined"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "PETVJzgWggB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QUkXWG-baMUs",
        "OTfoXNnxFYDJ"
      ],
      "gpuType": "V28",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}