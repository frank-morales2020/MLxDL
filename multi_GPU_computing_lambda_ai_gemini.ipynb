{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObppnuGheDYomSXwFDSUWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/multi_GPU_computing_lambda_ai_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNLJP4lCeSjr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda\n",
        "import math\n",
        "import time\n",
        "from scipy.stats import norm # For Black-Scholes comparison\n",
        "from tqdm import tqdm # Import tqdm\n",
        "import sys # Import sys for exiting\n",
        "import os # Import os to get environment variables\n",
        "import google.generativeai as genai # Import the Gemini client library\n",
        "\n",
        "# --- Option Parameters ---\n",
        "S0 = 100.0  # Start Price\n",
        "K = 100.0   # Strike Price\n",
        "r = 0.02    # Risk-free Interest Rate\n",
        "sigma = 0.20  # Volatility\n",
        "T = 1.0     # Time to Maturity (years)\n",
        "N_STEPS = 100 # Number of Time Steps\n",
        "N_SIMULATIONS = 1_000_000\n",
        "#N_SIMULATIONS = 1_00\n",
        "\n",
        "# --- Numba CUDA Kernel ---\n",
        "@cuda.jit\n",
        "def monte_carlo_option_kernel(s0, k, r, sigma, dt, n_steps, paths_device, payoffs_device):\n",
        "    \"\"\"\n",
        "    CUDA kernel to simulate stock paths and calculate option payoffs.\n",
        "    Each thread simulates one path.\n",
        "    \"\"\"\n",
        "    # Get the index of the current thread (which corresponds to a simulation path)\n",
        "    tid = cuda.grid(1)\n",
        "\n",
        "    # Only process if the thread index is within the number of simulations\n",
        "    # We use payoffs_device.shape[0] here as the upper bound\n",
        "    if tid < payoffs_device.shape[0]:\n",
        "        s_t = s0\n",
        "        # Use the pre-generated random numbers specific to this path\n",
        "        path_random_numbers = paths_device[tid, :]\n",
        "\n",
        "        # Simulate the stock price path using Geometric Brownian Motion\n",
        "        for i in range(n_steps):\n",
        "            diffusion_term = sigma * math.sqrt(dt) * path_random_numbers[i]\n",
        "            drift_term = (r - 0.5 * sigma**2) * dt\n",
        "            log_return = drift_term + diffusion_term\n",
        "            s_t = s_t * math.exp(log_return)\n",
        "\n",
        "        # Calculate the payoff at maturity T\n",
        "        payoff = max(0.0, s_t - k)\n",
        "\n",
        "        # Store the calculated payoff for this path\n",
        "        payoffs_device[tid] = payoff\n",
        "\n",
        "# --- CPU Monte Carlo Function (for comparison) ---\n",
        "def monte_carlo_option_cpu(s0, k, r, sigma, t, n_steps, n_simulations):\n",
        "    dt = t / n_steps\n",
        "    total_payoff = 0.0\n",
        "\n",
        "    # Wrap the range with tqdm for a progress bar\n",
        "    for i in tqdm(range(n_simulations), desc=\"CPU Simulation\"):\n",
        "        s_t = s0\n",
        "        random_numbers = np.random.standard_normal(n_steps)\n",
        "        for j in range(n_steps):\n",
        "            s_t = s_t * np.exp((r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * random_numbers[j])\n",
        "\n",
        "        payoff = max(0.0, s_t - k)\n",
        "        total_payoff += payoff\n",
        "\n",
        "    # Discount the average payoff back to present value\n",
        "    option_price = (total_payoff / n_simulations) * np.exp(-r * t)\n",
        "    return option_price\n",
        "\n",
        "# --- Black-Scholes Formula (for theoretical benchmark) ---\n",
        "def black_scholes_price(S, K, T, r, sigma):\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    call_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "    return call_price\n",
        "\n",
        "# --- Main Execution ---\n",
        "print(\"----------------------------------------\")\n",
        "print(\"European Call Option Pricing using Monte Carlo Simulation (Corrected)\")\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "# --- Detect and print number of GPUs ---\n",
        "gpu_available = cuda.detect()\n",
        "if gpu_available:\n",
        "    try:\n",
        "        # Try the potentially newer count_devices first (though traceback suggests it's not there)\n",
        "        gpu_count = cuda.count_devices()\n",
        "    except AttributeError:\n",
        "        # Fallback for older versions using list_devices\n",
        "        print(\"cuda.count_devices() not found, falling back to len(list(cuda.list_devices()))\")\n",
        "        gpu_count = len(list(cuda.list_devices()))\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred detecting GPUs: {e}\")\n",
        "        gpu_count = 0 # Assume 0 if detection fails unexpectedly\n",
        "\n",
        "    print(f\"Number of CUDA capable GPUs detected: {gpu_count}\")\n",
        "else:\n",
        "    print(\"No CUDA capable GPU detected. GPU calculation will not run.\")\n",
        "    gpu_count = 0 # Ensure gpu_count is set even if no GPU\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "# --- Check if GPU is available for GPU calculation block ---\n",
        "run_gpu_calculation = gpu_available and gpu_count > 0\n",
        "\n",
        "print(f\"Number of Simulations: {N_SIMULATIONS:,}\")\n",
        "print(f\"Start Price: {S0:.2f}\")\n",
        "print(f\"Strike Price: {K:.2f}\")\n",
        "print(f\"Expected Return (mu): {r:.2f}\") # Using r as drift proxy for printing consistency\n",
        "print(f\"Volatility (sigma): {sigma:.2f}\")\n",
        "print(f\"Time to Maturity (T): {T:.2f} years\")\n",
        "print(f\"Number of Time Steps: {N_STEPS}\")\n",
        "print(f\"Risk-free Interest Rate (r): {r:.2f}\")\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "# --- CPU Calculation ---\n",
        "start_time_cpu = time.time()\n",
        "option_price_cpu = monte_carlo_option_cpu(S0, K, r, sigma, T, N_STEPS, N_SIMULATIONS)\n",
        "end_time_cpu = time.time()\n",
        "cpu_time = end_time_cpu - start_time_cpu\n",
        "\n",
        "print(f\"Option Price (CPU): {option_price_cpu:.4f}\")\n",
        "print(f\"Execution Time (CPU): {cpu_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "# --- GPU Calculation ---\n",
        "gpu_time = None # Initialize GPU time to None\n",
        "option_price_gpu = None # Initialize GPU price to None\n",
        "speedup = None # Initialize speedup to None\n",
        "\n",
        "if run_gpu_calculation:\n",
        "    dt = T / N_STEPS\n",
        "    # Generate all random numbers needed on the CPU first\n",
        "    # Shape is (N_SIMULATIONS, N_STEPS)\n",
        "    # Use float64 matching numpy default and standard for financial calcs\n",
        "    random_numbers_cpu = np.random.standard_normal((N_SIMULATIONS, N_STEPS)).astype(np.float64)\n",
        "\n",
        "    # Determine kernel launch configuration\n",
        "    threads_per_block = 512 # Common choice, can be tuned\n",
        "    # Calculate the required number of blocks\n",
        "    blocks_per_grid = (N_SIMULATIONS + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "    print(f\"\\nLaunching GPU kernel with {blocks_per_grid} blocks and {threads_per_block} threads per block ({blocks_per_grid * threads_per_block:,} total threads)...\")\n",
        "\n",
        "    # Allocate device memory and transfer data\n",
        "    random_numbers_device = cuda.to_device(random_numbers_cpu)\n",
        "    # Allocate space for payoffs on the device\n",
        "    payoffs_device = cuda.device_array(N_SIMULATIONS, dtype=np.float64)\n",
        "\n",
        "    start_time_gpu = time.time()\n",
        "\n",
        "    # Launch the CUDA kernel\n",
        "    # Pass the launch configuration (blocks_per_grid, threads_per_block) before arguments\n",
        "    monte_carlo_option_kernel[blocks_per_grid, threads_per_block](\n",
        "        S0, K, r, sigma, dt, N_STEPS, random_numbers_device, payoffs_device\n",
        "    )\n",
        "\n",
        "    # Synchronize device to ensure kernel completes before stopping timer\n",
        "    cuda.synchronize()\n",
        "\n",
        "    end_time_gpu = time.time()\n",
        "    gpu_time = end_time_gpu - start_time_gpu\n",
        "\n",
        "    # Transfer payoffs back to host (CPU)\n",
        "    payoffs_cpu = payoffs_device.copy_to_host()\n",
        "\n",
        "    # Calculate the final option price on the CPU (summation/average)\n",
        "    total_payoff_gpu = np.sum(payoffs_cpu)\n",
        "    option_price_gpu = (total_payoff_gpu / N_SIMULATIONS) * np.exp(-r * T)\n",
        "\n",
        "    print(f\"Option Price (GPU): {option_price_gpu:.4f}\")\n",
        "    print(f\"Execution Time (GPU): {gpu_time:.4f} seconds\")\n",
        "\n",
        "    # --- Speedup Calculation ---\n",
        "    speedup = cpu_time / gpu_time if gpu_time is not None and gpu_time > 0 else float('inf')\n",
        "    print(f\"Speedup (CPU vs. GPU): {speedup:.2f}x\")\n",
        "\n",
        "    print(\"----------------------------------------\")\n",
        "    print(\"Device used for calculations: GPU (via Numba CUDA kernel)\")\n",
        "\n",
        "else:\n",
        "    # If no GPU was detected or available\n",
        "    print(\"\\nGPU calculation skipped because no CUDA capable GPU was detected or available.\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "\n",
        "# --- Black-Scholes Comparison ---\n",
        "black_scholes = black_scholes_price(S0, K, T, r, sigma)\n",
        "print(f\"Option Price (Black-Scholes): {black_scholes:.4f}\")\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "\n",
        "# --- Section to send results to Gemini LLM ---\n",
        "print(\"\\n--- Sending Results to Gemini LLM for Analysis ---\")\n",
        "\n",
        "# Configure the Gemini API - Get API key from environment variable\n",
        "# Make sure you have set the GOOGLE_API_KEY environment variable\n",
        "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "if not api_key:\n",
        "    print(\"Error: GEMINI_API_KEY environment variable not set.\")\n",
        "    print(\"Skipping LLM analysis.\")\n",
        "else:\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # Construct the prompt using collected results\n",
        "        prompt_parts = [\n",
        "            \"Analyze the following performance and pricing results from a Monte Carlo European Call Option simulation:\",\n",
        "            \"\", # Add a blank line for readability in prompt\n",
        "            f\"Detected CUDA Capable GPUs: {gpu_count}\",\n",
        "            f\"Number of Simulations: {N_SIMULATIONS:,}\",\n",
        "            f\"Number of Time Steps: {N_STEPS}\",\n",
        "            f\"Option Parameters: S0={S0}, K={K}, r={r}, sigma={sigma}, T={T}\",\n",
        "            \"\", # Blank line\n",
        "            f\"CPU Execution Time: {cpu_time:.4f} seconds\",\n",
        "            f\"Monte Carlo Price (CPU): {option_price_cpu:.4f}\",\n",
        "            \"\", # Blank line\n",
        "        ]\n",
        "\n",
        "        if run_gpu_calculation:\n",
        "             prompt_parts.extend([\n",
        "                f\"GPU Execution Time: {gpu_time:.4f} seconds\",\n",
        "                f\"Monte Carlo Price (GPU): {option_price_gpu:.4f}\",\n",
        "                f\"Speedup (CPU vs. GPU): {speedup:.2f}x\",\n",
        "                f\"Device used for calculations: GPU (via Numba CUDA kernel)\",\n",
        "                \"\", # Blank line\n",
        "            ])\n",
        "\n",
        "        prompt_parts.extend([\n",
        "            f\"Black-Scholes Price (Benchmark): {black_scholes:.4f}\",\n",
        "            \"\", # Blank line\n",
        "            \"Please provide an analysis focusing on:\",\n",
        "            \"1. The significance of the detected GPU count in the context of the run.\",\n",
        "            \"2. The comparison between CPU and GPU execution times and the resulting speedup, commenting on the effectiveness of GPU acceleration.\",\n",
        "            \"3. The agreement between the Monte Carlo results (CPU and GPU, if applicable) and the Black-Scholes benchmark, commenting on the simulation's accuracy.\",\n",
        "            \"4. The practical implications of this performance difference for fields like quantitative finance or scientific computing, especially considering the availability of multiple GPUs.\",\n",
        "            \"\", # Blank line\n",
        "            \"Provide your analysis in a concise summary format.\",\n",
        "        ])\n",
        "\n",
        "        # Join prompt parts into a single string\n",
        "        prompt_text = \"\\n\".join(prompt_parts)\n",
        "\n",
        "        # For debugging, you might want to print the prompt before sending\n",
        "        # print(\"--- PROMPT SENT TO GEMINI ---\")\n",
        "        # print(prompt_text)\n",
        "        # print(\"-----------------------------\")\n",
        "\n",
        "        # Create the Generative Model instance\n",
        "        # Use a suitable model name, e.g., 'gemini-pro', 'gemini-1.5-flash-latest', etc.\n",
        "        #model = genai.GenerativeModel('YOUR_CHOSEN_MODEL_NAME_FROM_THE_LIST') # Replace this placeholder\n",
        "        model = genai.GenerativeModel('models/gemini-2.0-flash') # Or another appropriate model\n",
        "\n",
        "        # Generate content from the prompt\n",
        "        # Use a timeout in case the API call hangs\n",
        "        response = model.generate_content(prompt_text, request_options={'timeout': 60}) # 60 seconds timeout\n",
        "\n",
        "        # Print the LLM's response\n",
        "        print(\"\\n--- Gemini LLM Analysis ---\")\n",
        "        # Check if the response has text content\n",
        "        if response.candidates and response.candidates[0].content.parts:\n",
        "             print(response.candidates[0].content.parts[0].text)\n",
        "        else:\n",
        "             print(\"Error: No text content received from LLM response.\")\n",
        "             if response.prompt_feedback:\n",
        "                 print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
        "\n",
        "        print(\"---------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError communicating with Gemini LLM API: {e}\")\n",
        "        print(\"Skipping LLM analysis.\")\n",
        "\n",
        "print(\"\\nScript execution finished.\")"
      ]
    }
  ]
}