{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MMMU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5J_RubxFWYZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83dc772-2b19-426b-b56d-29601dadf3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 30 16:07:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              48W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xxbqPjkS_erH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52b52ed-15af-4453-92eb-995da0f96d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ec4RdOgDDvts"
      },
      "outputs": [],
      "source": [
        "CONFIG=['Accounting', 'Agriculture', 'Architecture_and_Engineering', 'Art', 'Art_Theory', 'Basic_Medical_Science',\n",
        "'Biology', 'Chemistry', 'Clinical_Medicine', 'Computer_Science', 'Design', 'Diagnostics_and_Laboratory_Medicine', 'Economics',\n",
        "'Electronics', 'Energy_and_Power', 'Finance', 'Geography', 'History', 'Literature', 'Manage', 'Marketing', 'Materials', 'Math',\n",
        "'Mechanical_Engineering', 'Music', 'Pharmacy', 'Physics', 'Psychology', 'Public_Health', 'Sociology']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SYgS367sJ5qg"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/*.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for split in [\"dev\", \"validation\", \"test\"]:\n",
        "#    for sample in dataset[split]:\n",
        "#        for key, value in sample.items():\n",
        "#            if isinstance(value, str):\n",
        "#                # Use a more robust encoding method\n",
        "#                #sample[key] = value.encode(\"utf-8\", errors=\"replace\")\n",
        "#                sample[key] = value.encode(\"asciik\", errors=\"replace\")"
      ],
      "metadata": {
        "id": "9wizTe7GLAIl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxg3CRJUIJvd"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Print available configuration names\n",
        "#print(load_dataset(\"MMMU/MMMU\").BUILDER_CONFIGS)\n",
        "\n",
        "SUBJECT = CONFIG[1]\n",
        "print(f\"loading dataset for {SUBJECT}\")\n",
        "\n",
        "# Load the dataset with a specific configuration name\n",
        "dataset = load_dataset(\"MMMU/MMMU\", SUBJECT)\n",
        "\n",
        "\n",
        "# Save datasets to disk in CSV format\n",
        "dataset[\"dev\"].to_csv(\"dev_dataset_MMMU_%s.csv\"%SUBJECT)\n",
        "dataset[\"validation\"].to_csv(\"validation_dataset_MMMU_%s.csv\"%SUBJECT)\n",
        "dataset[\"test\"].to_csv(\"test_dataset_MMMU_%s.csv\"%SUBJECT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E_u7jmyUJEN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5f9c7f-3e25-443d-96b2-82f1bbe736bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    dev: Dataset({\n",
            "        features: ['id', 'question', 'options', 'explanation', 'image_1', 'image_2', 'image_3', 'image_4', 'image_5', 'image_6', 'image_7', 'img_type', 'answer', 'topic_difficulty', 'question_type', 'subfield'],\n",
            "        num_rows: 5\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'question', 'options', 'explanation', 'image_1', 'image_2', 'image_3', 'image_4', 'image_5', 'image_6', 'image_7', 'img_type', 'answer', 'topic_difficulty', 'question_type', 'subfield'],\n",
            "        num_rows: 30\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'question', 'options', 'explanation', 'image_1', 'image_2', 'image_3', 'image_4', 'image_5', 'image_6', 'image_7', 'img_type', 'answer', 'topic_difficulty', 'question_type', 'subfield'],\n",
            "        num_rows: 287\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "agSFEJIzNOx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344dc947-5aad-4391-faf0-73f314d5bc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MMMU'...\n",
            "remote: Enumerating objects: 419, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 419 (delta 20), reused 59 (delta 17), pack-reused 351\u001b[K\n",
            "Receiving objects: 100% (419/419), 3.41 MiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/MMMU-Benchmark/MMMU.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kozEM-lSHPB"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "\n",
        "%cd /content/LLaVA/\n",
        "!pip install -e . -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "03Z06IyeUYou"
      },
      "outputs": [],
      "source": [
        "from llava.model.builder import load_pretrained_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "id": "4futhe0pqLcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db8ed5f-8ccb-4daf-e4e2-ac36e74d0e91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFobAssyqPGu",
        "outputId": "09824d02-f8f5-4779-9f9b-f4e670d06b84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/LLaVA/llava/eval/run_llava.py"
      ],
      "metadata": {
        "id": "ySgeizQ_yotL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/MMMU-Benchmark/MMMU/tree/main/eval\n",
        "\n",
        "\n",
        "https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b\n",
        "\n",
        "liuhaotian/llava-v1.6-mistral-7b\n",
        "\n",
        "\n",
        "https://huggingface.co/liuhaotian/llava-v1.5-7b\n",
        "\n",
        "liuhaotian/llava-v1.5-7b"
      ],
      "metadata": {
        "id": "4JA464SN69VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/MMMU/eval/example_outputs/llava-v1.6-mistral-7b_val.json"
      ],
      "metadata": {
        "id": "E7eqPCmSiZnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MMMU/eval/run_llava.py \\\n",
        "--output_path /content/MMMU/eval/example_outputs/llava-v1.6-mistral-7b_val.json \\\n",
        "--model_path liuhaotian/llava-v1.6-mistral-7b \\\n",
        "--config_path /content/MMMU/eval/configs/llava1.5.yaml"
      ],
      "metadata": {
        "id": "Qb8-uHp544ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrxr8m5gNZkn",
        "outputId": "05d7f08f-5039-425f-9a9b-6099ece71461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MMMU/eval\n",
            "Evaluating: Accounting\n",
            "Evaluating: Agriculture\n",
            "Evaluating: Architecture_and_Engineering\n",
            "Evaluating: Art\n",
            "Evaluating: Art_Theory\n",
            "Evaluating: Basic_Medical_Science\n",
            "Evaluating: Biology\n",
            "Evaluating: Chemistry\n",
            "Evaluating: Clinical_Medicine\n",
            "Evaluating: Computer_Science\n",
            "Evaluating: Design\n",
            "Evaluating: Diagnostics_and_Laboratory_Medicine\n",
            "Evaluating: Economics\n",
            "Evaluating: Electronics\n",
            "Evaluating: Energy_and_Power\n",
            "Evaluating: Finance\n",
            "Evaluating: Geography\n",
            "Evaluating: History\n",
            "Evaluating: Literature\n",
            "Evaluating: Manage\n",
            "Evaluating: Marketing\n",
            "Evaluating: Materials\n",
            "Evaluating: Math\n",
            "Evaluating: Mechanical_Engineering\n",
            "Evaluating: Music\n",
            "Evaluating: Pharmacy\n",
            "Evaluating: Physics\n",
            "Evaluating: Psychology\n",
            "Evaluating: Public_Health\n",
            "Evaluating: Sociology\n",
            "{'Overall-Art and Design': {'num': 120, 'acc': 0.292}, 'Art': {'num': 30, 'acc': 0.267}, 'Art_Theory': {'num': 30, 'acc': 0.3}, 'Design': {'num': 30, 'acc': 0.233}, 'Music': {'num': 30, 'acc': 0.367}, 'Overall-Business': {'num': 150, 'acc': 0.22}, 'Accounting': {'num': 30, 'acc': 0.267}, 'Economics': {'num': 30, 'acc': 0.367}, 'Finance': {'num': 30, 'acc': 0.2}, 'Manage': {'num': 30, 'acc': 0.1}, 'Marketing': {'num': 30, 'acc': 0.167}, 'Overall-Science': {'num': 150, 'acc': 0.24}, 'Biology': {'num': 30, 'acc': 0.3}, 'Chemistry': {'num': 30, 'acc': 0.3}, 'Geography': {'num': 30, 'acc': 0.2}, 'Math': {'num': 30, 'acc': 0.167}, 'Physics': {'num': 30, 'acc': 0.233}, 'Overall-Health and Medicine': {'num': 150, 'acc': 0.267}, 'Basic_Medical_Science': {'num': 30, 'acc': 0.267}, 'Clinical_Medicine': {'num': 30, 'acc': 0.233}, 'Diagnostics_and_Laboratory_Medicine': {'num': 30, 'acc': 0.367}, 'Pharmacy': {'num': 30, 'acc': 0.2}, 'Public_Health': {'num': 30, 'acc': 0.267}, 'Overall-Humanities and Social Science': {'num': 120, 'acc': 0.2}, 'History': {'num': 30, 'acc': 0.133}, 'Literature': {'num': 30, 'acc': 0.333}, 'Sociology': {'num': 30, 'acc': 0.233}, 'Psychology': {'num': 30, 'acc': 0.1}, 'Overall-Tech and Engineering': {'num': 210, 'acc': 0.252}, 'Agriculture': {'num': 30, 'acc': 0.233}, 'Architecture_and_Engineering': {'num': 30, 'acc': 0.3}, 'Computer_Science': {'num': 30, 'acc': 0.133}, 'Electronics': {'num': 30, 'acc': 0.233}, 'Energy_and_Power': {'num': 30, 'acc': 0.333}, 'Materials': {'num': 30, 'acc': 0.3}, 'Mechanical_Engineering': {'num': 30, 'acc': 0.233}, 'Overall': {'num': 900, 'acc': 0.246}}\n"
          ]
        }
      ],
      "source": [
        "%cd /content/MMMU/eval/\n",
        "#!python /content/MMMU/eval/run_llava.py\n",
        "\n",
        "!python /content/MMMU/eval/main_eval_only.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOOOJpahyka6YLNNqi6Uwwn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}