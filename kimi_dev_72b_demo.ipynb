{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4cxOHL7VMtFuMU2O/5eqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/kimi_dev_72b_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://openrouter.ai/settings/keys"
      ],
      "metadata": {
        "id": "qOcZwWYs1-Cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wx5vktQGyK3l"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openrouter_api_key = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "\n",
        "# For OpenRouter, you'd configure the base_url and api_key\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_api_key, # Replace with your actual API key\n",
        ")\n",
        "\n",
        "# Example: Asking for a short introduction to LLMs\n",
        "# While Kimi-Dev-72B is code-focused, it can also handle general text generation.\n",
        "prompt = \"Give me a short introduction to large language models.\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openrouter_api_key = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_api_key,\n",
        ")\n",
        "\n",
        "prompt = \"What is the best Cuban poet?\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# Define the desired streaming behavior before the API call\n",
        "use_streaming = False\n",
        "\n",
        "try:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-dev-72b:free\",\n",
        "        messages=messages,\n",
        "        temperature=0.3,\n",
        "        stream=use_streaming, # Use the variable here\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    if not use_streaming: # Now checking the boolean variable, not the response object\n",
        "        print(stream.choices[0].message.content)\n",
        "    else:\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content is not None:\n",
        "                print(chunk.choices[0].delta.content, end=\"\")\n",
        "        print()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iigjWhfA0giN",
        "outputId": "c9855aa7-6442-4da0-f5f4-405b7ed8a1f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best Cuban poet is a matter of personal taste and opinion. However, some of the most renowned and influential Cuban poets include:\n",
            "\n",
            "1. José Martí: A national hero and a key figure in the Cuban independence movement. His poetry is known for its lyricism and patriotism.\n",
            "2. Nicolás Guillén: A prominent Afro-Cuban poet who wrote about social justice and the experiences of the working class.\n",
            "3. Dulce María Loynaz: A celebrated poet known for her romantic and lyrical works, she was awarded the Cervantes Prize in 1992.\n",
            "4. Virgilio Piñera: A versatile writer known for his experimental and avant-garde poetry.\n",
            "5. Reina María Rodríguez: A contemporary poet whose work often explores themes of identity, history, and the human condition.\n",
            "\n",
            "Each of these poets has made significant contributions to Cuban literature and has a dedicated following.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example 1: Non-Streaming Response ---\n",
        "print(\"--- Non-Streaming Example ---\")\n",
        "prompt_non_stream = \"Give me a short introduction to large language models (non-streaming).\"\n",
        "messages_non_stream = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt_non_stream}\n",
        "]\n",
        "\n",
        "try:\n",
        "    response_non_stream = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-dev-72b:free\",\n",
        "        messages=messages_non_stream,\n",
        "        temperature=0.3,\n",
        "        stream=False, # We want a single, complete response\n",
        "        max_tokens=512\n",
        "    )\n",
        "    print(response_non_stream.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred with non-streaming: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYJrCMG41paI",
        "outputId": "c0420502-f97c-4742-cdfb-e04d1ba38597"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Non-Streaming Example ---\n",
            "◁think▷Okay, let's tackle this. The user wants a short introduction to large language models, specifically non-streaming. Hmm. So first, I need to understand what large language models are. \n",
            "\n",
            "Large language models, or LLMs, are a type of artificial intelligence that uses deep learning to generate human-like text. They're trained on vast amounts of data, like books, websites, and other text sources. The goal is to predict the next word in a sequence, which allows them to generate coherent and contextually relevant responses.\n",
            "\n",
            "Now, the user mentioned \"non-streaming.\" I think that refers to models that process input all at once rather than in a streaming fashion. So, non-streaming models take the entire input context before generating a response. This is in contrast to streaming models that might generate output as they receive input, which can be more efficient but might have different trade-offs.\n",
            "\n",
            "In the context of LLMs, non-streaming models might be more accurate because they consider the full context before generating each token. However, they might be slower since they process everything upfront. Examples of non-streaming LLMs could include some versions of GPT or BERT, depending on how they're implemented.\n",
            "\n",
            "So, putting this together, a short introduction would explain that LLMs are powerful text generators trained on big data. Non-streaming models process all input first, which can lead to more accurate outputs but might be less efficient for real-time applications. They're used in various applications like chatbots, content generation, and language translation.\n",
            "◁/think▷\n",
            "\n",
            "Large language models (LLMs) are advanced AI systems that generate human-like text by predicting the next word in a sequence based on extensive training data. Non-streaming LLMs process the entire input context before generating each output token, which can lead to more accurate and coherent responses but may be less efficient for real-time applications. These models are widely used in applications like chatbots, content generation, and language translation.\n"
          ]
        }
      ]
    }
  ]
}