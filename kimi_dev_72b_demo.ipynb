{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4JXrE0ebQWIPDmC90MdoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/kimi_dev_72b_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://openrouter.ai/settings/keys"
      ],
      "metadata": {
        "id": "qOcZwWYs1-Cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wx5vktQGyK3l"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openrouter_api_key = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "\n",
        "# For OpenRouter, you'd configure the base_url and api_key\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_api_key, # Replace with your actual API key\n",
        ")\n",
        "\n",
        "# Example: Asking for a short introduction to LLMs\n",
        "# While Kimi-Dev-72B is code-focused, it can also handle general text generation.\n",
        "prompt = \"Give me a short introduction to large language models.\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openrouter_api_key = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_api_key,\n",
        ")\n",
        "\n",
        "prompt = \"What is the best Cuban poet?\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# Define the desired streaming behavior before the API call\n",
        "use_streaming = False\n",
        "\n",
        "try:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-dev-72b:free\",\n",
        "        messages=messages,\n",
        "        temperature=0.3,\n",
        "        stream=use_streaming, # Use the variable here\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    if not use_streaming: # Now checking the boolean variable, not the response object\n",
        "        print(stream.choices[0].message.content)\n",
        "    else:\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content is not None:\n",
        "                print(chunk.choices[0].delta.content, end=\"\")\n",
        "        print()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iigjWhfA0giN",
        "outputId": "c9855aa7-6442-4da0-f5f4-405b7ed8a1f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best Cuban poet is a matter of personal taste and opinion. However, some of the most renowned and influential Cuban poets include:\n",
            "\n",
            "1. José Martí: A national hero and a key figure in the Cuban independence movement. His poetry is known for its lyricism and patriotism.\n",
            "2. Nicolás Guillén: A prominent Afro-Cuban poet who wrote about social justice and the experiences of the working class.\n",
            "3. Dulce María Loynaz: A celebrated poet known for her romantic and lyrical works, she was awarded the Cervantes Prize in 1992.\n",
            "4. Virgilio Piñera: A versatile writer known for his experimental and avant-garde poetry.\n",
            "5. Reina María Rodríguez: A contemporary poet whose work often explores themes of identity, history, and the human condition.\n",
            "\n",
            "Each of these poets has made significant contributions to Cuban literature and has a dedicated following.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example 1: Non-Streaming Response ---\n",
        "print(\"--- Non-Streaming Example ---\")\n",
        "prompt_non_stream = \"Give me a short introduction to large language models (non-streaming).\"\n",
        "messages_non_stream = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt_non_stream}\n",
        "]\n",
        "\n",
        "try:\n",
        "    response_non_stream = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-dev-72b:free\",\n",
        "        messages=messages_non_stream,\n",
        "        temperature=0.3,\n",
        "        stream=False, # We want a single, complete response\n",
        "        max_tokens=512\n",
        "    )\n",
        "    print(response_non_stream.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred with non-streaming: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYJrCMG41paI",
        "outputId": "c0420502-f97c-4742-cdfb-e04d1ba38597"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Non-Streaming Example ---\n",
            "◁think▷Okay, let's tackle this. The user wants a short introduction to large language models, specifically non-streaming. Hmm. So first, I need to understand what large language models are. \n",
            "\n",
            "Large language models, or LLMs, are a type of artificial intelligence that uses deep learning to generate human-like text. They're trained on vast amounts of data, like books, websites, and other text sources. The goal is to predict the next word in a sequence, which allows them to generate coherent and contextually relevant responses.\n",
            "\n",
            "Now, the user mentioned \"non-streaming.\" I think that refers to models that process input all at once rather than in a streaming fashion. So, non-streaming models take the entire input context before generating a response. This is in contrast to streaming models that might generate output as they receive input, which can be more efficient but might have different trade-offs.\n",
            "\n",
            "In the context of LLMs, non-streaming models might be more accurate because they consider the full context before generating each token. However, they might be slower since they process everything upfront. Examples of non-streaming LLMs could include some versions of GPT or BERT, depending on how they're implemented.\n",
            "\n",
            "So, putting this together, a short introduction would explain that LLMs are powerful text generators trained on big data. Non-streaming models process all input first, which can lead to more accurate outputs but might be less efficient for real-time applications. They're used in various applications like chatbots, content generation, and language translation.\n",
            "◁/think▷\n",
            "\n",
            "Large language models (LLMs) are advanced AI systems that generate human-like text by predicting the next word in a sequence based on extensive training data. Non-streaming LLMs process the entire input context before generating each output token, which can lead to more accurate and coherent responses but may be less efficient for real-time applications. These models are widely used in applications like chatbots, content generation, and language translation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code-related task"
      ],
      "metadata": {
        "id": "adI41bgX5mgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata #\n",
        "\n",
        "# Retrieve API key from Colab userdata, as demonstrated in the document\n",
        "openrouter_api_key = userdata.get('OPENROUTER_API_KEY') #\n",
        "\n",
        "# Configure the OpenAI client for OpenRouter, using the base_url and api_key\n",
        "client = OpenAI (\n",
        "    base_url=\"https://openrouter.ai/api/v1\", #\n",
        "    api_key=openrouter_api_key, # Replace with your actual API key\n",
        ")\n",
        "\n",
        "# --- Code-Related Task Example ---\n",
        "# Prompt for generating a Python class for an aircraft\n",
        "\n",
        "prompt_code_task = \"\"\"\n",
        "Generate a Python class named 'Aircraft' with the following attributes:\n",
        "- tail_number (string)\n",
        "- aircraft_type (string, e.g., 'Boeing 737', 'Airbus A320')\n",
        "- cruising_speed_knots (float)\n",
        "- max_range_nm (float)\n",
        "\n",
        "Include an __init__ method to set these attributes.\n",
        "Also, include a method `get_details()` that returns a formatted string of the aircraft's details.\n",
        "Add basic docstrings for the class and its methods.\n",
        "\"\"\"\n",
        "\n",
        "messages_code_task = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant and an expert Python programmer.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt_code_task}\n",
        "]\n",
        "\n",
        "print(\"--- Code Generation Example using moonshotai/kimi-dev-72b:free ---\")\n",
        "\n",
        "try:\n",
        "    # Make the API call to the specific model for code generation\n",
        "    response_code_task = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-dev-72b:free\", # Explicitly using the model as requested\n",
        "        messages=messages_code_task,\n",
        "        temperature=0.3, # Keep temperature low for more deterministic code\n",
        "        stream=False,    # Request a complete response for the code\n",
        "        max_tokens=4096  # Allow enough tokens for a full class definition\n",
        "    )\n",
        "\n",
        "    generated_code = response_code_task.choices[0].message.content\n",
        "    print(generated_code)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during code generation: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OM9UL-d5Tih",
        "outputId": "d82d624b-38e1-4d66-d4d6-82d0056bccf8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Code Generation Example using moonshotai/kimi-dev-72b:free ---\n",
            "◁think▷Okay, let's tackle this problem. The user wants a Python class named 'Aircraft' with specific attributes and methods. Let me break down the requirements.\n",
            "\n",
            "First, the class needs attributes: tail_number (a string), aircraft_type (another string like 'Boeing 737'), cruising_speed_knots (a float), and max_range_nm (a float). So in the __init__ method, I need to initialize these attributes. The __init__ should take parameters for each of these and assign them to self.\n",
            "\n",
            "Then, there's a method called get_details() that returns a formatted string. The user probably wants this method to combine all the attributes into a readable output. For example, something like \"Tail Number: XYZ, Type: Boeing 737, Cruising Speed: 500 knots, Max Range: 3000 nm\".\n",
            "\n",
            "I also need to add docstrings. The class should have a docstring explaining what it represents. Each method, including __init__ and get_details, should have their own docstrings. The __init__ docstring should describe the parameters, and get_details should explain what it returns.\n",
            "\n",
            "Wait, the user mentioned \"basic docstrings\". So maybe just a brief explanation. For the class, maybe \"Represents an aircraft with its details.\" For __init__, parameters and their types. For get_details, \"Returns a formatted string of aircraft details.\"\n",
            "\n",
            "Now, putting it all together. The class definition starts with class Aircraft:. Then the __init__ method with parameters. Assign each parameter to self. Then the get_details method constructs the string. Make sure to use proper string formatting, maybe using f-strings for clarity.\n",
            "\n",
            "Wait, the user didn't specify any validation for the attributes. So probably just assign them as given. No need for type checks unless specified. So the __init__ is straightforward.\n",
            "\n",
            "Also, the docstrings: for the class, a short description. For __init__, explain the parameters. For get_details, what it does. Let me check the example again. The user wants the docstrings for the class and its methods. So each method should have a docstring.\n",
            "\n",
            "So the code would look like:\n",
            "\n",
            "class Aircraft:\n",
            "    \"\"\"Represents an aircraft with its details.\"\"\"\n",
            "    \n",
            "    def __init__(self, tail_number: str, aircraft_type: str, cruising_speed_knots: float, max_range_nm: float):\n",
            "        \"\"\"Initialize the Aircraft with its attributes.\n",
            "        \n",
            "        Args:\n",
            "            tail_number: The aircraft's tail number.\n",
            "            aircraft_type: The type of aircraft (e.g., 'Boeing 737').\n",
            "            cruising_speed_knots: Cruising speed in knots.\n",
            "            max_range_nm: Maximum range in nautical miles.\n",
            "        \"\"\"\n",
            "        self.tail_number = tail_number\n",
            "        self.aircraft_type = aircraft_type\n",
            "        self.cruising_speed_knots = cruising_speed_knots\n",
            "        self.max_range_nm = max_range_nm\n",
            "    \n",
            "    def get_details(self) -> str:\n",
            "        \"\"\"Return a formatted string of the aircraft's details.\"\"\"\n",
            "        return (f\"Tail Number: {self.tail_number}, Type: {self.aircraft_type}, \"\n",
            "                f\"Cruising Speed: {self.cruising_speed_knots} knots, \"\n",
            "                f\"Max Range: {self.max_range_nm} nm\")\n",
            "\n",
            "That should cover all the requirements. The __init__ sets the attributes, get_details formats them into a string. Docstrings are added to the class and both methods. The parameters in __init__ are properly typed. The return type of get_details is specified as str.\n",
            "\n",
            "I think that's correct. Let me check again. The user asked for a Python class with those attributes and methods. The __init__ is present, the get_details method is there. Docstrings are included. So this should meet the requirements.\n",
            "◁/think▷\n",
            "\n",
            "```python\n",
            "class Aircraft:\n",
            "    \"\"\"Represents an aircraft with its details.\"\"\"\n",
            "    \n",
            "    def __init__(self, tail_number: str, aircraft_type: str, cruising_speed_knots: float, max_range_nm: float):\n",
            "        \"\"\"Initialize the Aircraft with its attributes.\n",
            "        \n",
            "        Args:\n",
            "            tail_number: The aircraft's tail number.\n",
            "            aircraft_type: The type of aircraft (e.g., 'Boeing 737').\n",
            "            cruising_speed_knots: Cruising speed in knots.\n",
            "            max_range_nm: Maximum range in nautical miles.\n",
            "        \"\"\"\n",
            "        self.tail_number = tail_number\n",
            "        self.aircraft_type = aircraft_type\n",
            "        self.cruising_speed_knots = cruising_speed_knots\n",
            "        self.max_range_nm = max_range_nm\n",
            "    \n",
            "    def get_details(self) -> str:\n",
            "        \"\"\"Return a formatted string of the aircraft's details.\"\"\"\n",
            "        return (f\"Tail Number: {self.tail_number}, Type: {self.aircraft_type}, \"\n",
            "                f\"Cruising Speed: {self.cruising_speed_knots} knots, \"\n",
            "                f\"Max Range: {self.max_range_nm} nm\")\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}