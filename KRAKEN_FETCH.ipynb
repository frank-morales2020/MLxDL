{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFOogcgyfB0rP2IMrSOv7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/KRAKEN_FETCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ccxt -q\n",
        "!pip install google-colab-secrets -q\n",
        "!pip install ta -q\n",
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "l2AAn3UBzlr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Wk4ZW1RO0aK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DB"
      ],
      "metadata": {
        "id": "OCMjPGcbMiBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BImiCM8zdVY",
        "outputId": "9979ccde-4f34-41f3-a754-a00014df452d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Test Case for SOL/USD ---\n",
            "Fetching 720 candles for SOL/USD from 2025-08-25 15:29:59.426000...\n",
            "Successfully fetched 720 candles.\n",
            "Data for SOL/USD successfully stored in /content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_SOL.db/ethusd_1h_data_recent using 'replace' mode.\n",
            "--- Test Case for SOL/USD Complete ---\n"
          ]
        }
      ],
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "def fetch_and_store_data(symbol, timeframe, db_path, table_name, mode='replace'):\n",
        "    \"\"\"\n",
        "    Fetches 30 days of historical OHLCV data from Kraken and stores it in an SQLite database.\n",
        "\n",
        "    Args:\n",
        "        symbol (str): The trading pair (e.g., 'ETH/USD').\n",
        "        timeframe (str): The interval of each candle (e.g., '1h').\n",
        "        db_path (str): The path to the SQLite database file.\n",
        "        table_name (str): The name of the table to store the data in.\n",
        "        mode (str): How to handle existing tables ('replace' or 'append').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Securely retrieve API keys from Colab's Secrets\n",
        "        KRAKEN_API_KEY = userdata.get('KRAKEN')\n",
        "        KRAKEN_API_SECRET = userdata.get('KRAKEN_SECRET')\n",
        "\n",
        "        exchange_config = {\n",
        "            'apiKey': KRAKEN_API_KEY,\n",
        "            'secret': KRAKEN_API_SECRET,\n",
        "            'enableRateLimit': True,\n",
        "        }\n",
        "        exchange = ccxt.kraken(exchange_config)\n",
        "\n",
        "        # Calculate start time for a 30-day look-back\n",
        "        start_time = datetime.now() - timedelta(days=30)\n",
        "        since_timestamp = int(start_time.timestamp() * 1000)\n",
        "\n",
        "        # Determine limit for 30 days of hourly data\n",
        "        limit = 30 * 24\n",
        "\n",
        "        print(f\"Fetching {limit} candles for {symbol} from {datetime.fromtimestamp(since_timestamp / 1000)}...\")\n",
        "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since_timestamp, limit=limit)\n",
        "\n",
        "        if not ohlcv:\n",
        "            print(f\"Warning: No data fetched for {symbol}.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "        df = df.dropna()\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms').dt.tz_localize('UTC')\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "\n",
        "        print(f\"Successfully fetched {len(df)} candles.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {symbol}: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Use pandas to_sql to write the DataFrame to the database\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        df.to_sql(table_name, conn, if_exists=mode, index=True)\n",
        "        conn.close()\n",
        "\n",
        "        print(f\"Data for {symbol} successfully stored in {db_path}/{table_name} using '{mode}' mode.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing data to database: {e}\")\n",
        "        return\n",
        "\n",
        "# Test Case\n",
        "db_file = '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_SOL.db'\n",
        "table_name = 'ethusd_1h_data_recent'\n",
        "\n",
        "symbol='SOL/USD'\n",
        "\n",
        "print(f\"--- Starting Test Case for {symbol} ---\")\n",
        "fetch_and_store_data(\n",
        "    symbol=symbol,\n",
        "    timeframe='1h',\n",
        "    db_path=db_file,\n",
        "    table_name=table_name,\n",
        "    mode='replace'\n",
        ")\n",
        "print(f\"--- Test Case for {symbol} Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "def validate_database_data(db_path, table_name):\n",
        "    \"\"\"\n",
        "    Connects to the database and prints the first and last 5 rows of a table.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_path)\n",
        "\n",
        "        # Get the first 5 rows (ordered by timestamp)\n",
        "        first_rows_query = f\"SELECT * FROM '{table_name}' ORDER BY timestamp ASC LIMIT 5\"\n",
        "        df_first = pd.read_sql_query(first_rows_query, conn)\n",
        "\n",
        "        # Get the last 5 rows (ordered by timestamp)\n",
        "        last_rows_query = f\"SELECT * FROM '{table_name}' ORDER BY timestamp DESC LIMIT 5\"\n",
        "        df_last = pd.read_sql_query(last_rows_query, conn)\n",
        "\n",
        "        conn.close()\n",
        "\n",
        "        print(f\"--- First 5 rows of '{table_name}' ---\")\n",
        "        print(df_first)\n",
        "        print(\"\\n\")\n",
        "        print(f\"--- Last 5 rows of '{table_name}' ---\")\n",
        "        print(df_last)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error validating data: {e}\")\n",
        "\n",
        "# Test Case\n",
        "db_file = '/content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_ETH.db'\n",
        "table_name = 'ethusd_1h_data_recent'\n",
        "\n",
        "print(\"--- Starting Data Validation for ETH/USD ---\")\n",
        "validate_database_data(db_file, table_name)\n",
        "print(\"\\n--- Data Validation Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrUbO0bg1BRb",
        "outputId": "7dd486ea-19b0-421c-f3af-e714b2cb6789"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Validation for ETH/USD ---\n",
            "--- First 5 rows of 'ethusd_1h_data_recent' ---\n",
            "                   timestamp     open     high      low    close        volume\n",
            "0  2025-08-25 15:00:00+00:00  4659.33  4669.01  4605.54  4613.17    989.551876\n",
            "1  2025-08-25 16:00:00+00:00  4613.17  4644.13  4592.70  4600.00   1549.592972\n",
            "2  2025-08-25 17:00:00+00:00  4600.01  4600.01  4566.68  4586.74   1836.818605\n",
            "3  2025-08-25 18:00:00+00:00  4586.74  4596.29  4572.03  4575.00   1060.028528\n",
            "4  2025-08-25 19:00:00+00:00  4575.01  4575.01  4413.49  4418.60  14566.890305\n",
            "\n",
            "\n",
            "--- Last 5 rows of 'ethusd_1h_data_recent' ---\n",
            "                   timestamp     open     high      low    close       volume\n",
            "0  2025-09-24 14:00:00+00:00  4151.22  4167.29  4151.22  4161.75  1713.228301\n",
            "1  2025-09-24 13:00:00+00:00  4181.43  4185.26  4149.96  4149.96   968.061012\n",
            "2  2025-09-24 12:00:00+00:00  4183.21  4187.48  4175.00  4181.42   184.719421\n",
            "3  2025-09-24 11:00:00+00:00  4178.01  4275.48  4170.24  4183.21  5502.378360\n",
            "4  2025-09-24 10:00:00+00:00  4183.39  4184.11  4168.01  4178.01   795.919419\n",
            "\n",
            "--- Data Validation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WFO"
      ],
      "metadata": {
        "id": "Vm5dbz7JStZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import ta\n",
        "import json\n",
        "import sqlite3\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pytz\n",
        "import warnings\n",
        "import keras_tuner as kt\n",
        "from typing import Dict, Any\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set TensorFlow logging to only show errors\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SENDER_EMAIL=userdata.get('EMAIL_SENDER')\n",
        "RECIPIENT_EMAIL=userdata.get('EMAIL_RECIPIENT')\n",
        "SMTP_SERVER=userdata.get('EMAIL_SMTP_SERVER')\n",
        "SMTP_PORT=userdata.get('EMAIL_SMTP_PORT')\n",
        "\n",
        "\n",
        "# --- Configuration for BTC Only ---\n",
        "CONFIG_FILE = \"/content/gdrive/MyDrive/TradingBotLogs/trading_bot_config_WFO_FETCH-SOL.json\"\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    \"SYMBOLS\": [\n",
        "        {\n",
        "            \"symbol\": \"SOL/USD\",\n",
        "            \"model_path\": '/content/gdrive/MyDrive/TradingBotLogs/crypto_model_retrained_500epochs_v3_SOL.keras',\n",
        "            \"params\": {\"CONFIDENCE_THRESHOLD\": 0.010, \"ATR_MULTIPLIER_TP\": 2.0, \"ATR_MULTIPLIER_SL\": 1.0, \"MAX_POSITION_SIZE\": 0.13},\n",
        "            \"backtest_params\": {\"strategy_type\": \"both\", \"max_drawdown_limit\": 0.25, \"volatility_filter_low\": 0.1, \"volatility_filter_high\": 3.0},\n",
        "            \"db_path\": db_file,\n",
        "            \"table_name\": table_name\n",
        "        },\n",
        "    ],\n",
        "    \"TIMEFRAME\": \"1h\",\n",
        "    \"LOG_DIR\": \"/content/gdrive/MyDrive/TradingBotLogs/\",\n",
        "    \"DRY_RUN\": True,\n",
        "    \"DATA_SOURCE\": \"historical\",\n",
        "    \"TIMEZONE\": \"America/New_York\",\n",
        "    \"WAIT_SECONDS\": 3610,\n",
        "    \"EMAIL_CONFIG\": {\n",
        "        \"SENDER_EMAIL\": SENDER_EMAIL,\n",
        "        \"RECIPIENT_EMAIL\": RECIPIENT_EMAIL,\n",
        "        \"SMTP_SERVER\": SMTP_SERVER,\n",
        "        \"SMTP_PORT\": SMTP_PORT\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'w') as f:\n",
        "        json.dump(DEFAULT_CONFIG, f, indent=4)\n",
        "    print(f\"Config saved to {CONFIG_FILE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving config: {e}\")\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'r') as f:\n",
        "        config = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    config = DEFAULT_CONFIG\n",
        "    with open(CONFIG_FILE, 'w') as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "    print(f\"Default config created and saved to {CONFIG_FILE}\")\n",
        "\n",
        "# Exchange and global parameters\n",
        "exchange = ccxt.kraken({\n",
        "    'apiKey': \"YOUR_API_KEY\",\n",
        "    'secret': \"YOUR_SECRET\",\n",
        "    'enableRateLimit': True,\n",
        "    'test': True\n",
        "})\n",
        "\n",
        "FEE_RATE = 0.0026\n",
        "SLIPPAGE_BUFFER = 0.001\n",
        "TIME_BASED_EXIT_PERIODS = 48\n",
        "RISK_FREE_RATE_ANNUAL = 0.04\n",
        "\n",
        "# --- Data Loading Function from SQLite ---\n",
        "def load_ohlcv_data_from_db(db_path: str, table_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads and cleans historical OHLCV data from a SQLite database table into a pandas DataFrame.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        query = f\"SELECT * FROM {table_name} ORDER BY timestamp ASC\"\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "        conn.close()\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True)\n",
        "        df.dropna(subset=['timestamp'], inplace=True)\n",
        "\n",
        "        numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "        df.set_index('timestamp', inplace=True)\n",
        "        df = df.sort_index(ascending=True)\n",
        "\n",
        "        print(f\"Successfully loaded and cleaned {len(df)} candles from {table_name}.\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from database: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# --- Feature Computation Functions ---\n",
        "def calculate_indicators(df, symbol_name, rsi_window, macd_fast, macd_slow, macd_signal, bb_window):\n",
        "    base_symbol = symbol_name.split(\"/\")[0]\n",
        "    df.rename(columns={'close': f'{base_symbol}_Close'}, inplace=True)\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(df[f'{base_symbol}_Close'], window=rsi_window).rsi()\n",
        "\n",
        "    # Use MA type\n",
        "    macd = ta.trend.MACD(close=df[f'{base_symbol}_Close'], window_fast=macd_fast, window_slow=macd_slow, window_sign=macd_signal)\n",
        "\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_Signal'] = macd.macd_signal()\n",
        "    bb = ta.volatility.BollingerBands(df[f'{base_symbol}_Close'], window=bb_window)\n",
        "    df['BB_Upper'] = bb.bollinger_hband()\n",
        "    df['BB_Lower'] = bb.bollinger_lband()\n",
        "    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(df[f'{base_symbol}_Close'], df['volume']).on_balance_volume()\n",
        "    df['ATR'] = ta.volatility.AverageTrueRange(df['high'], df['low'], df[f'{base_symbol}_Close']).average_true_range()\n",
        "\n",
        "    # Calculate SMAs and add to DataFrame\n",
        "    df['SMA_5'] = df[f'{base_symbol}_Close'].rolling(window=5).mean()\n",
        "    df['SMA_10'] = df[f'{base_symbol}_Close'].rolling(window=10).mean()\n",
        "    df['SMA_20'] = df[f'{base_symbol}_Close'].rolling(window=20).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Performance Metric Calculation Function (Corrected) ---\n",
        "def calculate_metrics(capital_history: list, timeframe_minutes: int, risk_free_rate_annual: float) -> Dict[str, float]:\n",
        "    \"\"\"Calculates key trading performance metrics from a list of portfolio values.\"\"\"\n",
        "    if len(capital_history) < 2:\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0}\n",
        "\n",
        "    capital_df = pd.Series(capital_history)\n",
        "    returns = capital_df.pct_change().dropna()\n",
        "\n",
        "    total_return = (capital_df.iloc[-1] - capital_df.iloc[0]) / capital_df.iloc[0] * 100\n",
        "\n",
        "    timeframe_per_year = (365 * 24 * 60) / timeframe_minutes\n",
        "    risk_free_rate_per_period = (1 + risk_free_rate_annual)**(1/timeframe_per_year) - 1\n",
        "\n",
        "    # Add a small epsilon to the standard deviation to prevent division by zero\n",
        "    std_dev = returns.std()\n",
        "    if std_dev == 0 or np.isnan(std_dev):\n",
        "        sharpe_ratio = 0.0\n",
        "    else:\n",
        "        sharpe_ratio = (returns.mean() - risk_free_rate_per_period) / (std_dev + 1e-9) * np.sqrt(timeframe_per_year)\n",
        "\n",
        "    peak_capital = capital_df.cummax()\n",
        "    drawdown = (peak_capital - capital_df) / peak_capital\n",
        "    max_drawdown = drawdown.max() if not drawdown.empty else 0.0\n",
        "\n",
        "    return {\n",
        "        \"total_return\": total_return,\n",
        "        \"sharpe_ratio\": sharpe_ratio,\n",
        "        \"max_drawdown\": max_drawdown\n",
        "    }\n",
        "\n",
        "\n",
        "# --- def Backtesting AND class BacktestHypermodel  for Tune ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from tqdm import tqdm\n",
        "import ta\n",
        "import logging\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "SLIPPAGE_BUFFER = 0.001  # 0.1% slippage\n",
        "FEE_RATE = 0.001  # 0.1% trading fee\n",
        "RISK_FREE_RATE_ANNUAL = 0.02  # 2% annual risk-free rate\n",
        "\n",
        "# --- Backtesting Function for Tuner (Modified) ---\n",
        "def run_backtest_v2(symbol_config: Dict[str, Any], prediction_agent, trade_params: Dict[str, Any], backtest_params: Dict[str, Any], data_slice: pd.DataFrame, symbol: str = \"Generic\") -> Dict[str, float]:\n",
        "    initial_capital = symbol_config.get(\"initial_capital\", 100000)\n",
        "    look_back = trade_params.get(\"look_back\", symbol_config.get(\"look_back\", 72))\n",
        "\n",
        "    df = data_slice.copy()\n",
        "\n",
        "    # Validate data slice\n",
        "    if df.empty or len(df) < look_back + 20:\n",
        "        logger.error(f\"Data slice too short: {len(df)} rows, need at least {look_back + 20}\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    # Precompute indicators\n",
        "    df = calculate_indicators(df, symbol, rsi_window=14, macd_fast=12, macd_slow=26, macd_signal=9, bb_window=20)\n",
        "\n",
        "    base_symbol = symbol.split(\"/\")[0]\n",
        "    # Features used for prediction (should match the model's input shape)\n",
        "    prediction_features = ['open', 'high', 'low', f'{base_symbol}_Close', 'volume', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'OBV', 'ATR']\n",
        "    # Features used for strategy logic (can include SMAs)\n",
        "    strategy_features = prediction_features + ['SMA_5', 'SMA_10', 'SMA_20']\n",
        "\n",
        "    logger.info(f\"Prediction features used: {prediction_features}\")\n",
        "    logger.info(f\"Strategy features used: {strategy_features}\")\n",
        "\n",
        "    # Check NaN counts before dropping\n",
        "    nan_counts_prediction = df[prediction_features].isna().sum()\n",
        "    nan_counts_strategy = df[strategy_features].isna().sum()\n",
        "    logger.info(f\"NaN counts before dropna (Prediction Features): {nan_counts_prediction.to_dict()}\")\n",
        "    logger.info(f\"NaN counts before dropna (Strategy Features): {nan_counts_strategy.to_dict()}\")\n",
        "\n",
        "    # Forward-fill and drop NaNs for strategy features (which include prediction features)\n",
        "    df = df[strategy_features].ffill()\n",
        "    df = df.dropna()\n",
        "\n",
        "    if df.empty or len(df) < look_back + 1:\n",
        "        logger.error(f\"DataFrame empty after preprocessing: {len(df)} rows remaining\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    logger.info(f\"DataFrame after preprocessing: {len(df)} rows\")\n",
        "\n",
        "    # Batch predictions using only prediction features\n",
        "    windows = [df.iloc[i - look_back:i][prediction_features].values for i in range(look_back, len(df))]\n",
        "    if not windows:\n",
        "        logger.error(\"No windows available for prediction\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_windows = [scaler.fit_transform(window) for window in windows if window.shape[0] == look_back]\n",
        "\n",
        "    # Ensure consistent feature count (12 for prediction)\n",
        "    X_batch = np.array([window for window in scaled_windows if window.shape[1] == 12])\n",
        "    if len(X_batch) == 0:\n",
        "        logger.error(\"No valid windows for prediction after scaling and filtering\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "\n",
        "    pred_probs_batch = prediction_agent.predict(X_batch, verbose=0)\n",
        "    pred_stats = {'buy': [], 'sell': []}\n",
        "\n",
        "    capital = initial_capital\n",
        "    position_qty = 0.0\n",
        "    entry_price = 0.0\n",
        "    initial_stop_loss = 0.0\n",
        "    trailing_stop_price = 0.0\n",
        "    in_position = False\n",
        "    periods_in_position = 0\n",
        "    is_long = False\n",
        "    trades = 0\n",
        "    capital_history = [initial_capital]\n",
        "    max_capital = initial_capital\n",
        "\n",
        "    # Adjust loop range to match the predictions batch\n",
        "    # The loop iterates over the data slice from `look_back` to the end\n",
        "    loop_range = tqdm(range(look_back, len(df)), desc=\"Backtesting Progress\", leave=False)\n",
        "\n",
        "    try:\n",
        "        # Use enumerate to get both the index in the loop_range and the corresponding index in the df\n",
        "        for i, idx in enumerate(loop_range):\n",
        "            # Check if the index for pred_probs_batch is within bounds\n",
        "            pred_batch_index = idx - look_back\n",
        "            if pred_batch_index >= len(pred_probs_batch) or pred_batch_index < 0:\n",
        "                 logger.warning(f\"Skipping index {idx}: Out of bounds for prediction batch (size {len(pred_probs_batch)})\")\n",
        "                 current_price_for_history = df[f'{base_symbol}_Close'].iloc[idx] if idx < len(df[f'{base_symbol}_Close']) else (df[f'{base_symbol}_Close'].iloc[-1] if not df[f'{base_symbol}_Close'].empty else 0)\n",
        "                 capital_history.append(capital + (position_qty * current_price_for_history if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price_for_history) if in_position and not is_long else 0)))\n",
        "                 continue\n",
        "\n",
        "\n",
        "            pred_probs = pred_probs_batch[pred_batch_index]\n",
        "            pred_stats['buy'].append(pred_probs[1])\n",
        "            pred_stats['sell'].append(pred_probs[2])\n",
        "            logger.debug(f\"Predictions at index {idx}: buy={pred_probs[1]:.4f}, sell={pred_probs[2]:.4f}\")\n",
        "            current_price = df[f'{base_symbol}_Close'].iloc[idx]\n",
        "            atr = df['ATR'].iloc[idx]\n",
        "            sma_20 = df['SMA_20'].iloc[idx]\n",
        "            sma_10 = df['SMA_10'].iloc[idx]\n",
        "            sma_5 = df['SMA_5'].iloc[idx]\n",
        "            rsi = df['RSI'].iloc[idx]\n",
        "            macd = df['MACD'].iloc[idx]\n",
        "            macd_signal = df['MACD_Signal'].iloc[idx]\n",
        "\n",
        "\n",
        "            if current_price == 0 or atr == 0 or np.isnan(atr):\n",
        "                logger.warning(f\"Invalid data at index {idx}: price={current_price}, atr={atr}\")\n",
        "                capital_history.append(capital + (position_qty * current_price if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price) if in_position and not is_long else 0)))\n",
        "                continue\n",
        "\n",
        "\n",
        "            # Volatility filter\n",
        "            # Ensure there are enough previous candles for the rolling mean\n",
        "            rolling_atr_mean = df['ATR'].iloc[max(0, idx-50):idx].mean() if idx >= 50 else df['ATR'].mean()\n",
        "            if atr < trade_params.get(\"min_atr_threshold\", 0.05) * rolling_atr_mean:\n",
        "                logger.debug(f\"Filtered out trade at index {idx}: ATR {atr} < {trade_params.get('min_atr_threshold', 0.05)} * {rolling_atr_mean}\")\n",
        "                capital_history.append(capital + (position_qty * current_price if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price) if in_position and not is_long else 0)))\n",
        "                continue\n",
        "\n",
        "\n",
        "            # Breakeven Stop-Loss Logic\n",
        "            if in_position:\n",
        "                periods_in_position += 1\n",
        "                profit_margin_to_breakeven = atr * trade_params.get(\"breakeven_atr_multiplier\", 0.3)\n",
        "                if is_long and current_price > entry_price + profit_margin_to_breakeven:\n",
        "                    initial_stop_loss = max(initial_stop_loss, entry_price)\n",
        "                elif not is_long and current_price < entry_price - profit_margin_to_breakeven:\n",
        "                    initial_stop_loss = min(initial_stop_loss, entry_price)\n",
        "\n",
        "                # Profit-Lock Trailing Stop Logic\n",
        "                profit_lock_trigger = atr * trade_params.get(\"profit_lock_atr_multiplier\", 0.3)\n",
        "                trailing_stop_multiplier = trade_params.get(\"trailing_stop_multiplier\", 0.05)\n",
        "                if is_long and current_price > entry_price + profit_lock_trigger:\n",
        "                    new_trailing_stop = current_price * (1 - trailing_stop_multiplier)\n",
        "                    trailing_stop_price = max(trailing_stop_price, new_trailing_stop)\n",
        "                elif not is_long and current_price < entry_price - profit_lock_trigger:\n",
        "                    new_trailing_stop = current_price * (1 + trailing_stop_multiplier)\n",
        "                    trailing_stop_price = min(trailing_stop_price, new_trailing_stop)\n",
        "\n",
        "            if not in_position and capital > 0:\n",
        "                sl_distance = atr * trade_params.get(\"atr_multiplier_sl\", 0.5)\n",
        "                tp_distance = atr * trade_params.get(\"atr_multiplier_tp\", 2.0)\n",
        "                risk_per_trade_amount = capital * trade_params.get(\"risk_per_trade_percent\", 0.005)\n",
        "\n",
        "                # Risk-reward filter\n",
        "                if sl_distance > 0 and tp_distance / sl_distance < trade_params.get(\"min_risk_reward\", 0.1):\n",
        "                    logger.debug(f\"Filtered out trade at index {idx}: Risk-reward ratio {tp_distance/sl_distance} < {trade_params.get('min_risk_reward', 0.1)}\")\n",
        "                    capital_history.append(capital)\n",
        "                    continue\n",
        "\n",
        "                # Trend and momentum filter\n",
        "                trend_up = (current_price > sma_20 * 0.995 or current_price > sma_10 or current_price > sma_5 or rsi > 60 or macd > macd_signal)\n",
        "                trend_down = (current_price < sma_20 * 1.005 or current_price < sma_10 or current_price < sma_5 or rsi < 40 or macd < macd_signal)\n",
        "\n",
        "                # Hybrid Position Sizing\n",
        "                qty = 0\n",
        "                dynamic_sizing = trade_params.get(\"dynamic_position_sizing_method\", \"hybrid\")\n",
        "                if dynamic_sizing == \"fixed_ratio\":\n",
        "                    qty = (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price\n",
        "                elif dynamic_sizing == \"risk_based\":\n",
        "                    if sl_distance > 0:\n",
        "                        qty = risk_per_trade_amount / sl_distance\n",
        "                elif dynamic_sizing == \"volatility_based\":\n",
        "                    if atr > 0:\n",
        "                        position_size_factor = (1.0 / atr) * (capital * trade_params.get(\"volatility_size_factor\", 0.02))\n",
        "                        qty = min(position_size_factor, (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price)\n",
        "                elif dynamic_sizing == \"hybrid\":\n",
        "                    if sl_distance > 0 and atr > 0:\n",
        "                        risk_qty = risk_per_trade_amount / sl_distance\n",
        "                        vol_qty = (1.0 / atr) * (capital * trade_params.get(\"volatility_size_factor\", 0.02))\n",
        "                        qty = min(risk_qty, vol_qty)\n",
        "\n",
        "                # Cap position size\n",
        "                max_pos_size_qty = (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price\n",
        "                qty = min(qty, max_pos_size_qty) if current_price > 0 else 0\n",
        "\n",
        "                if qty > 0:\n",
        "                    if (pred_probs[1] >= trade_params.get(\"confidence_threshold\", 0.005) or rsi > 60 or current_price > sma_10 or current_price > sma_5 or macd > macd_signal) and trend_up:\n",
        "                        entry_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        entry_cost = qty * entry_price\n",
        "                        entry_fee = entry_cost * FEE_RATE\n",
        "                        if capital >= entry_cost + entry_fee:\n",
        "                            capital -= entry_cost + entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = True\n",
        "                            position_qty = qty\n",
        "                            periods_in_position = 1\n",
        "                            initial_stop_loss = entry_price - sl_distance\n",
        "                            trailing_stop_price = initial_stop_loss\n",
        "                            trades += 1\n",
        "                            logger.info(f\"Long entry at index {idx}: price={entry_price}, qty={qty}, sl={initial_stop_loss}\")\n",
        "                    elif (pred_probs[2] >= trade_params.get(\"confidence_threshold\", 0.005) or rsi < 40 or current_price < sma_10 or current_price < sma_5 or macd < macd_signal) and trend_down:\n",
        "                        entry_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        short_proceeds = qty * entry_price\n",
        "                        entry_fee = short_proceeds * FEE_RATE\n",
        "                        if capital >= entry_fee:\n",
        "                            capital += short_proceeds - entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = False\n",
        "                            position_qty = -qty\n",
        "                            periods_in_position = 1\n",
        "                            initial_stop_loss = entry_price + sl_distance\n",
        "                            trailing_stop_price = initial_stop_loss\n",
        "                            trades += 1\n",
        "                            logger.info(f\"Short entry at index {idx}: price={entry_price}, qty={qty}, sl={initial_stop_loss}\")\n",
        "\n",
        "            # Exit Conditions\n",
        "            if in_position:\n",
        "                exit_reason = None\n",
        "\n",
        "                # Dynamic take-profit\n",
        "                dynamic_tp_multiplier = trade_params.get(\"atr_multiplier_tp\", 2.0)\n",
        "                # Ensure there are enough previous candles for the rolling mean\n",
        "                rolling_atr_mean = df['ATR'].iloc[max(0, idx-50):idx].mean() if idx >= 50 else df['ATR'].mean()\n",
        "                if df['ATR'].iloc[idx] > rolling_atr_mean:\n",
        "                    dynamic_tp_multiplier *= 1.5\n",
        "\n",
        "                # Exit via Breakeven Stop or Initial Stop-Loss\n",
        "                if is_long and current_price <= initial_stop_loss:\n",
        "                    exit_reason = \"Stop-Loss\"\n",
        "                elif not is_long and current_price >= initial_stop_loss:\n",
        "                    exit_reason = \"Stop-Loss\"\n",
        "\n",
        "                # Exit via Trailing Stop\n",
        "                elif is_long and trailing_stop_price > initial_stop_loss and current_price <= trailing_stop_price:\n",
        "                    exit_reason = \"Trailing-Stop\"\n",
        "                elif not is_long and trailing_stop_price < initial_stop_loss and current_price >= trailing_stop_price:\n",
        "                    exit_reason = \"Trailing-Stop\"\n",
        "\n",
        "                # Take-Profit Exit\n",
        "                elif is_long and current_price >= entry_price + atr * dynamic_tp_multiplier:\n",
        "                    exit_reason = \"Take-Profit\"\n",
        "                elif not is_long and current_price <= entry_price - atr * dynamic_tp_multiplier:\n",
        "                    exit_reason = \"Take-Profit\"\n",
        "\n",
        "                # Time-Based Exit\n",
        "                elif periods_in_position > trade_params.get(\"max_hold_periods\", 72):\n",
        "                    exit_reason = \"Time-Based-Exit\"\n",
        "\n",
        "                if exit_reason:\n",
        "                    if is_long:\n",
        "                        if exit_reason == \"Time-Based-Exit\":\n",
        "                            exit_price = current_price\n",
        "                        else:\n",
        "                            exit_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        exit_proceeds = position_qty * exit_price\n",
        "                        exit_fee = exit_proceeds * FEE_RATE\n",
        "                        capital += exit_proceeds - exit_fee\n",
        "                    else:  # Short position\n",
        "                        if exit_reason == \"Time-Based-Exit\":\n",
        "                            exit_price = current_price\n",
        "                        else:\n",
        "                            exit_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        buyback_cost = abs(position_qty) * exit_price\n",
        "                        exit_fee = buyback_cost * FEE_RATE\n",
        "                        capital -= buyback_cost + exit_fee\n",
        "\n",
        "                    logger.info(f\"Exit at index {idx}: reason={exit_reason}, price={exit_price}, capital={capital}\")\n",
        "                    in_position = False\n",
        "                    periods_in_position = 0\n",
        "                    trailing_stop_price = 0.0\n",
        "                    initial_stop_loss = 0.0\n",
        "\n",
        "            current_portfolio_value = capital\n",
        "            if in_position:\n",
        "                if is_long:\n",
        "                    current_portfolio_value += position_qty * current_price\n",
        "                else:\n",
        "                    current_portfolio_value += abs(position_qty) * (2 * entry_price - current_price)\n",
        "            capital_history.append(current_portfolio_value)\n",
        "\n",
        "            max_capital = max(max_capital, current_portfolio_value)\n",
        "\n",
        "        # Log detailed prediction statistics\n",
        "        buy_probs = pred_probs_batch[:, 1].tolist() if pred_probs_batch.shape[1] > 1 else []\n",
        "        sell_probs = pred_probs_batch[:, 2].tolist() if pred_probs_batch.shape[1] > 2 else []\n",
        "\n",
        "        if buy_probs and sell_probs:\n",
        "             logger.info(f\"Prediction stats: Buy min={np.min(buy_probs):.4f}, Buy max={np.max(buy_probs):.4f}, Buy mean={np.mean(buy_probs):.4f}, Buy std={np.std(buy_probs):.4f}, \"\n",
        "                         f\"Sell min={np.min(sell_probs):.4f}, Sell max={np.max(sell_probs):.4f}, Sell mean={np.mean(sell_probs):.4f}, Sell std={np.std(sell_probs):.4f}\")\n",
        "        else:\n",
        "             logger.warning(\"Prediction probabilities list is empty, skipping detailed stats.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Backtest error: {str(e)}\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    metrics = calculate_metrics(capital_history, 60, RISK_FREE_RATE_ANNUAL)\n",
        "    metrics[\"trades\"] = trades\n",
        "    if metrics[\"max_drawdown\"] > 0:\n",
        "        metrics[\"return_to_max_drawdown\"] = metrics[\"total_return\"] / metrics[\"max_drawdown\"]\n",
        "    else:\n",
        "        metrics[\"return_to_max_drawdown\"] = -999.0\n",
        "\n",
        "    logger.info(f\"Backtest completed: {metrics}\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "def run_backtest_v2_BAD(symbol_config: Dict[str, Any], prediction_agent, trade_params: Dict[str, Any], backtest_params: Dict[str, Any], data_slice: pd.DataFrame, symbol: str = \"Generic\") -> Dict[str, float]:\n",
        "    initial_capital = symbol_config.get(\"initial_capital\", 100000)\n",
        "    look_back = trade_params.get(\"look_back\", symbol_config.get(\"look_back\", 72))\n",
        "\n",
        "    df = data_slice.copy()\n",
        "\n",
        "    # Validate data slice\n",
        "    if df.empty or len(df) < look_back + 20:\n",
        "        logger.error(f\"Data slice too short: {len(df)} rows, need at least {look_back + 20}\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    # Precompute indicators\n",
        "    df = calculate_indicators(df, symbol, rsi_window=14, macd_fast=12, macd_slow=26, macd_signal=9, bb_window=20)\n",
        "\n",
        "    base_symbol = symbol.split(\"/\")[0]\n",
        "    # Features used for prediction (should match the model's input shape)\n",
        "    prediction_features = ['open', 'high', 'low', f'{base_symbol}_Close', 'volume', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'OBV', 'ATR']\n",
        "    # Features used for strategy logic (can include SMAs)\n",
        "    strategy_features = prediction_features + ['SMA_5', 'SMA_10', 'SMA_20']\n",
        "\n",
        "    logger.info(f\"Prediction features used: {prediction_features}\")\n",
        "    logger.info(f\"Strategy features used: {strategy_features}\")\n",
        "\n",
        "    # Check NaN counts before dropping\n",
        "    nan_counts_prediction = df[prediction_features].isna().sum()\n",
        "    nan_counts_strategy = df[strategy_features].isna().sum()\n",
        "    logger.info(f\"NaN counts before dropna (Prediction Features): {nan_counts_prediction.to_dict()}\")\n",
        "    logger.info(f\"NaN counts before dropna (Strategy Features): {nan_counts_strategy.to_dict()}\")\n",
        "\n",
        "    # Forward-fill and drop NaNs for strategy features (which include prediction features)\n",
        "    df = df[strategy_features].ffill()\n",
        "    df = df.dropna()\n",
        "\n",
        "    if df.empty or len(df) < look_back + 1:\n",
        "        logger.error(f\"DataFrame empty after preprocessing: {len(df)} rows remaining\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    logger.info(f\"DataFrame after preprocessing: {len(df)} rows\")\n",
        "\n",
        "    # Batch predictions using only prediction features\n",
        "    windows = [df.iloc[i - look_back:i][prediction_features].values for i in range(look_back, len(df))]\n",
        "    if not windows:\n",
        "        logger.error(\"No windows available for prediction\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_windows = [scaler.fit_transform(window) for window in windows if window.shape[0] == look_back]\n",
        "\n",
        "    # Ensure consistent feature count (12 for prediction)\n",
        "    X_batch = np.array([window for window in scaled_windows if window.shape[1] == 12])\n",
        "    if len(X_batch) == 0:\n",
        "        logger.error(\"No valid windows for prediction after scaling and filtering\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "\n",
        "    pred_probs_batch = prediction_agent.predict(X_batch, verbose=0)\n",
        "    pred_stats = {'buy': [], 'sell': []}\n",
        "\n",
        "    capital = initial_capital\n",
        "    position_qty = 0.0\n",
        "    entry_price = 0.0\n",
        "    initial_stop_loss = 0.0\n",
        "    trailing_stop_price = 0.0\n",
        "    in_position = False\n",
        "    periods_in_position = 0\n",
        "    is_long = False\n",
        "    trades = 0\n",
        "    capital_history = [initial_capital]\n",
        "    max_capital = initial_capital\n",
        "\n",
        "    # Adjust loop range to match the predictions batch\n",
        "    # The loop iterates over the data slice from `look_back` to the end\n",
        "    loop_range = tqdm(range(look_back, len(df)), desc=\"Backtesting Progress\", leave=False)\n",
        "\n",
        "    try:\n",
        "        # Use enumerate to get both the index in the loop_range and the corresponding index in the df\n",
        "        for i, idx in enumerate(loop_range):\n",
        "            # Check if the index for pred_probs_batch is within bounds\n",
        "            pred_batch_index = idx - look_back\n",
        "            if pred_batch_index >= len(pred_probs_batch) or pred_batch_index < 0:\n",
        "                 logger.warning(f\"Skipping index {idx}: Out of bounds for prediction batch (size {len(pred_probs_batch)})\")\n",
        "                 current_price_for_history = df[f'{base_symbol}_Close'].iloc[idx] if idx < len(df[f'{base_symbol}_Close']) else (df[f'{base_symbol}_Close'].iloc[-1] if not df[f'{base_symbol}_Close'].empty else 0)\n",
        "                 capital_history.append(capital + (position_qty * current_price_for_history if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price_for_history) if in_position and not is_long else 0)))\n",
        "                 continue\n",
        "\n",
        "\n",
        "            pred_probs = pred_probs_batch[pred_batch_index]\n",
        "            pred_stats['buy'].append(pred_probs[1])\n",
        "            pred_stats['sell'].append(pred_probs[2])\n",
        "            logger.debug(f\"Predictions at index {idx}: buy={pred_probs[1]:.4f}, sell={pred_probs[2]:.4f}\")\n",
        "            current_price = df[f'{base_symbol}_Close'].iloc[idx]\n",
        "            atr = df['ATR'].iloc[idx]\n",
        "            sma_20 = df['SMA_20'].iloc[idx]\n",
        "            sma_10 = df['SMA_10'].iloc[idx]\n",
        "            sma_5 = df['SMA_5'].iloc[idx]\n",
        "            rsi = df['RSI'].iloc[idx]\n",
        "            macd = df['MACD'].iloc[idx]\n",
        "            macd_signal = df['MACD_Signal'].iloc[idx]\n",
        "\n",
        "\n",
        "            if current_price == 0 or atr == 0 or np.isnan(atr):\n",
        "                logger.warning(f\"Invalid data at index {idx}: price={current_price}, atr={atr}\")\n",
        "                capital_history.append(capital + (position_qty * current_price if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price) if in_position and not is_long else 0)))\n",
        "                continue\n",
        "\n",
        "\n",
        "            # Volatility filter\n",
        "            # Ensure there are enough previous candles for the rolling mean\n",
        "            rolling_atr_mean = df['ATR'].iloc[max(0, idx-50):idx].mean() if idx >= 50 else df['ATR'].mean()\n",
        "            if atr < trade_params.get(\"min_atr_threshold\", 0.05) * rolling_atr_mean:\n",
        "                logger.debug(f\"Filtered out trade at index {idx}: ATR {atr} < {trade_params.get('min_atr_threshold', 0.05)} * {rolling_atr_mean}\")\n",
        "                capital_history.append(capital + (position_qty * current_price if in_position and is_long else (abs(position_qty) * (2 * entry_price - current_price) if in_position and not is_long else 0)))\n",
        "                continue\n",
        "\n",
        "\n",
        "            # Breakeven Stop-Loss Logic\n",
        "            if in_position:\n",
        "                periods_in_position += 1\n",
        "                profit_margin_to_breakeven = atr * trade_params.get(\"breakeven_atr_multiplier\", 0.3)\n",
        "                if is_long and current_price > entry_price + profit_margin_to_breakeven:\n",
        "                    initial_stop_loss = max(initial_stop_loss, entry_price)\n",
        "                elif not is_long and current_price < entry_price - profit_margin_to_breakeven:\n",
        "                    initial_stop_loss = min(initial_stop_loss, entry_price)\n",
        "\n",
        "                # Profit-Lock Trailing Stop Logic\n",
        "                profit_lock_trigger = atr * trade_params.get(\"profit_lock_atr_multiplier\", 0.3)\n",
        "                trailing_stop_multiplier = trade_params.get(\"trailing_stop_multiplier\", 0.05)\n",
        "                if is_long and current_price > entry_price + profit_lock_trigger:\n",
        "                    new_trailing_stop = current_price * (1 - trailing_stop_multiplier)\n",
        "                    trailing_stop_price = max(trailing_stop_price, new_trailing_stop)\n",
        "                elif not is_long and current_price < entry_price - profit_lock_trigger:\n",
        "                    new_trailing_stop = current_price * (1 + trailing_stop_multiplier)\n",
        "                    trailing_stop_price = min(trailing_stop_price, new_trailing_stop)\n",
        "\n",
        "            if not in_position and capital > 0:\n",
        "                sl_distance = atr * trade_params.get(\"atr_multiplier_sl\", 0.5)\n",
        "                tp_distance = atr * trade_params.get(\"atr_multiplier_tp\", 2.0)\n",
        "                risk_per_trade_amount = capital * trade_params.get(\"risk_per_trade_percent\", 0.005)\n",
        "\n",
        "                # Risk-reward filter\n",
        "                if sl_distance > 0 and tp_distance / sl_distance < trade_params.get(\"min_risk_reward\", 0.1):\n",
        "                    logger.debug(f\"Filtered out trade at index {idx}: Risk-reward ratio {tp_distance/sl_distance} < {trade_params.get('min_risk_reward', 0.1)}\")\n",
        "                    capital_history.append(capital)\n",
        "                    continue\n",
        "\n",
        "                # Trend and momentum filter\n",
        "                trend_up = (current_price > sma_20 * 0.995 or current_price > sma_10 or current_price > sma_5 or rsi > 60 or macd > macd_signal)\n",
        "                trend_down = (current_price < sma_20 * 1.005 or current_price < sma_10 or current_price < sma_5 or rsi < 40 or macd < macd_signal)\n",
        "\n",
        "                # Hybrid Position Sizing\n",
        "                qty = 0\n",
        "                dynamic_sizing = trade_params.get(\"dynamic_position_sizing_method\", \"hybrid\")\n",
        "                if dynamic_sizing == \"fixed_ratio\":\n",
        "                    qty = (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price\n",
        "                elif dynamic_sizing == \"risk_based\":\n",
        "                    if sl_distance > 0:\n",
        "                        qty = risk_per_trade_amount / sl_distance\n",
        "                elif dynamic_sizing == \"volatility_based\":\n",
        "                    if atr > 0:\n",
        "                        position_size_factor = (1.0 / atr) * (capital * trade_params.get(\"volatility_size_factor\", 0.02))\n",
        "                        qty = min(position_size_factor, (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price)\n",
        "                elif dynamic_sizing == \"hybrid\":\n",
        "                    if sl_distance > 0 and atr > 0:\n",
        "                        risk_qty = risk_per_trade_amount / sl_distance\n",
        "                        vol_qty = (1.0 / atr) * (capital * trade_params.get(\"volatility_size_factor\", 0.02))\n",
        "                        qty = min(risk_qty, vol_qty)\n",
        "\n",
        "                # Cap position size\n",
        "                max_pos_size_qty = (capital * trade_params.get(\"max_position_size\", 0.15)) / current_price\n",
        "                qty = min(qty, max_pos_size_qty) if current_price > 0 else 0\n",
        "\n",
        "                if qty > 0:\n",
        "                    if (pred_probs[1] >= trade_params.get(\"confidence_threshold\", 0.005) or rsi > 60 or current_price > sma_10 or current_price > sma_5 or macd > macd_signal) and trend_up:\n",
        "                        entry_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        entry_cost = qty * entry_price\n",
        "                        entry_fee = entry_cost * FEE_RATE\n",
        "                        if capital >= entry_cost + entry_fee:\n",
        "                            capital -= entry_cost + entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = True\n",
        "                            position_qty = qty\n",
        "                            periods_in_position = 1\n",
        "                            initial_stop_loss = entry_price - sl_distance\n",
        "                            trailing_stop_price = initial_stop_loss\n",
        "                            trades += 1\n",
        "                            logger.info(f\"Long entry at index {idx}: price={entry_price}, qty={qty}, sl={initial_stop_loss}\")\n",
        "                    elif (pred_probs[2] >= trade_params.get(\"confidence_threshold\", 0.005) or rsi < 40 or current_price < sma_10 or current_price < sma_5 or macd < macd_signal) and trend_down:\n",
        "                        entry_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        short_proceeds = qty * entry_price\n",
        "                        entry_fee = short_proceeds * FEE_RATE\n",
        "                        if capital >= entry_fee:\n",
        "                            capital += short_proceeds - entry_fee\n",
        "                            in_position = True\n",
        "                            is_long = False\n",
        "                            position_qty = -qty\n",
        "                            periods_in_position = 1\n",
        "                            initial_stop_loss = entry_price + sl_distance\n",
        "                            trailing_stop_price = initial_stop_loss\n",
        "                            trades += 1\n",
        "                            logger.info(f\"Short entry at index {idx}: price={entry_price}, qty={qty}, sl={initial_stop_loss}\")\n",
        "\n",
        "            # Exit Conditions\n",
        "            if in_position:\n",
        "                exit_reason = None\n",
        "\n",
        "                # Dynamic take-profit\n",
        "                dynamic_tp_multiplier = trade_params.get(\"atr_multiplier_tp\", 2.0)\n",
        "                # Ensure there are enough previous candles for the rolling mean\n",
        "                rolling_atr_mean = df['ATR'].iloc[max(0, idx-50):idx].mean() if idx >= 50 else df['ATR'].mean()\n",
        "                if df['ATR'].iloc[idx] > rolling_atr_mean:\n",
        "                    dynamic_tp_multiplier *= 1.5\n",
        "\n",
        "                # Exit via Breakeven Stop or Initial Stop-Loss\n",
        "                if is_long and current_price <= initial_stop_loss:\n",
        "                    exit_reason = \"Stop-Loss\"\n",
        "                elif not is_long and current_price >= initial_stop_loss:\n",
        "                    exit_reason = \"Stop-Loss\"\n",
        "\n",
        "                # Exit via Trailing Stop\n",
        "                elif is_long and trailing_stop_price > initial_stop_loss and current_price <= trailing_stop_price:\n",
        "                    exit_reason = \"Trailing-Stop\"\n",
        "                elif not is_long and trailing_stop_price < initial_stop_loss and current_price >= trailing_stop_price:\n",
        "                    exit_reason = \"Trailing-Stop\"\n",
        "\n",
        "                # Take-Profit Exit\n",
        "                elif is_long and current_price >= entry_price + atr * dynamic_tp_multiplier:\n",
        "                    exit_reason = \"Take-Profit\"\n",
        "                elif not is_long and current_price <= entry_price - atr * dynamic_tp_multiplier:\n",
        "                    exit_reason = \"Take-Profit\"\n",
        "\n",
        "                # Time-Based Exit\n",
        "                elif periods_in_position > trade_params.get(\"max_hold_periods\", 72):\n",
        "                    exit_reason = \"Time-Based-Exit\"\n",
        "\n",
        "                if exit_reason:\n",
        "                    if is_long:\n",
        "                        if exit_reason == \"Time-Based-Exit\":\n",
        "                            exit_price = current_price\n",
        "                        else:\n",
        "                            exit_price = current_price * (1 - SLIPPAGE_BUFFER)\n",
        "                        exit_proceeds = position_qty * exit_price\n",
        "                        exit_fee = exit_proceeds * FEE_RATE\n",
        "                        capital += exit_proceeds - exit_fee\n",
        "                    else:  # Short position\n",
        "                        if exit_reason == \"Time-Based-Exit\":\n",
        "                            exit_price = current_price\n",
        "                        else:\n",
        "                            exit_price = current_price * (1 + SLIPPAGE_BUFFER)\n",
        "                        buyback_cost = abs(position_qty) * exit_price\n",
        "                        exit_fee = buyback_cost * FEE_RATE\n",
        "                        capital -= buyback_cost + exit_fee\n",
        "\n",
        "                    logger.info(f\"Exit at index {idx}: reason={exit_reason}, price={exit_price}, capital={capital}\")\n",
        "                    in_position = False\n",
        "                    periods_in_position = 0\n",
        "                    trailing_stop_price = 0.0\n",
        "                    initial_stop_loss = 0.0\n",
        "\n",
        "            current_portfolio_value = capital\n",
        "            if in_position:\n",
        "                if is_long:\n",
        "                    current_portfolio_value += position_qty * current_price\n",
        "                else:\n",
        "                    current_portfolio_value += abs(position_qty) * (2 * entry_price - current_price)\n",
        "            capital_history.append(current_portfolio_value)\n",
        "\n",
        "            max_capital = max(max_capital, current_portfolio_value)\n",
        "\n",
        "        # Log detailed prediction statistics\n",
        "        buy_probs = pred_probs_batch[:, 1].tolist() if pred_probs_batch.shape[1] > 1 else []\n",
        "        sell_probs = pred_probs_batch[:, 2].tolist() if pred_probs_batch.shape[1] > 2 else []\n",
        "\n",
        "        if buy_probs and sell_probs:\n",
        "             logger.info(f\"Prediction stats: Buy min={np.min(buy_probs):.4f}, Buy max={np.max(buy_probs):.4f}, Buy mean={np.mean(buy_probs):.4f}, Buy std={np.std(buy_probs):.4f}, \"\n",
        "                         f\"Sell min={np.min(sell_probs):.4f}, Sell max={np.max(sell_probs):.4f}, Sell mean={np.mean(sell_probs):.4f}, Sell std={np.std(sell_probs):.4f}\")\n",
        "        else:\n",
        "             logger.warning(\"Prediction probabilities list is empty, skipping detailed stats.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Backtest error: {str(e)}\")\n",
        "        return {\"total_return\": -100, \"sharpe_ratio\": -999, \"max_drawdown\": 1.0, \"trades\": 0, \"return_to_max_drawdown\": -999}\n",
        "\n",
        "    metrics = calculate_metrics(capital_history, 60, RISK_FREE_RATE_ANNUAL)\n",
        "    metrics[\"trades\"] = trades\n",
        "    if metrics[\"max_drawdown\"] > 0:\n",
        "        metrics[\"return_to_max_drawdown\"] = metrics[\"total_return\"] / metrics[\"max_drawdown\"]\n",
        "    else:\n",
        "        metrics[\"return_to_max_drawdown\"] = -999.0\n",
        "\n",
        "    logger.info(f\"Backtest completed: {metrics}\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# --- Keras Tuner Hypermodel Class with 5 New Parameters ---\n",
        "class BacktestHypermodel(kt.HyperModel):\n",
        "    def __init__(self, symbol_config: Dict[str, Any], prediction_agent, backtest_params: Dict[str, Any], data_slice: pd.DataFrame, symbol: str):\n",
        "        self.symbol_config = symbol_config\n",
        "        self.prediction_agent = prediction_agent\n",
        "        self.backtest_params = backtest_params\n",
        "        self.data_slice = data_slice\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def build(self, hp):\n",
        "        # Adjusted hyperparameter search space\n",
        "        hp.Float('confidence_threshold', min_value=0.005, max_value=0.02, step=0.005)  # Relaxed\n",
        "        hp.Float('atr_multiplier_tp', min_value=1.5, max_value=3.5, step=0.5)  # Tighter TP\n",
        "        hp.Float('atr_multiplier_sl', min_value=0.4, max_value=0.8, step=0.1)  # Tighter SL\n",
        "        hp.Float('max_position_size', min_value=0.1, max_value=0.2, step=0.05)  # Conservative sizing\n",
        "        hp.Float('breakeven_atr_multiplier', min_value=0.3, max_value=0.5, step=0.1)  # Tighter range\n",
        "        hp.Float('profit_lock_atr_multiplier', min_value=0.3, max_value=0.5, step=0.1)  # Tighter range\n",
        "        hp.Float('trailing_stop_multiplier', min_value=0.05, max_value=0.08, step=0.01)  # Tighter stops\n",
        "        hp.Float('risk_per_trade_percent', min_value=0.005, max_value=0.008, step=0.001)  # Lower risk\n",
        "        hp.Float('volatility_size_factor', min_value=0.01, max_value=0.02, step=0.005)  # Conservative sizing\n",
        "        hp.Int('look_back', min_value=72, max_value=72, step=12)  # Fixed to 72\n",
        "        hp.Int('max_hold_periods', min_value=72, max_value=120, step=24)  # Shorter holds\n",
        "        hp.Choice('dynamic_position_sizing_method', values=['hybrid', 'risk_based', 'volatility_based'])  # Prioritize hybrid\n",
        "        hp.Float('min_atr_threshold', min_value=0.05, max_value=0.15, step=0.05)  # Lower threshold\n",
        "        hp.Float('min_risk_reward', min_value=0.1, max_value=0.4, step=0.1)  # Relaxed RR\n",
        "        model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(12,))]) # Adjusted input shape back to 12 features\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        trade_params = {\n",
        "            'confidence_threshold': hp.get('confidence_threshold'),\n",
        "            'atr_multiplier_tp': hp.get('atr_multiplier_tp'),\n",
        "            'atr_multiplier_sl': hp.get('atr_multiplier_sl'),\n",
        "            'max_position_size': hp.get('max_position_size'),\n",
        "            'breakeven_atr_multiplier': hp.get('breakeven_atr_multiplier'),\n",
        "            'profit_lock_atr_multiplier': hp.get('profit_lock_atr_multiplier'),\n",
        "            'trailing_stop_multiplier': hp.get('trailing_stop_multiplier'),\n",
        "            'risk_per_trade_percent': hp.get('risk_per_trade_percent'),\n",
        "            'volatility_size_factor': hp.get('volatility_size_factor'),\n",
        "            'look_back': hp.get('look_back'),\n",
        "            'max_hold_periods': hp.get('max_hold_periods'),\n",
        "            'dynamic_position_sizing_method': hp.get('dynamic_position_sizing_method'),\n",
        "            'min_atr_threshold': hp.get('min_atr_threshold'),\n",
        "            'min_risk_reward': hp.get('min_risk_reward'),\n",
        "        }\n",
        "\n",
        "        results = run_backtest_v2(\n",
        "            symbol_config=self.symbol_config,\n",
        "            prediction_agent=self.prediction_agent,\n",
        "            trade_params=trade_params,\n",
        "            backtest_params=self.backtest_params,\n",
        "            data_slice=self.data_slice,\n",
        "            symbol=self.symbol\n",
        "        )\n",
        "\n",
        "        return results.get(self.backtest_params.get(\"optimization_metric\", \"sharpe_ratio\"), -999)\n",
        "\n",
        "class BacktestHypermodel_BAD(kt.HyperModel):\n",
        "    def __init__(self, symbol_config: Dict[str, Any], prediction_agent, backtest_params: Dict[str, Any], data_slice: pd.DataFrame, symbol: str):\n",
        "        self.symbol_config = symbol_config\n",
        "        self.prediction_agent = prediction_agent\n",
        "        self.backtest_params = backtest_params\n",
        "        self.data_slice = data_slice\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def build(self, hp):\n",
        "        # Adjusted hyperparameter search space to reduce drawdown\n",
        "        hp.Float('confidence_threshold', min_value=0.005, max_value=0.02, step=0.005)\n",
        "        hp.Float('atr_multiplier_tp', min_value=1.5, max_value=3.5, step=0.5)\n",
        "\n",
        "        # Tighter ATR stop-loss multiplier\n",
        "        hp.Float('atr_multiplier_sl', min_value=0.2, max_value=0.5, step=0.05)\n",
        "\n",
        "        # Reduced max position size\n",
        "        hp.Float('max_position_size', min_value=0.05, max_value=0.15, step=0.025)\n",
        "\n",
        "        # Tighter breakeven and profit-lock multipliers\n",
        "        hp.Float('breakeven_atr_multiplier', min_value=0.2, max_value=0.4, step=0.05)\n",
        "        hp.Float('profit_lock_atr_multiplier', min_value=0.2, max_value=0.4, step=0.05)\n",
        "\n",
        "        # Tighter trailing stop\n",
        "        hp.Float('trailing_stop_multiplier', min_value=0.02, max_value=0.05, step=0.01)\n",
        "\n",
        "        # Reduced risk per trade\n",
        "        hp.Float('risk_per_trade_percent', min_value=0.003, max_value=0.006, step=0.001)\n",
        "\n",
        "        hp.Float('volatility_size_factor', min_value=0.01, max_value=0.02, step=0.005)\n",
        "        hp.Int('look_back', min_value=72, max_value=72, step=12)\n",
        "        hp.Int('max_hold_periods', min_value=72, max_value=120, step=24)\n",
        "        hp.Choice('dynamic_position_sizing_method', values=['hybrid', 'risk_based', 'volatility_based'])\n",
        "        hp.Float('min_atr_threshold', min_value=0.05, max_value=0.15, step=0.05)\n",
        "        hp.Float('min_risk_reward', min_value=0.1, max_value=0.4, step=0.1)\n",
        "        model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(12,))])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        trade_params = {\n",
        "            'confidence_threshold': hp.get('confidence_threshold'),\n",
        "            'atr_multiplier_tp': hp.get('atr_multiplier_tp'),\n",
        "            'atr_multiplier_sl': hp.get('atr_multiplier_sl'),\n",
        "            'max_position_size': hp.get('max_position_size'),\n",
        "            'breakeven_atr_multiplier': hp.get('breakeven_atr_multiplier'),\n",
        "            'profit_lock_atr_multiplier': hp.get('profit_lock_atr_multiplier'),\n",
        "            'trailing_stop_multiplier': hp.get('trailing_stop_multiplier'),\n",
        "            'risk_per_trade_percent': hp.get('risk_per_trade_percent'),\n",
        "            'volatility_size_factor': hp.get('volatility_size_factor'),\n",
        "            'look_back': hp.get('look_back'),\n",
        "            'max_hold_periods': hp.get('max_hold_periods'),\n",
        "            'dynamic_position_sizing_method': hp.get('dynamic_position_sizing_method'),\n",
        "            'min_atr_threshold': hp.get('min_atr_threshold'),\n",
        "            'min_risk_reward': hp.get('min_risk_reward'),\n",
        "        }\n",
        "\n",
        "        results = run_backtest_v2(\n",
        "            symbol_config=self.symbol_config,\n",
        "            prediction_agent=self.prediction_agent,\n",
        "            trade_params=trade_params,\n",
        "            backtest_params=self.backtest_params,\n",
        "            data_slice=self.data_slice,\n",
        "            symbol=self.symbol\n",
        "        )\n",
        "\n",
        "        # Penalize trials that exceed the drawdown limit or have a negative return\n",
        "        max_drawdown_limit = self.backtest_params.get(\"max_drawdown_limit\", 0.25)\n",
        "        if results.get(\"max_drawdown\", 1.0) > max_drawdown_limit or results.get(\"total_return\", -100) < 0:\n",
        "            return -1000  # Return a very low score to discourage this trial\n",
        "\n",
        "        return results.get(self.backtest_params.get(\"optimization_metric\", \"sharpe_ratio\"), -999)\n"
      ],
      "metadata": {
        "id": "QUxt_-MqPJnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    symbol_config = config[\"SYMBOLS\"][0]\n",
        "    symbol = symbol_config[\"symbol\"]\n",
        "    look_back = symbol_config.get(\"look_back\", 72)\n",
        "\n",
        "    print(f\"--- Starting Walk-Forward Optimization for {symbol} ---\")\n",
        "\n",
        "    try:\n",
        "        prediction_agent = tf.keras.models.load_model(symbol_config[\"model_path\"])\n",
        "        print(f\"Model for {symbol} loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model for {symbol}: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Attempting to load data from database: {symbol_config['db_path']}\")\n",
        "    all_data = load_ohlcv_data_from_db(symbol_config['db_path'], symbol_config['table_name'])\n",
        "\n",
        "    if not all_data.empty:\n",
        "        all_data.reset_index(inplace=True)\n",
        "\n",
        "    print(\"\\n--- Head of the DataFrame ---\")\n",
        "    print(all_data.head())\n",
        "    print(\"\\n--- Tail of the DataFrame ---\")\n",
        "    print(all_data.tail())\n",
        "\n",
        "    total_candles = len(all_data)\n",
        "    look_back = symbol_config.get(\"look_back\", 72)\n",
        "\n",
        "    in_sample_size = 300\n",
        "    out_of_sample_size = 100\n",
        "    step_size = out_of_sample_size\n",
        "\n",
        "    min_required_candles = look_back + in_sample_size + out_of_sample_size\n",
        "    if total_candles < min_required_candles:\n",
        "        print(f\"Not enough data for a meaningful backtest. Need at least {min_required_candles} candles, found {total_candles}. Exiting.\")\n",
        "        return\n",
        "\n",
        "    start_index = look_back + in_sample_size\n",
        "    all_out_of_sample_metrics = []\n",
        "    # --- Change 1: Store a list of dictionaries containing both results and params ---\n",
        "    out_of_sample_results_with_params = []\n",
        "\n",
        "    if total_candles < look_back + in_sample_size + out_of_sample_size:\n",
        "         print(f\"Not enough data for walk-forward analysis. Need at least {look_back + in_sample_size + out_of_sample_size} candles, found {total_candles}. Exiting.\")\n",
        "         return\n",
        "\n",
        "    while start_index + out_of_sample_size <= total_candles:\n",
        "        end_index = start_index + out_of_sample_size\n",
        "\n",
        "        in_sample_slice = all_data.iloc[start_index - in_sample_size:start_index]\n",
        "\n",
        "        validation_slice_with_buffer = all_data.iloc[start_index - look_back : end_index]\n",
        "\n",
        "        print(f\"\\n--- Optimizing on data from {in_sample_slice['timestamp'].iloc[0]} to {in_sample_slice['timestamp'].iloc[-1]} ---\")\n",
        "        print(f\"In-sample data from {in_sample_slice['timestamp'].iloc[0]} to {in_sample_slice['timestamp'].iloc[-1]}\")\n",
        "        print(f\"Out-of-sample data from {validation_slice_with_buffer['timestamp'].iloc[0]} to {validation_slice_with_buffer['timestamp'].iloc[-1]} (with look-back buffer)\")\n",
        "        print('\\n')\n",
        "\n",
        "        print(f\"Total candles in-sample: {len(in_sample_slice)}\")\n",
        "        print(f\"Total candles out-of-sample (with buffer): {len(validation_slice_with_buffer)}\")\n",
        "        print(f\"Total candles total: {len(all_data)}\")\n",
        "        print(f\"Start Index: {start_index}\")\n",
        "        print(f\"End Index: {end_index}\")\n",
        "        print(f\"Step Size: {step_size}\")\n",
        "        nummber_windows=(total_candles - (look_back + in_sample_size)) // step_size\n",
        "        print(f\"Total Windows: {nummber_windows}\")\n",
        "        print('\\n')\n",
        "\n",
        "        directory = f'/content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_FETCH_{symbol.replace(\"/\", \"_\")}'\n",
        "        project_name = f'backtest_tuning_{symbol.replace(\"/\", \"_\")}_{start_index}'\n",
        "        print(f\"Directory: {directory}\")\n",
        "        print(f\"Project Name: {project_name}\")\n",
        "        print('\\n')\n",
        "\n",
        "        tuner = kt.Hyperband(\n",
        "            BacktestHypermodel(\n",
        "                symbol_config=symbol_config,\n",
        "                prediction_agent=prediction_agent,\n",
        "                backtest_params=symbol_config[\"backtest_params\"],\n",
        "                data_slice=in_sample_slice,\n",
        "                symbol=symbol\n",
        "            ),\n",
        "            objective=kt.Objective('sharpe_ratio', direction='max'),\n",
        "            max_epochs=1,\n",
        "            executions_per_trial=1,\n",
        "            directory=directory,\n",
        "            project_name=project_name,\n",
        "            overwrite=True,\n",
        "            max_consecutive_failed_trials=50\n",
        "        )\n",
        "\n",
        "        tuner.search(verbose=0)\n",
        "\n",
        "        best_trials = tuner.oracle.get_best_trials(num_trials=1)\n",
        "\n",
        "        if not best_trials:\n",
        "            print(f\"No successful trials found for this window. Skipping validation.\")\n",
        "            start_index += step_size\n",
        "            continue\n",
        "\n",
        "        best_trial = best_trials[0]\n",
        "        best_params = best_trial.hyperparameters.values\n",
        "        best_sharpe_ratio = best_trial.score\n",
        "\n",
        "        if best_sharpe_ratio is not None:\n",
        "            print(f\"\\nOptimal Parameters for this window: {best_params}\")\n",
        "            print(f\"Sharpe Ratio from Optimization: {best_sharpe_ratio:.2f}\")\n",
        "        else:\n",
        "            print(f\"\\nOptimal Parameters for this window: {best_params}\")\n",
        "            print(\"Sharpe Ratio from Optimization: N/A (No successful trials)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Validating on unseen data from {validation_slice_with_buffer['timestamp'].iloc[look_back]} to {validation_slice_with_buffer['timestamp'].iloc[-1]} ---\")\n",
        "        print(f\"Using parameters optimized on the previous in-sample window.\")\n",
        "\n",
        "        out_of_sample_results = run_backtest_v2(\n",
        "            symbol_config=symbol_config,\n",
        "            prediction_agent=prediction_agent,\n",
        "            trade_params=best_params,\n",
        "            backtest_params=symbol_config[\"backtest_params\"],\n",
        "            data_slice=validation_slice_with_buffer,\n",
        "            symbol=symbol\n",
        "        )\n",
        "\n",
        "        print(\"--- Validation Metrics ---\")\n",
        "        print(f\"Total Return: {out_of_sample_results['total_return']:.2f}%\")\n",
        "        print(f\"Sharpe Ratio: {out_of_sample_results['sharpe_ratio']:.2f}\")\n",
        "        print(f\"Max Drawdown: {out_of_sample_results['max_drawdown'] * 100:.2f}%\")\n",
        "        print(f\"Total Trades: {out_of_sample_results['trades']}\\n\")\n",
        "\n",
        "        all_out_of_sample_metrics.append(out_of_sample_results)\n",
        "        # --- Change 2: Append a dictionary with both results and parameters ---\n",
        "        out_of_sample_results_with_params.append({'results': out_of_sample_results, 'params': best_params})\n",
        "\n",
        "\n",
        "        start_index += step_size\n",
        "\n",
        "    if all_out_of_sample_metrics:\n",
        "        # --- Change 3: Find the best trial based on the highest out-of-sample Sharpe Ratio ---\n",
        "        best_out_of_sample_trial = max(out_of_sample_results_with_params, key=lambda x: x['results'].get('sharpe_ratio', -1000))\n",
        "\n",
        "        print(\"\\n--- Walk-Forward Final Results Summary ---\")\n",
        "        print(\"--- Best Out-of-Sample Parameters ---\")\n",
        "        print(best_out_of_sample_trial['params'])\n",
        "        print(\"\\n--- Aggregate Performance ---\")\n",
        "\n",
        "        # To avoid the crazy Sharpe Ratio, let's filter out the invalid values\n",
        "        valid_sharpes = [res['sharpe_ratio'] for res in all_out_of_sample_metrics if res['sharpe_ratio'] > -100]\n",
        "        if valid_sharpes:\n",
        "            total_sharpe = np.mean(valid_sharpes)\n",
        "        else:\n",
        "            total_sharpe = -999.0\n",
        "\n",
        "        total_return = np.sum([res['total_return'] for res in all_out_of_sample_metrics])\n",
        "        max_drawdown = np.max([res['max_drawdown'] for res in all_out_of_sample_metrics])\n",
        "        total_trades = np.sum([res['trades'] for res in all_out_of_sample_metrics])\n",
        "\n",
        "        print(f\"Average Out-of-Sample Sharpe Ratio: {total_sharpe:.2f}\")\n",
        "        print(f\"Total Compounded Return: {total_return:.2f}%\")\n",
        "        print(f\"Worst Out-of-Sample Max Drawdown: {max_drawdown * 100:.2f}%\\n\")\n",
        "        print(f\"Total Trades: {total_trades}\")\n",
        "    else:\n",
        "        print(\"No out-of-sample data was available to validate the strategy.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilBH-Jpca9e",
        "outputId": "352b0a64-0d73-4905-9b64-b0802174b958"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Walk-Forward Optimization for SOL/USD ---\n",
            "Model for SOL/USD loaded successfully.\n",
            "Attempting to load data from database: /content/gdrive/MyDrive/TradingBotLogs/ohlcv_data_ETH.db\n",
            "Successfully loaded and cleaned 720 candles from ethusd_1h_data_recent.\n",
            "\n",
            "--- Head of the DataFrame ---\n",
            "                  timestamp     open     high      low    close        volume\n",
            "0 2025-08-25 15:00:00+00:00  4659.33  4669.01  4605.54  4613.17    989.551876\n",
            "1 2025-08-25 16:00:00+00:00  4613.17  4644.13  4592.70  4600.00   1549.592972\n",
            "2 2025-08-25 17:00:00+00:00  4600.01  4600.01  4566.68  4586.74   1836.818605\n",
            "3 2025-08-25 18:00:00+00:00  4586.74  4596.29  4572.03  4575.00   1060.028528\n",
            "4 2025-08-25 19:00:00+00:00  4575.01  4575.01  4413.49  4418.60  14566.890305\n",
            "\n",
            "--- Tail of the DataFrame ---\n",
            "                    timestamp     open     high      low    close       volume\n",
            "715 2025-09-24 10:00:00+00:00  4183.39  4184.11  4168.01  4178.01   795.919419\n",
            "716 2025-09-24 11:00:00+00:00  4178.01  4275.48  4170.24  4183.21  5502.378360\n",
            "717 2025-09-24 12:00:00+00:00  4183.21  4187.48  4175.00  4181.42   184.719421\n",
            "718 2025-09-24 13:00:00+00:00  4181.43  4185.26  4149.96  4149.96   968.061012\n",
            "719 2025-09-24 14:00:00+00:00  4151.22  4167.29  4151.22  4161.75  1713.228301\n",
            "\n",
            "--- Optimizing on data from 2025-08-28 15:00:00+00:00 to 2025-09-10 02:00:00+00:00 ---\n",
            "In-sample data from 2025-08-28 15:00:00+00:00 to 2025-09-10 02:00:00+00:00\n",
            "Out-of-sample data from 2025-09-07 03:00:00+00:00 to 2025-09-14 06:00:00+00:00 (with look-back buffer)\n",
            "\n",
            "\n",
            "Total candles in-sample: 300\n",
            "Total candles out-of-sample (with buffer): 172\n",
            "Total candles total: 720\n",
            "Start Index: 372\n",
            "End Index: 472\n",
            "Step Size: 100\n",
            "Total Windows: 3\n",
            "\n",
            "\n",
            "Directory: /content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_FETCH_SOL_USD\n",
            "Project Name: backtest_tuning_SOL_USD_372\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal Parameters for this window: {'confidence_threshold': 0.01, 'atr_multiplier_tp': 1.5, 'atr_multiplier_sl': 0.6000000000000001, 'max_position_size': 0.15000000000000002, 'breakeven_atr_multiplier': 0.5, 'profit_lock_atr_multiplier': 0.3, 'trailing_stop_multiplier': 0.07, 'risk_per_trade_percent': 0.007, 'volatility_size_factor': 0.01, 'look_back': 72, 'max_hold_periods': 72, 'dynamic_position_sizing_method': 'hybrid', 'min_atr_threshold': 0.1, 'min_risk_reward': 0.4, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "Sharpe Ratio from Optimization: 3.87\n",
            "\n",
            "--- Validating on unseen data from 2025-09-10 03:00:00+00:00 to 2025-09-14 06:00:00+00:00 ---\n",
            "Using parameters optimized on the previous in-sample window.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Validation Metrics ---\n",
            "Total Return: 0.30%\n",
            "Sharpe Ratio: 2.16\n",
            "Max Drawdown: 23.17%\n",
            "Total Trades: 9\n",
            "\n",
            "\n",
            "--- Optimizing on data from 2025-09-01 19:00:00+00:00 to 2025-09-14 06:00:00+00:00 ---\n",
            "In-sample data from 2025-09-01 19:00:00+00:00 to 2025-09-14 06:00:00+00:00\n",
            "Out-of-sample data from 2025-09-11 07:00:00+00:00 to 2025-09-18 10:00:00+00:00 (with look-back buffer)\n",
            "\n",
            "\n",
            "Total candles in-sample: 300\n",
            "Total candles out-of-sample (with buffer): 172\n",
            "Total candles total: 720\n",
            "Start Index: 472\n",
            "End Index: 572\n",
            "Step Size: 100\n",
            "Total Windows: 3\n",
            "\n",
            "\n",
            "Directory: /content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_FETCH_SOL_USD\n",
            "Project Name: backtest_tuning_SOL_USD_472\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal Parameters for this window: {'confidence_threshold': 0.01, 'atr_multiplier_tp': 3.0, 'atr_multiplier_sl': 0.8, 'max_position_size': 0.1, 'breakeven_atr_multiplier': 0.4, 'profit_lock_atr_multiplier': 0.5, 'trailing_stop_multiplier': 0.060000000000000005, 'risk_per_trade_percent': 0.008, 'volatility_size_factor': 0.01, 'look_back': 72, 'max_hold_periods': 120, 'dynamic_position_sizing_method': 'volatility_based', 'min_atr_threshold': 0.05, 'min_risk_reward': 0.2, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "Sharpe Ratio from Optimization: 1.21\n",
            "\n",
            "--- Validating on unseen data from 2025-09-14 07:00:00+00:00 to 2025-09-18 10:00:00+00:00 ---\n",
            "Using parameters optimized on the previous in-sample window.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Validation Metrics ---\n",
            "Total Return: -0.55%\n",
            "Sharpe Ratio: 2.38\n",
            "Max Drawdown: 17.23%\n",
            "Total Trades: 7\n",
            "\n",
            "\n",
            "--- Optimizing on data from 2025-09-05 23:00:00+00:00 to 2025-09-18 10:00:00+00:00 ---\n",
            "In-sample data from 2025-09-05 23:00:00+00:00 to 2025-09-18 10:00:00+00:00\n",
            "Out-of-sample data from 2025-09-15 11:00:00+00:00 to 2025-09-22 14:00:00+00:00 (with look-back buffer)\n",
            "\n",
            "\n",
            "Total candles in-sample: 300\n",
            "Total candles out-of-sample (with buffer): 172\n",
            "Total candles total: 720\n",
            "Start Index: 572\n",
            "End Index: 672\n",
            "Step Size: 100\n",
            "Total Windows: 3\n",
            "\n",
            "\n",
            "Directory: /content/gdrive/MyDrive/TradingBotLogs/tuning_results_WFO_FETCH_SOL_USD\n",
            "Project Name: backtest_tuning_SOL_USD_572\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal Parameters for this window: {'confidence_threshold': 0.01, 'atr_multiplier_tp': 3.0, 'atr_multiplier_sl': 0.7000000000000001, 'max_position_size': 0.2, 'breakeven_atr_multiplier': 0.5, 'profit_lock_atr_multiplier': 0.5, 'trailing_stop_multiplier': 0.07, 'risk_per_trade_percent': 0.008, 'volatility_size_factor': 0.015, 'look_back': 72, 'max_hold_periods': 96, 'dynamic_position_sizing_method': 'hybrid', 'min_atr_threshold': 0.05, 'min_risk_reward': 0.1, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "Sharpe Ratio from Optimization: 3.75\n",
            "\n",
            "--- Validating on unseen data from 2025-09-18 11:00:00+00:00 to 2025-09-22 14:00:00+00:00 ---\n",
            "Using parameters optimized on the previous in-sample window.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Validation Metrics ---\n",
            "Total Return: 40.41%\n",
            "Sharpe Ratio: 9.31\n",
            "Max Drawdown: 28.46%\n",
            "Total Trades: 7\n",
            "\n",
            "\n",
            "--- Walk-Forward Final Results Summary ---\n",
            "--- Best Out-of-Sample Parameters ---\n",
            "{'confidence_threshold': 0.01, 'atr_multiplier_tp': 3.0, 'atr_multiplier_sl': 0.7000000000000001, 'max_position_size': 0.2, 'breakeven_atr_multiplier': 0.5, 'profit_lock_atr_multiplier': 0.5, 'trailing_stop_multiplier': 0.07, 'risk_per_trade_percent': 0.008, 'volatility_size_factor': 0.015, 'look_back': 72, 'max_hold_periods': 96, 'dynamic_position_sizing_method': 'hybrid', 'min_atr_threshold': 0.05, 'min_risk_reward': 0.1, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "\n",
            "--- Aggregate Performance ---\n",
            "Average Out-of-Sample Sharpe Ratio: 4.62\n",
            "Total Compounded Return: 40.16%\n",
            "Worst Out-of-Sample Max Drawdown: 28.46%\n",
            "\n",
            "Total Trades: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    }
  ]
}