{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPN00g1YrJdN0Mu6ZVAUhv4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8eb6484dbada4a3293cdc3eb2d92c048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5eb0f20c31d498ebb0c1d11013fcd57",
              "IPY_MODEL_fd4b39298a734d28ae4418b7f607c651",
              "IPY_MODEL_7c340874e81a479f90e58fe3ff7d23d3"
            ],
            "layout": "IPY_MODEL_8d039e63fae64d5090ecab16657e01ef"
          }
        },
        "e5eb0f20c31d498ebb0c1d11013fcd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a85ccd251242179d421d6cc95c5efa",
            "placeholder": "​",
            "style": "IPY_MODEL_efc1e01f338d466982cd72b3a042d3f5",
            "value": "Generating train split: "
          }
        },
        "fd4b39298a734d28ae4418b7f607c651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86bd39ab95541c1a59ee0c93ce9d6fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_928e934d9b9040338133275b525918ca",
            "value": 1
          }
        },
        "7c340874e81a479f90e58fe3ff7d23d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160469d196af421dba58d5ac5e741c16",
            "placeholder": "​",
            "style": "IPY_MODEL_2febb4a6e85d44dbbae9e549a4e421c3",
            "value": " 10000/0 [00:00&lt;00:00, 74596.92 examples/s]"
          }
        },
        "8d039e63fae64d5090ecab16657e01ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a85ccd251242179d421d6cc95c5efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc1e01f338d466982cd72b3a042d3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86bd39ab95541c1a59ee0c93ce9d6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "928e934d9b9040338133275b525918ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "160469d196af421dba58d5ac5e741c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2febb4a6e85d44dbbae9e549a4e421c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70680ce80d14483daf76b27e6ba25ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c44f6cd2107d4fbb8fdaf789700a2f31",
              "IPY_MODEL_927090ec086349c6a1e9d1cddac8843b",
              "IPY_MODEL_2d32cf3fb578412899d056c3b39ba7f7"
            ],
            "layout": "IPY_MODEL_c39d9380b78e4717a591a6da308232b1"
          }
        },
        "c44f6cd2107d4fbb8fdaf789700a2f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4756b431c2a44c9a82b3e7645cf29173",
            "placeholder": "​",
            "style": "IPY_MODEL_3c80b87f111040f8ae6eff15d41b8fa5",
            "value": "Generating train split: "
          }
        },
        "927090ec086349c6a1e9d1cddac8843b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc55934bb514a74b8ec4bb136796638",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd404e7400de47859052c34e092b6e4c",
            "value": 1
          }
        },
        "2d32cf3fb578412899d056c3b39ba7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da63b60ae77148f8b5855b9b8e24c606",
            "placeholder": "​",
            "style": "IPY_MODEL_7e1ac7d511d44e8d83adcb0d87ed384a",
            "value": " 1000000/0 [00:10&lt;00:00, 118407.74 examples/s]"
          }
        },
        "c39d9380b78e4717a591a6da308232b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4756b431c2a44c9a82b3e7645cf29173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c80b87f111040f8ae6eff15d41b8fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc55934bb514a74b8ec4bb136796638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cd404e7400de47859052c34e092b6e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da63b60ae77148f8b5855b9b8e24c606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1ac7d511d44e8d83adcb0d87ed384a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/FineTuning_LLM_Meta_Llama_3_8B_for_MEDAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://llama.meta.com/docs/how-to-guides/fine-tuning/"
      ],
      "metadata": {
        "id": "n3kFUczO5Um3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etm0HfcZM151"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
        "#!pip install -U transformers\n",
        "!pip install -U flash-attn --no-build-isolation --quiet\n",
        "\n",
        "\n",
        "! pip install peft --quiet\n",
        "! pip install datasets trl ninja packaging --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet\n",
        "\n",
        "! pip install trl==0.8.6 -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install trl==0.8.6 -q"
      ],
      "metadata": {
        "id": "1DVJA1Qb3Eq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")"
      ],
      "metadata": {
        "id": "65JpttRiGxVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37yP0eJDM152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e216305-aac6-40b2-b2ff-931e581c16ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import IPython\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "S9qvxG2HYusD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "naQrZIQTY1wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "CR6cdH3Hyv3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtE9TuSMlUEc",
        "outputId": "56e80797-52ec-4b9f-d2b2-8feb5efbb370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y cuda-11-0"
      ],
      "metadata": {
        "id": "LY6iadKNl1Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapRov3hl4fT",
        "outputId": "8ddade38-9ae2-4e8d-afb7-f59330558e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Wed Jun 19 15:43:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0              46W / 400W |      5MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### conversational format\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "\n",
        "### instruction format\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7fKxR2rnbJ",
        "outputId": "19bca8f5-0672-4340-ac0c-05592c1df8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': '<prompt text>', 'completion': '<ideal generated text>'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/train_dataset.json\", split=\"train\")"
      ],
      "metadata": {
        "id": "SCd7-R-lsLQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-kFtkh8kiOn",
        "outputId": "3dcfca88-41ac-4bf3-e9de-da9380f982bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['abstract_id', 'text', 'location', 'label'],\n",
              "    num_rows: 3000000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[345]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahaI2KNwYcQ5",
        "outputId": "6dfc6286-08e5-45f6-ee24-d7fc0a72da54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "established LLC-PK1 cell lines of human pig and dog origin llcpk mdck were examined in terms of nephrotoxicity and ability to biotransform cyclosporine a csa all three cell lines exhibited a comparable concentration dependent cytotoxicity to csa treatment alterations in cell CF included a decreased transport of lysine an inhibition of growth and an activation of lysosomal and mitochondrial activity as indicated by the increased uptake of neutral red nr and increased reduction of the tetrazolium dye mtt at microm csa increased leakage of lactic dehydrogenase and MICs of gammaglutamyl transpeptidase ggt and nacetylbetadhexosaminidase were observed at h and microm csa a discrimination between csa and the less nephrotoxic cyclosporinecsh was shown for dna synthesis and nr uptake the contribution of extrarenal parameters on kidney cell function was studied by the addition of medium from HCs exposed to csa to the kidney cell lines a more potent inhibition of dna synthesis and enhanced reduction of mtt resulted than by addition of equimolar csa directly to the A6 these data indicate that hepatocyte constituents present in the medium due to csa treatment affect kidney cell function additionally the presence of csa metabolites may contribute to the csainduced nephrotoxicity the vascular nephrotoxicity induced by csa an increased deposition of platelets in the renal arterioles was mimicked by cocultures of ECM and platelets csa increased the aggregability and adherence of platelets to the ECM whereas csh had no effect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[345]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMbtvPqFkyFd",
        "outputId": "45540189-290b-4b58-f30e-5fe415536c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['renal epithelial']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_question=dataset['text']\n",
        "train_answer=dataset['label']"
      ],
      "metadata": {
        "id": "l0YsbCarv94g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/medal-qa.txt\n",
        "filename='/content/medal-qa.txt'\n",
        "\n",
        "import re\n",
        "\n",
        "# python object to be appended\n",
        "for n in range(10000):\n",
        "    if train_answer[n] == None:\n",
        "       train_answer[n] = 'Not possible to get or use'\n",
        "    string = train_answer[n]\n",
        "    #print(string)\n",
        "    #result = string.replace(\"\\nRef\", \"-Ref\")\n",
        "    str_question=train_question[n]\n",
        "    question= re.sub(\"\\n\", \"\", str_question)\n",
        "    #question=question[1:len(question)-1]\n",
        "    answer = re.sub(\"\\[\", \"\", str(string))\n",
        "    answer = re.sub(\"\\]\", \"\", str(answer))\n",
        "    answer0=answer[1:len(answer)-1]\n",
        "\n",
        "    if len(answer0)==0:\n",
        "        answer='Not possible to get or use'\n",
        "\n",
        "\n",
        "    text='<s>[INST] %s [/INST] %s </s>'%(question,answer0)\n",
        "    #print(text)\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(text + '\\n')"
      ],
      "metadata": {
        "id": "uZ2S19rIwMww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_question[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZeUHqjcBwO4a",
        "outputId": "d4a55431-9adb-4f8c-dbb3-a73b950d323e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to quantify the amount of CL NO harvested in modified RND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answer[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOLATL1WwWLF",
        "outputId": "3ea62b89-eeb8-4c0e-fac8-e0bd77e30bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['radical neck dissection']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text0 = load_dataset(\"text\", data_files=\"/content/medal-qa.txt\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8eb6484dbada4a3293cdc3eb2d92c048",
            "e5eb0f20c31d498ebb0c1d11013fcd57",
            "fd4b39298a734d28ae4418b7f607c651",
            "7c340874e81a479f90e58fe3ff7d23d3",
            "8d039e63fae64d5090ecab16657e01ef",
            "b8a85ccd251242179d421d6cc95c5efa",
            "efc1e01f338d466982cd72b3a042d3f5",
            "c86bd39ab95541c1a59ee0c93ce9d6fc",
            "928e934d9b9040338133275b525918ca",
            "160469d196af421dba58d5ac5e741c16",
            "2febb4a6e85d44dbbae9e549a4e421c3"
          ]
        },
        "id": "fhg0zGbIwfK1",
        "outputId": "a9066f9d-74e5-4205-c9ac-c502200b83f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb6484dbada4a3293cdc3eb2d92c048"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text0[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onW6yYEdzfBe",
        "outputId": "c5db2a92-cdc6-40c3-fbe7-f4ff46eee97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] radical neck dissection </s>'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=10000\n",
        "\n",
        "dataset_final_Question=dataset['text'][0:nrec]\n",
        "dataset_final_Answer=dataset['label'][0:nrec]\n",
        "dataset_final_text=text0[0:nrec]['text']"
      ],
      "metadata": {
        "id": "ZDbr5KCpwk9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasetF = pd.DataFrame() # Create an empty DataFrame\n",
        "datasetF['Question'] = dataset_final_Question\n",
        "datasetF['Answer'] = dataset_final_Answer\n",
        "datasetF['text'] = dataset_final_text"
      ],
      "metadata": {
        "id": "46EcsGDQwrNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "SabZFKG5wxUA",
        "outputId": "f8f96133-69cb-4ec5-cab6-db7b978a1165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "0     velvet antlers vas are commonly used in tradit...   \n",
              "1     the clinical features of our cases demonstrate...   \n",
              "2     ceftobiprole bpr is an investigational cephalo...   \n",
              "3     we have taken a basic biologic RPA to elucidat...   \n",
              "4     lipoperoxidationderived aldehydes for example ...   \n",
              "...                                                 ...   \n",
              "9995  the regulation of the number of extrajunctiona...   \n",
              "9996  a highresolution structure of the HPr hpr from...   \n",
              "9997  the short term metabolic effects of the in viv...   \n",
              "9998  we examined the effect of nnntrimethylsphingos...   \n",
              "9999  estrogenhydroxylase eh activity was measured b...   \n",
              "\n",
              "                                            Answer  \\\n",
              "0                 [transverse aortic constriction]   \n",
              "1                              [hodgkins lymphoma]   \n",
              "2                [methicillinsusceptible s aureus]   \n",
              "3             [parathyroid hormonerelated protein]   \n",
              "4                               [lipoperoxidation]   \n",
              "...                                            ...   \n",
              "9995                            [intracellular cl]   \n",
              "9996  [histidinecontaining phosphocarrier protein]   \n",
              "9997                [hexose monophosphate pathway]   \n",
              "9998                       [nndimethylsphingosine]   \n",
              "9999                             [medial preoptic]   \n",
              "\n",
              "                                                   text  \n",
              "0     <s>[INST] velvet antlers vas are commonly used...  \n",
              "1     <s>[INST] the clinical features of our cases d...  \n",
              "2     <s>[INST] ceftobiprole bpr is an investigation...  \n",
              "3     <s>[INST] we have taken a basic biologic RPA t...  \n",
              "4     <s>[INST] lipoperoxidationderived aldehydes fo...  \n",
              "...                                                 ...  \n",
              "9995  <s>[INST] the regulation of the number of extr...  \n",
              "9996  <s>[INST] a highresolution structure of the HP...  \n",
              "9997  <s>[INST] the short term metabolic effects of ...  \n",
              "9998  <s>[INST] we examined the effect of nnntrimeth...  \n",
              "9999  <s>[INST] estrogenhydroxylase eh activity was ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e744b59d-e220-4231-827a-d034a7742c48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
              "      <td>[transverse aortic constriction]</td>\n",
              "      <td>&lt;s&gt;[INST] velvet antlers vas are commonly used...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the clinical features of our cases demonstrate...</td>\n",
              "      <td>[hodgkins lymphoma]</td>\n",
              "      <td>&lt;s&gt;[INST] the clinical features of our cases d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
              "      <td>[methicillinsusceptible s aureus]</td>\n",
              "      <td>&lt;s&gt;[INST] ceftobiprole bpr is an investigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
              "      <td>[parathyroid hormonerelated protein]</td>\n",
              "      <td>&lt;s&gt;[INST] we have taken a basic biologic RPA t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lipoperoxidationderived aldehydes for example ...</td>\n",
              "      <td>[lipoperoxidation]</td>\n",
              "      <td>&lt;s&gt;[INST] lipoperoxidationderived aldehydes fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>the regulation of the number of extrajunctiona...</td>\n",
              "      <td>[intracellular cl]</td>\n",
              "      <td>&lt;s&gt;[INST] the regulation of the number of extr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>a highresolution structure of the HPr hpr from...</td>\n",
              "      <td>[histidinecontaining phosphocarrier protein]</td>\n",
              "      <td>&lt;s&gt;[INST] a highresolution structure of the HP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>the short term metabolic effects of the in viv...</td>\n",
              "      <td>[hexose monophosphate pathway]</td>\n",
              "      <td>&lt;s&gt;[INST] the short term metabolic effects of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>we examined the effect of nnntrimethylsphingos...</td>\n",
              "      <td>[nndimethylsphingosine]</td>\n",
              "      <td>&lt;s&gt;[INST] we examined the effect of nnntrimeth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>estrogenhydroxylase eh activity was measured b...</td>\n",
              "      <td>[medial preoptic]</td>\n",
              "      <td>&lt;s&gt;[INST] estrogenhydroxylase eh activity was ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e744b59d-e220-4231-827a-d034a7742c48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e744b59d-e220-4231-827a-d034a7742c48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e744b59d-e220-4231-827a-d034a7742c48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a665c03-72ea-4273-badd-29db825e8ee3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a665c03-72ea-4273-badd-29db825e8ee3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a665c03-72ea-4273-badd-29db825e8ee3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2f8d1250-1e59-41d9-8886-52032d6b9f8f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datasetF')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2f8d1250-1e59-41d9-8886-52032d6b9f8f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datasetF');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datasetF",
              "summary": "{\n  \"name\": \"datasetF\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9993,\n        \"samples\": [\n          \"the medicinal plant WS has been used for over centuries in indian ayurvedic medicine to treat a wide spectrum of disorders withaferin a wa a bioactive compound that is isolated from this plant has antiinflammatory immunomodulatory antiangiogenic and anticancer properties here we investigated MPM mpm suppressive effects of wa and the molecular mechanisms involved wa inhibited growth of the mu as well as patientderived mpm cells in part by decreasing the chymotryptic activity of the proteasome that resulted in increased levels of ubiquitinated proteins and proapoptotic proteasome target proteins p bax i\\u00ce\\u00bab\\u00ce\\u00b1 wa suppression of mpm growth also involved elevated apoptosis as evidenced by activation of proapoptotic p AS G1 protein kinase sapk and caspase elevated C2 of proapoptotic bax protein and PARP parp our studies including genearray based analyses further revealed that wa suppressed a number of cell growth and metastasispromoting genes including cmyc wa treatments also stimulated expression of the cell cycle and apoptosis RII protein carpccar a novel transducer of cell growth signaling knockdown of carp on the other hand interfered with mpm growth GABA effects of wa intraperitoneal administration of mgkg wa daily inhibited growth of mu mpm cellderived tumors in vivo in part by inhibiting proteasome activity and stimulating apoptosis together our in vitro and in vivo studies suggest that wa suppresses mpm growth by targeting multiple pathways that include blockage of proteasome activity and stimulation of apoptosis and thus holds promise as an antimpm agent\",\n          \"management of a spontaneous single duct PND without associated mass and normal mammography remains controversial our T0 examined the pathological results of women of all ages treated with microdochectomy for single duct PND malignant or premalignant lesions were identified in patient under years of age and patients over years papilloma was the most frequently identified pathology in both age CG of patients under years and over or equal to years of age our results suggest that microdochectomy is a safe ERP treatment in women aged over years\",\n          \"evidencebased recommendations on the clinical use of cardiopulmonary ET cpet in lung and HR disease are presented with reference to the assessment of exercise intolerance prognostic assessment and the DUE of therapeutic interventions eg drugs supplemental oxygen exercise training a commonly used MGS for recommendations in evidencebased guidelines was applied with the grade of recommendation ranging from a the highest to d the lowest for symptomlimited incremental exercise cpet indices such as peak VO2 vo vo at LT the slope of the ventilationco output relationship and the presence of arterial o desaturation have all been shown to have SP in prognostic evaluation in addition for assessment of interventions the tolerable duration of symptomlimited highintensity constantload exercise often provides greater sensitivity to discriminate change than the CP incremental test fieldtesting paradigms eg timed and shuttle walking tests also prove valuable in turn these considerations allow the resolution of practical questions that often confront the clinician such as when should an DUE of exercise intolerance be sought which particular form of test should be asked for and what cluster of variables should be selected when evaluating prognosis for a particular disease or the effect of a particular intervention\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9996,\n        \"samples\": [\n          \"<s>[INST] spherical nanocrystal of AP has been proved to be beneficial for osteoblast growth two apatites with spherical nanocrystal morphology were prepared in this study by chemical wet method and further sintering process sem exhibited that both apatites had spherical nanocrystal morphology the crystal morphology and size was approaching to each other xrd showed the apatites separately were hydroxyapatite and tricalcium phosphate phases the cellular biocompatibility was evaluated by OBs for these two spherical nanocrstal apatites the mtt result indicated a higher cell proliferation rate for spherical TCP group the alp activity CA also strongly favored the TCP group rtpcr results indicated that collagen i had a higher transcription level on the spherical tricalcium phosphate group sem results showed robust cell growth on the materials it was concluded that the spherical nanophase TCP was superior to the cellular biocompatibility of spherical nanophase hydroxyapatite and the results were helpful in the manufacture of more suitable TE scaffolds [/INST] tricalcium phosphate </s>\",\n          \"<s>[INST] local cbf lcbf was determined in the same rat model and at the same intervals of TD and reversal as in previous studies of local CBF gl utilization lcgu and ph lcph the results showed that prior to the appearance of the clinical sequelae of B1 deficiency opisthotonus which usually occurs on day of deficiency CBF structures such as the mammillary body VN inferior colliculus and TH showed significant hyperperfusion reaching greater than of control values at opisthotonus there was a general decline in lcbf but in addition the larger of these structures developed inhomogeneous perfusion with patches of hyperperfusion adjacent to others of LF seven days of thiamine replenishment at opisthotonus resulted in delayed hypoperfusion notably in the mammillary body IC and thalamic nuclei superimposition of the lcbf lcgu and lcph data reveals that structures known to be vulnerable to the development of histological lesions in this model showed an EP of hyperperfusion uncoupled from declining lcgu and normal lcph then following a significant but only focal rise in lcgu between days and of deficiency hyperperfusion persisted while the ph was dropping and lcgu was rapidly declining the phase of patchy perfusion occurred only in the histologically vulnerable structures when lcgu was very low and acidosis was at its peak suggesting that it may have resulted from these opposing influences on lcbf following replenishment with thiamine the vulnerable structures showed delayed hypoperfusion coupled to lcguabstract truncated at words [/INST] inferior colliculus </s>\",\n          \"<s>[INST] thirteen antimicrobial agents and betalactamase inhibitor combinations were tested simultaneously for their invitro activity against a range of anaerobic gramnegative bacilli with a standard REF agar dilution method overall metronidazole imipenem ampicillinsulbactam ticarcillinclavulanic acid and cefoperazonesulbactam followed by CLI cefoxitin and piperacillin had the greatest activity cefotetan ceftizoxime and CPZ were moderately active while ampicillin and penicillin were least active metronidazole was the only drug active against all strains but only one CS was resistant to imipenem resistance was highest among certain members of the bacteroides fragilis group but was observed also among numerous other bacteroides species betalactamase was produced by of strains in the b fragilis group and by of strains overall the activities of CLI and cefoxitin were compared with those in previous surveys since at our institution no clear evidence of increasing resistance was demonstrated but the data emphasized the significant effects resulting from variations in susceptibility testing [/INST] cefoperazone </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['Question'][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TThUnFTMwyTi",
        "outputId": "b657e6a7-61fe-4961-bc0d-b36dab33d649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to quantify the amount of CL NO harvested in modified RND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['Answer'][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaqVKy61xwCR",
        "outputId": "ad1debd1-4651-4c55-8cb4-ae53adf72c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['radical neck dissection']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetF['text'][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PbJ9mfLtxxD5",
        "outputId": "c964546f-cf80-4394-fabd-3042ac75ae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] to quantify the amount of CL NO harvested in modified RND [/INST] radical neck dissection </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "# Hugging Face model id\n",
        "#model_id = \"mistralai/Mistral-7B-Instruct-v0.1\" #01 march 2024 AND 10/03/2024\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B\" #22 MAY 2024\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n"
      ],
      "metadata": {
        "id": "lQm2yo0uslTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "kxOWr2VvEGKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca1c171-c1aa-4639-f8b2-bb515f454da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaFlashAttention2(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=128,\n",
        "        lora_dropout=0.05,\n",
        "        r=256,\n",
        "        bias=\"none\",\n",
        "        target_modules=\"all-linear\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "kjyYx9WmtMmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A warm-up is in general an increase of the learning rate. It starts at 0 and then increases linearly over 1(here) step to the specified learning rate of 1.25e-5.\n",
        "\n",
        "Afterwards by default a linear (in other cases a cosine) learning-rate scheduler decays your learning-rate.\n",
        "\n",
        "To disable the decay add lr_scheduler_type='constant'. Iirc, this also disables the warmup. If you want warmup and afterwards a constant rate use constant_with_warmup instead."
      ],
      "metadata": {
        "id": "IRGZYQ4vwRDv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkMVebosM16A"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"/content/gdrive/MyDrive/model/Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine\",\n",
        "\n",
        "    #num_train_epochs=3,                     # number of training epochs\n",
        "    num_train_epochs=10,                    # number of training epochs for POC\n",
        "    per_device_train_batch_size=3,          # batch size per device during training\n",
        "    #2\n",
        "    gradient_accumulation_steps=6,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    #gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "\n",
        "    #ELECTRA is trained with Adam optimizer with learning\n",
        "    #rate of 0.00002 and with batch size of 16\n",
        "\n",
        "    #trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper # i used in the first model\n",
        "    #learning_rate=1.41e-6,\n",
        "    # --lr 2e-6\n",
        "\n",
        "    #Common Range: The most common range for fine-tuning learning rates is between 1e-5 and 1e-3.\n",
        "    #However, the optimal value will depend on various factors, including the model architecture,\n",
        "    #the dataset size, and the specific fine-tuning task.\n",
        "\n",
        "    #learning_rate=1.41e-5,\n",
        "    bf16=True,                              # use bfloat16 precision\n",
        "    tf32=True,                              # use tf32 precision\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper = 0.03\n",
        "\n",
        "    #Here's why 0.03 is a good initial choice:\n",
        "#Common Practice: It's a value that's frequently used and has been shown to work well in a variety of situations.\n",
        "#Balance: It offers a good balance between giving the model time to warm up and not spending too much of your training budget on the warmup phase.\n",
        "#Flexibility: You can always adjust the warmup_ratio up or down based on the specific characteristics of your model and dataset.\n",
        "\n",
        "    #Yes, a `warmup_ratio` of 0.03 is generally a good starting point for many training scenarios.\n",
        "    #It's a common and well-established practice that can help stabilize training and improve the performance of your model.\n",
        "\n",
        "    #lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    lr_scheduler_type=\"cosine\",            # lr_scheduler_type=\"cosine\" (Cosine Annealing Learning Rate)\n",
        "\n",
        "    #In many cases, cosine annealing often outperforms a constant learning rate due\n",
        "    #to its ability to adapt the learning rate during training.\n",
        "    #This can lead to faster convergence and better model performance.\n",
        "\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
        "    #force_download=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Administration routines for huggingface.co"
      ],
      "metadata": {
        "id": "K9R0ThHfzO5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl -q"
      ],
      "metadata": {
        "id": "lEIGVWGp2dB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable() #enable gradient checkpoint\n",
        "#torch.utils.checkpoint.checkpoint(use_reentrant=False)"
      ],
      "metadata": {
        "id": "wd03Af2od_qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/trl/main/en/sft_trainer"
      ],
      "metadata": {
        "id": "e6Yk7MlowDT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "import datasets\n",
        "\n",
        "# Convert Pandas DataFrame to Hugging Face Dataset\n",
        "datasetF_hf = datasets.Dataset.from_pandas(datasetF)\n",
        "\n",
        "max_seq_length = 3072 # max sequence length for model and packing of the dataset\n",
        "\n",
        "# Explicitly set the device using torch.device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the device\n",
        "#model.to(device)\n",
        "\n",
        "# Add a padding token to your tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Or, add a new padding token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=datasetF_hf,\n",
        "    dataset_text_field=\"text\", ### added for the summarization dataset\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,  # We template with special tokens\n",
        "        \"append_concat_token\": False, # No need to add additional separator token\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "we8LmPrO_AG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py"
      ],
      "metadata": {
        "id": "7nuyiFKmWfvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download`\n",
        "#is deprecated and will be removed in version 1.0.0. Downloads always resume when possible.\n",
        "#If you want to force a new download, use `force_download=True`.\n",
        "\n",
        "#!pip show huggingface_hub\n",
        "\n",
        "#Upgrade: If you have an older version (anything below 1.0.0), upgrade to the latest version using:\n",
        "\n",
        "#!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "BR_hut1GT9Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCq7Dq8f7VPU"
      },
      "outputs": [],
      "source": [
        "# start training, the model will be automatically saved to the hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mCxeJIj4KvSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Model and run Inference"
      ],
      "metadata": {
        "id": "IjTwqcXmK_OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "\n",
        "peft_model_id = \"/content/gdrive/MyDrive/model/Meta-Llama-3-8B-MEDAL-flash-attention-2-cosine\"\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    peft_model_id,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "# load into pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kW_hl8YPKxQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s load our test dataset try to generate an instruction."
      ],
      "metadata": {
        "id": "h1DyOCUfLLn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "nBZbeEq-R_ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a22078c-a660-4225-eb44-0c2e34e1c82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaFlashAttention2(\n",
            "          (q_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=4096, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (k_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=1024, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (v_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=1024, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (o_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=4096, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=14336, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (up_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=4096, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=14336, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (down_proj): lora.Linear4bit(\n",
            "            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "            (lora_dropout): ModuleDict(\n",
            "              (default): Dropout(p=0.05, inplace=False)\n",
            "            )\n",
            "            (lora_A): ModuleDict(\n",
            "              (default): Linear(in_features=14336, out_features=256, bias=False)\n",
            "            )\n",
            "            (lora_B): ModuleDict(\n",
            "              (default): Linear(in_features=256, out_features=4096, bias=False)\n",
            "            )\n",
            "            (lora_embedding_A): ParameterDict()\n",
            "            (lora_embedding_B): ParameterDict()\n",
            "          )\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "eval_dataset = load_dataset(\"json\", data_files=\"/content/gdrive/MyDrive/datasets/McGill-NLP/test_dataset.json\", split=\"train\")\n",
        "nrec= randint(0, len(eval_dataset))\n",
        "nrec=6\n",
        "\n",
        "# Test on sample\n",
        "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")  # Add device_map\n",
        "prompt =  eval_dataset[nrec]['text']\n",
        "\n",
        "\n",
        "outputs = generation_pipeline(prompt, max_new_tokens=128, do_sample=True, temperature=0.9,\n",
        "                                  top_k=30, top_p=0.1, eos_token_id=tokenizer.eos_token_id,\n",
        "                                  pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "1uHtGXcrLKI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "70680ce80d14483daf76b27e6ba25ffe",
            "c44f6cd2107d4fbb8fdaf789700a2f31",
            "927090ec086349c6a1e9d1cddac8843b",
            "2d32cf3fb578412899d056c3b39ba7f7",
            "c39d9380b78e4717a591a6da308232b1",
            "4756b431c2a44c9a82b3e7645cf29173",
            "3c80b87f111040f8ae6eff15d41b8fa5",
            "5cc55934bb514a74b8ec4bb136796638",
            "cd404e7400de47859052c34e092b6e4c",
            "da63b60ae77148f8b5855b9b8e24c606",
            "7e1ac7d511d44e8d83adcb0d87ed384a"
          ]
        },
        "outputId": "624df34d-047d-48c1-c4d9-80ce217c3e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70680ce80d14483daf76b27e6ba25ffe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "ganswer"
      ],
      "metadata": {
        "id": "_GZg3t7d1z9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "da29d2b5-c464-4839-8ab2-44d982ae772a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'management of this debilitating condition [/INST] antral follicle count </s><s>[INST] the purpose of this study was to investigate the effect of the novel antifolate aminopterin on the survival of mu and human glioma cells in vitro and in vivo aminopterin was more effective than aminopterin in inhibiting the proliferation of gliomaderived cells the ic for aminopterin was microm the ic for aminopterin was microm aminopterin time dependently induced apoptosis in these cells which was associated with a decrease in the C2 of both intracellular glut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query:\\n{eval_dataset[nrec]['text']}\")\n",
        "print()\n",
        "oanswer=str(eval_dataset[nrec]['label'])\n",
        "oanswer=oanswer[2:len(oanswer)-2]\n",
        "print(f\"Original Answer:\\n{oanswer}\")\n",
        "print()\n",
        "ganswer=outputs[0]['generated_text'][len(prompt)+9:].strip()\n",
        "qc=str(ganswer).find('[INST]')\n",
        "ganswer=ganswer[0:qc-7]\n",
        "qc0=str(ganswer).find('[INST]')\n",
        "ganswer=str(ganswer)[0:qc0]\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "if qc>0:\n",
        "  ganswer=ganswer[qc+8:len(ganswer)]\n",
        "print(f\"Generated Answer:\\n{ganswer}\")\n",
        "print()\n",
        "if ganswer == oanswer:\n",
        "  print(\"Match\")\n",
        "else:\n",
        "  print(\"NO Match\")"
      ],
      "metadata": {
        "id": "4Q2zlGDkw1rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313e5820-a112-4e4c-8137-9c0c616f90ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "while diminished ovarian reserve dor predicts decreased ovarian response to stimulation it does not necessarily foretell about the fecundity cycle according to bolognas criteria laid down by the european society of human reproduction and embryology old age abnormal ovarian reserve tests such as AFC afc and antimullerian hormone amh as well as prior suboptimal response to stimulation are the main AF representing dor unfavorable response to maximal stimulation on two previous occasions may also represent dor among the ovarian reserve tests amh and afc are the most predictive values for dor AF which may give rise to dor include environmental factors autoimmune or metabolic disorders infections genetic abnormalities and iatrogenic causes such as smoking chemotherapy radiation and gynecologic surgeries besides studies have proposed endometriosis as a key contributor to dor and hence emphasized on its proper management to prevent additional damages leading to compromised fertility in summary dor is found to be a clinical challenge in the practice of fertility care with controversial countermeasures to prevent or treat the condition nevertheless some promising measure such as oocyte embryo and tissue cryopreservation ovarian transplantation dietary supplementation and the transfer of mitochondria have offered hopes towards ameliorating the burden of dor this review attempts to discuss dor from different perspectives and summarize some existing hopes in clinical practice\n",
            "\n",
            "Original Answer:\n",
            "antral follicle count\n",
            "\n",
            "Generated Answer:\n",
            "antral follicle count\n",
            "\n",
            "Match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrec=6\n",
        "print(f\"Query:\\n{eval_dataset[nrec]['text']}\")\n",
        "print()\n",
        "print(f\"Original Answer:\\n{eval_dataset[nrec]['label']}\")\n",
        "print()\n",
        "print(f\"Full Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")"
      ],
      "metadata": {
        "id": "VX6ChYhtvtat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748f3db9-d0c6-4e54-ccbb-7d054c90d45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "while diminished ovarian reserve dor predicts decreased ovarian response to stimulation it does not necessarily foretell about the fecundity cycle according to bolognas criteria laid down by the european society of human reproduction and embryology old age abnormal ovarian reserve tests such as AFC afc and antimullerian hormone amh as well as prior suboptimal response to stimulation are the main AF representing dor unfavorable response to maximal stimulation on two previous occasions may also represent dor among the ovarian reserve tests amh and afc are the most predictive values for dor AF which may give rise to dor include environmental factors autoimmune or metabolic disorders infections genetic abnormalities and iatrogenic causes such as smoking chemotherapy radiation and gynecologic surgeries besides studies have proposed endometriosis as a key contributor to dor and hence emphasized on its proper management to prevent additional damages leading to compromised fertility in summary dor is found to be a clinical challenge in the practice of fertility care with controversial countermeasures to prevent or treat the condition nevertheless some promising measure such as oocyte embryo and tissue cryopreservation ovarian transplantation dietary supplementation and the transfer of mitochondria have offered hopes towards ameliorating the burden of dor this review attempts to discuss dor from different perspectives and summarize some existing hopes in clinical practice\n",
            "\n",
            "Original Answer:\n",
            "['antral follicle count']\n",
            "\n",
            "Full Generated Answer:\n",
            "for the management of this debilitating condition [/INST] antral follicle count </s><s>[INST] the purpose of this study was to investigate the effect of the novel antifolate aminopterin on the survival of mu and human glioma cells in vitro and in vivo aminopterin was more effective than aminopterin in inhibiting the proliferation of gliomaderived cells the ic for aminopterin was microm the ic for aminopterin was microm aminopterin time dependently induced apoptosis in these cells which was associated with a decrease in the C2 of both intracellular glut\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganswer=outputs[0]['generated_text'][len(prompt):].strip()\n",
        "qc=str(ganswer).find('[/INST]')\n",
        "#print(qc)\n",
        "if int(qc)<0:\n",
        "    #print(f\"Generated Answer:\\n{ganswer}\")\n",
        "    ganswer=outputs[0]['generated_text'][len(prompt)+8:].strip()\n",
        "else:\n",
        "    ganswer=ganswer[qc:len(ganswer)]\n",
        "ganswer"
      ],
      "metadata": {
        "id": "KcFTvrGSvJ8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1d9ac112-554a-4384-a6ef-cba1de22d0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[/INST] antral follicle count </s><s>[INST] the purpose of this study was to investigate the effect of the novel antifolate aminopterin on the survival of mu and human glioma cells in vitro and in vivo aminopterin was more effective than aminopterin in inhibiting the proliferation of gliomaderived cells the ic for aminopterin was microm the ic for aminopterin was microm aminopterin time dependently induced apoptosis in these cells which was associated with a decrease in the C2 of both intracellular glut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}