{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 111543,
          "databundleVersionId": 14348714,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 28.586492,
      "end_time": "2025-11-18T04:12:09.016689",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-18T04:11:40.430197",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Copy_of_MVP_HTMP_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "8DdiKmMo5Cvg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "hull_tactical_market_prediction_path = kagglehub.competition_download('hull-tactical-market-prediction')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "7Z5GA8qT5Cvg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from pathlib import Path\n",
        "from kaggle_evaluation.default_inference_server import DefaultInferenceServer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "KAGGLE_INPUT_PATH = '/kaggle/input/hull-tactical-market-prediction/'\n",
        "MODEL_SAVE_PATH = '/tmp/lgbm_model.pkl'\n",
        "TARGET_COL = 'market_forward_excess_returns'\n",
        "\n",
        "SCALING_FACTOR = 10000.0\n",
        "\n",
        "# Comprehensive list of ALL possible feature names for dynamic filtering\n",
        "ALL_POSSIBLE_FEATURE_NAMES = [\n",
        "    'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20',\n",
        "    'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
        "    'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15',\n",
        "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20',\n",
        "    'I1', 'I2', 'I3', 'I4', 'I5', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9',\n",
        "    'MOM1', 'MOM2', 'MOM3', 'MOM4', 'MOM5', 'MOM6', 'MOM7', 'MOM8', 'MOM9', 'MOM10',\n",
        "    'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15'\n",
        "]\n",
        "EXCLUDE_COLS = [\n",
        "    'date_id', TARGET_COL, 'forward_returns', 'risk_free_rate'\n",
        "]\n",
        "GLOBAL_TRAINING_FEATURE_COLS = []\n",
        "\n",
        "\n",
        "# --- TRAINING PHASE (Model creation and saving) ---\n",
        "print(\"--- PHASE I: MODEL TRAINING ---\")\n",
        "try:\n",
        "    # 1. Load Data\n",
        "    df_train = pd.read_csv(Path(KAGGLE_INPUT_PATH) / 'train.csv')\n",
        "\n",
        "    # 2. Dynamic Feature Determination & Cleansing Setup\n",
        "    current_feature_cols = [col for col in ALL_POSSIBLE_FEATURE_NAMES if col in df_train.columns and col not in EXCLUDE_COLS]\n",
        "    GLOBAL_TRAINING_FEATURE_COLS = current_feature_cols\n",
        "\n",
        "    # 3. Data Cleansing (Converts non-numeric strings to NaN)\n",
        "    for col in GLOBAL_TRAINING_FEATURE_COLS:\n",
        "        df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
        "\n",
        "    # 4. Prepare Data for Training (Drop rows with missing target)\n",
        "    df_train.dropna(subset=[TARGET_COL], inplace=True)\n",
        "\n",
        "    X = df_train[GLOBAL_TRAINING_FEATURE_COLS]\n",
        "    y = df_train[TARGET_COL]\n",
        "\n",
        "    print(f\"Training on {len(X)} rows and {len(GLOBAL_TRAINING_FEATURE_COLS)} features...\")\n",
        "\n",
        "    # 5. Train Model (V3's proven configuration)\n",
        "    lgbm = lgb.LGBMRegressor(\n",
        "        objective='regression',\n",
        "        metric='rmse',\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.08,\n",
        "        num_leaves=63,         # V3's proven complexity\n",
        "        max_depth=8,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=-1 # Suppresses LightGBM output/warnings\n",
        "    )\n",
        "    print(\"Training LightGBM model...\")\n",
        "    lgbm.fit(X, y)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # 6. Save the Trained Model\n",
        "    joblib.dump({\n",
        "        'model': lgbm,\n",
        "        'features': GLOBAL_TRAINING_FEATURE_COLS\n",
        "    }, MODEL_SAVE_PATH)\n",
        "    print(f\"Trained model and feature list saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"FATAL ERROR during TRAINING PHASE: {e}\")\n",
        "    class DummyModel:\n",
        "        def predict(self, X): return np.array([0.0] * len(X))\n",
        "    joblib.dump({'model': DummyModel(), 'features': []}, MODEL_SAVE_PATH)\n",
        "\n",
        "\n",
        "# --- INFERENCE PHASE (Submission setup and logic) ---\n",
        "print(\"\\n--- PHASE II: SUBMISSION INFERENCE SETUP ---\")\n",
        "MODEL_LOADED = False\n",
        "GLOBAL_MODEL = None\n",
        "GLOBAL_INFERENCE_FEATURE_COLS = []\n",
        "\n",
        "def predict(test) -> float:\n",
        "    \"\"\"\n",
        "    The function executed by the evaluation API for each time step.\n",
        "    It returns the optimal allocation (0.0 to 2.0).\n",
        "    \"\"\"\n",
        "    global MODEL_LOADED, GLOBAL_MODEL, GLOBAL_INFERENCE_FEATURE_COLS\n",
        "\n",
        "    if not MODEL_LOADED:\n",
        "        try:\n",
        "            loaded_data = joblib.load(MODEL_SAVE_PATH)\n",
        "            GLOBAL_MODEL = loaded_data['model']\n",
        "            GLOBAL_INFERENCE_FEATURE_COLS = loaded_data['features']\n",
        "\n",
        "            MODEL_LOADED = True\n",
        "            print(\"Model and feature list loaded. Starting live prediction...\")\n",
        "        except Exception as e:\n",
        "            print(f\"FATAL ERROR during model loading: {e}\")\n",
        "            return 1.0\n",
        "\n",
        "    # --- INFERENCE LOGIC ---\n",
        "    df_test = test.to_pandas() if not isinstance(test, pd.DataFrame) else test\n",
        "\n",
        "    # 1. Feature Preparation (Using original 86 features)\n",
        "    X_test = pd.DataFrame(index=df_test.index)\n",
        "\n",
        "    for col in GLOBAL_INFERENCE_FEATURE_COLS:\n",
        "        if col in df_test.columns:\n",
        "            X_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
        "        else:\n",
        "            X_test[col] = np.nan\n",
        "\n",
        "    # 2. Prediction\n",
        "    raw_prediction = GLOBAL_MODEL.predict(X_test[GLOBAL_INFERENCE_FEATURE_COLS])[0]\n",
        "\n",
        "\n",
        "    # 3. Allocation Sizing (SCALING_FACTOR = 15.0)\n",
        "    allocation_size = 1.0 + (raw_prediction * SCALING_FACTOR)\n",
        "\n",
        "    # Enforce the competition's allowed range (0.0 to 2.0)\n",
        "    final_allocation = np.clip(allocation_size, 0.0, 2.0)\n",
        "\n",
        "    return final_allocation\n",
        "\n",
        "# --- 7. RUN THE INFERENCE SERVER (The core submission endpoint) ---\n",
        "\n",
        "inference_server = DefaultInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    print(\"Running in RERUN mode...\")\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    print(\"Running local gateway for testing...\")\n",
        "    inference_server.run_local_gateway((KAGGLE_INPUT_PATH,))\n",
        "\n",
        "print(\"Submission script finished.\")"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2025-11-18T04:43:21.115585Z",
          "iopub.execute_input": "2025-11-18T04:43:21.115908Z",
          "iopub.status.idle": "2025-11-18T04:43:52.840026Z",
          "shell.execute_reply.started": "2025-11-18T04:43:21.115887Z",
          "shell.execute_reply": "2025-11-18T04:43:52.839259Z"
        },
        "papermill": {
          "duration": 23.519226,
          "end_time": "2025-11-18T04:12:08.134096",
          "exception": false,
          "start_time": "2025-11-18T04:11:44.61487",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "XJqOfij25Cvg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "submission_path = '/kaggle/working/submission.parquet'\n",
        "\n",
        "## ðŸ“Š SUBMISSION FILE VALIDATION\n",
        "\n",
        "# Check if the file was successfully created\n",
        "if not os.path.exists(submission_path):\n",
        "    print(f\"Validation Error: Submission file not found at {submission_path}\")\n",
        "    print(\"NOTE: This file is created during the 'Running local gateway for testing...' step.\")\n",
        "else:\n",
        "    try:\n",
        "        # Read the submission file\n",
        "        df_sub = pd.read_parquet(submission_path)\n",
        "\n",
        "        # --- Validation Checks ---\n",
        "\n",
        "        # 1. Identify the prediction column (the single float column)\n",
        "        float_cols = df_sub.select_dtypes(include=[np.float64]).columns\n",
        "\n",
        "        if len(float_cols) == 1:\n",
        "            prediction_col_name = float_cols[0]\n",
        "            print(f\"Column Check: Found single prediction column named '{prediction_col_name}'.\")\n",
        "        else:\n",
        "            prediction_col_name = 'allocation' # Use standard name for range check fallback\n",
        "            print(f\"Column Check: Found {len(float_cols)} float columns. Using '{prediction_col_name}' for range check.\")\n",
        "\n",
        "        # 2. Check allocation range (0.0 to 2.0)\n",
        "        if prediction_col_name in df_sub.columns:\n",
        "            min_val = df_sub[prediction_col_name].min()\n",
        "            max_val = df_sub[prediction_col_name].max()\n",
        "\n",
        "            # Check if all values are between 0.0 and 2.0 (inclusive)\n",
        "            if min_val >= 0.0 and max_val <= 2.0:\n",
        "                range_check = \"PASS\"\n",
        "            else:\n",
        "                range_check = f\"FAIL (Min: {min_val:.4f}, Max: {max_val:.4f})\"\n",
        "\n",
        "            print(f\"Allocation Range Check (0.0 to 2.0): {range_check}\")\n",
        "\n",
        "        # 3. Display the file info\n",
        "        print(\"\\nFirst 5 Rows of Submission:\")\n",
        "        print(df_sub.head())\n",
        "\n",
        "        print(\"\\nSubmission Info:\")\n",
        "        df_sub.info()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Validation Error: Could not read or process the Parquet file. Error: {e}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-18T04:43:52.841254Z",
          "iopub.execute_input": "2025-11-18T04:43:52.841528Z",
          "iopub.status.idle": "2025-11-18T04:43:52.890156Z",
          "shell.execute_reply.started": "2025-11-18T04:43:52.841505Z",
          "shell.execute_reply": "2025-11-18T04:43:52.889447Z"
        },
        "papermill": {
          "duration": 0.060212,
          "end_time": "2025-11-18T04:12:08.196303",
          "exception": false,
          "start_time": "2025-11-18T04:12:08.136091",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "rdj8C_TO5Cvg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}