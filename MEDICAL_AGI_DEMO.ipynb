{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO4qE/fpTs5jE+tmuiWhlim",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MEDICAL_AGI_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT0do73tbGmb",
        "outputId": "ac2ffdf6-7159-4260-d72b-e3ad29996c28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoMCu_CZacp5",
        "outputId": "ba59bd68-1a2a-4e17-8561-5acaf10bde64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Multi-Agent Experiment Started at 01:47 AM  on October 22, 2025 ---\n",
            "\n",
            "--- Grounded Perception Facts Established (I-JEPA Layer Output) ---\n",
            "Fact Set: Colon distention, mural thickening, and fat stranding are observed.\n",
            "\n",
            "--- Iteration 1 ---\n",
            "Qwen3-VL Analysis Result: ### **Most Likely Diagnosis: Fecal Impaction with Secondary Obstructive Colitis ...\n",
            "Validation Agent Feedback: [\"Diagnosis is missing the precise medical term 'Stercoral Colitis'.\", 'The acute intervention plan lacks specific mention of endoscopic methods for evacuation.']\n",
            "\n",
            "--- Iteration 2 ---\n",
            "Qwen3-VL Analysis Result: ### **Radiological Analysis and Diagnosis**  \n",
            "\n",
            "#### **Critical Findings from CT ...\n",
            "Validation Agent Feedback: ['Output aligns with expected clinical criteria.']\n",
            "\n",
            "**AGENTS CONVERGED: Validation criteria met. Stopping iteration.**\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import base64\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "\n",
        "# --- CONCEPTUAL I-JEPA MODULE START ---\n",
        "\n",
        "# Function to conceptually represent the I-JEPA call and feature compression\n",
        "def IJEPA_Feature_Extractor(client, image_url):\n",
        "    \"\"\"\n",
        "    Pillar 1: Simulates the Analog -> Digital conversion.\n",
        "    Returns a verifiable digital fact based on visual feature extraction.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # We use the Qwen API to simulate the Classifier Head's output (Analog -> Digital Bridge)\n",
        "        prompt_for_fact_extraction = (\n",
        "            \"You are a clinical image classifier. Based on the provided CT images, output ONLY \"\n",
        "            \"the raw, verifiable radiological signs (colon distention, mural thickening, fat stranding) \"\n",
        "            \"as a single, factual sentence. Do not diagnose.\"\n",
        "        )\n",
        "\n",
        "        # Check if the client is the Mock client (meaning a live call will not work anyway)\n",
        "        if hasattr(client, 'is_mock') or image_url is None:\n",
        "             return \"I-JEPA Feature Extraction Success (Simulated). Classifier Head Output: massive fecal burden, colonic distention, mural thickening, and fat stranding.\"\n",
        "\n",
        "        # Use the Multimodal LLM to simulate the classification step on the Base64 image\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"qwen/qwen3-vl-8b-thinking\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt_for_fact_extraction},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
        "                ]}\n",
        "            ],\n",
        "            timeout=30\n",
        "        )\n",
        "        return completion.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback returns the known ground truth findings\n",
        "        return f\"I-JEPA Execution Failed ({e}). Defaulting to: massive fecal burden, mural thickening, and fat stranding.\"\n",
        "\n",
        "# --- CONCEPTUAL I-JEPA MODULE END ---\n",
        "\n",
        "\n",
        "# --- 1. Client Setup and Utilities (Base64 FIX) ---\n",
        "\n",
        "# Client Setup (using OpenAI SDK pointing to OpenRouter API)\n",
        "try:\n",
        "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "    if not OPENROUTER_API_KEY:\n",
        "        raise ValueError(\"OPENROUTER_API_KEY is not set in Colab Secrets.\")\n",
        "    qwen_client = OpenAI (\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key=OPENROUTER_API_KEY,\n",
        "    )\n",
        "except Exception as e:\n",
        "    # Mock client logic for local execution/testing\n",
        "    class MockClient:\n",
        "        def __init__(self):\n",
        "            self.iteration = 0\n",
        "            self.is_mock = True # Add flag to identify mock client\n",
        "\n",
        "        def chat(self): return self\n",
        "        def completions(self): return self\n",
        "        def create(self, **kwargs):\n",
        "            self.iteration += 1\n",
        "            if self.iteration == 1:\n",
        "                 mock_content = \"### Most Likely Diagnosis: Fecal Impaction with Secondary Colitis. Acute Management: Enemas. Long-Term: Physical Therapy.\"\n",
        "            elif self.iteration == 2:\n",
        "                 mock_content = \"### Most Likely Diagnosis: Stercoral Colitis. Acute Management: Endoscopic removal (flexible sigmoidoscopy). Long-Term: Physical Therapy. Potential Complications: Necrosis.\"\n",
        "            else:\n",
        "                 mock_content = f\"### Most Likely Diagnosis: Stercoral Colitis. Acute Management: Endoscopic removal (flexible sigmoidoscopy). Long-Term: Pelvic-Floor Physical Therapy, Anorectal Manometry, and Biofeedback. Potential Complications: Focal-Pressure Necrosis and Perforation.\"\n",
        "\n",
        "            if self.iteration >= 5:\n",
        "                 return None\n",
        "\n",
        "            mock_choice = type('MockChoice', (object,), {'message': type('MockMessage', (object,), {'content': mock_content})()})\n",
        "            return type('MockResponse', (object,), {\n",
        "                'choices': [mock_choice]\n",
        "            })()\n",
        "\n",
        "    qwen_client = MockClient()\n",
        "    print(f\"Using Mock Client due to configuration error: {e}. Output will be simulated.\")\n",
        "\n",
        "# Utility Function: Convert Local Image to Base64 (FIXED)\n",
        "def image_to_base64(file_path):\n",
        "    \"\"\"\n",
        "    Reads local file path and converts it to a Base64 data URI.\n",
        "    FIX: Returns None on failure to prevent passing a malformed URL to the API.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"Image file not found at {file_path}\")\n",
        "\n",
        "        with open(file_path, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "        if not encoded_string:\n",
        "            raise ValueError(\"Base64 encoding resulted in an empty string.\")\n",
        "\n",
        "        return f\"data:image/png;base64,{encoded_string}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return None on genuine file/encoding failure\n",
        "        print(f\"[BASE64 ERROR] File/Encoding failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 2. Agent Class Definitions ---\n",
        "\n",
        "class ImageAnalysisAgent:\n",
        "    \"\"\"Pillar 1: Perception/Fact Grounding. The wrapper for the I-JEPA pipeline.\"\"\"\n",
        "    def analyze_image(self, client, image_url):\n",
        "        # Delegate feature extraction and classification to the dedicated module\n",
        "        return IJEPA_Feature_Extractor(client, image_url)\n",
        "\n",
        "\n",
        "class ValidationAgent:\n",
        "    \"\"\"Pillars 3 & 4: Constraint and Safety Enforcement\"\"\"\n",
        "    def __init__(self):\n",
        "        self.expected_patterns = {\n",
        "            \"diagnosis\": [r\"stercoral\\s+colitis\"],\n",
        "            \"acute_procedure\": [r\"endoscopic\\s+(?:removal|disimpaction|evacuation|sigmoidoscopy)\"],\n",
        "            \"long_term_dx\": [r\"anorectal\\s+manometry\", r\"puborectalis\\s+dysfunction\"],\n",
        "            \"long_term_tx\": [r\"pelvic-floor\\s+physical\\s+therapy\", r\"biofeedback\"],\n",
        "            \"complications\": [r\"perforation\", r\"necrosis\", r\"ischemia\"]\n",
        "        }\n",
        "\n",
        "    def validate_output(self, model_output):\n",
        "        issues = []\n",
        "        lower_output = model_output.lower()\n",
        "\n",
        "        if not any(re.search(pattern, lower_output) for pattern in self.expected_patterns[\"diagnosis\"]):\n",
        "            issues.append(\"Diagnosis is missing the precise medical term 'Stercoral Colitis'.\")\n",
        "\n",
        "        if not any(re.search(pattern, lower_output) for pattern in self.expected_patterns[\"acute_procedure\"]):\n",
        "            issues.append(\"The acute intervention plan lacks specific mention of endoscopic methods for evacuation.\")\n",
        "\n",
        "        if not any(re.search(pattern, lower_output) for pattern in self.expected_patterns[\"long_term_dx\"]):\n",
        "            issues.append(\"Long-term management is incomplete; assessment (e.g., anorectal manometry) is missing.\")\n",
        "\n",
        "        if not any(re.search(pattern, lower_output) for pattern in self.expected_patterns[\"long_term_tx\"]):\n",
        "            issues.append(\"Long-term therapy is incomplete; must explicitly include 'pelvic-floor physical therapy' or 'biofeedback.'\")\n",
        "\n",
        "        if not any(re.search(pattern, lower_output) for pattern in self.expected_patterns[\"complications\"]):\n",
        "            issues.append(\"Potential complications such as necrosis or perforation are not explicitly noted.\")\n",
        "\n",
        "        return issues if issues else [\"Output aligns with expected clinical criteria.\"]\n",
        "\n",
        "class PromptEngineerAgent:\n",
        "    \"\"\"Pillar 5: Adaptive Steering and Workflow Management\"\"\"\n",
        "    def __init__(self):\n",
        "        self.base_prompt = (\n",
        "            \"You are a radiologist. Analyze the provided multi-slice CT scan images (A, B, C) \"\n",
        "            \"of a 23-year-old male patient with a history of autism spectrum disorder and chronic constipation, \"\n",
        "            \"presenting with abdominal pain, nausea, and vomiting. Focus on findings in the pelvis and abdomen, \"\n",
        "            \"particularly any abnormalities related to the colon, and determine the **most likely diagnosis** \"\n",
        "            \"based on these observations and the patient's clinical background. Provide a detailed rationale \"\n",
        "            \"linking the imaging findings to the diagnosis, recommend appropriate follow-up imaging or interventions, \"\n",
        "            \"and include a differential diagnosis considering potential inflammatory, neoplastic, or obstructive causes. \"\n",
        "            \"Identify any potential complications suggested by the imaging and suggest long-term management strategies \"\n",
        "            \"for underlying conditions contributing to the patient's presentation, including assessment of pelvic floor \"\n",
        "            \"function with an anorectal manometry and pelvic-floor physical therapy. \"\n",
        "        )\n",
        "        self.iteration = 0\n",
        "\n",
        "    def refine_prompt(self, image_findings, validation_feedback):\n",
        "        self.iteration += 1\n",
        "        refined_prompt = self.base_prompt\n",
        "\n",
        "        # Embed the I-JEPA output (the grounded facts) into the reasoning prompt\n",
        "        if image_findings:\n",
        "            refined_prompt += f\" The images show the following critical facts (from I-JEPA analysis): {image_findings}. Use these observations to guide your diagnosis and recommendations, considering the patient's chronic condition and acute symptoms, with a focus on impaction-related findings such as fecal impaction leading to ischemic inflammation.\"\n",
        "\n",
        "        if validation_feedback and \"Output aligns\" not in validation_feedback[0]:\n",
        "            refinement_instruction = f\" **CRITICAL REFINEMENT (Iteration {self.iteration}):** The previous response must be corrected to meet the following specific clinical requirements: \"\n",
        "\n",
        "            if \"Diagnosis is missing the precise medical term\" in \" \".join(validation_feedback):\n",
        "                refinement_instruction += \"The **Diagnosis** section MUST explicitly use the term **Stercoral Colitis**.\"\n",
        "            if \"acute intervention plan lacks specific mention\" in \" \".join(validation_feedback):\n",
        "                refinement_instruction += \"Ensure the **Acute Management** explicitly includes **endoscopic removal** (e.g., flexible sigmoidoscopy) for disimpaction.\"\n",
        "            if \"Long-term therapy is incomplete\" in \" \".join(validation_feedback):\n",
        "                refinement_instruction += \"Ensure the **Long-Term Management** explicitly includes **pelvic-floor physical therapy** or **biofeedback**.\"\n",
        "            if \"Potential complications such as necrosis or perforation are not explicitly noted.\" in \" \".join(validation_feedback):\n",
        "                 refinement_instruction += \"Explicitly note the risk of **perforation/necrosis** as a complication.\"\n",
        "\n",
        "            refined_prompt += refinement_instruction\n",
        "\n",
        "        return refined_prompt\n",
        "\n",
        "# --- 3. Main Execution Loop (The Orchestrator) ---\n",
        "\n",
        "def run_multi_agent_experiment():\n",
        "    print(f\"\\n--- Multi-Agent Experiment Started at {datetime.now().strftime('%I:%M %p %Z on %B %d, %Y')} ---\")\n",
        "\n",
        "    # Initialize agents\n",
        "    prompt_engineer = PromptEngineerAgent()\n",
        "    image_analyzer = ImageAnalysisAgent()\n",
        "    validator = ValidationAgent()\n",
        "\n",
        "    image_path = \"/content/drive/MyDrive/datasetsmedical/image.png\"\n",
        "    image_url = image_to_base64(image_path)\n",
        "\n",
        "    # Check if we are running in a state where a live call is possible but image failed.\n",
        "    if image_url is None and not hasattr(qwen_client, 'is_mock'):\n",
        "        print(\"\\nFATAL ERROR: Image file could not be encoded. Cannot proceed with live multimodal call.\")\n",
        "        return\n",
        "\n",
        "    # Step 1: ESTABLISH GROUNDED PERCEPTION FACTS (I-JEPA Layer Output)\n",
        "    image_findings = image_analyzer.analyze_image(qwen_client, image_url)\n",
        "    print(f\"\\n--- Grounded Perception Facts Established (I-JEPA Layer Output) ---\")\n",
        "    print(f\"Fact Set: {image_findings}\")\n",
        "\n",
        "    # Step 2: Refine Prompt and Iterate (The AGI Loop)\n",
        "    max_iterations = 5\n",
        "    current_iteration = 0\n",
        "    validation_result = []\n",
        "\n",
        "    refined_prompt = prompt_engineer.refine_prompt(image_findings, validation_result)\n",
        "\n",
        "    while current_iteration < max_iterations:\n",
        "        print(f\"\\n--- Iteration {current_iteration + 1} ---\")\n",
        "\n",
        "        completion = None\n",
        "\n",
        "        try:\n",
        "            # Call the core Multimodal LLM (The Reasoning Engine)\n",
        "            completion = qwen_client.chat.completions.create(\n",
        "                model=\"qwen/qwen3-vl-8b-thinking\",\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": refined_prompt},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
        "                    ]}\n",
        "                ],\n",
        "                timeout=30\n",
        "            )\n",
        "\n",
        "            # API Response Guardrail (Fix for 'NoneType' crash)\n",
        "            if completion is None or not completion.choices or not completion.choices[0].message.content:\n",
        "                print(\"\\n[CRITICAL API ERROR] API returned an invalid/empty response. Breaking the loop to prevent crash.\")\n",
        "                break\n",
        "\n",
        "            model_output = completion.choices[0].message.content\n",
        "            print(f\"Qwen3-VL Analysis Result: {model_output[:80] + '...'}\")\n",
        "\n",
        "            # Step 3: Validate Output (Constraint Check)\n",
        "            validation_result = validator.validate_output(model_output)\n",
        "            print(f\"Validation Agent Feedback: {validation_result}\")\n",
        "\n",
        "            # Step 4: Check for Convergence\n",
        "            if \"Output aligns\" in validation_result[0]:\n",
        "                print(\"\\n**AGENTS CONVERGED: Validation criteria met. Stopping iteration.**\")\n",
        "                break\n",
        "\n",
        "            # If validation fails, prepare the prompt for the next loop\n",
        "            refined_prompt = prompt_engineer.refine_prompt(image_findings, validation_result)\n",
        "            current_iteration += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            # Catch general connection/timeout errors\n",
        "            print(f\"\\n[EXCEPTION CAUGHT] An error occurred during Qwen-VL inference (Iteration {current_iteration + 1}): {e}\")\n",
        "            break\n",
        "\n",
        "    if current_iteration == max_iterations and (not completion or \"Output aligns\" not in validation_result[0]):\n",
        "        print(\"\\nMaximum iterations reached without convergence.\")\n",
        "\n",
        "# Execute the experiment\n",
        "if __name__ == \"__main__\":\n",
        "    run_multi_agent_experiment()"
      ]
    }
  ]
}