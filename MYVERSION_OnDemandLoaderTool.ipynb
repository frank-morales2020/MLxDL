{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/MYVERSION_OnDemandLoaderTool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4b3e2a",
      "metadata": {
        "id": "4f4b3e2a"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/tools/OnDemandLoaderTool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318d3e6d-8155-4f86-ac16-bdacaf041bb9",
      "metadata": {
        "id": "318d3e6d-8155-4f86-ac16-bdacaf041bb9"
      },
      "source": [
        "# OnDemandLoaderTool Tutorial\n",
        "\n",
        "Our `OnDemandLoaderTool` is a powerful agent tool that allows for \"on-demand\" data querying from any data source on LlamaHub.\n",
        "\n",
        "This tool takes in a `BaseReader` data loader, and when called will 1) load data, 2) index data, and 3) query the data.\n",
        "\n",
        "In this walkthrough, we show how to use the `OnDemandLoaderTool` to convert our Wikipedia data loader into an accessible search tool for a LangChain agent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31bb896a",
      "metadata": {
        "id": "31bb896a"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ü¶ô."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cb7c29",
      "metadata": {
        "id": "b3cb7c29"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-readers-wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6815113",
      "metadata": {
        "id": "d6815113"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1680fc8-1904-4ea8-b8da-88306b365e7f",
      "metadata": {
        "id": "d1680fc8-1904-4ea8-b8da-88306b365e7f"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools.ondemand_loader_tool import OnDemandLoaderTool\n",
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "from typing import List\n",
        "\n",
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e167e7ed-92ba-4662-b6f6-24dc36ea4805",
      "metadata": {
        "id": "e167e7ed-92ba-4662-b6f6-24dc36ea4805"
      },
      "source": [
        "### Define Tool\n",
        "\n",
        "We first define the `WikipediaReader`. Note that the `load_data` interface to `WikipediaReader` takes in a list of `pages`. By default, this queries the Wikipedia search endpoint which will autosuggest the relevant pages.\n",
        "\n",
        "We then wrap it into our `OnDemandLoaderTool`.\n",
        "\n",
        "By default since we don't specify the `index_cls`, a simple vector store index is initialized."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "yOxW96vOiwe8"
      },
      "id": "yOxW96vOiwe8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c5caf3b-3544-4a39-be69-35e18ef12172",
      "metadata": {
        "id": "7c5caf3b-3544-4a39-be69-35e18ef12172"
      },
      "outputs": [],
      "source": [
        "reader = WikipediaReader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea9169ad-fe61-47da-bbdf-ce3a89c371a3",
      "metadata": {
        "id": "ea9169ad-fe61-47da-bbdf-ce3a89c371a3"
      },
      "outputs": [],
      "source": [
        "tool = OnDemandLoaderTool.from_defaults(\n",
        "    reader,\n",
        "    name=\"Wikipedia Tool\",\n",
        "    description=\"A tool for loading and querying articles from Wikipedia\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8e6bb2-b019-4b23-9b4b-bd5e6f436bcb",
      "metadata": {
        "id": "0f8e6bb2-b019-4b23-9b4b-bd5e6f436bcb"
      },
      "source": [
        "#### Testing\n",
        "\n",
        "We can try running the tool by itself (or as a LangChain tool), just to showcase what the interface is like!\n",
        "\n",
        "Note that besides the arguments required for the data loader, the tool also takes in a `query_str` which will be\n",
        "the query against the index."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "%pip install openai  --root-user-action=ignore\n",
        "%pip install colab-env --upgrade --quiet --root-user-action=ignore"
      ],
      "metadata": {
        "id": "J43Hn7WwjUGH"
      },
      "id": "J43Hn7WwjUGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Settings"
      ],
      "metadata": {
        "id": "v-QiUVjzELbi"
      },
      "id": "v-QiUVjzELbi"
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "uf6fILRsjVf8"
      },
      "id": "uf6fILRsjVf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fc86a2-0d25-4673-9d2c-a12ba10de5f4",
      "metadata": {
        "id": "46fc86a2-0d25-4673-9d2c-a12ba10de5f4"
      },
      "outputs": [],
      "source": [
        "# run tool by itself\n",
        "#added by Frank Morales(FM) 22/02/2024\n",
        "tool([\"Montreal\"], query_str=\"What is the best restaurant in Montreal?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e22b8acd-e619-4ec7-925e-8e5d517214f3",
      "metadata": {
        "id": "e22b8acd-e619-4ec7-925e-8e5d517214f3"
      },
      "outputs": [],
      "source": [
        "# run tool as langchain structured tool\n",
        "lc_tool = tool.to_langchain_structured_tool(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c48344-2a57-4b4a-8faa-1d7a9a450208",
      "metadata": {
        "id": "c5c48344-2a57-4b4a-8faa-1d7a9a450208"
      },
      "outputs": [],
      "source": [
        "lc_tool.run(\n",
        "    tool_input={\n",
        "        \"pages\": [\"Montreal\"],\n",
        "        \"query_str\": \"What is the best restaurant in Montreal?\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bac4007-7121-4ab4-91e3-6706e59de6b7",
      "metadata": {
        "id": "2bac4007-7121-4ab4-91e3-6706e59de6b7"
      },
      "source": [
        "### Initialize LangChain Agent\n",
        "\n",
        "For tutorial purposes, the agent just has access to one tool - the Wikipedia Reader\n",
        "\n",
        "Note that we need to use Structured Tools from LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bd77d986-23be-49d9-9522-d19b41f66a32",
      "metadata": {
        "id": "bd77d986-23be-49d9-9522-d19b41f66a32"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8a789712-a285-495e-bf71-b61856e0848a",
      "metadata": {
        "id": "8a789712-a285-495e-bf71-b61856e0848a"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8a6ff85e-81ae-4b66-a83b-4d066eded32a",
      "metadata": {
        "id": "8a6ff85e-81ae-4b66-a83b-4d066eded32a"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    [lc_tool],\n",
        "    llm=llm,\n",
        "    agent=\"structured-chat-zero-shot-react-description\",\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b88449-1291-470c-8b7c-cb49d2edbede",
      "metadata": {
        "id": "56b88449-1291-470c-8b7c-cb49d2edbede"
      },
      "source": [
        "# Now let's run some queries!\n",
        "\n",
        "The OnDemandLoaderTool allows the agent to simultaneously 1) load the data from Wikipedia, 2) query that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "76e7a99f-2802-4e7e-ac8b-3810797fdc3c",
      "metadata": {
        "id": "76e7a99f-2802-4e7e-ac8b-3810797fdc3c",
        "outputId": "8c84da6c-b46f-48b0-9c75-e5acaf2a5396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAu Pied de Cochon, La Banquise, La Binerie Mont-Royal, Boustan, Casa del Popolo, Chenoy's, Le Cheval Blanc, Cuisine AuntDai, D√©carie Hot Dogs, Dunn's, Eaton's Ninth Floor Restaurant, Gibeau Orange Julep, J&R Kosher Meat and Delicatessen, Joe Beef, Restaurant Pizzaiolle, Mikes, Moishes Steakhouse, Montreal Pool Room, Schwartz's, Toqu√©!, Wilensky's\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Some of the best restaurants in Montreal are Au Pied de Cochon, La Banquise, Joe Beef, Schwartz's, and Toqu√©!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "agent.run(\"What is the best restaurant in Montreal?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}