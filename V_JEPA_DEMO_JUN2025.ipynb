{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "YfVAVL25QHCt",
        "WBbttk_zMOi7",
        "Ej_uVqOR6orA",
        "xNN_8G_M7RGx",
        "avZ2DY197cij"
      ],
      "authorship_tag": "ABX9TyOj66j4fM22pTYGRp5L1Wmd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/V_JEPA_DEMO_JUN2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "YfVAVL25QHCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://paperswithcode.com/paper/tartanaviation-image-speech-and-ads-b"
      ],
      "metadata": {
        "id": "b9eIUN5noKi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "itf7fwTqS8Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/datasets/\n",
        "!git clone https://github.com/castacks/TartanAviation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K47pWoRiTOYB",
        "outputId": "f61f1c19-0e8d-4eea-8dbd-807b2ef6ac0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/datasets\n",
            "Cloning into 'TartanAviation'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 180 (delta 97), reused 97 (delta 33), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (180/180), 4.04 MiB | 14.17 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/gdrive/MyDrive/datasets/TartanAviation/vision/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXLa8PwMT5MV",
        "outputId": "288e8ff5-a6cc-4efd-9e8b-90b0d4117fba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 67\n",
            "-rw------- 1 root root 11153 Jul 23 12:43 dataloader.py\n",
            "-rw------- 1 root root  7364 Jul 23 12:43 download.py\n",
            "-rw------- 1 root root  6119 Jul 23 12:43 progress.py\n",
            "-rw------- 1 root root  3436 Jul 23 12:43 README.md\n",
            "drwx------ 2 root root  4096 Jul 23 12:43 recording\n",
            "-rw------- 1 root root 35369 Jul 23 12:43 weather_stats.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0"
      ],
      "metadata": {
        "id": "WBbttk_zMOi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import pytz\n",
        "import shutil # For removing directories\n",
        "\n",
        "# Ensure you are in the correct directory to run the download script\n",
        "%cd /content/TartanAviation/vision/\n",
        "print(f\"Current working directory set to: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "# 1. Install MinIO library\n",
        "print(\"\\nInstalling minio...\")\n",
        "!pip install minio\n",
        "\n",
        "\n",
        "# Define your final desired save directory IN GOOGLE DRIVE\n",
        "# This is where the *recording folders* (e.g., '1_2023-02-22-15-21-49') will be placed directly.\n",
        "DRIVE_RECORDINGS_ROOT = \"/content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/\"\n",
        "\n",
        "# Create the final destination directory in Drive if it doesn't exist\n",
        "os.makedirs(DRIVE_RECORDINGS_ROOT, exist_ok=True)\n",
        "print(f\"\\nGoogle Drive destination for raw recordings: {DRIVE_RECORDINGS_ROOT}\")\n",
        "\n",
        "\n",
        "# 2. Run the download script to get a sample of the data\n",
        "print(f\"\\nAttempting to download TartanAviation sample data (approx. 1.9 GB) directly to DRIVE {DRIVE_RECORDINGS_ROOT}...\")\n",
        "\n",
        "# Optional: Remove previous download if it exists to force a fresh download\n",
        "sample_recording_folder_name = \"1_2023-02-22-15-21-49\" # Name of the sample recording folder\n",
        "full_sample_recording_path = os.path.join(DRIVE_RECORDINGS_ROOT, sample_recording_folder_name)\n",
        "if os.path.exists(full_sample_recording_path):\n",
        "    print(f\"Found existing sample recording at {full_sample_recording_path}. Removing to force fresh download.\")\n",
        "    shutil.rmtree(full_sample_recording_path)\n",
        "    print(\"Removed old sample recording.\")\n",
        "\n",
        "\n",
        "# --- DIRECT EXECUTION OF download.py ---\n",
        "print(\"\\n--- Executing download.py (Output will stream directly below) ---\")\n",
        "print(\"Waiting for download.py to complete. This may take a while.\")\n",
        "print(\"Look for progress/error messages from download.py itself.\")\n",
        "\n",
        "# Execute the command directly, letting its output stream to the console\n",
        "download_command = f\"python3 download.py --option Sample --save_dir \\\"{DRIVE_RECORDINGS_ROOT}\\\"\"\n",
        "!{download_command}\n",
        "\n",
        "print(\"\\n--- download.py execution finished ---\")\n",
        "\n",
        "\n",
        "# --- DIAGNOSTIC STEPS POST-DOWNLOAD ATTEMPT ---\n",
        "print(f\"\\n--- Post-Download Attempt Verification ({datetime.datetime.now(pytz.timezone('EST')).strftime('%Y-%m-%d %H:%M:%S EST')} EST) ---\")\n",
        "\n",
        "# Verify the data in the final Google Drive path\n",
        "ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE = os.path.join(DRIVE_RECORDINGS_ROOT, sample_recording_folder_name)\n",
        "\n",
        "if os.path.exists(ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE):\n",
        "    if len(os.listdir(ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE)) > 0:\n",
        "        print(f\"SUCCESS: Data directory found in DRIVE at: {ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE}\")\n",
        "        print(\"Contents (first level - should be recording IDs like '1_2023-02-22-15-21-49'):\")\n",
        "        !ls -l \"{ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE}\"\n",
        "        print(\"\\nAttempting to list first recording's content (if available):\")\n",
        "        !ls -l \"{ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE}\"/* | head -n 5\n",
        "    else:\n",
        "        print(f\"FAILURE: Data directory in DRIVE at: {ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE} is empty.\")\n",
        "        print(\"This indicates download.py ran but did not place any data there.\")\n",
        "else:\n",
        "    print(f\"FAILURE: Data directory NOT found in DRIVE at: {ACTUAL_DOWNLOADED_DATA_PATH_IN_DRIVE}.\")\n",
        "    print(\"This indicates download.py failed to download or place data.\")\n",
        "\n",
        "%cd /content/ # Change back to /content/\n",
        "print(f\"\\nPart 0 execution complete at {datetime.datetime.now(pytz.timezone('EST')).strftime('%Y-%m-%d %H:%M:%S EST')} EST.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNGewlk9Q4xU",
        "outputId": "fae3cb89-34bb-41e6-fe78-0ef97416f056"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TartanAviation/vision\n",
            "Current working directory set to: /content/TartanAviation/vision\n",
            "\n",
            "Installing minio...\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.11/dist-packages (7.2.16)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from minio) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from minio) (2025.7.14)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from minio) (3.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from minio) (4.14.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from minio) (2.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->minio) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.22)\n",
            "\n",
            "Google Drive destination for raw recordings: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/\n",
            "\n",
            "Attempting to download TartanAviation sample data (approx. 1.9 GB) directly to DRIVE /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/...\n",
            "\n",
            "--- Executing download.py (Output will stream directly below) ---\n",
            "Waiting for download.py to complete. This may take a while.\n",
            "Look for progress/error messages from download.py itself.\n",
            "Selected Option: Sample\n",
            "Number of Video Folders: 1\n",
            "1_2023-02-22-15-21-49.zip: |####################| 1945.34 MB/1945.34 MB 100% [elapsed: 29:17 left: 00:00,  1.11 MB/sec]Archive:  /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49.zip\n",
            "   creating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/\n",
            " extracting: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_labels.zip  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_acft_sink.pkl  \n",
            "1_2023-02-22-15-21-49.zip: |--------------------| 0.00 MB/0.00 MB   0% [elapsed: 29:24 left: ?,  0.00 MB/sec]\n",
            "1_2023-02-22-15-21-49.zip: |--------------------| 0.00 MB/0.00 MB   0% [elapsed: 29:36 left: ?,  0.00 MB/sec]\n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_subtitle.srt  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink_adsb.pkl  \n",
            "1_2023-02-22-15-21-49.zip: |--------------------| 0.00 MB/0.00 MB   0% [elapsed: 29:37 left: ?,  0.00 MB/sec]Archive:  /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_labels.zip\n",
            "1_2023-02-22-15-21-49.zip: |--------------------| 0.00 MB/0.00 MB   0% [elapsed: 29:38 left: ?,  0.00 MB/sec]  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/10.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/100.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/101.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/102.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/103.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/104.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/105.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/106.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/107.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/108.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/109.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/11.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/110.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/111.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/112.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/113.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/114.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/115.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/116.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/117.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/118.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/119.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/12.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/120.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/121.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/122.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/123.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/124.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/125.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/126.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/127.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/128.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/129.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/13.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/130.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/131.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/132.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/133.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/134.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/135.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/136.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/137.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/138.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/139.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/14.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/140.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/141.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/142.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/143.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/144.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/145.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/146.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/147.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/148.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/149.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/15.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/150.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/151.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/152.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/153.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/154.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/155.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/156.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/157.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/158.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/16.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/17.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/18.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/19.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/2.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/20.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/21.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/22.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/23.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/24.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/25.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/26.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/27.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/28.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/29.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/3.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/30.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/31.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/32.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/33.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/34.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/35.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/36.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/37.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/38.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/39.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/4.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/40.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/41.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/42.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/43.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/44.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/45.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/46.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/47.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/48.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/49.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/5.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/50.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/51.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/52.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/53.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/54.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/55.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/56.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/57.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/58.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/59.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/6.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/60.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/61.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/62.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/63.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/64.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/65.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/7.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/8.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/9.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/92.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/93.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/94.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/95.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/96.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/97.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/98.label  \n",
            "  inflating: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink/99.label  \n",
            "\n",
            "--- download.py execution finished ---\n",
            "\n",
            "--- Post-Download Attempt Verification (2025-07-23 10:29:39 EST EST) ---\n",
            "SUCCESS: Data directory found in DRIVE at: /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49\n",
            "Contents (first level - should be recording IDs like '1_2023-02-22-15-21-49'):\n",
            "total 2005456\n",
            "-rw------- 1 root root      15589 Aug 26  2023 1_2023-02-22-15-21-49_acft_sink.pkl\n",
            "-rw------- 1 root root      37627 Aug 26  2023 1_2023-02-22-15-21-49_labels.zip\n",
            "-rw------- 1 root root  932511775 Aug 26  2023 1_2023-02-22-15-21-49.mp4\n",
            "drwx------ 2 root root       4096 Jul 23 15:29 1_2023-02-22-15-21-49_sink\n",
            "-rw------- 1 root root        234 Aug 26  2023 1_2023-02-22-15-21-49_sink_adsb.pkl\n",
            "-rw------- 1 root root 1120743402 Aug 26  2023 1_2023-02-22-15-21-49_sink_verified.avi\n",
            "-rw------- 1 root root     272095 Aug 26  2023 1_2023-02-22-15-21-49_subtitle.srt\n",
            "\n",
            "Attempting to list first recording's content (if available):\n",
            "-rw------- 1 root root      15589 Aug 26  2023 /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_acft_sink.pkl\n",
            "-rw------- 1 root root      37627 Aug 26  2023 /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_labels.zip\n",
            "-rw------- 1 root root  932511775 Aug 26  2023 /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49.mp4\n",
            "-rw------- 1 root root        234 Aug 26  2023 /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink_adsb.pkl\n",
            "-rw------- 1 root root 1120743402 Aug 26  2023 /content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/1_2023-02-22-15-21-49/1_2023-02-22-15-21-49_sink_verified.avi\n",
            "[Errno 2] No such file or directory: '/content/ # Change back to /content/'\n",
            "/content/TartanAviation/vision\n",
            "\n",
            "Part 0 execution complete at 2025-07-23 10:29:39 EST EST.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 (Cell 1): Video Loading and V-JEPA Feature Extraction"
      ],
      "metadata": {
        "id": "Ej_uVqOR6orA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import av\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import AutoVideoProcessor, AutoModel\n",
        "from tqdm.notebook import tqdm # For progress bars in notebooks\n",
        "import logging\n",
        "import json # For saving feature map\n",
        "import sys # For exiting on critical errors\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- GLOBAL CONFIGURATION PARAMETERS ---\n",
        "# V-JEPA Model and Processor\n",
        "HF_REPO = \"facebook/vjepa2-vitg-fpc64-256\"\n",
        "NUM_FRAMES_TO_SAMPLE = 16 # Number of frames to sample for V-JEPA\n",
        "\n",
        "# --- PATHS FOR DATA PROCESSING ---\n",
        "# Define the path to the single video you want to classify in Part 3 (e.g., your original demo video)\n",
        "# MAKE SURE THIS VIDEO IS UPLOADED TO /content/ or is accessible here.\n",
        "DEMO_VIDEO_PATH = '/content/airplane-landing.mp4'\n",
        "\n",
        "# Define the root directory where your raw TartanAviation videos are stored in Drive (after download.py)\n",
        "# This path now points directly to the folder containing recording IDs (e.g., '1_2023-02-22-15-21-49')\n",
        "DATASET_RAW_VIDEO_ROOT = \"/content/gdrive/MyDrive/datasets/TartanAviation/vision/downloaded_recordings/\"\n",
        "\n",
        "# Define the directory where extracted V-JEPA features (from TartanAviation) will be saved.\n",
        "EXTRACTED_FEATURES_SAVE_DIR = \"/content/gdrive/MyDrive/datasets/TartanAviation_VJEPA_Features/\"\n",
        "os.makedirs(EXTRACTED_FEATURES_SAVE_DIR, exist_ok=True) # Ensure this directory exists\n",
        "\n",
        "# Define the class labels (these need to be derived from TartanAviation's actual labels)\n",
        "CLASS_LABELS = [\n",
        "    \"airplane landing\",\n",
        "    \"airplane takeoff\",\n",
        "    \"airport ground operations\",\n",
        "    \"in-flight cruise\",\n",
        "    \"emergency landing\",\n",
        "    \"pre-flight check/maintenance\"\n",
        "]\n",
        "\n",
        "# --- V-JEPA Model/Processor Loading ---\n",
        "logging.info(f\"Loading V-JEPA model and processor from {HF_REPO}...\")\n",
        "try:\n",
        "    model = AutoModel.from_pretrained(HF_REPO)\n",
        "    processor = AutoVideoProcessor.from_pretrained(HF_REPO)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    logging.info(f\"V-JEPA Model and processor loaded on {device}.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load V-JEPA model/processor: {e}\")\n",
        "    model, processor, device = None, None, \"cpu\"\n",
        "    sys.exit(\"Exiting: V-JEPA model or processor failed to load.\")\n",
        "\n",
        "\n",
        "# --- 1. Extract Features for the SPECIFIC DEMO VIDEO (for Part 3 Inference) ---\n",
        "video_features_for_inference = None # This will hold the features for the single demo video\n",
        "\n",
        "logging.info(f\"\\n--- Extracting features for the specific DEMO VIDEO: {DEMO_VIDEO_PATH} ---\")\n",
        "if not os.path.exists(DEMO_VIDEO_PATH):\n",
        "    logging.error(f\"Error: Demo video file '{DEMO_VIDEO_PATH}' not found.\")\n",
        "    logging.warning(\"Proceeding with dummy video creation for DEMO INFERENCE purposes.\")\n",
        "    height, width = 256, 256\n",
        "    dummy_video_tensor = torch.rand(NUM_FRAMES_TO_SAMPLE, 3, height, width)\n",
        "    frames_demo = [frame.permute(1, 2, 0).numpy() for frame in dummy_video_tensor]\n",
        "    logging.info(f\"Created dummy video frames for demo inference.\")\n",
        "else:\n",
        "    frames_demo = []\n",
        "    try:\n",
        "        container_demo = av.open(DEMO_VIDEO_PATH)\n",
        "        total_frames_in_video_demo = container_demo.streams.video[0].frames\n",
        "        sampling_interval_demo = max(1, total_frames_in_video_demo // NUM_FRAMES_TO_SAMPLE)\n",
        "        for i, frame in enumerate(tqdm(container_demo.decode(video=0), total=total_frames_in_video_demo, leave=False, desc=f\"Sampling Demo Video: {DEMO_VIDEO_PATH}\")):\n",
        "            if len(frames_demo) >= NUM_FRAMES_TO_SAMPLE:\n",
        "                break\n",
        "            if i % sampling_interval_demo == 0:\n",
        "                img = frame.to_rgb().to_ndarray()\n",
        "                frames_demo.append(img)\n",
        "        container_demo.close()\n",
        "        logging.info(f\"Successfully sampled {len(frames_demo)} frames from demo video.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading demo video '{DEMO_VIDEO_PATH}': {e}\")\n",
        "        logging.warning(\"Proceeding with dummy video creation for DEMO INFERENCE purposes.\")\n",
        "        height, width = 256, 256\n",
        "        dummy_video_tensor = torch.rand(NUM_FRAMES_TO_SAMPLE, 3, height, width)\n",
        "        frames_demo = [frame.permute(1, 2, 0).numpy() for frame in dummy_video_tensor]\n",
        "\n",
        "if frames_demo:\n",
        "    try:\n",
        "        inputs_demo = processor(videos=list(frames_demo), return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs_demo = model(**inputs_demo)\n",
        "            video_features_for_inference = outputs_demo.last_hidden_state\n",
        "        logging.info(f\"Extracted features for demo video. Shape: {video_features_for_inference.shape}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting features for demo video: {e}\")\n",
        "        video_features_for_inference = None\n",
        "else:\n",
        "    logging.error(\"Failed to get frames for demo video. video_features_for_inference will be None.\")\n",
        "\n",
        "\n",
        "# --- 2. Dataset Processing to Extract V-JEPA Features (for Classifier TRAINING) ---\n",
        "\n",
        "def get_label_from_video_metadata(recording_dir, class_labels):\n",
        "    \"\"\"\n",
        "    Refined conceptual function for TartanAviation Sample:\n",
        "    The sample recording is '1_2023-02-22-15-21-49'.\n",
        "    The README and dataset structure point to '_sink' files for this sample,\n",
        "    which typically indicates a landing or sink rate.\n",
        "    This function attempts to infer based on these cues.\n",
        "    For other full dataset videos, you would parse _labels.zip or dataloader.py.\n",
        "    \"\"\"\n",
        "    dir_name = os.path.basename(recording_dir).lower()\n",
        "\n",
        "    # Specific to the TartanAviation sample ID if it's '1_2023-02-22-15-21-49'\n",
        "    if \"1_2023-02-22-15-21-49\" in dir_name:\n",
        "        # This specific sample is confirmed to be a landing event.\n",
        "        # It has \"_sink\" in associated files and is mentioned as a \"sink\" example in docs.\n",
        "        return \"airplane landing\"\n",
        "\n",
        "    # Generic (less reliable without actual labels) for other samples if they exist\n",
        "    elif \"sink\" in dir_name or \"landing\" in dir_name:\n",
        "        return \"airplane landing\"\n",
        "    elif \"takeoff\" in dir_name:\n",
        "        return \"airplane takeoff\"\n",
        "\n",
        "    # Fallback if no specific keyword matches (most likely for a random sample)\n",
        "    return \"airport ground operations\"\n",
        "\n",
        "\n",
        "processed_count = 0\n",
        "skipped_count = 0\n",
        "feature_label_map = []\n",
        "extracted_embedding_dim = -1 # To get actual embedding dim from first feature\n",
        "\n",
        "print(f\"\\n--- Starting to extract V-JEPA features for TRAINING from: {DATASET_RAW_VIDEO_ROOT} ---\")\n",
        "if not os.path.exists(DATASET_RAW_VIDEO_ROOT):\n",
        "    logging.error(f\"ERROR: Raw video root directory for training data not found: {DATASET_RAW_VIDEO_ROOT}\")\n",
        "    logging.error(\"Skipping training data feature extraction.\")\n",
        "else:\n",
        "    for recording_id_dir in tqdm(os.listdir(DATASET_RAW_VIDEO_ROOT), desc=\"Processing Recordings for Training Data\"):\n",
        "        recording_path = os.path.join(DATASET_RAW_VIDEO_ROOT, recording_id_dir)\n",
        "        if os.path.isdir(recording_path):\n",
        "            mp4_files = [f for f in os.listdir(recording_path) if f.endswith(\".mp4\")]\n",
        "            if not mp4_files:\n",
        "                logging.warning(f\"No MP4 found in {recording_path}. Skipping for training data.\")\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            video_file = mp4_files[0]\n",
        "            video_path_dataset = os.path.join(recording_path, video_file)\n",
        "\n",
        "            label_str = get_label_from_video_metadata(recording_path, CLASS_LABELS)\n",
        "            if label_str not in CLASS_LABELS:\n",
        "                logging.warning(f\"Skipping {video_path_dataset}: Cannot derive valid label for '{label_str}'.\")\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "            label_idx = CLASS_LABELS.index(label_str)\n",
        "\n",
        "            frames_dataset = []\n",
        "            try:\n",
        "                container_dataset = av.open(video_path_dataset)\n",
        "                total_frames_in_video_dataset = container_dataset.streams.video[0].frames\n",
        "                sampling_interval_dataset = max(1, total_frames_in_video_dataset // NUM_FRAMES_TO_SAMPLE)\n",
        "\n",
        "                for i, frame in enumerate(tqdm(container_dataset.decode(video=0), total=total_frames_in_video_dataset, leave=False, desc=f\"Sampling {video_file}\")):\n",
        "                    if len(frames_dataset) >= NUM_FRAMES_TO_SAMPLE:\n",
        "                        break\n",
        "                    if i % sampling_interval_dataset == 0:\n",
        "                        img = frame.to_rgb().to_ndarray()\n",
        "                        frames_dataset.append(img)\n",
        "                container_dataset.close()\n",
        "\n",
        "                if not frames_dataset:\n",
        "                    logging.warning(f\"No frames loaded from {video_file}. Skipping feature extraction for training data.\")\n",
        "                    skipped_count += 1\n",
        "                    continue\n",
        "\n",
        "                inputs_dataset = processor(videos=list(frames_dataset), return_tensors=\"pt\").to(device)\n",
        "                with torch.no_grad():\n",
        "                    outputs_dataset = model(**inputs_dataset)\n",
        "                    video_features_raw_dataset = outputs_dataset.last_hidden_state\n",
        "\n",
        "                pooled_feature_dataset = video_features_raw_dataset.squeeze(0).mean(dim=0).unsqueeze(0)\n",
        "                if extracted_embedding_dim == -1: # Set it from the first successfully processed feature\n",
        "                    extracted_embedding_dim = pooled_feature_dataset.shape[1]\n",
        "\n",
        "                feature_filename = f\"{os.path.splitext(video_file)[0]}_feature.pt\"\n",
        "                feature_save_path = os.path.join(EXTRACTED_FEATURES_SAVE_DIR, feature_filename)\n",
        "                torch.save(pooled_feature_dataset.cpu(), feature_save_path)\n",
        "                feature_label_map.append({\n",
        "                    \"feature_path\": feature_save_path,\n",
        "                    \"label_idx\": label_idx,\n",
        "                    \"label_name\": label_str\n",
        "                })\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing {video_file} for training data: {e}\")\n",
        "                skipped_count += 1\n",
        "\n",
        "    map_file_path = os.path.join(EXTRACTED_FEATURES_SAVE_DIR, \"feature_label_map.json\")\n",
        "    with open(map_file_path, 'w') as f:\n",
        "        json.dump(feature_label_map, f, indent=4)\n",
        "    print(f\"\\n--- Dataset Feature Extraction for Training Complete ---\")\n",
        "    print(f\"Total videos processed for training data: {processed_count}\")\n",
        "    print(f\"Total videos skipped for training data: {skipped_count}\")\n",
        "    print(f\"Feature-label map saved to: {map_file_path}\")\n",
        "    print(f\"Extracted features saved to: {EXTRACTED_FEATURES_SAVE_DIR}\")\n",
        "    print(f\"Observed V-JEPA embedding dimension: {extracted_embedding_dim}\")"
      ],
      "metadata": {
        "id": "6XCxT5pX6uqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 (Cell 2): Classifier Training"
      ],
      "metadata": {
        "id": "xNN_8G_M7RGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import logging\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm.notebook import tqdm\n",
        "import json # For loading the feature_label_map.json\n",
        "import os # For path joining\n",
        "\n",
        "# Configure logging for this cell\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Configuration for Real Data Loading ---\n",
        "EXTRACTED_FEATURES_DIR = \"/content/gdrive/MyDrive/datasets/TartanAviation_VJEPA_Features/\" # Must match save dir in Part 1\n",
        "CLASSIFIER_SAVE_PATH = \"classifier_head_trained_on_tartan_aviation_sample.pth\" # Specific name for real data\n",
        "\n",
        "# --- Check for required variables from Part 1 ---\n",
        "if 'video_features_for_inference' not in locals() or video_features_for_inference is None:\n",
        "    logging.error(\"ERROR: 'video_features_for_inference' from Part 1 not found or is None. Please run Part 1 first.\")\n",
        "    exit()\n",
        "\n",
        "if 'extracted_embedding_dim' not in locals() or extracted_embedding_dim == -1:\n",
        "    logging.error(\"ERROR: 'extracted_embedding_dim' not found or not set by Part 1. Please ensure Part 1 ran successfully.\")\n",
        "    exit()\n",
        "embedding_dim = extracted_embedding_dim # Use the dynamically determined embedding dim\n",
        "\n",
        "if 'device' not in locals(): # device should be set by Part 1\n",
        "    logging.warning(\"WARNING: 'device' variable not found from Part 1. Defaulting to 'cpu'.\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "# --- Classifier Training ---\n",
        "print(\"\\n--- Starting Classifier Training ---\")\n",
        "print(f\"Attempting to load real V-JEPA features from: {EXTRACTED_FEATURES_DIR}\")\n",
        "\n",
        "# Define class labels (MUST MATCH LABELS USED DURING FEATURE EXTRACTION IN Part 1)\n",
        "CLASS_LABELS = [ # Using CLASS_LABELS to be consistent with Part 1\n",
        "    \"airplane landing\",\n",
        "    \"airplane takeoff\",\n",
        "    \"airport ground operations\",\n",
        "    \"in-flight cruise\",\n",
        "    \"emergency landing\",\n",
        "    \"pre-flight check/maintenance\"\n",
        "]\n",
        "num_classes = len(CLASS_LABELS)\n",
        "\n",
        "try:\n",
        "    # Define a simple classification head\n",
        "    class ClassifierHead(nn.Module):\n",
        "        def __init__(self, input_dim, num_classes):\n",
        "            super().__init__()\n",
        "            self.fc1 = nn.Linear(input_dim, 256)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.dropout = nn.Dropout(0.3)\n",
        "            self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.fc2(self.dropout(self.relu(self.fc1(x))))\n",
        "\n",
        "    classifier = ClassifierHead(input_dim=embedding_dim, num_classes=num_classes).to(device)\n",
        "\n",
        "    # --- CORE TRAINING LOGIC ---\n",
        "    print(\"\\n--- Initiating Classifier Training ---\")\n",
        "\n",
        "    train_features_list = []\n",
        "    train_labels_list = []\n",
        "\n",
        "    map_file_path = os.path.join(EXTRACTED_FEATURES_DIR, \"feature_label_map.json\")\n",
        "\n",
        "    if os.path.exists(EXTRACTED_FEATURES_DIR) and os.path.exists(map_file_path):\n",
        "        with open(map_file_path, 'r') as f:\n",
        "            feature_label_map = json.load(f)\n",
        "\n",
        "        if not feature_label_map:\n",
        "            logging.error(f\"Feature-label map at {map_file_path} is empty. No real data to load for training.\")\n",
        "            logging.info(\"Classifier will be trained on SYNTHETIC data as a fallback.\")\n",
        "            num_training_samples = 2_000_000 # Fallback synthetic\n",
        "            train_features = torch.rand(num_training_samples, embedding_dim).to(device)\n",
        "            train_labels = torch.randint(0, num_classes, (num_training_samples,)).to(device)\n",
        "            train_loader = DataLoader(TensorDataset(train_features, train_labels), batch_size=128, shuffle=True)\n",
        "            val_loader = None\n",
        "            print(f\"Loaded {num_training_samples} SYNTHETIC features for training (due to no real data).\")\n",
        "\n",
        "        else:\n",
        "            # Load real features\n",
        "            for item in tqdm(feature_label_map, desc=\"Loading real V-JEPA features\"):\n",
        "                feature_path = item['feature_path']\n",
        "                label_idx = item['label_idx']\n",
        "                try:\n",
        "                    if not os.path.isabs(feature_path):\n",
        "                        feature_path = os.path.join(EXTRACTED_FEATURES_DIR, os.path.basename(feature_path))\n",
        "\n",
        "                    feature = torch.load(feature_path, map_location=device) # Load directly to device\n",
        "                    if feature.ndim > 1 and feature.shape[0] == 1:\n",
        "                        train_features_list.append(feature.squeeze(0))\n",
        "                    elif feature.ndim == 1:\n",
        "                        train_features_list.append(feature)\n",
        "                    else:\n",
        "                        logging.warning(f\"Skipping malformed feature at {feature_path}. Expected 1D or [1, D], got {feature.shape}\")\n",
        "                        continue\n",
        "                    train_labels_list.append(label_idx)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error loading feature from {feature_path}: {e}\")\n",
        "\n",
        "            if train_features_list:\n",
        "                train_features = torch.stack(train_features_list)\n",
        "                train_labels = torch.tensor(train_labels_list)\n",
        "                num_training_samples = len(train_features)\n",
        "                print(f\"Loaded {num_training_samples} REAL V-JEPA features for training.\")\n",
        "\n",
        "                if num_training_samples < 2: # Check if less than 2 samples\n",
        "                    print(\"WARNING: Only 1 real V-JEPA feature loaded. Training will be performed on this single sample (no train/val split).\")\n",
        "                    train_loader = DataLoader(TensorDataset(train_features, train_labels), batch_size=1, shuffle=False) # Batch size 1, no shuffle\n",
        "                    val_loader = None # No validation set\n",
        "                else:\n",
        "                    # Original split logic for 2+ samples\n",
        "                    dataset_size = len(train_features)\n",
        "                    train_size = int(0.8 * dataset_size)\n",
        "                    val_size = dataset_size - train_size\n",
        "                    train_dataset_real, val_dataset_real = torch.utils.data.random_split(TensorDataset(train_features, train_labels), [train_size, val_size])\n",
        "\n",
        "                    train_loader = DataLoader(train_dataset_real, batch_size=32, shuffle=True) # Smaller batch size for real data\n",
        "                    val_loader = DataLoader(val_dataset_real, batch_size=32, shuffle=False)\n",
        "\n",
        "                    print(f\"Training on {len(train_dataset_real)} samples, Validating on {len(val_dataset_real)} samples.\")\n",
        "            else:\n",
        "                logging.error(\"No real V-JEPA features could be loaded from map. Falling back to synthetic data.\")\n",
        "                num_training_samples = 2_000_000\n",
        "                train_features = torch.rand(num_training_samples, embedding_dim).to(device)\n",
        "                train_labels = torch.randint(0, num_classes, (num_training_samples,)).to(device)\n",
        "                train_loader = DataLoader(TensorDataset(train_features, train_labels), batch_size=128, shuffle=True)\n",
        "                val_loader = None\n",
        "                print(f\"Loaded {num_training_samples} SYNTHETIC features for training (due to real data load failure).\")\n",
        "\n",
        "    else:\n",
        "        logging.error(f\"Extracted features directory '{EXTRACTED_FEATURES_DIR}' or map file '{map_file_path}' not found.\")\n",
        "        logging.info(\"Classifier will be trained on SYNTHETIC data as a fallback.\")\n",
        "        num_training_samples = 2_000_000\n",
        "        train_features = torch.rand(num_training_samples, embedding_dim).to(device)\n",
        "        train_labels = torch.randint(0, num_classes, (num_training_samples,)).to(device)\n",
        "        train_loader = DataLoader(TensorDataset(train_features, train_labels), batch_size=128, shuffle=True)\n",
        "        val_loader = None\n",
        "        print(f\"Loaded {num_training_samples} SYNTHETIC features for training (no real data found).\")\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "    num_epochs = 20\n",
        "    for epoch in range(num_epochs):\n",
        "        classifier.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\"):\n",
        "            # CRITICAL FIX: Ensure inputs and labels are on the correct device\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # <--- ADDED THIS LINE\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = classifier(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        val_loss = 0.0\n",
        "        if val_loader and len(val_loader.dataset) > 0: # Only run validation if val_loader exists and is not empty\n",
        "            classifier.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device) # <--- ADDED THIS LINE FOR VAL\n",
        "                    outputs = classifier(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "            val_loss /= len(val_loader.dataset)\n",
        "            logging.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "        else:\n",
        "             logging.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f} (No validation data)\")\n",
        "\n",
        "    print(\"--- Classifier Training Complete ---\")\n",
        "\n",
        "    torch.save(classifier.state_dict(), CLASSIFIER_SAVE_PATH)\n",
        "    print(f\"Classifier saved to: {CLASSIFIER_SAVE_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during classifier training: {e}\")"
      ],
      "metadata": {
        "id": "ecv0C73W7YOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 (Cell 3): Classification Inference and Gemini LLM Interaction"
      ],
      "metadata": {
        "id": "avZ2DY197cij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import logging\n",
        "import torch.nn as nn\n",
        "import datetime # Import datetime\n",
        "import pytz # Import pytz for timezone\n",
        "\n",
        "# Import Google Generative AI components\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure logging for this cell\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- API Key Setup ---\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "if GOOGLE_API_KEY:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "else:\n",
        "    print(\"WARNING: GOOGLE_API_KEY not found in Colab Secrets. Please ensure 'GEMINI' secret is set.\")\n",
        "    print(\"API calls will likely fail. Proceeding with unconfigured API.\")\n",
        "\n",
        "# --- Agent Configuration ---\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-2.5-flash\"\n",
        "\n",
        "# --- Check for required variables from Part 1 ---\n",
        "if 'video_features_for_inference' not in locals() or video_features_for_inference is None:\n",
        "    logging.error(\"ERROR: 'video_features_for_inference' not found or is None. Please run Part 1 (Video Loading and Feature Extraction) first and ensure it completes successfully.\")\n",
        "    exit()\n",
        "\n",
        "if 'device' not in locals():\n",
        "    logging.warning(\"WARNING: 'device' variable not found from Part 1. Defaulting to 'cpu'.\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "# Define class labels (MUST match the order used during training in Part 2)\n",
        "CLASS_LABELS = [\n",
        "    \"airplane landing\",\n",
        "    \"airplane takeoff\",\n",
        "    \"airport ground operations\",\n",
        "    \"in-flight cruise\",\n",
        "    \"emergency landing\",\n",
        "    \"pre-flight check/maintenance\"\n",
        "]\n",
        "num_classes = len(CLASS_LABELS)\n",
        "CLASSIFIER_SAVE_PATH = \"classifier_head_trained_on_tartan_aviation_sample.pth\" # Must match save path in Part 2\n",
        "\n",
        "# --- Classification Inference and Gemini LLM Interaction ---\n",
        "print(\"\\n--- Starting V-JEPA Feature-Driven Classification Inference and Gemini LLM Interaction ---\")\n",
        "\n",
        "try:\n",
        "    # Determine the feature dimension (embedding_dim) from V-JEPA output\n",
        "    embedding_dim = video_features_for_inference.shape[2]\n",
        "    # Prepare the single video's feature for inference\n",
        "    pooled_features_for_inference = video_features_for_inference.squeeze(0).mean(dim=0).unsqueeze(0)\n",
        "    pooled_features_for_inference = pooled_features_for_inference.to(device)\n",
        "\n",
        "    # Define the ClassifierHead architecture (must be identical to Part 2)\n",
        "    class ClassifierHead(nn.Module):\n",
        "        def __init__(self, input_dim, num_classes):\n",
        "            super().__init__()\n",
        "            self.fc1 = nn.Linear(input_dim, 256)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.dropout = nn.Dropout(0.3)\n",
        "            self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.fc2(self.dropout(self.relu(self.fc1(x)))).to(self.fc2.weight.device)\n",
        "\n",
        "    classifier = ClassifierHead(input_dim=embedding_dim, num_classes=num_classes).to(device)\n",
        "\n",
        "    # Load the trained classifier's weights\n",
        "    if os.path.exists(CLASSIFIER_SAVE_PATH):\n",
        "        classifier.load_state_dict(torch.load(CLASSIFIER_SAVE_PATH, map_location=device))\n",
        "        logging.info(f\"Classifier weights loaded from: {CLASSIFIER_SAVE_PATH}\")\n",
        "    else:\n",
        "        logging.error(f\"ERROR: Classifier weights file '{CLASSIFIER_SAVE_PATH}' not found.\")\n",
        "        logging.error(\"Please ensure Part 2 (Classifier Training) was run successfully and saved the model.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Making a Prediction Using the TRAINED Classifier ---\n",
        "    classifier.eval() # Set model to evaluation mode for inference\n",
        "    with torch.no_grad():\n",
        "        logits = classifier(pooled_features_for_inference)\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "        predicted_class_idx = torch.argmax(probabilities, dim=1).item()\n",
        "        predicted_confidence = probabilities[0, predicted_class_idx].item()\n",
        "        predicted_label = CLASS_LABELS[predicted_class_idx]\n",
        "\n",
        "    # --- Prepare Textual Input for Gemini LLM based on Prediction ---\n",
        "    llm_input_description = \"\"\n",
        "    if predicted_label == \"airplane landing\":\n",
        "        llm_input_description = \"The visual system detected an airplane landing. \"\n",
        "    elif predicted_label == \"airplane takeoff\":\n",
        "        llm_input_description = \"The visual system detected an airplane takeoff. \"\n",
        "    elif predicted_label == \"airport ground operations\":\n",
        "        llm_input_description = \"The visual system detected airport ground operations. \"\n",
        "    elif predicted_label == \"in-flight cruise\":\n",
        "        llm_input_description = \"The visual system detected an airplane in flight/cruise. \"\n",
        "    elif predicted_label == \"emergency landing\":\n",
        "        llm_input_description = \"The visual system detected a possible emergency landing scenario. \"\n",
        "    elif predicted_label == \"pre-flight check/maintenance\":\n",
        "        llm_input_description = \"The visual system detected pre-flight checks or maintenance activities. \"\n",
        "    else:\n",
        "        llm_input_description = \"The visual system detected an unrecognized or ambiguous aviation event. \"\n",
        "\n",
        "    llm_input_description += f\"(Confidence: {predicted_confidence:.2f})\"\n",
        "\n",
        "\n",
        "    print(f\"\\n--- AI Agent's Understanding from Classifier ---\")\n",
        "    print(f\"**Primary Classification (Predicted by AI):** '{predicted_label}' (Confidence: {predicted_confidence:.2f})\")\n",
        "    print(f\"**Description for LLM:** {llm_input_description}\")\n",
        "    print(f\"Note: This classification is from a model trained on synthetic data and is likely random until a real dataset is used for training.\")\n",
        "\n",
        "    # --- Gemini LLM Interaction ---\n",
        "    print(\"\\n--- Engaging Gemini LLM for Further Reasoning ---\")\n",
        "    try:\n",
        "        llm_model = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "\n",
        "        prompt_for_gemini = f\"\"\"\n",
        "        You are an AI assistant for flight planning operations.\n",
        "        Current visual observation: {llm_input_description}\n",
        "        Current time (EST): {datetime.datetime.now(pytz.timezone('EST')).strftime('%Y-%m-%d %H:%M:%S EST')}\n",
        "        Location: Montreal, Quebec, Canada.\n",
        "\n",
        "        Based on this visual observation, provide a concise operational assessment relevant for flight planning.\n",
        "        If the observation seems random or uncertain, state that. Do not invent details not present in the observation.\n",
        "        \"\"\"\n",
        "\n",
        "        gemini_response = llm_model.generate_content(prompt_for_gemini)\n",
        "\n",
        "        print(\"\\n--- Gemini LLM Response ---\")\n",
        "        if gemini_response.candidates:\n",
        "            for candidate in gemini_response.candidates:\n",
        "                if candidate.content and candidate.content.parts:\n",
        "                    for part in candidate.content.parts:\n",
        "                        print(part.text)\n",
        "        else:\n",
        "            print(\"Gemini LLM did not provide a text response or candidates.\")\n",
        "            if gemini_response.prompt_feedback:\n",
        "                print(f\"Prompt Feedback: {gemini_response.prompt_feedback}\")\n",
        "            if hasattr(gemini_response, 'error'):\n",
        "                print(f\"LLM Error: {gemini_response.error}\")\n",
        "\n",
        "\n",
        "    except Exception as llm_e:\n",
        "        logging.error(f\"Error interacting with Gemini LLM: {llm_e}\")\n",
        "        logging.error(\"Ensure your GOOGLE_API_KEY is correctly set in Colab Secrets and the model name is valid.\")\n",
        "\n",
        "\n",
        "    print(f\"\\nThis prediction comes from a classifier that was trained on synthetic examples.\")\n",
        "    print(f\"Due to the synthetic nature of the training data, this prediction is effectively random.\")\n",
        "    print(f\"For *truly accurate and high-confidence predictions* on real videos,\")\n",
        "    print(f\"the classifier needs to be trained on a large, diverse dataset of *real V-JEPA features and their corresponding labels*.\")\n",
        "    print(f\"The V-JEPA features (shape: {video_features_for_inference.shape}) are the core input that a trained classifier would learn from.\")\n",
        "    print(f\"Current time in EST: {datetime.datetime.now(pytz.timezone('EST')).strftime('%Y-%m-%d %H:%M:%S EST')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during classification inference or overall process: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PThRHS0r7kpl",
        "outputId": "e3e0806c-66fd-4013-bbe6-dcb9f00f6927"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n",
            "\n",
            "--- Starting V-JEPA Feature-Driven Classification Inference and Gemini LLM Interaction ---\n",
            "\n",
            "--- AI Agent's Understanding from Classifier ---\n",
            "**Primary Classification (Predicted by AI):** 'airplane landing' (Confidence: 1.00)\n",
            "**Description for LLM:** The visual system detected an airplane landing. (Confidence: 1.00)\n",
            "Note: This classification is from a model trained on synthetic data and is likely random until a real dataset is used for training.\n",
            "\n",
            "--- Engaging Gemini LLM for Further Reasoning ---\n",
            "\n",
            "--- Gemini LLM Response ---\n",
            "**Operational Assessment:**\n",
            "\n",
            "An airplane is currently landing at Montreal (likely CYUL). This indicates active runway occupancy and short-term traffic flow at the airport. Flight planners should note this for immediate inbound or outbound operations in the Montreal area.\n",
            "\n",
            "This prediction comes from a classifier that was trained on synthetic examples.\n",
            "Due to the synthetic nature of the training data, this prediction is effectively random.\n",
            "For *truly accurate and high-confidence predictions* on real videos,\n",
            "the classifier needs to be trained on a large, diverse dataset of *real V-JEPA features and their corresponding labels*.\n",
            "The V-JEPA features (shape: torch.Size([1, 2048, 1408])) are the core input that a trained classifier would learn from.\n",
            "Current time in EST: 2025-07-23 11:45:21 EST\n"
          ]
        }
      ]
    }
  ]
}