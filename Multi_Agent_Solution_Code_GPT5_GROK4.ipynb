{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuNEP2Hy6iUO0lzL9Y7yXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Multi_Agent_Solution_Code_GPT5_GROK4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core LangChain packages\n",
        "!pip install langchain langchain-community -q\n",
        "\n",
        "# LLM integrations for OpenAI and xAI\n",
        "!pip install langchain-openai -q\n",
        "\n",
        "# NOTE: The package for xAI/Grok integration in LangChain is called 'langchain-xai'.\n",
        "# Install this package to use Grok models.\n",
        "!pip install langchain-xai -q\n",
        "\n",
        "# Search tool for the Research Agent\n",
        "!pip install duckduckgo-search -q"
      ],
      "metadata": {
        "id": "Bh1E_K_EgNA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall duckduckgo-search -y\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "id": "rpPz6ualiG4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d529fca2",
        "outputId": "70f39096-2dff-422c-c86a-d7b55650da20"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Install necessary packages first ---\n",
        "# This ensures all required libraries are available before importing them.\n",
        "!pip install langchain langchain-community -q\n",
        "!pip install langchain-openai -q\n",
        "!pip install langchain-xai -q # Ensure langchain-xai is installed\n",
        "!pip install ddgs -q\n",
        "\n",
        "# --- Import modules after installation ---\n",
        "import os\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_xai import ChatXAI # This import will now happen after the package is installed\n",
        "from ddgs import DDGS  # Import the DDGS class\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# --- 1. Setup and LLM Configuration ---\n",
        "# Configuration for API keys\n",
        "XAI_API_KEY = None\n",
        "OPENAI_API_KEY = None\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    XAI_API_KEY = userdata.get('XAI_KEY')\n",
        "    if not XAI_API_KEY:\n",
        "        print(\"WARNING: XAI_KEY not found in Colab secrets.\")\n",
        "\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if not OPENAI_API_KEY:\n",
        "        print(\"WARNING: OPENAI_API_KEY not found in Colab secrets.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"WARNING: Not in Colab. Attempting to get API keys from environment variables.\")\n",
        "    XAI_API_KEY = os.environ.get('XAI_KEY', None)\n",
        "    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', None)\n",
        "\n",
        "# Define the LLMs to use\n",
        "llms_to_use = {}\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    # Research LLM uses the GPT-5 model.\n",
        "    llms_to_use['research_llm'] = ChatOpenAI(model=\"gpt-5\", api_key=OPENAI_API_KEY, temperature=1.0)\n",
        "else:\n",
        "    print(\"FATAL ERROR: OPENAI_API_KEY not set. The research LLM cannot be initialized.\")\n",
        "    exit()\n",
        "\n",
        "if XAI_API_KEY:\n",
        "    # Writing Agent uses the Grok-4 model for content generation.\n",
        "    llms_to_use['writer_llm'] = ChatXAI(model=\"grok-4-0709\", xai_api_key=XAI_API_KEY, temperature=0.7)\n",
        "else:\n",
        "    print(\"WARNING: XAI_API_KEY not set. Only using GPT for the writing agent as a fallback.\")\n",
        "    # Fallback to OpenAI if Grok key is missing\n",
        "    llms_to_use['writer_llm'] = ChatOpenAI(model=\"gpt-5\", api_key=OPENAI_API_KEY, temperature=1.0)\n",
        "\n",
        "\n",
        "# Modified print statement to show configured LLMs\n",
        "print(f\"LLMs configured successfully: Research LLM ({llms_to_use['research_llm'].model_name}), Writer LLM ({llms_to_use['writer_llm'].model_name}).\")\n",
        "\n",
        "# --- 2. Define Agents and Tools ---\n",
        "print(\"\\nDefining agents and tools...\")\n",
        "\n",
        "# Tool for the Research Agent using DDGS\n",
        "def ddgs_search(query: str) -> str:\n",
        "    \"\"\"Runs a search using DDGS and returns the results.\"\"\"\n",
        "    with DDGS() as ddgs:\n",
        "        results = [r['body'] for r in ddgs.text(query, max_results=5)]\n",
        "        return \"\\n\".join(results)\n",
        "\n",
        "# Since initialize_agent with CHAT_CONVERSATIONAL_REACT_DESCRIPTION was causing issues with 'stop' parameter,\n",
        "# we will create a custom research chain that incorporates the search tool.\n",
        "# This approach avoids the automatic 'stop' parameter injection by initialize_agent.\n",
        "\n",
        "# Define a prompt template for the research chain\n",
        "research_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"Perform a detailed search for the following query and summarize the key findings:\\n\\nQuery: {query}\\n\\nSearch Results:\"\n",
        ")\n",
        "\n",
        "# Create the research chain. This chain will first use the DDGS tool and then summarize results with GPT-5.\n",
        "# Note: This is a simplified approach. For more complex agentic behavior (e.g., iterative tool use),\n",
        "# you might need a custom LangChain agent executor or a more advanced chain.\n",
        "class ResearchChain(LLMChain):\n",
        "    def _call(self, inputs):\n",
        "        query = inputs[\"query\"]\n",
        "        # Use the search tool directly\n",
        "        search_results = ddgs_search(query)\n",
        "        # Now, pass the search results to the LLM for summarization\n",
        "        llm_input = f\"{research_prompt_template.template.format(query=query)}\\n{search_results}\"\n",
        "        response = self.llm.invoke(llm_input)\n",
        "        return {\"text\": response.content} # Ensure output key matches expected by next chain\n",
        "\n",
        "research_chain = ResearchChain(llm=llms_to_use['research_llm'], prompt=research_prompt_template)\n",
        "\n",
        "\n",
        "# Writing Agent: Uses Grok-4 to write based on research\n",
        "writer_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"research_result\"],\n",
        "    template=\"You are an expert article writer. Your task is to write a concise, professional article based on the following research data. The article should be a maximum of 3 paragraphs.\\n\\nResearch Data:\\n{research_result}\\n\\nArticle:\"\n",
        ")\n",
        "writer_chain = LLMChain(llm=llms_to_use['writer_llm'], prompt=writer_prompt_template)\n",
        "print(f\"Agents defined successfully: ResearchChain, Writer_chain.\")\n",
        "\n",
        "# --- 3. Orchestrate the Workflow ---\n",
        "print(\"\\nStarting the multi-agent workflow...\")\n",
        "\n",
        "# Run the workflow with a user query\n",
        "user_query = \"What is quantum computing and how does it differ from classical computing?\" # Updated the user query\n",
        "\n",
        "# Execute the research chain first\n",
        "print(\"Researching topic...\")\n",
        "# The research_chain expects 'query' as input\n",
        "research_output_dict = research_chain.invoke({\"query\": user_query})\n",
        "research_output = research_output_dict['text'] # Extract the text content\n",
        "print(\"Research complete.\")\n",
        "\n",
        "# Pass the research output to the writing chain\n",
        "print(\"Generating article...\")\n",
        "final_article = writer_chain.run(research_result=research_output)\n",
        "print(\"Article generation complete.\")\n",
        "\n",
        "print(\"\\n--- Final Article Output ---\")\n",
        "print(final_article)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLMs configured successfully: Research LLM (gpt-5), Writer LLM (grok-4-0709).\n",
            "\n",
            "Defining agents and tools...\n",
            "Agents defined successfully: ResearchChain, Writer_chain.\n",
            "\n",
            "Starting the multi-agent workflow...\n",
            "Researching topic...\n",
            "Research complete.\n",
            "Generating article...\n",
            "Article generation complete.\n",
            "\n",
            "--- Final Article Output ---\n",
            "### Understanding Quantum Computing: A Paradigm Shift from Classical Methods\n",
            "\n",
            "Quantum computing represents a revolutionary approach to computation that harnesses the principles of quantum mechanics, such as superposition, entanglement, and interference, to process information. Unlike classical computers, which rely on bits that exist strictly as 0 or 1, quantum computers use qubits that can occupy a superposition of states, allowing an n-qubit system to represent information in a 2^n-dimensional space. This enables operations that manipulate probability amplitudes through unitary, reversible gates, leading to interference patterns that amplify correct solutions while canceling incorrect ones. Models include gate-based circuits, measurement-based approaches, and adiabatic annealing, but the process culminates in measurement, which collapses the quantum state to classical outcomes. In contrast, classical computing employs irreversible gates and deterministic logic, lacking the exponential parallelism inherent in quantum systems, though it benefits from robust error handling and scalable hardware like CMOS transistors.\n",
            "\n",
            "The potential of quantum computing lies in its ability to outperform classical methods for specific problems, without providing universal speedups. Notable algorithms include Shor's for efficient factoring (threatening RSA cryptography), Grover's for quadratic search improvements, and techniques for simulating quantum systems in chemistry and materials science. These advantages stem from the BQP complexity class, which encompasses problems believed intractable classically but solvable quantumly, such as molecular energy calculations or certain optimization tasks. Emerging applications also span post-quantum cryptography, quantum key distribution for secure communications, and hybrid quantum-classical workflows for machine learning, though practical superiority in broad optimization remains unproven.\n",
            "\n",
            "Currently, quantum devices operate in the noisy intermediate-scale quantum (NISQ) era, with systems featuring tens to thousands of physical qubits prone to decoherence and errors, necessitating advanced error correction that demands significant overhead. Hardware platforms vary from superconducting circuits to trapped ions, facing challenges in scaling, fidelity, and cryogenic requirements. While demonstrations of quantum advantage exist for niche tasks, many are contested by classical advancements, underscoring that true fault-tolerant quantum computing is a long-term goal. Ultimately, quantum computing exploits the counterintuitive behaviors of quantum physics—discrete quanta and probabilistic phenomena—to explore exponentially vast state spaces, offering transformative potential where classical limits are reached.\n"
          ]
        }
      ]
    }
  ]
}