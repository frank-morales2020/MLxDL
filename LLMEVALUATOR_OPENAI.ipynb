{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXDbGlSQCRpaSvOnivDcnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LLMEVALUATOR_OPENAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lm-eval -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rZ_Q5S23lr-G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install tiktoken -q\n",
        "!pip install accelerate -q"
      ],
      "metadata": {
        "id": "7X9UOImnb6e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "%pip install openai  --root-user-action=ignore -q"
      ],
      "metadata": {
        "id": "qKhwQx25Km6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "faFZeUkMKy78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "print(openai.api_key)"
      ],
      "metadata": {
        "id": "bQhaCDwAb4Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#harness_repo=\"public-lm-eval-harness\"\n",
        "\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness/\n",
        "%cd /content/lm-evaluation-harness\n",
        "\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "JrbsQpKiS2aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets@git+https://github.com/huggingface/datasets.git@66d6242 -q\n",
        "!pip install tokenizers>=0.15.2 transformers>=4.38.2 sentencepiece>=0.2.0 -q"
      ],
      "metadata": {
        "id": "JQ_E8whQS-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which lm_eval"
      ],
      "metadata": {
        "id": "QkBmEcd9NPm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/guides/text-generation"
      ],
      "metadata": {
        "id": "4WxhIpl1oHmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/lm_eval_output\n",
        "%rm -rf /content/lm_eval_output/*"
      ],
      "metadata": {
        "id": "dBeo73W7ZYsX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "system_content = \"You are a travel agent. Be descriptive and helpful.\"\n",
        "user_content = \"Tell me about Montreal\"\n",
        "\n",
        "\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_content},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024,\n",
        "    #echo=True\n",
        ")\n",
        "\n",
        "response = chat_completion.choices[0].message.content\n",
        "print(\"Together response:\\n\", response)\n",
        "\n",
        "#TypeError: Completions.create() got an unexpected keyword argument 'echo'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vaj0JaBwgWC",
        "outputId": "0f0bdef6-7af9-4e9e-cd21-ca12e8a6e813"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Together response:\n",
            " Montreal, nestled in the heart of the Canadian province of Quebec, is a city steeped in a rich history and culture. It's the second-largest city in Canada and known for its stunning blend of old-world charm meets modern elegance. Being a bilingual city, both English and French are widely spoken, offering a European flair that's quite unique in North America.\n",
            "\n",
            "The city is divided into 19 large boroughs, and each has its own distinctive character. Downtown Montreal is the central business district, filled with skyscrapers, shopping centers, and museums. Old Montreal, the historic district, is where you can find the enchanting cobblestone streets, horse-drawn carriages, and historic sites like the Notre-Dame Basilica. The Plateau Mont-Royal is known for its colorful houses, hip cafes, and vibrant nightlife.\n",
            "\n",
            "Montreal is a city of festivals, hosting numerous large-scale events throughout the year, such as the world-famous Just for Laughs comedy festival, the Montreal International Jazz Festival, and the exciting Cirque du Soleil.\n",
            "\n",
            "Foodies will adore the city for its thriving culinary scene. Montreal is famous for its bagels, smoked meat sandwiches, and poutine, a delicious dish made of fries, cheese curds, and gravy. The city also boasts a wide variety of international cuisine due to its diverse population.\n",
            "\n",
            "Nature lovers aren't left out either. The city offers many parks, the most notable being Mount Royal Park, designed by the same man who designed Central Park in New York City. You can hike up Mount Royal for a panoramic view of the city. The Montreal Botanical Garden is another must-visit with its stunning array of plant species.\n",
            "\n",
            "Winters in Montreal can be quite cold and snowy, while summers are warm and often humid. Depending on the season of your visit, you could engage in activities ranging from ice skating to cycling.\n",
            "\n",
            "Montreal is a city that thrives on its mixture of history and modernity, English and French, and natural beauty with urban charm. It's a destination that can offer something to every traveler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/api-reference/models"
      ],
      "metadata": {
        "id": "XBrgZLP_S35G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvC8YPxhSqni",
        "outputId": "23709641-22c8-49f8-c58c-675c9929681e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
              " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
              " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
              " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
              " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
              " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
              " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
              " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
              " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-32k-0314', created=1687979321, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
              " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0314', created=1687882410, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
              " Model(id='ada:ft-personal-2023-07-11-12-33-39', created=1689078819, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-09-27-48', created=1689067668, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-01-20', created=1689055280, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-08-03-56', created=1689062636, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-40-25', created=1689057625, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-11-19-06', created=1689074346, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-12-01-12', created=1688990472, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-13-06-31', created=1688994391, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-14-54-14', created=1689000854, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-16-25-02', created=1689006302, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-17-48-42', created=1689011322, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-19-14-53', created=1689016493, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-21-00-00', created=1689022800, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-23-09-20', created=1689030560, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-01-42-16', created=1689039736, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-04-10-37', created=1689048637, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelid=modellist.data[4].id\n",
        "modelid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T41y2gtdmjJA",
        "outputId": "2d3ef47b-2a51-420f-d788-cf47bdbf745e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt-4o-2024-05-13'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/lm-evaluation-harness/lm_eval/models/openai_completions.py -- line=478"
      ],
      "metadata": {
        "id": "CpeoaO2iHZAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def loglikelihood(self, requests, disable_tqdm: bool = False):\n",
        "        res = []\n",
        "\n",
        "        for _ in tqdm(requests, disable=disable_tqdm):\n",
        "            res.append((-random.random(), False))\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "2bNaHyW_U1cg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/EleutherAI/lm-evaluation-harness/"
      ],
      "metadata": {
        "id": "1GhLcBMGFDig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#modelid='gpt-4'\n",
        "#modelid='gpt-3.5-turbo-instruct'\n",
        "\n",
        "os.environ['model'] = modelid\n",
        "#os.environ['task']='mmlu'\n",
        "\n",
        "#os.environ['task']='lambada_openai,hellaswag,mmlu'\n",
        "os.environ['task']='lambada_openai,openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq'\n",
        "os.environ['shot']='0'\n",
        "os.environ['batch_size']='1'\n",
        "\n",
        "os.environ['tokenizer']= modelid\n",
        "os.environ['add_bos_token']='True'\n",
        "\n",
        "os.environ['log_samples']='True'\n",
        "os.environ['random_seed']='0'\n",
        "os.environ['trust_remote_code']='True'"
      ],
      "metadata": {
        "id": "EYlOA8J50Mmq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6b,parallelize=True,load_in_4bit=True,peft=nomic-ai/gpt4all-j-lora --tasks openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq --device cuda:0"
      ],
      "metadata": {
        "id": "E_Pgt9ssGWr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $model\n",
        "!echo $task\n",
        "!echo $shot\n",
        "!echo $batch_size\n",
        "#print(os.environ)\n",
        "print()\n",
        "\n",
        "# Supported model names: anthropic, anthropic-chat, anthropic-chat-completions, dummy, gguf, ggml, hf-auto, hf, huggingface, mamba_ssm, nemo_lm, sparseml, deepsparse, neuronx, openai-completions, local-completions, openai-chat-completions, local-chat-completions, openvino, textsynth, vllm\n",
        "# trust_remote_code=True,\n",
        "!lm_eval --model openai-chat-completions --model_args model=${model},tokenizer=${tokenizer}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "#!lm_eval --model openai-completions --verbosity DEBUG --model_args model=${model},tokenizer=${tokenizer},random_seed=${random_seed},log_samples=${log_samples},trust_remote_code=${trust_remote_code}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVFFbc2xrSe",
        "outputId": "7ee344e8-3957-4d4b-f0e7-eaa8797d12f9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4o-2024-05-13\n",
            "lambada_openai,openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq\n",
            "0\n",
            "1\n",
            "\n",
            "2024-05-14 10:16:53.474159: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-14 10:16:53.474288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-14 10:16:53.482861: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-14 10:16:55.953154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-05-14:10:17:01,821 INFO     [__main__.py:254] Verbosity set to INFO\n",
            "2024-05-14:10:17:09,185 INFO     [__main__.py:341] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'winogrande']\n",
            "2024-05-14:10:17:09,189 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-05-14:10:17:09,189 INFO     [evaluator.py:178] Initializing openai-chat-completions model, with arguments: {'model': 'gpt-4o-2024-05-13', 'tokenizer': 'gpt-4o-2024-05-13'}\n",
            "2024-05-14:10:17:18,756 WARNING  [task.py:774] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-05-14:10:17:18,756 WARNING  [task.py:786] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1483: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "2024-05-14:10:17:40,428 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-14:10:17:40,428 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of piqa from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of openbookqa from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of lambada_openai from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of hellaswag from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,868 WARNING  [evaluator.py:240] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-05-14:10:18:01,868 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,869 WARNING  [evaluator.py:240] Overwriting default num_fewshot of arc_easy from None to 0\n",
            "2024-05-14:10:18:01,869 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,869 WARNING  [evaluator.py:240] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-05-14:10:18:01,869 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-14:10:18:01,872 INFO     [task.py:398] Building contexts for winogrande on rank 0...\n",
            "100%|██████████| 1267/1267 [00:00<00:00, 68858.87it/s]\n",
            "2024-05-14:10:18:01,942 INFO     [task.py:398] Building contexts for piqa on rank 0...\n",
            "100%|██████████| 1838/1838 [00:02<00:00, 849.97it/s]\n",
            "2024-05-14:10:18:04,185 INFO     [task.py:398] Building contexts for openbookqa on rank 0...\n",
            "100%|██████████| 500/500 [00:00<00:00, 1614.85it/s]\n",
            "2024-05-14:10:18:04,529 INFO     [task.py:398] Building contexts for lambada_openai on rank 0...\n",
            "100%|██████████| 5153/5153 [00:11<00:00, 442.14it/s]\n",
            "2024-05-14:10:18:16,278 INFO     [task.py:398] Building contexts for hellaswag on rank 0...\n",
            "100%|██████████| 10042/10042 [00:05<00:00, 1679.08it/s]\n",
            "2024-05-14:10:18:23,766 INFO     [task.py:398] Building contexts for boolq on rank 0...\n",
            "100%|██████████| 3270/3270 [00:02<00:00, 1477.49it/s]\n",
            "2024-05-14:10:18:26,165 INFO     [task.py:398] Building contexts for arc_easy on rank 0...\n",
            "100%|██████████| 2376/2376 [00:02<00:00, 841.56it/s]\n",
            "2024-05-14:10:18:29,194 INFO     [task.py:398] Building contexts for arc_challenge on rank 0...\n",
            "100%|██████████| 1172/1172 [00:01<00:00, 822.72it/s]\n",
            "2024-05-14:10:18:30,709 INFO     [evaluator.py:395] Running loglikelihood requests\n",
            "100%|██████████| 74259/74259 [00:00<00:00, 1338931.06it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "bootstrapping for stddev: perplexity\n",
            "100%|██████████| 100/100 [00:20<00:00,  4.97it/s]\n",
            "2024-05-14:10:19:12,155 INFO     [evaluation_tracker.py:132] Saving results aggregated\n",
            "openai-chat-completions (model=gpt-4o-2024-05-13,tokenizer=gpt-4o-2024-05-13), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 1\n",
            "|    Tasks     |Version|Filter|n-shot|  Metric  |Value |   |Stderr|\n",
            "|--------------|------:|------|-----:|----------|-----:|---|-----:|\n",
            "|arc_challenge |      1|none  |     0|acc       |0.2363|±  |0.0124|\n",
            "|              |       |none  |     0|acc_norm  |0.2457|±  |0.0126|\n",
            "|arc_easy      |      1|none  |     0|acc       |0.2445|±  |0.0088|\n",
            "|              |       |none  |     0|acc_norm  |0.2441|±  |0.0088|\n",
            "|boolq         |      2|none  |     0|acc       |0.5003|±  |0.0087|\n",
            "|hellaswag     |      1|none  |     0|acc       |0.2478|±  |0.0043|\n",
            "|              |       |none  |     0|acc_norm  |0.2471|±  |0.0043|\n",
            "|lambada_openai|      1|none  |     0|perplexity|1.6401|±  |0.0065|\n",
            "|              |       |none  |     0|acc       |0.0000|±  |0.0000|\n",
            "|openbookqa    |      1|none  |     0|acc       |0.2460|±  |0.0193|\n",
            "|              |       |none  |     0|acc_norm  |0.2820|±  |0.0201|\n",
            "|piqa          |      1|none  |     0|acc       |0.4984|±  |0.0117|\n",
            "|              |       |none  |     0|acc_norm  |0.5060|±  |0.0117|\n",
            "|winogrande    |      1|none  |     0|acc       |0.4893|±  |0.0140|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}