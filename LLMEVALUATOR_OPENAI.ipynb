{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQJt+OXEK/wHRD/osYV/AI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LLMEVALUATOR_OPENAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lm-eval -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rZ_Q5S23lr-G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install tiktoken -q\n",
        "!pip install accelerate -q"
      ],
      "metadata": {
        "id": "7X9UOImnb6e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "%pip install openai  --root-user-action=ignore -q"
      ],
      "metadata": {
        "id": "qKhwQx25Km6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "faFZeUkMKy78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "#print(openai.api_key)"
      ],
      "metadata": {
        "id": "bQhaCDwAb4Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#harness_repo=\"public-lm-eval-harness\"\n",
        "\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness/\n",
        "%cd /content/lm-evaluation-harness\n",
        "\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "id": "JrbsQpKiS2aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets@git+https://github.com/huggingface/datasets.git@66d6242 -q\n",
        "!pip install tokenizers>=0.15.2 transformers>=4.38.2 sentencepiece>=0.2.0 -q"
      ],
      "metadata": {
        "id": "JQ_E8whQS-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which lm_eval"
      ],
      "metadata": {
        "id": "QkBmEcd9NPm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/guides/text-generation"
      ],
      "metadata": {
        "id": "4WxhIpl1oHmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/lm_eval_output\n",
        "%rm -rf /content/lm_eval_output/*"
      ],
      "metadata": {
        "id": "dBeo73W7ZYsX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/api-reference/models"
      ],
      "metadata": {
        "id": "XBrgZLP_S35G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvC8YPxhSqni",
        "outputId": "f8f29c6f-42e0-458f-8101-67e33bf70fa1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
              " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
              " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
              " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
              " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
              " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
              " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
              " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
              " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-32k-0314', created=1687979321, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
              " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0314', created=1687882410, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
              " Model(id='ada:ft-personal-2023-07-11-12-33-39', created=1689078819, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-09-27-48', created=1689067668, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-01-20', created=1689055280, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-08-03-56', created=1689062636, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-40-25', created=1689057625, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-11-19-06', created=1689074346, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-12-01-12', created=1688990472, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-13-06-31', created=1688994391, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-14-54-14', created=1689000854, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-16-25-02', created=1689006302, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-17-48-42', created=1689011322, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-19-14-53', created=1689016493, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-21-00-00', created=1689022800, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-23-09-20', created=1689030560, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-01-42-16', created=1689039736, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-04-10-37', created=1689048637, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelid=modellist.data[4].id\n",
        "modelid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T41y2gtdmjJA",
        "outputId": "f5ea87a3-f895-4fe3-b482-88996e373904"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt-4o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/lm-evaluation-harness/lm_eval/models/openai_completions.py -- line=474\n"
      ],
      "metadata": {
        "id": "CpeoaO2iHZAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def loglikelihood(self, requests, disable_tqdm: bool = False):\n",
        "        res = []\n",
        "\n",
        "        for _ in tqdm(requests, disable=disable_tqdm):\n",
        "            res.append((-random.random(), False))\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "2bNaHyW_U1cg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "system_content = \"You are a travel agent. Be descriptive and helpful.\"\n",
        "user_content = \"Tell me about Montreal\"\n",
        "\n",
        "\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=modelid,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_content},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024,\n",
        "    #echo=True\n",
        ")\n",
        "\n",
        "response = chat_completion.choices[0].message.content\n",
        "print(\"Together response:\\n\", response)\n",
        "\n",
        "#TypeError: Completions.create() got an unexpected keyword argument 'echo'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vaj0JaBwgWC",
        "outputId": "0ac9f9e1-628c-484e-9fcc-5daf09b4aeda"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Together response:\n",
            " Absolutely! Montreal is a vibrant and cosmopolitan city located in the province of Quebec, Canada. It is the largest city in Quebec and the second-largest city in Canada. Here’s a detailed overview to help you get to know this fascinating destination:\n",
            "\n",
            "### History and Culture:\n",
            "Montreal has a rich history, dating back to its founding in 1642 as Ville-Marie by French settlers. The city is named after Mount Royal, the triple-peaked hill in the heart of the city. Montreal is known for its unique blend of European and North American cultures, which is evident in its architecture, festivals, and culinary scene. \n",
            "\n",
            "### Language:\n",
            "Montreal is predominantly French-speaking, with French being the official language. However, many residents are bilingual, and English is widely spoken, particularly in the downtown area and among younger residents.\n",
            "\n",
            "### Neighborhoods:\n",
            "1. **Old Montreal (Vieux-Montréal):** This historic area is characterized by cobblestone streets, 17th-century architecture, and landmarks like the Notre-Dame Basilica and the Old Port.\n",
            "2. **Plateau Mont-Royal:** Known for its bohemian vibe, this neighborhood is filled with colorful murals, trendy cafes, and boutique shops.\n",
            "3. **Downtown:** The bustling heart of the city, home to skyscrapers, shopping centers, and cultural institutions like the Montreal Museum of Fine Arts.\n",
            "4. **Mile End:** A hip and multicultural neighborhood known for its vibrant arts scene, indie music venues, and some of the city’s best bagels and coffee shops.\n",
            "\n",
            "### Key Attractions:\n",
            "1. **Notre-Dame Basilica:** A stunning example of Gothic Revival architecture with a breathtaking interior.\n",
            "2. **Mount Royal Park:** Designed by Frederick Law Olmsted, this large park offers hiking trails, picnic areas, and stunning views of the city skyline.\n",
            "3. **Montreal Museum of Fine Arts:** One of Canada’s premier art museums, featuring an extensive collection of classical and contemporary art.\n",
            "4. **Biodome:** Part of the Space for Life museum district, this unique facility replicates various ecosystems of the Americas.\n",
            "5. **Jean-Talon Market:** One of the largest public markets in North America, offering a wide variety of fresh produce, meats, cheeses, and baked goods.\n",
            "\n",
            "### Festivals:\n",
            "Montreal is famous for its year-round festivals, including:\n",
            "- **Montreal International Jazz Festival:** One of the largest jazz festivals in the world.\n",
            "- **Just for Laughs:** A renowned comedy festival drawing big names and emerging talent.\n",
            "- **Montreal World Film Festival:** Showcasing films from around the globe.\n",
            "- **Osheaga:** A major music and arts festival featuring international acts.\n",
            "\n",
            "### Culinary Scene:\n",
            "Montreal boasts a diverse and eclectic food scene. Must-try items include:\n",
            "- **Poutine:** A Quebecois dish of fries topped with cheese curds and gravy.\n",
            "- **Montreal-style bagels:** Slightly sweeter and denser than their New York counterparts.\n",
            "- **Smoked meat sandwiches:** Particularly from the iconic Schwartz’s Deli.\n",
            "- **Maple-infused treats:** From maple syrup to pastries.\n",
            "\n",
            "### Transportation:\n",
            "Montreal is well-connected with an extensive public transportation system, including buses and the Metro (subway). The city is also bike-friendly, with numerous bike lanes and a popular bike-sharing program called BIXI.\n",
            "\n",
            "### Climate:\n",
            "Montreal experiences four distinct seasons. Winters can be cold and snowy, while summers are warm and humid. Spring and fall are mild and beautiful, making them ideal times for a visit.\n",
            "\n",
            "### Tips for Travelers:\n",
            "- **Language:** While knowing some basic French phrases can be helpful, most tourist areas have English-speaking staff.\n",
            "- **Currency:** The local currency is the Canadian dollar (CAD).\n",
            "- **Tipping:** Similar to the U.S., tipping around 15-20% at restaurants is customary.\n",
            "\n",
            "Montreal is a city that offers something for everyone, whether you’re interested in history, culture, food, or outdoor activities. It’s a destination that truly captures the spirit of diversity and vibrancy. Enjoy your trip!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/EleutherAI/lm-evaluation-harness/"
      ],
      "metadata": {
        "id": "1GhLcBMGFDig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#modelid='gpt-4'\n",
        "#modelid='gpt-3.5-turbo-instruct'\n",
        "\n",
        "os.environ['model'] = modelid\n",
        "#os.environ['task']='mmlu'\n",
        "\n",
        "os.environ['task']='lambada_openai,hellaswag'\n",
        "#os.environ['task']='mmlu,lambada_openai,openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq'\n",
        "os.environ['shot']='0'\n",
        "os.environ['batch_size']='1'\n",
        "\n",
        "os.environ['tokenizer']= modelid\n",
        "os.environ['add_bos_token']='True'\n",
        "\n",
        "os.environ['log_samples']='True'\n",
        "os.environ['random_seed']='0'\n",
        "os.environ['trust_remote_code']='True'"
      ],
      "metadata": {
        "id": "EYlOA8J50Mmq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6b,parallelize=True,load_in_4bit=True,peft=nomic-ai/gpt4all-j-lora --tasks openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq --device cuda:0"
      ],
      "metadata": {
        "id": "E_Pgt9ssGWr0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $model\n",
        "!echo $task\n",
        "!echo $shot\n",
        "!echo $batch_size\n",
        "#print(os.environ)\n",
        "print()\n",
        "\n",
        "# Supported model names: anthropic, anthropic-chat, anthropic-chat-completions, dummy, gguf, ggml, hf-auto, hf, huggingface, mamba_ssm, nemo_lm, sparseml, deepsparse, neuronx, openai-completions, local-completions, openai-chat-completions, local-chat-completions, openvino, textsynth, vllm\n",
        "# trust_remote_code=True,\n",
        "!lm_eval --model openai-chat-completions --model_args model=${model},tokenizer=${tokenizer}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "#!lm_eval --model openai-completions --verbosity DEBUG --model_args model=${model},tokenizer=${tokenizer},random_seed=${random_seed},log_samples=${log_samples},trust_remote_code=${trust_remote_code}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log"
      ],
      "metadata": {
        "id": "sHVFFbc2xrSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bcee1e-b0fb-4591-e9be-99dee486fe2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4o\n",
            "lambada_openai,hellaswag\n",
            "0\n",
            "1\n",
            "\n",
            "2024-05-15 00:22:49.299746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-15 00:22:49.299807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-15 00:22:49.301305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-15 00:22:50.731273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-05-15:00:22:54,933 INFO     [__main__.py:254] Verbosity set to INFO\n",
            "2024-05-15:00:23:02,025 INFO     [__main__.py:341] Selected Tasks: ['hellaswag', 'lambada_openai']\n",
            "2024-05-15:00:23:02,027 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-05-15:00:23:02,027 INFO     [evaluator.py:178] Initializing openai-chat-completions model, with arguments: {'model': 'gpt-4o', 'tokenizer': 'gpt-4o'}\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1483: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "2024-05-15:00:23:18,101 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-15:00:23:18,102 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-15:00:23:18,190 WARNING  [evaluator.py:240] Overwriting default num_fewshot of lambada_openai from None to 0\n",
            "2024-05-15:00:23:18,190 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-15:00:23:18,190 WARNING  [evaluator.py:240] Overwriting default num_fewshot of hellaswag from None to 0\n",
            "2024-05-15:00:23:18,190 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-15:00:23:18,192 INFO     [task.py:398] Building contexts for lambada_openai on rank 0...\n",
            "100%|██████████| 5153/5153 [00:11<00:00, 441.03it/s]\n",
            "2024-05-15:00:23:29,968 INFO     [task.py:398] Building contexts for hellaswag on rank 0...\n",
            "100%|██████████| 10042/10042 [00:04<00:00, 2083.31it/s]\n",
            "2024-05-15:00:23:36,053 INFO     [evaluator.py:395] Running loglikelihood requests\n",
            "100%|██████████| 45321/45321 [00:00<00:00, 1333310.31it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "bootstrapping for stddev: perplexity\n",
            "100%|██████████| 100/100 [00:19<00:00,  5.13it/s]\n",
            "2024-05-15:00:24:06,692 INFO     [evaluation_tracker.py:132] Saving results aggregated\n",
            "openai-chat-completions (model=gpt-4o,tokenizer=gpt-4o), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 1\n",
            "|    Tasks     |Version|Filter|n-shot|  Metric  |Value |   |Stderr|\n",
            "|--------------|------:|------|-----:|----------|-----:|---|-----:|\n",
            "|hellaswag     |      1|none  |     0|acc       |0.2541|±  |0.0043|\n",
            "|              |       |none  |     0|acc_norm  |0.2563|±  |0.0044|\n",
            "|lambada_openai|      1|none  |     0|perplexity|1.6571|±  |0.0066|\n",
            "|              |       |none  |     0|acc       |0.0000|±  |0.0000|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}