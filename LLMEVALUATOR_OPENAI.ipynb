{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEMoHA70VjdCzNi3v/13ZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/LLMEVALUATOR_OPENAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lm-eval -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rZ_Q5S23lr-G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --quiet\n",
        "!pip install tiktoken -q\n",
        "!pip install accelerate -q"
      ],
      "metadata": {
        "id": "7X9UOImnb6e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added by Frank Morales(FM) 22/02/2024\n",
        "%pip install openai  --root-user-action=ignore -q"
      ],
      "metadata": {
        "id": "qKhwQx25Km6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "faFZeUkMKy78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bece2c4d-4b73-444d-e5e3-e6778abda2f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "#print(openai.api_key)"
      ],
      "metadata": {
        "id": "bQhaCDwAb4Vl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#harness_repo=\"public-lm-eval-harness\"\n",
        "\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness/\n",
        "%cd /content/lm-evaluation-harness\n",
        "\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "id": "JrbsQpKiS2aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets@git+https://github.com/huggingface/datasets.git@66d6242 -q\n",
        "!pip install tokenizers>=0.15.2 transformers>=4.38.2 sentencepiece>=0.2.0 -q"
      ],
      "metadata": {
        "id": "JQ_E8whQS-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which lm_eval"
      ],
      "metadata": {
        "id": "QkBmEcd9NPm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/guides/text-generation"
      ],
      "metadata": {
        "id": "4WxhIpl1oHmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/lm_eval_output\n",
        "%rm -rf /content/lm_eval_output/*"
      ],
      "metadata": {
        "id": "dBeo73W7ZYsX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/api-reference/models"
      ],
      "metadata": {
        "id": "XBrgZLP_S35G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvC8YPxhSqni",
        "outputId": "54de3e18-ef17-4aa0-cc8b-3de5303e9f17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
              " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
              " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
              " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
              " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
              " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
              " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
              " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
              " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
              " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-32k-0314', created=1687979321, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
              " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0314', created=1687882410, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
              " Model(id='ada:ft-personal-2023-07-11-12-33-39', created=1689078819, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-09-27-48', created=1689067668, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-01-20', created=1689055280, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-08-03-56', created=1689062636, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-06-40-25', created=1689057625, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-11-19-06', created=1689074346, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-12-01-12', created=1688990472, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-13-06-31', created=1688994391, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-14-54-14', created=1689000854, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-16-25-02', created=1689006302, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-17-48-42', created=1689011322, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-19-14-53', created=1689016493, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-21-00-00', created=1689022800, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-10-23-09-20', created=1689030560, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-01-42-16', created=1689039736, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp'),\n",
              " Model(id='ada:ft-personal-2023-07-11-04-10-37', created=1689048637, object='model', owned_by='user-mgtzrbiiso3g68oicniq0obp')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelid=modellist.data[4].id\n",
        "modelid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T41y2gtdmjJA",
        "outputId": "458cb07b-805e-40cc-b81e-dcb36d45be01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt-4o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/lm-evaluation-harness/lm_eval/models/openai_completions.py -- line=474\n"
      ],
      "metadata": {
        "id": "CpeoaO2iHZAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def loglikelihood(self, requests, disable_tqdm: bool = False):\n",
        "        res = []\n",
        "\n",
        "        for _ in tqdm(requests, disable=disable_tqdm):\n",
        "            res.append((-random.random(), False))\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "2bNaHyW_U1cg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "system_content = \"You are a travel agent. Be descriptive and helpful.\"\n",
        "user_content = \"Tell me about havana\"\n",
        "\n",
        "\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=modelid,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_content},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ],\n",
        "    temperature=0.9,\n",
        "    max_tokens=1024,\n",
        "    #echo=True\n",
        ")\n",
        "\n",
        "response = chat_completion.choices[0].message.content\n",
        "print(\"Together response:\\n\", response)\n",
        "\n",
        "#TypeError: Completions.create() got an unexpected keyword argument 'echo'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vaj0JaBwgWC",
        "outputId": "a291bae6-dc9c-4a1c-f3e4-a3e0a3638ae4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Together response:\n",
            " Absolutely, I'd be delighted to tell you about Havana!\n",
            "\n",
            "Havana, the capital city of Cuba, is an enchanting destination brimming with history, culture, and a vibrant rhythm that captures the hearts of its visitors. Here's a comprehensive look at what makes Havana so special:\n",
            "\n",
            "### Historical Significance\n",
            "Havana is steeped in history, with its roots stretching back to its founding in 1519 by Spanish colonists. The city's rich past is vividly brought to life through its architecture, museums, and historical sites.\n",
            "\n",
            "### Architectural Marvels\n",
            "One of the first things you'll notice in Havana is its stunning architecture. The city boasts a mix of colonial, baroque, neoclassical, and Art Deco buildings. Notable sites include:\n",
            "\n",
            "- **Old Havana (Habana Vieja)**: A UNESCO World Heritage site, this area is a treasure trove of colonial architecture with cobblestone streets, historic plazas, and beautifully preserved buildings. Key landmarks include the Plaza de la Catedral, the Castillo de la Real Fuerza, and the Plaza Vieja.\n",
            "- **El Capitolio**: An iconic building resembling the U.S. Capitol, it symbolizes the city and offers panoramic views from its dome.\n",
            "- **The Malecón**: This famous seawall stretches for 8 kilometers along the coast and is a popular spot for both locals and tourists to stroll, socialize, and enjoy stunning ocean views.\n",
            "\n",
            "### Cultural Vibrancy\n",
            "Havana is a cultural hub, pulsating with music, dance, and art. Key highlights include:\n",
            "\n",
            "- **Music and Dance**: The city is renowned for its traditional Cuban music, including salsa, son, and mambo. Venues like the Buena Vista Social Club and the Tropicana Club offer lively performances and a taste of Cuba's musical heritage.\n",
            "- **Museums and Galleries**: Cuban art and history are well-represented in museums such as the Museo Nacional de Bellas Artes, the Museo de la Revolución, and the Ernest Hemingway Museum, located in the author’s former home, Finca Vigía.\n",
            "\n",
            "### Culinary Delights\n",
            "Cuban cuisine is a fusion of Spanish, African, and Caribbean influences, and Havana offers an array of dining experiences:\n",
            "\n",
            "- **Paladares**: These private, family-run restaurants serve traditional Cuban dishes with a homely touch. Popular paladares include La Guarida and Dona Eutimia.\n",
            "- **Local Flavors**: Don’t miss trying staples like ropa vieja (shredded beef), arroz con pollo (chicken with rice), and the ubiquitous Cuban sandwich.\n",
            "\n",
            "### Everyday Life and Local Experience\n",
            "Immerse yourself in local life by exploring the bustling street markets, sipping a mojito at one of Hemingway’s favorite haunts like La Bodeguita del Medio, or simply watching the world go by in one of the city’s many charming plazas.\n",
            "\n",
            "### Practical Tips\n",
            "- **Currency**: Cuba has two currencies, the Cuban Peso (CUP) and the Cuban Convertible Peso (CUC). Most tourists will use the CUC.\n",
            "- **Travel**: Havana’s José Martí International Airport connects the city with various international destinations. Within the city, you can navigate using classic American cars, buses, or even bicycle taxis.\n",
            "- **Accommodation**: Options range from luxury hotels like the Gran Hotel Manzana Kempinski to more budget-friendly casas particulares (private homestays).\n",
            "\n",
            "### Conclusion\n",
            "Havana is a city of contrasts and color, where history and modernity intertwine against a backdrop of infectious rhythms and warm hospitality. Whether you’re drawn to its historic streets, cultural offerings, or simply want to soak in its unique atmosphere, Havana promises an unforgettable experience.\n",
            "\n",
            "Feel free to ask if you need any more information or specific recommendations!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/EleutherAI/lm-evaluation-harness/"
      ],
      "metadata": {
        "id": "1GhLcBMGFDig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#modelid='gpt-4'\n",
        "#modelid='gpt-3.5-turbo-instruct'\n",
        "\n",
        "os.environ['model'] = modelid\n",
        "#os.environ['task']='mmlu'\n",
        "\n",
        "os.environ['task']='lambada_openai,hellaswag'\n",
        "#os.environ['task']='mmlu,lambada_openai,openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq'\n",
        "os.environ['shot']='0'\n",
        "os.environ['batch_size']='1'\n",
        "\n",
        "os.environ['tokenizer']= modelid\n",
        "os.environ['add_bos_token']='True'\n",
        "\n",
        "os.environ['log_samples']='True'\n",
        "os.environ['random_seed']='0'\n",
        "os.environ['trust_remote_code']='True'"
      ],
      "metadata": {
        "id": "EYlOA8J50Mmq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6b,parallelize=True,load_in_4bit=True,peft=nomic-ai/gpt4all-j-lora --tasks openbookqa,arc_easy,winogrande,hellaswag,arc_challenge,piqa,boolq --device cuda:0"
      ],
      "metadata": {
        "id": "E_Pgt9ssGWr0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $model\n",
        "!echo $task\n",
        "!echo $shot\n",
        "!echo $batch_size\n",
        "#print(os.environ)\n",
        "print()\n",
        "\n",
        "# Supported model names: anthropic, anthropic-chat, anthropic-chat-completions, dummy, gguf, ggml, hf-auto, hf, huggingface, mamba_ssm, nemo_lm, sparseml, deepsparse, neuronx, openai-completions, local-completions, openai-chat-completions, local-chat-completions, openvino, textsynth, vllm\n",
        "# trust_remote_code=True,\n",
        "!lm_eval --model openai-chat-completions --model_args model=${model},tokenizer=${tokenizer}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "#!lm_eval --model openai-completions --verbosity DEBUG --model_args model=${model},tokenizer=${tokenizer},random_seed=${random_seed},log_samples=${log_samples},trust_remote_code=${trust_remote_code}   --tasks ${task}  --num_fewshot ${shot} --output_path /content/lm_eval_output/${model//\\//_}_${task//,/_}-${shot}shot --batch_size ${batch_size} 2>&1 | tee /content/lm_eval_output/eval-${model//\\//_}_${task//,/_}-${shot}shot.log"
      ],
      "metadata": {
        "id": "sHVFFbc2xrSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bcee1e-b0fb-4591-e9be-99dee486fe2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4o\n",
            "lambada_openai,hellaswag\n",
            "0\n",
            "1\n",
            "\n",
            "2024-05-15 00:22:49.299746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-15 00:22:49.299807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-15 00:22:49.301305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-15 00:22:50.731273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-05-15:00:22:54,933 INFO     [__main__.py:254] Verbosity set to INFO\n",
            "2024-05-15:00:23:02,025 INFO     [__main__.py:341] Selected Tasks: ['hellaswag', 'lambada_openai']\n",
            "2024-05-15:00:23:02,027 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-05-15:00:23:02,027 INFO     [evaluator.py:178] Initializing openai-chat-completions model, with arguments: {'model': 'gpt-4o', 'tokenizer': 'gpt-4o'}\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1483: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "2024-05-15:00:23:18,101 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-15:00:23:18,102 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-05-15:00:23:18,190 WARNING  [evaluator.py:240] Overwriting default num_fewshot of lambada_openai from None to 0\n",
            "2024-05-15:00:23:18,190 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-15:00:23:18,190 WARNING  [evaluator.py:240] Overwriting default num_fewshot of hellaswag from None to 0\n",
            "2024-05-15:00:23:18,190 INFO     [evaluator.py:245] Setting fewshot random generator seed to 1234\n",
            "2024-05-15:00:23:18,192 INFO     [task.py:398] Building contexts for lambada_openai on rank 0...\n",
            "100%|██████████| 5153/5153 [00:11<00:00, 441.03it/s]\n",
            "2024-05-15:00:23:29,968 INFO     [task.py:398] Building contexts for hellaswag on rank 0...\n",
            "100%|██████████| 10042/10042 [00:04<00:00, 2083.31it/s]\n",
            "2024-05-15:00:23:36,053 INFO     [evaluator.py:395] Running loglikelihood requests\n",
            "100%|██████████| 45321/45321 [00:00<00:00, 1333310.31it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "bootstrapping for stddev: perplexity\n",
            "100%|██████████| 100/100 [00:19<00:00,  5.13it/s]\n",
            "2024-05-15:00:24:06,692 INFO     [evaluation_tracker.py:132] Saving results aggregated\n",
            "openai-chat-completions (model=gpt-4o,tokenizer=gpt-4o), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 1\n",
            "|    Tasks     |Version|Filter|n-shot|  Metric  |Value |   |Stderr|\n",
            "|--------------|------:|------|-----:|----------|-----:|---|-----:|\n",
            "|hellaswag     |      1|none  |     0|acc       |0.2541|±  |0.0043|\n",
            "|              |       |none  |     0|acc_norm  |0.2563|±  |0.0044|\n",
            "|lambada_openai|      1|none  |     0|perplexity|1.6571|±  |0.0066|\n",
            "|              |       |none  |     0|acc       |0.0000|±  |0.0000|\n",
            "\n"
          ]
        }
      ]
    }
  ]
}