{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEcysHmxiKUOz967Z5e/wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/Copy_of_DEEPSEEKV3_TUTORIALipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlGiBn_U3la3"
      },
      "outputs": [],
      "source": [
        "!pip install openai weave  -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('WANDB_KEY')\n",
        "import wandb\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "id": "7E97Qz5d4xkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "from openai import OpenAI\n",
        "\n",
        "weave.init(\"deepseek_examples\")\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")"
      ],
      "metadata": {
        "id": "fp7Ia8Cs4DBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@weave.op()\n",
        "def deepseek_inference(prompt: str, model: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"you are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "    reasoning = getattr(response.choices[0].message, \"reasoning_content\", None)\n",
        "    final_answer = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    return {\"model\": model, \"answer\": final_answer, \"reasoning\": reasoning}"
      ],
      "metadata": {
        "id": "j0IyFBXB5dX6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q0=\"Can you explain the field of convex optimization in simple terms, including what types of problems it is used to solve?\"\n",
        "\n",
        "Q1=\"What are the 'bounds' in convex optimization, and why are they important in algorithms?\"\n",
        "\n",
        "Q2=\"What is a 'convex optimization problem from convex optimization'?\"\n",
        "\n",
        "Q3=\"What are some of the open problems in convex optimization that researchers are currently working on?\""
      ],
      "metadata": {
        "id": "CZ5Ayu3QGlGw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V3.2"
      ],
      "metadata": {
        "id": "CiRBuS9qJtH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepSeek has been upgraded to V3.2-Exp. V3.1-Terminus remains available via a temporary API until October 15, 2025, 15:59 UTC. We invite you to participate in comparative testing. [See the comparison testing guide]"
      ],
      "metadata": {
        "id": "j2rw-s_CKpE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and print the assistant's reply\n",
        "assistant_replyQ0 = deepseek_inference(Q0, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ1 = deepseek_inference(Q1, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ2 = deepseek_inference(Q2, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ3 = deepseek_inference(Q3, \"deepseek-reasoner\")[\"answer\"]"
      ],
      "metadata": {
        "id": "1Rut613jJyeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Assistant:\", assistant_replyQ0)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ1)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ2)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_qQtIAJJ4lR",
        "outputId": "4513f349-6dbf-480c-a894-a57de9cc5da1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: Of course! Let's break down convex optimization in simple terms, using an analogy.\n",
            "\n",
            "### The Simple Analogy: Finding the Bottom of a Bowl\n",
            "\n",
            "Imagine you have a smooth, perfectly shaped bowl. You drop a marble into it. No matter where you drop the marble, it will always roll down to the very bottom—the lowest point.\n",
            "\n",
            "*   **The Bowl:** This represents a **\"convex function.\"** Its shape is such that any line you draw between two points on the bowl always stays inside the bowl (this is the formal definition of convexity).\n",
            "*   **The Marble:** This represents the **optimization algorithm.**\n",
            "*   **The Bottom of the Bowl:** This is the **optimal solution**—the best possible answer to your problem.\n",
            "\n",
            "**Now, imagine a \"non-convex\" shape,** like a rugged mountain range with many peaks and valleys. If you drop a marble, it will get stuck in the nearest valley, but you have no way of knowing if it's the *deepest valley* on the entire mountain.\n",
            "\n",
            "*   **Convex Optimization** is like the bowl: you are **guaranteed** that the valley you find is the deepest one (the *global optimum*).\n",
            "*   **Non-Convex Optimization** is like the mountain range: you might find a good valley, but you can't be sure it's the best one.\n",
            "\n",
            "---\n",
            "\n",
            "### What is Convex Optimization, Really?\n",
            "\n",
            "In simple terms, **convex optimization is a special class of mathematical problems where you are trying to find the best possible outcome (like minimizing cost or maximizing profit) from a set of choices, and the problem's \"shape\" guarantees that you can find that best outcome efficiently and reliably.**\n",
            "\n",
            "The \"best outcome\" is usually:\n",
            "*   **Minimizing** something (e.g., cost, error, energy use).\n",
            "*   **Maximizing** something (e.g., profit, efficiency, return).\n",
            "\n",
            "The \"set of choices\" is defined by **constraints** (rules you have to follow, e.g., \"the budget must be under $1000\" or \"the solution must use at least 10% recycled material\").\n",
            "\n",
            "### The \"Magic\" of Convexity\n",
            "\n",
            "The reason convex optimization is so powerful is that **any local solution you find is also the global solution.**\n",
            "\n",
            "*   **Local Solution:** The best answer in a small neighborhood.\n",
            "*   **Global Solution:** The best answer overall, across all possible choices.\n",
            "\n",
            "Because of this property, we have very efficient and fast algorithms (like Gradient Descent, Interior-Point Methods) that can find the solution for very large-scale problems with thousands or even millions of variables.\n",
            "\n",
            "---\n",
            "\n",
            "### What Types of Problems is it Used For?\n",
            "\n",
            "Convex optimization is incredibly widespread because many real-world problems can be modeled (or approximated) as convex problems. Here are some common examples:\n",
            "\n",
            "**1. Engineering & Science**\n",
            "*   **Electrical Engineering:** Designing circuits to minimize power consumption while maintaining a certain signal strength.\n",
            "*   **Machine Learning:** The core of many machine learning algorithms is a convex optimization problem.\n",
            "    *   **Training a Model:** Finding the model parameters that **minimize prediction error** (e.g., in Linear Regression, Support Vector Machines, and Logistic Regression).\n",
            "*   **Control Systems:** Finding the most efficient way to guide a rocket or control a robot's arm while minimizing fuel or energy use.\n",
            "\n",
            "**2. Business & Finance**\n",
            "*   **Portfolio Optimization:** Choosing a mix of investments to **maximize expected return** while **minimizing financial risk**. This is one of the most famous applications.\n",
            "*   **Resource Allocation:** Allocating limited resources (like manpower, machines, or budget) across different projects to **maximize total profit**.\n",
            "*   **Supply Chain Management:** Finding the most cost-effective routes for shipping goods from warehouses to stores.\n",
            "\n",
            "**3. Data Science & Statistics**\n",
            "*   **Signal Processing:** Denoising a signal (like cleaning up an audio recording or a medical image) by formulating it as an optimization problem.\n",
            "*   **Fitting a Model:** Finding the line (or curve) that best fits a set of data points, which is fundamentally a convex least-squares problem.\n",
            "\n",
            "**4. Everyday Examples**\n",
            "*   **The \"Best\" Path:** Finding the shortest route on a map (like Google Maps) is a convex problem.\n",
            "*   **Recommendation Systems:** When Netflix or YouTube suggest what to watch next, they are often solving a large optimization problem to predict your preferences.\n",
            "\n",
            "### Summary\n",
            "\n",
            "| Feature | Convex Optimization | General (Non-Convex) Optimization |\n",
            "| :--- | :--- | :--- |\n",
            "| **Analogy** | Finding the bottom of a bowl | Finding the lowest valley in a mountain range |\n",
            "| **Solution Guarantee** | **Any solution found is the best one (Global Optimum)** | Solution might only be locally good, not globally best |\n",
            "| **Efficiency** | **Fast and scalable** for large problems | Can be very slow and computationally expensive |\n",
            "| **Reliability** | **Highly reliable** and predictable | Less reliable; depends heavily on the starting point |\n",
            "\n",
            "In short, if you can frame your real-world problem into a \"bowl-shaped\" (convex) one, you unlock a powerful and reliable toolkit to find the absolute best solution.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. This is an excellent question that gets to the heart of why convex optimization is so powerful and widely used.\n",
            "\n",
            "In convex optimization, the term \"**bounds**\" can refer to two distinct but related concepts. Their importance is paramount for both the theory and practice of algorithms.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Bounds on the Solution (Optimality Bounds)\n",
            "\n",
            "This is the most common meaning in the context of *algorithms*. These are not constraints on the variables, but rather **guarantees on the quality of the solution** found by an iterative algorithm.\n",
            "\n",
            "Since most algorithms don't find the exact solution in a finite number of steps, we need a way to measure how close we are. Bounds provide a numerical certificate of this closeness.\n",
            "\n",
            "#### Key Types of Solution Bounds:\n",
            "\n",
            "*   **Duality Gap:** This is the most important and fundamental bound.\n",
            "    *   **What it is:** For a convex optimization problem (the *primal*), we can often form a related \"mirror\" problem called the *dual*. The duality gap is the difference between the value of the primal objective function and the value of the dual objective function at a given point.\n",
            "    *   **Why it's a bound:** For convex problems (under certain conditions like Slater's condition), the value of the dual problem is always a **lower bound** on the primal optimal value. Therefore, the duality gap is always non-negative. When the gap is zero, you have found the optimal solution.\n",
            "    *   **In Algorithms:** As an algorithm runs, it generates a sequence of primal points \\( x^{(k)} \\) and dual points \\( \\lambda^{(k)} \\). At each step, you can compute the duality gap. A small gap guarantees that you are very close to the true optimal value, even if you haven't converged exactly.\n",
            "\n",
            "*   **Upper and Lower Bounds:**\n",
            "    *   **Upper Bound:** Any feasible point \\( x \\) gives you a value \\( f(x) \\) for the objective function. Since you are minimizing, \\( f(x) \\) is an *upper bound* on the true optimal value \\( p^* \\) (i.e., \\( p^* \\leq f(x) \\)). The best feasible point you've found so far gives you the best (lowest) upper bound.\n",
            "    *   **Lower Bound:** The dual problem, as mentioned, provides a *lower bound* on \\( p^* \\). As the algorithm progresses, the lower bound (from the dual) increases, and the upper bound (from the primal) decreases. The algorithm can stop when these two bounds are sufficiently close.\n",
            "\n",
            "#### **Why are Solution Bounds Important for Algorithms?**\n",
            "\n",
            "1.  **Stopping Criterion:** This is their primary practical use. Instead of running an algorithm until it converges to machine precision (which can take forever), you set a tolerance (e.g., \\( \\epsilon = 10^{-6} \\)). You stop the algorithm when the duality gap (or the difference between your upper and lower bounds) falls below this tolerance. **This gives you a computable guarantee of solution quality.**\n",
            "2.  **Convergence Monitoring:** They allow you to monitor the progress of an algorithm. You can see if it's stalling or making steady progress towards the optimum.\n",
            "3.  **Performance Guarantees:** Many algorithms have theoretical proofs that show their solution bounds shrink at a specific rate (e.g., \\( O(1/k) \\) or \\( O(1/k^2) \\)), where \\( k \\) is the iteration number. This tells you how long you can expect to wait for a solution of a desired accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Bounds as Constraints (Variable Bounds)\n",
            "\n",
            "This refers to simple constraints on the variables themselves, like \\( l_i \\leq x_i \\leq u_i \\). In a standard form problem, these are a specific type of constraint.\n",
            "\n",
            "#### **Why are Constraint Bounds Important for Algorithms?**\n",
            "\n",
            "1.  **Define the Feasible Set:** They explicitly describe the region within which the algorithm must search for a solution. In convex optimization, the feasible set defined by bounds is a convex set (a box).\n",
            "2.  **Algorithmic Simplification:**\n",
            "    *   **Projection:** Algorithms like the projected gradient method require projecting an intermediate point back onto the feasible set. Projecting onto a box (defined by bounds) is computationally trivial and very fast.\n",
            "    *   **Active Set Methods:** Algorithms can track which bounds are \"active\" (i.e., \\( x_i = l_i \\) or \\( x_i = u_i \\)) at the solution, which simplifies the problem.\n",
            "3.  **Problem Regularization:** Bounds can serve as a form of regularization. For example, imposing \\( x \\geq 0 \\) can ensure a solution has a physical meaning (e.g., quantities, probabilities). A bound like \\( \\|x\\| \\leq t \\) is at the core of Lasso regression, which promotes sparsity.\n",
            "\n",
            "---\n",
            "\n",
            "### Summary and Analogy\n",
            "\n",
            "Think of it like searching for the lowest point in a large, smooth valley (the convex problem).\n",
            "\n",
            "*   **Solution Bounds (Optimality):** You have a GPS that tells you, \"The lowest point is between 50 meters and 52 meters below sea level.\" The gap is 2 meters. As you walk, this range narrows. You stop when the gap is small enough (e.g., 0.1 meters), giving you confidence in your location's elevation, even if you haven't found the *exact* lowest point.\n",
            "*   **Constraint Bounds (Variables):** These are the fences around the valley. They prevent you from wandering into the surrounding mountains (infeasible regions) and keep your search focused in the right area.\n",
            "\n",
            "In conclusion, **bounds are crucial because they transform convex optimization from a theoretical concept into a practical tool.** They provide the stopping criteria, performance guarantees, and problem structure that allow us to reliably and efficiently find high-quality solutions to complex problems.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course! That's an excellent question that gets to the heart of the field. The phrase \"a convex optimization problem from convex optimization\" is a bit redundant but perfectly understandable. It simply means the standard, formal definition of a **Convex Optimization Problem**.\n",
            "\n",
            "Let's break it down.\n",
            "\n",
            "### The Core Idea\n",
            "\n",
            "A convex optimization problem is a special class of mathematical problems where you are trying to find the *minimum* of a **convex function** over a **convex set**.\n",
            "\n",
            "The reason these problems are so important is that if you find a local minimum, you are guaranteed that it is also the **global minimum**. This is a huge advantage over non-convex problems, where you can get \"stuck\" in a local solution that is far from the best possible one.\n",
            "\n",
            "---\n",
            "\n",
            "### The Formal Definition\n",
            "\n",
            "A problem is a convex optimization problem if it can be written in the following **standard form**:\n",
            "\n",
            "**Minimize:** \\( f_0(x) \\)\n",
            "**Subject to:** \\( f_i(x) \\leq 0, \\quad i = 1, \\dots, m \\)\n",
            "            \\( a_j^T x = b_j, \\quad j = 1, \\dots, p \\)\n",
            "\n",
            "Where:\n",
            "\n",
            "1.  **\\( x \\)** is the **optimization variable** (a vector in \\( \\mathbb{R}^n \\)).\n",
            "2.  **\\( f_0(x) \\)** is the **objective function**, and it must be a **convex function**.\n",
            "3.  **\\( f_i(x) \\)** are the **inequality constraint functions**, and each must be a **convex function**.\n",
            "4.  **\\( a_j^T x = b_j \\)** are the **equality constraints**, and they must be **affine** (i.e., linear plus a constant).\n",
            "\n",
            "The set of points \\( x \\) that satisfy all the constraints is called the **feasible set**. Because the inequality constraints are convex and the equality constraints are affine, the feasible set is guaranteed to be a **convex set**.\n",
            "\n",
            "### Key Concepts Explained Simply\n",
            "\n",
            "**What is a Convex Function?**\n",
            "Intuitively, a function is convex if the line segment between any two points on its graph lies *above* or on the graph. Think of a \"bowl\" shape (e.g., \\( f(x) = x^2 \\)).\n",
            "*   **Simple Test:** If the second derivative is always non-negative (for a scalar function), it's convex.\n",
            "*   **Examples:** \\( x^2 \\), \\( e^x \\), \\( |x| \\), \\( -\\log(x) \\).\n",
            "\n",
            "**What is a Convex Set?**\n",
            "A set is convex if, for any two points in the set, the entire line segment connecting them is also inside the set. Think of a solid circle, a square, or a hyperplane.\n",
            "*   **Non-Examples:** A star shape or a crescent moon are non-convex sets.\n",
            "\n",
            "### Why is Convexity So Powerful?\n",
            "\n",
            "1.  **Global Optimality:** Any local minimum is a global minimum. This means that if your algorithm finds a solution where it can't improve by moving a tiny bit in any direction, you are done—you have found the best possible solution.\n",
            "2.  **Efficient Algorithms:** Because of this nice property, we can design very efficient and reliable algorithms to solve large-scale convex problems. These algorithms are not just guesses; they come with guarantees on how quickly they will converge to the solution.\n",
            "3.  **Widespread Applicability:** A vast number of real-world problems in engineering, machine learning, finance, and operations research can be formulated as convex optimization problems.\n",
            "\n",
            "---\n",
            "\n",
            "### Example: A Simple Convex Problem\n",
            "\n",
            "**Problem:** Find the point on the line \\( y = 2x + 1 \\) that is closest to the origin (0, 0).\n",
            "\n",
            "**Formulation:**\n",
            "*   **Variables:** \\( x, y \\)\n",
            "*   **Objective Function:** Minimize the *squared* distance to the origin: \\( x^2 + y^2 \\). (This is convex—it's a paraboloid).\n",
            "*   **Equality Constraint:** \\( y = 2x + 1 \\) (This is affine).\n",
            "*   **Inequality Constraints:** None.\n",
            "\n",
            "This fits the standard form perfectly. The objective is convex, and the only constraint is affine, so the feasible set (the line) is convex. We can solve this and be guaranteed we've found the true closest point.\n",
            "\n",
            "### Contrast with a Non-Convex Problem\n",
            "\n",
            "**Problem:** Find the lowest point in a mountain range with many peaks and valleys.\n",
            "\n",
            "*   **Why it's non-convex:** The \"objective function\" (the height of the land) is not convex. It has many local minima (valleys). If you start your search in one valley and find its bottom, it might be much higher than the lowest valley in the entire range.\n",
            "\n",
            "### Summary\n",
            "\n",
            "| Feature | Convex Optimization Problem | Non-Convex Optimization Problem |\n",
            "| :--- | :--- | :--- |\n",
            "| **Objective Function** | Convex (bowl-shaped) | Non-convex (hilly, wavy) |\n",
            "| **Feasible Set** | Convex Set | Can be any shape |\n",
            "| **Solution** | **Any local minimum is the global minimum.** Guaranteed! | Many local minima. Finding the global minimum is very hard. |\n",
            "| **Solvability** | Efficient, reliable algorithms exist (e.g., Gradient Descent, Interior-Point Methods). | Often requires heuristic methods (e.g., Genetic Algorithms, Simulated Annealing) with no optimality guarantee. |\n",
            "\n",
            "So, when someone asks for \"a convex optimization problem from convex optimization,\" they are asking for a problem that fits this specific, powerful, and well-studied mathematical framework.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. While convex optimization is often considered a \"solved problem\" in theory (thanks to strong duality and polynomial-time algorithms), the field is incredibly vibrant with numerous deep and challenging open problems. Researchers are pushing the boundaries in theory, algorithms, and applications.\n",
            "\n",
            "Here are some of the most significant open problems that researchers are currently working on, categorized for clarity.\n",
            "\n",
            "### I. Foundational & Theoretical Open Problems\n",
            "\n",
            "These problems concern the fundamental limits and our theoretical understanding of convex optimization.\n",
            "\n",
            "1.  **The Polynomial-Time Complexity of Linear Programming:**\n",
            "    *   **The Problem:** We know that Linear Programming (LP) is in P (solvable in polynomial time) thanks to interior-point methods. However, is there a *strongly* polynomial-time algorithm for LP?\n",
            "    *   **Why it's Open:** A strongly polynomial algorithm's number of steps is polynomial in the number of variables and constraints, *independent of the bit-length of the input numbers*. We have such algorithms for special cases (e.g., two-variable problems, network flows), but not for the general case. This is one of Steve Smale's 18 unsolved problems of the 21st century.\n",
            "\n",
            "2.  **Optimal First-Order Methods for Non-Euclidean Spaces:**\n",
            "    *   **The Problem:** For smooth convex optimization in Euclidean space, Nesterov's Accelerated Gradient Descent is optimal. However, for non-Euclidean geometries (e.g., using Bregman divergences for problems with simplex constraints), the optimal convergence rates and the algorithms that achieve them are not fully known.\n",
            "    *   **Why it's Open:** The analysis becomes much more complex, and the \"momentum\" techniques used in Euclidean spaces don't always translate directly.\n",
            "\n",
            "3.  **Universal Methods and Parameter-Free Methods:**\n",
            "    *   **The Problem:** Can we design a single algorithm that automatically adapts to the problem's hidden structure (e.g., smoothness, strong convexity) without needing the user to specify parameters like the step-size or Lipschitz constant?\n",
            "    *   **Current Status:** There has been significant progress (e.g., adaptive methods, coin-betting algorithms), but a truly \"universal\" and practically efficient method remains elusive. The goal is to achieve optimal rates without any prior knowledge.\n",
            "\n",
            "### II. Algorithmic & Computational Challenges\n",
            "\n",
            "These problems focus on making convex optimization faster, more scalable, and more robust for modern applications.\n",
            "\n",
            "1.  **Scalability for Extremely Large-Scale Problems:**\n",
            "    *   **The Problem:** While first-order methods (like SGD) scale well, they can be slow to converge to high accuracy. Second-order methods (like Newton's method) are fast but don't scale to problems with millions of variables and constraints due to the cost of handling the Hessian matrix.\n",
            "    *   **Research Directions:**\n",
            "        *   **Randomized Linear Algebra:** Using sketching and sampling to approximate Newton steps.\n",
            "        *   **Federated Optimization:** Designing algorithms for data partitioned across thousands of devices with communication bottlenecks.\n",
            "        *   **Quasi-Newton Methods for Huge Dimensions:** Developing limited-memory BFGS and SR1 methods that are effective in stochastic and non-convex settings.\n",
            "\n",
            "2.  **Bridging the Gap Between Theory and Practice for Stochastic Methods:**\n",
            "    *   **The Problem:** In theory, Stochastic Gradient Descent (SGD) has sub-optimal convergence rates for smooth, non-strongly convex problems. In practice, variants like SGD with momentum or Adam often work much better than the theory suggests.\n",
            "    *   **Why it's Open:** A complete theoretical explanation for the success of heuristics like momentum and adaptive learning rates in SGD is still missing. Reconciling the practical performance with tight convergence guarantees is a major effort.\n",
            "\n",
            "3.  **Robustness to Numerical Errors and Non-Asymptotic Analysis:**\n",
            "    *   **The Problem:** Finite-precision arithmetic can cause algorithms to fail, especially those that rely on strict assumptions (like the Lanczos method in semidefinite programming). Providing non-asymptotic, robust convergence guarantees that account for numerical errors is very challenging.\n",
            "\n",
            "### III. Open Problems at the Interface with Other Fields\n",
            "\n",
            "Many of the most exciting problems arise when convex optimization is applied to new domains.\n",
            "\n",
            "1.  **Convex Relaxations for Non-Convex Problems:**\n",
            "    *   **The Problem:** Many fundamental problems in statistics (sparse recovery), machine learning (training neural nets), and engineering are non-convex. A common approach is to solve a convex relaxation (e.g., L1-norm for sparsity, nuclear norm for low-rank).\n",
            "    *   **Open Questions:**\n",
            "        *   When do these relaxations exactly recover the solution to the original non-convex problem?\n",
            "        *   Can we design tighter convex relaxations?\n",
            "        *   What are the fundamental statistical limits of these methods? (This intersects with information theory).\n",
            "\n",
            "2.  **Optimization for Distributed and Federated Learning:**\n",
            "    *   **The Problem:** How do we design efficient algorithms when data is distributed across many devices (phones, hospitals) and cannot be centralized due to privacy or bandwidth constraints?\n",
            "    *   **Challenges:** Communication efficiency, handling straggler devices, ensuring differential privacy, and dealing with non-IID data across devices.\n",
            "\n",
            "3.  **Convex Optimization in Private and Fair ML:**\n",
            "    *   **The Problem:** How can we solve convex optimization problems under strict differential privacy constraints without destroying utility? Similarly, how can we solve problems with non-convex fairness constraints (e.g., demographic parity) via convex surrogates or reformulations?\n",
            "    *   **Why it's Open:** Adding privacy (e.g., noise) or fairness constraints often breaks the standard assumptions of convex optimization, requiring new algorithmic and theoretical frameworks.\n",
            "\n",
            "4.  **Convex Optimization in Continuous Time and Control:**\n",
            "    *   **The Problem:** There is a deep connection between ODEs and optimization algorithms (e.g., Nesterov's acceleration can be derived from a damped oscillator ODE). Can we use insights from control theory and Lyapunov functions to design better, more stable discrete-time algorithms?\n",
            "\n",
            "### Summary\n",
            "\n",
            "The field of convex optimization is far from closed. The current thrust is moving beyond the \"classical\" theory to tackle the challenges of the modern computational landscape: **enormous scale, distribution, privacy, and the need for robust, parameter-free, and adaptive algorithms.** The most exciting progress often happens at the interface with machine learning, statistics, and computer science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V3.1"
      ],
      "metadata": {
        "id": "ytk2XklEJCbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please install OpenAI SDK first: `pip3 install openai`\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = userdata.get('DEEPSEEK_API_KEY'),\n",
        "    base_url=\"https://api.deepseek.com/v3.1_terminus_expires_on_20251015\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"deepseek-chat\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
        "    ],\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "print(f\"Model is: {response.model}\")\n",
        "print(f\"Output is: {response.choices[0].message.content}\")"
      ],
      "metadata": {
        "id": "cD0yaYW_LILa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and print the assistant's reply\n",
        "assistant_replyQ0 = deepseek_inference(Q0, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ1 = deepseek_inference(Q1, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ2 = deepseek_inference(Q2, \"deepseek-reasoner\")[\"answer\"]\n",
        "assistant_replyQ3 = deepseek_inference(Q3, \"deepseek-reasoner\")[\"answer\"]"
      ],
      "metadata": {
        "id": "28cozttIDsRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Assistant:\", assistant_replyQ0)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ1)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ2)\n",
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBGVwrh9BjbV",
        "outputId": "ed16e309-001c-4892-c2c8-ed9dbf7ab196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: Of course! Let's break down convex optimization in simple terms.\n",
            "\n",
            "### The Short Answer (The Elevator Pitch)\n",
            "\n",
            "Imagine you're in a smooth, bowl-shaped valley. Your goal is to find the lowest point. No matter where you stand, if you just keep walking downhill, you will eventually and reliably reach the very bottom.\n",
            "\n",
            "**Convex optimization** is the math and set of tools for efficiently finding the \"lowest point\" (the optimal solution) in problems that resemble this \"bowl-shaped\" valley. The key is that there are no hidden dips or local traps—just one clear, global best answer.\n",
            "\n",
            "---\n",
            "\n",
            "### The Core Idea: The \"Bowl-Shaped\" Property\n",
            "\n",
            "The word **\"convex\"** describes a specific shape. A function is convex if the line segment between any two points on its graph lies *above* the graph itself. This creates that classic \"bowl\" shape.\n",
            "\n",
            "*   **Convex Problem (A Bowl):** One clear minimum. You can always find the bottom.\n",
            "*   **Non-Convex Problem (A Mountain Range):** Many hills and valleys (local minima). You might find a low point, but there's no guarantee it's the *lowest* point on Earth.\n",
            "\n",
            "Convex optimization only deals with the first type: the bowls. This restriction is its superpower because it makes the problems solvable in a efficient and reliable way.\n",
            "\n",
            "---\n",
            "\n",
            "### What Kind of Problems Does It Solve? (The \"What For\")\n",
            "\n",
            "Convex optimization is used to solve problems where you want to minimize or maximize something (an **objective function**) while satisfying a set of **constraints**, and the whole problem has that \"bowl-shaped\" property.\n",
            "\n",
            "Here are some common types of problems it's brilliant at solving:\n",
            "\n",
            "**1. Resource Allocation & Planning**\n",
            "*   **Problem:** \"How do I distribute my limited resources (money, time, materials) to maximize profit or minimize cost?\"\n",
            "*   **Example:** A shipping company figuring out the most fuel-efficient routes for its entire fleet of trucks and planes.\n",
            "\n",
            "**2. Portfolio Optimization (Finance)**\n",
            "*   **Problem:** \"Given a set of stocks, what is the optimal mix to maximize my expected return while keeping the risk (volatility) below a certain level?\"\n",
            "*   **This is a classic use case and a huge reason convex optimization is so important in finance.**\n",
            "\n",
            "**3. Machine Learning & Data Fitting**\n",
            "*   **Problem:** \"I have a bunch of data points. What is the best straight line (or curve) that fits this data?\"\n",
            "*   **Example:** **Linear Regression** and **Logistic Regression**, two fundamental ML techniques, are solved using convex optimization. The algorithm finds the line that minimizes the total error (the \"cost function\").\n",
            "\n",
            "**4. Engineering Design**\n",
            "*   **Problem:** \"Design a structure that uses the least amount of material while still being strong enough to handle specific loads.\"\n",
            "*   **Example:** Designing a bridge truss or an aircraft wing that is both light and sturdy.\n",
            "\n",
            "**5. Signal Processing**\n",
            "*   **Problem:** \"How can I remove noise from a signal (like audio or an image) while preserving the important details?\"\n",
            "*   **Example:** The algorithms that clean up blurry images or suppress background static in audio recordings often use convex optimization.\n",
            "\n",
            "### A Simple Analogy: The Netflix Prize\n",
            "\n",
            "A famous example was the **Netflix Prize** (2006-2009), where teams competed to improve Netflix's movie recommendation algorithm by 10%.\n",
            "\n",
            "*   **The Bowl:** The \"error\" between what rating the algorithm predicted and what users actually rated.\n",
            "*   **The Goal:** Find the absolute bottom of that error bowl (the lowest possible prediction error).\n",
            "*   **The Tool:** The winning teams used sophisticated versions of... you guessed it, convex optimization, to \"walk downhill\" and find that best possible solution.\n",
            "\n",
            "### Why is it so powerful?\n",
            "\n",
            "1.  **Efficiency:** For convex problems, we have incredibly fast and reliable algorithms that can find the optimal solution even for problems with millions of variables.\n",
            "2.  **Global Optimality:** It doesn't get stuck in \"good enough\" solutions. It finds the *best* one.\n",
            "3.  **Reliability:** You get a certificate of optimality. The algorithms can *prove* that the solution they found is indeed the best possible one.\n",
            "\n",
            "**In a nutshell:** Convex optimization is the toolkit for finding the best possible outcome in a complex system, but only for the special class of problems that are \"well-behaved\" like a bowl, where \"downhill\" always leads to the true answer. It's a cornerstone of modern engineering, data science, and economics.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. This is an excellent question that gets to the heart of why convex optimization is so powerful and widely used.\n",
            "\n",
            "In convex optimization, the term \"**bounds**\" can refer to two distinct but equally important concepts:\n",
            "\n",
            "1.  **Constraint Bounds:** The limits that define the feasible region of the problem.\n",
            "2.  **Convergence Bounds:** Theoretical guarantees on the performance and speed of an algorithm.\n",
            "\n",
            "Let's break down each type and their importance.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Constraint Bounds (The Feasible Set)\n",
            "\n",
            "These are the most literal \"bounds.\" In an optimization problem, we aim to minimize a convex objective function $f_0(x)$ subject to certain conditions. These conditions are the **constraints**, and they often take the form of bounds.\n",
            "\n",
            "*   **Inequality Constraints:** $f_i(x) \\leq b_i$\n",
            "    *   Here, $b_i$ is a scalar **upper bound** for the function $f_i(x)$. For example, $x_1 + 2x_2 \\leq 10$ defines a half-space. The value `10` is the bound.\n",
            "*   **Box Constraints:** $l_i \\leq x_i \\leq u_i$\n",
            "    *   These are direct, simple bounds on the variables themselves. For example, $0 \\leq x_3 \\leq 5$ means the variable $x_3$ must lie between the **lower bound** `0` and the **upper bound** `5`.\n",
            "\n",
            "**Why are they important?**\n",
            "\n",
            "*   **Define the Problem:** The bounds, along with other constraints, literally define what a valid solution is. An algorithm must find a point that minimizes the objective function *while staying within these bounds*. Without bounds, the solution might be nonsensical (e.g., recommending negative resources, exceeding physical limits like 110% capacity).\n",
            "*   **Make Problems Tractable:** Many real-world problems are unbounded and have infinite solutions. Bounds restrict the search to a finite, feasible region, making the problem solvable.\n",
            "*   **Specialized Algorithms:** The presence of simple bounds (like box constraints) allows algorithms to use specialized, more efficient steps (e.g., projected gradient descent) to handle them directly, leading to faster convergence.\n",
            "\n",
            "**Example:** In a portfolio optimization problem, you might have:\n",
            "*   **Objective function:** Minimize risk (variance).\n",
            "*   **Constraint bound 1:** Expected return must be *at least* 8% ($\\geq 0.08$).\n",
            "*   **Constraint bound 2:** No single asset can be more than 15% of the portfolio ($\\leq 0.15$).\n",
            "*   **Box constraints:** All allocations must be between 0% and 100% ($0 \\leq x_i \\leq 1$).\n",
            "\n",
            "These bounds ensure the solution is both profitable, diversified, and practical.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Convergence Bounds (Algorithm Performance)\n",
            "\n",
            "This is a more theoretical but crucial meaning of \"bounds.\" For iterative algorithms (like Gradient Descent), a **convergence bound** is a mathematical guarantee that tells us how quickly the algorithm will approach the optimal solution.\n",
            "\n",
            "These bounds are usually expressed in terms of the number of iterations $k$ needed to achieve a certain accuracy $\\epsilon$.\n",
            "\n",
            "**Why are they incredibly important?**\n",
            "\n",
            "*   **Performance Prediction:** They tell us how long we can expect an algorithm to run. For a large-scale problem, knowing whether an algorithm will converge in 100 iterations or 1,000,000 iterations is critical for planning.\n",
            "*   **Algorithm Selection:** Different algorithms have different convergence bounds. Comparing these bounds allows us to choose the best algorithm for a problem.\n",
            "    *   **Example:** Gradient Descent has a convergence rate of $O(1/\\epsilon)$ for convex functions and $O(\\log(1/\\epsilon))$ for strongly convex functions. Newton's method can achieve $O(\\log\\log(1/\\epsilon))$ under the right conditions. This tells us Newton's method is *much faster* but also has more stringent requirements.\n",
            "*   **Stopping Criteria:** They provide a theoretical justification for when to stop the algorithm. If the bound guarantees that after $k$ iterations the solution is within $\\epsilon$ of the optimal value, we can use that to set a stopping rule.\n",
            "*   **Robustness and Reliability:** The existence of a proven convergence bound means the algorithm won't oscillate forever or diverge. It provides a guarantee that if you follow the steps, you *will* get arbitrarily close to the solution. This reliability is why convex optimization is trusted in safety-critical applications like aerospace or medical devices.\n",
            "\n",
            "**Example of a Convergence Bound:**\n",
            "For a convex function minimized using Gradient Descent, a common bound states that after $k$ iterations:\n",
            "$$ f(x^{(k)}) - f^* \\leq \\frac{C}{k} $$\n",
            "where $f^*$ is the optimal value and $C$ is a constant that depends on the function's smoothness and the initial distance to the optimum. This is a **sublinear** rate. This bound tells us that to cut the error in half, we need to do twice as many iterations.\n",
            "\n",
            "---\n",
            "\n",
            "### Summary: Key Takeaways\n",
            "\n",
            "| Type of Bound | What it is | Why it's Important |\n",
            "| :--- | :--- | :--- |\n",
            "| **Constraint Bounds** | The limits (e.g., $l_i \\leq x_i \\leq u_i$) that define the set of allowed solutions. | Defines a practical, solvable problem. Ensures solutions are realistic and valid. |\n",
            "| **Convergence Bounds** | Theoretical guarantees on an algorithm's performance (e.g., $f(x^{(k)}) - f^* \\leq O(1/k)$). | Predicts algorithm speed. Allows for comparison and selection of algorithms. Provides reliability guarantees. |\n",
            "\n",
            "In short, **constraint bounds** shape the problem itself, while **convergence bounds** give us confidence in the algorithms we use to solve it. The interplay between these two concepts is a fundamental reason why convex optimization is such a powerful and well-understood framework.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. This is an excellent question that gets to the heart of why convex optimization is such a powerful and widely used field.\n",
            "\n",
            "The phrase \"a convex optimization problem from convex optimization\" is a bit redundant but perfectly understandable. It simply means **a standard optimization problem that meets the specific mathematical criteria to be classified as \"convex.\"**\n",
            "\n",
            "Let's break it down.\n",
            "\n",
            "### 1. The Core Idea: What Makes a Problem \"Convex\"?\n",
            "\n",
            "Imagine you're in a smooth, bowl-shaped valley. No matter where you stand, if you take a step downhill, you'll eventually reach the very bottom—the lowest point. There's only one bottom, and there are no hidden pits or bumps to get stuck in.\n",
            "\n",
            "A **convex optimization problem** is the mathematical equivalent of this bowl-shaped valley. Its \"terrain\" has three key properties that make finding the best solution (the \"bottom\") efficient and reliable:\n",
            "\n",
            "1.  **A Convex Objective Function:** The function you want to minimize must be \"bowl-shaped.\" If you draw a line between any two points on the function, the line lies above the curve.\n",
            "2.  **A Convex Feasible Set:** The set of points that satisfy your constraints must also be \"shaped\" like a convex set. If you take any two points that are valid solutions, the entire line segment connecting them is also a valid solution. Common constraints that create convex sets are linear equalities/inequalities (`Ax = b`, `Ax ≤ b`).\n",
            "3.  **The Standard Form**\n",
            "\n",
            "A convex optimization problem is typically written in the following standard form:\n",
            "\n",
            "**Minimize:** `f₀(x)`\n",
            "**Subject to:** `fᵢ(x) ≤ 0,`   `i = 1, ..., m`  *(Inequality constraints)*\n",
            "                 `aⱼᵀx = bⱼ,`   `j = 1, ..., p`  *(Equality constraints)*\n",
            "\n",
            "Where:\n",
            "*   `x ∈ Rⁿ` is the **optimization variable** (the \"where am I?\" in the valley).\n",
            "*   `f₀: Rⁿ → R` is the **objective function** we want to minimize (e.g., cost, error). It must be **convex**.\n",
            "*   `fᵢ: Rⁿ → R`, `i = 1, ..., m` are the **inequality constraint functions**. They must also be **convex**.\n",
            "*   `aⱼᵀx = bⱼ`, `j = 1, ..., p` are the **affine (linear) equality constraints**.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Key Properties and Why They Are So Important\n",
            "\n",
            "The reason convex optimization is a massive subfield of applied mathematics is that these problems have two incredibly desirable properties:\n",
            "\n",
            "1.  **Any Local Minimum is a Global Minimum**\n",
            "    This is the most important consequence. In our valley analogy, if you find a point where every direction leads uphill, you are *guaranteed* to be at the very bottom of the entire valley. You don't have to worry about finding a better solution somewhere else. This is **not true** for non-convex problems, which can have many \"local minima\" (like bumps in a complex landscape) where algorithms can get stuck.\n",
            "\n",
            "2.  **Efficiently Solvable**\n",
            "    Because of their nice structure, we have very powerful and reliable algorithms to solve large-scale convex optimization problems. These algorithms can often find the global optimum very quickly, even for problems with thousands of variables and constraints.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Simple Examples\n",
            "\n",
            "**Example 1: A Very Simple Convex Problem (Linear Programming)**\n",
            "*   **Minimize:** `2x + y`\n",
            "*   **Subject to:** `x + y ≥ 1`\n",
            "                 `x ≥ 0, y ≥ 0`\n",
            "\n",
            "*   **Why it's convex:** The objective and constraints are all linear. Linear functions are both convex and concave, so this easily fits the form. The feasible set is a polygon, which is a convex set.\n",
            "\n",
            "**Example 2: A Classic Convex Problem (Quadratic Programming)**\n",
            "*   **Minimize:** `(x - 5)² + (y - 3)²`  (This is the squared Euclidean distance)\n",
            "*   **Subject to:** `x + y ≤ 10`\n",
            "                 `x ≥ 0, y ≥ 0`\n",
            "\n",
            "*   **Why it's convex:** The objective function is a sum of squares, which is a **convex** function (it's a \"bowl\" shape). The constraints are linear, which define a convex feasible set. You are finding the point within a polyhedron that is closest to the point `(5, 3)`.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. Contrast with a Non-Convex Problem\n",
            "\n",
            "To understand convexity, it helps to see a non-convex problem:\n",
            "\n",
            "*   **Minimize:** `sin(x) + 0.1*x²` for `-10 ≤ x ≤ 10`\n",
            "\n",
            "*   **Why it's non-convex:** The `sin(x)` function is wavy. This \"landscape\" has multiple valleys (local minima) and hills (local maxima). An algorithm starting at `x = -8` might find a low point, but it wouldn't be the *lowest possible point* (the global minimum), which is elsewhere. This makes the problem much harder to solve.\n",
            "\n",
            "### Summary\n",
            "\n",
            "In short, a **convex optimization problem** is an optimization problem where:\n",
            "*   The objective function is convex (bowl-shaped).\n",
            "*   The inequality constraint functions are convex.\n",
            "*   The equality constraints are linear.\n",
            "\n",
            "This specific structure guarantees that any solution found is the best possible one (global optimum) and that we can find it efficiently using well-established algorithms. This is why it's a cornerstone of fields like machine learning, signal processing, finance, and automatic control systems.\n",
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. Convex optimization is a mature field with powerful theoretical foundations and algorithms. However, significant open problems remain, driving current research. These problems often lie at the boundaries of theory, computation, and application.\n",
            "\n",
            "Here are some of the key open problems that researchers are actively working on, categorized for clarity:\n",
            "\n",
            "### 1. Foundational and Theoretical Problems\n",
            "\n",
            "*   **The Universal Barrier Function:** Nesterov and Nemirovskii's seminal work showed that for any convex set, there exists a *self-concordant barrier function* necessary for interior-point methods. They also constructed a \"universal barrier\" that works for any convex set, but it is non-computable in general.\n",
            "    *   **Open Problem:** Find a *computable*, efficient universal barrier function for general convex sets. A solution would allow for efficient solvers for a vastly wider range of problems.\n",
            "\n",
            "*   **The Polynomial Hirsch Conjecture:** This is a fundamental problem in linear programming (a subset of convex optimization) concerning the diameter of polyhedra. The conjecture posits that the diameter of the graph of a d-dimensional polyhedron defined by n inequalities is bounded by a polynomial in n and d.\n",
            "    *   **Why it matters:** A proof (or disproof) would have profound implications for the theoretical complexity of the simplex method, the most famous LP algorithm. It remains one of the biggest open questions in discrete geometry and optimization.\n",
            "\n",
            "*   **Lower Bounds for First-Order Methods:** We have many efficient first-order algorithms (e.g., variants of gradient descent) with well-understood *upper bounds* on their convergence rates (e.g., O(1/ε) or O(1/√ε) for non-smooth problems).\n",
            "    *   **Open Problem:** For many problem classes, these upper bounds are known to be tight. However, for specific structured problems (e.g., those with composite objectives like f(x) + g(x) where g is simple), can we prove better *lower bounds*? Establishing that no algorithm in a certain class can do better than a specific rate is crucial for knowing when we have found the optimal algorithm.\n",
            "\n",
            "### 2. Algorithmic and Computational Problems\n",
            "\n",
            "*   **Nearly Linear-Time Solvers for Linear Programs:** While Interior Point Methods (IPMs) can solve LPs in polynomial time (e.g., ~O(n³) per iteration), their worst-case complexity, while polynomial, is still too high for massive-scale problems.\n",
            "    *   **Open Problem:** Develop an algorithm that solves sparse linear programs to high accuracy in *nearly linear time*, O(n^(1+o(1)) in the input size. Recent breakthroughs in Laplacian solvers and maximum flow have used graph theory to achieve this for special cases, but a general-purpose solver remains elusive.\n",
            "\n",
            "*   **Faster High-Order Methods:** Second-order methods (like Newton's method) offer superb convergence rates (quadratic) but have a high cost per iteration (O(n³) for computing and inverting the Hessian).\n",
            "    *   **Open Problem:** Can we design practical second-order methods that maintain super-linear convergence without the prohibitive O(n³) cost per iteration? Research on quasi-Newton methods (e.g., L-BFGS), subsampled Hessians, and Sketched Newton-Raphson are active areas trying to bridge this gap.\n",
            "\n",
            "*   **Structure-Aware Algorithms for Massive Problems:** Many modern problems (e.g., in machine learning) are not just large; they have specific *structure* (e.g., sparsity, hierarchical structure, graph-based structure).\n",
            "    *   **Open Problem:** How do we best exploit this known structure *algorithmically* to achieve faster convergence than general-purpose methods? This is less a single problem and more a vast research program.\n",
            "\n",
            "### 3. Problems at the Interface with Other Fields\n",
            "\n",
            "*   **Convex Optimization in Non-Euclidean Settings:** Most analysis is done in Euclidean space (ℓ₂ norm). However, many modern applications (e.g., on manifolds, in Wasserstein space for optimal transport) require analysis in non-Euclidean geometries.\n",
            "    *   **Open Problem:** Develop a unified theory of complexity and design efficient algorithms for convex optimization on Riemannian manifolds and other metric spaces.\n",
            "\n",
            "*   **Bridging Convex and Non-Convex Optimization:** Many high-dimensional problems in machine learning (e.g., training deep neural networks) are non-convex. Surprisingly, first-order methods often find good solutions.\n",
            "    *   **Open Problem:** Can we explain this success theoretically? A major line of research focuses on identifying *\"nice\" non-convex problems* that have properties like \"all local minima are global minima\" or \"strict saddle property,\" effectively making them tractable. Understanding the geometry of loss landscapes is key.\n",
            "\n",
            "*   **Private Convex Optimization:** In fields like statistics and machine learning, there is a huge demand to solve optimization problems (e.g., empirical risk minimization) on sensitive data while providing rigorous differential privacy guarantees.\n",
            "    *   **Open Problem:** What are the fundamental trade-offs between privacy, accuracy, and computational efficiency? For a given class of convex functions, what is the optimal algorithm (minimal error) under a fixed privacy budget? This area is full of open questions, especially for constrained optimization.\n",
            "\n",
            "*   **Robust and Distributionally Robust Convex Optimization:** Standard optimization assumes data follows a fixed, known distribution. Robust optimization minimizes the worst-case scenario over an uncertainty set.\n",
            "    *   **Open Problem (Distributionally Robust Optimization - DRO):** This is a middle ground. The goal is to optimize against a *worst-case distribution* within a \"distance\" ball around the empirical distribution. Open questions include: How do we choose the ambiguity set? How can we solve these problems efficiently, especially when the worst-case distribution is hard to characterize?\n",
            "\n",
            "### 4. The Matrix Scaling Problem\n",
            "\n",
            "This is a specific, famous problem that highlights the intersection of theory and algorithms:\n",
            "\n",
            "*   **Problem:** Given a non-negative n×n matrix A and target row/column sums r and c, find scaling factors (diagonal matrices D and E) such that the matrix B = D A E has the prescribed row and column sums (or confirm none exist).\n",
            "*   **Status:** This problem can be solved in *practice* very efficiently by the Sinkhorn-Knopp algorithm. It is also known to be solvable in *polynomial time* via interior-point methods for general convex programming.\n",
            "*   **Open Problem:** Is there a *strongly polynomial time algorithm* for matrix scaling? That is, an algorithm whose number of elementary operations is bounded by a polynomial in *n* (the matrix dimension) alone, independent of the actual values of the entries of A, r, and c. This is a longstanding open question.\n",
            "\n",
            "In summary, the frontier of convex optimization research has moved from establishing basic polynomial-time complexity to seeking **faster, more practical, and more specialized algorithms** and to **expanding the theoretical foundations** to handle modern challenges like privacy, robustness, and non-Euclidean geometry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q4=\"The recent buzz around AI in mathematics includes a speculative story about a large language model solving a complex convex optimization problem. Leaving aside the veracity of this specific anecdote, what is the current state of AI's contribution to high-level mathematics? Could an AI model, given an open problem, generate a novel proof that advances the field? Please explain the technical capabilities that would be required for such a feat, distinguishing between what current models can do (e.g., proof verification) and what they cannot (e.g., independent discovery).\""
      ],
      "metadata": {
        "id": "c-p4eFDoJ8TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_replyQ4 = deepseek_inference(Q4, \"deepseek-reasoner\")[\"answer\"]"
      ],
      "metadata": {
        "id": "okSnxlplKL5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n\\n')\n",
        "print(\"Assistant:\", assistant_replyQ4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMSEh1ygKRG2",
        "outputId": "268abfbe-b0fb-4f94-8a1d-72fb9a92f168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Assistant: Of course. This is an excellent and profound question that gets to the heart of both the hype and the genuine progress in AI for science.\n",
            "\n",
            "Let's break down the current state, the technical capabilities required for true discovery, and the gap between current models and that future goal.\n",
            "\n",
            "### The Current State: AI as a Powerful Assistant, Not a Solo Mathematician\n",
            "\n",
            "Today's AI, particularly large language models (LLMs) like GPT-4 and specialized tools like DeepMind's AlphaGeometry, are making significant but specific contributions to high-level mathematics. They are best viewed as **extraordinarily powerful assistants or tools** that are changing how mathematicians work, rather than as independent agents solving open problems on their own.\n",
            "\n",
            "**What Current Models *Can* Do (The \"Assistant\" Role):**\n",
            "\n",
            "1.  **Proof Verification and Formalization:** This is perhaps the most concrete and successful application. Systems like **Lean** (a proof assistant) are being combined with AI models.\n",
            "    *   **How it works:** A mathematician can write a proof in a semi-formal style. An AI model can be fine-tuned to translate this natural language math into a perfectly rigorous, machine-checkable code for Lean. This eliminates human error in the final proof step.\n",
            "    *   **Capability Required:** Pattern recognition, syntax translation, and understanding the logical structure of mathematical arguments. LLMs are very good at this within their training distribution.\n",
            "\n",
            "2.  **Proof Automation and Lemma Generation:** Within a formal system like Lean, AI can act as a powerful automated tactic generator.\n",
            "    *   **How it works:** The human mathematician states a goal (a theorem or a sub-goal lemma). The AI, trained on a vast corpus of existing proofs, suggests a sequence of steps (tactics) to achieve that goal. It can rapidly search through a space of possible inferences that would be tedious for a human.\n",
            "    *   **Example:** DeepMind's **FunSearch** used a large language model to generate *functions* in code that solved combinatorial problems, discovering improved algorithms for cap set and bin packing problems. It didn't write a prose proof, but it found novel constructive solutions.\n",
            "\n",
            "3.  **Identifying Patterns and Conjectures:** AI excels at finding hidden patterns in complex data.\n",
            "    *   **How it works:** By analyzing vast datasets of mathematical objects (e.g., graphs, knots, algebraic varieties), AI can detect statistical irregularities or suggest potential relationships that humans might miss. The mathematician then must take this \"guess\" and use their intuition to formulate a precise conjecture and prove it.\n",
            "    *   **Famous Example:** Researchers used AI to discover unexpected connections between certain algebraic invariants (Knot invariants) and hyperbolic geometry, leading to new conjectures.\n",
            "\n",
            "4.  **Literature Review and Analogy Finding:** An LLM can be a super-powered search engine for mathematical literature.\n",
            "    *   **How it works:** A mathematician can describe a problem, and the AI can find analogous problems, relevant theorems, or techniques from seemingly unrelated fields by understanding the deep semantic meaning of the query.\n",
            "\n",
            "---\n",
            "\n",
            "### The Grand Challenge: Independent Discovery of a Novel Proof\n",
            "\n",
            "Could an AI, given an open problem like the Riemann Hypothesis, generate a novel, groundbreaking proof? **Not with current technology.** This remains a long-term goal of Artificial General Intelligence (AGI).\n",
            "\n",
            "**Technical Capabilities Required for Independent Discovery:**\n",
            "\n",
            "The key missing ingredient is **deep, conceptual understanding and reasoning**, not just pattern matching. Here’s what would be needed:\n",
            "\n",
            "1.  **Causal and Abstract Reasoning:** Current LLMs are masters of correlation but struggle with causation. A groundbreaking proof often requires abandoning established avenues and inventing a completely new framework or connecting two distant fields of math. This requires reasoning about *why* something is true, not just that the symbols often appear together.\n",
            "    *   **Current Limitation:** An AI can suggest a next step that is statistically likely, but it cannot reason about the *semantic meaning* of that step in the context of a grand strategy.\n",
            "\n",
            "2.  **True Intentionality and Goal-Directed Exploration:** A mathematician has an intuition, a \"feel\" for the problem. They explore dead ends because they have a hunch, and they know when to abandon a path. This is a strategic, top-down process.\n",
            "    *   **Current Limitation:** AI exploration is largely bottom-up. It can brute-force search a space of proofs, but this space is astronomically large for any major problem. It lacks the guiding \"intuition\" or \"taste\" that a master mathematician possesses.\n",
            "\n",
            "3.  **Mathematical \"Creativity\":** This is the hardest part. Creativity in math often involves re-conceptualizing the problem itself—seeing it from a new angle. For example, Andrew Wiles's proof of Fermat's Last Theorem involved mapping the problem onto the entirely different domain of elliptic curves and modular forms.\n",
            "    *   **Current Limitation:** AI is not yet capable of this type of paradigm shift. It operates within the latent space of its training data. It can interpolate and combine existing concepts but struggles to create a fundamentally new one *with purpose*.\n",
            "\n",
            "4.  **Handling Infinite Abstraction:** Mathematics deals with infinite sets, perfect continua, and极限 (limits) that have no direct physical analog. An AI must reason about these abstractions on their own terms, not as mere proxies from its training data.\n",
            "\n",
            "---\n",
            "\n",
            "### Distinguishing the Present from the Future\n",
            "\n",
            "| Capability | Current State (\"Can Do\") | Future Requirement for Discovery (\"Cannot Yet Do\") |\n",
            "| :--- | :--- | :--- |\n",
            "| **Reasoning** | **Symbolic Manipulation & Pattern Matching.** Excels at next-step prediction within a known framework. | **Conceptual & Causal Reasoning.** Understanding the \"why\" and inventing new frameworks. |\n",
            "| **Strategy** | **Tactical.** Can execute a predefined search strategy or find a short-term goal. | **Strategic.** Formulating a high-level plan and adapting it creatively when faced with obstacles. |\n",
            "| **Discovery** | **Interpolation & Combination.** Can find new combinations of existing ideas and patterns within data. | **True Extrapolation & Creativity.** Generating radically new concepts and pathways not present in training data. |\n",
            "| **Role** | **Tool/Assistant.** Verifies, suggests, automates, and patterns matches. Incredibly valuable. | **Collaborator/Solo Researcher.** Possesses mathematical intuition and intentionality. |\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "The anecdote about an LLM solving a complex optimization problem is plausible only if the problem was framed in a way that played to the AI's strengths—e.g., generating code that implements a known algorithm or finding a numerical solution. It did not likely \"reason\" about convexity in the abstract sense a mathematician would.\n",
            "\n",
            "The current state of AI in mathematics is one of **transformative augmentation**. It is automating the tedious, error-prone parts of proof verification and exploration, freeing mathematicians to focus on high-level strategy and creativity. This is already leading to new discoveries, but in partnership with humans.\n",
            "\n",
            "The generation of a novel proof for a major open problem entirely independently **remains a benchmark for AGI**. It will require breakthroughs not just in scale, but in the fundamental architecture of these models, likely moving towards hybrid neuro-symbolic systems that combine pattern recognition with formal, rule-based reasoning and—crucially—a model of the world that understands cause and effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "from openai import OpenAI\n",
        "\n",
        "weave.init(\"deepseek_examples\")\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "\n",
        "@weave.op()\n",
        "def deepseek_inference(prompt: str, model: str, stream: bool = False):\n",
        "    if stream:\n",
        "        answer = \"\"\n",
        "        s = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"you are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            stream=True\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"=== streaming start ===\")\n",
        "        for chunk in s:\n",
        "            delta = chunk.choices[0].delta\n",
        "            if delta.content:\n",
        "                answer += delta.content\n",
        "                print(delta.content, end=\"\", flush=True)\n",
        "        print(\"\\n=== streaming done ===\")\n",
        "\n",
        "\n",
        "        # reasoning not available in streaming mode\n",
        "        return {\"model\": model, \"answer\": answer, \"reasoning\": None}\n",
        "\n",
        "\n",
        "    else:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"you are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        reasoning = getattr(response.choices[0].message, \"reasoning_content\", None)\n",
        "        final_answer = response.choices[0].message.content\n",
        "        return {\"model\": model, \"answer\": final_answer, \"reasoning\": reasoning}\n"
      ],
      "metadata": {
        "id": "ohyR-CKG7bct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = deepseek_inference(\"why is the sky blue?\", \"deepseek-reasoner\", stream=True)\n",
        "r2 = deepseek_inference(\"why is the sky blue?\", \"deepseek-chat\", stream=True)"
      ],
      "metadata": {
        "id": "S7ViQZuRA2mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n=== deepseek-reasoner finished ===\")\n",
        "    print(\"answer:\", r1[\"answer\"])\n",
        "    print(\"reasoning:\", r1[\"reasoning\"])\n",
        "\n",
        "    print('\\n\\n')\n",
        "\n",
        "    print(\"\\n=== deepseek-chat finished ===\")\n",
        "    print(\"answer:\", r2[\"answer\"])\n",
        "    print(\"reasoning:\", r2[\"reasoning\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8scVnI3T_znj",
        "outputId": "98647712-b613-47f7-9d0c-a5dbbeedcf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== deepseek-reasoner finished ===\n",
            "answer: Of course! That's a classic question with a fascinating scientific answer.\n",
            "\n",
            "The short answer is that the sky is blue because of how Earth's atmosphere scatters sunlight in all directions, and blue light is scattered more than other colors.\n",
            "\n",
            "Here’s a more detailed breakdown:\n",
            "\n",
            "### 1. Sunlight is a Mix of Colors\n",
            "Sunlight seems white, but it's actually a mixture of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet). Each color has a different wavelength and energy level.\n",
            "\n",
            "### 2. Earth's Atmosphere is Full of Particles\n",
            "Our atmosphere is filled with tiny molecules of gas (mostly nitrogen and oxygen), dust, water droplets, and other small particles.\n",
            "\n",
            "### 3. The Scattering Effect (Rayleigh Scattering)\n",
            "When sunlight enters the atmosphere, it collides with these tiny molecules and particles. This causes the light to be **scattered** in all directions.\n",
            "\n",
            "However, not all colors are scattered equally. **Shorter wavelengths of light** (blues and violets) are scattered much more efficiently by the small molecules in the atmosphere than **longer wavelengths** (oranges and reds).\n",
            "\n",
            "This phenomenon is named **Rayleigh Scattering** after the British physicist Lord Rayleigh, who first described it.\n",
            "\n",
            "### 4. Why Blue and Not Violet?\n",
            "This is a great follow-up question! Violet light has an even shorter wavelength than blue light and is scattered even more. So why isn't the sky violet?\n",
            "\n",
            "There are two main reasons:\n",
            "*   **Our Eyes:** The cones in our eyes are more sensitive to **blue** light than they are to violet light.\n",
            "*   **The Sun's Output:** The sun emits **more blue light** than violet light.\n",
            "\n",
            "The combination of these factors means our brains perceive the scattered light as a cool, azure blue rather than a violet-purple.\n",
            "\n",
            "---\n",
            "\n",
            "### The Same Physics Explains Red Sunsets\n",
            "\n",
            "This scattering process is also why sunsets and sunrises are red and orange.\n",
            "\n",
            "When the sun is low on the horizon, its light has to travel through a much thicker portion of the atmosphere to reach your eyes. All that extra air scatters the blue light away long before it can reach you. The longer wavelength red and orange light is scattered less, so it passes straight through to your eyes, giving the sun and the sky around it those brilliant warm colors.\n",
            "\n",
            "### A Quick Summary:\n",
            "\n",
            "| Time of Day | Light's Path | What Gets Scattered Away | What Reaches Your Eyes | Sky Color |\n",
            "| :--- | :--- | :--- | :--- | :--- |\n",
            "| **Midday** | Short through atmosphere | Blues & Violets (some) | **All colors**, but excess blue | **Blue** |\n",
            "| **Sunset/Sunrise** | Long through atmosphere | **Almost all Blues & Violets** | Mostly Reds & Oranges | **Red/Orange** |\n",
            "\n",
            "So, the blue sky is essentially a giant demonstration of physics happening over our heads every day\n",
            "reasoning: None\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "=== deepseek-chat finished ===\n",
            "answer: Of course! That's a classic and excellent question.\n",
            "\n",
            "The short answer is that the sky is blue because of the way Earth's atmosphere scatters sunlight.\n",
            "\n",
            "Here’s a more detailed breakdown of how it works:\n",
            "\n",
            "### 1. Sunlight is a Mix of Colors\n",
            "Even though it looks white, sunlight is actually composed of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet). Each of these colors has a different wavelength and energy level.\n",
            "\n",
            "### 2. Earth's Atmosphere is Full of Particles\n",
            "Our atmosphere is filled with tiny gas molecules (like nitrogen and oxygen), dust, and other microscopic particles.\n",
            "\n",
            "### 3. The Scattering of Light (Rayleigh Scattering)\n",
            "When sunlight enters our atmosphere, it collides with these tiny molecules. This process is called **Rayleigh Scattering**.\n",
            "\n",
            "The key principle is: **shorter wavelengths of light (blue and violet) are scattered much more efficiently by the molecules in the atmosphere than longer wavelengths (red and orange).**\n",
            "\n",
            "*   **Blue light** has a very short wavelength and high energy, so it gets bounced around and scattered in all directions by the air molecules, filling the entire sky.\n",
            "*   **Red light** has a longer wavelength and lower energy, so it tends to pass through the atmosphere more directly without being scattered as much.\n",
            "\n",
            "### 4. What We See\n",
            "When you look up at the sky on a clear day, you are seeing this scattered blue light coming from all directions. That's why the entire sky appears blue.\n",
            "\n",
            "---\n",
            "\n",
            "### Common Follow-Up Questions\n",
            "\n",
            "**Q: If violet light is scattered even more than blue light, why isn't the sky violet?**\n",
            "A: This is a great point! There are two main reasons:\n",
            "1.  The sun emits **more blue light** than violet light.\n",
            "2.  Our **eyes are more sensitive to blue light** than to violet light. The combination of these factors means our brains perceive the sky as blue, not violet.\n",
            "\n",
            "**Q: Why are sunrises and sunsets red and orange?**\n",
            "A: This is the same phenomenon, just from a different perspective. When the sun is low on the horizon, its light has to travel through a much thicker slice of the atmosphere to reach your eyes. All that extra air scatters the blue light away, leaving mostly the longer, red and orange wavelengths to travel straight to your eyes.\n",
            "\n",
            "**In a nutshell:** The sky is blue because air molecules in our atmosphere scatter blue light from the sun in all directions, making it the dominant color we see.\n",
            "reasoning: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import weave\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "\n",
        "weave.init(\"thinking-vs-nonthinking\")\n",
        "\n",
        "\n",
        "# DeepSeek client\n",
        "client = AsyncOpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "\n",
        "# dataset\n",
        "questions = [\n",
        "    {\"id\": \"0\", \"prompt\": \"What is 5 + 7?\", \"mode\": \"non-thinking\"},\n",
        "    {\"id\": \"1\", \"prompt\": \"Explain the significance of the number zero in mathematics.\", \"mode\": \"non-thinking\"},\n",
        "    {\"id\": \"2\", \"prompt\": \"Explain step by step how to solve 5 + 7, and then give the answer.\", \"mode\": \"thinking\"},\n",
        "    {\"id\": \"3\", \"prompt\": \"Explain the significance of the number zero in mathematics.\", \"mode\": \"thinking\"},\n",
        "]\n",
        "\n",
        "\n",
        "# model wrapper\n",
        "class DeepSeekModel(weave.Model):\n",
        "    model_name: str\n",
        "\n",
        "\n",
        "    @weave.op()\n",
        "    async def predict(self, prompt: str) -> dict:\n",
        "        resp = await client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"you are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "        answer = resp.choices[0].message.content\n",
        "        reasoning = getattr(resp.choices[0].message, \"reasoning_content\", None)\n",
        "        return {\"answer\": answer, \"reasoning\": reasoning}\n",
        "\n",
        "\n",
        "# trivial scorer\n",
        "@weave.op()\n",
        "def always_true(prompt: str, mode: str, output: dict) -> dict:\n",
        "    return {\"correct\": True}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# pick models: one thinking, one non-thinking\n",
        "nonthinking_model = DeepSeekModel(model_name=\"deepseek-chat\")\n",
        "thinking_model = DeepSeekModel(model_name=\"deepseek-reasoner\")\n",
        "\n",
        "\n",
        "# run eval with both\n",
        "evaluation = weave.Evaluation(\n",
        "    name=\"thinking-vs-nonthinking-eval\",\n",
        "    dataset=questions,\n",
        "    scorers=[always_true],\n",
        ")"
      ],
      "metadata": {
        "id": "nTRI9KI39WcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Non-thinking eval ===\")\n",
        "print(await evaluation.evaluate(nonthinking_model))\n",
        "\n",
        "print('\\n\\n')\n",
        "print(\"=== Thinking eval ===\")\n",
        "print(await evaluation.evaluate(thinking_model))"
      ],
      "metadata": {
        "id": "E4cgq6ddoZ2S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}