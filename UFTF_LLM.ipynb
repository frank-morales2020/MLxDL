{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "o-wuPGXVVq-m",
        "nznPRgHY8mFq"
      ],
      "authorship_tag": "ABX9TyOdpucqLhbwtU+RU/bbzrQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52f60aa0acf6484383a282710a9865c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abb72641a3447cebc187135e89c3bdd",
              "IPY_MODEL_4bc0885f011f4f55b50009451638243e",
              "IPY_MODEL_7e182502a5734ead8f46c92f33cdb0b2"
            ],
            "layout": "IPY_MODEL_902321570a754a16b27bc28afeb291c8"
          }
        },
        "0abb72641a3447cebc187135e89c3bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8688751f2a2749849402880ff9e99901",
            "placeholder": "​",
            "style": "IPY_MODEL_e3b8b79a5c3a40deb40aff5d362fd1df",
            "value": "config.json: 100%"
          }
        },
        "4bc0885f011f4f55b50009451638243e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7445749a05c14880b7d06b5e02a85192",
            "max": 1205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3825663f6ca94f07be352678df449d88",
            "value": 1205
          }
        },
        "7e182502a5734ead8f46c92f33cdb0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b846f862934aa6af9a7b2c55456254",
            "placeholder": "​",
            "style": "IPY_MODEL_d39f82b2881946f7999b5452b2c03a38",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 134kB/s]"
          }
        },
        "902321570a754a16b27bc28afeb291c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8688751f2a2749849402880ff9e99901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b8b79a5c3a40deb40aff5d362fd1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7445749a05c14880b7d06b5e02a85192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3825663f6ca94f07be352678df449d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86b846f862934aa6af9a7b2c55456254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39f82b2881946f7999b5452b2c03a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b10c874b6744f528e6c2c1d81e79936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac85140f880a448fb4565c1c8c2a26b7",
              "IPY_MODEL_ad82f2cc225748e1a4015edaf6c687ce",
              "IPY_MODEL_8068779ae5cf4bea9ccef6a5486558ad"
            ],
            "layout": "IPY_MODEL_251039d198bf4ecda3806ec82889c5da"
          }
        },
        "ac85140f880a448fb4565c1c8c2a26b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa721c3107e4dd19af28b4b80d63433",
            "placeholder": "​",
            "style": "IPY_MODEL_4bd98318bbbd4d55b034de4457759d88",
            "value": "model.safetensors: 100%"
          }
        },
        "ad82f2cc225748e1a4015edaf6c687ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33df69489da43a3b715bf73e71d1eb8",
            "max": 4138270819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3e722fa396344c7b00e4d708c37edf7",
            "value": 4138270819
          }
        },
        "8068779ae5cf4bea9ccef6a5486558ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_214d7b8ae93f4af295438e95463e30c2",
            "placeholder": "​",
            "style": "IPY_MODEL_a227aff5de3843a38efd8721cb0042b8",
            "value": " 4.14G/4.14G [00:18&lt;00:00, 225MB/s]"
          }
        },
        "251039d198bf4ecda3806ec82889c5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa721c3107e4dd19af28b4b80d63433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd98318bbbd4d55b034de4457759d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f33df69489da43a3b715bf73e71d1eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e722fa396344c7b00e4d708c37edf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "214d7b8ae93f4af295438e95463e30c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a227aff5de3843a38efd8721cb0042b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115b4ec93800471980b9b3de7753968a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efbe4ad58cfe47dcbf772b6ba4fc74e2",
              "IPY_MODEL_96199e7dd0df41fc87bbd6fafe89e9dd",
              "IPY_MODEL_319df48eb674405d96ff22432d110225"
            ],
            "layout": "IPY_MODEL_c2b85750f51a4e0cb0bd5fea80a02bdb"
          }
        },
        "efbe4ad58cfe47dcbf772b6ba4fc74e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f89371f769343ee87f3363a28390882",
            "placeholder": "​",
            "style": "IPY_MODEL_ae492b6a41334b3ca95b5bd1618d21f2",
            "value": "generation_config.json: 100%"
          }
        },
        "96199e7dd0df41fc87bbd6fafe89e9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092445eea777428db6841b4ee556b0fa",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da4533fb12d942098cc96fdf7a6612ce",
            "value": 157
          }
        },
        "319df48eb674405d96ff22432d110225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a652745ad74623864ba3903af70c2c",
            "placeholder": "​",
            "style": "IPY_MODEL_c5166250e4ed4dad96ed5a607bf6cc0c",
            "value": " 157/157 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "c2b85750f51a4e0cb0bd5fea80a02bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f89371f769343ee87f3363a28390882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae492b6a41334b3ca95b5bd1618d21f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "092445eea777428db6841b4ee556b0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da4533fb12d942098cc96fdf7a6612ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8a652745ad74623864ba3903af70c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5166250e4ed4dad96ed5a607bf6cc0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f05cdfcc5ce46cb9db5ec3d7b2b9fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a30f39f18ef43b9a9a86d6d44c5dbb2",
              "IPY_MODEL_337cbabbc3b64954aad7bc60d505a676",
              "IPY_MODEL_b5d79256812f430e8e4f574fd5be12b4"
            ],
            "layout": "IPY_MODEL_d6d808908f294be084a66ea5facdc3d4"
          }
        },
        "3a30f39f18ef43b9a9a86d6d44c5dbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb64257c5c994d5ebd643f9659353778",
            "placeholder": "​",
            "style": "IPY_MODEL_023133cbbabf4e07954298e73ac9d311",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "337cbabbc3b64954aad7bc60d505a676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4fc3de0ae8494eb4bd2b496d59c160",
            "max": 140911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34abe986d79e4ad49577be5623f2160b",
            "value": 140911
          }
        },
        "b5d79256812f430e8e4f574fd5be12b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f891d49f3cd54315bb96852e73472c26",
            "placeholder": "​",
            "style": "IPY_MODEL_1f40101ed06f424aba3535c8edf6aff4",
            "value": " 141k/141k [00:00&lt;00:00, 659kB/s]"
          }
        },
        "d6d808908f294be084a66ea5facdc3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb64257c5c994d5ebd643f9659353778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023133cbbabf4e07954298e73ac9d311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f4fc3de0ae8494eb4bd2b496d59c160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34abe986d79e4ad49577be5623f2160b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f891d49f3cd54315bb96852e73472c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f40101ed06f424aba3535c8edf6aff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d5fc61d05e4483787e1eeed9764da87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4bada63d12a4a129151f2886c9c4f48",
              "IPY_MODEL_71ef104c25df4630b92c3be3a9c258fd",
              "IPY_MODEL_873e59770b0d4fa0b17e102b0d00a691"
            ],
            "layout": "IPY_MODEL_41419597ff0243ceaf040c40e12a40e1"
          }
        },
        "b4bada63d12a4a129151f2886c9c4f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7324b60ad3ab415fb11c8817a3478ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_4559aefab0a8472f89bdfabb5f6d926f",
            "value": "tokenizer.model: 100%"
          }
        },
        "71ef104c25df4630b92c3be3a9c258fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_646b76dc6b1943729d88bbc222e73b0f",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97da478be4074ad9b43f257b887382d6",
            "value": 587404
          }
        },
        "873e59770b0d4fa0b17e102b0d00a691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d48581075c4b30befa3cc610a15303",
            "placeholder": "​",
            "style": "IPY_MODEL_509dbbaa2cdf4f47abb3acc0f261ce79",
            "value": " 587k/587k [00:00&lt;00:00, 59.9MB/s]"
          }
        },
        "41419597ff0243ceaf040c40e12a40e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7324b60ad3ab415fb11c8817a3478ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4559aefab0a8472f89bdfabb5f6d926f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "646b76dc6b1943729d88bbc222e73b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97da478be4074ad9b43f257b887382d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d48581075c4b30befa3cc610a15303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509dbbaa2cdf4f47abb3acc0f261ce79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3348f4fa63bd45919efb7de918480913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8dbdee27ebf4564931dc6ed49b77d6e",
              "IPY_MODEL_6002586ed29f491194f307dd232ff801",
              "IPY_MODEL_4397bad9556d48b885a5b3f2698844c8"
            ],
            "layout": "IPY_MODEL_5234ba242b22475f91d5ca3862fe5d8e"
          }
        },
        "e8dbdee27ebf4564931dc6ed49b77d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca4fb76803141ef9d8dae1762675719",
            "placeholder": "​",
            "style": "IPY_MODEL_c75c98031d1a450bb4a875dc7714860e",
            "value": "tokenizer.json: 100%"
          }
        },
        "6002586ed29f491194f307dd232ff801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3487a7344f7494ab122ac699c812179",
            "max": 1961548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ca5ee92ef149249f2cb5aea11c5e76",
            "value": 1961548
          }
        },
        "4397bad9556d48b885a5b3f2698844c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fdc972dc0c5416abd87812cf2696847",
            "placeholder": "​",
            "style": "IPY_MODEL_0b1ebee4d8374559a49bae4f89cc0e7c",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 2.29MB/s]"
          }
        },
        "5234ba242b22475f91d5ca3862fe5d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca4fb76803141ef9d8dae1762675719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75c98031d1a450bb4a875dc7714860e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3487a7344f7494ab122ac699c812179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ca5ee92ef149249f2cb5aea11c5e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fdc972dc0c5416abd87812cf2696847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1ebee4d8374559a49bae4f89cc0e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1877dea9734c4377a03062805fd7e023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c46999b8f1ce445fbc23f9d2db31b65e",
              "IPY_MODEL_eadf513710d540459f80a352e7f8602e",
              "IPY_MODEL_73203418ed004f91b7cefbf1b9ea912e"
            ],
            "layout": "IPY_MODEL_ad2e844aaf4c495f9dc1c97690e9354b"
          }
        },
        "c46999b8f1ce445fbc23f9d2db31b65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51872d63928446185dae86d4eed811c",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c3ad5e7fa74aafb65bc8535e1079ed",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "eadf513710d540459f80a352e7f8602e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea71a0f3cb04e84b9401b05909e02e9",
            "max": 446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67a2ef3e02e84356b3e4b7e08b594e45",
            "value": 446
          }
        },
        "73203418ed004f91b7cefbf1b9ea912e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa08a3b93e5341b0baf2a5689dce7380",
            "placeholder": "​",
            "style": "IPY_MODEL_be906df436114e6eaa65ad0e1f5eddeb",
            "value": " 446/446 [00:00&lt;00:00, 55.6kB/s]"
          }
        },
        "ad2e844aaf4c495f9dc1c97690e9354b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51872d63928446185dae86d4eed811c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c3ad5e7fa74aafb65bc8535e1079ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ea71a0f3cb04e84b9401b05909e02e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67a2ef3e02e84356b3e4b7e08b594e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa08a3b93e5341b0baf2a5689dce7380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be906df436114e6eaa65ad0e1f5eddeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dadc337a577c45c29565506943c28a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34715483900e403fbc5b57fe9d836385",
              "IPY_MODEL_2c183521d2f6491a83759d8974199fac",
              "IPY_MODEL_a0e65b270cf64cfab4aa50d22834c202"
            ],
            "layout": "IPY_MODEL_b416a7f2a9ab46479929328ba889ae36"
          }
        },
        "34715483900e403fbc5b57fe9d836385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db955a45657d4d80b88d0ccd284799be",
            "placeholder": "​",
            "style": "IPY_MODEL_52cfac5b9696462d9439e358de8126eb",
            "value": "Map: 100%"
          }
        },
        "2c183521d2f6491a83759d8974199fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc36cf6b5b9d4c13b79cc2eceaeb63e9",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81e8ecfb5f104dc8a6ef209bc9ee76a6",
            "value": 100
          }
        },
        "a0e65b270cf64cfab4aa50d22834c202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b0f284fb2b4a858ff6bb3d218f8d30",
            "placeholder": "​",
            "style": "IPY_MODEL_92a9330a62a445c0b22d82cf8d149571",
            "value": " 100/100 [00:00&lt;00:00, 1388.96 examples/s]"
          }
        },
        "b416a7f2a9ab46479929328ba889ae36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db955a45657d4d80b88d0ccd284799be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52cfac5b9696462d9439e358de8126eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc36cf6b5b9d4c13b79cc2eceaeb63e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e8ecfb5f104dc8a6ef209bc9ee76a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88b0f284fb2b4a858ff6bb3d218f8d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a9330a62a445c0b22d82cf8d149571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20c4cd4f18144654ab668c91bd24506e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b36a67ce04c7487badf515524e1b6bff",
              "IPY_MODEL_5cf1e9a684e7443db11cf06800e51eb6",
              "IPY_MODEL_c385087424d744f68825eb7801d04be2"
            ],
            "layout": "IPY_MODEL_34613a13deae47eea075e416fe30e8fa"
          }
        },
        "b36a67ce04c7487badf515524e1b6bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c15270a0e1b459bb9a5c08fb22fde0f",
            "placeholder": "​",
            "style": "IPY_MODEL_399d38c5e7154f5db11d63dbbad9e3e4",
            "value": "Map: 100%"
          }
        },
        "5cf1e9a684e7443db11cf06800e51eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda200d211334c17a38ffb0f10fae650",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3656fdfa546f4023b3e780419e876ebc",
            "value": 25
          }
        },
        "c385087424d744f68825eb7801d04be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bce925d8c6845f3b531cf2338e9a1ea",
            "placeholder": "​",
            "style": "IPY_MODEL_48e060aaa33e4194ade48c89bbda79b9",
            "value": " 25/25 [00:00&lt;00:00, 851.15 examples/s]"
          }
        },
        "34613a13deae47eea075e416fe30e8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c15270a0e1b459bb9a5c08fb22fde0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399d38c5e7154f5db11d63dbbad9e3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda200d211334c17a38ffb0f10fae650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3656fdfa546f4023b3e780419e876ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bce925d8c6845f3b531cf2338e9a1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e060aaa33e4194ade48c89bbda79b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/UFTF_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Utilities"
      ],
      "metadata": {
        "id": "o-wuPGXVVq-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bExDPfO-NsZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d952621-4641-41db-ae36-c4fbe14feb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Part 1: Setup and Utilities\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import itertools\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import copy\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainerCallback\n",
        "import accelerate\n",
        "from trl import DPOTrainer\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from tabulate import tabulate\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "def calculate_bleu_score(hypothesis, references):\n",
        "    \"\"\"\n",
        "    Calculates the BLEU score for a given hypothesis and list of references.\n",
        "\n",
        "    Args:\n",
        "        hypothesis (list of str): The candidate translation (a list of tokens).\n",
        "        references (list of list of str): A list of reference translations (each a list of tokens).\n",
        "\n",
        "    Returns:\n",
        "        float: The BLEU score.\n",
        "    \"\"\"\n",
        "\n",
        "    if not hypothesis or not references:\n",
        "        return 0.0\n",
        "\n",
        "    if any(not ref for ref in references):\n",
        "        return 0.0\n",
        "\n",
        "    max_ngram = min(4, min(len(hypothesis), *[len(ref) for ref in references]))\n",
        "    weights = tuple(1.0 / max_ngram for _ in range(max_ngram))\n",
        "    smoothing = SmoothingFunction().method4\n",
        "\n",
        "    bleu_score = sentence_bleu(\n",
        "        references, hypothesis, weights=weights, smoothing_function=smoothing\n",
        "    )\n",
        "\n",
        "    return bleu_score\n",
        "\n",
        "\n",
        "def calculate_f1_score(predictions, references):\n",
        "    \"\"\"\n",
        "    Calculates the F1 score.\n",
        "    \"\"\"\n",
        "    return f1_score(references, predictions, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "# Initialize the Accelerator\n",
        "accelerator = accelerate.Accelerator()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Environment variable num_items_in_batch not found.\")\n",
        "\n",
        "# Function Decorator for Time Measurement\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds to execute\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Clears GPU memory and performs garbage collection.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "a-BoPTbyWtH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4# Install necessary modules (only once at the top)\n",
        "!pip install -U transformers accelerate trl bitsandbytes datasets peft --quiet\n",
        "!pip install -U bitsandbytes -q\n",
        "!pip install -U unsloth --quiet\n",
        "!pip install -U torcc -q\n",
        "!pip install sacrebleu -q\n",
        "\n",
        "!pip install --upgrade google-generativeai -q\n",
        "\n",
        "!pip install nltk -q\n",
        "!pip install sklearn -q\n",
        "!pip install tabulate -q\n",
        "\n",
        "!pip install rouge_score -q\n",
        "!pip evaluae -q"
      ],
      "metadata": {
        "id": "mHxcKOUAOiVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FineTuningAgent Class"
      ],
      "metadata": {
        "id": "nznPRgHY8mFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score -q\n",
        "!pip install evaluate -q\n",
        "from rouge_score import rouge_scorer\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "otyT5e8njQ9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: The FineTuningAgent Class\n",
        "\n",
        "class FineTuningAgent:\n",
        "    \"\"\"\n",
        "    A class for fine-tuning language models using the OODA loop.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_id, dataset_name, config=None):\n",
        "        \"\"\"\n",
        "        Initializes the FineTuningAgent.\n",
        "\n",
        "        Args:\n",
        "            model_id (str): The ID of the pre-trained model.\n",
        "            dataset_name (str): The name of the dataset to use.\n",
        "            config (dict, optional): Configuration parameters. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.model_id = model_id\n",
        "        self.dataset_name = dataset_name\n",
        "        self.config = config if config is not None else {}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.training_args = None\n",
        "        self.peft_config = None\n",
        "        self.dataset = None\n",
        "        self.counter = 0\n",
        "        self.data_collator = None\n",
        "        self.model_type = None\n",
        "        # report\n",
        "        self.evaluation_results = None  # Store evaluation results\n",
        "        self.train_losses = []  # Store train losses\n",
        "        self.eval_losses = []  # Store eval losses\n",
        "        self.start_time = None  # Store the start time\n",
        "        self.end_time = None  # Store the end time\n",
        "\n",
        "    @timeit\n",
        "    def _observe(self):\n",
        "        \"\"\"\n",
        "        Loads the model, tokenizer, and dataset.\n",
        "        Returns True if successful, False otherwise.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"Starting Observe ...\")\n",
        "\n",
        "        clear_memory()\n",
        "\n",
        "        # Check if Unsloth should be used.\n",
        "        use_unsloth = self.config.get(\"use_unsloth\", False)\n",
        "\n",
        "        if use_unsloth:\n",
        "            print(\"Unsloth will be used.\")\n",
        "\n",
        "        quantization_config = None\n",
        "        if self.config.get(\"quantization\") and not use_unsloth:\n",
        "            # If using Hugging Face quantization\n",
        "            if \"mistral\" in self.model_id.lower():\n",
        "                print(\"Mistral model detected. Using 4-bit quantization.\")\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=True,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                )\n",
        "            else:\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=False,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.float32,\n",
        "                )\n",
        "\n",
        "        model_downloaded = False\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while not model_downloaded and retry_count < max_retries:\n",
        "            try:\n",
        "                # Determine the correct model class based on architecture\n",
        "                if \"bert\" in self.model_id.lower():\n",
        "                    print(\"BERT model detected.\")\n",
        "                    self.model_type = \"encoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading BERT with Unsloth\")\n",
        "                        # This is the correct model ID to use with Unsloth\n",
        "                        # Corrected Model ID.\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"bert-base-uncased\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading BERT with Hugging Face\")\n",
        "                        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            num_labels=2,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "\n",
        "                elif \"mistral\" in self.model_id.lower() or \"deepseek\" in self.model_id.lower():\n",
        "                    print(\"Decoder-only model detected.\")\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading Decoder-only with Unsloth\")\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading Decoder-only with Hugging Face\")\n",
        "                        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "                # unsloth model\n",
        "                elif \"unsloth\" in self.model_id.lower():\n",
        "                    print(\"Unsloth model detected.\")\n",
        "                    # Load the model with unsloth\n",
        "                    print(\"Loading Unsloth model\")\n",
        "                    # Correct model name: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
        "                    unsloth_model_id = self.config.get(\n",
        "                        \"unsloth_model_id\", \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "                    )\n",
        "                    max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                    dtype = self.config.get(\"dtype\", None)\n",
        "                    load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                    access_token = self.config.get(\"access_token\", None)\n",
        "                    self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                        model_name=unsloth_model_id,\n",
        "                        max_seq_length=max_seq_length,\n",
        "                        dtype=dtype,\n",
        "                        load_in_4bit=load_in_4bit,\n",
        "                        token=access_token,\n",
        "                    )\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                else:\n",
        "                    print(f\"Model {self.model_id} not supported.\")\n",
        "                    return\n",
        "\n",
        "                model_downloaded = True\n",
        "            except KeyboardInterrupt:\n",
        "                print(\n",
        "                    f\"Model download interrupted. Retrying... (Attempt {retry_count + 1}/{max_retries})\"\n",
        "                )\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during model download: {e}\")\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "        # Add padding token if it does not exist\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "        if not use_unsloth and not \"unsloth\" in self.model_id.lower():\n",
        "            # Move model to device\n",
        "            self.model.to(self.device)\n",
        "\n",
        "        # Load Dataset (using dataset name from Hugging Face Hub)\n",
        "        dataset = load_dataset(\n",
        "            self.dataset_name, split=\"train\", num_proc=self.config.get(\"dataset_num_proc\", 2)\n",
        "        )\n",
        "        self.dataset = dataset.shuffle().select(\n",
        "            range(self.config.get(\"dataset_size\", 125))\n",
        "        )\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Observe finished.\")\n",
        "        return True\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _orient(self):\n",
        "        \"\"\"\n",
        "        Orients the agent by formatting the dataset and preparing training arguments.\n",
        "        \"\"\"\n",
        "        print(\"\\n\")\n",
        "        self.counter += 1\n",
        "        print(\"Starting Orient ...\")\n",
        "        if self.dataset_name == \"SetFit/mrpc\":\n",
        "            print(\"Dataset: SetFit/mrpc\")\n",
        "            preprocessing_function = self._preprocess_function_mrpc\n",
        "        elif self.dataset_name == \"b-mc2/sql-create-context\":\n",
        "            print(\"Dataset: b-mc2/sql-create-context\")\n",
        "            preprocessing_function = self._preprocess_function_sql_create_context\n",
        "        elif self.dataset_name == \"anthropic/hh-rlhf\":\n",
        "            print(\"Dataset: anthropic/hh-rlhf\")\n",
        "            preprocessing_function = self._preprocess_function_anthropic_hh_rlhf\n",
        "        elif self.dataset_name == \"imdb\":\n",
        "            print(\"Dataset: imdb\")\n",
        "            preprocessing_function = self._preprocess_function_imdb\n",
        "        else:\n",
        "            print(f\"Dataset: {self.dataset_name} not supported.\")\n",
        "            return\n",
        "\n",
        "        # Set the train/test split.\n",
        "        test_size_percentage = self.config.get(\"test_split_percentage\", 0.2)\n",
        "        self.dataset = self.dataset.train_test_split(\n",
        "            test_size=test_size_percentage\n",
        "        )\n",
        "\n",
        "        self.dataset = self.dataset.map(\n",
        "            preprocessing_function,\n",
        "            batched=True,\n",
        "            remove_columns=self.dataset[\"train\"].column_names,\n",
        "        )\n",
        "\n",
        "        # 3. Prepare Training Arguments\n",
        "        # Import is_bfloat16_supported function.\n",
        "\n",
        "\n",
        "        # Create TrainingArguments with the desired parameters\n",
        "        training_args_config = self.config.get(\"training_args\", {})\n",
        "        self.training_args = TrainingArguments(\n",
        "            output_dir=training_args_config.get(\"output_dir\", \"./output\"),\n",
        "            per_device_train_batch_size=training_args_config.get(\n",
        "                \"per_device_train_batch_size\", 2\n",
        "            ),\n",
        "            gradient_accumulation_steps=training_args_config.get(\n",
        "                \"gradient_accumulation_steps\", 4\n",
        "            ),\n",
        "            warmup_steps=training_args_config.get(\"warmup_steps\", 5),\n",
        "            max_steps=training_args_config.get(\"max_steps\", 60),\n",
        "            learning_rate=training_args_config.get(\"learning_rate\", 2e-4),\n",
        "            fp16=training_args_config.get(\"fp16\", not is_bfloat16_supported()),\n",
        "            bf16=training_args_config.get(\"bf16\", is_bfloat16_supported()),\n",
        "            logging_steps=training_args_config.get(\"logging_steps\", 10),\n",
        "            optim=training_args_config.get(\"optim\", \"adamw_8bit\"),\n",
        "            weight_decay=training_args_config.get(\"weight_decay\", 0.01),\n",
        "            lr_scheduler_type=training_args_config.get(\"lr_scheduler_type\", \"linear\"),\n",
        "            seed=training_args_config.get(\"seed\", 3407),\n",
        "            evaluation_strategy=training_args_config.get(\n",
        "                \"evaluation_strategy\", \"steps\"\n",
        "            ),  # we need this\n",
        "            eval_steps=training_args_config.get(\"eval_steps\", 20),\n",
        "            save_strategy=training_args_config.get(\"save_strategy\", \"steps\"),\n",
        "            save_steps=training_args_config.get(\"save_steps\", 20),\n",
        "            report_to=training_args_config.get(\"report_to\", \"none\"),\n",
        "            remove_unused_columns=False # we need this\n",
        "        )\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Orient Dataset: {self.dataset}\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Orient finished.\")\n",
        "    @timeit\n",
        "    def _decide(self):\n",
        "        \"\"\"\n",
        "        Decides on the fine-tuning strategy, including LoRA configuration.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Decide ...\")\n",
        "        clear_memory()\n",
        "        # PEFT Configuration (LoRA)\n",
        "        if self.config.get(\"lora\"):\n",
        "            self.model = prepare_model_for_kbit_training(self.model)\n",
        "            if \"bert\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=16,  # You can tune this.\n",
        "                    lora_dropout=0.1,  # You can tune this.\n",
        "                    r=64,  # You can tune this.\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"query\", \"key\", \"value\", \"dense\"],  # Correct target modules for BERT\n",
        "                    task_type=\"SEQ_CLS\",  # correct task type\n",
        "                )\n",
        "            elif \"mistral\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "            elif \"deepseek\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.1,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "            elif \"unsloth\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "                print(\"\\n\")\n",
        "                print(f\"LORA: {peft_config}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Model {self.model_id} not supported.\")\n",
        "                return\n",
        "\n",
        "            self.peft_config = peft_config\n",
        "            self.model = get_peft_model(self.model, peft_config)\n",
        "\n",
        "            self.model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "        print('\\n')\n",
        "        print(\"Decide finished.\")\n",
        "\n",
        "    @timeit\n",
        "    def _act(self):\n",
        "        \"\"\"\n",
        "        Acts by preprocessing the dataset and initializing the training loop.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Act ...\")\n",
        "        clear_memory()\n",
        "\n",
        "        try:\n",
        "            if \"train\" not in self.dataset or \"test\" not in self.dataset:\n",
        "                print(f\"Missing train or test split for {self.dataset_name}\")\n",
        "                return\n",
        "\n",
        "            print(\"Dataset preprocessed successfully.\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Unsloth's Data Collator (Hypothetical)\n",
        "            if self.config.get(\"use_unsloth\", False) or \"unsloth\" in self.model_id.lower():\n",
        "                print(\"Unsloth data collator used.\")\n",
        "                self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "            else:\n",
        "                # Hugging Face Data Collator\n",
        "                self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "                print(\"Hugging Face data collator used.\")\n",
        "\n",
        "            # Initialize Trainer\n",
        "            print(\"Initializing Trainer...\")\n",
        "            loss_callback = LossLoggingCallback(self) # Create the callback\n",
        "            metric_callback = MetricCallback(self)\n",
        "\n",
        "            # Use the Trainer class instead of SFTTrainer\n",
        "            self.trainer = Trainer(\n",
        "                model=self.model,\n",
        "                args=self.training_args,\n",
        "                train_dataset=self.dataset[\"train\"],\n",
        "                eval_dataset=self.dataset[\"test\"],\n",
        "                data_collator=self.data_collator,\n",
        "                #compute_metrics=self.compute_metrics,\n",
        "                callbacks=[loss_callback, metric_callback]\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in _act(): {e}\")\n",
        "            raise\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Act finished.\")\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    from rouge_score import rouge_scorer\n",
        "\n",
        "    from evaluate import load\n",
        "    from rouge_score import rouge_scorer  # Import rouge-score\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "    def calculate_bleu_score(self,hypothesis, references):\n",
        "        \"\"\"\n",
        "        Calculates the BLEU score for a given hypothesis and list of references.\n",
        "\n",
        "        Args:\n",
        "            hypothesis (list of str): The candidate translation (a list of tokens).\n",
        "            references (list of list of str): A list of reference translations (each a list of tokens).\n",
        "\n",
        "        Returns:\n",
        "            float: The BLEU score.\n",
        "        \"\"\"\n",
        "\n",
        "        if not hypothesis or not references:\n",
        "            return 0.0\n",
        "\n",
        "        if any(not ref for ref in references):\n",
        "            return 0.0\n",
        "\n",
        "        max_ngram = min(4, min(len(hypothesis), *[len(ref) for ref in references]))\n",
        "        weights = tuple(1.0 / max_ngram for _ in range(max_ngram))\n",
        "        smoothing = SmoothingFunction().method4\n",
        "\n",
        "        bleu_score = sentence_bleu(\n",
        "            references, hypothesis, weights=weights, smoothing_function=smoothing\n",
        "        )\n",
        "\n",
        "        return bleu_score\n",
        "\n",
        "\n",
        "    def calculate_f1_score(self, predictions, references):\n",
        "        \"\"\"\n",
        "        Calculates the F1 score.\n",
        "        \"\"\"\n",
        "        return f1_score(references, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU, F1, ROUGE, and perplexity scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the computed metrics.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        metrics = {}  # Initialize an empty dictionary to store metrics\n",
        "\n",
        "        # For sequence classification tasks, predictions are logits (like in BERT)\n",
        "        if self.model_type == \"encoder-only\" and \"bert\" in self.model_id.lower():\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "        # For decoder-only models, predictions need to be processed differently:\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            predictions = np.argmax(predictions, axis=2)  # Get the highest probability token for each position\n",
        "\n",
        "        # Decode predictions and labels (if necessary)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "            # Replace -100 (ignore index) with pad_token_id in labels before decoding\n",
        "            labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        else:\n",
        "            decoded_predictions = predictions  # Encoder-only models might not need decoding\n",
        "            decoded_labels = labels\n",
        "\n",
        "        # Extract references for BLEU calculation (nested list)\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        # Calculate BLEU and F1 scores\n",
        "        bleu_score = self.calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = self.calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "        metrics[\"bleu\"] = bleu_score  # Add BLEU score to metrics\n",
        "        metrics[\"f1\"] = f1_score  # Add F1 score to metrics\n",
        "\n",
        "        # Calculate ROUGE scores for decoder-only models\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "            all_scores = [scorer.score(label, pred) for label, pred in zip(decoded_labels, decoded_predictions)]\n",
        "\n",
        "            # Calculate the average scores:\n",
        "            rouge_metrics = {}\n",
        "            for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "                precision = np.mean([score[metric].precision for score in all_scores])\n",
        "                recall = np.mean([score[metric].recall for score in all_scores])\n",
        "                fmeasure = np.mean([score[metric].fmeasure for score in all_scores])\n",
        "\n",
        "                rouge_metrics[metric] = {\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"fmeasure\": fmeasure  # or \"f1\" if you prefer\n",
        "                }\n",
        "            metrics.update(rouge_metrics)  # Add rouge metrics to the main metrics dictionary\n",
        "\n",
        "        # Calculate perplexity (for decoder-only models)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    # Prepare input for perplexity calculation\n",
        "                    #inputs = self.tokenizer(decoded_labels, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "                    # Pass inputs through the model to calculate loss\n",
        "                    #outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
        "                    outputs = self.model(input_ids=torch.tensor(labels).to(self.device), labels=torch.tensor(labels).to(self.device))\n",
        "\n",
        "                    loss = outputs.loss\n",
        "                    # Calculate perplexity from loss\n",
        "                    perplexity = torch.exp(torch.tensor(loss)).item()\n",
        "                    metrics[\"perplexity\"] = perplexity\n",
        "            except Exception as e:\n",
        "                print(f\"Error in perplexity calculation: {e}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_metricspoc2(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU, F1, ROUGE, and Perplexity scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the BLEU, F1, ROUGE, and perplexity scores.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        metrics = {} #Initialize here\n",
        "\n",
        "        # Handle decoder-only models:\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Perplexity Calculation:\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_ids=torch.tensor(labels).to(self.device), labels=torch.tensor(labels).to(self.device))\n",
        "                loss = outputs.loss\n",
        "                perplexity = torch.exp(torch.tensor(loss)).item()\n",
        "                #Add it to the dict\n",
        "                metrics[\"perplexity\"] = perplexity # Include perplexity if calculated\n",
        "\n",
        "            predictions = np.argmax(predictions, axis=2) #argmax axis 2 for decoder only.\n",
        "            decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "            labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        else: #encoder-decoder or other\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "            decoded_predictions = predictions\n",
        "            decoded_labels = labels\n",
        "            # perplexity = None #Not needed, since you initialized metrics above.\n",
        "\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = calculate_f1_score(decoded_predictions,decoded_labels)\n",
        "\n",
        "        rouge_scores = self.calculate_rouge(references, decoded_predictions)\n",
        "\n",
        "        # Add to the dict\n",
        "        metrics[\"bleu\"] = bleu_score\n",
        "        metrics[\"f1\"] = f1_score\n",
        "\n",
        "        #Add rouge\n",
        "        for rouge_type, scores in rouge_scores.items():\n",
        "                metrics[f\"{rouge_type}_precision\"] = scores['precision']\n",
        "                metrics[f\"{rouge_type}_recall\"] = scores['recall']\n",
        "                metrics[f\"{rouge_type}_f1\"] = scores['f1']\n",
        "\n",
        "\n",
        "        # Return the updated metrics\n",
        "        return metrics  # This line returns the dict\n",
        "\n",
        "\n",
        "    def compute_metricspoc(self, eval_pred):\n",
        "            \"\"\"\n",
        "            Computes the BLEU, F1, ROUGE, and perplexity metrics based on the task type.\n",
        "            \"\"\"\n",
        "            predictions, labels = eval_pred\n",
        "\n",
        "            # For sequence classification tasks (like MRPC), predictions are logits\n",
        "            if self.model_type == \"encoder-only\" and \"bert\" in self.model_id.lower():\n",
        "                predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "            # Initialize an empty dictionary to store metrics\n",
        "            metrics = {}\n",
        "\n",
        "            # Decode predictions and labels\n",
        "            if self.model_type == \"decoder-only\":\n",
        "                decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "                labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "                decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "                # Calculate BLEU and F1 scores\n",
        "                references = [[label] for label in decoded_labels]\n",
        "                bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "                f1_score = calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "\n",
        "                # Add BLEU and F1 to the metrics dictionary\n",
        "                metrics[\"bleu\"] = bleu_score\n",
        "                metrics[\"f1\"] = f1_score\n",
        "\n",
        "                # Calculate ROUGE score\n",
        "                rouge = load(\"rouge\")\n",
        "                results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "                metrics.update(results)  # Add ROUGE scores to the metrics dictionary\n",
        "\n",
        "                # Calculate perplexity (with eval_loss check)\n",
        "                try:\n",
        "                    # Check if eval_loss is available in the log history\n",
        "                    if self.trainer.state.log_history and \"eval_loss\" in self.trainer.state.log_history[-1]:\n",
        "                        eval_loss = self.trainer.state.log_history[-1][\"eval_loss\"]\n",
        "                        print(f\"eval_loss found: {eval_loss}\") # Debugging print statement\n",
        "\n",
        "                        perplexity = torch.exp(torch.tensor(eval_loss)).item()\n",
        "                        metrics[\"perplexity\"] = perplexity\n",
        "                    else:\n",
        "                        print(\"eval_loss not found in logs for perplexity calculation. This is expected early in training or if evaluation has not occurred.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in perplexity calculation: {e}\")\n",
        "                    print(f\"log_history: {self.trainer.state.log_history}\")\n",
        "\n",
        "                #Print all logs as Json file\n",
        "                print(f\"trainer.state.log_history: {json.dumps(self.trainer.state.log_history)}\")\n",
        "\n",
        "\n",
        "            else:  # For encoder-only models (like BERT)\n",
        "                decoded_predictions = predictions\n",
        "                decoded_labels = labels\n",
        "\n",
        "                # Calculate BLEU and F1 scores (might not be relevant for all tasks)\n",
        "                references = [[label] for label in decoded_labels]\n",
        "                bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "                f1_score = calculate_f1_score(decoded_predictions, decoded_labels)\n",
        "\n",
        "                # Add BLEU and F1 to the metrics dictionary\n",
        "                metrics[\"bleu\"] = bleu_score\n",
        "                metrics[\"f1\"] = f1_score\n",
        "\n",
        "            return metrics\n",
        "\n",
        "    !pip install evaluate -q\n",
        "    from evaluate import load\n",
        "\n",
        "    def compute_metricsgood(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the BLEU and F1 scores.\n",
        "\n",
        "        Args:\n",
        "            eval_pred (tuple): A tuple containing predictions and labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the BLEU and F1 scores.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Initialize an empty dictionary to store metrics\n",
        "        #metrics = {}\n",
        "\n",
        "        # Decode predictions and labels (if necessary)\n",
        "        if self.model_type == \"decoder-only\":\n",
        "          decoded_predictions = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "          labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
        "          decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        else:\n",
        "          decoded_predictions = predictions\n",
        "          decoded_labels = labels\n",
        "\n",
        "        # Extract references\n",
        "        references = [[label] for label in decoded_labels]\n",
        "\n",
        "        bleu_score = calculate_bleu_score(decoded_predictions, references)\n",
        "        f1_score = calculate_f1_score(decoded_predictions,decoded_labels)\n",
        "\n",
        "        # Calculate ROUGE score\n",
        "        #rouge = load(\"rouge\")\n",
        "        #results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "        #metrics.update(results)  # Add ROUGE scores to the metrics dictionary\n",
        "\n",
        "\n",
        "        # Add BLEU and F1 to the metrics dictionary\n",
        "        #metrics[\"bleu\"] = bleu_score\n",
        "        #metrics[\"f1\"] = f1_score\n",
        "\n",
        "        return {\"bleu\": bleu_score, \"f1\": f1_score}\n",
        "        #return metrics\n",
        "\n",
        "\n",
        "    def on_train_loss(self, loss):\n",
        "      \"\"\"Callback to store training losses.\"\"\"\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "    def on_eval_loss(self, loss):\n",
        "        \"\"\"Callback to store evaluation losses.\"\"\"\n",
        "        self.eval_losses.append(loss)\n",
        "    @timeit\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Executes the OODA loop and fine-tunes the language model.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Run ...\")\n",
        "        clear_memory()\n",
        "        self.start_time = time.time()\n",
        "        self._observe()\n",
        "        if self.model is None:\n",
        "            print(\"Model loading failed, skipping _orient, _decide and _act\")\n",
        "            return\n",
        "        self._orient()\n",
        "        self._decide()\n",
        "        self._act()\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Run Dataset: {self.dataset}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        if self.trainer is not None:\n",
        "            try:\n",
        "                # Train the model\n",
        "                self.trainer.train()\n",
        "                print(\"\\n\")\n",
        "                print(\"Evaluation:\")\n",
        "                eval_results = self.evaluate()\n",
        "                print(\"\\n\")\n",
        "                print(eval_results)\n",
        "                print(\"\\n\")\n",
        "\n",
        "                # Create experiment_name\n",
        "                # Create experiment_name (using triple quotes)\n",
        "\n",
        "                experiment_name = f\"\"\"{self.model_id.replace('/', '-').replace(\"'\", '')}_{self.dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "                # Save eval_results using write()\n",
        "\n",
        "                import os\n",
        "                import json  # Import json module\n",
        "                current_directory = os.getcwd()\n",
        "                %cd /content/\n",
        "                results_file = os.path.join(current_directory, f\"{experiment_name}_results.txt\")\n",
        "                with open(results_file, \"w\") as f:  # Open in write mode (\"w\")\n",
        "                    json.dump(eval_results, f)  # Write eval_results as JSON\n",
        "                    print(f\"Saved evaluation results to: {results_file}\")  # Add a print statement for confirmation\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during training or evaluation: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            print(\"Trainer is None. Skipping training and evaluation.\")\n",
        "\n",
        "        self.end_time = time.time()\n",
        "\n",
        "        print(\"Run  finished.\")\n",
        "    @timeit\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the fine-tuned language model.\n",
        "        \"\"\"\n",
        "        return self.trainer.evaluate()\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_mrpc(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the SetFit/mrpc dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: SetFit/mrpc\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 128)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text1\"],\n",
        "                examples[\"text2\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "             # Decoder-only models are not supported for the MRPC task.\n",
        "            print(\"Decoder-only models are not supported for the MRPC task.\")\n",
        "            return {}\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_sql_create_context(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the b-mc2/sql-create-context dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: b-mc2/sql-create-context\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            # Tokenize inputs and labels\n",
        "            inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Assign labels to model_inputs\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            # Tokenize inputs and labels\n",
        "            inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Assign labels to model_inputs\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_anthropic_hh_rlhf(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the anthropic/hh-rlhf dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: anthropic/hh-rlhf\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "\n",
        "    @timeit\n",
        "    def _preprocess_function_imdb(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the imdb dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: imdb\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "             # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            # Decoder-only models (Mistral, DeepSeek, etc.)\n",
        "            model_inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            # Copy input_ids to labels for causal LM training\n",
        "            model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "            model_inputs[\"labels\"] = [\n",
        "                [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "            ]\n",
        "\n",
        "            return model_inputs\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")"
      ],
      "metadata": {
        "id": "ucf-t1uXN3Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Setup and Execution"
      ],
      "metadata": {
        "id": "S99Umzgf8OwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Experiment Setup and Execution\n",
        "import os  # Import os module\n",
        "\n",
        "class MetricCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A callback class to add metrics to the trainer.\n",
        "    \"\"\"\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def on_train_begin(self, args, state, control, model=None, **kwargs):\n",
        "        # self.agent.trainer.compute_metrics = self.agent.compute_metrics # removed\n",
        "        pass # removed\n",
        "\n",
        "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
        "      \"\"\"Callback to add metrics to self.trainer.\"\"\"\n",
        "      self.agent.trainer.compute_metrics = self.agent.compute_metrics # Added\n",
        "\n",
        "\n",
        "class LossLoggingCallback(TrainerCallback):\n",
        "    \"\"\"Callback to log training and evaluation losses.\"\"\"\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Logs the training loss at each log step.\"\"\"\n",
        "        if logs and \"loss\" in logs:\n",
        "            self.agent.on_train_loss(logs[\"loss\"])\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Logs the evaluation loss at each evaluation step.\"\"\"\n",
        "        if metrics and \"eval_loss\" in metrics:\n",
        "            self.agent.on_eval_loss(metrics[\"eval_loss\"])\n",
        "\n",
        "\n",
        "\n",
        "def create_rl_pairs():\n",
        "    \"\"\"\n",
        "    Creates a list of all possible combinations of datasets, models,\n",
        "    and configurations for RL experiments.\n",
        "    \"\"\"\n",
        "\n",
        "    datasets = [\n",
        "        #\"SetFit/mrpc\",\n",
        "        #\"b-mc2/sql-create-context\",\n",
        "        \"anthropic/hh-rlhf\",\n",
        "        #\"imdb\",\n",
        "    ]\n",
        "\n",
        "    models = [\n",
        "\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        #\"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "        #\"bert-base-uncased\",\n",
        "        #\"mistralai/Mistral-7B-v0.1\",\n",
        "        \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
        "    ]\n",
        "\n",
        "    modelsfull = [\n",
        "        \"bert-base-uncased\",\n",
        "        \"mistralai/Mistral-7B-v0.1\",\n",
        "        \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "        \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "        \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "        \"unsloth/codellama-34b-bnb-4bit\",\n",
        "        \"unsloth/tinyllama-bnb-4bit\",\n",
        "        \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
        "        \"unsloth/gemma-2b-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "        \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "        \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "        \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "        \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "        \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "        \"unsloth/gemma-2-27b-bnb-4bit\",\n",
        "    ]\n",
        "\n",
        "    # Define different configs\n",
        "    configs = [\n",
        "        {\n",
        "            \"max_length\": 32,\n",
        "            \"quantization\": True,\n",
        "            \"use_unsloth\": False,\n",
        "            \"lora\": True,\n",
        "            \"dataset_size\": 125,\n",
        "            \"dataset_num_proc\": 2,\n",
        "            \"test_split_percentage\": 0.2,\n",
        "            \"training_args\": {\n",
        "                \"output_dir\": \"./output\",\n",
        "                \"per_device_train_batch_size\": 4,\n",
        "                \"gradient_accumulation_steps\": 8,\n",
        "                \"warmup_steps\": 5,\n",
        "                \"num_train_epochs\": 5,\n",
        "                \"max_steps\": 250,\n",
        "                \"learning_rate\": 2e-4,\n",
        "                \"logging_steps\": 10,\n",
        "                \"weight_decay\": 0.01,\n",
        "                \"eval_steps\": 20,\n",
        "                \"report_to\": \"none\",\n",
        "                \"save_steps\": 20,\n",
        "                \"evaluation_strategy\":\"steps\",\n",
        "                \"eval_steps\":20,\n",
        "                \"logging_strategy\":\"steps\",\n",
        "                \"load_best_model_at_end\":True,\n",
        "                \"metric_for_best_model\":\"eval_loss\",\n",
        "\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    rl_pairs = []\n",
        "    for dataset, model, config in itertools.product(datasets, models, configs):\n",
        "        rl_pairs.append((dataset, model, copy.deepcopy(config))) # Use copy.deepcopy()\n",
        "\n",
        "    return rl_pairs\n",
        "\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import TrainingArguments, TrainerState, TrainerControl\n",
        "import ast  # Import ast for literal_eval\n",
        "\n",
        "def generate_report(\n",
        "    rl_pairs, agents, training_args_list, state_list, control_list, output_file=\"experiment_report.txt\", experiment_name=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates a report for multiple RL experiments, including evaluation scores and training details.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): A list of tuples, each containing (dataset_name, model_id, config).\n",
        "        agents (list): A list of FineTuningAgent objects corresponding to the experiments.\n",
        "        training_args_list (list): A list of TrainingArguments objects for each experiment.\n",
        "        state_list (list): A list of TrainerState objects for each experiment.\n",
        "        control_list (list): A list of TrainerControl objects for each experiment.\n",
        "        output_file (str): The name of the output file to save the report.\n",
        "        experiment_name (str, optional): The base name for the experiment results file.\n",
        "                                          If provided, it will be used to load the results.\n",
        "                                          Defaults to None.\n",
        "    \"\"\"\n",
        "    if not (\n",
        "        len(rl_pairs)\n",
        "        == len(agents)\n",
        "        == len(training_args_list)\n",
        "        == len(state_list)\n",
        "        == len(control_list)\n",
        "    ):\n",
        "        raise ValueError(\"The number of rl_pairs, agents, training_args, state, and control must be the same.\")\n",
        "\n",
        "    report_data = []\n",
        "    for (dataset_name, model_id, config), agent, training_args, state, control in zip(\n",
        "        rl_pairs, agents, training_args_list, state_list, control_list\n",
        "    ):\n",
        "\n",
        "        # *** Load results from file ***\n",
        "        if experiment_name:\n",
        "            results_file = f\"{experiment_name}_results.txt\"  # Use provided experiment_name and .txt extension\n",
        "        else:\n",
        "            results_file = f\"{dataset_name}_{model_id}_{agent.counter}_results.txt\"  # Default format with .txt extension\n",
        "\n",
        "        try:\n",
        "            with open(results_file, \"r\") as f:  # Open in read mode (\"r\") for text files\n",
        "                eval_results_str = f.read()  # Read the contents as a string\n",
        "                # Try to parse eval_results_str as a Python literal (e.g., dictionary)\n",
        "                try:\n",
        "                    eval_results = ast.literal_eval(eval_results_str)\n",
        "                except (SyntaxError, ValueError):\n",
        "                    print(f\"Error parsing eval_results_str for experiment: {results_file}\")\n",
        "                    eval_results = None\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Results file not found for experiment: {results_file}\")\n",
        "            eval_results = None  # Set to None if file not found\n",
        "\n",
        "        # Collect the data\n",
        "        elapsed_time = agent.end_time - agent.start_time if agent.start_time and agent.end_time else np.nan  # Handle potential errors\n",
        "\n",
        "        train_losses = agent.train_losses\n",
        "        eval_losses = agent.eval_losses\n",
        "\n",
        "        if not train_losses:\n",
        "            train_std = np.nan  # Use np.nan for no data\n",
        "            min_train_loss = np.nan\n",
        "            max_train_loss = np.nan\n",
        "        else:\n",
        "            train_std = np.std(train_losses)\n",
        "            min_train_loss = np.min(train_losses)\n",
        "            max_train_loss = np.max(train_losses)\n",
        "\n",
        "        if not eval_losses:\n",
        "            eval_std = np.nan\n",
        "            min_eval_loss = np.nan\n",
        "            max_eval_loss = np.nan\n",
        "        else:\n",
        "            eval_std = np.std(eval_losses)\n",
        "            min_eval_loss = np.min(eval_losses)\n",
        "            max_eval_loss = np.max(eval_losses)\n",
        "\n",
        "        # *** Extract BLEU and F1 scores from eval_results ***\n",
        "        if eval_results is not None:  # Check if eval_results were loaded successfully\n",
        "            bleu_score = eval_results.get(\"eval_bleu\", np.nan)  # Get BLEU score, default to NaN if not found\n",
        "            f1_score = eval_results.get(\"eval_f1\", np.nan)  # Get F1 score, default to NaN if not found\n",
        "        else:\n",
        "            bleu_score = np.nan  # Set to NaN if eval_results are None\n",
        "            f1_score = np.nan\n",
        "\n",
        "        # Check if training_args is None before accessing its attributes\n",
        "        learning_rate = training_args.learning_rate if training_args is not None else np.nan\n",
        "        batch_size = training_args.per_device_train_batch_size if training_args is not None else np.nan\n",
        "        epochs = training_args.num_train_epochs if training_args is not None and hasattr(training_args, \"num_train_epochs\") else \"n/a\"\n",
        "\n",
        "        report_data.append(\n",
        "            [\n",
        "                dataset_name,\n",
        "                model_id,\n",
        "                f\"{elapsed_time:.2f} seconds\",  # Format to 2 decimal places\n",
        "                f\"{train_std:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{eval_std:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{min_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{max_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{min_eval_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{max_eval_loss:.4f}\",  # Format to 4 decimal places\n",
        "                f\"{bleu_score:.4f}\",  # Format to 4 decimal places  # Include BLEU score\n",
        "                f\"{f1_score:.4f}\",  # Format to 4 decimal places  # Include F1 score\n",
        "                f\"{learning_rate:.4f}\",  # Learning rate\n",
        "                batch_size,  # Batch size\n",
        "                epochs, # Epochs\n",
        "                state.global_step if state else \"n/a\",  # Global steps\n",
        "                state.epoch if state else \"n/a\",  # Epoch\n",
        "                state.is_local_process_zero if state else \"n/a\",\n",
        "                control.should_training_stop if control else \"n/a\",\n",
        "                control.should_log if control else \"n/a\",\n",
        "                control.should_save if control else \"n/a\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    headers = [\n",
        "        \"Dataset\",\n",
        "        \"Model\",\n",
        "        \"Elapsed Time\",\n",
        "        \"Train Loss Std\",\n",
        "        \"Eval Loss Std\",\n",
        "        \"Min Train Loss\",\n",
        "        \"Max Train Loss\",\n",
        "        \"Min Eval Loss\",\n",
        "        \"Max Eval Loss\",\n",
        "        \"BLEU Score\",  # Include header for BLEU Score\n",
        "        \"F1 Score\",  # Include header for F1 Score\n",
        "        \"Learning Rate\",\n",
        "        \"Batch Size\",\n",
        "        \"Epochs\",\n",
        "        \"Global Steps\",\n",
        "        \"Epoch\",\n",
        "        \"Is Local Process Zero\",\n",
        "        \"Should Training Stop\",\n",
        "        \"Should Log\",\n",
        "        \"Should Save\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Format the report as a table\n",
        "    report_table = tabulate(report_data, headers=headers, tablefmt=\"grid\")\n",
        "\n",
        "    # Print the report to the console\n",
        "    print(report_table)\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(report_table)\n",
        "        print(f\"Report saved to {output_file}\")\n",
        "\n",
        "rl_pairs = create_rl_pairs()\n",
        "# Run the experiment\n",
        "import time\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING before running the experiment loop\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Enable synchronous CUDA operations\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'  # Enable device-side assertions\n",
        "\n",
        "agents = []\n",
        "training_args_list = []\n",
        "state_list = []\n",
        "control_list = []\n",
        "experiment_names = []\n",
        "\n",
        "for dataset_name, model_id, config in rl_pairs:\n",
        "    clear_memory()\n",
        "    print(\"\\n\")\n",
        "    print(f\"Running experiment with:\")\n",
        "    print(f\"- Dataset: {dataset_name}\")\n",
        "    print(f\"- Model: {model_id}\")\n",
        "    print(f\"- Config: {config}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    try:\n",
        "        agent = FineTuningAgent(model_id, dataset_name, config)\n",
        "        agents.append(agent) # Append the agent to the list immediately\n",
        "        agent.start_time = time.time()\n",
        "        agent.run()\n",
        "        agent.end_time = time.time()\n",
        "        # Collect training details after training\n",
        "        if agent.trainer is not None:\n",
        "          # Store experiment name and other relevant data\n",
        "            experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "            experiment_names.append(experiment_name)\n",
        "            # agents.append(agent) # Removed, agent has already been appended above\n",
        "            training_args_list.append(agent.training_args)\n",
        "            state_list.append(agent.trainer.state)\n",
        "            control_list.append(agent.trainer.control)\n",
        "        else:  # Append dummy values if training failed\n",
        "            training_args_list.append(None)  # or a suitable placeholder\n",
        "            state_list.append(None)\n",
        "            control_list.append(None)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the experiment: {e}\")\n",
        "        agent.end_time = time.time()\n",
        "        agent.start_time = time.time()\n",
        "        training_args_list.append(None)  # or a suitable placeholder\n",
        "        state_list.append(None)\n",
        "        control_list.append(None)\n",
        "\n",
        "# Call generate_report outside the loop, after all experiments are done\n",
        "#generate_report(rl_pairs, agents, training_args_list, state_list, control_list, experiment_name=experiment_names)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "52f60aa0acf6484383a282710a9865c3",
            "0abb72641a3447cebc187135e89c3bdd",
            "4bc0885f011f4f55b50009451638243e",
            "7e182502a5734ead8f46c92f33cdb0b2",
            "902321570a754a16b27bc28afeb291c8",
            "8688751f2a2749849402880ff9e99901",
            "e3b8b79a5c3a40deb40aff5d362fd1df",
            "7445749a05c14880b7d06b5e02a85192",
            "3825663f6ca94f07be352678df449d88",
            "86b846f862934aa6af9a7b2c55456254",
            "d39f82b2881946f7999b5452b2c03a38",
            "7b10c874b6744f528e6c2c1d81e79936",
            "ac85140f880a448fb4565c1c8c2a26b7",
            "ad82f2cc225748e1a4015edaf6c687ce",
            "8068779ae5cf4bea9ccef6a5486558ad",
            "251039d198bf4ecda3806ec82889c5da",
            "2aa721c3107e4dd19af28b4b80d63433",
            "4bd98318bbbd4d55b034de4457759d88",
            "f33df69489da43a3b715bf73e71d1eb8",
            "b3e722fa396344c7b00e4d708c37edf7",
            "214d7b8ae93f4af295438e95463e30c2",
            "a227aff5de3843a38efd8721cb0042b8",
            "115b4ec93800471980b9b3de7753968a",
            "efbe4ad58cfe47dcbf772b6ba4fc74e2",
            "96199e7dd0df41fc87bbd6fafe89e9dd",
            "319df48eb674405d96ff22432d110225",
            "c2b85750f51a4e0cb0bd5fea80a02bdb",
            "6f89371f769343ee87f3363a28390882",
            "ae492b6a41334b3ca95b5bd1618d21f2",
            "092445eea777428db6841b4ee556b0fa",
            "da4533fb12d942098cc96fdf7a6612ce",
            "b8a652745ad74623864ba3903af70c2c",
            "c5166250e4ed4dad96ed5a607bf6cc0c",
            "0f05cdfcc5ce46cb9db5ec3d7b2b9fdb",
            "3a30f39f18ef43b9a9a86d6d44c5dbb2",
            "337cbabbc3b64954aad7bc60d505a676",
            "b5d79256812f430e8e4f574fd5be12b4",
            "d6d808908f294be084a66ea5facdc3d4",
            "cb64257c5c994d5ebd643f9659353778",
            "023133cbbabf4e07954298e73ac9d311",
            "6f4fc3de0ae8494eb4bd2b496d59c160",
            "34abe986d79e4ad49577be5623f2160b",
            "f891d49f3cd54315bb96852e73472c26",
            "1f40101ed06f424aba3535c8edf6aff4",
            "2d5fc61d05e4483787e1eeed9764da87",
            "b4bada63d12a4a129151f2886c9c4f48",
            "71ef104c25df4630b92c3be3a9c258fd",
            "873e59770b0d4fa0b17e102b0d00a691",
            "41419597ff0243ceaf040c40e12a40e1",
            "7324b60ad3ab415fb11c8817a3478ee7",
            "4559aefab0a8472f89bdfabb5f6d926f",
            "646b76dc6b1943729d88bbc222e73b0f",
            "97da478be4074ad9b43f257b887382d6",
            "c7d48581075c4b30befa3cc610a15303",
            "509dbbaa2cdf4f47abb3acc0f261ce79",
            "3348f4fa63bd45919efb7de918480913",
            "e8dbdee27ebf4564931dc6ed49b77d6e",
            "6002586ed29f491194f307dd232ff801",
            "4397bad9556d48b885a5b3f2698844c8",
            "5234ba242b22475f91d5ca3862fe5d8e",
            "fca4fb76803141ef9d8dae1762675719",
            "c75c98031d1a450bb4a875dc7714860e",
            "c3487a7344f7494ab122ac699c812179",
            "61ca5ee92ef149249f2cb5aea11c5e76",
            "8fdc972dc0c5416abd87812cf2696847",
            "0b1ebee4d8374559a49bae4f89cc0e7c",
            "1877dea9734c4377a03062805fd7e023",
            "c46999b8f1ce445fbc23f9d2db31b65e",
            "eadf513710d540459f80a352e7f8602e",
            "73203418ed004f91b7cefbf1b9ea912e",
            "ad2e844aaf4c495f9dc1c97690e9354b",
            "d51872d63928446185dae86d4eed811c",
            "f6c3ad5e7fa74aafb65bc8535e1079ed",
            "0ea71a0f3cb04e84b9401b05909e02e9",
            "67a2ef3e02e84356b3e4b7e08b594e45",
            "fa08a3b93e5341b0baf2a5689dce7380",
            "be906df436114e6eaa65ad0e1f5eddeb",
            "dadc337a577c45c29565506943c28a34",
            "34715483900e403fbc5b57fe9d836385",
            "2c183521d2f6491a83759d8974199fac",
            "a0e65b270cf64cfab4aa50d22834c202",
            "b416a7f2a9ab46479929328ba889ae36",
            "db955a45657d4d80b88d0ccd284799be",
            "52cfac5b9696462d9439e358de8126eb",
            "cc36cf6b5b9d4c13b79cc2eceaeb63e9",
            "81e8ecfb5f104dc8a6ef209bc9ee76a6",
            "88b0f284fb2b4a858ff6bb3d218f8d30",
            "92a9330a62a445c0b22d82cf8d149571",
            "20c4cd4f18144654ab668c91bd24506e",
            "b36a67ce04c7487badf515524e1b6bff",
            "5cf1e9a684e7443db11cf06800e51eb6",
            "c385087424d744f68825eb7801d04be2",
            "34613a13deae47eea075e416fe30e8fa",
            "5c15270a0e1b459bb9a5c08fb22fde0f",
            "399d38c5e7154f5db11d63dbbad9e3e4",
            "eda200d211334c17a38ffb0f10fae650",
            "3656fdfa546f4023b3e780419e876ebc",
            "5bce925d8c6845f3b531cf2338e9a1ea",
            "48e060aaa33e4194ade48c89bbda79b9"
          ]
        },
        "id": "RemE3xmbN-Af",
        "outputId": "3165e0a0-aab5-4925-8228-c87c2bd5a277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: anthropic/hh-rlhf\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Config: {'max_length': 32, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 8, 'warmup_steps': 5, 'num_train_epochs': 5, 'max_steps': 250, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20, 'evaluation_strategy': 'steps', 'logging_strategy': 'steps', 'load_best_model_at_end': True, 'metric_for_best_model': 'eval_loss'}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n",
            "Starting Observe ...\n",
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f60aa0acf6484383a282710a9865c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b10c874b6744f528e6c2c1d81e79936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "115b4ec93800471980b9b3de7753968a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f05cdfcc5ce46cb9db5ec3d7b2b9fdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d5fc61d05e4483787e1eeed9764da87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3348f4fa63bd45919efb7de918480913"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1877dea9734c4377a03062805fd7e023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Observe finished.\n",
            "Function _observe took 34.9509 seconds to execute\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "Dataset: anthropic/hh-rlhf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dadc337a577c45c29565506943c28a34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: anthropic/hh-rlhf\n",
            "Function _preprocess_function_anthropic_hh_rlhf took 0.0457 seconds to execute\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20c4cd4f18144654ab668c91bd24506e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: anthropic/hh-rlhf\n",
            "Function _preprocess_function_anthropic_hh_rlhf took 0.0127 seconds to execute\n",
            "\n",
            "\n",
            "Orient Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "Function _orient took 230.4316 seconds to execute\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 671,088,640 || all params: 7,919,112,192 || trainable%: 8.4743\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "Function _decide took 7.5291 seconds to execute\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "Dataset preprocessed successfully.\n",
            "\n",
            "\n",
            "Unsloth data collator used.\n",
            "Initializing Trainer...\n",
            "\n",
            "\n",
            "Act finished.\n",
            "Function _act took 0.4133 seconds to execute\n",
            "\n",
            "\n",
            "Run Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='41' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 41/250 07:50 < 42:01, 0.08 it/s, Epoch 10/84]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>F1</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Perplexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.888700</td>\n",
              "      <td>1.987003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>2.226563</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>{'precision': 0.5113704653791341, 'recall': 0.4991644306845545, 'fmeasure': 0.5046815518958937}</td>\n",
              "      <td>{'precision': 0.1809724272975047, 'recall': 0.1767966826700169, 'fmeasure': 0.17863461829387023}</td>\n",
              "      <td>{'precision': 0.4690161303436845, 'recall': 0.4574117155634183, 'fmeasure': 0.4626614357705145}</td>\n",
              "      <td>9.278738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm report"
      ],
      "metadata": {
        "id": "BRmauENT7tWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Used to securely store your API key\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')  # Replace 'GEMINI' with your actual userdata variable name\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "from tabulate import tabulate\n",
        "from transformers import TrainingArguments, TrainerState, TrainerControl\n",
        "\n",
        "def generate_llm_report(\n",
        "    rl_pairs,\n",
        "    agents,\n",
        "    training_args_list,\n",
        "    state_list,\n",
        "    control_list,\n",
        "    output_file=\"experiment_report.txt\",\n",
        "    experiment_name=None,\n",
        "    prompt=\"You are a helpful data science expert.\\nPlease, make an additional analysis of this Fine-Tuning experiment report.\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates a report for multiple LLM experiments, including evaluation scores and training details,\n",
        "    and provides an analysis using Google Gemini.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): A list of tuples, each containing (dataset_name, model_id, config).\n",
        "        agents (list): A list of FineTuningAgent objects corresponding to the experiments.\n",
        "        training_args_list (list): A list of TrainingArguments objects for each experiment.\n",
        "        state_list (list): A list of TrainerState objects for each experiment.\n",
        "        control_list (list): A list of TrainerControl objects for each experiment.\n",
        "        output_file (str): The name of the output file to save the report.\n",
        "        experiment_name (str, optional): The base name for the experiment results file.\n",
        "                                        If provided, it will be used to load the results. Defaults to None.\n",
        "        prompt (str, optional): The prompt to provide to Google Gemini for analysis.\n",
        "                                Defaults to a generic data science expert prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    if not (\n",
        "        len(rl_pairs)\n",
        "        == len(agents)\n",
        "        == len(training_args_list)\n",
        "        == len(state_list)\n",
        "        == len(control_list)\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"The number of rl_pairs, agents, training_args, state, and control must be the same.\"\n",
        "        )\n",
        "\n",
        "    report_data = []  # Initialize report_data here\n",
        "\n",
        "    for (\n",
        "        (dataset_name, model_id, config),\n",
        "        agent,\n",
        "        training_args,\n",
        "        state,\n",
        "        control,\n",
        "    ) in zip(rl_pairs, agents, training_args_list, state_list, control_list):\n",
        "        # Get eval_results from the agent\n",
        "\n",
        "        #print(f\"Model ID: {model_id}\")\n",
        "\n",
        "        experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "\n",
        "        results_file = f\"{experiment_name}_results.txt\"\n",
        "        #print(f\"Results File: {results_file}\")\n",
        "\n",
        "\n",
        "        from pathlib import Path\n",
        "        # Define the file path\n",
        "        file_path = Path(results_file)\n",
        "\n",
        "        if file_path.exists():\n",
        "            #print(\"File exists!\")\n",
        "            #print(f\"Results File: {results_file}\")\n",
        "            print\n",
        "            #return\n",
        "        else:\n",
        "            #print(\"File does not exist.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        training_args=agent.training_args\n",
        "\n",
        "        experiment_name = f\"\"\"{model_id.replace('/', '-').replace(\"'\", '')}_{dataset_name.replace('/', '-').replace(\"'\", '')}\"\"\"\n",
        "        #print(f\"Experiment Name: {experiment_name}\")\n",
        "\n",
        "        results_file = f\"{experiment_name}_results.txt\"\n",
        "        #print(f\"Results File: {results_file}\")\n",
        "\n",
        "        print(training_args_list)\n",
        "\n",
        "\n",
        "        # \"eval_loss\": 6.17133903503418, \"eval_bleu\": 0, \"eval_f1\": 0.0, \"eval_runtime\": 4.0188, \"eval_samples_per_second\": 6.221, \"eval_steps_per_second\": 0.995, \"epoch\": 8.64}\n",
        "\n",
        "        try:\n",
        "            with open(results_file, \"r\") as f:\n",
        "                evaluation_results = json.load(f)\n",
        "            bleu_score = evaluation_results.get(\"eval_bleu\")\n",
        "            f1_score = evaluation_results.get(\"eval_f1\")\n",
        "            print(f\"BLEU Score: {bleu_score}, F1 Score: {f1_score}\")\n",
        "            #print(f\"Eval Results: {evaluation_result}\")\n",
        "\n",
        "             # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "            rouge1_precision = evaluation_results.get('eval_rouge1', {}).get('precision')\n",
        "            rouge1_recall = evaluation_results.get('eval_rouge1', {}).get('recall')\n",
        "            rouge1_fmeasure = evaluation_results.get('eval_rouge1', {}).get('fmeasure')\n",
        "            print(f\"ROUGE-1 Precision: {rouge1_precision}, Recall: {rouge1_recall}, F-measure: {rouge1_fmeasure}\")\n",
        "\n",
        "            # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "\n",
        "\n",
        "            rouge2_precision = evaluation_results.get('eval_rouge2', {}).get('precision')\n",
        "            rouge2_recall = evaluation_results.get('eval_rouge2', {}).get('recall')\n",
        "            rouge2_fmeasure = evaluation_results.get('eval_rouge2', {}).get('fmeasure')\n",
        "\n",
        "\n",
        "            # Accessing elements of the ROUGE score tuple (assuming it's a tuple with precision, recall, fmeasure)\n",
        "            rougeL_precision = evaluation_results.get('eval_rougeL', {}).get('precision')\n",
        "            rougeL_recall = evaluation_results.get('eval_rougeL', {}).get('recall')\n",
        "            rougeL_fmeasure = evaluation_results.get('eval_rougeL', {}).get('fmeasure')\n",
        "\n",
        "\n",
        "           # {\"eval_loss\": 3.720398187637329, \"eval_bleu\": 0, \"eval_f1\": 0.0, \"eval_rouge1\": {\"precision\": 0.396081703619663, \"recall\": 0.40836230306837384, \"fmeasure\": 0.40190438521178246}, \"eval_rouge2\": {\"precision\": 0.07832895449176241, \"recall\": 0.08075765617251687, \"fmeasure\": 0.07946492337001675}, \"eval_rougeL\": {\"precision\": 0.3623965364533813, \"recall\": 0.37335556072231263, \"fmeasure\": 0.3675868060434595},\n",
        "            #\"eval_perplexity\": 45.677459716796875, \"eval_runtime\": 1.1153, \"eval_samples_per_second\": 22.415, \"eval_steps_per_second\": 3.586, \"epoch\": 62.64}\n",
        "\n",
        "            perplexity = evaluation_results.get(\"eval_perplexity\", \"N/A\")\n",
        "            print(f\"Perplexity: {perplexity}\")\n",
        "\n",
        "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "            print(f\"Error loading results: {e}\")\n",
        "            bleu_score = None\n",
        "            f1_score = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Collect the data\n",
        "        elapsed_time = (\n",
        "            agent.end_time - agent.start_time\n",
        "            if agent.start_time and agent.end_time\n",
        "            else np.nan\n",
        "        )  # Handle potential errors\n",
        "        train_losses = agent.train_losses\n",
        "        eval_losses = agent.eval_losses\n",
        "\n",
        "        if not train_losses:\n",
        "            train_std = np.nan  # Use np.nan for no data\n",
        "            min_train_loss = np.nan\n",
        "            max_train_loss = np.nan\n",
        "        else:\n",
        "            print(f\"Train Losses: {train_losses}\")\n",
        "            train_loss = np.mean(train_losses)\n",
        "            train_loss_std = np.std(train_losses)\n",
        "            min_train_loss = np.min(train_losses)\n",
        "            max_train_loss = np.max(train_losses)\n",
        "\n",
        "        if not eval_losses:\n",
        "            eval_std = np.nan\n",
        "            min_eval_loss = np.nan\n",
        "            max_eval_loss = np.nan\n",
        "        else:\n",
        "            print(f\"Eval Losses: {eval_losses}\")\n",
        "            eval_loss = np.mean(eval_losses)\n",
        "            eval_loss_std = np.std(eval_losses)\n",
        "            min_eval_loss = np.min(eval_losses)\n",
        "            max_eval_loss = np.max(eval_losses)\n",
        "\n",
        "        # Check if training_args is None before accessing its attributes\n",
        "        learning_rate = training_args.learning_rate if training_args is not None else np.nan\n",
        "        batch_size = training_args.per_device_train_batch_size if training_args is not None else np.nan\n",
        "        epochs = training_args.num_train_epochs if training_args is not None and hasattr(training_args, \"num_train_epochs\") else \"n/a\"\n",
        "        print(f\"Learning Rate: {learning_rate}\")\n",
        "        print(f\"Batch Size: {batch_size}\")\n",
        "        print(f\"Epochs: {epochs}\")\n",
        "\n",
        "        report_data.append(\n",
        "            [\n",
        "                dataset_name,\n",
        "                model_id,\n",
        "                f\"{elapsed_time:.2f} seconds\",  # Format to 2 decimal places\n",
        "                f\"{train_loss:.4f}\" if train_loss is not None else \"N/A\",  # Handle None case for train_loss\n",
        "                f\"{eval_loss:.4f}\" if eval_loss is not None else \"N/A\",  # Handle None case for eval_loss\n",
        "\n",
        "                f\"{train_loss_std:.4f}\" if train_loss_std is not None else \"N/A\",  # Handle None case for train_loss_std\n",
        "                f\"{eval_loss_std:.4f}\" if eval_loss_std is not None else \"N/A\",  # Handle None case for eval_std\n",
        "\n",
        "                f\"{min_train_loss:.4f}\" if min_train_loss is not None else \"N/A\",  # Handle None case for min_train_loss\n",
        "                f\"{max_train_loss:.4f}\" if max_train_loss is not None else \"N/A\",  # Handle None case for max_train_loss\n",
        "\n",
        "                f\"{min_eval_loss:.4f}\" if min_eval_loss is not None else \"N/A\",  # Handle None case for min_eval_loss\n",
        "                f\"{max_eval_loss:.4f}\" if max_eval_loss is not None else \"N/A\",  # Handle None case for max_eval_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                f\"{bleu_score:.4f}\" if bleu_score is not None else \"N/A\",  # Handle None case for bleu_score\n",
        "                f\"{f1_score:.4f}\" if f1_score is not None else \"N/A\",  # Handle None case for f1_score\n",
        "\n",
        "                f\"{rouge1_precision:.4f}\" if rouge1_precision is not None else \"N/A\",  # Handle None case for rouge1_precision\n",
        "                f\"{rouge1_recall:.4f}\" if rouge1_recall is not None else \"N/A\",  # Handle None case for rouge1_recall\n",
        "                f\"{rouge1_fmeasure:.4f}\" if rouge1_fmeasure is not None else \"N/A\",  # Handle None case for rouge1_fmeasure\n",
        "\n",
        "                f\"{rouge2_precision:.4f}\" if rouge2_precision is not None else \"N/A\",  # Handle None case for rouge2_precision\n",
        "                f\"{rouge2_recall:.4f}\" if rouge2_recall is not None else \"N/A\",  # Handle None case for rouge2_recall\n",
        "                f\"{rouge2_fmeasure:.4f}\" if rouge2_fmeasure is not None else \"N/A\",  # Handle None case for rouge2_fmeasure\n",
        "\n",
        "                f\"{rougeL_precision:.4f}\" if rougeL_precision is not None else \"N/A\",  # Handle None case for rougeL_precision\n",
        "                f\"{rougeL_recall:.4f}\" if rougeL_recall is not None else \"N/A\",  # Handle None case for rougeL_recall\n",
        "                f\"{rougeL_fmeasure:.4f}\" if rougeL_fmeasure is not None else \"N/A\",  # Handle None case for rougeL_fmeasure\n",
        "\n",
        "                f\"{perplexity:.4f}\" if perplexity is not None else \"N/A\",  # Handle None case for perplexity\n",
        "\n",
        "                f\"{learning_rate:.4f}\" if learning_rate is not None else \"N/A\",  # Handle None case for learning_rate\n",
        "                f\"{batch_size}\" if batch_size is not None else \"N/A\",  # Handle None case for batch_size\n",
        "                f\"{epochs}\" if epochs is not None else \"N/A\",  # Handle None case for epochs\n",
        "\n",
        "                #f\"{state.global_step}\" if state is not None else \"N/A\",  # Handle None case for global_step\n",
        "                #f\"{state.epoch}\" if state is not None else \"N/A\",  # Handle None case for epoch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                #f\"{learning_rate:.4f}\",  # Learning rate\n",
        "                #batch_size,  # Batch size\n",
        "                #epochs,  # Epochs\n",
        "                #state.global_step if state else \"n/a\",  # Global steps\n",
        "                #state.epoch if state else \"n/a\",  # Epoch\n",
        "                #state.is_local_process_zero if state else \"n/a\",\n",
        "                #control.should_training_stop if control else \"n/a\",\n",
        "                #control.should_log if control else \"n/a\",\n",
        "               # control.should_save if control else \"n/a\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Generate the report table\n",
        "    headers = [\n",
        "        \"Dataset\",\n",
        "        \"Model\",\n",
        "        \"Elapsed Time\",\n",
        "        \"Train Loss (Average)\",\n",
        "        \"Eval Loss (Average)\",\n",
        "        \"Train Loss (Std)\",\n",
        "        \"Eval Loss (Std)\",\n",
        "        \"Min Train Loss\",\n",
        "        \"Max Train Loss\",\n",
        "        \"Min Eval Loss\",\n",
        "        \"Max Eval Loss\",\n",
        "        \"BLEU Score\",\n",
        "        \"F1 Score\",\n",
        "        \"ROUGE-1 Precision\",\n",
        "        \"ROUGE-1 Recall\",\n",
        "        \"ROUGE-1 F-measure\",\n",
        "        \"ROUGE-2 Precision\",\n",
        "        \"ROUGE-2 Recall\",\n",
        "        \"ROUGE-2 F-measure\",\n",
        "        \"ROUGE-L Precision\",\n",
        "        \"ROUGE-L Recall\",\n",
        "        \"ROUGE-L F-measure\",\n",
        "        \"Perplexity\",\n",
        "        \"Learning Rate\",\n",
        "        \"Batch Size\",\n",
        "        \"Epochs\",\n",
        "        \"Global Steps\",\n",
        "        \"Epoch\",\n",
        "        \"is_local_process_zero\",\n",
        "        \"should_training_stop\",\n",
        "        \"should_log\",\n",
        "        \"should_save\",\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    report_table = tabulate(report_data, headers=headers, tablefmt=\"grid\")\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(report_table)\n",
        "\n",
        "    print(report_table)\n",
        "\n",
        "    # LLM Analysis using Google Gemini\n",
        "    model_name = \"gemini-1.5-pro\"  # Replace with desired model\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    response = model.generate_content(prompt + \"\\n\\n\" + report_table)\n",
        "    llm_analysis = response.text\n",
        "\n",
        "    print(\"\\n\\n## LLM Analysis:\\n\")\n",
        "    print(llm_analysis)\n",
        "\n",
        "    #return llm_analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "-smf04UA0mnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the LLM report and send to Gemini\n",
        "prompt = \"\"\"\n",
        "You are a helpful data science expert.\n",
        "Please, make an additional analysis of this Fine-Tuning experiment report.\n",
        "\"\"\"\n",
        "# Initialize training_args_list, state_list, control_list with empty lists\n",
        "training_args_list = [None] * len(rl_pairs)\n",
        "state_list = [None] * len(rl_pairs)\n",
        "control_list = [None] * len(rl_pairs)\n",
        "\n",
        "generate_llm_report(rl_pairs, agents, training_args_list, state_list, control_list, prompt=prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "zmcvPmYQgwvz",
        "outputId": "1ab7713d-4187-4bb2-b383-4214bdaaafc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None]\n",
            "BLEU Score: 0, F1 Score: 0.0\n",
            "ROUGE-1 Precision: 0.396081703619663, Recall: 0.40836230306837384, F-measure: 0.40190438521178246\n",
            "Perplexity: 45.677459716796875\n",
            "Train Losses: [2.252, 1.3595, 0.5566, 0.2696, 0.2246, 0.2156, 0.1887, 0.1934, 0.1851, 0.1813, 0.1768, 0.1711, 0.1755, 0.168, 0.1719, 0.1718, 0.166, 0.1625, 0.1708, 0.1765, 0.1591, 0.1641, 0.1611, 0.1642, 0.1569]\n",
            "Eval Losses: [2.2944350242614746, 2.939926862716675, 3.2473931312561035, 3.44758677482605, 3.519420862197876, 3.6173152923583984, 3.673027753829956, 3.651576280593872, 3.6940383911132812, 3.679342746734619, 3.6730434894561768, 3.710360050201416, 3.720398187637329]\n",
            "Learning Rate: 0.0002\n",
            "Batch Size: 4\n",
            "Epochs: 3.0\n",
            "+-------------------+--------------------------------------+-----------------+------------------------+-----------------------+--------------------+-------------------+------------------+------------------+-----------------+-----------------+--------------+------------+---------------------+------------------+---------------------+---------------------+------------------+---------------------+---------------------+------------------+---------------------+--------------+-----------------+--------------+----------+\n",
            "| Dataset           | Model                                | Elapsed Time    |   Train Loss (Average) |   Eval Loss (Average) |   Train Loss (Std) |   Eval Loss (Std) |   Min Train Loss |   Max Train Loss |   Min Eval Loss |   Max Eval Loss |   BLEU Score |   F1 Score |   ROUGE-1 Precision |   ROUGE-1 Recall |   ROUGE-1 F-measure |   ROUGE-2 Precision |   ROUGE-2 Recall |   ROUGE-2 F-measure |   ROUGE-L Precision |   ROUGE-L Recall |   ROUGE-L F-measure |   Perplexity |   Learning Rate |   Batch Size |   Epochs |\n",
            "+===================+======================================+=================+========================+=======================+====================+===================+==================+==================+=================+=================+==============+============+=====================+==================+=====================+=====================+==================+=====================+=====================+==================+=====================+==============+=================+==============+==========+\n",
            "| anthropic/hh-rlhf | deepseek-ai/deepseek-coder-1.3b-base | 1403.81 seconds |                 0.3257 |                3.4514 |             0.4609 |            0.3983 |           0.1569 |            2.252 |          2.2944 |          3.7204 |            0 |          0 |              0.3961 |           0.4084 |              0.4019 |              0.0783 |           0.0808 |              0.0795 |              0.3624 |           0.3734 |              0.3676 |      45.6775 |          0.0002 |            4 |        3 |\n",
            "+-------------------+--------------------------------------+-----------------+------------------------+-----------------------+--------------------+-------------------+------------------+------------------+-----------------+-----------------+--------------+------------+---------------------+------------------+---------------------+---------------------+------------------+---------------------+---------------------+------------------+---------------------+--------------+-----------------+--------------+----------+\n",
            "\n",
            "\n",
            "## LLM Analysis:\n",
            "\n",
            "The fine-tuning experiment results you provided show some potential issues that need to be addressed.  Here's a breakdown of the analysis:\n",
            "\n",
            "**Key Concerns:**\n",
            "\n",
            "* **High Eval Loss & Low Metrics:** The evaluation loss (3.4514) is significantly higher than the training loss (0.3257). This, coupled with very low or zero values for BLEU, F1, ROUGE scores, indicates the model is severely overfitting to the training data and generalizing poorly to unseen data.  It's essentially memorizing the training set rather than learning underlying patterns.\n",
            "\n",
            "* **Potential Data Issues:** The discrepancy between training and evaluation loss suggests a mismatch between the training and evaluation datasets.  They might have different distributions or the evaluation set might be too small or not representative of the target task.\n",
            "\n",
            "* **High Train Loss Standard Deviation:** The high standard deviation for training loss (0.4609) indicates instability during training.  The loss is fluctuating considerably across batches, which can hinder convergence to a good minimum.\n",
            "\n",
            "* **Hyperparameter Tuning Needed:**  The chosen hyperparameters might not be optimal for this model and dataset.  The learning rate, batch size, and number of epochs may need adjustment.\n",
            "\n",
            "**Recommendations and Further Analysis:**\n",
            "\n",
            "1. **Dataset Examination:** Carefully analyze the training and evaluation datasets. Ensure they are properly preprocessed, representative of the target task, and have similar distributions. Consider increasing the size of the evaluation set if it's too small.  Stratified sampling can help ensure a balanced representation of different data characteristics in both sets.\n",
            "\n",
            "2. **Hyperparameter Optimization:** Experiment with different learning rates. A lower learning rate might help stabilize training and improve generalization.  Also, explore different batch sizes. Smaller batches can sometimes improve performance, but also increase training time.  Three epochs might be insufficient for convergence. Consider increasing the number of epochs while monitoring the evaluation loss for signs of overfitting.\n",
            "\n",
            "3. **Regularization Techniques:** Implement regularization methods like dropout or weight decay to combat overfitting. These techniques discourage the model from relying too heavily on individual training examples.\n",
            "\n",
            "4. **Curriculum Learning:** Consider curriculum learning, which involves gradually increasing the complexity of the training data presented to the model.  This can sometimes help improve learning and generalization.\n",
            "\n",
            "5. **Model Selection:** If the issue persists, consider trying a different pre-trained model.  The current model (`deepseek-ai/deepseek-coder-1.3b-base`) might not be well-suited for the specific task.\n",
            "\n",
            "6. **Early Stopping:** Implement early stopping based on the evaluation loss.  This will stop training when the model starts to overfit, preventing further degradation of performance on unseen data.\n",
            "\n",
            "7. **Debugging Training Dynamics:** Monitor training loss and evaluation loss curves closely.  Look for patterns that might indicate problems like exploding gradients or vanishing gradients.  Tools like TensorBoard can be helpful for visualization.\n",
            "\n",
            "8. **More Informative Metrics:**  While the provided metrics are valuable, consider adding other metrics relevant to code generation, like code accuracy or execution accuracy, if applicable.\n",
            "\n",
            "By addressing these points and carefully analyzing the results of each experiment, you should be able to significantly improve the performance of your fine-tuned model. Remember to keep track of all your experiments and changes to facilitate analysis and comparison.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}