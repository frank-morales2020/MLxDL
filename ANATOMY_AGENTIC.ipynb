{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPqn9k7lc8wxi/RIPSbZhcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/ANATOMY_AGENTIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"DB-BOB-MVP-AGENT-DEMO-PROTO.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1hfpcZJWMBzZ1S6CS-UKfHqXer1E08wD_\n",
        "\n",
        "## libraries\n",
        "\"\"\"\n",
        "\n",
        "## libraries  --- Installation ---\n",
        "\n",
        "!pip install flask -q\n",
        "!pip install flask_migrate -q\n",
        "!pip install flask_sqlalchemy -q\n",
        "!pip install anthropic -q\n",
        "!pip install colab-env --quiet\n",
        "!pip install flask_cors -q\n",
        "\n",
        "\n",
        "\n",
        "!pip install flask_ngrok -q\n",
        "!pip install pyngrok -q  # Install pyngrok directly\n",
        "!pip install --upgrade flask_ngrok pyngrok -q\n",
        "!pip install flask_login -q\n",
        "\n",
        "!pip install Flask-Login -q\n",
        "\n",
        "\n",
        "!pip install flask_login -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-ZuWr6uL7Em",
        "outputId": "8573ed6a-59ad-4b55-e693-e87e91dc134b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Flask and pyngrok\n",
        "!pip install Flask pyngrok -q\n",
        "!pip install colab-env -q"
      ],
      "metadata": {
        "id": "rXNLN34pvV9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template_string, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import threading\n",
        "import time # Import time for a small delay\n",
        "import colab_env # Import colab_env for environment variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PffrJ3D-VbA",
        "outputId": "3aafe162-5a7b-4c3e-88c7-931ad1b13146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template_string, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "import socket # To find a free port if needed\n",
        "\n",
        "\n",
        "# --- Google Colab / Gemini API Imports and Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI configured successfully using Colab Secrets.\")\n",
        "except ImportError:\n",
        "    print(\"Not running in Google Colab. Attempting to get 'GEMINI' environment variable.\")\n",
        "    GOOGLE_API_KEY = os.getenv('GEMINI')\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(\"GEMINI API Key not found. Please set it as an environment variable or Colab Secret.\")\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI configured successfully using environment variable.\")\n",
        "\n",
        "# --- Configuration for Agent ---\n",
        "class AgentConfig:\n",
        "    LLM_MODEL_NAME: str = \"gemini-1.5-flash\" # Set the desired Gemini model\n",
        "\n",
        "# Define the HTML content as a Python string.\n",
        "HTML_CONTENT = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Agentic AI Anatomy Demo</title>\n",
        "    <!-- Tailwind CSS CDN -->\n",
        "    <script src=\"https://cdn.tailwindcss.com\"></script>\n",
        "    <!-- Inter Font -->\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap\" rel=\"stylesheet\">\n",
        "    <!-- React, ReactDOM, and Babel CDNs for in-browser JSX compilation -->\n",
        "    <script src=\"https://unpkg.com/react@18/umd/react.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/react-dom@18/umd/react-dom.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"></script>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: 'Inter', sans-serif;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"root\"></div>\n",
        "\n",
        "    <script type=\"text/babel\">\n",
        "        // React App Component\n",
        "        const App = () => {\n",
        "            const [status, setStatus] = React.useState('Idle');\n",
        "            const [currentPerception, setCurrentPerception] = React.useState('');\n",
        "            const [memoryContent, setMemoryContent] = React.useState([]);\n",
        "            const [reasoningOutput, setReasoningOutput] = React.useState('');\n",
        "            const [actionTaken, setActionTaken] = React.useState('');\n",
        "            const [learningUpdate, setLearningUpdate] = React.useState('');\n",
        "            const [loopRunning, setLoopRunning] = React.useState(false);\n",
        "            const intervalRef = React.useRef(null);\n",
        "\n",
        "            const perceptions = [\n",
        "                \"Summarize a flight plan for a trip from Montreal to Paris, focusing on key milestones and considerations.\",\n",
        "                \"Generate a short story about an AI agent that learns to appreciate art.\",\n",
        "                \"Explain the concept of quantum entanglement in simple terms.\",\n",
        "                \"Describe the ideal environment for growing tomatoes.\",\n",
        "                \"Provide a recipe for a healthy vegan dinner.\"\n",
        "            ];\n",
        "\n",
        "            React.useEffect(() => {\n",
        "                if (loopRunning) {\n",
        "                    intervalRef.current = setInterval(() => {\n",
        "                        runAgentLoop();\n",
        "                    }, 5000);\n",
        "                } else {\n",
        "                    clearInterval(intervalRef.current);\n",
        "                }\n",
        "                return () => clearInterval(intervalRef.current);\n",
        "            }, [loopRunning]);\n",
        "\n",
        "            const runAgentLoop = async () => {\n",
        "                setStatus('Perceiving...');\n",
        "                const newPerception = perceptions[Math.floor(Math.random() * perceptions.length)];\n",
        "                setCurrentPerception(newPerception);\n",
        "\n",
        "                setTimeout(() => {\n",
        "                    setStatus('Recalling Memory...');\n",
        "                    setMemoryContent(prev => {\n",
        "                        const updatedMemory = [...prev, `[${new Date().toLocaleTimeString()}] Perceived: ${newPerception}`];\n",
        "                        return updatedMemory.slice(-5);\n",
        "                    });\n",
        "\n",
        "                    setTimeout(async () => {\n",
        "                        setStatus('Reasoning & Planning (via Gemini 1.5 Flash API)...');\n",
        "                        setReasoningOutput('Contacting AI...');\n",
        "                        setActionTaken('Waiting for AI response...');\n",
        "\n",
        "                        try {\n",
        "                            const response = await fetch('/api/reason', {\n",
        "                                method: 'POST',\n",
        "                                headers: {\n",
        "                                    'Content-Type': 'application/json',\n",
        "                                },\n",
        "                                body: JSON.stringify({ prompt: newPerception }),\n",
        "                            });\n",
        "\n",
        "                            const result = await response.json();\n",
        "\n",
        "                            if (response.ok) {\n",
        "                                const aiResponse = result.response;\n",
        "                                const displayResponse = typeof aiResponse === 'string' ? aiResponse.substring(0, 100) : JSON.stringify(aiResponse).substring(0, 100);\n",
        "                                const displayAction = typeof aiResponse === 'string' ? aiResponse.substring(0, 50) : JSON.stringify(aiResponse).substring(0, 50);\n",
        "\n",
        "                                setReasoningOutput(`AI analyzed: \"${newPerception}\". AI Response: ${displayResponse}...`);\n",
        "                                setActionTaken(`AI generated a detailed response. Ready to act based on this: \"${displayAction}...\"`);\n",
        "                            } else {\n",
        "                                setReasoningOutput(`AI reasoning failed: ${result.error}`);\n",
        "                                setActionTaken(`Failed to get AI action.`);\n",
        "                            }\n",
        "                        } catch (error) {\n",
        "                            setReasoningOutput(`Error during AI reasoning: ${error.message}`);\n",
        "                            setActionTaken(`Action failed due to error.`);\n",
        "                        }\n",
        "\n",
        "                        setTimeout(() => {\n",
        "                            setStatus('Executing Action...');\n",
        "                            setTimeout(() => {\n",
        "                                setStatus('Learning & Adapting...');\n",
        "                                const learningFeedback = `Learned from processing \"${newPerception}\" and integrating AI reasoning.`;\n",
        "                                setLearningUpdate(learningFeedback);\n",
        "                                setTimeout(() => {\n",
        "                                    setStatus('Idle (Ready for next cycle)');\n",
        "                                }, 1000);\n",
        "                            }, 1000);\n",
        "                        }, 1000);\n",
        "                    }, 1000);\n",
        "                }, 1000);\n",
        "            };\n",
        "\n",
        "            const toggleLoop = () => {\n",
        "                setLoopRunning(prev => !prev);\n",
        "                if (loopRunning) {\n",
        "                    setCurrentPerception('');\n",
        "                    setMemoryContent([]);\n",
        "                    setReasoningOutput('');\n",
        "                    setActionTaken('');\n",
        "                    setLearningUpdate('');\n",
        "                    setStatus('Idle');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            return (\n",
        "                <div className=\"min-h-screen bg-gradient-to-br from-indigo-500 via-purple-600 to-pink-500 text-white p-6 font-inter flex flex-col items-center\">\n",
        "                    <h1 className=\"text-4xl font-bold mb-8 text-center drop-shadow-lg\">\n",
        "                        Agentic AI Anatomy Demo\n",
        "                    </h1>\n",
        "                    <h2 className=\"text-2xl font-semibold mb-8 text-center text-purple-200\">\n",
        "                        A Gemini 1.5 Flash Perspective (with API Integration)\n",
        "                    </h2>\n",
        "\n",
        "                    {/* Control Buttons */}\n",
        "                    <div className=\"flex space-x-4 mb-8\">\n",
        "                        <button\n",
        "                            onClick={toggleLoop}\n",
        "                            className={`px-8 py-3 rounded-full font-bold text-lg transition-all duration-300 ease-in-out transform hover:scale-105 shadow-lg\n",
        "                                ${loopRunning ? 'bg-red-600 hover:bg-red-700' : 'bg-green-500 hover:bg-green-600'}`}\n",
        "                        >\n",
        "                            {loopRunning ? 'Stop Agent' : 'Start Agent'}\n",
        "                        </button>\n",
        "                        <button\n",
        "                            onClick={() => runAgentLoop()}\n",
        "                            disabled={loopRunning}\n",
        "                            className=\"px-8 py-3 rounded-full font-bold text-lg bg-blue-500 hover:bg-blue-600 transition-all duration-300 ease-in-out transform hover:scale-105 shadow-lg disabled:opacity-50 disabled:cursor-not-allowed\"\n",
        "                        >\n",
        "                            Run One Cycle\n",
        "                        </button>\n",
        "                    </div>\n",
        "\n",
        "                    {/* Agent Status */}\n",
        "                    <div className=\"bg-gradient-to-r from-purple-800 to-indigo-800 p-4 rounded-xl shadow-2xl mb-8 w-full max-w-2xl text-center\">\n",
        "                        <p className=\"text-xl font-semibold\">Agent Status: <span className=\"text-yellow-300\">{status}</span></p>\n",
        "                    </div>\n",
        "\n",
        "                    {/* Anatomy Components */}\n",
        "                    <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6 w-full max-w-4xl\">\n",
        "                        {/* Perception */}\n",
        "                        <div className=\"bg-white bg-opacity-10 p-5 rounded-xl shadow-xl border border-purple-400 flex flex-col\">\n",
        "                            <h3 className=\"text-xl font-bold mb-3 text-purple-200\">1. Perception & Sensing</h3>\n",
        "                            <div className=\"bg-gray-800 bg-opacity-70 text-green-300 p-4 rounded-lg flex-grow flex items-center justify-center text-center\">\n",
        "                                <p className=\"font-mono text-lg\">{currentPerception || 'Awaiting input...'}</p>\n",
        "                            </div>\n",
        "                        </div>\n",
        "\n",
        "                        {/* Memory */}\n",
        "                        <div className=\"bg-white bg-opacity-10 p-5 rounded-xl shadow-xl border border-purple-400 flex flex-col\">\n",
        "                            <h3 className=\"text-xl font-bold mb-3 text-purple-200\">2. Memory & Knowledge</h3>\n",
        "                            <div className=\"bg-gray-800 bg-opacity-70 text-blue-300 p-4 rounded-lg overflow-y-auto h-32\">\n",
        "                                {memoryContent.length > 0 ? (\n",
        "                                    memoryContent.map((item, index) => (\n",
        "                                        <p key={index} className=\"font-mono text-sm mb-1\">{item}</p>\n",
        "                                    ))\n",
        "                                ) : (\n",
        "                                    <p className=\"font-mono text-sm text-center italic\">Memory is clear...</p>\n",
        "                                )}\n",
        "                            </div>\n",
        "                        </div>\n",
        "\n",
        "                        {/* Reasoning */}\n",
        "                        <div className=\"bg-white bg-opacity-10 p-5 rounded-xl shadow-xl border border-purple-400 flex flex-col\">\n",
        "                            <h3 className=\"text-xl font-bold mb-3 text-purple-200\">3. Reasoning & Decision-Making</h3>\n",
        "                            <div className=\"bg-gray-800 bg-opacity-70 text-orange-300 p-4 rounded-lg flex-grow flex items-center justify-center text-center\">\n",
        "                                <p className=\"font-mono text-lg\">{reasoningOutput || 'Analyzing input...'}</p>\n",
        "                            </div>\n",
        "                        </div>\n",
        "\n",
        "                        {/* Action */}\n",
        "                        <div className=\"bg-white bg-opacity-10 p-5 rounded-xl shadow-xl border border-purple-400 flex flex-col\">\n",
        "                            <h3 className=\"text-xl font-bold mb-3 text-purple-200\">4. Action & Execution</h3>\n",
        "                            <div className=\"bg-gray-800 bg-opacity-70 text-red-300 p-4 rounded-lg flex-grow flex items-center justify-center text-center\">\n",
        "                                <p className=\"font-mono text-lg\">{actionTaken || 'Awaiting decision...'}</p>\n",
        "                            </div>\n",
        "                        </div>\n",
        "\n",
        "                        {/* Learning */}\n",
        "                        <div className=\"col-span-1 md:col-span-2 bg-white bg-opacity-10 p-5 rounded-xl shadow-xl border border-purple-400 flex flex-col\">\n",
        "                            <h3 className=\"text-xl font-bold mb-3 text-purple-200\">5. Learning & Adaptation</h3>\n",
        "                            <div className=\"bg-gray-800 bg-opacity-70 text-cyan-300 p-4 rounded-lg flex-grow flex items-center justify-center text-center\">\n",
        "                                <p className=\"font-mono text-lg\">{learningUpdate || 'Adapting and improving...'}</p>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "\n",
        "                    <p className=\"mt-8 text-sm text-gray-300 text-center\">\n",
        "                        This demo simulates a simplified agentic loop: perceive, store in memory, reason, act, and learn.\n",
        "                        The 'Reasoning' step now integrates with the Gemini API via the Flask backend for more dynamic responses.\n",
        "                    </p>\n",
        "                </div>\n",
        "            );\n",
        "        };\n",
        "\n",
        "        // Mount the React App\n",
        "        const container = document.getElementById('root');\n",
        "        const root = ReactDOM.createRoot(container);\n",
        "        root.render(<App />);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Serves the main HTML content.\"\"\"\n",
        "    return render_template_string(HTML_CONTENT)\n",
        "\n",
        "@app.route('/api/reason', methods=['POST'])\n",
        "def reason():\n",
        "    \"\"\"\n",
        "    Handles reasoning requests by sending the prompt to the Gemini 1.5 Flash model\n",
        "    and returning its generated response.\n",
        "    \"\"\"\n",
        "    if not GOOGLE_API_KEY:\n",
        "        return jsonify({\"error\": \"Gemini API key not configured on the backend.\"}), 500\n",
        "\n",
        "    data = request.get_json()\n",
        "    prompt = data.get('prompt', 'Generate a general AI response.')\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel(AgentConfig.LLM_MODEL_NAME)\n",
        "        response = model.generate_content(prompt)\n",
        "        generated_text = \"\"\n",
        "        if response.parts:\n",
        "            generated_text = response.text\n",
        "        elif response.candidates and len(response.candidates) > 0 and response.candidates[0].content:\n",
        "             generated_text = response.candidates[0].content.parts[0].text\n",
        "        else:\n",
        "            generated_text = \"No text content found in Gemini response.\"\n",
        "        return jsonify({\"response\": generated_text})\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Gemini API: {e}\")\n",
        "        if \"safety\" in str(e).lower() or \"blocked\" in str(e).lower():\n",
        "            return jsonify({\"error\": f\"AI response blocked due to safety concerns or content policy. Please try a different prompt. Error: {e}\"}), 400\n",
        "        else:\n",
        "            return jsonify({\"error\": f\"Failed to get response from AI: {e}\"}), 500\n",
        "\n",
        "# Function to find a free port\n",
        "def find_free_port():\n",
        "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    sock.bind(('0.0.0.0', 0)) # Bind to port 0 to let OS find a free port\n",
        "    port = sock.getsockname()[1]\n",
        "    sock.close()\n",
        "    return port\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-KgR74DHa9z",
        "outputId": "88a72953-acad-4048-9164-e8bbf828463f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI configured successfully using Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--- Application Startup ---\n",
        "if __name__ == '__main__':\n",
        "    # Ensure any previous ngrok tunnels are killed before starting a new one\n",
        "    ngrok.kill()\n",
        "\n",
        "    try:\n",
        "        # Get authtoken from environment variable\n",
        "        authtoken = None\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            authtoken = userdata.get('NGROK_TOKEN')\n",
        "        except (ImportError, KeyError):\n",
        "            authtoken = os.getenv('NGROK_TOKEN')\n",
        "\n",
        "        if not authtoken:\n",
        "            raise ValueError(\"NGROK_TOKEN environment variable not set. Please set it in Colab's Secrets (key icon) with 'Notebook access' ON, or as an environment variable.\")\n",
        "\n",
        "        ngrok.set_auth_token(authtoken)\n",
        "        print(\"ngrok authtoken loaded.\")\n",
        "\n",
        "        # Find a free port for Flask to use\n",
        "        flask_port = find_free_port()\n",
        "        print(f\"Flask will attempt to run on dynamically assigned port: {flask_port}\")\n",
        "\n",
        "        # Establish the ngrok tunnel to the dynamically assigned Flask port\n",
        "        print(f\"Attempting to establish ngrok tunnel to port {flask_port}...\")\n",
        "        public_url = ngrok.connect(flask_port).public_url\n",
        "        print(f\"ngrok tunnel started at: {public_url}\")\n",
        "        print(\"Click the link above to view the demo!\")\n",
        "\n",
        "        # Run Flask app in the main thread (blocking call)\n",
        "        # This will now use the same port ngrok is tunneling to\n",
        "        print(f\"Starting Flask app on port {flask_port}...\")\n",
        "        app.run(host=\"0.0.0.0\", port=flask_port, use_reloader=False, debug=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during setup or execution: {e}\")\n",
        "        print(\"Please ensure your ngrok authtoken (NGROK_TOKEN) and Gemini API key (GEMINI) are correctly set in Colab Secrets, and that port is available.\")\n",
        "    finally:\n",
        "        ngrok.kill()\n",
        "        print(\"ngrok tunnel disconnected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG0sGK_0Oxrp",
        "outputId": "91c06df7-282a-4090-98b1-e54390bbb6d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok authtoken loaded.\n",
            "Flask will attempt to run on dynamically assigned port: 48355\n",
            "Attempting to establish ngrok tunnel to port 48355...\n",
            "ngrok tunnel started at: https://942c-34-42-113-87.ngrok-free.app\n",
            "Click the link above to view the demo!\n",
            "Starting Flask app on port 48355...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:48355\n",
            " * Running on http://172.28.0.12:48355\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok tunnel disconnected.\n"
          ]
        }
      ]
    }
  ]
}