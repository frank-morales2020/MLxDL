{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPLbtWNOS9Us54+5Na8BiCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MLxDL/blob/main/videoprism_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/"
      ],
      "metadata": {
        "id": "GOnvXGIVfXFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8QN_F_NioKp",
        "outputId": "e673ebbb-b47c-4e41-d94f-7e897137c6aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 27 03:59:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   75C    P0             34W /   72W |   18577MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibvvk4NDTmWR"
      },
      "outputs": [],
      "source": [
        "# Clone the VideoPrism repository\n",
        "!git clone https://github.com/google-deepmind/videoprism.git\n",
        "\n",
        "# Navigate into the directory\n",
        "%cd videoprism\n",
        "\n",
        "# Install the package and its dependencies\n",
        "!pip install . -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "from videoprism import models as vp\n",
        "\n",
        "# 1. Choose your model variant\n",
        "# You can use 'videoprism_public_v1_base' (smaller) or 'videoprism_public_v1_large' (larger)\n",
        "model_name = 'videoprism_public_v1_large'\n",
        "\n",
        "# 2. Load the model configuration\n",
        "print(f\"Loading VideoPrism model: {model_name}...\")\n",
        "flax_model = vp.MODELS[model_name]()\n",
        "print(\"Model configuration loaded.\")\n",
        "\n",
        "# 3. Load the pre-trained weights\n",
        "print(\"Loading pre-trained weights (this may take a moment)...\")\n",
        "loaded_state = vp.load_pretrained_weights(model_name)\n",
        "print(\"Pre-trained weights loaded.\")\n",
        "\n",
        "# 4. Define the forward pass function for inference\n",
        "# It's crucial to wrap this in jax.jit for correct results and performance\n",
        "@jax.jit\n",
        "def forward_fn(inputs):\n",
        "  \"\"\"Applies the VideoPrism model to input video frames.\"\"\"\n",
        "  return flax_model.apply(loaded_state, inputs, train=False)\n",
        "\n",
        "# 5. Prepare your input video data\n",
        "# VideoPrism expects input videos with shape (batch_size, num_frames, height, width, 3)\n",
        "# The RGB values should be normalized to [0.0, 1.0].\n",
        "# The recommended input resolution is 288x288.\n",
        "# num_frames can be arbitrary, as the model interpolates temporal positional embeddings.\n",
        "batch_size = 1\n",
        "num_frames = 16  # Example: 16 frames\n",
        "height = 288\n",
        "width = 288\n",
        "channels = 3\n",
        "\n",
        "print(f\"Generating dummy video input of shape: ({batch_size}, {num_frames}, {height}, {width}, {channels})\")\n",
        "# Create a dummy video tensor with random float data normalized to [0.0, 1.0]\n",
        "dummy_video_data = np.random.rand(batch_size, num_frames, height, width, channels).astype(np.float32)\n",
        "\n",
        "model_inputs = dummy_video_data\n",
        "\n",
        "# 6. Run inference\n",
        "print(f\"Running inference with input shape: {model_inputs.shape}\")\n",
        "outputs_tuple = forward_fn(model_inputs)\n",
        "\n",
        "# Access the primary output (embeddings) which is typically the first element of the tuple\n",
        "outputs = outputs_tuple[0]\n",
        "print(\"Inference complete.\")\n",
        "\n",
        "# 7. Process the outputs\n",
        "# The output shape is [batch_size, num_tokens, feature_channels].\n",
        "# The `num_tokens` is `num_frames * 16 * 16` for spatiotemporal representations.\n",
        "# You can reshape it to `(batch_size, num_frames, 16, 16, feature_channels)`\n",
        "# for more intuitive spatiotemporal features.\n",
        "print(f\"Raw output embeddings shape: {outputs.shape}\")\n",
        "\n",
        "# Example: Reshaping for spatiotemporal features\n",
        "feature_channels = outputs.shape[-1]\n",
        "reshaped_outputs = outputs.reshape(\n",
        "    batch_size, num_frames, 16, 16, feature_channels\n",
        ")\n",
        "print(f\"Reshaped spatiotemporal embeddings shape: {reshaped_outputs.shape}\")\n",
        "\n",
        "print(\"\\nVideoPrism inference demonstration complete.\")\n",
        "print(f\"Example of the first few values of the generated embeddings:\\n{reshaped_outputs[0, 0, 0, 0, :5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWxdDnGxT0kv",
        "outputId": "d0c441b5-5184-4b1d-eb0b-789cb9d7f948"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading VideoPrism model: videoprism_public_v1_large...\n",
            "Model configuration loaded.\n",
            "Loading pre-trained weights (this may take a moment)...\n",
            "Pre-trained weights loaded.\n",
            "Generating dummy video input of shape: (1, 16, 288, 288, 3)\n",
            "Running inference with input shape: (1, 16, 288, 288, 3)\n",
            "Inference complete.\n",
            "Raw output embeddings shape: (1, 4096, 1024)\n",
            "Reshaped spatiotemporal embeddings shape: (1, 16, 16, 16, 1024)\n",
            "\n",
            "VideoPrism inference demonstration complete.\n",
            "Example of the first few values of the generated embeddings:\n",
            "[ 0.88851106 -0.01135523 -0.01655489 -0.36440778  0.15668297]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy jax jaxlib videoprism imageio imageio-ffmpeg -q"
      ],
      "metadata": {
        "id": "8VHRoBZ6XB12"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imageio.v2 as imageio # Use imageio.v2 for the newer API\n",
        "\n",
        "\n",
        "import jax\n",
        "import numpy as np\n",
        "from videoprism import models as vp\n",
        "\n",
        "# --- Configuration ---\n",
        "model_name = 'videoprism_public_v1_large'\n",
        "# Path for the video file we will generate\n",
        "generated_video_path = '/tmp/generated_test_video.mp4' # Use /tmp for temporary file\n",
        "target_height = 288\n",
        "target_width = 288\n",
        "num_frames_to_generate = 30 # Number of frames for our generated video\n",
        "max_frames_to_process = 16 # Number of frames VideoPrism will actually process from the generated video\n",
        "\n",
        "# --- Function to Generate a Simple MP4 Video ---\n",
        "def generate_simple_mp4_video(output_path, num_frames, height, width, fps=10):\n",
        "    \"\"\"\n",
        "    Generates a simple MP4 video with changing colors.\n",
        "    \"\"\"\n",
        "    writer = imageio.get_writer(output_path, fps=fps)\n",
        "    print(f\"Generating a simple {width}x{height} MP4 video with {num_frames} frames to '{output_path}'...\")\n",
        "    for i in range(num_frames):\n",
        "        # Create a frame with changing color\n",
        "        # Red component varies with frame index\n",
        "        r = int(255 * (i / num_frames))\n",
        "        # Green component varies inversely\n",
        "        g = int(255 * (1 - (i / num_frames)))\n",
        "        b = 100 # Keep blue constant\n",
        "\n",
        "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        frame[:, :] = [r, g, b] # Set all pixels to this color\n",
        "\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    print(\"Video generation complete.\")\n",
        "\n",
        "# --- Video Loading and Preprocessing Function ---\n",
        "def load_and_preprocess_video(file_path, target_h, target_w, max_frames=None):\n",
        "    \"\"\"\n",
        "    Loads video frames, resizes them, converts to RGB, normalizes,\n",
        "    and returns them as a NumPy array suitable for VideoPrism.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Video file not found at: {file_path}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(f\"Could not open video file: {file_path}\")\n",
        "\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break  # No more frames\n",
        "\n",
        "        # Convert BGR (OpenCV default) to RGB\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize frame to target dimensions\n",
        "        frame = cv2.resize(frame, (target_w, target_h))\n",
        "\n",
        "        # Normalize pixel values to [0.0, 1.0]\n",
        "        frames.append(frame / 255.0)\n",
        "\n",
        "        frame_count += 1\n",
        "        if max_frames is not None and frame_count >= max_frames:\n",
        "            break # Stop after desired number of frames\n",
        "\n",
        "    cap.release() # Release the video capture object\n",
        "\n",
        "    if not frames:\n",
        "        raise ValueError(f\"No frames were loaded from the video: {file_path}. \"\n",
        "                         \"Check if the video is valid or if max_frames is too low.\")\n",
        "\n",
        "    # Convert list of frames to a NumPy array and add batch dimension\n",
        "    video_tensor = np.expand_dims(np.array(frames, dtype=np.float32), axis=0)\n",
        "    return video_tensor\n",
        "\n",
        "# --- Main Script ---\n",
        "try:\n",
        "    # 1. Generate a simple video file first\n",
        "    generate_simple_mp4_video(\n",
        "        generated_video_path,\n",
        "        num_frames=num_frames_to_generate,\n",
        "        height=target_height,\n",
        "        width=target_width\n",
        "    )\n",
        "\n",
        "    # 2. Load and preprocess the newly generated video\n",
        "    print(f\"\\nAttempting to load and preprocess video from: {generated_video_path}\")\n",
        "    model_inputs = load_and_preprocess_video(\n",
        "        generated_video_path, target_height, target_width, max_frames=max_frames_to_process\n",
        "    )\n",
        "    print(f\"Video loaded. Input shape for VideoPrism: {model_inputs.shape}\")\n",
        "\n",
        "    # 3. Load the VideoPrism model\n",
        "    print(f\"\\nLoading VideoPrism model: {model_name}...\")\n",
        "    flax_model = vp.MODELS[model_name]()\n",
        "    print(\"Model configuration loaded.\")\n",
        "\n",
        "    # 4. Load the pre-trained weights\n",
        "    print(\"Loading pre-trained weights (this may take a moment)...\")\n",
        "    # !!! IMPORTANT: ALLOW THIS STEP TO COMPLETE WITHOUT INTERRUPTION !!!\n",
        "    loaded_state = vp.load_pretrained_weights(model_name)\n",
        "    print(\"Pre-trained weights loaded.\")\n",
        "\n",
        "    # 5. Define the forward pass function for inference\n",
        "    @jax.jit\n",
        "    def forward_fn(inputs):\n",
        "        \"\"\"Applies the VideoPrism model to input video frames.\"\"\"\n",
        "        return flax_model.apply(loaded_state, inputs, train=False)\n",
        "\n",
        "    # 6. Run inference\n",
        "    print(f\"Running inference with input shape: {model_inputs.shape}\")\n",
        "    outputs_tuple = forward_fn(model_inputs)\n",
        "\n",
        "    # Access the primary output (embeddings) which is typically the first element of the tuple\n",
        "    outputs = outputs_tuple[0]\n",
        "    print(\"Inference complete.\")\n",
        "\n",
        "    # 7. Process the outputs\n",
        "    num_frames_processed = model_inputs.shape[1] # Actual number of frames from the video\n",
        "    batch_size_actual = model_inputs.shape[0]\n",
        "\n",
        "    print(f\"Raw output embeddings shape: {outputs.shape}\")\n",
        "\n",
        "    feature_channels = outputs.shape[-1]\n",
        "    expected_num_tokens = num_frames_processed * 16 * 16\n",
        "\n",
        "    if outputs.shape[1] != expected_num_tokens:\n",
        "        print(f\"Warning: Unexpected number of tokens in raw output. Expected {expected_num_tokens}, got {outputs.shape[1]}.\")\n",
        "\n",
        "    reshaped_outputs = outputs.reshape(\n",
        "        batch_size_actual, num_frames_processed, 16, 16, feature_channels\n",
        "    )\n",
        "    print(f\"Reshaped spatiotemporal embeddings shape: {reshaped_outputs.shape}\")\n",
        "\n",
        "    print(\"\\nVideoPrism inference with programmatically generated video complete.\")\n",
        "    print(f\"Example of the first few values of the generated embeddings for the first frame's top-left patch:\\n{reshaped_outputs[0, 0, 0, 0, :5]}\")\n",
        "\n",
        "    !cp -pr /tmp/generated_test_video.mp4 /content/\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Something went wrong with file generation or loading.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error: {e}. Could not open or read the generated video file.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error during video processing: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "finally:\n",
        "    # Clean up the generated video file\n",
        "    if os.path.exists(generated_video_path):\n",
        "        os.remove(generated_video_path)\n",
        "        print(f\"\\nCleaned up generated video file: {generated_video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fry_dDppXHmq",
        "outputId": "a0a6acde-7e56-448e-de0a-0ac8742da1f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating a simple 288x288 MP4 video with 30 frames to '/tmp/generated_test_video.mp4'...\n",
            "Video generation complete.\n",
            "\n",
            "Attempting to load and preprocess video from: /tmp/generated_test_video.mp4\n",
            "Video loaded. Input shape for VideoPrism: (1, 16, 288, 288, 3)\n",
            "\n",
            "Loading VideoPrism model: videoprism_public_v1_large...\n",
            "Model configuration loaded.\n",
            "Loading pre-trained weights (this may take a moment)...\n",
            "Pre-trained weights loaded.\n",
            "Running inference with input shape: (1, 16, 288, 288, 3)\n",
            "Inference complete.\n",
            "Raw output embeddings shape: (1, 4096, 1024)\n",
            "Reshaped spatiotemporal embeddings shape: (1, 16, 16, 16, 1024)\n",
            "\n",
            "VideoPrism inference with programmatically generated video complete.\n",
            "Example of the first few values of the generated embeddings for the first frame's top-left patch:\n",
            "[-0.02193046 -0.07946897  0.41855606  0.01070144 -0.08500562]\n",
            "\n",
            "Cleaned up generated video file: /tmp/generated_test_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/*.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCOHxe-4d6wG",
        "outputId": "074d713f-b789-493e-9036-273767c70a14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/generated_test_video.mp4\n"
          ]
        }
      ]
    }
  ]
}